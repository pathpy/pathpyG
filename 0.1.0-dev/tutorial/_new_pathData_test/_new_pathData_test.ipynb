{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from tqdm import trange\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.experimental import disable_dynamic_shapes\n",
    "from torch_geometric.nn.aggr import Aggregation\n",
    "from torch_geometric.utils import coalesce, degree, cumsum\n",
    "from torch_geometric import EdgeIndex\n",
    "\n",
    "import pathpyG as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dags = pp.DAGData()\n",
    "dags.append(torch.tensor([[3,0,1],[0,1,2]]))\n",
    "dags.append(torch.tensor([[1,0,2],[0,2,0]]))\n",
    "dags.append(torch.tensor([[0,1],[1,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAGData with 3 dags and total weight 3\n"
     ]
    }
   ],
   "source": [
    "print(dags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor, num_nodes: int | None = None) -> torch.Tensor:\n",
    "        # Since this is a complicated function, we will use the following example to explain the steps:\n",
    "        # Example:\n",
    "        #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],\n",
    "        #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]\n",
    "\n",
    "        # Compute the outdegree of each node which we will use to get all the edge combinations that lead to a higher order edge\n",
    "        # Example:\n",
    "        #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]\n",
    "        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n",
    "\n",
    "        # For each center node, we need to combine each outgoing edge with each incoming edge\n",
    "        # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index\n",
    "        # Example:\n",
    "        #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]\n",
    "        #   num_new_edges = 9\n",
    "        outdegree_per_dst = outdegree[edge_index[1]]\n",
    "        num_new_edges = outdegree_per_dst.sum()\n",
    "\n",
    "        # We use each edge from the edge index as new node and assign the new indices in the order of the original edge index\n",
    "        # Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n",
    "        # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor\n",
    "        # Example:\n",
    "        #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]\n",
    "        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n",
    "\n",
    "        # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges (new higher order nodes) that have the node as source node\n",
    "        # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])\n",
    "        # Example:\n",
    "        #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]\n",
    "        ptrs = cumsum(outdegree, dim=0)[:-1]\n",
    "\n",
    "        # Use these pointers to get the start of the edges for each higher order source node and repeat it `outdegree` times\n",
    "        # Since we keep the ordering, all new higher order edges that have the same source node are indexed consecutively\n",
    "        # Example:\n",
    "        #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]\n",
    "        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n",
    "\n",
    "        # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) for all `outdegree` number of edges consecutively to get the correct destination nodes\n",
    "        # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\n",
    "        # Example: \n",
    "        #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n",
    "        # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.\n",
    "        # Example:\n",
    "        #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]\n",
    "        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n",
    "        # Finally, we add this tensor to the destination nodes to get the correct destination nodes for each higher order edge\n",
    "        # Example:\n",
    "        #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]\n",
    "        ho_edge_dsts += idx_correction\n",
    "    # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n",
    "    #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n",
    "        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_higher_order_index(edge_indices, k):\n",
    "    \"\"\"map node indices in k-th order edge index\n",
    "    to corresponding tensor of k first-order nodes\n",
    "    \"\"\" \n",
    "\n",
    "    # we need to reverse the node indices\n",
    "    # to construct an edge_index with k-th order nodes\n",
    "    \n",
    "    ei = edge_indices[k].reshape(2,-1,1)\n",
    "    \n",
    "    j = 0\n",
    "    for i in range(k-1, 0, -1):\n",
    "        src_edge, tgt_edge = ei\n",
    "        src = edge_indices[i][:,src_edge]\n",
    "        tgt = edge_indices[i][:,tgt_edge]\n",
    "        if j == 0:\n",
    "            ei = torch.cat([src, tgt], dim=2)\n",
    "        else:\n",
    "            ei = torch.cat([src[:,:,:j], tgt], dim=2)\n",
    "        j -= 1\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_DAGs(data: pp.DAGData, max_order: int = 1) -> pp.MultiOrderModel:\n",
    "    \"\"\"Creates multiple higher-order De Bruijn graphs for paths in DAGData.\"\"\"\n",
    "    m = pp.MultiOrderModel()\n",
    "\n",
    "    data_list = [Data(edge_index=dag.long()) for dag in data.dags]\n",
    "    # We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs\n",
    "    # If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards\n",
    "    # Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once\n",
    "    dag_graph = next(iter(DataLoader(data_list, batch_size=len(data.dags))))\n",
    "    dag_edge_index = dag_graph.edge_index\n",
    "    dag_edge_index = coalesce(dag_edge_index)\n",
    "\n",
    "    print(dag_edge_index)\n",
    "    print(dag_graph.ptr)\n",
    "    print(dag_graph.batch)\n",
    "\n",
    "    edge_index = pp.MultiOrderModel.map_batch_indices(dag_edge_index, dag_graph.batch, dag_graph.ptr)\n",
    "    unique_nodes = torch.unique(edge_index)\n",
    "    m.layers[1] = pp.Graph(Data(edge_index=edge_index, num_nodes=unique_nodes.size(), fo_nodes=unique_nodes.reshape(-1, 1)))\n",
    "    print(m.layers[1].data.edge_index)\n",
    "    print(m.layers[1].data.fo_nodes)\n",
    "\n",
    "    edge_indices = {}\n",
    "    edge_indices[1] = edge_index\n",
    "\n",
    "    for k in range(2, max_order+1):\n",
    "        print('=== k={0} ==='.format(k))\n",
    "        num_nodes = torch.unique(dag_edge_index).size(0)\n",
    "        print('num nodes = ', num_nodes)\n",
    "        ho_index = lift_order_edge_index(dag_edge_index, num_nodes = num_nodes)\n",
    "        edge_indices[k] = ho_index\n",
    "        print(ho_index)\n",
    "\n",
    "        # Map k-th-order edge index to nodes in (k-1)-th order edge index\n",
    "        # src_edge, tgt_edge = ho_index\n",
    "        # src = dag_edge_index[:,src_edge]\n",
    "        # tgt = dag_edge_index[:,tgt_edge]\n",
    "        # print(src)\n",
    "        # print(tgt)\n",
    "\n",
    "        #ho_edge_index, inverse = x.unique(dim=0, return_inverse=True)\n",
    "\n",
    "        # weights of the two unique higher-order edges should be N and 3*N\n",
    "        # weights of k-th element in output = sum of all w at indices where inverse is k\n",
    "        #weights = torch.zeros(ho_edge_index.size()[0], device=config['torch']['device'], dtype=torch.long).index_add(0, inverse, w)\n",
    " \n",
    "\n",
    "        #m.layers[k] = pp.Graph(data=Data(edge_index=dag_edge_index))\n",
    "\n",
    "        dag_edge_index = coalesce(ho_index)\n",
    "\n",
    "    return m, edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 3, 4, 5, 6, 7, 8],\n",
      "        [1, 2, 0, 6, 4, 4, 8, 9]])\n",
      "tensor([ 0,  4,  7, 10])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 2, 2, 2])\n",
      "EdgeIndex([[0, 0, 0, 1, 1, 1, 2, 3],\n",
      "           [1, 2, 1, 2, 0, 2, 0, 0]], sparse_size=(4, 4), nnz=8,\n",
      "          sort_order=row)\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "=== k=2 ===\n",
      "num nodes =  10\n",
      "tensor([[0, 2, 3, 4, 5, 6],\n",
      "        [1, 0, 5, 3, 3, 7]])\n",
      "=== k=3 ===\n",
      "num nodes =  8\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [0, 4, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "m, edge_indices = from_DAGs(dags, max_order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3, 0, 1],\n",
       "         [0, 2, 0],\n",
       "         [1, 0, 2],\n",
       "         [2, 0, 2]],\n",
       "\n",
       "        [[0, 1, 2],\n",
       "         [2, 0, 2],\n",
       "         [0, 2, 0],\n",
       "         [0, 2, 0]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_higher_order_index(edge_indices, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
