{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pathpyG","text":"<p>This is the index page of the pathpyG documentation.</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#what-is-pathpyg","title":"What is pathpyG?","text":"<p>pathpyG is an Open Source package facilitating GPU-accelerated next-generation network analytics and graph learning for time series data on graphs.</p> <p>pathpyG is tailored to analyse time-stamped network data as well as sequential data that capture multiple short walks or paths observed in a graph or network. Examples for data that can be analysed with pathpyG include high-resolution time-stamped network data, dynamic social networks, user click streams on the Web, biological pathway data, directed acyclic graphs like citation networks, passenger trajectories in transportation networks, or trajectories of information propagation in social networks.</p> <p>pathpyG is fully integrated with jupyter, providing rich interactive visualisations of networks, temporal networks, and higher-order models. Visualisations can be exported to HTML5 files that can be shared and published on the Web.</p>"},{"location":"about/#what-is-the-science-behind-pathpyg","title":"What is the science behind pathpyG?","text":"<p>The theoretical foundation of this package, higher- and multi-order network models, was developed in the following peer-reviewed research articles:</p> <ol> <li>L Qarkaxhija, V Perri, I Scholtes: De Bruijn goes Neural: Causality-Aware Graph Neural Networks for Time Series Data on Dynamic Graphs, In Proceedings of the First Learning on Graphs Conference, PMLR 198:51:1-51:21, December 2022</li> <li>L Petrovic, I Scholtes: Learning the Markov order of paths in graphs, In Proceedings of WWW '22: The Web Conference 2022, Lyon, France, April 2022</li> <li>V Perri, I Scholtes: HOTVis: Higher-Order Time-Aware Visualisation of Dynamic Graphs, In Proceedings of the 28<sup>th</sup> International Symposium on Graph Drawing and Network Visualization (GD 2020), Vancouver, BC, Canada, September 15-18, 2020</li> <li>I Scholtes: When is a network a network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks, In KDD'17 - Proceedings of the 23<sup>rd</sup> ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, Nova Scotia, Canada, August 13-17, 2017</li> <li>I Scholtes, N Wider, A Garas: Higher-Order Aggregate Networks in the Analysis of Temporal Networks: Path structures and centralities, The European Physical Journal B, 89:61, March 2016</li> <li>I Scholtes, N Wider, R Pfitzner, A Garas, CJ Tessone, F Schweitzer: Causality-driven slow-down and speed-up of diffusion in non-Markovian temporal networks, Nature Communications, 5, September 2014</li> <li>R Pfitzner, I Scholtes, A Garas, CJ Tessone, F Schweitzer: Betweenness preference: Quantifying correlations in the topological dynamics of temporal networks, Phys Rev Lett, 110(19), 198701, May 2013</li> </ol> <p>A broader view on the importance of higher-order graph models for complex systems can be found in this overview article. </p>"},{"location":"contributing/","title":"Contributing","text":"<p>This project is open source and welcomes contributions. In the following sections, you will find information about how to contribute to this project, set up your environment correctly, how to document your code and more.</p>"},{"location":"contributing/#overview","title":"Overview","text":"<ul> <li>Setting up your environment</li> <li>Documentation</li> <li>Code Style</li> <li>Formatting</li> <li>Testing</li> <li>Benchmarking</li> </ul>"},{"location":"contributing/#setting-up-your-environment","title":"Setting up your environment","text":""},{"location":"contributing/#clone-the-repository","title":"Clone the Repository","text":"<p>The first step is to clone the repository. You can do this by running the following command: <pre><code>git clone https://github.com/pathpy/pathpyG\n</code></pre> If you do not have the rights to push to the repository, you can also fork the repository and clone your fork instead. From there you can create a pull request to the original repository.</p>"},{"location":"contributing/#installation","title":"Installation","text":"<p>To ensure version consistency, we use a Development Container for this project.   VSCode provides an easy-to-use extension for this. Check out their official documentation for more information. Once you've installed the extension successfully,   VSCode will recommend reopening the project in the Dev Container. You can also do this manually by clicking on the button in the bottom left corner of   VSCode and then selecting <code>Reopen in Container</code>.</p> Setup without Dev Containers <p>If you do not want to use Dev Containers, you can also install the dependencies into your virtual Python environment manually. We recommend that you follow the instructions provided on our getting started page. As last step, install the package in editable mode and include the dependencies necessary for testing, documentation and general development: <pre><code>pip install -e '.[dev,test,doc]'\n</code></pre></p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>This project uses <code>MkDocs</code> for documentation. It is a static site generator that creates the necessary <code>html</code>-files automatically from the <code>markdown</code>-files and  Group.svg Created using Figma 0.90  Jupyter notebooks in the <code>docs/</code>-directory and the <code>Python</code>-files in <code>src/</code>. The documentation is hosted on GitHub Pages.</p>"},{"location":"contributing/#hosting-the-documentation-locally","title":"Hosting the documentation locally","text":"<p>You can host the documentation locally with the following command: <pre><code>mkdocs serve\n</code></pre> The documentation is then available at <code>http://localhost:8000/</code>.</p> Actual Deployment <p>The development version of the documentation is deployed automatically to GitHub Pages when something is pushed to the <code>main</code>-branch. The workflow for deploying a new stable version needs to be triggered manually. You can find it in the <code>Actions</code>-tab of the repository. Both workflows use <code>mike</code> instead of <code>MkDocs</code> to enable versioning.</p>"},{"location":"contributing/#code-reference","title":"Code Reference","text":"<p>The <code>Code Reference</code> is generated automatically from the   Python source files. The docstrings should be formatted according to the Google Python Style Guide. Be sure to also use the advanced stuff like notes, tips and more. They can e.g. look as follows:</p> DocstringResult <pre><code>\"\"\"\nNote:\n    This is a note.\n\nTip: This is a heading\n    This is a tip.\n\"\"\"\n</code></pre> <p>Note</p> <p>This is a note.</p> <p>This is a heading</p> <p>This is a tip.</p> <p>See the documentation of the underlying griffe package for more details.</p> <p>To get an overview for each module, <code>mkdocstrings</code> automatically uses the docstrings from the <code>__init__.py</code> files in each module as description. Thus, do not forget to add a docstring to each <code>__init__.py</code> file.</p>"},{"location":"contributing/#tutorials","title":"Tutorials","text":"<p>The tutorials are written in  Group.svg Created using Figma 0.90  Jupyter notebooks. They are located in the <code>docs/</code>-directory. You can add new tutorials by adding the notebook to the <code>docs/tutorial/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The tutorials are automatically converted to <code>html</code>-files when the documentation is built.</p>"},{"location":"contributing/#adding-new-pages","title":"Adding new pages","text":"<p>You can add more pages to the documentation by adding a <code>markdown</code>-file to the <code>docs/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The pages are automatically converted to <code>html</code>-files when the documentation is built. We are using Material for MkDocs as a theme. It includes many great features like annotations, code blocks, diagrams, admonitions and more. Check out their documentation for more information.</p>"},{"location":"contributing/#code-style","title":"Code Style","text":"<p>We (soon) enforce code style guidelines with <code>pylint</code>, <code>flake8</code>, <code>mypy</code> and <code>pyright</code>. These packages are configured as defaults in the Dev Container setup via <code>VSCode</code> and the settings are saved in <code>pyproject.toml</code>. You can run them locally with the following commands:</p> <ul> <li><code>pylint</code>: A linter that checks for errors and code style violations.     <pre><code>pylint scr/ # (1)!\n</code></pre><ol> <li>This runs <code>pylint</code> on all files in <code>scr/</code>. You can also run <code>pylint</code> on a single file by specifying the path to the file instead.</li> </ol> </li> <li><code>flake8</code>: Another linter that checks for bad code smells and suspicious constructs.     <pre><code>flake8 . # (1)!\n</code></pre><ol> <li>This runs <code>flake8</code> on all files in the current directory. You can also run <code>flake8</code> on a single file or a subdirectory by specifying the path accordingly.</li> </ol> </li> <li><code>mypy</code>: A static type checker for Python.     <pre><code>mypy src/ # (1)!\n</code></pre><ol> <li>This runs <code>mypy</code> on all files in <code>src/</code>. You can also run <code>mypy</code> on a single file by specifying the path to the file instead.</li> </ol> </li> <li><code>pyright</code>: A second static type checker for Python.     <pre><code>pyright . # (1)!\n</code></pre><ol> <li>This runs <code>pyright</code> on all files in the current directory. You can also run it on a single file or a subdirectory by specifying the path accordingly.</li> </ol> </li> </ul>"},{"location":"contributing/#formatting","title":"Formatting","text":"<p>We use <code>black</code> for formatting. You can run it locally with the following command:</p> <pre><code>black . # (1)!\n</code></pre> <ol> <li>This command will format all files in the current directory. You can also run <code>black</code> on a single file or a subdirectory by specifying the path accordingly.</li> </ol> <p>We further use <code>isort</code> for sorting imports. You can run it locally with the following command: <pre><code>isort .\n</code></pre> The default keyboard shortcut for formatting in <code>VSCode</code> is <code>Alt + Shift + F</code>.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>We are using <code>pytest</code> for testing. You can run the tests locally with the following command: <pre><code>pytest\n</code></pre> The tests are located in the <code>tests/</code>-directory. We use <code>pytest-cov</code> to measure the test coverage and are aiming for 100% coverage with a hard limit of 80%. Tests will fail if the coverage drops below 80%.</p> <p>Add tests</p> <p>We are currently only at 60% coverage. So the lines above are currently pure fiction.</p>"},{"location":"contributing/#benchmarking","title":"Benchmarking","text":"<p>For optimal runtime, we continually measure the execution time of our core functions using pytest benchmarks. These benchmarks are located in <code>tests/benchmarks/</code> and are unit-tests that utilize the <code>benchmark</code> fixture from <code>pytest-benchmark</code>. All of them are marked with the benchmark decorator (<code>@pytest.mark.benchmark</code>) to exclude them from the normal unit-tests. You can run all benchmarks in the command line using <pre><code>pytest -m benchmark\n</code></pre> If you are working on runtime improvements, you can compare the runtime of your changes to the runtime of the main branch by saving the results of each run with <pre><code>pytest -m benchmark --benchmark-autosave\n</code></pre> or with a custom name <code>&lt;custom-name&gt;</code> <pre><code>pytest -m benchmark --benchmark-save=&lt;custom-name&gt;\n</code></pre> After running the benchmarks both in your current branch and in the main branch, you can compare them as follows: <pre><code>pytest-benchmark compare # (1)!\n</code></pre></p> <ol> <li>This will compare all runs that are currently saved in <code>.benchmarks/</code>. If you want to compare specific runs, you can add the number of the runs at the end of the command. The numbering usually starts with <code>0001</code>.</li> </ol> <p>Note</p> <p>Since the runtime is strongly dependent on the underlying machine, we do not keep any up-to-date results on <code>git</code> and recommend to do any comparisons locally.</p>"},{"location":"docker_installation/","title":"Docker Installation","text":"<p>  PyTorch provides a  Docker image with PyTorch preinstalled. Using this image, the Dockerfile below creates a Docker image with PathpyG installed.</p> GPUCPU <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre> <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu # CPU only\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html # CPU only\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate the code reference pages and navigation.\"\"\"\n# See for more detail: https://mkdocstrings.github.io/recipes/\n</pre> \"\"\"Generate the code reference pages and navigation.\"\"\" # See for more detail: https://mkdocstrings.github.io/recipes/ In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n</pre> nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>for path in sorted(Path(\"src\").rglob(\"*.py\")):\n    module_path = path.relative_to(\"src\").with_suffix(\"\")\n    doc_path = path.relative_to(\"src\").with_suffix(\".md\")\n    full_doc_path = Path(\"reference\", doc_path)\n\n    parts = tuple(module_path.parts)\n\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1] == \"__main__\":\n        continue\n\n    nav[parts] = doc_path.as_posix()\n\n    with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n        ident = \".\".join(parts)\n        fd.write(f\"::: {ident}\")\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path)\n</pre> for path in sorted(Path(\"src\").rglob(\"*.py\")):     module_path = path.relative_to(\"src\").with_suffix(\"\")     doc_path = path.relative_to(\"src\").with_suffix(\".md\")     full_doc_path = Path(\"reference\", doc_path)      parts = tuple(module_path.parts)      if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1] == \"__main__\":         continue      nav[parts] = doc_path.as_posix()      with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:         ident = \".\".join(parts)         fd.write(f\"::: {ident}\")      mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path) In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"getting_started/","title":"Getting Started","text":"<p>The following will guide you through the installation of the package and the first steps to use it.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>PathpyG is available for   Python versions 3.10 and above. It is not recommended to install it on your system Python. Instead, we recommend using a virtual environment such as   conda or virtualenv. You can also set up a   Docker image as described in the next section.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<p>Once you have an environment up and running, you can install the package simply via pip. But first make sure that you installed the necessary dependencies.</p>"},{"location":"getting_started/#dependencies","title":"Dependencies","text":"<p>This package is based on   PyTorch and   PyTorch Geometric. Please install both libraries before installing PathpyG. You can follow the installation instructions in their respective documentation (  PyTorch and   PyG).</p> <p>Warning</p> <p>We currently only support PyG version 2.5.0 and above.</p>"},{"location":"getting_started/#install-stable-release","title":"Install Stable Release","text":"<p>You can install the latest stable release of PathpyG via pip:</p> <p>TODO</p> <p>This is not yet available. We will release the first stable version soon.</p> <pre><code>pip install pathpyg\n</code></pre>"},{"location":"getting_started/#install-latest-development-version","title":"Install Latest Development Version","text":"<p>If you want to install the latest development version, you can do so via pip directly from the GitHub repository:</p> <pre><code>pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"plot_tutorial/","title":"Develop Custom Plot Functions","text":"<p>This tutorial guides you through the process of creating your own plotting functions in pathpyG.</p> <p>The visualization framework of pathpyg is designed in such a way that is easy to extend it according your own needs.</p> <p>For this tutorial we want to implement capabilities to plot histograms.</p> <p>You will learn:</p> <ul> <li>How to set up a generic plot function</li> <li>How to convert <code>pathpyG</code> data to plot data</li> <li>How to plot with <code>d3js</code> </li> <li>How to plot with <code>tikz</code></li> <li>How to plot with <code>matplotlib</code></li> </ul>"},{"location":"plot_tutorial/#structure","title":"Structure","text":"<p>Plotting commands and functions are located under <code>/src/pathpyG/visualisation/</code></p> <pre><code>\ud83d\udcc1 visualisation\n\u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u251c\u2500\u2500 \ud83d\udcc1 _d3js\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc1 _matplotlib\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc1 _tikz\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc4 layout.py\n\u251c\u2500\u2500 \ud83d\udcc4 network_plots.py\n\u251c\u2500\u2500 \ud83d\udcc4 plot.py\n\u2514\u2500\u2500 \ud83d\udcc4 utils.py\n</code></pre> <p>Folders with <code>_...</code> indicate the supported backends. We will have a look at them later.</p> <p>The <code>layout.py</code> file includes algorithms to calculate the positions of the nodes.</p> <p>In the <code>utils.py</code> file are useful helper functions collected. E.g. among others a function that converts <code>hex_to_rgb</code>, <code>rgb_to_hex</code>, or a simple <code>Colormap</code> class. If your plot needs generic functions which might be helpful for other plots as well, this would be a good place to store them.</p> <p>The <code>network_plots.py</code> file includes all plots related to network visualization. We will create in this tutorial a similar collection for histograms.</p> <p>Finally, the <code>plot.py</code> file contains our generic <code>PathPyPlot</code> class which we will use to build our own class. </p> <p>This abstract class has a property <code>_kind</code> which will specify the type of plot for the generic plot function. Similar to <code>pandas</code> we should be able to call:</p> <pre><code>pp.plot(graph, kind=\"hist\")\n</code></pre> <p>This abstract class has two dict variables <code>self.data</code> and <code>self.config</code>. The <code>self.data</code> variable is used to store the data needed for the plot, while the <code>self.config</code> stores all the configurations passed to the plot.</p> <p>Furthermore this class has three abstract methods we have to define later for our supported backends: <code>generate</code> to generate the plot, <code>save</code> to save the plot to a file, <code>show</code> to show the current plot.</p>"},{"location":"plot_tutorial/#lets-get-started","title":"Let's get started","text":"<p>In order to get started, we have to create a new python file where we will store our histogram plots. So let's generate a new file <code>hist_plots.py</code></p> <pre><code>touch hist_plots.py\n</code></pre> <p>We start with creating a function which allows us later to plot a histogram.</p> <p>This function will take a <code>Graph</code> object as input and has the parameters <code>key</code> and <code>bins</code> as well as a dict of <code>kwargs</code> for furthermore specifications.</p> <p>We will use the <code>key</code> variable to define the data type of the histogram e.g. <code>by='betweenes'</code> to get the betweenes centrality plotted. With the <code>bins</code> parameters we will change the amount of bins in the histogram. all other options will by passed to the function as keyword arguments and can be backend specific.</p> <pre><code>\"\"\"Histogram plot classes.\"\"\"\nfrom __future__ import annotations\n\nimport logging\n\nfrom typing import TYPE_CHECKING, Any\n\n# pseudo load class for type checking\nif TYPE_CHECKING:\n    from pathpyG.core.Graph import Graph\n\n# create logger\nlogger = logging.getLogger(\"pathpyG\")\n\n\ndef hist(network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre> <p>pathpyG is using logging to print out messages and errors. It's a good habit to use it also for your plotting function.</p> <p>Our <code>hist</code> function will be callable via the package. e.g. <code>pp.hist(...)</code>. Itself it will return a plotting class which we have to create.</p> <pre><code>from pathpyG.visualisations.plot import PathPyPlot\n\nclass HistogramPlot(PathPyPlot):\n    \"\"\"Histogram plot class for a network properties.\"\"\"\n\n    _kind = \"hist\"\n\n    def __init__(self, network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.config['bins'] = bins\n        self.config['key'] = key\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n</code></pre> <p>The <code>HistogramPlot</code> plotting class is a child from our abstract <code>PathPyPlot</code> function. We will overwrite the abstract <code>generate()</code> function in order to get the data needed for our plot.</p> <p>By convention we assume <code>d3js</code> will be the default plot backend, hence the final data generated by this function should provide the necessary data structure for this backend. </p> <p>For other backends, this data might be needed to be converted e.g. keywords might be different. We will address this later in our tutorial.</p>"},{"location":"plot_tutorial/#testing-testing-testing","title":"Testing, Testing, Testing","text":"<p>Before we start developing our histogram plot, we should set up a test environment so that we can directly develop the unit test next to our plot function.</p> <p>Therefore we are going to our testing folder an create a new test file.</p> <pre><code>cd ../../../tests/\ntouch test_hist.py\n</code></pre> <p>Now we can create a simple test environment with a simple graph and call our <code>hist(...)</code> function.</p> <pre><code>from pathpyG.core.Graph import Graph\nfrom pathpyG.visualisations.hist_plots import hist\n\n\ndef test_hist_plot() -&gt; None:\n    \"\"\"Test to plot a histogram.\"\"\"\n    net = Graph.from_edge_list([[\"a\", \"b\"], [\"b\", \"c\"], [\"a\", \"c\"]])\n    hist(net)\n</code></pre> <p>Note: If you only want to run this function and not all other test you can use:</p> <pre><code>pytest -s -k 'test_hist_plot'\n</code></pre>"},{"location":"plot_tutorial/#generating-the-plot-data","title":"Generating the plot data","text":"<p>To plot our histogram we first have to generate the required data from our graph.</p> <p>In the future we might want to add more options for histograms, hence we use the <code>match</code>-<code>case</code> function form python.</p> <pre><code>    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n\n        data: dict = {}\n\n        match self.config[\"key\"]:\n            case \"indegrees\":\n                logger.debug(\"Generate data for in-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n            case \"outdegrees\":\n                logger.debug(\"Generate data for out-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n            case _:\n                logger.error(\n                    f\"The &lt;{self.config['key']}&gt; property\",\n                    \"is currently not supported for hist plots.\",\n                )\n                raise KeyError\n\n        data[\"title\"] = self.config[\"key\"]\n        self.data[\"data\"] = data\n</code></pre> <p>First we initialize a dictionary <code>data</code> to store our values. In this case we are interested in the in and out-degrees of our graph, which are already implemented in <code>pathpyG</code> (state 2023-11-26). </p> <p>If the keyword is not supported the function will raise a <code>KeyError</code>.</p> <p>To provide a default title for our plot we also store the keyword in the data dict. If further data is required for the plot it can be stored here.</p> <p>Finally, we add the data dict to our <code>self.data</code> variable of the plotting class. This variable will be used later in the backend classes.</p> <p>With this our basic histogram plot function is finished. We are now able to call the plot function, get the data from our graph and create a data-set which can be passed down to the backend for visualization.</p>"},{"location":"plot_tutorial/#the-matplotlib-backend","title":"The matplotlib backend","text":"<p>Let's open the <code>_matplotlib</code> folder located under <code>/src/pathpyG/visualisation/_matplotlib</code>, where all matplotlib functions are stored.</p> <pre><code>\ud83d\udcc1 _matplotlib\n\u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u251c\u2500\u2500 \ud83d\udcc4 core.py\n\u2514\u2500\u2500 \ud83d\udcc4 network_plots.py\n</code></pre> <p>The <code>_init_.py</code> holds the configuration for the plot function, which we will modify later. The <code>core.py</code> file contains the generic <code>MatplotlibPlot</code> class, which provides <code>save</code> and <code>show</code> functionalities for our plots. We do not need to modify these functions. Instead, we have to generate a translation function from our generic data dict (see above) to a histogram in matplotlib. To do so, lets create first a new python file named <code>hist_plots.py</code></p> <pre><code>cd _matplotlib\ntouch hist_plots.py\n</code></pre> <p>Here we will add our missing piece for a functional matplotlib plot.</p> <pre><code>\"\"\"Histogram plot classes.\"\"\"\nfrom __future__ import annotations\n\nimport logging\n\nfrom typing import TYPE_CHECKING, Any\n\n# pseudo load class for type checking\nif TYPE_CHECKING:\n    from pathpyG.core.Graph import Graph\n\n# create logger\nlogger = logging.getLogger(\"pathpyG\")\n\n\ndef hist(network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre>"},{"location":"tutorial/","title":"Overview","text":"<p>In this tutorial, we will introduce basic concepts of pathpyG. pathpyG can be used as a wrapper around pytorch-geometric that facilitates network analysis, graph learning, and interactive data visualization. However, its real power comes into play when modelling causal path structures in time series data on networks, such as trajectories on graphs or temporal graphs with time-stamped interactions. pathpyG allows to compute causal paths in temporal graphs and model them based on higher-order De Bruijn graphs, a higher-dimensional generalization of standard graph models for relational data.</p> <p>The following introductory video explains the basic idea of higher-order De Bruijn graph models for causal path structures in time series data:</p> <p>The science behind pathpyG has been published in outlets like SIGKDD, WWW, Learning on Graphs, Nature Communications, Nature Physics, and Physical Review Letters. Please check here for more details on key scientific works that have laid the foundations for this package.</p> <p>Different from previous versions of pathpy, the latest version pathpyG fully utilizes the power of torch and tensor-based representations of sparse graph models to failitate the use of higher-order De Bruijn graph models. pathpyG's data structures naturally generalize the concepts of pytorch-geometric, which makes it easy to apply it in (temnporal) graph learning tasks.</p> <p>Finally, pathpyG comes with an implementation of De Bruijn Graph Neural Networks (DBGNN), a causality-aware deep learning architecture for temporal graph data. In the tutorial, we illustrate this temporal graph learning approach in a simple toy example.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>pathpyG<ul> <li>algorithms<ul> <li>RollingTimeWindow</li> <li>centrality</li> <li>components</li> <li>generative_models</li> <li>random_graphs</li> <li>shortest_paths</li> <li>temporal</li> <li>weisfeiler_leman</li> </ul> </li> <li>core<ul> <li>Graph</li> <li>IndexMap</li> <li>MultiOrderModel</li> <li>TemporalGraph</li> <li>path_data</li> </ul> </li> <li>io<ul> <li>netzschleuder</li> </ul> </li> <li>nn<ul> <li>dbgnn</li> </ul> </li> <li>processes<ul> <li>process</li> <li>random_walk</li> <li>sampling</li> </ul> </li> <li>statistics<ul> <li>degrees</li> <li>node_similarities</li> </ul> </li> <li>utils<ul> <li>config</li> <li>dbgnn</li> <li>progress</li> </ul> </li> <li>visualisations<ul> <li>_d3js<ul> <li>core</li> <li>network_plots</li> </ul> </li> <li>_matplotlib<ul> <li>core</li> <li>network_plots</li> </ul> </li> <li>_tikz<ul> <li>core</li> <li>network_plots</li> </ul> </li> <li>hist_plots</li> <li>layout</li> <li>network_plots</li> <li>plot</li> <li>utils</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/pathpyG/","title":"pathpyG","text":"<p>pathpyG is an Open Source package facilitating next-generation network analytics and graph learning for time series data on graphs.</p> <p>Building on the industry-proven data structures and concepts of <code>pytorch</code> and <code>torch_geometric</code>, pathpyG makes it easier than ever to apply machine learning to temporal graph data.</p> <p>pathpyG is jointly developed at University of Wuerzburg, Princeton University, and University of Zurich. The research behind pathpyG has been funded by the Swiss National Science Foundation via  grant 176938.</p>"},{"location":"reference/pathpyG/algorithms/","title":"algorithms","text":"<p>Algorithms for temporal path calculation and graph metrics.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG and configure your torch device if you want to use GPU .\nimport pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n\n# Generate a toy example for a temporal graph.\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)\n])\n\n# Extract DAG capturing causal interaction sequences in temporal graph.\ne_i = pp.algorithms.lift_order_temporal(g, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\nprint(dag)\n\n# Calculate shortest time-respecting pathas\ndist, pred = pp.algorithms.temporal.temporal_shortest_paths(g, delta=1)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as \n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if 'num_nodes' not in data:\n            data.num_nodes = data.edge_index.max().item()+1\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if data.edge_index.get_sparse_size(dim=0) != data.num_nodes or data.edge_index.get_sparse_size(dim=1) != data.num_nodes:\n            raise Exception('sparse size of EdgeIndex should match number of nodes!')\n\n        # sort EdgeIndex and validate\n        data.edge_index = data.edge_index.sort_by('row').values\n        data.edge_index.validate()\n\n        self.data = data\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i\n            for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes=None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can \n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index\n\n        Example:\n            ```py\n            import pathpyG as pp\n\n            g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            print(g)\n\n            g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                                    mapping=pp.IndexMap(['a', 'b', 'c']))\n            print(g)\n            ```\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else: \n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(\n            d,\n            mapping=mapping\n        )\n\n\n    @staticmethod\n    def from_edge_list(edge_list: Iterable[Tuple[str, str]], is_undirected: bool = False, mapping: IndexMap = None, num_nodes=None) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n        Example:\n            ```\n            import pathpyG as pp\n\n            l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            g = pp.Graph.from_edge_list(l)\n            print(g)\n            print(g.mapping)\n\n            l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            g = pp.Graph.from_edge_list(l)\n            print(g)\n            print(g.mapping)\n            ```\n        \"\"\"\n\n        if mapping is None:\n            node_ids = set()\n            for v, w in edge_list:\n                node_ids.add(v)\n                node_ids.add(w)\n            node_list = list(node_ids)\n            node_list.sort()\n            mapping = IndexMap(node_list)\n\n        sources = []\n        targets = []\n        for v, w in edge_list:\n            sources.append(mapping.to_idx(v))\n            targets.append(mapping.to_idx(w))\n\n        if num_nodes is None:\n            num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex([sources, targets], sparse_size=(num_nodes, num_nodes), is_undirected=is_undirected, device=config['torch']['device'])\n        return Graph(\n            Data(edge_index=edge_index, num_nodes=num_nodes),\n            mapping=mapping\n        )\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        tf = ToUndirected()\n        d = tf(self.data)\n        # unfortunately, the application of a transform creates a new edge_index of type tensor\n        # so we have to recreate the EdgeIndex tensor and sort it again\n\n        e = EdgeIndex(data=d.edge_index, is_undirected=True)\n        d.edge_index = e\n        return Graph(d, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\"\"\"\n        i, w = torch_geometric.utils.coalesce(self.data.edge_index, torch.ones(self.M).to(config[\"torch\"][\"device\"]))\n        return Graph(Data(edge_index=i, edge_weight=w), mapping=self.mapping)\n\n    @staticmethod\n    def attr_types(attr: Dict) -&gt; Dict:\n        \"\"\"\n        Return name, type, and size of all node, edge, and graph attributes.\n\n        This method returns a dictionary that contains the name (key), as well as\n        the type and size of all attributes.\n        \"\"\"\n        a = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                a[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                a[k] = str(t)\n        return a\n\n    def node_attrs(self) -&gt; List:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_id` attribute.\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_id\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; Generator[Union[int, str], None, None]:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a generator object that yields all nodes.\n        If an IndexMap is used, nodes\n        are returned as str IDs. If no IndexMap is used, nodes\n        are returned as integer indices.\n        \"\"\"\n        for i in range(self.N):\n            yield self.mapping.to_id(i)\n\n    @property\n    def edges(self) -&gt; Generator[Union[Tuple[int, int], Tuple[str, str]], None, None]:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a generator object that yields all edges.\n        If an IndexMap is used to map node indices to string IDs, edges\n        are returned as tuples of str IDs. If no mapping is used, edges\n        are returned as tuples of integer indices.\n        \"\"\"\n        for e in self.data.edge_index.t():\n            yield self.mapping.to_id(e[0].item()), self.mapping.to_id(e[1].item())\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([])\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n        \"\"\"        \n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([])\n\n    def successors(self, node: Union[int, str] | tuple) \\\n            -&gt; Generator[Union[int, str] | tuple, None, None]:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n        \"\"\"\n\n        for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n            yield self.mapping.to_id(j.item())\n\n    def predecessors(self, node: Union[str, int] | tuple) \\\n            -&gt; Generator[Union[int, str] | tuple, None, None]:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n        \"\"\"\n        for i in self.get_predecessors(self.mapping.to_idx(node)):  # type: ignore\n            yield self.mapping.to_id(i.item())\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID \n        \"\"\"\n        row = self.mapping.to_idx(v)\n        ((row_ptr, col), perm) = self.data.edge_index.get_csr()\n        row_start = row_ptr[row]\n        row_end   = row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in col[row_start:row_end]\n\n    def get_sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index, edge_attr=self.data[edge_attr], num_nodes=self.N\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return in-degrees of nodes in directed network.\"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return out-degrees of nodes in directed network.\"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n        \"\"\"\n        Return degrees of nodes.\n\n        Args:\n            mode:   `in` or `out` to calculate the in- or out-degree for\n                directed networks.\n        \"\"\"\n        if mode == \"in\":\n            d = torch_geometric.utils.degree(\n                self.data.edge_index[1], num_nodes=self.N, dtype=torch.int\n            )\n        else:\n            d = torch_geometric.utils.degree(\n                self.data.edge_index[0], num_nodes=self.N, dtype=torch.int\n            )\n        return {self.mapping.to_id(i): d[i].item() for i in range(self.N)}\n\n    def get_laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.get_laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.get_laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization:  normalization parameter passed to pyG `get_laplacian`\n                            function\n            edge_attr:      optinal name of numerical edge attribute that shall\n                            be passed to pyG `get_laplacian` function as edge weight\n        \"\"\"\n        if edge_attr is None:\n            index, weight =torch_geometric.utils.get_laplacian(\n                self.data.edge_index, normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index,\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def add_node_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n        \"\"\"Add one-hot encoding of nodes to node attribute.\n\n        Args:\n            attr_name: attribute name used to store one-hot encoding\n            dim: dimension of one-hot encoding\n        \"\"\"\n        if dim == 0:\n            dim = self.N\n        self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n            config[\"torch\"][\"device\"]\n        )[: self.N]\n\n    def add_edge_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n        \"\"\"Add one-hot encoding of edges to edge attribute.\n\n        Args:\n            attr_name: attribute name used to store one-hot encoding\n            dim: dimension of one-hot encoding\n        \"\"\"\n        if dim == 0:\n            dim = self.M\n        self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n            config[\"torch\"][\"device\"]\n        )[: self.M]\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                print(key, \"is not a graph attribute\")\n                return None\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        elif key in self.data.keys():\n            return self.data[key[0]]\n        else:\n            print(key[0], \"is not a node or edge attribute\")\n            return None\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                self.data[key] = val\n            else:\n                print(key, \"is not a graph attribute\")\n        elif self.key[0].starts_with(\"node_\"):  # type: ignore\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif self.key[0].starts_with(\"edge_\"):  # type: ignore\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            print(key[0], \"is not a node or edge attribute\")\n\n    @property\n    def N(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns the number of nodes in the graph.\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def M(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the numnber of directed edges is returned.\n        \"\"\"\n        return self.data.num_edges  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\"\"\"\n        return not is_undirected(self.data.edge_index)        \n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\"\"\"\n        return is_undirected(self.data.edge_index)\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph) -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Example: \n        ```py\n        # no node IDs\n        g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        print(g1 + g2)\n        # Graph with 3 nodes and 6 edges\n\n        # Identical node IDs\n        g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        print(g1 + g2)\n        # Graph with 3 nodes and 4 edges\n\n        # Non-overlapping node IDs\n        g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        print(g1 + g2)\n        # Graph with 6 nodes and 4 edges\n\n        # Partly overlapping node IDs\n        g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        print(g1 + g2)\n        # Graph with 5 nodes and 4 edges\n        ```\n        \"\"\"\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        # compute overlap and additional nodes in g2 over g1\n        overlap = set(m2.node_ids).intersection(m1.node_ids)\n        additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n        d2_idx_translation = {}\n        node_ids = ['']*(self.N + len(additional_nodes))\n        # keep mappings of nodes in g1\n        for v in m1.node_ids:\n            node_ids[m1.to_idx(v)] = v\n        for v in m2.node_ids:\n            d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n        # for overlapping node IDs we must correct node indices in m2\n        for v in overlap:\n            d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n        # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n        for v in additional_nodes:\n            new_idx = m2.to_idx(v) + self.N - len(overlap)\n            node_ids[new_idx] = v\n            d2_idx_translation[m2.to_idx(v)] = new_idx\n        # apply index translation to d2\n        # fast dictionary based mapping using torch\n        palette, key = zip(*d2_idx_translation.items())\n        key = torch.tensor(key)\n        palette = torch.tensor(palette)\n\n        index = torch.bucketize(d2.edge_index.ravel(), palette)\n        d2.edge_index = key[index].reshape(d2.edge_index.shape)\n        d = d1.concat(d2)\n        mapping = IndexMap(node_ids)\n        d.num_nodes = self.N + len(additional_nodes)\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr_types = Graph.attr_types(self.data.to_dict())\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.N, self.M)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.N, self.M)\n        if len(self.data.node_attrs()) &gt; 0:\n            s += \"\\nNode attributes\\n\"\n            for a in self.data.node_attrs():\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.edge_attrs()) &gt; 1:\n            s += \"\\nEdge attributes\\n\"\n            for a in self.data.edge_attrs():\n                if a != \"edge_index\":\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n            self.data.node_attrs()\n        ):\n            s += \"\\nGraph attributes\\n\"\n            for a in self.data.keys():\n                if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.M","title":"<code>M: int</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the numnber of directed edges is returned.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.N","title":"<code>N: int</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns the number of nodes in the graph.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.edges","title":"<code>edges: Generator[Union[Tuple[int, int], Tuple[str, str]], None, None]</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a generator object that yields all edges. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of str IDs. If no mapping is used, edges are returned as tuples of integer indices.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.in_degrees","title":"<code>in_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return in-degrees of nodes in directed network.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.nodes","title":"<code>nodes: Generator[Union[int, str], None, None]</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a generator object that yields all nodes. If an IndexMap is used, nodes are returned as str IDs. If no IndexMap is used, nodes are returned as integer indices.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.out_degrees","title":"<code>out_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return out-degrees of nodes in directed network.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Example:  <pre><code># no node IDs\ng1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\ng1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\nprint(g1 + g2)\n# Graph with 3 nodes and 6 edges\n\n# Identical node IDs\ng1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\nprint(g1 + g2)\n# Graph with 3 nodes and 4 edges\n\n# Non-overlapping node IDs\ng1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\nprint(g1 + g2)\n# Graph with 6 nodes and 4 edges\n\n# Partly overlapping node IDs\ng1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\nprint(g1 + g2)\n# Graph with 5 nodes and 4 edges\n</code></pre></p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __add__(self, other: Graph) -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Example: \n    ```py\n    # no node IDs\n    g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n    g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n    print(g1 + g2)\n    # Graph with 3 nodes and 6 edges\n\n    # Identical node IDs\n    g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n    g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n    print(g1 + g2)\n    # Graph with 3 nodes and 4 edges\n\n    # Non-overlapping node IDs\n    g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n    g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n    print(g1 + g2)\n    # Graph with 6 nodes and 4 edges\n\n    # Partly overlapping node IDs\n    g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n    g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n    print(g1 + g2)\n    # Graph with 5 nodes and 4 edges\n    ```\n    \"\"\"\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    # compute overlap and additional nodes in g2 over g1\n    overlap = set(m2.node_ids).intersection(m1.node_ids)\n    additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n    d2_idx_translation = {}\n    node_ids = ['']*(self.N + len(additional_nodes))\n    # keep mappings of nodes in g1\n    for v in m1.node_ids:\n        node_ids[m1.to_idx(v)] = v\n    for v in m2.node_ids:\n        d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n    # for overlapping node IDs we must correct node indices in m2\n    for v in overlap:\n        d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n    # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n    for v in additional_nodes:\n        new_idx = m2.to_idx(v) + self.N - len(overlap)\n        node_ids[new_idx] = v\n        d2_idx_translation[m2.to_idx(v)] = new_idx\n    # apply index translation to d2\n    # fast dictionary based mapping using torch\n    palette, key = zip(*d2_idx_translation.items())\n    key = torch.tensor(key)\n    palette = torch.tensor(palette)\n\n    index = torch.bucketize(d2.edge_index.ravel(), palette)\n    d2.edge_index = key[index].reshape(d2.edge_index.shape)\n    d = d1.concat(d2)\n    mapping = IndexMap(node_ids)\n    d.num_nodes = self.N + len(additional_nodes)\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            print(key, \"is not a graph attribute\")\n            return None\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    elif key in self.data.keys():\n        return self.data[key[0]]\n    else:\n        print(key[0], \"is not a node or edge attribute\")\n        return None\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as  optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.IndexMap.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as \n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if 'num_nodes' not in data:\n        data.num_nodes = data.edge_index.max().item()+1\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if data.edge_index.get_sparse_size(dim=0) != data.num_nodes or data.edge_index.get_sparse_size(dim=1) != data.num_nodes:\n        raise Exception('sparse size of EdgeIndex should match number of nodes!')\n\n    # sort EdgeIndex and validate\n    data.edge_index = data.edge_index.sort_by('row').values\n    data.edge_index.validate()\n\n    self.data = data\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i\n        for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            self.data[key] = val\n        else:\n            print(key, \"is not a graph attribute\")\n    elif self.key[0].starts_with(\"node_\"):  # type: ignore\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif self.key[0].starts_with(\"edge_\"):  # type: ignore\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        print(key[0], \"is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr_types = Graph.attr_types(self.data.to_dict())\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.N, self.M)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.N, self.M)\n    if len(self.data.node_attrs()) &gt; 0:\n        s += \"\\nNode attributes\\n\"\n        for a in self.data.node_attrs():\n            s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.edge_attrs()) &gt; 1:\n        s += \"\\nEdge attributes\\n\"\n        for a in self.data.edge_attrs():\n            if a != \"edge_index\":\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n        self.data.node_attrs()\n    ):\n        s += \"\\nGraph attributes\\n\"\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.add_edge_ohe","title":"<code>add_edge_ohe</code>","text":"<p>Add one-hot encoding of edges to edge attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attr_name</code> <code>str</code> <p>attribute name used to store one-hot encoding</p> required <code>dim</code> <code>int</code> <p>dimension of one-hot encoding</p> <code>0</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def add_edge_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n    \"\"\"Add one-hot encoding of edges to edge attribute.\n\n    Args:\n        attr_name: attribute name used to store one-hot encoding\n        dim: dimension of one-hot encoding\n    \"\"\"\n    if dim == 0:\n        dim = self.M\n    self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n        config[\"torch\"][\"device\"]\n    )[: self.M]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.add_node_ohe","title":"<code>add_node_ohe</code>","text":"<p>Add one-hot encoding of nodes to node attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attr_name</code> <code>str</code> <p>attribute name used to store one-hot encoding</p> required <code>dim</code> <code>int</code> <p>dimension of one-hot encoding</p> <code>0</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def add_node_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n    \"\"\"Add one-hot encoding of nodes to node attribute.\n\n    Args:\n        attr_name: attribute name used to store one-hot encoding\n        dim: dimension of one-hot encoding\n    \"\"\"\n    if dim == 0:\n        dim = self.N\n    self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n        config[\"torch\"][\"device\"]\n    )[: self.N]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.attr_types","title":"<code>attr_types</code>  <code>staticmethod</code>","text":"<p>Return name, type, and size of all node, edge, and graph attributes.</p> <p>This method returns a dictionary that contains the name (key), as well as the type and size of all attributes.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef attr_types(attr: Dict) -&gt; Dict:\n    \"\"\"\n    Return name, type, and size of all node, edge, and graph attributes.\n\n    This method returns a dictionary that contains the name (key), as well as\n    the type and size of all attributes.\n    \"\"\"\n    a = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            a[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            a[k] = str(t)\n    return a\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate the in- or out-degree for directed networks.</p> <code>'in'</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n    \"\"\"\n    Return degrees of nodes.\n\n    Args:\n        mode:   `in` or `out` to calculate the in- or out-degree for\n            directed networks.\n    \"\"\"\n    if mode == \"in\":\n        d = torch_geometric.utils.degree(\n            self.data.edge_index[1], num_nodes=self.N, dtype=torch.int\n        )\n    else:\n        d = torch_geometric.utils.degree(\n            self.data.edge_index[0], num_nodes=self.N, dtype=torch.int\n        )\n    return {self.mapping.to_id(i): d[i].item() for i in range(self.N)}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def edge_attrs(self) -&gt; List:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can  be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.IndexMap.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index</p> <code>None</code> Example <pre><code>import pathpyG as pp\n\ng = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\nprint(g)\n\ng = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                        mapping=pp.IndexMap(['a', 'b', 'c']))\nprint(g)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes=None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can \n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        print(g)\n\n        g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                                mapping=pp.IndexMap(['a', 'b', 'c']))\n        print(g)\n        ```\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else: \n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(\n        d,\n        mapping=mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>pathpyG.core.IndexMap.IndexMap</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>num_nodes</code> <p>optional number of nodes (useful in case not all nodes have incident edges)</p> <code>None</code> Example <pre><code>import pathpyG as pp\n\nl = [('a', 'b'), ('a', 'c'), ('b', 'c')]\ng = pp.Graph.from_edge_list(l)\nprint(g)\nprint(g.mapping)\n\nl = [('a', 'b'), ('a', 'c'), ('b', 'c')]\ng = pp.Graph.from_edge_list(l)\nprint(g)\nprint(g.mapping)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(edge_list: Iterable[Tuple[str, str]], is_undirected: bool = False, mapping: IndexMap = None, num_nodes=None) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n    Example:\n        ```\n        import pathpyG as pp\n\n        l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        g = pp.Graph.from_edge_list(l)\n        print(g)\n        print(g.mapping)\n\n        l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        g = pp.Graph.from_edge_list(l)\n        print(g)\n        print(g.mapping)\n        ```\n    \"\"\"\n\n    if mapping is None:\n        node_ids = set()\n        for v, w in edge_list:\n            node_ids.add(v)\n            node_ids.add(w)\n        node_list = list(node_ids)\n        node_list.sort()\n        mapping = IndexMap(node_list)\n\n    sources = []\n    targets = []\n    for v, w in edge_list:\n        sources.append(mapping.to_idx(v))\n        targets.append(mapping.to_idx(w))\n\n    if num_nodes is None:\n        num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex([sources, targets], sparse_size=(num_nodes, num_nodes), is_undirected=is_undirected, device=config['torch']['device'])\n    return Graph(\n        Data(edge_index=edge_index, num_nodes=num_nodes),\n        mapping=mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_laplacian","title":"<code>get_laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.get_laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code>             function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall             be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.get_laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.get_laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization:  normalization parameter passed to pyG `get_laplacian`\n                        function\n        edge_attr:      optinal name of numerical edge attribute that shall\n                        be passed to pyG `get_laplacian` function as edge weight\n    \"\"\"\n    if edge_attr is None:\n        index, weight =torch_geometric.utils.get_laplacian(\n            self.data.edge_index, normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index,\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n    \"\"\"        \n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([])\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_sparse_adj_matrix","title":"<code>get_sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index, edge_attr=self.data[edge_attr], num_nodes=self.N\n        )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([])\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\"\"\"\n    return not is_undirected(self.data.edge_index)        \n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID \n    \"\"\"\n    row = self.mapping.to_idx(v)\n    ((row_ptr, col), perm) = self.data.edge_index.get_csr()\n    row_start = row_ptr[row]\n    row_end   = row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\"\"\"\n    return is_undirected(self.data.edge_index)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_id</code> attribute.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def node_attrs(self) -&gt; List:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_id` attribute.\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_id\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) \\\n        -&gt; Generator[Union[int, str] | tuple, None, None]:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n    \"\"\"\n    for i in self.get_predecessors(self.mapping.to_idx(node)):  # type: ignore\n        yield self.mapping.to_id(i.item())\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) \\\n        -&gt; Generator[Union[int, str] | tuple, None, None]:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n    \"\"\"\n\n    for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n        yield self.mapping.to_id(j.item())\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    tf = ToUndirected()\n    d = tf(self.data)\n    # unfortunately, the application of a transform creates a new edge_index of type tensor\n    # so we have to recreate the EdgeIndex tensor and sort it again\n\n    e = EdgeIndex(data=d.edge_index, is_undirected=True)\n    d.edge_index = e\n    return Graph(d, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\"\"\"\n    i, w = torch_geometric.utils.coalesce(self.data.edge_index, torch.ones(self.M).to(config[\"torch\"][\"device\"]))\n    return Graph(Data(edge_index=i, edge_weight=w), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.IndexMap","title":"<code>IndexMap</code>","text":"<p>Maps node indices to string ids</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>class IndexMap:\n    \"\"\"Maps node indices to string ids\"\"\"\n    def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n        \"\"\"Initialize mapping from indices to node IDs.\"\"\"\n        if node_ids is not None:\n            assert len(node_ids) == len(set(node_ids)), \"node_id entries must be unique\"\n            # first-order: nodes = integer indices\n            self.node_ids: np.ndarray = np.array(node_ids)\n            self.id_to_idx: Dict[str, int] = {v: i for i, v in enumerate(node_ids)}\n            self.has_ids = True\n        else:\n            self.node_ids = np.array([])\n            self.id_to_idx = {}\n            self.has_ids = False\n\n    def num_ids(self) -&gt; int:\n        return len(self.node_ids)\n\n    def add_id(self, node_id: str) -&gt; None:\n        \"\"\"Assigns additional ID to next consecutive index.\"\"\"\n        if node_id not in self.id_to_idx:\n            idx = self.num_ids()\n            self.node_ids = np.append(self.node_ids, node_id)\n            self.id_to_idx[node_id] = idx\n            self.has_ids = True\n\n    def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n        \"\"\"Assigns additional IDs to next consecutive indices.\"\"\"\n        cur_num_ids = self.num_ids()\n        node_ids = np.array(node_ids)\n        mask = np.isin(node_ids, self.node_ids)\n        new_ids = np.unique(node_ids[~mask])\n        self.node_ids = np.append(self.node_ids, new_ids)\n        self.id_to_idx.update({v: i + cur_num_ids for i, v in enumerate(new_ids)})\n        self.has_ids = True\n\n    def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n        \"\"\"Map index to ID if mapping is defined, return index otherwise.\"\"\"\n        if self.has_ids:\n            if self.node_ids.ndim == 1:\n                return self.node_ids[idx]\n            else:\n                return tuple(self.node_ids[idx])\n        else:\n            return idx\n\n    def to_ids(self, idxs: list | tuple) -&gt; list:\n        \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise.\"\"\"\n        if self.has_ids:\n            return self.node_ids[idxs].tolist()\n        else:\n            return idxs\n\n    def to_idx(self, node: Union[str, int]) -&gt; int:\n        \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\"\"\"\n        if self.has_ids:\n            return self.id_to_idx[node]\n        else:\n            return node\n\n    def to_idxs(self, nodes: list | tuple) -&gt; torch.Tensor:\n        \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise.\"\"\"\n        if self.has_ids:\n            return torch.tensor([self.id_to_idx[node] for node in nodes])\n        else:\n            return torch.tensor(nodes)\n\n    def __str__(self) -&gt; str:\n        s = ''\n        for v in self.id_to_idx:\n            s += str(v) + ' -&gt; ' + str(self.to_idx(v)) + '\\n'\n        return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.IndexMap.__init__","title":"<code>__init__</code>","text":"<p>Initialize mapping from indices to node IDs.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n    \"\"\"Initialize mapping from indices to node IDs.\"\"\"\n    if node_ids is not None:\n        assert len(node_ids) == len(set(node_ids)), \"node_id entries must be unique\"\n        # first-order: nodes = integer indices\n        self.node_ids: np.ndarray = np.array(node_ids)\n        self.id_to_idx: Dict[str, int] = {v: i for i, v in enumerate(node_ids)}\n        self.has_ids = True\n    else:\n        self.node_ids = np.array([])\n        self.id_to_idx = {}\n        self.has_ids = False\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.IndexMap.add_id","title":"<code>add_id</code>","text":"<p>Assigns additional ID to next consecutive index.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def add_id(self, node_id: str) -&gt; None:\n    \"\"\"Assigns additional ID to next consecutive index.\"\"\"\n    if node_id not in self.id_to_idx:\n        idx = self.num_ids()\n        self.node_ids = np.append(self.node_ids, node_id)\n        self.id_to_idx[node_id] = idx\n        self.has_ids = True\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.IndexMap.add_ids","title":"<code>add_ids</code>","text":"<p>Assigns additional IDs to next consecutive indices.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n    \"\"\"Assigns additional IDs to next consecutive indices.\"\"\"\n    cur_num_ids = self.num_ids()\n    node_ids = np.array(node_ids)\n    mask = np.isin(node_ids, self.node_ids)\n    new_ids = np.unique(node_ids[~mask])\n    self.node_ids = np.append(self.node_ids, new_ids)\n    self.id_to_idx.update({v: i + cur_num_ids for i, v in enumerate(new_ids)})\n    self.has_ids = True\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.IndexMap.to_id","title":"<code>to_id</code>","text":"<p>Map index to ID if mapping is defined, return index otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n    \"\"\"Map index to ID if mapping is defined, return index otherwise.\"\"\"\n    if self.has_ids:\n        if self.node_ids.ndim == 1:\n            return self.node_ids[idx]\n        else:\n            return tuple(self.node_ids[idx])\n    else:\n        return idx\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.IndexMap.to_ids","title":"<code>to_ids</code>","text":"<p>Map list of indices to IDs if mapping is defined, return indices otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_ids(self, idxs: list | tuple) -&gt; list:\n    \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise.\"\"\"\n    if self.has_ids:\n        return self.node_ids[idxs].tolist()\n    else:\n        return idxs\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.IndexMap.to_idx","title":"<code>to_idx</code>","text":"<p>Map argument (ID or index) to index if mapping is defined, return argument otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_idx(self, node: Union[str, int]) -&gt; int:\n    \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\"\"\"\n    if self.has_ids:\n        return self.id_to_idx[node]\n    else:\n        return node\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.IndexMap.to_idxs","title":"<code>to_idxs</code>","text":"<p>Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_idxs(self, nodes: list | tuple) -&gt; torch.Tensor:\n    \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise.\"\"\"\n    if self.has_ids:\n        return torch.tensor([self.id_to_idx[node] for node in nodes])\n    else:\n        return torch.tensor(nodes)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel","title":"<code>MultiOrderModel</code>","text":"<p>MultiOrderModel based on torch_geometric.Data.</p> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>class MultiOrderModel:\n    \"\"\"MultiOrderModel based on torch_geometric.Data.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.layers: dict[int, Graph] = {}\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the higher-order graph.\"\"\"\n        max_order = max(list(self.layers.keys())) if self.layers else 0\n        s = f\"MultiOrderModel with max. order {max_order}\"\n        return s\n\n    @staticmethod\n    def aggregate_edge_weight(ho_index: torch.Tensor, edge_weight: torch.Tensor, aggr: str = \"src\") -&gt; torch.Tensor:\n        \"\"\"\n        Aggregate edge weights of a (k-1)-th order graph for a kth-order graph.\n\n        Args:\n            ho_index: The higher-order edge index of the higher-order graph.\n            edge_weight: The edge weights of the (k-1)th order graph.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        \"\"\"\n        if aggr == \"src\":\n            ho_edge_weight = edge_weight[ho_index[0]]\n        elif aggr == \"dst\":\n            ho_edge_weight = edge_weight[ho_index[1]]\n        elif aggr == \"max\":\n            ho_edge_weight = torch.maximum(edge_weight[ho_index[0]], edge_weight[ho_index[1]])\n        elif aggr == \"mul\":\n            ho_edge_weight = edge_weight[ho_index[0]] * edge_weight[ho_index[1]]\n        else:\n            raise ValueError(f\"Unknown aggregation method {aggr}\")\n        return ho_edge_weight\n\n    @staticmethod\n    def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int) -&gt; torch.Tensor:\n        \"\"\"\n        Do a line graph transformation on the edge index to lift the order of the graph by one.\n        Assumes that the edge index is sorted.\n\n        Args:\n            edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n            num_nodes: The number of nodes in the graph.\n        \"\"\"\n        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n        # Map outdegree to each destination node to create an edge for each combination\n        # of incoming and outgoing edges for each destination node\n        outdegree_per_dst = outdegree[edge_index[1]]\n        num_new_edges = outdegree_per_dst.sum()\n        # Create sources of the new higher-order edges\n        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n        # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n        # of all previous nodes in the ordered sequence of nodes\n        ptrs = cumsum(outdegree, dim=0)[:-1]\n        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n        ho_edge_dsts += idx_correction\n        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n\n    @staticmethod\n    def lift_order_edge_index_weighted(\n        edge_index: torch.Tensor, edge_weight: torch.Tensor, num_nodes: int, aggr: str = \"src\"\n    ) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Do a line graph transformation on the edge index to lift the order of the graph by one.\n        Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph.\n        Assumes that the edge index is sorted.\n\n        Args:\n            edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n            edge_weight: The edge weights of the (k-1)th order graph.\n            num_nodes: The number of nodes in the graph.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        \"\"\"\n        ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes)\n        ho_edge_weight = MultiOrderModel.aggregate_edge_weight(ho_index, edge_weight, aggr)\n\n        return ho_index, ho_edge_weight\n\n    @staticmethod\n    def aggregate_edge_index(\n        edge_index: torch.Tensor, node_sequence: torch.Tensor, edge_weight: torch.Tensor | None = None\n    ) -&gt; Graph:\n        \"\"\"\n        Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object\n        containing the (higher-order) edge index without duplicates and the node sequences.\n        The edge weights of duplicated edges are summed up.\n\n        Args:\n            edge_index: The edge index of a (higher-order) graph where each source and destination node\n                corresponds to a node which is an edge in the (k-1)-th order graph.\n            node_sequence: The node sequences of first order nodes that each node in the edge index corresponds to.\n            edge_weight: The edge weights corresponding to the edge index.\n        \"\"\"\n        if edge_weight is None:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n\n        # If first order, then the indices in the node sequence are the inverse idx we would need already\n        if node_sequence.size(1) == 1:\n            unique_nodes = torch.arange(node_sequence.max().item() + 1, device=node_sequence.device).unsqueeze(1)\n            mapped_edge_index = node_sequence.squeeze()[edge_index]\n        else:\n            unique_nodes, inverse_idx = torch.unique(node_sequence, dim=0, return_inverse=True)\n            mapped_edge_index = inverse_idx[edge_index]\n        aggregated_edge_index, edge_weight = coalesce(\n            mapped_edge_index,\n            edge_attr=edge_weight,\n            num_nodes=unique_nodes.size(0),\n            reduce=\"sum\",\n        )\n        data = Data(\n            edge_index=aggregated_edge_index,\n            num_nodes=unique_nodes.size(0),\n            node_sequence=unique_nodes,\n            edge_weight=edge_weight,\n        )\n        return Graph(data)\n\n    @staticmethod\n    def iterate_lift_order(\n        edge_index: torch.Tensor,\n        node_sequence: torch.Tensor,\n        mapping: IndexMap,\n        edge_weight: torch.Tensor | None = None,\n        aggr: str = \"src\",\n        save: bool = True,\n    ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n        \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n        This is a helper function that should not be called directly.\n        Only use for edge_indices after the special cases have been handled e.g.\n        in the from_temporal_graph (filtering non-time-respecting paths of order 2)\n        or from_PathData (reindexing with dataloader) functions.\n\n        Args:\n            edge_index: The edge index of the (k-1)-th order graph.\n            node_sequence: The node sequences of the (k-1)-th order graph.\n            edge_weight: The edge weights of the (k-1)-th order graph.\n            k: The order of the graph that should be computed.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n            save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n        \"\"\"\n        # Lift order\n        if edge_weight is None:\n            ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n        else:\n            ho_index, edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n                edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n            )\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n        # Aggregate\n        if save:\n            gk = MultiOrderModel.aggregate_edge_index(ho_index, node_sequence, edge_weight)\n            gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n        else:\n            gk = None\n        return ho_index, node_sequence, edge_weight, gk\n\n    @staticmethod\n    def from_temporal_graph(\n        g: TemporalGraph, delta: float | int = 1, max_order: int = 1, weight: str = \"edge_weight\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\"\"\"\n        m = MultiOrderModel()\n        edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n        node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n        if weight in g.data:\n            edge_weight = g.data[weight]\n        else:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n        if cached or max_order == 1:\n            m.layers[1] = MultiOrderModel.aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[1].mapping = g.mapping\n\n        if max_order &gt; 1:\n            # Compute null model\n            null_model_edge_index, null_model_edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n                edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=\"src\"\n            )\n            # Update node sequences\n            node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n            # Remove non-time-respecting higher-order edges\n            time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n            non_negative_mask = time_diff &gt; 0\n            delta_mask = time_diff &lt;= delta\n            time_respecting_mask = non_negative_mask &amp; delta_mask\n            edge_index = null_model_edge_index[:, time_respecting_mask]\n            edge_weight = null_model_edge_weight[time_respecting_mask]\n            # Aggregate\n            if cached or max_order == 2:\n                m.layers[2] = MultiOrderModel.aggregate_edge_index(\n                    edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n                )\n                m.layers[2].mapping = IndexMap(\n                    [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n                )\n\n            for k in range(3, max_order + 1):\n                edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                    edge_index=edge_index,\n                    node_sequence=node_sequence,\n                    mapping=g.mapping,\n                    edge_weight=edge_weight,\n                    aggr=\"src\",\n                    save=cached or k == max_order,\n                )\n                if cached or k == max_order:\n                    m.layers[k] = gk\n\n        return m\n\n    @staticmethod\n    def from_PathData(\n        path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"\n        Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n        Args:\n            path_data: `PathData` object containing paths as list of PyG Data objects\n                with sorted edge indices, node sequences and num_nodes.\n            max_order: The maximum order of the MultiOrderModel that should be computed\n            mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n            cached: Whether to save the aggregated higher-order graphs smaller than max order\n                in the MultiOrderModel.\n        \"\"\"\n        m = MultiOrderModel()\n\n        # We assume that paths are sorted\n        path_graph = next(iter(DataLoader(path_data.paths, batch_size=len(path_data.paths)))).to(config[\"torch\"][\"device\"])\n        edge_index = path_graph.edge_index\n        node_sequence = path_graph.node_sequence\n        if path_graph.edge_weight is None:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n        else:\n            edge_weight = path_graph.edge_weight\n        if mode == \"diffusion\":\n            edge_weight = (\n                edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n            )\n            aggr = \"mul\"\n        elif mode == \"propagation\":\n            aggr = \"src\"\n\n        m.layers[1] = MultiOrderModel.aggregate_edge_index(\n            edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n        )\n        m.layers[1].mapping = path_data.mapping\n\n        for k in range(2, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=m.layers[1].mapping,\n                edge_weight=edge_weight,\n                aggr=aggr,\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n        return m\n\n    def to_dbgnn_data(self, max_order: int = 2, mapping: str = 'last') -&gt; Data:\n        \"\"\"\n        Convert the MultiOrderModel to a De Bruijn graph for the given maximum order.\n\n        Args:\n            max_order: The maximum order of the De Bruijn graph to be computed.\n            mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n        \"\"\"\n        if max_order not in self.layers:\n            raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n        g = self.layers[1]\n        g_max_order = self.layers[max_order]\n        num_nodes = g.data.num_nodes\n        num_ho_nodes = g_max_order.data.num_nodes\n        if g.data.x is not None:\n            x = g.data.x\n        else:\n            x = torch.eye(num_nodes, num_nodes)\n        x_max_order = torch.eye(num_ho_nodes, num_ho_nodes)\n        edge_index = g.data.edge_index\n        edge_index_max_order = g_max_order.data.edge_index\n        edge_weight = g.data.edge_weight\n        edge_weight_max_order = g_max_order.data.edge_weight\n        bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping)\n\n        if g.data.y is not None:\n            y = g.data.y\n\n        return Data(\n            num_nodes=num_nodes,\n            num_ho_nodes=num_ho_nodes,\n            x=x,\n            x_h=x_max_order,\n            edge_index=edge_index,\n            edge_index_higher_order=edge_index_max_order,\n            edge_weights=edge_weight.float(),\n            edge_weights_higher_order=edge_weight_max_order.float(),\n            bipartite_edge_index=bipartite_edge_index,\n            y=y if 'y' in locals() else None\n        )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the higher-order graph.</p> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the higher-order graph.\"\"\"\n    max_order = max(list(self.layers.keys())) if self.layers else 0\n    s = f\"MultiOrderModel with max. order {max_order}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel.aggregate_edge_index","title":"<code>aggregate_edge_index</code>  <code>staticmethod</code>","text":"<p>Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object containing the (higher-order) edge index without duplicates and the node sequences. The edge weights of duplicated edges are summed up.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of a (higher-order) graph where each source and destination node corresponds to a node which is an edge in the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of first order nodes that each node in the edge index corresponds to.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights corresponding to the edge index.</p> <code>None</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef aggregate_edge_index(\n    edge_index: torch.Tensor, node_sequence: torch.Tensor, edge_weight: torch.Tensor | None = None\n) -&gt; Graph:\n    \"\"\"\n    Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object\n    containing the (higher-order) edge index without duplicates and the node sequences.\n    The edge weights of duplicated edges are summed up.\n\n    Args:\n        edge_index: The edge index of a (higher-order) graph where each source and destination node\n            corresponds to a node which is an edge in the (k-1)-th order graph.\n        node_sequence: The node sequences of first order nodes that each node in the edge index corresponds to.\n        edge_weight: The edge weights corresponding to the edge index.\n    \"\"\"\n    if edge_weight is None:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n\n    # If first order, then the indices in the node sequence are the inverse idx we would need already\n    if node_sequence.size(1) == 1:\n        unique_nodes = torch.arange(node_sequence.max().item() + 1, device=node_sequence.device).unsqueeze(1)\n        mapped_edge_index = node_sequence.squeeze()[edge_index]\n    else:\n        unique_nodes, inverse_idx = torch.unique(node_sequence, dim=0, return_inverse=True)\n        mapped_edge_index = inverse_idx[edge_index]\n    aggregated_edge_index, edge_weight = coalesce(\n        mapped_edge_index,\n        edge_attr=edge_weight,\n        num_nodes=unique_nodes.size(0),\n        reduce=\"sum\",\n    )\n    data = Data(\n        edge_index=aggregated_edge_index,\n        num_nodes=unique_nodes.size(0),\n        node_sequence=unique_nodes,\n        edge_weight=edge_weight,\n    )\n    return Graph(data)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel.aggregate_edge_weight","title":"<code>aggregate_edge_weight</code>  <code>staticmethod</code>","text":"<p>Aggregate edge weights of a (k-1)-th order graph for a kth-order graph.</p> <p>Parameters:</p> Name Type Description Default <code>ho_index</code> <code>torch.Tensor</code> <p>The higher-order edge index of the higher-order graph.</p> required <code>edge_weight</code> <code>torch.Tensor</code> <p>The edge weights of the (k-1)th order graph.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef aggregate_edge_weight(ho_index: torch.Tensor, edge_weight: torch.Tensor, aggr: str = \"src\") -&gt; torch.Tensor:\n    \"\"\"\n    Aggregate edge weights of a (k-1)-th order graph for a kth-order graph.\n\n    Args:\n        ho_index: The higher-order edge index of the higher-order graph.\n        edge_weight: The edge weights of the (k-1)th order graph.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n    \"\"\"\n    if aggr == \"src\":\n        ho_edge_weight = edge_weight[ho_index[0]]\n    elif aggr == \"dst\":\n        ho_edge_weight = edge_weight[ho_index[1]]\n    elif aggr == \"max\":\n        ho_edge_weight = torch.maximum(edge_weight[ho_index[0]], edge_weight[ho_index[1]])\n    elif aggr == \"mul\":\n        ho_edge_weight = edge_weight[ho_index[0]] * edge_weight[ho_index[1]]\n    else:\n        raise ValueError(f\"Unknown aggregation method {aggr}\")\n    return ho_edge_weight\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel.from_PathData","title":"<code>from_PathData</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graphs modelling paths in PathData.</p> <p>Parameters:</p> Name Type Description Default <code>path_data</code> <code>pathpyG.core.path_data.PathData</code> <p><code>PathData</code> object containing paths as list of PyG Data objects with sorted edge indices, node sequences and num_nodes.</p> required <code>max_order</code> <code>int</code> <p>The maximum order of the MultiOrderModel that should be computed</p> <code>1</code> <code>mode</code> <code>str</code> <p>The process that we assume. Can be \"diffusion\" or \"propagation\".</p> <code>'propagation'</code> <code>cached</code> <code>bool</code> <p>Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.</p> <code>True</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef from_PathData(\n    path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"\n    Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n    Args:\n        path_data: `PathData` object containing paths as list of PyG Data objects\n            with sorted edge indices, node sequences and num_nodes.\n        max_order: The maximum order of the MultiOrderModel that should be computed\n        mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n        cached: Whether to save the aggregated higher-order graphs smaller than max order\n            in the MultiOrderModel.\n    \"\"\"\n    m = MultiOrderModel()\n\n    # We assume that paths are sorted\n    path_graph = next(iter(DataLoader(path_data.paths, batch_size=len(path_data.paths)))).to(config[\"torch\"][\"device\"])\n    edge_index = path_graph.edge_index\n    node_sequence = path_graph.node_sequence\n    if path_graph.edge_weight is None:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n    else:\n        edge_weight = path_graph.edge_weight\n    if mode == \"diffusion\":\n        edge_weight = (\n            edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n        )\n        aggr = \"mul\"\n    elif mode == \"propagation\":\n        aggr = \"src\"\n\n    m.layers[1] = MultiOrderModel.aggregate_edge_index(\n        edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n    )\n    m.layers[1].mapping = path_data.mapping\n\n    for k in range(2, max_order + 1):\n        edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n            edge_index=edge_index,\n            node_sequence=node_sequence,\n            mapping=m.layers[1].mapping,\n            edge_weight=edge_weight,\n            aggr=aggr,\n            save=cached or k == max_order,\n        )\n        if cached or k == max_order:\n            m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel.from_temporal_graph","title":"<code>from_temporal_graph</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.</p> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef from_temporal_graph(\n    g: TemporalGraph, delta: float | int = 1, max_order: int = 1, weight: str = \"edge_weight\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\"\"\"\n    m = MultiOrderModel()\n    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n    if weight in g.data:\n        edge_weight = g.data[weight]\n    else:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n    if cached or max_order == 1:\n        m.layers[1] = MultiOrderModel.aggregate_edge_index(\n            edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n        )\n        m.layers[1].mapping = g.mapping\n\n    if max_order &gt; 1:\n        # Compute null model\n        null_model_edge_index, null_model_edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n            edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=\"src\"\n        )\n        # Update node sequences\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n        # Remove non-time-respecting higher-order edges\n        time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n        non_negative_mask = time_diff &gt; 0\n        delta_mask = time_diff &lt;= delta\n        time_respecting_mask = non_negative_mask &amp; delta_mask\n        edge_index = null_model_edge_index[:, time_respecting_mask]\n        edge_weight = null_model_edge_weight[time_respecting_mask]\n        # Aggregate\n        if cached or max_order == 2:\n            m.layers[2] = MultiOrderModel.aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[2].mapping = IndexMap(\n                [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n            )\n\n        for k in range(3, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=g.mapping,\n                edge_weight=edge_weight,\n                aggr=\"src\",\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel.iterate_lift_order","title":"<code>iterate_lift_order</code>  <code>staticmethod</code>","text":"<p>Lift order by one and save the result in the layers dictionary of the object. This is a helper function that should not be called directly. Only use for edge_indices after the special cases have been handled e.g. in the from_temporal_graph (filtering non-time-respecting paths of order 2) or from_PathData (reindexing with dataloader) functions.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of the (k-1)-th order graph.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights of the (k-1)-th order graph.</p> <code>None</code> <code>k</code> <p>The order of the graph that should be computed.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> <code>save</code> <code>bool</code> <p>Whether to compute the aggregated graph and later save it in the layers dictionary.</p> <code>True</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef iterate_lift_order(\n    edge_index: torch.Tensor,\n    node_sequence: torch.Tensor,\n    mapping: IndexMap,\n    edge_weight: torch.Tensor | None = None,\n    aggr: str = \"src\",\n    save: bool = True,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n    \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n    This is a helper function that should not be called directly.\n    Only use for edge_indices after the special cases have been handled e.g.\n    in the from_temporal_graph (filtering non-time-respecting paths of order 2)\n    or from_PathData (reindexing with dataloader) functions.\n\n    Args:\n        edge_index: The edge index of the (k-1)-th order graph.\n        node_sequence: The node sequences of the (k-1)-th order graph.\n        edge_weight: The edge weights of the (k-1)-th order graph.\n        k: The order of the graph that should be computed.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n    \"\"\"\n    # Lift order\n    if edge_weight is None:\n        ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n    else:\n        ho_index, edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n            edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n        )\n    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n    # Aggregate\n    if save:\n        gk = MultiOrderModel.aggregate_edge_index(ho_index, node_sequence, edge_weight)\n        gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n    else:\n        gk = None\n    return ho_index, node_sequence, edge_weight, gk\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel.lift_order_edge_index","title":"<code>lift_order_edge_index</code>  <code>staticmethod</code>","text":"<p>Do a line graph transformation on the edge index to lift the order of the graph by one. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>num_nodes</code> <code>int</code> <p>The number of nodes in the graph.</p> required Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int) -&gt; torch.Tensor:\n    \"\"\"\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        num_nodes: The number of nodes in the graph.\n    \"\"\"\n    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n    # Map outdegree to each destination node to create an edge for each combination\n    # of incoming and outgoing edges for each destination node\n    outdegree_per_dst = outdegree[edge_index[1]]\n    num_new_edges = outdegree_per_dst.sum()\n    # Create sources of the new higher-order edges\n    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n    # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n    # of all previous nodes in the ordered sequence of nodes\n    ptrs = cumsum(outdegree, dim=0)[:-1]\n    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n    idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n    ho_edge_dsts += idx_correction\n    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel.lift_order_edge_index_weighted","title":"<code>lift_order_edge_index_weighted</code>  <code>staticmethod</code>","text":"<p>Do a line graph transformation on the edge index to lift the order of the graph by one. Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>edge_weight</code> <code>torch.Tensor</code> <p>The edge weights of the (k-1)th order graph.</p> required <code>num_nodes</code> <code>int</code> <p>The number of nodes in the graph.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef lift_order_edge_index_weighted(\n    edge_index: torch.Tensor, edge_weight: torch.Tensor, num_nodes: int, aggr: str = \"src\"\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        edge_weight: The edge weights of the (k-1)th order graph.\n        num_nodes: The number of nodes in the graph.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n    \"\"\"\n    ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes)\n    ho_edge_weight = MultiOrderModel.aggregate_edge_weight(ho_index, edge_weight, aggr)\n\n    return ho_index, ho_edge_weight\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.MultiOrderModel.to_dbgnn_data","title":"<code>to_dbgnn_data</code>","text":"<p>Convert the MultiOrderModel to a De Bruijn graph for the given maximum order.</p> <p>Parameters:</p> Name Type Description Default <code>max_order</code> <code>int</code> <p>The maximum order of the De Bruijn graph to be computed.</p> <code>2</code> <code>mapping</code> <code>str</code> <p>The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".</p> <code>'last'</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>def to_dbgnn_data(self, max_order: int = 2, mapping: str = 'last') -&gt; Data:\n    \"\"\"\n    Convert the MultiOrderModel to a De Bruijn graph for the given maximum order.\n\n    Args:\n        max_order: The maximum order of the De Bruijn graph to be computed.\n        mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n    \"\"\"\n    if max_order not in self.layers:\n        raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n    g = self.layers[1]\n    g_max_order = self.layers[max_order]\n    num_nodes = g.data.num_nodes\n    num_ho_nodes = g_max_order.data.num_nodes\n    if g.data.x is not None:\n        x = g.data.x\n    else:\n        x = torch.eye(num_nodes, num_nodes)\n    x_max_order = torch.eye(num_ho_nodes, num_ho_nodes)\n    edge_index = g.data.edge_index\n    edge_index_max_order = g_max_order.data.edge_index\n    edge_weight = g.data.edge_weight\n    edge_weight_max_order = g_max_order.data.edge_weight\n    bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping)\n\n    if g.data.y is not None:\n        y = g.data.y\n\n    return Data(\n        num_nodes=num_nodes,\n        num_ho_nodes=num_ho_nodes,\n        x=x,\n        x_h=x_max_order,\n        edge_index=edge_index,\n        edge_index_higher_order=edge_index_max_order,\n        edge_weights=edge_weight.float(),\n        edge_weights_higher_order=edge_weight_max_order.float(),\n        bipartite_edge_index=bipartite_edge_index,\n        y=y if 'y' in locals() else None\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph","title":"<code>TemporalGraph</code>","text":"<p>               Bases: <code>pathpyG.Graph</code></p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>class TemporalGraph(Graph):\n    def __init__(self, data: TemporalData, mapping: IndexMap = None) -&gt; None:\n        \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n\n        Example:\n            ```py\n            from pytorch_geometric.data import TemporalData\n            import pathpyG as pp\n\n            d = TemporalData(src=[0,0,1], dst=[1,2,2], t=[0,1,2])\n            t = pp.TemporalGraph(d, mapping)\n            print(t)\n            ```\n        \"\"\"\n\n        # sort edges by timestamp\n        # Note: function sort_by_time mentioned in pyG documentation does not exist\n        t_sorted, sort_index = torch.sort(data.t)\n\n        # reorder temporal data\n        self.data = TemporalData(\n            src=data.src[sort_index],\n            dst=data.dst[sort_index],\n            t=t_sorted\n        ).to(config['torch']['device'])\n\n        if mapping is not None:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n\n        # create mapping between edge index and edge tuples\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i\n            for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        self.start_time = t_sorted.min().item()\n        self.end_time = t_sorted.max().item()\n\n        # # initialize adjacency matrix\n        # self._sparse_adj_matrix = torch_geometric.utils.to_scipy_sparse_matrix(\n        #     self.data.edge_index\n        # ).tocsr()\n\n    @staticmethod\n    def from_edge_list(edge_list) -&gt; TemporalGraph:\n        sources = []\n        targets = []\n        ts = []\n\n        index_map = IndexMap()\n\n        for v, w, t in edge_list:\n            index_map.add_id(v)\n            index_map.add_id(w)\n            sources.append(index_map.to_idx(v))\n            targets.append(index_map.to_idx(w))\n            ts.append(t)\n\n        return TemporalGraph(\n            data=TemporalData(\n                        src=torch.Tensor(sources).long(),\n                        dst=torch.Tensor(targets).long(),\n                        t=torch.Tensor(ts)),\n            mapping=index_map\n        )\n\n    @staticmethod\n    def from_csv(file, timestamp_format='%Y-%m-%d %H:%M:%S', time_rescale=1) -&gt; TemporalGraph:\n        tedges = []\n        with open(file, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                fields = line.strip().split(\",\")\n                timestamp = fields[2]\n                if timestamp.isdigit():\n                    t = int(timestamp)\n                else:\n                    # if it is a string, we use the timestamp format to convert\n                    # it to a UNIX timestamp\n                    x = datetime.datetime.strptime(timestamp, timestamp_format)\n                    t = int(mktime(x.timetuple()))\n                tedges.append((fields[0], fields[1], int(t/time_rescale)))\n        return TemporalGraph.from_edge_list(tedges)\n\n    @property\n    def temporal_edges(self) -&gt; Generator[Tuple[int, int, int], None, None]:\n        \"\"\"Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.\"\"\"\n        i = 0\n        for e in self.data.edge_index.t():\n            yield self.mapping.to_id(e[0].item()), self.mapping.to_id(e[1].item()), self.data.t[i].item()  # type: ignore\n            i += 1\n\n    def shuffle_time(self) -&gt; None:\n        \"\"\"Randomly shuffles the temporal order of edges by randomly permuting timestamps.\"\"\"\n        self.data['t'] = self.data['t'][torch.randperm(len(self.data['t']))]\n        # t_sorted, indices = torch.sort(torch.tensor(t).to(config[\"torch\"][\"device\"]))\n        # self.data['src'] = self.data['src']\n        # self.data['dst'] = self.data['dst']\n        # self.data['t'] = t_sorted\n\n    def to_static_graph(self, weighted=False, time_window: Optional[Tuple[int,int]]=None) -&gt; Graph:\n        \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n        \"\"\"\n        if time_window is not None:\n            idx = (self.data.t &gt;= time_window[0]).logical_and(self.data.t &lt; time_window[1]).nonzero().ravel()\n            edge_index = torch.stack((self.data.src[idx], self.data.dst[idx]))\n        else:\n            edge_index = torch.stack((self.data.src, self.data.dst))\n\n        n = edge_index.max().item()+1\n\n        if weighted:\n            i, w = torch_geometric.utils.coalesce(edge_index, torch.ones(edge_index.size(1), device=self.data.edge_index.device))\n            return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n,n)), edge_weight=w), self.mapping)\n        else:\n            return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n,n)), self.mapping)\n\n    def to_undirected(self) -&gt; TemporalGraph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"        \n        rev_edge_index = self.data.edge_index.flip([0])\n        edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n        times = torch.cat([self.data.t, self.data.t])\n        return TemporalGraph(\n            data=TemporalData(\n                src=edge_index[0],\n                dst=edge_index[1],\n                t=times\n            ),\n            mapping=self.mapping\n        )        \n\n    def get_window(self, start: int, end: int) -&gt; TemporalGraph:\n        \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n        edges in a given window defined by start and (non-inclusive) end, where start\n        and end refer to the number of events\"\"\"\n\n        #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n        #max_idx = torch.max(idx).item()\n\n        # return TemporalGraph(\n        #     edge_index = idx,\n        #     t = self.data.t[start:end],\n        #     node_id = self.data.node_id[:max_idx+1]\n        #     )\n        return TemporalGraph(\n            data=TemporalData(\n                src=self.data.src[start:end],\n                dst=self.data.dst[start:end],\n                t=self.data.t[start:end]\n            ),\n            mapping=self.mapping\n        )\n\n\n    def get_snapshot(self, start: int, end: int) -&gt; TemporalGraph:\n        \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n        edges in a given time window defined by start and (non-inclusive) end, where start\n        and end refer to the time stamps\"\"\"\n\n        #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n        #max_idx = torch.max(idx).item()\n\n        return TemporalGraph(\n            data=TemporalData(\n                src=self.data.src[start:end],\n                dst=self.data.dst[start:end],\n                t=self.data.t[start:end]\n            ),\n            mapping=self.mapping\n        )\n\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Returns a string representation of the graph\n        \"\"\"\n        s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n            self.data.num_nodes,\n            self.data.edge_index.unique(dim=1).size(dim=1),\n            self.data.num_events,\n            self.start_time,\n            self.end_time,\n        )\n\n        attr_types = Graph.attr_types(self.data.to_dict())\n\n        if len(self.data.node_attrs()) &gt; 0:\n            s += \"\\nNode attributes\\n\"\n            for a in self.data.node_attrs():\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.edge_attrs()) &gt; 1:\n            s += \"\\nEdge attributes\\n\"\n            for a in self.data.edge_attrs():\n                if a != \"edge_index\":\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n            self.data.node_attrs()\n        ):\n            s += \"\\nGraph attributes\\n\"\n            for a in self.data.keys():\n                if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.temporal_edges","title":"<code>temporal_edges: Generator[Tuple[int, int, int], None, None]</code>  <code>property</code>","text":"<p>Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__init__","title":"<code>__init__</code>","text":"<p>Creates an instance of a temporal graph from a <code>TemporalData</code> object.</p> Example <pre><code>from pytorch_geometric.data import TemporalData\nimport pathpyG as pp\n\nd = TemporalData(src=[0,0,1], dst=[1,2,2], t=[0,1,2])\nt = pp.TemporalGraph(d, mapping)\nprint(t)\n</code></pre> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def __init__(self, data: TemporalData, mapping: IndexMap = None) -&gt; None:\n    \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n\n    Example:\n        ```py\n        from pytorch_geometric.data import TemporalData\n        import pathpyG as pp\n\n        d = TemporalData(src=[0,0,1], dst=[1,2,2], t=[0,1,2])\n        t = pp.TemporalGraph(d, mapping)\n        print(t)\n        ```\n    \"\"\"\n\n    # sort edges by timestamp\n    # Note: function sort_by_time mentioned in pyG documentation does not exist\n    t_sorted, sort_index = torch.sort(data.t)\n\n    # reorder temporal data\n    self.data = TemporalData(\n        src=data.src[sort_index],\n        dst=data.dst[sort_index],\n        t=t_sorted\n    ).to(config['torch']['device'])\n\n    if mapping is not None:\n        self.mapping = mapping\n    else:\n        self.mapping = IndexMap()\n\n    # create mapping between edge index and edge tuples\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i\n        for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    self.start_time = t_sorted.min().item()\n    self.end_time = t_sorted.max().item()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__str__","title":"<code>__str__</code>","text":"<p>Returns a string representation of the graph</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Returns a string representation of the graph\n    \"\"\"\n    s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n        self.data.num_nodes,\n        self.data.edge_index.unique(dim=1).size(dim=1),\n        self.data.num_events,\n        self.start_time,\n        self.end_time,\n    )\n\n    attr_types = Graph.attr_types(self.data.to_dict())\n\n    if len(self.data.node_attrs()) &gt; 0:\n        s += \"\\nNode attributes\\n\"\n        for a in self.data.node_attrs():\n            s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.edge_attrs()) &gt; 1:\n        s += \"\\nEdge attributes\\n\"\n        for a in self.data.edge_attrs():\n            if a != \"edge_index\":\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n        self.data.node_attrs()\n    ):\n        s += \"\\nGraph attributes\\n\"\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.get_snapshot","title":"<code>get_snapshot</code>","text":"<p>Returns an instance of the TemporalGraph that captures all time-stamped  edges in a given time window defined by start and (non-inclusive) end, where start and end refer to the time stamps</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def get_snapshot(self, start: int, end: int) -&gt; TemporalGraph:\n    \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n    edges in a given time window defined by start and (non-inclusive) end, where start\n    and end refer to the time stamps\"\"\"\n\n    #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n    #max_idx = torch.max(idx).item()\n\n    return TemporalGraph(\n        data=TemporalData(\n            src=self.data.src[start:end],\n            dst=self.data.dst[start:end],\n            t=self.data.t[start:end]\n        ),\n        mapping=self.mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.get_window","title":"<code>get_window</code>","text":"<p>Returns an instance of the TemporalGraph that captures all time-stamped  edges in a given window defined by start and (non-inclusive) end, where start and end refer to the number of events</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def get_window(self, start: int, end: int) -&gt; TemporalGraph:\n    \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n    edges in a given window defined by start and (non-inclusive) end, where start\n    and end refer to the number of events\"\"\"\n\n    #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n    #max_idx = torch.max(idx).item()\n\n    # return TemporalGraph(\n    #     edge_index = idx,\n    #     t = self.data.t[start:end],\n    #     node_id = self.data.node_id[:max_idx+1]\n    #     )\n    return TemporalGraph(\n        data=TemporalData(\n            src=self.data.src[start:end],\n            dst=self.data.dst[start:end],\n            t=self.data.t[start:end]\n        ),\n        mapping=self.mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.shuffle_time","title":"<code>shuffle_time</code>","text":"<p>Randomly shuffles the temporal order of edges by randomly permuting timestamps.</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def shuffle_time(self) -&gt; None:\n    \"\"\"Randomly shuffles the temporal order of edges by randomly permuting timestamps.\"\"\"\n    self.data['t'] = self.data['t'][torch.randperm(len(self.data['t']))]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to_static_graph","title":"<code>to_static_graph</code>","text":"<p>Return weighted time-aggregated instance of <code>Graph</code> graph.</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def to_static_graph(self, weighted=False, time_window: Optional[Tuple[int,int]]=None) -&gt; Graph:\n    \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n    \"\"\"\n    if time_window is not None:\n        idx = (self.data.t &gt;= time_window[0]).logical_and(self.data.t &lt; time_window[1]).nonzero().ravel()\n        edge_index = torch.stack((self.data.src[idx], self.data.dst[idx]))\n    else:\n        edge_index = torch.stack((self.data.src, self.data.dst))\n\n    n = edge_index.max().item()+1\n\n    if weighted:\n        i, w = torch_geometric.utils.coalesce(edge_index, torch.ones(edge_index.size(1), device=self.data.edge_index.device))\n        return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n,n)), edge_weight=w), self.mapping)\n    else:\n        return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n,n)), self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def to_undirected(self) -&gt; TemporalGraph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"        \n    rev_edge_index = self.data.edge_index.flip([0])\n    edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n    times = torch.cat([self.data.t, self.data.t])\n    return TemporalGraph(\n        data=TemporalData(\n            src=edge_index[0],\n            dst=edge_index[1],\n            t=times\n        ),\n        mapping=self.mapping\n    )        \n</code></pre>"},{"location":"reference/pathpyG/algorithms/RollingTimeWindow/","title":"RollingTimeWindow","text":"<p>Iterator interface for rolling time window analysis in temporal graphs.</p>"},{"location":"reference/pathpyG/algorithms/RollingTimeWindow/#pathpyG.algorithms.RollingTimeWindow.RollingTimeWindow","title":"<code>RollingTimeWindow</code>","text":"<p>An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.</p> Source code in <code>src/pathpyG/algorithms/RollingTimeWindow.py</code> <pre><code>class RollingTimeWindow:\n    \"\"\"An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.\n    \"\"\"\n\n    def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n        \"\"\"Initialize a RollingTimeWindow instance that can be used to\n        iterate through a sequence of time-slice networks for a given\n        TemporalNetwork instance.\n\n        Args:\n            temporal_graph: TemporalGraphinstance that will be used to generate the\n                sequence of time-slice networks.\n            window_size: The width of the rolling time window used to create time-slice networks.\n            step_size: The step size in time units by which the starting \n                time of the rolling window will be incremented on each iteration.\n            return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n            weighted: Whether or not to return a weighted graph\n\n        Example:\n            ```py\n            tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n            t = pp.TemporalGraph.from_edge_list(tedges)\n            r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n            for g, w in r:\n                print('Time window ', w)\n                print(g)\n                print(g.data.edge_index)\n                print('---')\n            ```\n        \"\"\"\n        self.g = temporal_graph\n        self.window_size = window_size\n        self.step_size = step_size\n        self.current_time = self.g.start_time\n        self.return_window = return_window\n        self.weighted = weighted\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.current_time &lt;= self.g.end_time:\n            time_window = (self.current_time, self.current_time+self.window_size)\n            s = self.g.to_static_graph(weighted=self.weighted, time_window=time_window)\n            self.current_time += self.step_size\n            if self.return_window:\n                return s, time_window\n            else:\n                return s\n        else:\n            raise StopIteration()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/RollingTimeWindow/#pathpyG.algorithms.RollingTimeWindow.RollingTimeWindow.__init__","title":"<code>__init__</code>","text":"<p>Initialize a RollingTimeWindow instance that can be used to iterate through a sequence of time-slice networks for a given TemporalNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>temporal_graph</code> <p>TemporalGraphinstance that will be used to generate the sequence of time-slice networks.</p> required <code>window_size</code> <p>The width of the rolling time window used to create time-slice networks.</p> required <code>step_size</code> <p>The step size in time units by which the starting  time of the rolling window will be incremented on each iteration.</p> <code>1</code> <code>return_window</code> <p>Whether or not the iterator shall return the current time window as a second return value. Default is False.</p> <code>False</code> <code>weighted</code> <p>Whether or not to return a weighted graph</p> <code>True</code> Example <pre><code>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n  ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n  ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n  ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n  ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nr = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</code></pre> Source code in <code>src/pathpyG/algorithms/RollingTimeWindow.py</code> <pre><code>def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n    \"\"\"Initialize a RollingTimeWindow instance that can be used to\n    iterate through a sequence of time-slice networks for a given\n    TemporalNetwork instance.\n\n    Args:\n        temporal_graph: TemporalGraphinstance that will be used to generate the\n            sequence of time-slice networks.\n        window_size: The width of the rolling time window used to create time-slice networks.\n        step_size: The step size in time units by which the starting \n            time of the rolling window will be incremented on each iteration.\n        return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n        weighted: Whether or not to return a weighted graph\n\n    Example:\n        ```py\n        tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n          ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n          ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n          ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n          ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n        t = pp.TemporalGraph.from_edge_list(tedges)\n        r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n        for g, w in r:\n            print('Time window ', w)\n            print(g)\n            print(g.data.edge_index)\n            print('---')\n        ```\n    \"\"\"\n    self.g = temporal_graph\n    self.window_size = window_size\n    self.step_size = step_size\n    self.current_time = self.g.start_time\n    self.return_window = return_window\n    self.weighted = weighted\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/","title":"centrality","text":"<p>Algorithms to calculate centralities in (temporal) graphs.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG and configure your torch device if you want to use GPU acceleration.\nimport pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n\n# Generate toy example for temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)\n])    \n\nbw_t = pp.algorithms.temporal_betweenness_centrality(g, delta=1)\ncl_t = pp.algorithms.temporal_closeness_centrality(g, delta=1)\n\nstatic_graph = g.to_static_graph()\nbw_s = pp.algorithms.betweenness_centrality(static_graph)\nbw_s = pp.algorithms.closeness_centrality(static_graph)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.__getattr__","title":"<code>__getattr__</code>","text":"<p>Map to corresponding functions in centrality module of networkx.</p> <p>Any call to a function that is not implemented in the module centrality and whose first argument is of type Graph will be delegated to the corresponding function in the networkx module <code>centrality</code>. Please refer to the networkx documentation for a reference of available functions.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>the name of the function that shall be called</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def __getattr__(name: str) -&gt; Any:\n    \"\"\"Map to corresponding functions in centrality module of networkx.\n\n    Any call to a function that is not implemented in the module centrality\n    and whose first argument is of type Graph will be delegated to the\n    corresponding function in the networkx module `centrality`. Please\n    refer to the [networkx documentation](https://networkx.org/documentation/stable/reference/algorithms/centrality.html)\n    for a reference of available functions.\n\n    Args:\n        name: the name of the function that shall be called\n    \"\"\"\n\n    def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n        if len(args) == 0:\n            raise RuntimeError(f\"Did not find method {name} with no arguments\")\n        if isinstance(args[0], TemporalGraph):\n            raise NotImplementedError(f\"Missing implementation of {name} for temporal graphs\")\n        # if first argument is of type Graph, delegate to networkx function\n        if isinstance(args[0], Graph):\n            g = to_networkx(args[0].data)\n            r = getattr(centrality, name)(g, *args[1:], **kwargs)\n            if name.index(\"centrality\") &gt; 0 and isinstance(r, dict):\n                return map_to_nodes(args[0], r)\n            return r\n        else:\n            return wrapper(*args, **kwargs)\n            # raise RuntimeError(f'Did not find method {name} that accepts first argument of type {type(args[0])}')\n\n    return wrapper\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.betweenness_centrality","title":"<code>betweenness_centrality</code>","text":"<p>Calculate the betweenness centrality of nodes based on the fast algorithm  proposed by Brandes:</p> <p>U. Brandes: A faster algorithm for betweenness centrality, The Journal of  Mathematical Sociology, 2001</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.Graph.Graph</code> <p><code>Graph</code> object for which betweenness centrality will be computed</p> required <code>sources</code> <p>optional list of source nodes for BFS-based shortest path calculation</p> <code>None</code> Example <pre><code>import pathpyG as pp\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                    ('b', 'd'), ('c', 'e'), ('d', 'e')])\nbw = pp.algorithms.betweenness_centrality(g)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def betweenness_centrality(g: Graph, sources=None) -&gt; dict[str, float]:\n    \"\"\"Calculate the betweenness centrality of nodes based on the fast algorithm \n    proposed by Brandes:\n\n    U. Brandes: A faster algorithm for betweenness centrality, The Journal of \n    Mathematical Sociology, 2001\n\n    Args:\n        g: `Graph` object for which betweenness centrality will be computed\n        sources: optional list of source nodes for BFS-based shortest path calculation\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                            ('b', 'd'), ('c', 'e'), ('d', 'e')])\n        bw = pp.algorithms.betweenness_centrality(g)\n        ```\n    \"\"\"\n    bw = defaultdict(lambda: 0.0)\n\n    if sources == None:\n        sources = [v for v in g.nodes]\n\n    for s in sources:\n        S = list()\n        P = defaultdict(list)\n\n        sigma = defaultdict(lambda: 0)  \n        sigma[s] = 1\n\n        d = defaultdict(lambda: -1)        \n        d[s] = 0\n\n        Q = [s]\n        while Q:\n            v = Q.pop(0)\n            S.append(v)\n            for w in g.successors(v):\n                if d[w] &lt; 0:\n                    Q.append(w)\n                    d[w] = d[v] + 1\n                if d[w] == d[v] + 1:\n                    # we found shortest path from s via v to w\n                    sigma[w] = sigma[w] + sigma[v]\n                    P[w].append(v)\n        delta = defaultdict(lambda: 0.0)\n        while S:\n            w = S.pop()\n            for v in P[w]:\n                delta[v] = delta[v] + sigma[v]/sigma[w] * (1 + delta[w])\n                if v != w:\n                    bw[w] = bw[w] + delta[w]\n    return bw\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.map_to_nodes","title":"<code>map_to_nodes</code>","text":"<p>Map node-level centralities in dictionary to node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.Graph.Graph</code> <p>Graph object</p> required <code>c</code> <code>typing.Dict</code> <p>dictionary mapping node indices to metrics</p> required Example <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n...                               node_id=['a', 'b', 'c'])\n&gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n&gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n&gt;&gt;&gt; print(c_mapped)\n{'a': 0.5, 'b': 2.7, 'c': 0.3}\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def map_to_nodes(g: Graph, c: Dict) -&gt; Dict:\n    \"\"\"Map node-level centralities in dictionary to node IDs.\n\n    Args:\n        g: Graph object\n        c: dictionary mapping node indices to metrics\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        ...                               node_id=['a', 'b', 'c'])\n        &gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n        &gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n        &gt;&gt;&gt; print(c_mapped)\n        {'a': 0.5, 'b': 2.7, 'c': 0.3}\n        ```\n    \"\"\"\n    return {g.mapping.to_id(i): c[i] for i in c}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_node_traversals","title":"<code>path_node_traversals</code>","text":"<p>Calculate the number of times any path traverses each of the nodes.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>pathpyG.core.path_data.PathData</code> <p><code>PathData</code> object that contains observations of paths in a graph</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_node_traversals(paths: PathData) -&gt; Counter:\n    \"\"\"Calculate the number of times any path traverses each of the nodes.\n\n    Args:\n        paths: `PathData` object that contains observations of paths in a graph\n    \"\"\"\n    traversals = Counter()\n    for i in range(paths.num_paths):\n        w = paths.get_walk(i)\n        for v in w:\n            traversals[v] += paths.paths[i].edge_weight.max().item()\n    return traversals\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_visitation_probabilities","title":"<code>path_visitation_probabilities</code>","text":"<p>Calculate the probabilities that a randomly chosen path passes through each of the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be assigned a visitation probability of 0.05. This measure can be interpreted as ground truth for the notion of importance captured by PageRank applied to a graphical abstraction of the paths.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>pathpyG.core.path_data.PathData</code> <p>PathData object that contains path data</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_visitation_probabilities(paths: PathData) -&gt; dict:\n    \"\"\"Calculate the probabilities that a randomly chosen path passes through each of\n    the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be\n    assigned a visitation probability of 0.05. This measure can be interpreted as ground\n    truth for the notion of importance captured by PageRank applied to a graphical\n    abstraction of the paths.\n\n    Args:\n        paths: PathData object that contains path data\n    \"\"\"\n    # if not isinstance(paths, PathData):\n    #    assert False, \"`paths` must be an instance of Paths\"\n    # Log.add('Calculating visitation probabilities...', Severity.INFO)\n\n    # entries capture the probability that a given node is visited on an arbitrary path\n    # Note: this is identical to the subpath count of zero-length paths\n    # (i.e. the relative frequencies of nodes across all pathways)\n    visit_probabilities = path_node_traversals(paths)\n\n    # total number of visits\n    visits = 0.0\n    for v in visit_probabilities:\n        visits += visit_probabilities[v]\n\n    for v in visit_probabilities:\n        visit_probabilities[v] /= visits\n    return visit_probabilities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_betweenness_centrality","title":"<code>temporal_betweenness_centrality</code>","text":"<p>Calculate the temporal betweenness of nodes in a temporal graph.</p> <p>The temporal betweenness centrality definition is based on shortest  time-respecting paths with a given maximum time difference delta, where  the length of a path is given as the number of traversed edges (i.e. not  the temporal duration of a path or the earliest arrival at a node).</p> <p>The algorithm is an adaptation of Brandes' fast algorithm for betweenness  centrality based on the following work:</p> <p>S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal Betweenness, arXiv:2006.08668v2</p> <p>Different from the algorithm proposed above, the temporal betweenness centrality implemented in pathpyG is based on a directed acyclic event graph representation of  a temporal graph and it considers a maximum waiting time of delta. The complexity  is in O(nm) where n is the number of nodes in the temporal graph and m is the number  of time-stamped edges.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.TemporalGraph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> <code>1</code> Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\nbw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_betweenness_centrality(g: TemporalGraph, delta: int = 1) -&gt; dict[str, float]:\n    \"\"\"Calculate the temporal betweenness of nodes in a temporal graph.\n\n    The temporal betweenness centrality definition is based on shortest \n    time-respecting paths with a given maximum time difference delta, where \n    the length of a path is given as the number of traversed edges (i.e. not \n    the temporal duration of a path or the earliest arrival at a node).\n\n    The algorithm is an adaptation of Brandes' fast algorithm for betweenness \n    centrality based on the following work:\n\n    S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal\n    Betweenness, arXiv:2006.08668v2\n\n    Different from the algorithm proposed above, the temporal betweenness centrality\n    implemented in pathpyG is based on a directed acyclic event graph representation of \n    a temporal graph and it considers a maximum waiting time of delta. The complexity \n    is in O(nm) where n is the number of nodes in the temporal graph and m is the number \n    of time-stamped edges.\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        bw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.M\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    # add edges from first-order source nodes to edge events\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges], dim=1)\n    src_indices = torch.unique(src_edges_src).tolist()\n\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.M+g.N)\n\n    e_i = g.data.edge_index.numpy()\n\n    fo_nodes = dict()\n    for v in range(g.M+g.N):\n        if v &lt; g.M:  # return first-order target node otherwise\n            fo_nodes[v] = e_i[1, v]\n        else:\n            fo_nodes[v] = v - g.M\n\n    bw: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n    # for all first-order nodes\n    for s in tqdm(src_indices):\n\n        # for any given s, d[v] is the shortest path distance from s to v\n        # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)\n        delta_: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n        # for any given s, sigma[v] counts shortest paths from s to v\n        sigma: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma[s] = 1.0\n\n        sigma_fo: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma_fo[fo_nodes[s]] = 1.0\n\n        dist: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist[s] = 0\n\n        dist_fo: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist_fo[fo_nodes[s]] = 0\n\n        # for any given s, P[v] is the set of predecessors of v on shortest paths from s\n        P = defaultdict(set)\n\n        # Q is a queue, so we append at the right and pop from the left\n        Q: deque = deque()\n        Q.append(s)\n\n        # S is a stack, so we append at the end and pop from the end\n        S = list()\n\n        # dijkstra with path counting\n        while Q:\n            v = Q.popleft()\n            # for all successor events within delta\n            for w in event_graph.successors(v):\n\n                # we dicover w for the first time\n                if dist[w] == -1:\n                    dist[w] = dist[v] + 1\n                    if dist_fo[fo_nodes[w]] == -1:\n                        dist_fo[fo_nodes[w]] = dist[v] + 1\n                    S.append(w)\n                    Q.append(w)\n                # we found a shortest path to event w via event v\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[v]\n                    P[w].add(v)\n                    # we found a shortest path to first-order node of event w\n                    if dist[w] == dist_fo[fo_nodes[w]]:\n                        sigma_fo[fo_nodes[w]] += sigma[v]\n\n        c = 0.0\n        for i in dist_fo:\n            if dist_fo[i] &gt;= 0:\n                c += 1.0\n        bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1.0\n\n        while S:\n            w = S.pop()\n            # work backwards through paths to all targets and sum delta and sigma   \n            if dist[w] == dist_fo[fo_nodes[w]]:\n                x = sigma[w]/sigma_fo[fo_nodes[w]]\n                if isnan(x):\n                    x = 0.0\n                delta_[w] += x\n            for v in P[w]:\n                x = sigma[v]/sigma[w]\n                if isnan(x):\n                    x = 0.0\n                delta_[v] += x * delta_[w]\n                bw[fo_nodes[v]] += delta_[w] * x\n\n    # map index-based centralities to node IDs\n    bw_id = defaultdict(lambda: 0.0)\n    for idx in bw:\n        bw_id[g.mapping.to_id(idx)] = bw[idx]\n    return bw_id\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_closeness_centrality","title":"<code>temporal_closeness_centrality</code>","text":"<p>Calculates the temporal closeness centrality of nodes based on observed shortest time-respecting paths between all nodes.</p> <p>Following the definition by M. A. Beauchamp 1965 (https://doi.org/10.1002/bs.3830100205).</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.TemporalGraph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> required Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\ncl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_closeness_centrality(g: TemporalGraph, delta: int) -&gt; dict[str, float]:\n    \"\"\"Calculates the temporal closeness centrality of nodes based on\n    observed shortest time-respecting paths between all nodes.\n\n    Following the definition by M. A. Beauchamp 1965\n    (https://doi.org/10.1002/bs.3830100205).\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        cl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    centralities = dict()\n    dist, _ = temporal_shortest_paths(g, delta)\n    for x in g.nodes:\n        centralities[x] = sum((g.N - 1) / dist[_np.arange(g.N) != g.mapping.to_idx(x), g.mapping.to_idx(x)])\n\n    return centralities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/components/","title":"components","text":"<p>Algorithms to calculate connected components</p>"},{"location":"reference/pathpyG/algorithms/generative_models/","title":"generative_models","text":"<p>Algorithms to generate random graphs</p> <p>The functions in this module allow to generate graphs based on  probabilistic generative models.</p> Example <pre><code>import pathpyG as pp\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.G_nm","title":"<code>G_nm</code>","text":"<p>Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>the number of nodes of the graph</p> required <code>m</code> <code>int</code> <p>the number of random edges to be generated</p> required <code>mapping</code> <code>pathpyG.core.IndexMap.IndexMap | None</code> <p>optional given mapping of n nodes to node IDs. If this is not given a mapping is created</p> <code>None</code> <code>self_loops</code> <code>bool</code> <p>whether or not to allow self-loops (v,v) to be generated</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>whether or not multiple identical edges are allowed</p> <code>False</code> <code>directed</code> <code>bool</code> <p>whether or not to generate a directed graph</p> <code>False</code> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def G_nm(n: int, m: int, mapping: IndexMap | None = None, self_loops: bool = False, multi_edges: bool = False, directed: bool = False) -&gt; Graph:\n    \"\"\"Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.\n\n    Args:\n        n: the number of nodes of the graph\n        m: the number of random edges to be generated\n        mapping: optional given mapping of n nodes to node IDs. If this is not given a mapping is created\n        self_loops: whether or not to allow self-loops (v,v) to be generated\n        multi_edges: whether or not multiple identical edges are allowed\n        directed: whether or not to generate a directed graph\n    \"\"\"\n    assert m &lt;= max_edges(n, directed=directed, self_loops=self_loops, multi_edges=multi_edges)\n\n    edges = set()\n    edges_added: int = 0\n\n    if mapping is None:\n        # make sure that we have indices for all n nodes even if not all\n        # nodes have incident edges\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    # Add m edges at random\n    while edges_added &lt; m:\n\n        # Choose two random nodes (with replacement if self-loops are included)\n        v, w = _np.random.choice(n, size=2, replace=self_loops)\n\n        # avoid multi-edges\n        if multi_edges or (mapping.to_id(v), mapping.to_id(w)) not in edges:\n            edges.add((mapping.to_id(v), mapping.to_id(w)))\n            if not directed and v != w:\n                edges.add((mapping.to_id(w), mapping.to_id(v)))\n            edges_added += 1\n\n    return Graph.from_edge_list(list(edges), is_undirected=not directed, mapping=mapping, num_nodes=n)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.G_nm_randomize","title":"<code>G_nm_randomize</code>","text":"<p>Generate a random graph whose number of nodes, edges, edge directedness and node IDs match the corresponding values of a given network instance. Useful to generate a randomized version of a network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.Graph.Graph</code> <p>A given network used to determine number of nodes, edges, node uids, and edge directedness    </p> required <code>self_loops</code> <code>bool</code> <p>Whether or not the generated network can contain loops.</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>Whether or not multiple edges can be added to the same node pair</p> <code>False</code> <p>Example: ```py     # Generate undirected network     import pathpyG as pp     g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('d', 'e')])       r = pp.algorithms.generative_models.G_nm_randomize(g)</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def G_nm_randomize(graph: Graph, self_loops: bool = False, multi_edges: bool = False) -&gt; Graph | None:\n    \"\"\"Generate a random graph whose number of nodes, edges, edge directedness and node IDs\n    match the corresponding values of a given network instance. Useful to generate a randomized\n    version of a network.\n\n    Args:\n        graph: A given network used to determine number of nodes, edges, node uids, and edge directedness    \n        self_loops: Whether or not the generated network can contain loops.\n        multi_edges: Whether or not multiple edges can be added to the same node pair\n\n    Example:\n    ```py\n        # Generate undirected network\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('d', 'e')])    \n        r = pp.algorithms.generative_models.G_nm_randomize(g)\n    \"\"\"\n    if graph.is_undirected():\n        m = int(graph.M/2)\n    else:\n        m = graph.M\n    return G_nm(graph.N, m, directed=graph.is_directed(), self_loops=self_loops, multi_edges=multi_edges,\n                mapping=graph.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.G_np","title":"<code>G_np</code>","text":"<p>Generate a random graph with n nodes link probability p on the G(n,p) model by Edgar Nelson Gilbert.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>the number of nodes of the graph</p> required <code>p</code> <code>float</code> <p>the link probability</p> required <code>self_loops</code> <code>bool</code> <p>whether or not to allow self-loops (v,v) to be generated</p> <code>False</code> <code>directed</code> <code>bool</code> <p>whether or not to generate a directed graph</p> <code>False</code> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def G_np(n: int, p: float, mapping: IndexMap | None = None, self_loops: bool = False, directed: bool = False) -&gt; Graph:\n    \"\"\"Generate a random graph with n nodes link probability p on the G(n,p) model by Edgar Nelson Gilbert.\n\n    Args:\n        n: the number of nodes of the graph\n        p: the link probability\n        self_loops: whether or not to allow self-loops (v,v) to be generated\n        directed: whether or not to generate a directed graph\n    \"\"\"\n    edges = set()\n\n    if mapping is None:\n        # make sure that we have indices for all n nodes even if not all\n        # nodes have incident edges\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    # connect pairs of nodes with probability p\n    for s in range(n):\n        if directed:\n            x = n\n        else:\n            x = s + 1\n        for t in range(x):\n            if not self_loops and t == s:\n                continue\n            if _np.random.random() &lt;= p:\n                edges.add((mapping.to_id(s), mapping.to_id(t)))\n                if not directed and s != t:\n                    edges.add((mapping.to_id(t), mapping.to_id(s)))\n\n    return Graph.from_edge_list(list(edges), is_undirected=not directed, mapping=mapping, num_nodes=n)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.G_np_MLE","title":"<code>G_np_MLE</code>","text":"<p>Calculate the maximum likelihood estimate of parameter p for a G(n,p) model and a given undirected graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def G_np_MLE(graph: Graph) -&gt; float:\n    \"\"\"Calculate the maximum likelihood estimate of parameter p for a G(n,p) model and a given undirected graph\n    \"\"\"\n    assert graph.is_directed() is False\n    return (graph.M/2) / scipy.special.binom(graph.N, 2)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.G_np_likelihood","title":"<code>G_np_likelihood</code>","text":"<p>Calculate the likelihood of parameter p for a G(n,p) model and a given graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def G_np_likelihood(p: float, graph: Graph) -&gt; float:\n    \"\"\"Calculate the likelihood of parameter p for a G(n,p) model and a given graph\n    \"\"\"\n    assert graph.is_directed is False\n    return p**graph.N * (1-p)**(scipy.special.binom(graph.N, 2)-graph.M/2)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.G_np_randomize","title":"<code>G_np_randomize</code>","text":"<p>Generate a random microstate based on the G(n,p) model. </p> <p>The number of nodes, the expected number of edges, the edge directedness and the node uids of the  generated network match the corresponding values of a given network instance.</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def G_np_randomize(graph: Graph, self_loops: bool = False) -&gt; Graph:\n    \"\"\"Generate a random microstate based on the G(n,p) model. \n\n    The number of nodes,\n    the expected number of edges, the edge directedness and the node uids of the \n    generated network match the corresponding values of a given network instance.\n    \"\"\"\n    if graph.is_directed():\n        m = graph.M\n    else:\n        m = int(graph.M/2)\n    M = max_edges(graph.N, directed=graph.is_directed(), self_loops=self_loops)\n    p = m/M\n    return G_np(n=graph.N, p=p, directed=graph.is_directed(), self_loops=self_loops, mapping=graph.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.Gnp_log_likelihood","title":"<code>Gnp_log_likelihood</code>","text":"<p>Calculate the log-likelihood of parameter p for a G(n,p) model and a given graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def Gnp_log_likelihood(p: float, graph: Graph) -&gt; float:\n    \"\"\"Calculate the log-likelihood of parameter p for a G(n,p) model and a given graph\n    \"\"\"\n    return (graph.M/2)*_np.log10(p) + (scipy.special.binom(graph.N, 2)-(graph.M/2)) * _np.log10(1-p)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.generate_degree_sequence","title":"<code>generate_degree_sequence</code>","text":"<p>Generates a random graphic degree sequence drawn from a given degree distribution</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def generate_degree_sequence(n, distribution: Dict[float, float] | scipy.stats.rv_continuous | scipy.stats.rv_discrete, \n                             **distribution_args) -&gt; _np.array:\n    \"\"\"Generates a random graphic degree sequence drawn from a given degree distribution\"\"\"\n    # create rv_discrete object with custom distribution and generate degree sequence\n    if isinstance(distribution, dict):\n        degrees = [k for k in distribution]\n        probs = [distribution[k] for k in degrees]\n\n        dist = scipy.stats.rv_discrete(name='custom', values=(degrees, probs))\n        s = [1]\n        while not is_graphic_Erdos_Gallai(s):\n            s = dist.rvs(size=n, **distribution_args)\n        return s\n    # use scipy rv objects to generate graphic degree sequence\n    elif isinstance(distribution, scipy.stats.rv_discrete):\n        s = [1]\n        while not is_graphic_Erdos_Gallai(s):\n            s = distribution.rvs(size=n, **distribution_args)\n        return s\n\n    elif isinstance(distribution, scipy.stats.rv_continuous):\n        s = [1]\n        while not is_graphic_Erdos_Gallai(s):\n            s = _np.rint(distribution.rvs(size=n, **distribution_args))\n        return s\n    else:\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.is_graphic_Erdos_Gallai","title":"<code>is_graphic_Erdos_Gallai</code>","text":"<p>Check Erd\u00f6s and Gallai condition.</p> <p>Checks whether the condition by Erd\u00f6s and Gallai (1967) for a graphic degree sequence is fulfilled.</p> <p>Parameters:</p> Name Type Description Default <code>degrees</code> <code>list[int]</code> <p>List of integer node degrees to be tested.</p> required Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def is_graphic_Erdos_Gallai(degrees: list[int]) -&gt; bool:\n    \"\"\"Check Erd\u00f6s and Gallai condition.\n\n    Checks whether the condition by Erd\u00f6s and Gallai (1967) for a graphic degree\n    sequence is fulfilled.\n\n    Args:\n        degrees: List of integer node degrees to be tested.\n    \"\"\"\n    degree_sequence = sorted(degrees, reverse=True)\n    S = sum(degree_sequence)\n    n = len(degree_sequence)\n    if S % 2 != 0:\n        return False\n    for r in range(1, n):\n        M = 0\n        S = 0\n        for i in range(1, r+1):\n            S += degree_sequence[i-1]\n        for i in range(r+1, n+1):\n            M += min(r, degree_sequence[i-1])\n        if S &gt; r * (r-1) + M:\n            return False\n    return True\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.max_edges","title":"<code>max_edges</code>","text":"<p>Returns the maximum number of edges that a directed or undirected network with n nodes can possible have (with or without loops).</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of nodes in the network  </p> required <code>directed</code> <code>bool</code> <p>If True, return the maximum number of edges in a directed network.</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>If True, multiple edges between each node pair are allowed. In this case np.inf is returned.</p> <code>False</code> <code>self_loops</code> <code>bool</code> <p>If True, include self-loops.</p> <code>False</code> <p>Example: <pre><code>    # Compute maximum number of edges in directed/undirected network with/without self-loops and 100 nodes\n    import pathpyG as pp\n    print(pp.algorithms.generative_models.max_edges(100)\n    # 4950\n\n    print(pp.algorithms.generative_models.max_edges(100, directed=True)\n    9900\n\n    print(pp.algorithms.generative_models.max_edges(100, directed=True, loops=True)\n    # 10000\n</code></pre></p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def max_edges(n: int, directed: bool = False, multi_edges: bool = False, self_loops: bool = False) -&gt; int | float:\n    \"\"\"Returns the maximum number of edges that a directed or undirected network with n nodes can\n    possible have (with or without loops).\n\n    Args:\n        n: The number of nodes in the network  \n        directed: If True, return the maximum number of edges in a directed network.\n        multi_edges: If True, multiple edges between each node pair are allowed. In this case np.inf is returned.\n        self_loops: If True, include self-loops.\n\n    Example:\n    ```py\n        # Compute maximum number of edges in directed/undirected network with/without self-loops and 100 nodes\n        import pathpyG as pp\n        print(pp.algorithms.generative_models.max_edges(100)\n        # 4950\n\n        print(pp.algorithms.generative_models.max_edges(100, directed=True)\n        9900\n\n        print(pp.algorithms.generative_models.max_edges(100, directed=True, loops=True)\n        # 10000\n    ```\n    \"\"\"\n\n    if multi_edges:\n        return _np.inf\n    elif self_loops and directed:\n        return int(n**2)\n    elif self_loops and not directed:\n        return int(n*(n+1)/2)\n    elif not self_loops and not directed:\n        return int(n*(n-1)/2)\n    else:  # not loops and directed:\n        return int(n*(n-1))\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.stochastic_block_model","title":"<code>stochastic_block_model</code>","text":"<p>Generate a random undirected graph based on the stochastic block model</p> <p>Parameters:</p> Name Type Description Default <code>M</code> <code>numpy.matrix</code> <p>n x n stochastic block matrix, where entry M[i,j] gives probability of edge to be generated between nodes in blocks i and j</p> required <code>z</code> <code>numpy.array</code> <p>n-dimensional block assignment vector, where z[i] gives block assignment of i-th node</p> required <code>mapping</code> <code>pathpyG.core.IndexMap.IndexMap</code> <p>optional mapping of node IDs to indices. If not given, a standard  mapping based on integer IDs will be created</p> <code>None</code> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def stochastic_block_model(M: _np.matrix, z: _np.array, mapping: IndexMap = None) -&gt; Graph:\n    \"\"\"Generate a random undirected graph based on the stochastic block model\n\n    Args:\n        M: n x n stochastic block matrix, where entry M[i,j] gives probability of edge to be generated\n            between nodes in blocks i and j\n        z: n-dimensional block assignment vector, where z[i] gives block assignment of i-th node\n        mapping: optional mapping of node IDs to indices. If not given, a standard \n            mapping based on integer IDs will be created\n    \"\"\"\n    # the number of nodes is implicitly given by the length of block assignment vector z \n    n = len(z)\n\n    # we can use pre-defined node names, if not given, we use contiguous numbers\n    if mapping is None:\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    edges = []\n\n    # randomly generate links with probabilities given by entries of the stochastic block matrix M\n    for u in range(n):\n        for v in range(u):\n            if _np.random.random() &lt;= M[z[u], z[v]]:\n                edges.append((mapping.to_id(u), mapping.to_id(v)))\n                edges.append((mapping.to_id(v), mapping.to_id(u)))\n\n    G = Graph.from_edge_list(edges, mapping=mapping, num_nodes=n)\n    G.data.node_label = torch.tensor(z)\n    return G\n</code></pre>"},{"location":"reference/pathpyG/algorithms/random_graphs/","title":"random_graphs","text":"<p>Random Graph Generation Algorithms</p>"},{"location":"reference/pathpyG/algorithms/random_graphs/#pathpyG.algorithms.random_graphs.Watts_Strogatz","title":"<code>Watts_Strogatz</code>","text":"<p>Generate a Watts-Strogatz small-world graph.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of nodes in the graph.</p> required <code>s</code> <code>int</code> <p>The number of edges to attach from a new node to existing nodes.</p> required <code>p</code> <code>float</code> <p>The probability of rewiring each edge.</p> <code>0.0</code> <code>undirected</code> <code>bool</code> <p>If True, the graph will be undirected.</p> <code>True</code> <code>allow_duplicate_edges</code> <code>bool</code> <p>If True, allow duplicate edges in the graph. This is faster but may result in fewer edges than requested in the undirected case or duplicates in the directed case.</p> <code>True</code> <code>allow_self_loops</code> <code>bool</code> <p>If True, allow self-loops in the graph. This is faster but may result in fewer edges than requested in the undirected case.</p> <code>True</code> <code>mapping</code> <code>pathpyG.IndexMap | None</code> <p>A mapping from the node indices to node names.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.Graph</code> <p>A Watts-Strogatz small-world graph.</p> <p>Examples:</p> <pre><code>g = Watts_Strogatz(100, 4, 0.1, mapping=pp.IndexMap([f\"n_{i}\" for i in range(100)])\n</code></pre> Source code in <code>src/pathpyG/algorithms/random_graphs.py</code> <pre><code>def Watts_Strogatz(\n    n: int,\n    s: int,\n    p: float = 0.0,\n    undirected: bool = True,\n    allow_duplicate_edges: bool = True,\n    allow_self_loops: bool = True,\n    mapping: pp.IndexMap | None = None,\n) -&gt; pp.Graph:\n    \"\"\"Generate a Watts-Strogatz small-world graph.\n\n    Args:\n        n: The number of nodes in the graph.\n        s: The number of edges to attach from a new node to existing nodes.\n        p: The probability of rewiring each edge.\n        undirected: If True, the graph will be undirected.\n        allow_duplicate_edges: If True, allow duplicate edges in the graph.\n            This is faster but may result in fewer edges than requested in the undirected case\n            or duplicates in the directed case.\n        allow_self_loops: If True, allow self-loops in the graph.\n            This is faster but may result in fewer edges than requested in the undirected case.\n        mapping: A mapping from the node indices to node names.\n\n    Returns:\n        Graph: A Watts-Strogatz small-world graph.\n\n    Examples:\n        ```py\n        g = Watts_Strogatz(100, 4, 0.1, mapping=pp.IndexMap([f\"n_{i}\" for i in range(100)])\n        ```\n    \"\"\"\n\n    nodes = torch.arange(n)\n\n    # construct a ring lattice (dimension 1)\n    edges = (\n        torch.stack([torch.stack((nodes, torch.roll(nodes, shifts=-i, dims=0))) for i in range(1, s + 1)], dim=0)\n        .permute(1, 0, 2)\n        .reshape(2, -1)\n    )\n\n    if not allow_duplicate_edges:\n        if n * (n - 1) &lt; edges.shape[1]:\n            raise ValueError(\n                \"The number of edges is greater than the number of possible edges in the graph. Set `allow_duplicate_edges=True` to allow this.\"\n            )\n        elif n * (n - 1) * 0.5 &lt; edges.shape[1] and p &gt; 0.3:\n            warnings.warn(\n                \"Avoding duplicate in graphs with high connectivity and high rewiring probability may be slow. Consider setting `allow_duplicate_edges=True`.\"\n            )\n\n    # Rewire each link with probability p\n    rand_vals = torch.rand(edges.shape[1])\n    rewire_mask = rand_vals &lt; p\n\n    # Generate random nodes excluding the current node for each edge that needs to be rewired, also avoid duplicate edges\n    edges[1, rewire_mask] = torch.randint(n, (rewire_mask.sum(),))\n\n    # In the undirected case, make sure the edges all point in the same direction\n    # to avoid duplicate edges pointing in opposite directions\n    if undirected:\n        edges = edges.sort(dim=0)[0]\n    final_edges = edges\n\n    if not allow_duplicate_edges:\n        # Remove duplicate edges\n        final_edges, counts = edges.unique(dim=1, return_counts=True)\n        if final_edges.shape[0] &lt; edges.shape[1]:\n            for i, edge in enumerate(final_edges[:, counts &gt; 1].T):\n                for _ in range(counts[counts &gt; 1][i] - 1):\n                    while True:\n                        new_edge = torch.tensor([edge[0], torch.randint(n, (1,))]).sort()[0].unsqueeze(1)\n                        # Check if the new edge is already in the final edges\n                        # and add it if not\n                        if (new_edge != final_edges).any(dim=0).all():\n                            final_edges = torch.cat((final_edges, new_edge), dim=1)\n                            break\n\n    if not allow_self_loops:\n        self_loop_edges = final_edges[:, final_edges[0] == final_edges[1]]\n        final_edges = final_edges[:, final_edges[0] != final_edges[1]]\n        for self_loop_edge in self_loop_edges.T:\n            while True:\n                new_edge = torch.tensor([self_loop_edge[0], torch.randint(n, (1,))]).sort()[0].unsqueeze(1)\n                # Check if the new edge is already in the final edges\n                # and add it if not\n                if (new_edge != final_edges).any(dim=0).all() and new_edge[0] != new_edge[1]:\n                    final_edges = torch.cat((final_edges, new_edge), dim=1)\n                    break\n\n    g = pp.Graph.from_edge_index(final_edges, mapping=mapping)\n    if undirected:\n        g = g.to_undirected()\n    return g\n</code></pre>"},{"location":"reference/pathpyG/algorithms/shortest_paths/","title":"shortest_paths","text":"<p>Algorithms to calculate shortest paths in static networks</p> <p>The functions  in this module allow to compute shortest paths in static networks.</p>"},{"location":"reference/pathpyG/algorithms/temporal/","title":"temporal","text":"<p>Algorithms for the analysis of time-respecting paths in temporal graphs.</p>"},{"location":"reference/pathpyG/algorithms/weisfeiler_leman/","title":"weisfeiler_leman","text":""},{"location":"reference/pathpyG/algorithms/weisfeiler_leman/#pathpyG.algorithms.weisfeiler_leman.WeisfeilerLeman_test","title":"<code>WeisfeilerLeman_test</code>","text":"<p>Run Weisfeiler-Leman isomorphism test on two graphs.</p> <p>The algorithm heuristically checks whether two graphs are isomorphic. If it returns False, we can be sure that the graphs are non-isomoprhic. If the test returns True we did not find conclusive evidence that they are not isomorphic, i.e. the graphs may or may not be isomophic.</p> <p>The two graphs must have IndexMap mappings that assign different node IDs to the nodes in both graphs. The function will raise an error if the node labels of both graphs overlap.</p> <p>The function returns a tuple (bool, list, list), where the first entry is the result of the test and the two lists represent the fingerprints of the two graphs. If the test yields true the fingerprints are identical. If the test fails, the fingerprints do not correspond.</p> <p>Parameters:</p> Name Type Description Default <code>g1</code> <code>pathpyG.core.Graph.Graph</code> <p>pp.Graph</p> required <code>g2</code> <code>pathpyG.core.Graph.Graph</code> <p>pp.Graph</p> required Source code in <code>src/pathpyG/algorithms/weisfeiler_leman.py</code> <pre><code>def WeisfeilerLeman_test(g1: Graph, g2: Graph, features_g1: dict = None, features_g2: dict = None) -&gt; Tuple[bool, List[str], List[str]]:\n    \"\"\"Run Weisfeiler-Leman isomorphism test on two graphs.\n\n    The algorithm heuristically checks whether two graphs are isomorphic. If it returns False,\n    we can be sure that the graphs are non-isomoprhic. If the test returns True we did not find\n    conclusive evidence that they are not isomorphic, i.e. the graphs may or may not be isomophic.\n\n    The two graphs must have IndexMap mappings that assign different node IDs to the nodes\n    in both graphs. The function will raise an error if the node labels of both graphs overlap.\n\n    The function returns a tuple (bool, list, list), where the first entry is the result of the test\n    and the two lists represent the fingerprints of the two graphs. If the test yields true the fingerprints\n    are identical. If the test fails, the fingerprints do not correspond.\n\n    Args:\n        g1: pp.Graph\n        g2: pp.Graph\n    \"\"\"\n    if g1.mapping is None or g2.mapping is None:\n        raise Exception('Graphs must contain IndexMap that assigns node IDs')\n    if len(set(g1.mapping.node_ids).intersection(g2.mapping.node_ids)) &gt; 0:\n        raise Exception('node identifiers of graphs must not overlap')\n    g_combined = g1 + g2\n    # initialize labels of all nodes to zero\n    if features_g1 is None or features_g2 is None:       \n        fingerprint: Dict[str | int, str] = {v: '0' for v in g_combined.nodes}\n    else:\n        fingerprint = features_g1.copy()\n        fingerprint.update(features_g2)\n    labels = {} \n    label_count = 1\n    stop = False\n    while not stop:\n        new_fingerprint = {} \n        for node in g_combined.nodes:\n            # create new label based on own label and sorted labels of all neighbors\n            n_label = [fingerprint[x] for x in g_combined.successors(node)]\n            n_label.sort()\n            label = str(fingerprint[node]) + str(n_label)\n            # previously unknown label\n            if label not in labels:\n                # create a new label based on next consecutive number\n                labels[label] = label_count\n                label_count += 1 \n            new_fingerprint[node] = labels[label]        \n        if len(set(fingerprint.values())) == len(set(new_fingerprint.values())):\n            # we processed all nodes in both graphs without encountering a new label, so we stop\n            stop = True\n        else:\n            # update fingerprint and continue\n            fingerprint = new_fingerprint.copy()\n\n    # Reduce fingerprints to nodes of g1 and g2 respectively\n    fingerprint_1 = [fingerprint[v] for v in g1.nodes]\n    fingerprint_1_sorted = fingerprint_1.copy()\n    fingerprint_1_sorted.sort()\n    fingerprint_2 = [fingerprint[v] for v in g2.nodes]\n    fingerprint_2_sorted = fingerprint_2.copy()\n    fingerprint_2_sorted.sort()\n\n    # perform WL-test\n    if fingerprint_1_sorted == fingerprint_2_sorted:\n        return True, fingerprint_1, fingerprint_2\n    return False, fingerprint_1, fingerprint_2\n</code></pre>"},{"location":"reference/pathpyG/core/","title":"core","text":"<p>Core classes for (temporal) graphs, paths, and higher-order De Bruijn graphs.</p> <p>The classes in the <code>core</code> module can be used to implement integrated pipelines to preprocess time-stamped network data, do inference and model selection of higher-order De Bruijn graph models and address temporal graph learning tasks based on time-aware graph neural networks.</p> Example <pre><code>import pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n\n# Generate toy example temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)])\n\n# Create Multi-Order model that models time-respecting paths\nm = pp.MultiOrderModel.from_temporal_graph(g, delta=1, max_order=3)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/","title":"Graph","text":""},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as \n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if 'num_nodes' not in data:\n            data.num_nodes = data.edge_index.max().item()+1\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if data.edge_index.get_sparse_size(dim=0) != data.num_nodes or data.edge_index.get_sparse_size(dim=1) != data.num_nodes:\n            raise Exception('sparse size of EdgeIndex should match number of nodes!')\n\n        # sort EdgeIndex and validate\n        data.edge_index = data.edge_index.sort_by('row').values\n        data.edge_index.validate()\n\n        self.data = data\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i\n            for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes=None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can \n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index\n\n        Example:\n            ```py\n            import pathpyG as pp\n\n            g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            print(g)\n\n            g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                                    mapping=pp.IndexMap(['a', 'b', 'c']))\n            print(g)\n            ```\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else: \n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(\n            d,\n            mapping=mapping\n        )\n\n\n    @staticmethod\n    def from_edge_list(edge_list: Iterable[Tuple[str, str]], is_undirected: bool = False, mapping: IndexMap = None, num_nodes=None) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n        Example:\n            ```\n            import pathpyG as pp\n\n            l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            g = pp.Graph.from_edge_list(l)\n            print(g)\n            print(g.mapping)\n\n            l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            g = pp.Graph.from_edge_list(l)\n            print(g)\n            print(g.mapping)\n            ```\n        \"\"\"\n\n        if mapping is None:\n            node_ids = set()\n            for v, w in edge_list:\n                node_ids.add(v)\n                node_ids.add(w)\n            node_list = list(node_ids)\n            node_list.sort()\n            mapping = IndexMap(node_list)\n\n        sources = []\n        targets = []\n        for v, w in edge_list:\n            sources.append(mapping.to_idx(v))\n            targets.append(mapping.to_idx(w))\n\n        if num_nodes is None:\n            num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex([sources, targets], sparse_size=(num_nodes, num_nodes), is_undirected=is_undirected, device=config['torch']['device'])\n        return Graph(\n            Data(edge_index=edge_index, num_nodes=num_nodes),\n            mapping=mapping\n        )\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        tf = ToUndirected()\n        d = tf(self.data)\n        # unfortunately, the application of a transform creates a new edge_index of type tensor\n        # so we have to recreate the EdgeIndex tensor and sort it again\n\n        e = EdgeIndex(data=d.edge_index, is_undirected=True)\n        d.edge_index = e\n        return Graph(d, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\"\"\"\n        i, w = torch_geometric.utils.coalesce(self.data.edge_index, torch.ones(self.M).to(config[\"torch\"][\"device\"]))\n        return Graph(Data(edge_index=i, edge_weight=w), mapping=self.mapping)\n\n    @staticmethod\n    def attr_types(attr: Dict) -&gt; Dict:\n        \"\"\"\n        Return name, type, and size of all node, edge, and graph attributes.\n\n        This method returns a dictionary that contains the name (key), as well as\n        the type and size of all attributes.\n        \"\"\"\n        a = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                a[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                a[k] = str(t)\n        return a\n\n    def node_attrs(self) -&gt; List:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_id` attribute.\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_id\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; Generator[Union[int, str], None, None]:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a generator object that yields all nodes.\n        If an IndexMap is used, nodes\n        are returned as str IDs. If no IndexMap is used, nodes\n        are returned as integer indices.\n        \"\"\"\n        for i in range(self.N):\n            yield self.mapping.to_id(i)\n\n    @property\n    def edges(self) -&gt; Generator[Union[Tuple[int, int], Tuple[str, str]], None, None]:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a generator object that yields all edges.\n        If an IndexMap is used to map node indices to string IDs, edges\n        are returned as tuples of str IDs. If no mapping is used, edges\n        are returned as tuples of integer indices.\n        \"\"\"\n        for e in self.data.edge_index.t():\n            yield self.mapping.to_id(e[0].item()), self.mapping.to_id(e[1].item())\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([])\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n        \"\"\"        \n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([])\n\n    def successors(self, node: Union[int, str] | tuple) \\\n            -&gt; Generator[Union[int, str] | tuple, None, None]:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n        \"\"\"\n\n        for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n            yield self.mapping.to_id(j.item())\n\n    def predecessors(self, node: Union[str, int] | tuple) \\\n            -&gt; Generator[Union[int, str] | tuple, None, None]:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n        \"\"\"\n        for i in self.get_predecessors(self.mapping.to_idx(node)):  # type: ignore\n            yield self.mapping.to_id(i.item())\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID \n        \"\"\"\n        row = self.mapping.to_idx(v)\n        ((row_ptr, col), perm) = self.data.edge_index.get_csr()\n        row_start = row_ptr[row]\n        row_end   = row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in col[row_start:row_end]\n\n    def get_sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index, edge_attr=self.data[edge_attr], num_nodes=self.N\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return in-degrees of nodes in directed network.\"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return out-degrees of nodes in directed network.\"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n        \"\"\"\n        Return degrees of nodes.\n\n        Args:\n            mode:   `in` or `out` to calculate the in- or out-degree for\n                directed networks.\n        \"\"\"\n        if mode == \"in\":\n            d = torch_geometric.utils.degree(\n                self.data.edge_index[1], num_nodes=self.N, dtype=torch.int\n            )\n        else:\n            d = torch_geometric.utils.degree(\n                self.data.edge_index[0], num_nodes=self.N, dtype=torch.int\n            )\n        return {self.mapping.to_id(i): d[i].item() for i in range(self.N)}\n\n    def get_laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.get_laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.get_laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization:  normalization parameter passed to pyG `get_laplacian`\n                            function\n            edge_attr:      optinal name of numerical edge attribute that shall\n                            be passed to pyG `get_laplacian` function as edge weight\n        \"\"\"\n        if edge_attr is None:\n            index, weight =torch_geometric.utils.get_laplacian(\n                self.data.edge_index, normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index,\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def add_node_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n        \"\"\"Add one-hot encoding of nodes to node attribute.\n\n        Args:\n            attr_name: attribute name used to store one-hot encoding\n            dim: dimension of one-hot encoding\n        \"\"\"\n        if dim == 0:\n            dim = self.N\n        self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n            config[\"torch\"][\"device\"]\n        )[: self.N]\n\n    def add_edge_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n        \"\"\"Add one-hot encoding of edges to edge attribute.\n\n        Args:\n            attr_name: attribute name used to store one-hot encoding\n            dim: dimension of one-hot encoding\n        \"\"\"\n        if dim == 0:\n            dim = self.M\n        self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n            config[\"torch\"][\"device\"]\n        )[: self.M]\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                print(key, \"is not a graph attribute\")\n                return None\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        elif key in self.data.keys():\n            return self.data[key[0]]\n        else:\n            print(key[0], \"is not a node or edge attribute\")\n            return None\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                self.data[key] = val\n            else:\n                print(key, \"is not a graph attribute\")\n        elif self.key[0].starts_with(\"node_\"):  # type: ignore\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif self.key[0].starts_with(\"edge_\"):  # type: ignore\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            print(key[0], \"is not a node or edge attribute\")\n\n    @property\n    def N(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns the number of nodes in the graph.\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def M(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the numnber of directed edges is returned.\n        \"\"\"\n        return self.data.num_edges  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\"\"\"\n        return not is_undirected(self.data.edge_index)        \n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\"\"\"\n        return is_undirected(self.data.edge_index)\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph) -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Example: \n        ```py\n        # no node IDs\n        g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        print(g1 + g2)\n        # Graph with 3 nodes and 6 edges\n\n        # Identical node IDs\n        g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        print(g1 + g2)\n        # Graph with 3 nodes and 4 edges\n\n        # Non-overlapping node IDs\n        g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        print(g1 + g2)\n        # Graph with 6 nodes and 4 edges\n\n        # Partly overlapping node IDs\n        g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        print(g1 + g2)\n        # Graph with 5 nodes and 4 edges\n        ```\n        \"\"\"\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        # compute overlap and additional nodes in g2 over g1\n        overlap = set(m2.node_ids).intersection(m1.node_ids)\n        additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n        d2_idx_translation = {}\n        node_ids = ['']*(self.N + len(additional_nodes))\n        # keep mappings of nodes in g1\n        for v in m1.node_ids:\n            node_ids[m1.to_idx(v)] = v\n        for v in m2.node_ids:\n            d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n        # for overlapping node IDs we must correct node indices in m2\n        for v in overlap:\n            d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n        # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n        for v in additional_nodes:\n            new_idx = m2.to_idx(v) + self.N - len(overlap)\n            node_ids[new_idx] = v\n            d2_idx_translation[m2.to_idx(v)] = new_idx\n        # apply index translation to d2\n        # fast dictionary based mapping using torch\n        palette, key = zip(*d2_idx_translation.items())\n        key = torch.tensor(key)\n        palette = torch.tensor(palette)\n\n        index = torch.bucketize(d2.edge_index.ravel(), palette)\n        d2.edge_index = key[index].reshape(d2.edge_index.shape)\n        d = d1.concat(d2)\n        mapping = IndexMap(node_ids)\n        d.num_nodes = self.N + len(additional_nodes)\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr_types = Graph.attr_types(self.data.to_dict())\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.N, self.M)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.N, self.M)\n        if len(self.data.node_attrs()) &gt; 0:\n            s += \"\\nNode attributes\\n\"\n            for a in self.data.node_attrs():\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.edge_attrs()) &gt; 1:\n            s += \"\\nEdge attributes\\n\"\n            for a in self.data.edge_attrs():\n                if a != \"edge_index\":\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n            self.data.node_attrs()\n        ):\n            s += \"\\nGraph attributes\\n\"\n            for a in self.data.keys():\n                if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.M","title":"<code>M: int</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the numnber of directed edges is returned.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.N","title":"<code>N: int</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns the number of nodes in the graph.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.edges","title":"<code>edges: Generator[Union[Tuple[int, int], Tuple[str, str]], None, None]</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a generator object that yields all edges. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of str IDs. If no mapping is used, edges are returned as tuples of integer indices.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.in_degrees","title":"<code>in_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return in-degrees of nodes in directed network.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.nodes","title":"<code>nodes: Generator[Union[int, str], None, None]</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a generator object that yields all nodes. If an IndexMap is used, nodes are returned as str IDs. If no IndexMap is used, nodes are returned as integer indices.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.out_degrees","title":"<code>out_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return out-degrees of nodes in directed network.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Example:  <pre><code># no node IDs\ng1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\ng1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\nprint(g1 + g2)\n# Graph with 3 nodes and 6 edges\n\n# Identical node IDs\ng1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\nprint(g1 + g2)\n# Graph with 3 nodes and 4 edges\n\n# Non-overlapping node IDs\ng1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\nprint(g1 + g2)\n# Graph with 6 nodes and 4 edges\n\n# Partly overlapping node IDs\ng1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\nprint(g1 + g2)\n# Graph with 5 nodes and 4 edges\n</code></pre></p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __add__(self, other: Graph) -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Example: \n    ```py\n    # no node IDs\n    g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n    g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n    print(g1 + g2)\n    # Graph with 3 nodes and 6 edges\n\n    # Identical node IDs\n    g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n    g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n    print(g1 + g2)\n    # Graph with 3 nodes and 4 edges\n\n    # Non-overlapping node IDs\n    g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n    g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n    print(g1 + g2)\n    # Graph with 6 nodes and 4 edges\n\n    # Partly overlapping node IDs\n    g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n    g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n    print(g1 + g2)\n    # Graph with 5 nodes and 4 edges\n    ```\n    \"\"\"\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    # compute overlap and additional nodes in g2 over g1\n    overlap = set(m2.node_ids).intersection(m1.node_ids)\n    additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n    d2_idx_translation = {}\n    node_ids = ['']*(self.N + len(additional_nodes))\n    # keep mappings of nodes in g1\n    for v in m1.node_ids:\n        node_ids[m1.to_idx(v)] = v\n    for v in m2.node_ids:\n        d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n    # for overlapping node IDs we must correct node indices in m2\n    for v in overlap:\n        d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n    # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n    for v in additional_nodes:\n        new_idx = m2.to_idx(v) + self.N - len(overlap)\n        node_ids[new_idx] = v\n        d2_idx_translation[m2.to_idx(v)] = new_idx\n    # apply index translation to d2\n    # fast dictionary based mapping using torch\n    palette, key = zip(*d2_idx_translation.items())\n    key = torch.tensor(key)\n    palette = torch.tensor(palette)\n\n    index = torch.bucketize(d2.edge_index.ravel(), palette)\n    d2.edge_index = key[index].reshape(d2.edge_index.shape)\n    d = d1.concat(d2)\n    mapping = IndexMap(node_ids)\n    d.num_nodes = self.N + len(additional_nodes)\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            print(key, \"is not a graph attribute\")\n            return None\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    elif key in self.data.keys():\n        return self.data[key[0]]\n    else:\n        print(key[0], \"is not a node or edge attribute\")\n        return None\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as  optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.IndexMap.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as \n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if 'num_nodes' not in data:\n        data.num_nodes = data.edge_index.max().item()+1\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if data.edge_index.get_sparse_size(dim=0) != data.num_nodes or data.edge_index.get_sparse_size(dim=1) != data.num_nodes:\n        raise Exception('sparse size of EdgeIndex should match number of nodes!')\n\n    # sort EdgeIndex and validate\n    data.edge_index = data.edge_index.sort_by('row').values\n    data.edge_index.validate()\n\n    self.data = data\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i\n        for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            self.data[key] = val\n        else:\n            print(key, \"is not a graph attribute\")\n    elif self.key[0].starts_with(\"node_\"):  # type: ignore\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif self.key[0].starts_with(\"edge_\"):  # type: ignore\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        print(key[0], \"is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr_types = Graph.attr_types(self.data.to_dict())\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.N, self.M)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.N, self.M)\n    if len(self.data.node_attrs()) &gt; 0:\n        s += \"\\nNode attributes\\n\"\n        for a in self.data.node_attrs():\n            s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.edge_attrs()) &gt; 1:\n        s += \"\\nEdge attributes\\n\"\n        for a in self.data.edge_attrs():\n            if a != \"edge_index\":\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n        self.data.node_attrs()\n    ):\n        s += \"\\nGraph attributes\\n\"\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.add_edge_ohe","title":"<code>add_edge_ohe</code>","text":"<p>Add one-hot encoding of edges to edge attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attr_name</code> <code>str</code> <p>attribute name used to store one-hot encoding</p> required <code>dim</code> <code>int</code> <p>dimension of one-hot encoding</p> <code>0</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def add_edge_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n    \"\"\"Add one-hot encoding of edges to edge attribute.\n\n    Args:\n        attr_name: attribute name used to store one-hot encoding\n        dim: dimension of one-hot encoding\n    \"\"\"\n    if dim == 0:\n        dim = self.M\n    self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n        config[\"torch\"][\"device\"]\n    )[: self.M]\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.add_node_ohe","title":"<code>add_node_ohe</code>","text":"<p>Add one-hot encoding of nodes to node attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attr_name</code> <code>str</code> <p>attribute name used to store one-hot encoding</p> required <code>dim</code> <code>int</code> <p>dimension of one-hot encoding</p> <code>0</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def add_node_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n    \"\"\"Add one-hot encoding of nodes to node attribute.\n\n    Args:\n        attr_name: attribute name used to store one-hot encoding\n        dim: dimension of one-hot encoding\n    \"\"\"\n    if dim == 0:\n        dim = self.N\n    self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n        config[\"torch\"][\"device\"]\n    )[: self.N]\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.attr_types","title":"<code>attr_types</code>  <code>staticmethod</code>","text":"<p>Return name, type, and size of all node, edge, and graph attributes.</p> <p>This method returns a dictionary that contains the name (key), as well as the type and size of all attributes.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef attr_types(attr: Dict) -&gt; Dict:\n    \"\"\"\n    Return name, type, and size of all node, edge, and graph attributes.\n\n    This method returns a dictionary that contains the name (key), as well as\n    the type and size of all attributes.\n    \"\"\"\n    a = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            a[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            a[k] = str(t)\n    return a\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate the in- or out-degree for directed networks.</p> <code>'in'</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n    \"\"\"\n    Return degrees of nodes.\n\n    Args:\n        mode:   `in` or `out` to calculate the in- or out-degree for\n            directed networks.\n    \"\"\"\n    if mode == \"in\":\n        d = torch_geometric.utils.degree(\n            self.data.edge_index[1], num_nodes=self.N, dtype=torch.int\n        )\n    else:\n        d = torch_geometric.utils.degree(\n            self.data.edge_index[0], num_nodes=self.N, dtype=torch.int\n        )\n    return {self.mapping.to_id(i): d[i].item() for i in range(self.N)}\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def edge_attrs(self) -&gt; List:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can  be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.IndexMap.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index</p> <code>None</code> Example <pre><code>import pathpyG as pp\n\ng = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\nprint(g)\n\ng = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                        mapping=pp.IndexMap(['a', 'b', 'c']))\nprint(g)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes=None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can \n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        print(g)\n\n        g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                                mapping=pp.IndexMap(['a', 'b', 'c']))\n        print(g)\n        ```\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else: \n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(\n        d,\n        mapping=mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>pathpyG.core.IndexMap.IndexMap</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>num_nodes</code> <p>optional number of nodes (useful in case not all nodes have incident edges)</p> <code>None</code> Example <pre><code>import pathpyG as pp\n\nl = [('a', 'b'), ('a', 'c'), ('b', 'c')]\ng = pp.Graph.from_edge_list(l)\nprint(g)\nprint(g.mapping)\n\nl = [('a', 'b'), ('a', 'c'), ('b', 'c')]\ng = pp.Graph.from_edge_list(l)\nprint(g)\nprint(g.mapping)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(edge_list: Iterable[Tuple[str, str]], is_undirected: bool = False, mapping: IndexMap = None, num_nodes=None) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n    Example:\n        ```\n        import pathpyG as pp\n\n        l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        g = pp.Graph.from_edge_list(l)\n        print(g)\n        print(g.mapping)\n\n        l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        g = pp.Graph.from_edge_list(l)\n        print(g)\n        print(g.mapping)\n        ```\n    \"\"\"\n\n    if mapping is None:\n        node_ids = set()\n        for v, w in edge_list:\n            node_ids.add(v)\n            node_ids.add(w)\n        node_list = list(node_ids)\n        node_list.sort()\n        mapping = IndexMap(node_list)\n\n    sources = []\n    targets = []\n    for v, w in edge_list:\n        sources.append(mapping.to_idx(v))\n        targets.append(mapping.to_idx(w))\n\n    if num_nodes is None:\n        num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex([sources, targets], sparse_size=(num_nodes, num_nodes), is_undirected=is_undirected, device=config['torch']['device'])\n    return Graph(\n        Data(edge_index=edge_index, num_nodes=num_nodes),\n        mapping=mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.get_laplacian","title":"<code>get_laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.get_laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code>             function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall             be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.get_laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.get_laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization:  normalization parameter passed to pyG `get_laplacian`\n                        function\n        edge_attr:      optinal name of numerical edge attribute that shall\n                        be passed to pyG `get_laplacian` function as edge weight\n    \"\"\"\n    if edge_attr is None:\n        index, weight =torch_geometric.utils.get_laplacian(\n            self.data.edge_index, normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index,\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n    \"\"\"        \n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([])\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.get_sparse_adj_matrix","title":"<code>get_sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index, edge_attr=self.data[edge_attr], num_nodes=self.N\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([])\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\"\"\"\n    return not is_undirected(self.data.edge_index)        \n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID \n    \"\"\"\n    row = self.mapping.to_idx(v)\n    ((row_ptr, col), perm) = self.data.edge_index.get_csr()\n    row_start = row_ptr[row]\n    row_end   = row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\"\"\"\n    return is_undirected(self.data.edge_index)\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_id</code> attribute.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def node_attrs(self) -&gt; List:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_id` attribute.\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_id\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) \\\n        -&gt; Generator[Union[int, str] | tuple, None, None]:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n    \"\"\"\n    for i in self.get_predecessors(self.mapping.to_idx(node)):  # type: ignore\n        yield self.mapping.to_id(i.item())\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) \\\n        -&gt; Generator[Union[int, str] | tuple, None, None]:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n    \"\"\"\n\n    for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n        yield self.mapping.to_id(j.item())\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    tf = ToUndirected()\n    d = tf(self.data)\n    # unfortunately, the application of a transform creates a new edge_index of type tensor\n    # so we have to recreate the EdgeIndex tensor and sort it again\n\n    e = EdgeIndex(data=d.edge_index, is_undirected=True)\n    d.edge_index = e\n    return Graph(d, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\"\"\"\n    i, w = torch_geometric.utils.coalesce(self.data.edge_index, torch.ones(self.M).to(config[\"torch\"][\"device\"]))\n    return Graph(Data(edge_index=i, edge_weight=w), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/","title":"IndexMap","text":""},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap","title":"<code>IndexMap</code>","text":"<p>Maps node indices to string ids</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>class IndexMap:\n    \"\"\"Maps node indices to string ids\"\"\"\n    def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n        \"\"\"Initialize mapping from indices to node IDs.\"\"\"\n        if node_ids is not None:\n            assert len(node_ids) == len(set(node_ids)), \"node_id entries must be unique\"\n            # first-order: nodes = integer indices\n            self.node_ids: np.ndarray = np.array(node_ids)\n            self.id_to_idx: Dict[str, int] = {v: i for i, v in enumerate(node_ids)}\n            self.has_ids = True\n        else:\n            self.node_ids = np.array([])\n            self.id_to_idx = {}\n            self.has_ids = False\n\n    def num_ids(self) -&gt; int:\n        return len(self.node_ids)\n\n    def add_id(self, node_id: str) -&gt; None:\n        \"\"\"Assigns additional ID to next consecutive index.\"\"\"\n        if node_id not in self.id_to_idx:\n            idx = self.num_ids()\n            self.node_ids = np.append(self.node_ids, node_id)\n            self.id_to_idx[node_id] = idx\n            self.has_ids = True\n\n    def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n        \"\"\"Assigns additional IDs to next consecutive indices.\"\"\"\n        cur_num_ids = self.num_ids()\n        node_ids = np.array(node_ids)\n        mask = np.isin(node_ids, self.node_ids)\n        new_ids = np.unique(node_ids[~mask])\n        self.node_ids = np.append(self.node_ids, new_ids)\n        self.id_to_idx.update({v: i + cur_num_ids for i, v in enumerate(new_ids)})\n        self.has_ids = True\n\n    def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n        \"\"\"Map index to ID if mapping is defined, return index otherwise.\"\"\"\n        if self.has_ids:\n            if self.node_ids.ndim == 1:\n                return self.node_ids[idx]\n            else:\n                return tuple(self.node_ids[idx])\n        else:\n            return idx\n\n    def to_ids(self, idxs: list | tuple) -&gt; list:\n        \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise.\"\"\"\n        if self.has_ids:\n            return self.node_ids[idxs].tolist()\n        else:\n            return idxs\n\n    def to_idx(self, node: Union[str, int]) -&gt; int:\n        \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\"\"\"\n        if self.has_ids:\n            return self.id_to_idx[node]\n        else:\n            return node\n\n    def to_idxs(self, nodes: list | tuple) -&gt; torch.Tensor:\n        \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise.\"\"\"\n        if self.has_ids:\n            return torch.tensor([self.id_to_idx[node] for node in nodes])\n        else:\n            return torch.tensor(nodes)\n\n    def __str__(self) -&gt; str:\n        s = ''\n        for v in self.id_to_idx:\n            s += str(v) + ' -&gt; ' + str(self.to_idx(v)) + '\\n'\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.__init__","title":"<code>__init__</code>","text":"<p>Initialize mapping from indices to node IDs.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n    \"\"\"Initialize mapping from indices to node IDs.\"\"\"\n    if node_ids is not None:\n        assert len(node_ids) == len(set(node_ids)), \"node_id entries must be unique\"\n        # first-order: nodes = integer indices\n        self.node_ids: np.ndarray = np.array(node_ids)\n        self.id_to_idx: Dict[str, int] = {v: i for i, v in enumerate(node_ids)}\n        self.has_ids = True\n    else:\n        self.node_ids = np.array([])\n        self.id_to_idx = {}\n        self.has_ids = False\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.add_id","title":"<code>add_id</code>","text":"<p>Assigns additional ID to next consecutive index.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def add_id(self, node_id: str) -&gt; None:\n    \"\"\"Assigns additional ID to next consecutive index.\"\"\"\n    if node_id not in self.id_to_idx:\n        idx = self.num_ids()\n        self.node_ids = np.append(self.node_ids, node_id)\n        self.id_to_idx[node_id] = idx\n        self.has_ids = True\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.add_ids","title":"<code>add_ids</code>","text":"<p>Assigns additional IDs to next consecutive indices.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n    \"\"\"Assigns additional IDs to next consecutive indices.\"\"\"\n    cur_num_ids = self.num_ids()\n    node_ids = np.array(node_ids)\n    mask = np.isin(node_ids, self.node_ids)\n    new_ids = np.unique(node_ids[~mask])\n    self.node_ids = np.append(self.node_ids, new_ids)\n    self.id_to_idx.update({v: i + cur_num_ids for i, v in enumerate(new_ids)})\n    self.has_ids = True\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.to_id","title":"<code>to_id</code>","text":"<p>Map index to ID if mapping is defined, return index otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n    \"\"\"Map index to ID if mapping is defined, return index otherwise.\"\"\"\n    if self.has_ids:\n        if self.node_ids.ndim == 1:\n            return self.node_ids[idx]\n        else:\n            return tuple(self.node_ids[idx])\n    else:\n        return idx\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.to_ids","title":"<code>to_ids</code>","text":"<p>Map list of indices to IDs if mapping is defined, return indices otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_ids(self, idxs: list | tuple) -&gt; list:\n    \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise.\"\"\"\n    if self.has_ids:\n        return self.node_ids[idxs].tolist()\n    else:\n        return idxs\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.to_idx","title":"<code>to_idx</code>","text":"<p>Map argument (ID or index) to index if mapping is defined, return argument otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_idx(self, node: Union[str, int]) -&gt; int:\n    \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\"\"\"\n    if self.has_ids:\n        return self.id_to_idx[node]\n    else:\n        return node\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.to_idxs","title":"<code>to_idxs</code>","text":"<p>Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_idxs(self, nodes: list | tuple) -&gt; torch.Tensor:\n    \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise.\"\"\"\n    if self.has_ids:\n        return torch.tensor([self.id_to_idx[node] for node in nodes])\n    else:\n        return torch.tensor(nodes)\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/","title":"MultiOrderModel","text":""},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel","title":"<code>MultiOrderModel</code>","text":"<p>MultiOrderModel based on torch_geometric.Data.</p> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>class MultiOrderModel:\n    \"\"\"MultiOrderModel based on torch_geometric.Data.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.layers: dict[int, Graph] = {}\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the higher-order graph.\"\"\"\n        max_order = max(list(self.layers.keys())) if self.layers else 0\n        s = f\"MultiOrderModel with max. order {max_order}\"\n        return s\n\n    @staticmethod\n    def aggregate_edge_weight(ho_index: torch.Tensor, edge_weight: torch.Tensor, aggr: str = \"src\") -&gt; torch.Tensor:\n        \"\"\"\n        Aggregate edge weights of a (k-1)-th order graph for a kth-order graph.\n\n        Args:\n            ho_index: The higher-order edge index of the higher-order graph.\n            edge_weight: The edge weights of the (k-1)th order graph.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        \"\"\"\n        if aggr == \"src\":\n            ho_edge_weight = edge_weight[ho_index[0]]\n        elif aggr == \"dst\":\n            ho_edge_weight = edge_weight[ho_index[1]]\n        elif aggr == \"max\":\n            ho_edge_weight = torch.maximum(edge_weight[ho_index[0]], edge_weight[ho_index[1]])\n        elif aggr == \"mul\":\n            ho_edge_weight = edge_weight[ho_index[0]] * edge_weight[ho_index[1]]\n        else:\n            raise ValueError(f\"Unknown aggregation method {aggr}\")\n        return ho_edge_weight\n\n    @staticmethod\n    def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int) -&gt; torch.Tensor:\n        \"\"\"\n        Do a line graph transformation on the edge index to lift the order of the graph by one.\n        Assumes that the edge index is sorted.\n\n        Args:\n            edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n            num_nodes: The number of nodes in the graph.\n        \"\"\"\n        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n        # Map outdegree to each destination node to create an edge for each combination\n        # of incoming and outgoing edges for each destination node\n        outdegree_per_dst = outdegree[edge_index[1]]\n        num_new_edges = outdegree_per_dst.sum()\n        # Create sources of the new higher-order edges\n        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n        # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n        # of all previous nodes in the ordered sequence of nodes\n        ptrs = cumsum(outdegree, dim=0)[:-1]\n        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n        ho_edge_dsts += idx_correction\n        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n\n    @staticmethod\n    def lift_order_edge_index_weighted(\n        edge_index: torch.Tensor, edge_weight: torch.Tensor, num_nodes: int, aggr: str = \"src\"\n    ) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Do a line graph transformation on the edge index to lift the order of the graph by one.\n        Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph.\n        Assumes that the edge index is sorted.\n\n        Args:\n            edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n            edge_weight: The edge weights of the (k-1)th order graph.\n            num_nodes: The number of nodes in the graph.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        \"\"\"\n        ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes)\n        ho_edge_weight = MultiOrderModel.aggregate_edge_weight(ho_index, edge_weight, aggr)\n\n        return ho_index, ho_edge_weight\n\n    @staticmethod\n    def aggregate_edge_index(\n        edge_index: torch.Tensor, node_sequence: torch.Tensor, edge_weight: torch.Tensor | None = None\n    ) -&gt; Graph:\n        \"\"\"\n        Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object\n        containing the (higher-order) edge index without duplicates and the node sequences.\n        The edge weights of duplicated edges are summed up.\n\n        Args:\n            edge_index: The edge index of a (higher-order) graph where each source and destination node\n                corresponds to a node which is an edge in the (k-1)-th order graph.\n            node_sequence: The node sequences of first order nodes that each node in the edge index corresponds to.\n            edge_weight: The edge weights corresponding to the edge index.\n        \"\"\"\n        if edge_weight is None:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n\n        # If first order, then the indices in the node sequence are the inverse idx we would need already\n        if node_sequence.size(1) == 1:\n            unique_nodes = torch.arange(node_sequence.max().item() + 1, device=node_sequence.device).unsqueeze(1)\n            mapped_edge_index = node_sequence.squeeze()[edge_index]\n        else:\n            unique_nodes, inverse_idx = torch.unique(node_sequence, dim=0, return_inverse=True)\n            mapped_edge_index = inverse_idx[edge_index]\n        aggregated_edge_index, edge_weight = coalesce(\n            mapped_edge_index,\n            edge_attr=edge_weight,\n            num_nodes=unique_nodes.size(0),\n            reduce=\"sum\",\n        )\n        data = Data(\n            edge_index=aggregated_edge_index,\n            num_nodes=unique_nodes.size(0),\n            node_sequence=unique_nodes,\n            edge_weight=edge_weight,\n        )\n        return Graph(data)\n\n    @staticmethod\n    def iterate_lift_order(\n        edge_index: torch.Tensor,\n        node_sequence: torch.Tensor,\n        mapping: IndexMap,\n        edge_weight: torch.Tensor | None = None,\n        aggr: str = \"src\",\n        save: bool = True,\n    ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n        \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n        This is a helper function that should not be called directly.\n        Only use for edge_indices after the special cases have been handled e.g.\n        in the from_temporal_graph (filtering non-time-respecting paths of order 2)\n        or from_PathData (reindexing with dataloader) functions.\n\n        Args:\n            edge_index: The edge index of the (k-1)-th order graph.\n            node_sequence: The node sequences of the (k-1)-th order graph.\n            edge_weight: The edge weights of the (k-1)-th order graph.\n            k: The order of the graph that should be computed.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n            save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n        \"\"\"\n        # Lift order\n        if edge_weight is None:\n            ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n        else:\n            ho_index, edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n                edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n            )\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n        # Aggregate\n        if save:\n            gk = MultiOrderModel.aggregate_edge_index(ho_index, node_sequence, edge_weight)\n            gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n        else:\n            gk = None\n        return ho_index, node_sequence, edge_weight, gk\n\n    @staticmethod\n    def from_temporal_graph(\n        g: TemporalGraph, delta: float | int = 1, max_order: int = 1, weight: str = \"edge_weight\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\"\"\"\n        m = MultiOrderModel()\n        edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n        node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n        if weight in g.data:\n            edge_weight = g.data[weight]\n        else:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n        if cached or max_order == 1:\n            m.layers[1] = MultiOrderModel.aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[1].mapping = g.mapping\n\n        if max_order &gt; 1:\n            # Compute null model\n            null_model_edge_index, null_model_edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n                edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=\"src\"\n            )\n            # Update node sequences\n            node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n            # Remove non-time-respecting higher-order edges\n            time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n            non_negative_mask = time_diff &gt; 0\n            delta_mask = time_diff &lt;= delta\n            time_respecting_mask = non_negative_mask &amp; delta_mask\n            edge_index = null_model_edge_index[:, time_respecting_mask]\n            edge_weight = null_model_edge_weight[time_respecting_mask]\n            # Aggregate\n            if cached or max_order == 2:\n                m.layers[2] = MultiOrderModel.aggregate_edge_index(\n                    edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n                )\n                m.layers[2].mapping = IndexMap(\n                    [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n                )\n\n            for k in range(3, max_order + 1):\n                edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                    edge_index=edge_index,\n                    node_sequence=node_sequence,\n                    mapping=g.mapping,\n                    edge_weight=edge_weight,\n                    aggr=\"src\",\n                    save=cached or k == max_order,\n                )\n                if cached or k == max_order:\n                    m.layers[k] = gk\n\n        return m\n\n    @staticmethod\n    def from_PathData(\n        path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"\n        Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n        Args:\n            path_data: `PathData` object containing paths as list of PyG Data objects\n                with sorted edge indices, node sequences and num_nodes.\n            max_order: The maximum order of the MultiOrderModel that should be computed\n            mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n            cached: Whether to save the aggregated higher-order graphs smaller than max order\n                in the MultiOrderModel.\n        \"\"\"\n        m = MultiOrderModel()\n\n        # We assume that paths are sorted\n        path_graph = next(iter(DataLoader(path_data.paths, batch_size=len(path_data.paths)))).to(config[\"torch\"][\"device\"])\n        edge_index = path_graph.edge_index\n        node_sequence = path_graph.node_sequence\n        if path_graph.edge_weight is None:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n        else:\n            edge_weight = path_graph.edge_weight\n        if mode == \"diffusion\":\n            edge_weight = (\n                edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n            )\n            aggr = \"mul\"\n        elif mode == \"propagation\":\n            aggr = \"src\"\n\n        m.layers[1] = MultiOrderModel.aggregate_edge_index(\n            edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n        )\n        m.layers[1].mapping = path_data.mapping\n\n        for k in range(2, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=m.layers[1].mapping,\n                edge_weight=edge_weight,\n                aggr=aggr,\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n        return m\n\n    def to_dbgnn_data(self, max_order: int = 2, mapping: str = 'last') -&gt; Data:\n        \"\"\"\n        Convert the MultiOrderModel to a De Bruijn graph for the given maximum order.\n\n        Args:\n            max_order: The maximum order of the De Bruijn graph to be computed.\n            mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n        \"\"\"\n        if max_order not in self.layers:\n            raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n        g = self.layers[1]\n        g_max_order = self.layers[max_order]\n        num_nodes = g.data.num_nodes\n        num_ho_nodes = g_max_order.data.num_nodes\n        if g.data.x is not None:\n            x = g.data.x\n        else:\n            x = torch.eye(num_nodes, num_nodes)\n        x_max_order = torch.eye(num_ho_nodes, num_ho_nodes)\n        edge_index = g.data.edge_index\n        edge_index_max_order = g_max_order.data.edge_index\n        edge_weight = g.data.edge_weight\n        edge_weight_max_order = g_max_order.data.edge_weight\n        bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping)\n\n        if g.data.y is not None:\n            y = g.data.y\n\n        return Data(\n            num_nodes=num_nodes,\n            num_ho_nodes=num_ho_nodes,\n            x=x,\n            x_h=x_max_order,\n            edge_index=edge_index,\n            edge_index_higher_order=edge_index_max_order,\n            edge_weights=edge_weight.float(),\n            edge_weights_higher_order=edge_weight_max_order.float(),\n            bipartite_edge_index=bipartite_edge_index,\n            y=y if 'y' in locals() else None\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the higher-order graph.</p> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the higher-order graph.\"\"\"\n    max_order = max(list(self.layers.keys())) if self.layers else 0\n    s = f\"MultiOrderModel with max. order {max_order}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.aggregate_edge_index","title":"<code>aggregate_edge_index</code>  <code>staticmethod</code>","text":"<p>Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object containing the (higher-order) edge index without duplicates and the node sequences. The edge weights of duplicated edges are summed up.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of a (higher-order) graph where each source and destination node corresponds to a node which is an edge in the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of first order nodes that each node in the edge index corresponds to.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights corresponding to the edge index.</p> <code>None</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef aggregate_edge_index(\n    edge_index: torch.Tensor, node_sequence: torch.Tensor, edge_weight: torch.Tensor | None = None\n) -&gt; Graph:\n    \"\"\"\n    Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object\n    containing the (higher-order) edge index without duplicates and the node sequences.\n    The edge weights of duplicated edges are summed up.\n\n    Args:\n        edge_index: The edge index of a (higher-order) graph where each source and destination node\n            corresponds to a node which is an edge in the (k-1)-th order graph.\n        node_sequence: The node sequences of first order nodes that each node in the edge index corresponds to.\n        edge_weight: The edge weights corresponding to the edge index.\n    \"\"\"\n    if edge_weight is None:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n\n    # If first order, then the indices in the node sequence are the inverse idx we would need already\n    if node_sequence.size(1) == 1:\n        unique_nodes = torch.arange(node_sequence.max().item() + 1, device=node_sequence.device).unsqueeze(1)\n        mapped_edge_index = node_sequence.squeeze()[edge_index]\n    else:\n        unique_nodes, inverse_idx = torch.unique(node_sequence, dim=0, return_inverse=True)\n        mapped_edge_index = inverse_idx[edge_index]\n    aggregated_edge_index, edge_weight = coalesce(\n        mapped_edge_index,\n        edge_attr=edge_weight,\n        num_nodes=unique_nodes.size(0),\n        reduce=\"sum\",\n    )\n    data = Data(\n        edge_index=aggregated_edge_index,\n        num_nodes=unique_nodes.size(0),\n        node_sequence=unique_nodes,\n        edge_weight=edge_weight,\n    )\n    return Graph(data)\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.aggregate_edge_weight","title":"<code>aggregate_edge_weight</code>  <code>staticmethod</code>","text":"<p>Aggregate edge weights of a (k-1)-th order graph for a kth-order graph.</p> <p>Parameters:</p> Name Type Description Default <code>ho_index</code> <code>torch.Tensor</code> <p>The higher-order edge index of the higher-order graph.</p> required <code>edge_weight</code> <code>torch.Tensor</code> <p>The edge weights of the (k-1)th order graph.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef aggregate_edge_weight(ho_index: torch.Tensor, edge_weight: torch.Tensor, aggr: str = \"src\") -&gt; torch.Tensor:\n    \"\"\"\n    Aggregate edge weights of a (k-1)-th order graph for a kth-order graph.\n\n    Args:\n        ho_index: The higher-order edge index of the higher-order graph.\n        edge_weight: The edge weights of the (k-1)th order graph.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n    \"\"\"\n    if aggr == \"src\":\n        ho_edge_weight = edge_weight[ho_index[0]]\n    elif aggr == \"dst\":\n        ho_edge_weight = edge_weight[ho_index[1]]\n    elif aggr == \"max\":\n        ho_edge_weight = torch.maximum(edge_weight[ho_index[0]], edge_weight[ho_index[1]])\n    elif aggr == \"mul\":\n        ho_edge_weight = edge_weight[ho_index[0]] * edge_weight[ho_index[1]]\n    else:\n        raise ValueError(f\"Unknown aggregation method {aggr}\")\n    return ho_edge_weight\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.from_PathData","title":"<code>from_PathData</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graphs modelling paths in PathData.</p> <p>Parameters:</p> Name Type Description Default <code>path_data</code> <code>pathpyG.core.path_data.PathData</code> <p><code>PathData</code> object containing paths as list of PyG Data objects with sorted edge indices, node sequences and num_nodes.</p> required <code>max_order</code> <code>int</code> <p>The maximum order of the MultiOrderModel that should be computed</p> <code>1</code> <code>mode</code> <code>str</code> <p>The process that we assume. Can be \"diffusion\" or \"propagation\".</p> <code>'propagation'</code> <code>cached</code> <code>bool</code> <p>Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.</p> <code>True</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef from_PathData(\n    path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"\n    Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n    Args:\n        path_data: `PathData` object containing paths as list of PyG Data objects\n            with sorted edge indices, node sequences and num_nodes.\n        max_order: The maximum order of the MultiOrderModel that should be computed\n        mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n        cached: Whether to save the aggregated higher-order graphs smaller than max order\n            in the MultiOrderModel.\n    \"\"\"\n    m = MultiOrderModel()\n\n    # We assume that paths are sorted\n    path_graph = next(iter(DataLoader(path_data.paths, batch_size=len(path_data.paths)))).to(config[\"torch\"][\"device\"])\n    edge_index = path_graph.edge_index\n    node_sequence = path_graph.node_sequence\n    if path_graph.edge_weight is None:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n    else:\n        edge_weight = path_graph.edge_weight\n    if mode == \"diffusion\":\n        edge_weight = (\n            edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n        )\n        aggr = \"mul\"\n    elif mode == \"propagation\":\n        aggr = \"src\"\n\n    m.layers[1] = MultiOrderModel.aggregate_edge_index(\n        edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n    )\n    m.layers[1].mapping = path_data.mapping\n\n    for k in range(2, max_order + 1):\n        edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n            edge_index=edge_index,\n            node_sequence=node_sequence,\n            mapping=m.layers[1].mapping,\n            edge_weight=edge_weight,\n            aggr=aggr,\n            save=cached or k == max_order,\n        )\n        if cached or k == max_order:\n            m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.from_temporal_graph","title":"<code>from_temporal_graph</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.</p> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef from_temporal_graph(\n    g: TemporalGraph, delta: float | int = 1, max_order: int = 1, weight: str = \"edge_weight\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\"\"\"\n    m = MultiOrderModel()\n    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n    if weight in g.data:\n        edge_weight = g.data[weight]\n    else:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n    if cached or max_order == 1:\n        m.layers[1] = MultiOrderModel.aggregate_edge_index(\n            edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n        )\n        m.layers[1].mapping = g.mapping\n\n    if max_order &gt; 1:\n        # Compute null model\n        null_model_edge_index, null_model_edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n            edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=\"src\"\n        )\n        # Update node sequences\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n        # Remove non-time-respecting higher-order edges\n        time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n        non_negative_mask = time_diff &gt; 0\n        delta_mask = time_diff &lt;= delta\n        time_respecting_mask = non_negative_mask &amp; delta_mask\n        edge_index = null_model_edge_index[:, time_respecting_mask]\n        edge_weight = null_model_edge_weight[time_respecting_mask]\n        # Aggregate\n        if cached or max_order == 2:\n            m.layers[2] = MultiOrderModel.aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[2].mapping = IndexMap(\n                [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n            )\n\n        for k in range(3, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=g.mapping,\n                edge_weight=edge_weight,\n                aggr=\"src\",\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.iterate_lift_order","title":"<code>iterate_lift_order</code>  <code>staticmethod</code>","text":"<p>Lift order by one and save the result in the layers dictionary of the object. This is a helper function that should not be called directly. Only use for edge_indices after the special cases have been handled e.g. in the from_temporal_graph (filtering non-time-respecting paths of order 2) or from_PathData (reindexing with dataloader) functions.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of the (k-1)-th order graph.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights of the (k-1)-th order graph.</p> <code>None</code> <code>k</code> <p>The order of the graph that should be computed.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> <code>save</code> <code>bool</code> <p>Whether to compute the aggregated graph and later save it in the layers dictionary.</p> <code>True</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef iterate_lift_order(\n    edge_index: torch.Tensor,\n    node_sequence: torch.Tensor,\n    mapping: IndexMap,\n    edge_weight: torch.Tensor | None = None,\n    aggr: str = \"src\",\n    save: bool = True,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n    \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n    This is a helper function that should not be called directly.\n    Only use for edge_indices after the special cases have been handled e.g.\n    in the from_temporal_graph (filtering non-time-respecting paths of order 2)\n    or from_PathData (reindexing with dataloader) functions.\n\n    Args:\n        edge_index: The edge index of the (k-1)-th order graph.\n        node_sequence: The node sequences of the (k-1)-th order graph.\n        edge_weight: The edge weights of the (k-1)-th order graph.\n        k: The order of the graph that should be computed.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n    \"\"\"\n    # Lift order\n    if edge_weight is None:\n        ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n    else:\n        ho_index, edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n            edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n        )\n    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n    # Aggregate\n    if save:\n        gk = MultiOrderModel.aggregate_edge_index(ho_index, node_sequence, edge_weight)\n        gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n    else:\n        gk = None\n    return ho_index, node_sequence, edge_weight, gk\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.lift_order_edge_index","title":"<code>lift_order_edge_index</code>  <code>staticmethod</code>","text":"<p>Do a line graph transformation on the edge index to lift the order of the graph by one. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>num_nodes</code> <code>int</code> <p>The number of nodes in the graph.</p> required Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int) -&gt; torch.Tensor:\n    \"\"\"\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        num_nodes: The number of nodes in the graph.\n    \"\"\"\n    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n    # Map outdegree to each destination node to create an edge for each combination\n    # of incoming and outgoing edges for each destination node\n    outdegree_per_dst = outdegree[edge_index[1]]\n    num_new_edges = outdegree_per_dst.sum()\n    # Create sources of the new higher-order edges\n    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n    # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n    # of all previous nodes in the ordered sequence of nodes\n    ptrs = cumsum(outdegree, dim=0)[:-1]\n    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n    idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n    ho_edge_dsts += idx_correction\n    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.lift_order_edge_index_weighted","title":"<code>lift_order_edge_index_weighted</code>  <code>staticmethod</code>","text":"<p>Do a line graph transformation on the edge index to lift the order of the graph by one. Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>edge_weight</code> <code>torch.Tensor</code> <p>The edge weights of the (k-1)th order graph.</p> required <code>num_nodes</code> <code>int</code> <p>The number of nodes in the graph.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef lift_order_edge_index_weighted(\n    edge_index: torch.Tensor, edge_weight: torch.Tensor, num_nodes: int, aggr: str = \"src\"\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        edge_weight: The edge weights of the (k-1)th order graph.\n        num_nodes: The number of nodes in the graph.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n    \"\"\"\n    ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes)\n    ho_edge_weight = MultiOrderModel.aggregate_edge_weight(ho_index, edge_weight, aggr)\n\n    return ho_index, ho_edge_weight\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.to_dbgnn_data","title":"<code>to_dbgnn_data</code>","text":"<p>Convert the MultiOrderModel to a De Bruijn graph for the given maximum order.</p> <p>Parameters:</p> Name Type Description Default <code>max_order</code> <code>int</code> <p>The maximum order of the De Bruijn graph to be computed.</p> <code>2</code> <code>mapping</code> <code>str</code> <p>The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".</p> <code>'last'</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>def to_dbgnn_data(self, max_order: int = 2, mapping: str = 'last') -&gt; Data:\n    \"\"\"\n    Convert the MultiOrderModel to a De Bruijn graph for the given maximum order.\n\n    Args:\n        max_order: The maximum order of the De Bruijn graph to be computed.\n        mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n    \"\"\"\n    if max_order not in self.layers:\n        raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n    g = self.layers[1]\n    g_max_order = self.layers[max_order]\n    num_nodes = g.data.num_nodes\n    num_ho_nodes = g_max_order.data.num_nodes\n    if g.data.x is not None:\n        x = g.data.x\n    else:\n        x = torch.eye(num_nodes, num_nodes)\n    x_max_order = torch.eye(num_ho_nodes, num_ho_nodes)\n    edge_index = g.data.edge_index\n    edge_index_max_order = g_max_order.data.edge_index\n    edge_weight = g.data.edge_weight\n    edge_weight_max_order = g_max_order.data.edge_weight\n    bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping)\n\n    if g.data.y is not None:\n        y = g.data.y\n\n    return Data(\n        num_nodes=num_nodes,\n        num_ho_nodes=num_ho_nodes,\n        x=x,\n        x_h=x_max_order,\n        edge_index=edge_index,\n        edge_index_higher_order=edge_index_max_order,\n        edge_weights=edge_weight.float(),\n        edge_weights_higher_order=edge_weight_max_order.float(),\n        bipartite_edge_index=bipartite_edge_index,\n        y=y if 'y' in locals() else None\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/","title":"TemporalGraph","text":""},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph","title":"<code>TemporalGraph</code>","text":"<p>               Bases: <code>pathpyG.Graph</code></p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>class TemporalGraph(Graph):\n    def __init__(self, data: TemporalData, mapping: IndexMap = None) -&gt; None:\n        \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n\n        Example:\n            ```py\n            from pytorch_geometric.data import TemporalData\n            import pathpyG as pp\n\n            d = TemporalData(src=[0,0,1], dst=[1,2,2], t=[0,1,2])\n            t = pp.TemporalGraph(d, mapping)\n            print(t)\n            ```\n        \"\"\"\n\n        # sort edges by timestamp\n        # Note: function sort_by_time mentioned in pyG documentation does not exist\n        t_sorted, sort_index = torch.sort(data.t)\n\n        # reorder temporal data\n        self.data = TemporalData(\n            src=data.src[sort_index],\n            dst=data.dst[sort_index],\n            t=t_sorted\n        ).to(config['torch']['device'])\n\n        if mapping is not None:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n\n        # create mapping between edge index and edge tuples\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i\n            for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        self.start_time = t_sorted.min().item()\n        self.end_time = t_sorted.max().item()\n\n        # # initialize adjacency matrix\n        # self._sparse_adj_matrix = torch_geometric.utils.to_scipy_sparse_matrix(\n        #     self.data.edge_index\n        # ).tocsr()\n\n    @staticmethod\n    def from_edge_list(edge_list) -&gt; TemporalGraph:\n        sources = []\n        targets = []\n        ts = []\n\n        index_map = IndexMap()\n\n        for v, w, t in edge_list:\n            index_map.add_id(v)\n            index_map.add_id(w)\n            sources.append(index_map.to_idx(v))\n            targets.append(index_map.to_idx(w))\n            ts.append(t)\n\n        return TemporalGraph(\n            data=TemporalData(\n                        src=torch.Tensor(sources).long(),\n                        dst=torch.Tensor(targets).long(),\n                        t=torch.Tensor(ts)),\n            mapping=index_map\n        )\n\n    @staticmethod\n    def from_csv(file, timestamp_format='%Y-%m-%d %H:%M:%S', time_rescale=1) -&gt; TemporalGraph:\n        tedges = []\n        with open(file, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                fields = line.strip().split(\",\")\n                timestamp = fields[2]\n                if timestamp.isdigit():\n                    t = int(timestamp)\n                else:\n                    # if it is a string, we use the timestamp format to convert\n                    # it to a UNIX timestamp\n                    x = datetime.datetime.strptime(timestamp, timestamp_format)\n                    t = int(mktime(x.timetuple()))\n                tedges.append((fields[0], fields[1], int(t/time_rescale)))\n        return TemporalGraph.from_edge_list(tedges)\n\n    @property\n    def temporal_edges(self) -&gt; Generator[Tuple[int, int, int], None, None]:\n        \"\"\"Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.\"\"\"\n        i = 0\n        for e in self.data.edge_index.t():\n            yield self.mapping.to_id(e[0].item()), self.mapping.to_id(e[1].item()), self.data.t[i].item()  # type: ignore\n            i += 1\n\n    def shuffle_time(self) -&gt; None:\n        \"\"\"Randomly shuffles the temporal order of edges by randomly permuting timestamps.\"\"\"\n        self.data['t'] = self.data['t'][torch.randperm(len(self.data['t']))]\n        # t_sorted, indices = torch.sort(torch.tensor(t).to(config[\"torch\"][\"device\"]))\n        # self.data['src'] = self.data['src']\n        # self.data['dst'] = self.data['dst']\n        # self.data['t'] = t_sorted\n\n    def to_static_graph(self, weighted=False, time_window: Optional[Tuple[int,int]]=None) -&gt; Graph:\n        \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n        \"\"\"\n        if time_window is not None:\n            idx = (self.data.t &gt;= time_window[0]).logical_and(self.data.t &lt; time_window[1]).nonzero().ravel()\n            edge_index = torch.stack((self.data.src[idx], self.data.dst[idx]))\n        else:\n            edge_index = torch.stack((self.data.src, self.data.dst))\n\n        n = edge_index.max().item()+1\n\n        if weighted:\n            i, w = torch_geometric.utils.coalesce(edge_index, torch.ones(edge_index.size(1), device=self.data.edge_index.device))\n            return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n,n)), edge_weight=w), self.mapping)\n        else:\n            return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n,n)), self.mapping)\n\n    def to_undirected(self) -&gt; TemporalGraph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"        \n        rev_edge_index = self.data.edge_index.flip([0])\n        edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n        times = torch.cat([self.data.t, self.data.t])\n        return TemporalGraph(\n            data=TemporalData(\n                src=edge_index[0],\n                dst=edge_index[1],\n                t=times\n            ),\n            mapping=self.mapping\n        )        \n\n    def get_window(self, start: int, end: int) -&gt; TemporalGraph:\n        \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n        edges in a given window defined by start and (non-inclusive) end, where start\n        and end refer to the number of events\"\"\"\n\n        #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n        #max_idx = torch.max(idx).item()\n\n        # return TemporalGraph(\n        #     edge_index = idx,\n        #     t = self.data.t[start:end],\n        #     node_id = self.data.node_id[:max_idx+1]\n        #     )\n        return TemporalGraph(\n            data=TemporalData(\n                src=self.data.src[start:end],\n                dst=self.data.dst[start:end],\n                t=self.data.t[start:end]\n            ),\n            mapping=self.mapping\n        )\n\n\n    def get_snapshot(self, start: int, end: int) -&gt; TemporalGraph:\n        \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n        edges in a given time window defined by start and (non-inclusive) end, where start\n        and end refer to the time stamps\"\"\"\n\n        #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n        #max_idx = torch.max(idx).item()\n\n        return TemporalGraph(\n            data=TemporalData(\n                src=self.data.src[start:end],\n                dst=self.data.dst[start:end],\n                t=self.data.t[start:end]\n            ),\n            mapping=self.mapping\n        )\n\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Returns a string representation of the graph\n        \"\"\"\n        s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n            self.data.num_nodes,\n            self.data.edge_index.unique(dim=1).size(dim=1),\n            self.data.num_events,\n            self.start_time,\n            self.end_time,\n        )\n\n        attr_types = Graph.attr_types(self.data.to_dict())\n\n        if len(self.data.node_attrs()) &gt; 0:\n            s += \"\\nNode attributes\\n\"\n            for a in self.data.node_attrs():\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.edge_attrs()) &gt; 1:\n            s += \"\\nEdge attributes\\n\"\n            for a in self.data.edge_attrs():\n                if a != \"edge_index\":\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n            self.data.node_attrs()\n        ):\n            s += \"\\nGraph attributes\\n\"\n            for a in self.data.keys():\n                if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.temporal_edges","title":"<code>temporal_edges: Generator[Tuple[int, int, int], None, None]</code>  <code>property</code>","text":"<p>Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.</p>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.__init__","title":"<code>__init__</code>","text":"<p>Creates an instance of a temporal graph from a <code>TemporalData</code> object.</p> Example <pre><code>from pytorch_geometric.data import TemporalData\nimport pathpyG as pp\n\nd = TemporalData(src=[0,0,1], dst=[1,2,2], t=[0,1,2])\nt = pp.TemporalGraph(d, mapping)\nprint(t)\n</code></pre> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def __init__(self, data: TemporalData, mapping: IndexMap = None) -&gt; None:\n    \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n\n    Example:\n        ```py\n        from pytorch_geometric.data import TemporalData\n        import pathpyG as pp\n\n        d = TemporalData(src=[0,0,1], dst=[1,2,2], t=[0,1,2])\n        t = pp.TemporalGraph(d, mapping)\n        print(t)\n        ```\n    \"\"\"\n\n    # sort edges by timestamp\n    # Note: function sort_by_time mentioned in pyG documentation does not exist\n    t_sorted, sort_index = torch.sort(data.t)\n\n    # reorder temporal data\n    self.data = TemporalData(\n        src=data.src[sort_index],\n        dst=data.dst[sort_index],\n        t=t_sorted\n    ).to(config['torch']['device'])\n\n    if mapping is not None:\n        self.mapping = mapping\n    else:\n        self.mapping = IndexMap()\n\n    # create mapping between edge index and edge tuples\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i\n        for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    self.start_time = t_sorted.min().item()\n    self.end_time = t_sorted.max().item()\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.__str__","title":"<code>__str__</code>","text":"<p>Returns a string representation of the graph</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Returns a string representation of the graph\n    \"\"\"\n    s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n        self.data.num_nodes,\n        self.data.edge_index.unique(dim=1).size(dim=1),\n        self.data.num_events,\n        self.start_time,\n        self.end_time,\n    )\n\n    attr_types = Graph.attr_types(self.data.to_dict())\n\n    if len(self.data.node_attrs()) &gt; 0:\n        s += \"\\nNode attributes\\n\"\n        for a in self.data.node_attrs():\n            s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.edge_attrs()) &gt; 1:\n        s += \"\\nEdge attributes\\n\"\n        for a in self.data.edge_attrs():\n            if a != \"edge_index\":\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n        self.data.node_attrs()\n    ):\n        s += \"\\nGraph attributes\\n\"\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.get_snapshot","title":"<code>get_snapshot</code>","text":"<p>Returns an instance of the TemporalGraph that captures all time-stamped  edges in a given time window defined by start and (non-inclusive) end, where start and end refer to the time stamps</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def get_snapshot(self, start: int, end: int) -&gt; TemporalGraph:\n    \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n    edges in a given time window defined by start and (non-inclusive) end, where start\n    and end refer to the time stamps\"\"\"\n\n    #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n    #max_idx = torch.max(idx).item()\n\n    return TemporalGraph(\n        data=TemporalData(\n            src=self.data.src[start:end],\n            dst=self.data.dst[start:end],\n            t=self.data.t[start:end]\n        ),\n        mapping=self.mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.get_window","title":"<code>get_window</code>","text":"<p>Returns an instance of the TemporalGraph that captures all time-stamped  edges in a given window defined by start and (non-inclusive) end, where start and end refer to the number of events</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def get_window(self, start: int, end: int) -&gt; TemporalGraph:\n    \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n    edges in a given window defined by start and (non-inclusive) end, where start\n    and end refer to the number of events\"\"\"\n\n    #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n    #max_idx = torch.max(idx).item()\n\n    # return TemporalGraph(\n    #     edge_index = idx,\n    #     t = self.data.t[start:end],\n    #     node_id = self.data.node_id[:max_idx+1]\n    #     )\n    return TemporalGraph(\n        data=TemporalData(\n            src=self.data.src[start:end],\n            dst=self.data.dst[start:end],\n            t=self.data.t[start:end]\n        ),\n        mapping=self.mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.shuffle_time","title":"<code>shuffle_time</code>","text":"<p>Randomly shuffles the temporal order of edges by randomly permuting timestamps.</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def shuffle_time(self) -&gt; None:\n    \"\"\"Randomly shuffles the temporal order of edges by randomly permuting timestamps.\"\"\"\n    self.data['t'] = self.data['t'][torch.randperm(len(self.data['t']))]\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.to_static_graph","title":"<code>to_static_graph</code>","text":"<p>Return weighted time-aggregated instance of <code>Graph</code> graph.</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def to_static_graph(self, weighted=False, time_window: Optional[Tuple[int,int]]=None) -&gt; Graph:\n    \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n    \"\"\"\n    if time_window is not None:\n        idx = (self.data.t &gt;= time_window[0]).logical_and(self.data.t &lt; time_window[1]).nonzero().ravel()\n        edge_index = torch.stack((self.data.src[idx], self.data.dst[idx]))\n    else:\n        edge_index = torch.stack((self.data.src, self.data.dst))\n\n    n = edge_index.max().item()+1\n\n    if weighted:\n        i, w = torch_geometric.utils.coalesce(edge_index, torch.ones(edge_index.size(1), device=self.data.edge_index.device))\n        return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n,n)), edge_weight=w), self.mapping)\n    else:\n        return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n,n)), self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def to_undirected(self) -&gt; TemporalGraph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"        \n    rev_edge_index = self.data.edge_index.flip([0])\n    edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n    times = torch.cat([self.data.t, self.data.t])\n    return TemporalGraph(\n        data=TemporalData(\n            src=edge_index[0],\n            dst=edge_index[1],\n            t=times\n        ),\n        mapping=self.mapping\n    )        \n</code></pre>"},{"location":"reference/pathpyG/core/path_data/","title":"path_data","text":""},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData","title":"<code>PathData</code>","text":"<p>Class that can be used to store multiple observations of node sequences representing paths or walks</p> Example <pre><code>import pathpyG as pp\nimport torch\n\npp.config['torch']['device'] = 'cuda'\n\n# Generate toy example graph\ng = pp.Graph.from_edge_list([('a', 'c'),\n                     ('b', 'c'),\n                     ('c', 'd'),\n                     ('c', 'e')])\n\n# Store observations of walks using the index mapping\n# from the graph above\npaths = pp.PathData(g.mapping)\npaths.append_walk(('a', 'c', 'd'), weight=2.0)\npaths.append_walk(('b', 'c', 'e'), weight=2.0)\nprint(paths)\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>class PathData:\n    \"\"\"Class that can be used to store multiple observations of\n    node sequences representing paths or walks\n\n    Example:\n        ```py\n        import pathpyG as pp\n        import torch\n\n        pp.config['torch']['device'] = 'cuda'\n\n        # Generate toy example graph\n        g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\n\n        # Store observations of walks using the index mapping\n        # from the graph above\n        paths = pp.PathData(g.mapping)\n        paths.append_walk(('a', 'c', 'd'), weight=2.0)\n        paths.append_walk(('b', 'c', 'e'), weight=2.0)\n        print(paths)\n        ```\n    \"\"\"\n\n    def __init__(self, mapping: IndexMap | None = None) -&gt; None:\n        self.paths: list = []\n\n        if mapping:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n        # If the function add_walks is used, all walks are saved in one Data object\n        # walk_index stores a tuple that contains the idx in the path list, the start and end index of the walk\n        self.path_index: list[tuple[int, int, int]] = []\n\n    @property\n    def num_paths(self) -&gt; int:\n        \"\"\"Return the number of stored paths.\"\"\"\n        return len(self.paths)\n\n    def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n        \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n        Example:\n                ```py\n                import torch\n                import pathpyG as pp\n\n                g = pp.Graph.from_edge_list([('a', 'c'),\n                        ('b', 'c'),\n                        ('c', 'd'),\n                        ('c', 'e')])\n\n                walks = pp.PathData(g.mapping)\n                walks.append_walk(('a', 'c', 'd'), weight=2.0)\n                paths.append_walk(('b', 'c', 'e'), weight=1.0)\n                ```\n        \"\"\"\n        idx_seq = self.mapping.to_idxs(node_seq)\n        idx = torch.arange(len(node_seq))\n        edge_index = torch.stack([idx[:-1], idx[1:]])\n\n        self.path_index.append((len(self.paths), 0, len(node_seq)))\n        self.paths.append(\n            Data(\n                edge_index=edge_index,\n                node_sequence=idx_seq.unsqueeze(1),\n                num_nodes=len(node_seq),\n                edge_weight=torch.full((edge_index.size(1),), weight),\n            )\n        )\n\n    def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n        \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\"\"\"\n        idx_seqs = torch.cat([self.mapping.to_idxs(seq) for seq in node_seqs]).unsqueeze(1)\n        path_lengths = torch.tensor([len(seq) for seq in node_seqs])\n        big_idx = torch.arange(path_lengths.sum())\n        big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n        # remove the edges that connect different walks\n        mask = torch.ones(big_edge_index.size(1), dtype=torch.bool)\n        cum_sum = cumsum(path_lengths, 0)\n        mask[cum_sum[1:-1] - 1] = False\n        big_edge_index = big_edge_index[:, mask]\n\n        self.path_index += [\n            (len(self.paths), start.item(), end.item()) for start, end in torch.vstack([cum_sum[:-1], cum_sum[1:]]).T\n        ]\n        self.paths.append(\n            Data(\n                edge_index=big_edge_index,\n                node_sequence=idx_seqs,\n                num_nodes=idx_seqs.max().item() + 1,\n                edge_weight=torch.cat([torch.full((length-1,), w) for length, w in zip(path_lengths, weights)]),\n            )\n        )\n\n    def get_walk(self, i: int) -&gt; tuple:\n        i_walk, start, end = self.path_index[i]\n        return tuple(self.mapping.to_ids(self.paths[i_walk].node_sequence[start:end].squeeze()))\n\n    def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n        \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n        return self.mapping.to_ids(node_seq)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the PathData object.\"\"\"\n        num_paths = len(self.paths)\n        weight = sum([d.edge_weight.max().item() for d in self.paths])\n        s = f\"PathData with {num_paths} paths with total weight {weight}\"\n        return s\n\n    @staticmethod\n    def from_ngram(file: str, sep: str = \",\", weight: bool = True) -&gt; PathData:\n        with open(file, \"r\", encoding=\"utf-8\") as f:\n            if weight:\n                paths_and_weights = [line.split(sep) for line in f]\n                paths = [path[:-1] for path in paths_and_weights]\n                weights = [float(path[-1]) for path in paths_and_weights]\n            else:\n                paths = [line.split(sep) for line in f]\n                weights = [1.0] * len(paths)\n\n        mapping = IndexMap()\n        mapping.add_ids(np.concatenate([np.array(path) for path in paths]))\n\n        pathdata = PathData(mapping)\n        pathdata.append_walks(node_seqs=paths, weights=weights)\n\n        return pathdata\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.num_paths","title":"<code>num_paths: int</code>  <code>property</code>","text":"<p>Return the number of stored paths.</p>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the PathData object.</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the PathData object.\"\"\"\n    num_paths = len(self.paths)\n    weight = sum([d.edge_weight.max().item() for d in self.paths])\n    s = f\"PathData with {num_paths} paths with total weight {weight}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.append_walk","title":"<code>append_walk</code>","text":"<p>Add an observation of a walk based on a list or tuple of node IDs or indices</p> Example <pre><code>import torch\nimport pathpyG as pp\n\ng = pp.Graph.from_edge_list([('a', 'c'),\n        ('b', 'c'),\n        ('c', 'd'),\n        ('c', 'e')])\n\nwalks = pp.PathData(g.mapping)\nwalks.append_walk(('a', 'c', 'd'), weight=2.0)\npaths.append_walk(('b', 'c', 'e'), weight=1.0)\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n    \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n    Example:\n            ```py\n            import torch\n            import pathpyG as pp\n\n            g = pp.Graph.from_edge_list([('a', 'c'),\n                    ('b', 'c'),\n                    ('c', 'd'),\n                    ('c', 'e')])\n\n            walks = pp.PathData(g.mapping)\n            walks.append_walk(('a', 'c', 'd'), weight=2.0)\n            paths.append_walk(('b', 'c', 'e'), weight=1.0)\n            ```\n    \"\"\"\n    idx_seq = self.mapping.to_idxs(node_seq)\n    idx = torch.arange(len(node_seq))\n    edge_index = torch.stack([idx[:-1], idx[1:]])\n\n    self.path_index.append((len(self.paths), 0, len(node_seq)))\n    self.paths.append(\n        Data(\n            edge_index=edge_index,\n            node_sequence=idx_seq.unsqueeze(1),\n            num_nodes=len(node_seq),\n            edge_weight=torch.full((edge_index.size(1),), weight),\n        )\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.append_walks","title":"<code>append_walks</code>","text":"<p>Add multiple observations of walks based on lists or tuples of node IDs or indices</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n    \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\"\"\"\n    idx_seqs = torch.cat([self.mapping.to_idxs(seq) for seq in node_seqs]).unsqueeze(1)\n    path_lengths = torch.tensor([len(seq) for seq in node_seqs])\n    big_idx = torch.arange(path_lengths.sum())\n    big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n    # remove the edges that connect different walks\n    mask = torch.ones(big_edge_index.size(1), dtype=torch.bool)\n    cum_sum = cumsum(path_lengths, 0)\n    mask[cum_sum[1:-1] - 1] = False\n    big_edge_index = big_edge_index[:, mask]\n\n    self.path_index += [\n        (len(self.paths), start.item(), end.item()) for start, end in torch.vstack([cum_sum[:-1], cum_sum[1:]]).T\n    ]\n    self.paths.append(\n        Data(\n            edge_index=big_edge_index,\n            node_sequence=idx_seqs,\n            num_nodes=idx_seqs.max().item() + 1,\n            edge_weight=torch.cat([torch.full((length-1,), w) for length, w in zip(path_lengths, weights)]),\n        )\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.map_node_seq","title":"<code>map_node_seq</code>","text":"<p>Map a sequence of node indices (e.g. representing a higher-order node) to node IDs</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n    \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n    return self.mapping.to_ids(node_seq)\n</code></pre>"},{"location":"reference/pathpyG/io/","title":"io","text":""},{"location":"reference/pathpyG/io/netzschleuder/","title":"netzschleuder","text":""},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.list_netzschleuder_records","title":"<code>list_netzschleuder_records</code>","text":"<p>Read a list of data sets available at the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <code>**kwargs</code> <code>typing.Any</code> <p>Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters. For supported parameters see https://networks.skewed.de/api</p> <code>{}</code> <p>Examples:</p> <p>Return a list of all data sets</p> <pre><code>&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records()\n['karate', 'reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a list of all data sets with a given tag</p> <pre><code>&gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records(tags='temporal')\n['reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a dictionary containing all data set names (keys) as well as all network attributes</p> <pre><code>&gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records(full=True)\n{ 'reality_mining': [...], 'karate': [...] }\n</code></pre> <p>Returns:</p> Type Description <code>typing.Union[list, dict]</code> <p>Either a list of data set names or a dictionary containing all data set names and network attributes.</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def list_netzschleuder_records(base_url: str='https://networks.skewed.de', **kwargs: Any) -&gt; Union[list, dict]:\n    \"\"\"\n    Read a list of data sets available at the netzschleuder repository.\n\n    Args:\n        base_url: Base URL of netzschleuder repository\n        **kwargs: Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters.\n            For supported parameters see https://networks.skewed.de/api\n\n\n    Examples:\n        Return a list of all data sets\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records()\n        ['karate', 'reality_mining', 'sp_hypertext', ...]\n\n        Return a list of all data sets with a given tag\n\n        &gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records(tags='temporal')\n        ['reality_mining', 'sp_hypertext', ...]\n\n        Return a dictionary containing all data set names (keys) as well as all network attributes\n\n        &gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records(full=True)\n        { 'reality_mining': [...], 'karate': [...] }\n\n\n    Returns:\n        Either a list of data set names or a dictionary containing all data set names and network attributes.\n\n    \"\"\"\n    url = '/api/nets'\n    for k, v in kwargs.items():\n        url += '?{0}={1}'.format(k, v)\n    try:\n        f = request.urlopen(base_url + url).read()\n        return json.loads(f)\n    except HTTPError:\n        msg = 'Could not connect to netzschleuder repository at {0}'.format(base_url)\n        # LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.parse_graphtool_format","title":"<code>parse_graphtool_format</code>","text":"<p>Decodes data in graphtool binary format and returns a <code>Graph</code>. For a documentation of hte graphtool binary format, see see doc at https://graph-tool.skewed.de/static/doc/gt_format.html</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>Array of bys to be decoded</p> required <code>ignore_temporal</code> <p>If False, this function will return a static or temporal network depending on whether edges contain a time attribute. If True, pathpy will not interpret time attributes and thus always return a static network.</p> required <p>Returns:</p> Type Description <code>pathpyG.core.Graph.Graph</code> <p>Network or TemporalNetwork: a static or temporal network object</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def parse_graphtool_format(data: bytes, id_node_attr=None) -&gt; Graph:\n    \"\"\"\n    Decodes data in graphtool binary format and returns a [`Graph`][pathpyG.Graph]. For a documentation of\n    hte graphtool binary format, see see doc at https://graph-tool.skewed.de/static/doc/gt_format.html\n\n    Args:\n        data: Array of bys to be decoded\n        ignore_temporal: If False, this function will return a static or temporal network depending\n            on whether edges contain a time attribute. If True, pathpy will not interpret\n            time attributes and thus always return a static network.\n\n    Returns:\n        Network or TemporalNetwork: a static or temporal network object\n    \"\"\"\n\n    # check magic bytes\n    if data[0:6] != b'\\xe2\\x9b\\xbe\\x20\\x67\\x74':\n        print('Invalid graphtool file. Wrong magic bytes.')\n        raise Exception('Invalid graphtool file. Wrong magic bytes.')\n    ptr = 6\n\n    # read graphtool version byte\n    graphtool_version = int(data[ptr])\n    ptr += 1\n\n    # read endianness\n    if bool(data[ptr]):\n        graphtool_endianness = '&gt;'\n    else:\n        graphtool_endianness = '&lt;'\n    ptr += 1\n\n    # read length of comment\n    str_len = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n    ptr += 8\n\n    # read string comment\n    comment = data[ptr:ptr+str_len].decode('ascii')\n    ptr += str_len\n\n    # read network directedness\n    directed = bool(data[ptr])\n    ptr += 1\n\n    # read number of nodes\n    n_nodes = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n    ptr += 8\n\n    # create pandas dataframe\n    network_dict = {}\n    # n = Network(directed = directed, multiedges=True)\n\n    # determine binary representation of neighbour lists\n    if n_nodes&lt;2**8:\n        fmt = 'B'\n        d = 1\n    elif n_nodes&lt;2**16:\n        fmt = 'H'\n        d = 2\n    elif n_nodes&lt;2**32:\n        fmt = 'I'\n        d = 4\n    else:\n        fmt = 'Q'\n        d = 8\n\n    sources = []\n    targets = []\n    # parse lists of out-neighbors for all n nodes\n    n_edges = 0\n    for v in range(n_nodes):\n        # read number of neighbors\n        num_neighbors = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n        ptr += 8\n\n        # add edges to record\n        for j in range(num_neighbors):\n            w = struct.unpack(graphtool_endianness + fmt, data[ptr:ptr+d])[0]\n            ptr += d\n            sources.append(v)\n            targets.append(w)\n            n_edges += 1\n\n    # collect attributes from property maps\n    graph_attr = dict()\n    node_attr = dict()\n    edge_attr = dict()\n\n    # parse property maps\n    property_maps = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n    ptr += 8\n\n    for i in range(property_maps):\n        key_type = struct.unpack(graphtool_endianness + 'B', data[ptr:ptr+1])[0]\n        ptr += 1\n\n        property_len  = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n        ptr += 8\n\n        property_name = data[ptr:ptr+property_len].decode('ascii')\n        ptr += property_len\n\n        property_type = struct.unpack(graphtool_endianness + 'B', data[ptr:ptr+1])[0]\n        ptr += 1\n\n        if key_type == 0: # graph-level property\n            res = _parse_property_value(data, ptr, property_type, graphtool_endianness)\n            graph_attr[property_name] = res[0]\n            ptr += res[1]\n        elif key_type == 1: # node-level property\n            if property_name not in node_attr:\n                node_attr[property_name] = []\n            for v in range(n_nodes):\n                res = _parse_property_value(data, ptr, property_type, graphtool_endianness)\n                node_attr[property_name].append([res[0]])\n                ptr += res[1]\n        elif key_type == 2: # edge-level property\n            if property_name not in edge_attr:\n                edge_attr[property_name] = []\n            for e in range(n_edges):\n                res = _parse_property_value(data, ptr, property_type, graphtool_endianness)\n                edge_attr[property_name].append(res[0])\n                ptr += res[1]\n        else:\n            print('Unknown key type {0}'.format(key_type))\n\n    # LOG.info('Version \\t= {0}'.format(graphtool_version))\n    # LOG.info('Endianness \\t= {0}'.format(graphtool_endianness))\n    # LOG.info('comment size \\t= {0}'.format(str_len))\n    # LOG.info('comment \\t= {0}'.format(comment))\n    # LOG.info('directed \\t= {0}'.format(directed))\n    # LOG.info('nodes \\t\\t= {0}'.format(n_nodes))\n\n    # add edge properties to data frame\n    # for p in edge_attribute_names:\n    #     # due to use of default_dict, this will add NA values to edges which have missing properties\n    #     network_data[p] = [ edge_attributes[e][p] for e in range(n_edges) ]\n\n    # create graph from pandas dataframe\n\n\n    # if 'time' in edge_attribute_names and not ignore_temporal:\n    #     raise Exception('')\n    #     n = to_temporal_network(network_data, directed=directed, **network_attributes)\n    # else:\n\n\n    if id_node_attr:\n        mapping = pp.IndexMap(node_attr[id_node_attr])\n    else:\n        mapping = None\n\n    g = Graph.from_edge_index(torch.LongTensor([sources, targets]).to(config['torch']['device']), mapping=mapping)\n    for a in node_attr:\n        if not a.startswith('node_'):\n            # print(node_attr[a])\n            # g.data['node_{0}'.format(a)] = torch.tensor(node_attr[a], dtype=torch.float).to(config['torch']['device'])\n            g.data['node_{0}'.format(a)] = node_attr[a]\n    for a in edge_attr:\n        if not a.startswith('edge_'):\n            g.data['edge_{0}'.format(a)] = torch.tensor(edge_attr[a], dtype=torch.float).to(config['torch']['device'])\n    for a in graph_attr:\n        g.data[a] = graph_attr[a]\n\n    if not directed:\n        return g.to_undirected()\n    return g\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_graphtool","title":"<code>read_graphtool</code>","text":"<p>Read a file in graphtool binary format.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>Path to graphtool file to be read</p> required Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_graphtool(file: str, ignore_temporal: bool=False, multiedges: bool=False) -&gt; Optional[Union[Graph, TemporalGraph]]:\n    \"\"\"\n    Read a file in graphtool binary format.\n\n    Args:\n        file: Path to graphtool file to be read\n    \"\"\"\n    with open(file, 'rb') as f:\n        if '.zst' in file:\n            try:\n                import zstandard as zstd\n                dctx = zstd.ZstdDecompressor()\n                data = f.read()\n                return parse_graphtool_format(dctx.decompress(data, max_output_size=len(data)))\n            except ModuleNotFoundError:\n                msg = 'Package zstandard is required to decompress graphtool files. Please install module, e.g., using \"pip install zstandard\".'\n                # LOG.error(msg)\n                raise Exception(msg)\n        else:\n            return parse_graphtool_format(f.read(), multiedges)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_network","title":"<code>read_netzschleuder_network</code>","text":"<p>Read a pathpy network record from the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the network data sets to read from</p> required <code>net</code> <code>typing.Optional[str]</code> <p>Identifier of the network within the data set to read. For data sets containing a single network only, this can be set to None.</p> <code>None</code> <code>ignore_temporal</code> <code>bool</code> <p>If False, this function will return a static or temporal network depending on whether edges contain a time attribute. If True, pathpy will not interpret time attributes and thus always return a static network.</p> <code>False</code> <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <p>Examples:</p> <p>Read network '77' from karate club data set</p> <pre><code>&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('karate', '77')\n&gt;&gt;&gt; print(type(n))\n&gt;&gt;&gt; pp.plot(n)\npp.Network\n</code></pre> <p>Read a temporal network from a data set containing a single network only (i.e. net can be omitted):</p> <pre><code>&gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('reality_mining')\n&gt;&gt;&gt; print(type(n))\n&gt;&gt;&gt; pp.plot(n)\npp.TemporalNetwork\n</code></pre> <p>Read temporal network but ignore time attribute of edges:</p> <pre><code>&gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('reality_mining', ignore_temporal=True)\n&gt;&gt;&gt; print(type(n))\n&gt;&gt;&gt; pp.plot(n)\npp.Network\n</code></pre> <p>Returns:</p> Type Description <code>typing.Union[pathpyG.core.Graph.Graph, pathpyG.core.TemporalGraph.TemporalGraph]</code> <p>Depending on whether the network data set contains an edge attribute</p> <code>typing.Union[pathpyG.core.Graph.Graph, pathpyG.core.TemporalGraph.TemporalGraph]</code> <p><code>time</code> (and whether ignore_temporal is set to True), this function</p> <code>typing.Union[pathpyG.core.Graph.Graph, pathpyG.core.TemporalGraph.TemporalGraph]</code> <p>returns an instance of Network or TemporalNetwork</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_network(name: str, net: Optional[str]=None,\n        ignore_temporal: bool=False, multiedges: bool=False,\n        base_url: str='https://networks.skewed.de') -&gt; Union[Graph, TemporalGraph]:\n    \"\"\"Read a pathpy network record from the netzschleuder repository.\n\n    Args:\n        name: Name of the network data sets to read from\n        net: Identifier of the network within the data set to read. For data sets\n            containing a single network only, this can be set to None.\n        ignore_temporal: If False, this function will return a static or temporal network depending\n            on whether edges contain a time attribute. If True, pathpy will not interpret\n            time attributes and thus always return a static network.\n        base_url: Base URL of netzschleuder repository\n\n    Examples:\n        Read network '77' from karate club data set\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('karate', '77')\n        &gt;&gt;&gt; print(type(n))\n        &gt;&gt;&gt; pp.plot(n)\n        pp.Network\n\n        Read a temporal network from a data set containing a single network only\n        (i.e. net can be omitted):\n\n        &gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('reality_mining')\n        &gt;&gt;&gt; print(type(n))\n        &gt;&gt;&gt; pp.plot(n)\n        pp.TemporalNetwork\n\n        Read temporal network but ignore time attribute of edges:\n\n        &gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('reality_mining', ignore_temporal=True)\n        &gt;&gt;&gt; print(type(n))\n        &gt;&gt;&gt; pp.plot(n)\n        pp.Network\n\n\n    Returns:\n        Depending on whether the network data set contains an edge attribute\n        `time` (and whether ignore_temporal is set to True), this function\n        returns an instance of Network or TemporalNetwork\n\n    \"\"\"\n    try:\n        import zstandard as zstd\n\n        # retrieve network properties\n        url = '/api/net/{0}'.format(name)\n        properties = json.loads(request.urlopen(base_url + url).read())\n\n        # retrieve data\n        if not net:\n            net = name\n        url = '/net/{0}/files/{1}.gt.zst'.format(name, net)\n        try:\n            f = request.urlopen(base_url + url)\n        except HTTPError:\n            msg = 'Could not connect to netzschleuder repository at {0}'.format(base_url)\n            #LOG.error(msg)\n            raise Exception(msg)\n\n        # decompress data\n        dctx = zstd.ZstdDecompressor()\n        reader = dctx.stream_reader(f)\n        decompressed = reader.readall()\n\n        # parse graphtool binary format\n        return parse_graphtool_format(bytes(decompressed))\n\n    except ModuleNotFoundError:\n        msg = 'Package zstandard is required to decompress graphtool files. Please install module, e.g., using \"pip install zstandard.'\n        # LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_record","title":"<code>read_netzschleuder_record</code>","text":"<p>Read metadata of a single data record with given name from the netzschleuder repository</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the data set for which to retrieve the metadata</p> required <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <p>Examples:</p> <p>Retrieve metadata of karate club network</p> <pre><code>&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; metdata = pp.io.graphtool.read_netzschleuder_record('karate')\n&gt;&gt;&gt; print(metadata)\n{\n    'analyses': {'77': {'average_degree': 4.52... } }\n}\n</code></pre> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing key-value pairs of metadata</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_record(name: str, base_url: str='https://networks.skewed.de') -&gt; dict:\n    \"\"\"\n    Read metadata of a single data record with given name from the netzschleuder repository\n\n    Args:\n        name: Name of the data set for which to retrieve the metadata\n        base_url: Base URL of netzschleuder repository\n\n    Examples:\n        Retrieve metadata of karate club network\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; metdata = pp.io.graphtool.read_netzschleuder_record('karate')\n        &gt;&gt;&gt; print(metadata)\n        {\n            'analyses': {'77': {'average_degree': 4.52... } }\n        }\n\n    Returns:\n        Dictionary containing key-value pairs of metadata\n    \"\"\"\n    url = '/api/net/{0}'.format(name)\n    try:\n        return json.loads(request.urlopen(base_url + url).read())\n    except HTTPError:\n        msg = 'Could not connect to netzschleuder repository at {0}'.format(base_url)\n        #LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/nn/","title":"nn","text":""},{"location":"reference/pathpyG/nn/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/nn/dbgnn/#pathpyG.nn.dbgnn.DBGNN","title":"<code>DBGNN</code>","text":"<p>               Bases: <code>torch.nn.Module</code></p> <p>Implementation of time-aware graph neural network DBGNN (Reference paper).</p> <p>Parameters:</p> Name Type Description Default <code>num_classes</code> <code>int</code> <p>number of classes</p> required <code>num_features</code> <code>list[int]</code> <p>number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]</p> required <code>hidden_dims</code> <code>list[int]</code> <p>number of hidden dimensions per each layer in the first/higher order network</p> required <code>p_dropout</code> <code>float</code> <p>drop-out probability</p> <code>0.0</code> Source code in <code>src/pathpyG/nn/dbgnn.py</code> <pre><code>class DBGNN(Module):\n    \"\"\"Implementation of time-aware graph neural network DBGNN ([Reference paper](https://openreview.net/pdf?id=Dbkqs1EhTr)).\n\n    Args:\n        num_classes: number of classes\n        num_features: number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]\n        hidden_dims: number of hidden dimensions per each layer in the first/higher order network\n        p_dropout: drop-out probability\n    \"\"\"\n    def __init__(\n        self,\n        num_classes: int,\n        num_features: list[int],\n        hidden_dims: list[int],\n        p_dropout: float = 0.0\n    ):\n        super().__init__()\n\n        self.num_features = num_features\n        self.num_classes = num_classes\n        self.hidden_dims = hidden_dims\n        self.p_dropout = p_dropout\n\n        # higher-order layers\n        self.higher_order_layers = ModuleList()\n        self.higher_order_layers.append(GCNConv(self.num_features[1], self.hidden_dims[0]))\n\n        # first-order layers\n        self.first_order_layers = ModuleList()\n        self.first_order_layers.append(GCNConv(self.num_features[0], self.hidden_dims[0]))\n\n        for dim in range(1, len(self.hidden_dims)-1):\n            # higher-order layers\n            self.higher_order_layers.append(GCNConv(self.hidden_dims[dim-1], self.hidden_dims[dim]))\n            # first-order layers\n            self.first_order_layers.append(GCNConv(self.hidden_dims[dim-1], self.hidden_dims[dim]))\n\n        self.bipartite_layer = BipartiteGraphOperator(self.hidden_dims[-2], self.hidden_dims[-1])\n\n        # Linear layer\n        self.lin = torch.nn.Linear(self.hidden_dims[-1], num_classes)\n\n\n\n    def forward(self, data):\n\n        x = data.x\n        x_h = data.x_h\n\n        # First-order convolutions\n        for layer in self.first_order_layers:\n            x = F.dropout(x, p=self.p_dropout, training=self.training)\n            x = F.elu(layer(x, data.edge_index, data.edge_weights))\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Second-order convolutions\n        for layer in self.higher_order_layers:\n            x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n            x_h = F.elu(layer(x_h, data.edge_index_higher_order, data.edge_weights_higher_order))\n        x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n\n        # Bipartite message passing\n        x = torch.nn.functional.elu(self.bipartite_layer((x_h, x), data.bipartite_edge_index, N = data.num_ho_nodes, M= data.num_nodes))\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Linear layer\n        x = self.lin(x)\n\n        return x\n</code></pre>"},{"location":"reference/pathpyG/processes/","title":"processes","text":"<p>Module for pathpy processes.</p>"},{"location":"reference/pathpyG/processes/process/","title":"process","text":"<p>Base classes for simulation of dynamical processes</p>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess","title":"<code>BaseProcess</code>","text":"<p>Abstract base class for all implementations of discrete-time dynamical processes.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>class BaseProcess:\n    \"\"\"Abstract base class for all implementations of discrete-time dynamical processes.\n    \"\"\"\n\n    def __init__(self, network: Graph):\n        \"\"\"initialize process.\"\"\"\n        self._network = network\n        self.init(self.random_seed())\n\n    @property\n    def network(self) -&gt; Graph:\n        return self._network\n\n    @abc.abstractmethod\n    def init(self, seed: Any) -&gt; None:\n        \"\"\"Abstract method to initialize the process with a given seed state.\"\"\"\n\n    @abc.abstractmethod\n    def random_seed(self) -&gt; Any:\n        \"\"\"Abstract method to generate a random seed state for the process.\"\"\"\n\n    @abc.abstractmethod\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"Abstract method to simulate a single step of the process. Returns \n        an iterable of node uids whose state has been changed in this step.\"\"\"\n\n    @abc.abstractproperty\n    def time(self) -&gt; int:\n        \"\"\"Abstract property returning the current time.\"\"\"\n\n    @abc.abstractmethod\n    def state_to_color(self, Any) -&gt; Union[Tuple[int, int, int], str]:\n        \"\"\"Abstract method mapping node states to RGB colors or color names.\"\"\"\n\n    @abc.abstractmethod\n    def node_state(self, v: str) -&gt; Any:\n        \"\"\"Abstract method returning the current state of a given node.\"\"\"\n\n    def simulation_run(self, steps: int, seed: Optional[Any] = None) -&gt; Tuple[int, Set[str]]:\n        \"\"\"Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.\"\"\"\n        if seed == None:\n            self.init(self.random_seed())\n        else:\n            self.init(seed)\n        for _ in range(steps):\n            ret = self.step()\n            if ret is not None:\n                yield self.time, ret\n            else:\n                return None\n\n    def run_experiment(self, steps: int, runs: Optional[Union[int, Iterable[Any]]] = 1) -&gt; DataFrame:\n        \"\"\"Perform one or more simulation runs of the process with a given number of steps.\"\"\"\n\n        # Generate initializations for different runs\n        seeds: List = list()\n        if type(runs) == int:\n            for s in range(runs):\n                seeds.append(self.random_seed())\n        else:\n            for s in runs:\n                seeds.append(s)\n\n        results = list()\n        run_id: int = 0\n        for seed in tqdm(seeds):\n\n            # initialize seed state and record initial state\n            self.init(seed)\n            for v in self.network.nodes:\n                results.append({'run_id': run_id, 'seed': seed,\n                               'time': self.time, 'node': v, 'state': self.node_state(v)})\n\n            # simulate the given number of steps\n            for time, updated_nodes in self.simulation_run(steps, seed):\n                # print(updated_nodes)\n                # record the new state of each changed node\n                for v in updated_nodes:\n                    results.append({'run_id': run_id, 'seed': seed,\n                                   'time': time, 'node': v, 'state': self.node_state(v)})\n            run_id += 1\n\n        return DataFrame.from_dict(results)\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.__init__","title":"<code>__init__</code>","text":"<p>initialize process.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def __init__(self, network: Graph):\n    \"\"\"initialize process.\"\"\"\n    self._network = network\n    self.init(self.random_seed())\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.init","title":"<code>init</code>  <code>abstractmethod</code>","text":"<p>Abstract method to initialize the process with a given seed state.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef init(self, seed: Any) -&gt; None:\n    \"\"\"Abstract method to initialize the process with a given seed state.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.node_state","title":"<code>node_state</code>  <code>abstractmethod</code>","text":"<p>Abstract method returning the current state of a given node.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef node_state(self, v: str) -&gt; Any:\n    \"\"\"Abstract method returning the current state of a given node.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.random_seed","title":"<code>random_seed</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate a random seed state for the process.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef random_seed(self) -&gt; Any:\n    \"\"\"Abstract method to generate a random seed state for the process.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.run_experiment","title":"<code>run_experiment</code>","text":"<p>Perform one or more simulation runs of the process with a given number of steps.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def run_experiment(self, steps: int, runs: Optional[Union[int, Iterable[Any]]] = 1) -&gt; DataFrame:\n    \"\"\"Perform one or more simulation runs of the process with a given number of steps.\"\"\"\n\n    # Generate initializations for different runs\n    seeds: List = list()\n    if type(runs) == int:\n        for s in range(runs):\n            seeds.append(self.random_seed())\n    else:\n        for s in runs:\n            seeds.append(s)\n\n    results = list()\n    run_id: int = 0\n    for seed in tqdm(seeds):\n\n        # initialize seed state and record initial state\n        self.init(seed)\n        for v in self.network.nodes:\n            results.append({'run_id': run_id, 'seed': seed,\n                           'time': self.time, 'node': v, 'state': self.node_state(v)})\n\n        # simulate the given number of steps\n        for time, updated_nodes in self.simulation_run(steps, seed):\n            # print(updated_nodes)\n            # record the new state of each changed node\n            for v in updated_nodes:\n                results.append({'run_id': run_id, 'seed': seed,\n                               'time': time, 'node': v, 'state': self.node_state(v)})\n        run_id += 1\n\n    return DataFrame.from_dict(results)\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.simulation_run","title":"<code>simulation_run</code>","text":"<p>Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def simulation_run(self, steps: int, seed: Optional[Any] = None) -&gt; Tuple[int, Set[str]]:\n    \"\"\"Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.\"\"\"\n    if seed == None:\n        self.init(self.random_seed())\n    else:\n        self.init(seed)\n    for _ in range(steps):\n        ret = self.step()\n        if ret is not None:\n            yield self.time, ret\n        else:\n            return None\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.state_to_color","title":"<code>state_to_color</code>  <code>abstractmethod</code>","text":"<p>Abstract method mapping node states to RGB colors or color names.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef state_to_color(self, Any) -&gt; Union[Tuple[int, int, int], str]:\n    \"\"\"Abstract method mapping node states to RGB colors or color names.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.step","title":"<code>step</code>  <code>abstractmethod</code>","text":"<p>Abstract method to simulate a single step of the process. Returns  an iterable of node uids whose state has been changed in this step.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef step(self) -&gt; Iterable[str]:\n    \"\"\"Abstract method to simulate a single step of the process. Returns \n    an iterable of node uids whose state has been changed in this step.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.time","title":"<code>time</code>","text":"<p>Abstract property returning the current time.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractproperty\ndef time(self) -&gt; int:\n    \"\"\"Abstract property returning the current time.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/","title":"random_walk","text":"<p>Classes to simlate random walks on static, temporal, and higher-order networks.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk","title":"<code>HigherOrderRandomWalk</code>","text":"<p>               Bases: <code>pathpyG.processes.random_walk.RandomWalk</code></p> <p>Class that implements a biased random walk process in a higher-order network.</p> <p>Instances of this class can be used to simulate random walk processes in higher-order networks for arbitrary orders k. The random walk process can include weighted edges as well as a  restart probability, i.e. a per-step probability to teleport to a randomly chosen higher-order node.</p> <p>Different from the class RandomWalk, instances of class HigherOrderRandomWalk automatically project states to the corresponding first-order network, i.e. paths and visualisations are given  in terms of the nodes in the first-order network, while the dynamics of the random walk is governed by the underlying higher-order network.</p> <p>The implementation follows the general concept to simulate discrete-time (stochastic) processes as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface to iterate through the steps of a single random walk process, or use the <code>run_experiment</code> function to simulate multiple runs of a random walk with different start nodes (i.e. seeds).</p> <p>The <code>run_experiment</code> function returns a pandas DataFrame object that contains all node state changes  during the process' evolution. This data frame can be converted to Path and PathCollection objects  and it can be visualized using the plot function.</p> <p>Examples:</p> <p>Generate and visualize a single random walk with 10 steps on a higher-order network</p> <pre><code>&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n&gt;&gt;&gt; paths = pp.WalkData(g3.mapping)\n&gt;&gt;&gt; paths.add_walk_seq(['a','b','c'],freq=1)\n&gt;&gt;&gt; paths.add_walk_seq(['b','c','a'],freq=1)\n&gt;&gt;&gt; paths.add_walk_seq(['b','c','d'],freq=0.2)\n&gt;&gt;&gt; paths.add_walk_seq(['c','a','b'],freq=1)\n&gt;&gt;&gt; paths.add_walk_seq(['c','d','a'],freq=0.2)\n&gt;&gt;&gt; paths.add_walk_seq(['d','a','b'],freq=1)\n&gt;&gt;&gt; g_ho = pp.HigherOrderGraph(paths, order =2)\n</code></pre> <pre><code>&gt;&gt;&gt; rw = pp.processes.HigherOrderRandomWalk(g_ho, weight=True)\n&gt;&gt;&gt; data = rw.run_experiment(steps=10, runs=[('b','c')])\n&gt;&gt;&gt; rw.plot(data)\n[interactive visualization in first-order network]\n</code></pre> <p>Use <code>plot</code> function of base class to visualize random walk in second-order network</p> <pre><code>&gt;&gt;&gt; pp.processes.RandomWalk.plot(rw, data)\n[interactive visualization in second-order network]\n</code></pre> <p>Generate a single random walk with 10 steps starting from node 'b-c' and  return a first-order path</p> <pre><code>&gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['b-c']))\n&gt;&gt;&gt; pprint([v.uid for v in p.nodes ]) \n[ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n</code></pre> <p>Use <code>get_path</code> function of base class to return path with second-order nodes</p> <pre><code>&gt;&gt;&gt; p = pp.processes.RandomWalk.get_path(rw2, data)\n&gt;&gt;&gt; print([ v.uid for v in p.nodes ])\n</code></pre> <p>Generate one random walk with 10 steps starting from each node and  return a WalkData instance with first-order paths</p> <pre><code>&gt;&gt;&gt; paths = rw.get_paths(rw.run_experiment(steps=10, runs=g_ho.nodes))\n&gt;&gt;&gt; pprint([v.uid for v in p.nodes ]) \n[ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b'] \n[ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n[ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n[ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n</code></pre> <p>Simulate a random walk using the iterator interface, which provides full access  to the state after each simulation step</p> <pre><code>&gt;&gt;&gt; for time, _ in rw2.simulation_run(steps=50, seed='b-c'):\n&gt;&gt;&gt;     print('Current node = {0}'.format(rw2.first_order_node(rw2.current_node)))\n&gt;&gt;&gt;     print(rw2._first_order_visitation_frequencies)\nCurrent node = b\n[0.33333333 0.33333333 0.33333333 0.        ]\nCurrent node = c\n[0.32142857 0.32142857 0.35714286 0.        ]\nCurrent node = a\n[0.34482759 0.31034483 0.34482759 0.        ]\nCurrent node = b\n[0.33333333 0.33333333 0.33333333 0.        ]\nCurrent node = c\n[0.32258065 0.32258065 0.35483871 0.        ]\nCurrent node = a\n</code></pre> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>class HigherOrderRandomWalk(RandomWalk):\n    \"\"\"Class that implements a biased random walk process in a higher-order network.\n\n        Instances of this class can be used to simulate random walk processes in higher-order networks for\n        arbitrary orders k. The random walk process can include weighted edges as well as a \n        restart probability, i.e. a per-step probability to teleport to a\n        randomly chosen higher-order node.\n\n        Different from the class RandomWalk, instances of class HigherOrderRandomWalk automatically project states to the corresponding first-order network, i.e. paths and visualisations are given \n        in terms of the nodes in the first-order network, while the dynamics of the random walk is governed by the underlying higher-order network.\n\n        The implementation follows the general concept to simulate discrete-time (stochastic) processes\n        as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface\n        to iterate through the steps of a single random walk process, or use the `run_experiment` function\n        to simulate multiple runs of a random walk with different start nodes (i.e. seeds).\n\n        The `run_experiment` function returns a pandas DataFrame object that contains all node state changes \n        during the process' evolution. This data frame can be converted to Path and PathCollection objects \n        and it can be visualized using the plot function.\n\n        Examples:\n            Generate and visualize a single random walk with 10 steps on a higher-order network\n\n            &gt;&gt;&gt; import pathpy as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n            &gt;&gt;&gt; paths = pp.WalkData(g3.mapping)\n            &gt;&gt;&gt; paths.add_walk_seq(['a','b','c'],freq=1)\n            &gt;&gt;&gt; paths.add_walk_seq(['b','c','a'],freq=1)\n            &gt;&gt;&gt; paths.add_walk_seq(['b','c','d'],freq=0.2)\n            &gt;&gt;&gt; paths.add_walk_seq(['c','a','b'],freq=1)\n            &gt;&gt;&gt; paths.add_walk_seq(['c','d','a'],freq=0.2)\n            &gt;&gt;&gt; paths.add_walk_seq(['d','a','b'],freq=1)\n            &gt;&gt;&gt; g_ho = pp.HigherOrderGraph(paths, order =2)\n\n            &gt;&gt;&gt; rw = pp.processes.HigherOrderRandomWalk(g_ho, weight=True)\n            &gt;&gt;&gt; data = rw.run_experiment(steps=10, runs=[('b','c')])\n            &gt;&gt;&gt; rw.plot(data)\n            [interactive visualization in first-order network]\n\n            Use `plot` function of base class to visualize random walk in second-order network\n\n            &gt;&gt;&gt; pp.processes.RandomWalk.plot(rw, data)\n            [interactive visualization in second-order network]\n\n            Generate a single random walk with 10 steps starting from node 'b-c' and \n            return a first-order path\n\n            &gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['b-c']))\n            &gt;&gt;&gt; pprint([v.uid for v in p.nodes ]) \n            [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n\n            Use `get_path` function of base class to return path with second-order nodes\n\n            &gt;&gt;&gt; p = pp.processes.RandomWalk.get_path(rw2, data)\n            &gt;&gt;&gt; print([ v.uid for v in p.nodes ])\n\n            Generate one random walk with 10 steps starting from each node and \n            return a WalkData instance with first-order paths\n\n            &gt;&gt;&gt; paths = rw.get_paths(rw.run_experiment(steps=10, runs=g_ho.nodes))\n            &gt;&gt;&gt; pprint([v.uid for v in p.nodes ]) \n            [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b'] \n            [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n            [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n            [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n\n            Simulate a random walk using the iterator interface, which provides full access \n            to the state after each simulation step\n\n            &gt;&gt;&gt; for time, _ in rw2.simulation_run(steps=50, seed='b-c'):\n            &gt;&gt;&gt;     print('Current node = {0}'.format(rw2.first_order_node(rw2.current_node)))\n            &gt;&gt;&gt;     print(rw2._first_order_visitation_frequencies)\n            Current node = b\n            [0.33333333 0.33333333 0.33333333 0.        ]\n            Current node = c\n            [0.32142857 0.32142857 0.35714286 0.        ]\n            Current node = a\n            [0.34482759 0.31034483 0.34482759 0.        ]\n            Current node = b\n            [0.33333333 0.33333333 0.33333333 0.        ]\n            Current node = c\n            [0.32258065 0.32258065 0.35483871 0.        ]\n            Current node = a\n    \"\"\"\n\n    def __init__(self, higher_order_network: Graph, first_order_network, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n        \"\"\"Creates a biased random walk process in a network.\n\n            Args:\n                higher_order_network: The higher-order network instance on which to perform the random walk process.\n                first_order_network: The first-order network instance to be used for mapping the process to first-order nodes\n                weight: If specified, the given numerical edge attribute will be used to bias\n                    the random walk transition probabilities.\n                restart_probability: The per-step probability that a random walker restarts in a random (higher-order) node\n        \"\"\"\n        self._first_order_network = first_order_network\n        RandomWalk.__init__(self, higher_order_network, weight, restart_prob)\n\n    def init(self, seed) -&gt; None:\n\n        # set number of times each first-order node has been visited\n        self._first_order_visitations = np.ravel(\n            np.zeros(shape=(1, self._first_order_network.N)))\n        self._first_order_visitations[self._first_order_network.mapping.to_idx(seed[-1])] = 1\n        RandomWalk.init(self, seed)\n\n    @property\n    def first_order_visitation_frequencies(self) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n        the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n        \"\"\"\n        return np.nan_to_num(self._first_order_visitations/(self._t+1))\n\n    def first_order_stationary_state(self, **kwargs) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n        the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n        \"\"\"\n        first_order_stationary_state = np.ravel(\n            np.zeros(shape=(1, self._first_order_network.N)))\n        higher_order_stationary_dist = RandomWalk.stationary_state(\n            self, **kwargs)\n        for v in self._network.nodes:\n            # newly visited node in first_order network\n            v1 = v.relations[-1]\n            first_order_stationary_state[self._first_order_network.mapping.to_idx[v1]\n                                         ] += higher_order_stationary_dist[self._network.mapping.to_idx[v]]\n        return first_order_stationary_state\n\n    @property\n    def first_order_total_variation_distance(self) -&gt; float:\n        \"\"\"Returns the total variation distance between stationary \n        visitation probabilities and the current visitation frequencies, projected\n        to nodes in the first_order_network.\n\n        Computes the total variation distance between the current (first-order) node visitation\n        probabilities and the (first-order) stationary node visitation probabilities. This quantity converges to zero for HigherOrderRandomWalk.time -&gt; np.infty and its magnitude indicates the\n        current relaxation of the higher-order random walk process.\n        \"\"\"\n        return self.TVD(self.first_order_stationary_state(), self.first_order_visitation_frequencies)\n\n    def first_order_node(self, higher_order_node: tuple) -&gt; str:\n        \"\"\"\n        Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.\n\n        Args:\n            higher_order_node: Tuple that represents the higher-order node \n\n        Returns:\n            String of the corresponding first-order node\n        \"\"\"\n        return higher_order_node[-1]\n\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"\n        Function that will be called for each step of the random walk. This function \n        returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.\n\n        Use the `first_order_node` function to map those nodes to nodes in the first-order network\n        \"\"\"\n        (current_node, previous_node) = RandomWalk.step(self)\n\n        self._first_order_visitations[self._first_order_network.mapping.to_idx(current_node[-1])] += 1\n\n        return (current_node, previous_node)\n\n\n    def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = 0) -&gt; PathData:\n        \"\"\"Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.\n\n        Args:\n            data: Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n            run_uid: Uid of the random walk simulations to be returned as WalkData (default: 0).\n\n        Returns:\n            WalkData object containing the sequences of nodes traversed by the random walks\n        \"\"\"\n        # list of traversed nodes starting with seed node\n\n        if not run_ids:  # generate paths for all run_ids in the data frame\n            runs = data['run_id'].unique()\n        else:\n            runs = run_ids\n\n        paths = PathData(mapping = self._first_order_network.mapping)\n        for run in runs:\n            walk_steps = list(data.loc[(data['run_id'] == run) &amp; (\n                data['state'] == True)]['node'].values)\n\n            # for higher-order random walk, seed node is a higher-order node\n            # consisting of one or more edges\n            seed = walk_steps[0]\n            walk = [v for v in seed]\n\n            # map higher-order nodes to first-order nodes\n            for i in range(1, len(walk_steps)):\n                walk.append(walk_steps[i][-1])\n            paths.append_walk(walk)\n        return paths\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_total_variation_distance","title":"<code>first_order_total_variation_distance: float</code>  <code>property</code>","text":"<p>Returns the total variation distance between stationary  visitation probabilities and the current visitation frequencies, projected to nodes in the first_order_network.</p> <p>Computes the total variation distance between the current (first-order) node visitation probabilities and the (first-order) stationary node visitation probabilities. This quantity converges to zero for HigherOrderRandomWalk.time -&gt; np.infty and its magnitude indicates the current relaxation of the higher-order random walk process.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_visitation_frequencies","title":"<code>first_order_visitation_frequencies: np.array</code>  <code>property</code>","text":"<p>Returns current normalized visitation frequencies of first-order nodes based on the history of the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.__init__","title":"<code>__init__</code>","text":"<p>Creates a biased random walk process in a network.</p> <p>Parameters:</p> Name Type Description Default <code>higher_order_network</code> <code>pathpyG.Graph</code> <p>The higher-order network instance on which to perform the random walk process.</p> required <code>first_order_network</code> <p>The first-order network instance to be used for mapping the process to first-order nodes</p> required <code>weight</code> <code>typing.Optional[pathpyG.processes.random_walk.Weight]</code> <p>If specified, the given numerical edge attribute will be used to bias the random walk transition probabilities.</p> <code>None</code> <code>restart_probability</code> <p>The per-step probability that a random walker restarts in a random (higher-order) node</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def __init__(self, higher_order_network: Graph, first_order_network, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n    \"\"\"Creates a biased random walk process in a network.\n\n        Args:\n            higher_order_network: The higher-order network instance on which to perform the random walk process.\n            first_order_network: The first-order network instance to be used for mapping the process to first-order nodes\n            weight: If specified, the given numerical edge attribute will be used to bias\n                the random walk transition probabilities.\n            restart_probability: The per-step probability that a random walker restarts in a random (higher-order) node\n    \"\"\"\n    self._first_order_network = first_order_network\n    RandomWalk.__init__(self, higher_order_network, weight, restart_prob)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_node","title":"<code>first_order_node</code>","text":"<p>Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.</p> <p>Parameters:</p> Name Type Description Default <code>higher_order_node</code> <code>tuple</code> <p>Tuple that represents the higher-order node </p> required <p>Returns:</p> Type Description <code>str</code> <p>String of the corresponding first-order node</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def first_order_node(self, higher_order_node: tuple) -&gt; str:\n    \"\"\"\n    Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.\n\n    Args:\n        higher_order_node: Tuple that represents the higher-order node \n\n    Returns:\n        String of the corresponding first-order node\n    \"\"\"\n    return higher_order_node[-1]\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_stationary_state","title":"<code>first_order_stationary_state</code>","text":"<p>Returns current normalized visitation frequencies of first-order nodes based on the history of the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def first_order_stationary_state(self, **kwargs) -&gt; np.array:\n    \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n    the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n    \"\"\"\n    first_order_stationary_state = np.ravel(\n        np.zeros(shape=(1, self._first_order_network.N)))\n    higher_order_stationary_dist = RandomWalk.stationary_state(\n        self, **kwargs)\n    for v in self._network.nodes:\n        # newly visited node in first_order network\n        v1 = v.relations[-1]\n        first_order_stationary_state[self._first_order_network.mapping.to_idx[v1]\n                                     ] += higher_order_stationary_dist[self._network.mapping.to_idx[v]]\n    return first_order_stationary_state\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.get_paths","title":"<code>get_paths</code>","text":"<p>Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pandas.DataFrame</code> <p>Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of <code>run_experiment</code></p> required <code>run_uid</code> <p>Uid of the random walk simulations to be returned as WalkData (default: 0).</p> required <p>Returns:</p> Type Description <code>pathpyG.PathData</code> <p>WalkData object containing the sequences of nodes traversed by the random walks</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = 0) -&gt; PathData:\n    \"\"\"Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.\n\n    Args:\n        data: Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n        run_uid: Uid of the random walk simulations to be returned as WalkData (default: 0).\n\n    Returns:\n        WalkData object containing the sequences of nodes traversed by the random walks\n    \"\"\"\n    # list of traversed nodes starting with seed node\n\n    if not run_ids:  # generate paths for all run_ids in the data frame\n        runs = data['run_id'].unique()\n    else:\n        runs = run_ids\n\n    paths = PathData(mapping = self._first_order_network.mapping)\n    for run in runs:\n        walk_steps = list(data.loc[(data['run_id'] == run) &amp; (\n            data['state'] == True)]['node'].values)\n\n        # for higher-order random walk, seed node is a higher-order node\n        # consisting of one or more edges\n        seed = walk_steps[0]\n        walk = [v for v in seed]\n\n        # map higher-order nodes to first-order nodes\n        for i in range(1, len(walk_steps)):\n            walk.append(walk_steps[i][-1])\n        paths.append_walk(walk)\n    return paths\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.step","title":"<code>step</code>","text":"<p>Function that will be called for each step of the random walk. This function  returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.</p> <p>Use the <code>first_order_node</code> function to map those nodes to nodes in the first-order network</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def step(self) -&gt; Iterable[str]:\n    \"\"\"\n    Function that will be called for each step of the random walk. This function \n    returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.\n\n    Use the `first_order_node` function to map those nodes to nodes in the first-order network\n    \"\"\"\n    (current_node, previous_node) = RandomWalk.step(self)\n\n    self._first_order_visitations[self._first_order_network.mapping.to_idx(current_node[-1])] += 1\n\n    return (current_node, previous_node)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk","title":"<code>RandomWalk</code>","text":"<p>               Bases: <code>pathpyG.processes.process.BaseProcess</code></p> <p>Class that implements a biased random walk process in a network.</p> <p>Instances of this class can be used to simulate random walk processes in any instance of the class Graph. The random walk process can include weighted edges as well as a  restart probability, i.e. a per-step probability to teleport to a randomly chosen node.</p> <p>Since any instance of HigherOrderGraph is also an instance of Graph, this class can be directly be applied to simulate random walks in higher-order networks. However,  the state space of such a random walk is given by the higher-order nodes. If you wish to simulate a higher-order random walk while projecting states to the corresponding first-order  network, you should use the class HigherOrderRandomWalk instead.</p> <p>The implementation follows the general concept to simulate discrete-time (stochastic) processes as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface to iterate through the steps of a single random walk process, or use the <code>run_experiment</code> function to simulate multiple runs of a random walk with different start nodes (i.e. seeds).</p> <p>The <code>run_experiment</code> function returns a pandas DataFrame object that contains all node state changes  during the process' evolution. This data frame can be converted to Path and PathCollection objects  and it can be visualized using the plot function.</p> <p>Examples:</p> <p>Generate and visualize a single biased random walk with 10 steps on a network</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n&gt;&gt;&gt; rw = pp.processes.RandomWalk(g, weight='edge_weight')\n&gt;&gt;&gt; data = rw.run_experiment(steps=10, seed='a')\n&gt;&gt;&gt; rw.plot(data)\n[interactive visualization]\n</code></pre> <p>Generate a single random walk with 10 steps starting from node 'a' and  return a WalkData instance</p> <pre><code>&gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['a']))\n</code></pre> <p>Generate one random walk with 10 steps starting from each node and  return a PathCollection instance</p> <pre><code>&gt;&gt;&gt; pc = rw.get_paths(rw.run_experiment(steps=10, runs=g.nodes))\n[ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b'] \n[ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n[ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n[ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n</code></pre> <p>Simulate a random walk using the iterator interface, which provides full access  to the state after each simulation step</p> <pre><code>&gt;&gt;&gt; for time, _ in rw.simulation_run(steps=5, seed='a'):\n&gt;&gt;&gt;     print('Current node = {0}'.format(rw.current_node))\n&gt;&gt;&gt;     print(rw.visitation_frequencies)\nCurrent node = b\n[0.5 0.5 0.  0. ]\nCurrent node = c\n[0.33333333 0.33333333 0.33333333 0. ]\nCurrent node = d\n[0.25 0.25 0.25 0.25]\nCurrent node = a\n[0.4 0.2 0.2 0.2]\nCurrent node = b\n[0.33333333 0.33333333 0.16666667 0.16666667]\nCurrent node = a\n[0.42857143 0.28571429 0.14285714 0.14285714]\nCurrent node = c\n[0.375 0.25  0.25  0.125]\nCurrent node = a\n[0.44444444 0.22222222 0.22222222 0.11111111]\nCurrent node = b\n[0.4 0.3 0.2 0.1]\nCurrent node = a\n[0.45454545 0.27272727 0.18181818 0.09090909]\n</code></pre> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>class RandomWalk(BaseProcess):\n    \"\"\"Class that implements a biased random walk process in a network.\n\n    Instances of this class can be used to simulate random walk processes in any instance\n    of the class Graph. The random walk process can include weighted edges as well as a \n    restart probability, i.e. a per-step probability to teleport to a\n    randomly chosen node.\n\n    Since any instance of HigherOrderGraph is also an instance of Graph, this class\n    can be directly be applied to simulate random walks in higher-order networks. However, \n    the state space of such a random walk is given by the higher-order nodes. If you wish to\n    simulate a higher-order random walk while projecting states to the corresponding first-order \n    network, you should use the class HigherOrderRandomWalk instead.\n\n    The implementation follows the general concept to simulate discrete-time (stochastic) processes\n    as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface\n    to iterate through the steps of a single random walk process, or use the `run_experiment` function\n    to simulate multiple runs of a random walk with different start nodes (i.e. seeds).\n\n    The `run_experiment` function returns a pandas DataFrame object that contains all node state changes \n    during the process' evolution. This data frame can be converted to Path and PathCollection objects \n    and it can be visualized using the plot function.\n\n    Examples:\n        Generate and visualize a single biased random walk with 10 steps on a network\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n        &gt;&gt;&gt; rw = pp.processes.RandomWalk(g, weight='edge_weight')\n        &gt;&gt;&gt; data = rw.run_experiment(steps=10, seed='a')\n        &gt;&gt;&gt; rw.plot(data)\n        [interactive visualization]\n\n        Generate a single random walk with 10 steps starting from node 'a' and \n        return a WalkData instance\n\n        &gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['a']))\n\n        Generate one random walk with 10 steps starting from each node and \n        return a PathCollection instance\n\n        &gt;&gt;&gt; pc = rw.get_paths(rw.run_experiment(steps=10, runs=g.nodes))\n        [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b'] \n        [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n        [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n        [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n\n        Simulate a random walk using the iterator interface, which provides full access \n        to the state after each simulation step\n\n        &gt;&gt;&gt; for time, _ in rw.simulation_run(steps=5, seed='a'):\n        &gt;&gt;&gt;     print('Current node = {0}'.format(rw.current_node))\n        &gt;&gt;&gt;     print(rw.visitation_frequencies)\n        Current node = b\n        [0.5 0.5 0.  0. ]\n        Current node = c\n        [0.33333333 0.33333333 0.33333333 0. ]\n        Current node = d\n        [0.25 0.25 0.25 0.25]\n        Current node = a\n        [0.4 0.2 0.2 0.2]\n        Current node = b\n        [0.33333333 0.33333333 0.16666667 0.16666667]\n        Current node = a\n        [0.42857143 0.28571429 0.14285714 0.14285714]\n        Current node = c\n        [0.375 0.25  0.25  0.125]\n        Current node = a\n        [0.44444444 0.22222222 0.22222222 0.11111111]\n        Current node = b\n        [0.4 0.3 0.2 0.1]\n        Current node = a\n        [0.45454545 0.27272727 0.18181818 0.09090909]\n    \"\"\"\n\n    def __init__(self, network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n        \"\"\"Creates a biased random walk process in a network.\n\n        Args:\n            network: The network instance on which to perform the random walk process. Can also \n                be an instance of HigherOrderNetwork.\n            weight: If specified, the given numerical edge attribute will be used to bias\n                the random walk transition probabilities.\n            restart_probability: The per-step probability that a random walker restarts in a random node\n        \"\"\"\n\n        # transition matrix of random walk\n        self._transition_matrix = RandomWalk.compute_transition_matrix(\n            network, weight, restart_prob)\n\n        # initialize Vose Alias Samplers\n\n        self.samplers = {v: VoseAliasSampling(np.nan_to_num(np.ravel(\n            self._transition_matrix[\n                network.mapping.to_idx(v), :].todense()))) for v in network.nodes}\n\n        # compute eigenvectors and eigenvalues of transition matrix\n        if network.N &gt; 2:\n            _, eigenvectors = spl.eigs(\n                self._transition_matrix.transpose(), k=1, which='LM')\n            pi = eigenvectors.reshape(eigenvectors.size, )\n        else:\n            eigenvals, eigenvectors = spla.eig(\n                self._transition_matrix.transpose().toarray())\n            x = np.argsort(-eigenvals)\n            pi = eigenvectors[x][:, 0]\n\n        # calculate stationary visitation probabilities\n        self._stationary_probabilities = np.real(pi/np.sum(pi))\n\n        self._network = network\n        self.init(self.random_seed())\n\n    def init(self, seed: str) -&gt; None:\n        \"\"\"\n        Initializes the random walk state with a given seed/source node\n\n        Args:\n            seed: Id of node in which the random walk will start\n        \"\"\"\n        # reset currently visited node (or higher-order node)\n        self._current_node = seed\n\n        # set time\n        self._t = 0\n\n        # set number of times each node has been visited\n        self._visitations = np.ravel(\n            np.zeros(shape=(1, self._network.N)))\n        self._visitations[self._network.mapping.to_idx(seed)] = 1\n\n    def random_seed(self) -&gt; Any:\n        \"\"\"\n        Returns a random node from the network, chosen uniformly at random\n        \"\"\"\n        x = np.random.choice(range(self._network.N))\n        return self._network.mapping.to_id(x)\n\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"\n        Function that will be called for each step of the random walk. This function \n        returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.\n        \"\"\"\n\n        # determine next node\n        next_node = self.network.mapping.to_id(self.samplers[self._current_node].sample(\n        ))\n        # TODO: assertion will not hold if restart_prob &gt; 0\n        # assert (self._current_node, next_node) in self._network.edges, 'Assertion Error: {0} not in edge list'.format(\n        #     (self._current_node, next_node))\n\n        previous_node = self._current_node\n        self._current_node = next_node\n\n        # increment visitations and current time\n        self._visitations[self._network.mapping.to_idx(self._current_node)] += 1\n        self._t += 1\n\n        # return tuple of changed nodes, where the first node is the currently visited node\n        return (self._current_node, previous_node)\n\n    def node_state(self, v) -&gt; bool:\n        \"\"\"\n        Returns a boolean variable indicating whether the walker is currently \n        visiting (first-order) node v\n        \"\"\"\n        if v in self._network.nodes:\n            return v == self._current_node\n        # TODO: Error here!\n        elif type(self._network) == HigherOrderGraph:\n            return v == self._network.mapping.to_id(self._current_node)[-1]\n        else:\n            raise NotImplementedError(\n                'Random walk not implemented for network of type {0}'.format(type(self._network)))\n\n    @property\n    def time(self) -&gt; int:\n        \"\"\"\n        The current time of the random walk process, i.e. the number of steps taken since the start node.\n        \"\"\"\n        return self._t\n\n    def state_to_color(self, state: bool) -&gt; str:\n        \"\"\"\n        Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.\n\n        Args: \n            state: Current visitation state\n        \"\"\"\n        if state:\n            return 'red'\n        else:\n            return 'blue'\n\n    @staticmethod\n    def compute_transition_matrix(network: Graph,\n                                  weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; sp.sparse.csr_matrix:\n        \"\"\"Returns the transition matrix of a (biased) random walk in the given network.\n\n        Returns a transition matrix that describes a random walk process in the\n        given network.\n\n        Args:\n            network: The network for which the transition matrix will be created.\n            weight: If specified, the numerical edge attribute that shall be used in the biased\n                transition probabilities of the random walk.\n\n        \"\"\"\n        if weight is None or weight is False:\n            A = network.get_sparse_adj_matrix().todense()\n        elif weight is True:\n            A = network.get_sparse_adj_matrix(edge_attr='edge_weight').todense()\n        else:\n            A = network.get_sparse_adj_matrix(edge_attr=weight).todense()\n        D = A.sum(axis=1)\n        n = network.N\n        T = sp.sparse.lil_matrix((n, n))\n        zero_deg = 0\n        for i in range(n):\n            if D[i] == 0:\n                zero_deg += 1\n            for j in range(n):\n                if D[i] &gt; 0:\n                    T[i, j] = restart_prob * \\\n                        (1./n) + (1-restart_prob)*A[i, j]/D[i]\n                else:\n                    if restart_prob &gt; 0:\n                        T[i, j] = 1./n\n                    else:\n                        T[i, j] = 0.0\n        # if zero_deg &gt; 0:\n        #     LOG.warning(\n        #         'Network contains {0} nodes with zero out-degree'.format(zero_deg))\n        return T.tocsr()\n\n    @property\n    def transition_matrix(self) -&gt; sp.sparse.csr_matrix:\n        \"\"\"Returns the transition matrix of the random walk\n        \"\"\"\n        return self._transition_matrix\n\n    def transition_probabilities(self, node: str) -&gt; np.array:\n        \"\"\"Returns a vector that contains transition probabilities.\n\n        Returns a vector that contains transition probabilities from a given\n        node to all other nodes in the network.\n        \"\"\"\n        return np.nan_to_num(np.ravel(\n            self._transition_matrix[\n                self._network.mapping.to_idx(node), :].todense()))\n\n    def visitation_probabilities(self, t, seed: str) -&gt; np.ndarray:\n        \"\"\"Calculates visitation probabilities of nodes after t steps for a given start node\n\n        Initially, all visitation probabilities are zero except for the start node.\n        \"\"\"\n        assert seed in self._network.nodes\n\n        initial_dist = np.zeros(self._network.N)\n        initial_dist[self._network.mapping.to_idx(seed)] = 1.0\n        return np.dot(initial_dist, (self._transition_matrix**t).todense())\n\n    def transition_matrix_pd(self) -&gt; DataFrame:\n        \"\"\"\n        Returns the transition matrix as pandas DataFrame with proper row/column labels.\n        \"\"\"\n        return DataFrame(self.transition_matrix.todense(), columns=[v for v in self._network.nodes], index=[v for v in self._network.nodes])\n\n    @property\n    def current_node(self) -&gt; str:\n        return self._current_node\n\n    def get_path(self, data: DataFrame, run_id: Optional[int] = 0, first_order: Optional[bool] = True) -&gt; PathData:\n        \"\"\"Returns a path that represents the sequence of (first-order) nodes traversed\n        by a single random walk.\n\n        Args:\n            data: Pandas `DataFrame` containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n            run_uid: Uid of the random walk simulation to be returns as Path (default: 0).\n\n        Returns:\n            Path object containing the sequence of nodes traversed by the random walk\n        \"\"\"\n        # list of traversed nodes starting with seed node\n        walk_steps = list(data.loc[(data['run_id'] == run_id) &amp; (\n            data['state'] == True)]['node'].values)\n\n        # generate Path\n        path = PathData(self._network.mapping)\n        path.append_walk([walk_steps[i] for i in range(len(walk_steps))])\n        return path\n\n    def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = None) -&gt; PathData:\n        \"\"\"Return a PathData object where each path is one random walk trajectory\n\n        Args:\n            data: Pandas `DataFrame` containing the trajectory of one or more random walks, generated by `run_experiment`\n            run_ids: UIDs of random walk simulation runs to be included in the `PathData`. If None (default), all runs will be included.\n        \"\"\"\n\n        if not run_ids:  # generate paths for all run_ids in the data frame\n            runs = data['run_id'].unique()\n        else:\n            runs = run_ids\n\n        walks = PathData(self._network.mapping)\n        for id in runs:\n            walk_steps = list(data.loc[(data['run_id'] == id) &amp; (\n            data['state'] == True)]['node'].values)\n\n            # add walk to PathData\n            walks.append_walk(walk_steps)\n\n        return walks\n\n    def stationary_state(self, **kwargs: Any) -&gt; np.array:\n        \"\"\"Compute stationary visitation probabilities of random walk.\n\n        Computes stationary visitation probabilities of nodes based on the\n        leading eigenvector of the transition matrix.\n\n        Args:\n            kwargs: Arbitrary key-value pairs to bee passed to the\n            scipy.sparse.linalg.eigs function.\n        \"\"\"\n        _p = self._stationary_probabilities\n        if kwargs:\n            _, eigenvectors = sp.sparse.linalg.eigs(\n                self._transition_matrix.transpose(), k=1, which='LM', **kwargs)\n            pi = eigenvectors.reshape(eigenvectors.size, )\n            _p = np.real(pi/np.sum(pi))\n        return _p\n\n    @property\n    def visitation_frequencies(self) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of nodes based on the history of\n        the random walk. Initially, all visitation probabilities are zero except for the start node.\n        \"\"\"\n        return np.nan_to_num(self._visitations/(self._t+1))\n\n    @property\n    def total_variation_distance(self) -&gt; float:\n        \"\"\"Returns the total variation distance between stationary \n        visitation probabilities and the current visitation frequencies\n\n        Computes the total variation distance between the current visitation\n        probabilities and the stationary probabilities. This quantity converges\n        to zero for RandomWalk.t -&gt; np.infty and its magnitude indicates the\n        current relaxation of the random walk process.\n        \"\"\"\n        return self.TVD(self.stationary_state(), self.visitation_frequencies)\n\n    @staticmethod\n    def TVD(a: np.array, b: np.array) -&gt; float:\n        \"\"\"Calculates the total variation distance between two probability vectors\n        \"\"\"\n        return np.abs(a - b).sum()/2.0\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.time","title":"<code>time: int</code>  <code>property</code>","text":"<p>The current time of the random walk process, i.e. the number of steps taken since the start node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.total_variation_distance","title":"<code>total_variation_distance: float</code>  <code>property</code>","text":"<p>Returns the total variation distance between stationary  visitation probabilities and the current visitation frequencies</p> <p>Computes the total variation distance between the current visitation probabilities and the stationary probabilities. This quantity converges to zero for RandomWalk.t -&gt; np.infty and its magnitude indicates the current relaxation of the random walk process.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_matrix","title":"<code>transition_matrix: sp.sparse.csr_matrix</code>  <code>property</code>","text":"<p>Returns the transition matrix of the random walk</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.visitation_frequencies","title":"<code>visitation_frequencies: np.array</code>  <code>property</code>","text":"<p>Returns current normalized visitation frequencies of nodes based on the history of the random walk. Initially, all visitation probabilities are zero except for the start node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.TVD","title":"<code>TVD</code>  <code>staticmethod</code>","text":"<p>Calculates the total variation distance between two probability vectors</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>@staticmethod\ndef TVD(a: np.array, b: np.array) -&gt; float:\n    \"\"\"Calculates the total variation distance between two probability vectors\n    \"\"\"\n    return np.abs(a - b).sum()/2.0\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.__init__","title":"<code>__init__</code>","text":"<p>Creates a biased random walk process in a network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.Graph</code> <p>The network instance on which to perform the random walk process. Can also  be an instance of HigherOrderNetwork.</p> required <code>weight</code> <code>typing.Optional[pathpyG.processes.random_walk.Weight]</code> <p>If specified, the given numerical edge attribute will be used to bias the random walk transition probabilities.</p> <code>None</code> <code>restart_probability</code> <p>The per-step probability that a random walker restarts in a random node</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def __init__(self, network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n    \"\"\"Creates a biased random walk process in a network.\n\n    Args:\n        network: The network instance on which to perform the random walk process. Can also \n            be an instance of HigherOrderNetwork.\n        weight: If specified, the given numerical edge attribute will be used to bias\n            the random walk transition probabilities.\n        restart_probability: The per-step probability that a random walker restarts in a random node\n    \"\"\"\n\n    # transition matrix of random walk\n    self._transition_matrix = RandomWalk.compute_transition_matrix(\n        network, weight, restart_prob)\n\n    # initialize Vose Alias Samplers\n\n    self.samplers = {v: VoseAliasSampling(np.nan_to_num(np.ravel(\n        self._transition_matrix[\n            network.mapping.to_idx(v), :].todense()))) for v in network.nodes}\n\n    # compute eigenvectors and eigenvalues of transition matrix\n    if network.N &gt; 2:\n        _, eigenvectors = spl.eigs(\n            self._transition_matrix.transpose(), k=1, which='LM')\n        pi = eigenvectors.reshape(eigenvectors.size, )\n    else:\n        eigenvals, eigenvectors = spla.eig(\n            self._transition_matrix.transpose().toarray())\n        x = np.argsort(-eigenvals)\n        pi = eigenvectors[x][:, 0]\n\n    # calculate stationary visitation probabilities\n    self._stationary_probabilities = np.real(pi/np.sum(pi))\n\n    self._network = network\n    self.init(self.random_seed())\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.compute_transition_matrix","title":"<code>compute_transition_matrix</code>  <code>staticmethod</code>","text":"<p>Returns the transition matrix of a (biased) random walk in the given network.</p> <p>Returns a transition matrix that describes a random walk process in the given network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.Graph</code> <p>The network for which the transition matrix will be created.</p> required <code>weight</code> <code>typing.Optional[pathpyG.processes.random_walk.Weight]</code> <p>If specified, the numerical edge attribute that shall be used in the biased transition probabilities of the random walk.</p> <code>None</code> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>@staticmethod\ndef compute_transition_matrix(network: Graph,\n                              weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; sp.sparse.csr_matrix:\n    \"\"\"Returns the transition matrix of a (biased) random walk in the given network.\n\n    Returns a transition matrix that describes a random walk process in the\n    given network.\n\n    Args:\n        network: The network for which the transition matrix will be created.\n        weight: If specified, the numerical edge attribute that shall be used in the biased\n            transition probabilities of the random walk.\n\n    \"\"\"\n    if weight is None or weight is False:\n        A = network.get_sparse_adj_matrix().todense()\n    elif weight is True:\n        A = network.get_sparse_adj_matrix(edge_attr='edge_weight').todense()\n    else:\n        A = network.get_sparse_adj_matrix(edge_attr=weight).todense()\n    D = A.sum(axis=1)\n    n = network.N\n    T = sp.sparse.lil_matrix((n, n))\n    zero_deg = 0\n    for i in range(n):\n        if D[i] == 0:\n            zero_deg += 1\n        for j in range(n):\n            if D[i] &gt; 0:\n                T[i, j] = restart_prob * \\\n                    (1./n) + (1-restart_prob)*A[i, j]/D[i]\n            else:\n                if restart_prob &gt; 0:\n                    T[i, j] = 1./n\n                else:\n                    T[i, j] = 0.0\n    # if zero_deg &gt; 0:\n    #     LOG.warning(\n    #         'Network contains {0} nodes with zero out-degree'.format(zero_deg))\n    return T.tocsr()\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_path","title":"<code>get_path</code>","text":"<p>Returns a path that represents the sequence of (first-order) nodes traversed by a single random walk.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pandas.DataFrame</code> <p>Pandas <code>DataFrame</code> containing the trajectory of one or more (higher-order) random walks, generated by a call of <code>run_experiment</code></p> required <code>run_uid</code> <p>Uid of the random walk simulation to be returns as Path (default: 0).</p> required <p>Returns:</p> Type Description <code>pathpyG.PathData</code> <p>Path object containing the sequence of nodes traversed by the random walk</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_path(self, data: DataFrame, run_id: Optional[int] = 0, first_order: Optional[bool] = True) -&gt; PathData:\n    \"\"\"Returns a path that represents the sequence of (first-order) nodes traversed\n    by a single random walk.\n\n    Args:\n        data: Pandas `DataFrame` containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n        run_uid: Uid of the random walk simulation to be returns as Path (default: 0).\n\n    Returns:\n        Path object containing the sequence of nodes traversed by the random walk\n    \"\"\"\n    # list of traversed nodes starting with seed node\n    walk_steps = list(data.loc[(data['run_id'] == run_id) &amp; (\n        data['state'] == True)]['node'].values)\n\n    # generate Path\n    path = PathData(self._network.mapping)\n    path.append_walk([walk_steps[i] for i in range(len(walk_steps))])\n    return path\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_paths","title":"<code>get_paths</code>","text":"<p>Return a PathData object where each path is one random walk trajectory</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pandas.DataFrame</code> <p>Pandas <code>DataFrame</code> containing the trajectory of one or more random walks, generated by <code>run_experiment</code></p> required <code>run_ids</code> <code>typing.Optional[typing.Iterable]</code> <p>UIDs of random walk simulation runs to be included in the <code>PathData</code>. If None (default), all runs will be included.</p> <code>None</code> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = None) -&gt; PathData:\n    \"\"\"Return a PathData object where each path is one random walk trajectory\n\n    Args:\n        data: Pandas `DataFrame` containing the trajectory of one or more random walks, generated by `run_experiment`\n        run_ids: UIDs of random walk simulation runs to be included in the `PathData`. If None (default), all runs will be included.\n    \"\"\"\n\n    if not run_ids:  # generate paths for all run_ids in the data frame\n        runs = data['run_id'].unique()\n    else:\n        runs = run_ids\n\n    walks = PathData(self._network.mapping)\n    for id in runs:\n        walk_steps = list(data.loc[(data['run_id'] == id) &amp; (\n        data['state'] == True)]['node'].values)\n\n        # add walk to PathData\n        walks.append_walk(walk_steps)\n\n    return walks\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.init","title":"<code>init</code>","text":"<p>Initializes the random walk state with a given seed/source node</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>str</code> <p>Id of node in which the random walk will start</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def init(self, seed: str) -&gt; None:\n    \"\"\"\n    Initializes the random walk state with a given seed/source node\n\n    Args:\n        seed: Id of node in which the random walk will start\n    \"\"\"\n    # reset currently visited node (or higher-order node)\n    self._current_node = seed\n\n    # set time\n    self._t = 0\n\n    # set number of times each node has been visited\n    self._visitations = np.ravel(\n        np.zeros(shape=(1, self._network.N)))\n    self._visitations[self._network.mapping.to_idx(seed)] = 1\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.node_state","title":"<code>node_state</code>","text":"<p>Returns a boolean variable indicating whether the walker is currently  visiting (first-order) node v</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def node_state(self, v) -&gt; bool:\n    \"\"\"\n    Returns a boolean variable indicating whether the walker is currently \n    visiting (first-order) node v\n    \"\"\"\n    if v in self._network.nodes:\n        return v == self._current_node\n    # TODO: Error here!\n    elif type(self._network) == HigherOrderGraph:\n        return v == self._network.mapping.to_id(self._current_node)[-1]\n    else:\n        raise NotImplementedError(\n            'Random walk not implemented for network of type {0}'.format(type(self._network)))\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.random_seed","title":"<code>random_seed</code>","text":"<p>Returns a random node from the network, chosen uniformly at random</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def random_seed(self) -&gt; Any:\n    \"\"\"\n    Returns a random node from the network, chosen uniformly at random\n    \"\"\"\n    x = np.random.choice(range(self._network.N))\n    return self._network.mapping.to_id(x)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.state_to_color","title":"<code>state_to_color</code>","text":"<p>Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>bool</code> <p>Current visitation state</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def state_to_color(self, state: bool) -&gt; str:\n    \"\"\"\n    Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.\n\n    Args: \n        state: Current visitation state\n    \"\"\"\n    if state:\n        return 'red'\n    else:\n        return 'blue'\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.stationary_state","title":"<code>stationary_state</code>","text":"<p>Compute stationary visitation probabilities of random walk.</p> <p>Computes stationary visitation probabilities of nodes based on the leading eigenvector of the transition matrix.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>typing.Any</code> <p>Arbitrary key-value pairs to bee passed to the</p> <code>{}</code> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def stationary_state(self, **kwargs: Any) -&gt; np.array:\n    \"\"\"Compute stationary visitation probabilities of random walk.\n\n    Computes stationary visitation probabilities of nodes based on the\n    leading eigenvector of the transition matrix.\n\n    Args:\n        kwargs: Arbitrary key-value pairs to bee passed to the\n        scipy.sparse.linalg.eigs function.\n    \"\"\"\n    _p = self._stationary_probabilities\n    if kwargs:\n        _, eigenvectors = sp.sparse.linalg.eigs(\n            self._transition_matrix.transpose(), k=1, which='LM', **kwargs)\n        pi = eigenvectors.reshape(eigenvectors.size, )\n        _p = np.real(pi/np.sum(pi))\n    return _p\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.step","title":"<code>step</code>","text":"<p>Function that will be called for each step of the random walk. This function  returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def step(self) -&gt; Iterable[str]:\n    \"\"\"\n    Function that will be called for each step of the random walk. This function \n    returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.\n    \"\"\"\n\n    # determine next node\n    next_node = self.network.mapping.to_id(self.samplers[self._current_node].sample(\n    ))\n    # TODO: assertion will not hold if restart_prob &gt; 0\n    # assert (self._current_node, next_node) in self._network.edges, 'Assertion Error: {0} not in edge list'.format(\n    #     (self._current_node, next_node))\n\n    previous_node = self._current_node\n    self._current_node = next_node\n\n    # increment visitations and current time\n    self._visitations[self._network.mapping.to_idx(self._current_node)] += 1\n    self._t += 1\n\n    # return tuple of changed nodes, where the first node is the currently visited node\n    return (self._current_node, previous_node)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_matrix_pd","title":"<code>transition_matrix_pd</code>","text":"<p>Returns the transition matrix as pandas DataFrame with proper row/column labels.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def transition_matrix_pd(self) -&gt; DataFrame:\n    \"\"\"\n    Returns the transition matrix as pandas DataFrame with proper row/column labels.\n    \"\"\"\n    return DataFrame(self.transition_matrix.todense(), columns=[v for v in self._network.nodes], index=[v for v in self._network.nodes])\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Returns a vector that contains transition probabilities.</p> <p>Returns a vector that contains transition probabilities from a given node to all other nodes in the network.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def transition_probabilities(self, node: str) -&gt; np.array:\n    \"\"\"Returns a vector that contains transition probabilities.\n\n    Returns a vector that contains transition probabilities from a given\n    node to all other nodes in the network.\n    \"\"\"\n    return np.nan_to_num(np.ravel(\n        self._transition_matrix[\n            self._network.mapping.to_idx(node), :].todense()))\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.visitation_probabilities","title":"<code>visitation_probabilities</code>","text":"<p>Calculates visitation probabilities of nodes after t steps for a given start node</p> <p>Initially, all visitation probabilities are zero except for the start node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def visitation_probabilities(self, t, seed: str) -&gt; np.ndarray:\n    \"\"\"Calculates visitation probabilities of nodes after t steps for a given start node\n\n    Initially, all visitation probabilities are zero except for the start node.\n    \"\"\"\n    assert seed in self._network.nodes\n\n    initial_dist = np.zeros(self._network.N)\n    initial_dist[self._network.mapping.to_idx(seed)] = 1.0\n    return np.dot(initial_dist, (self._transition_matrix**t).todense())\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/","title":"sampling","text":"<p>Classes for efficient random sampling from discrete distributions</p>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling","title":"<code>VoseAliasSampling</code>","text":"<p>Implementation of fast biased sampling of discrete values [0, ..., n]</p> <p>For a concise explanation see https://www.keithschwarz.com/darts-dice-coins/</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>typing.Union[numpy.array, list]</code> <p>relative weights of the n events, where weights[i] is the relative  statistical weight of event i. The weights do not need to be  normalized. </p> <p>For an array with length n, generated random values  will be from range(n).</p> required <p>Examples:</p> <p>Create a VoseAliasSampling instance</p> <pre><code>&gt;&gt;&gt; from pathpy.processes import VoseAliasSampling\n&gt;&gt;&gt; sampler = VoseAliasSampling([1,1,2])\n</code></pre> <p>Fast biased sampling in O(1)</p> <pre><code>&gt;&gt;&gt; [ sampler.sample() for i in range(10) ]\n[ 0 2 0 1 2 1 2 1 2 0 2 2 ]\n</code></pre> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>class VoseAliasSampling:\n    \"\"\"\n    Implementation of fast biased sampling of discrete values [0, ..., n]\n\n    For a concise explanation see https://www.keithschwarz.com/darts-dice-coins/\n\n    Args:\n        weights: relative weights of the n events, where weights[i] is the relative \n            statistical weight of event i. The weights do not need to be \n            normalized. \n\n            For an array with length n, generated random values \n            will be from range(n).\n\n    Examples:\n        Create a VoseAliasSampling instance\n\n        &gt;&gt;&gt; from pathpy.processes import VoseAliasSampling\n        &gt;&gt;&gt; sampler = VoseAliasSampling([1,1,2])\n\n        Fast biased sampling in O(1)\n\n        &gt;&gt;&gt; [ sampler.sample() for i in range(10) ]\n        [ 0 2 0 1 2 1 2 1 2 0 2 2 ] \n    \"\"\"\n\n    def __init__(self, weights: Union[np.array, list]) -&gt; None:\n        \"\"\"\n        Initializes probability and alias tables\n        \"\"\"\n        self.n = len(weights)\n        self.probs = dict()\n        self.scaled_probs = dict()\n        self.aliases = dict()\n\n        small = list()\n        large = list()\n\n        for i in range(1, self.n+1):\n            self.probs[i] = weights[i-1]\n            self.scaled_probs[i] = self.n*weights[i-1]\n            if self.scaled_probs[i]&gt;1:\n                large.append(i)\n            elif self.scaled_probs[i]&lt;=1:\n                small.append(i)\n\n        while small and large:\n            l = small.pop()\n            g = large.pop()\n\n            self.probs[l] = self.scaled_probs[l]\n            self.aliases[l] = g\n            self.scaled_probs[g] = self.scaled_probs[l] + self.scaled_probs[g] -1\n\n            if self.scaled_probs[g] &lt; 1:\n                small.append(g)\n            else:\n                large.append(g)\n        while large:\n            g = large.pop()\n            self.probs[g] = 1\n        while small:\n            l = small.pop()\n            self.probs[l] = 1\n\n    def sample(self) -&gt; int:\n        \"\"\"\n        Biased sampling of discrete value in O(1)\n\n        Returns: integer value from range(n), where n is the length \n            of the weight array used to create the instance.\n        \"\"\"\n        i = np.random.randint(1, self.n+1)\n        x = np.random.rand()\n        if x &lt; self.probs[i]:\n            return i-1\n        else:\n            return self.aliases[i]-1\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling.__init__","title":"<code>__init__</code>","text":"<p>Initializes probability and alias tables</p> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>def __init__(self, weights: Union[np.array, list]) -&gt; None:\n    \"\"\"\n    Initializes probability and alias tables\n    \"\"\"\n    self.n = len(weights)\n    self.probs = dict()\n    self.scaled_probs = dict()\n    self.aliases = dict()\n\n    small = list()\n    large = list()\n\n    for i in range(1, self.n+1):\n        self.probs[i] = weights[i-1]\n        self.scaled_probs[i] = self.n*weights[i-1]\n        if self.scaled_probs[i]&gt;1:\n            large.append(i)\n        elif self.scaled_probs[i]&lt;=1:\n            small.append(i)\n\n    while small and large:\n        l = small.pop()\n        g = large.pop()\n\n        self.probs[l] = self.scaled_probs[l]\n        self.aliases[l] = g\n        self.scaled_probs[g] = self.scaled_probs[l] + self.scaled_probs[g] -1\n\n        if self.scaled_probs[g] &lt; 1:\n            small.append(g)\n        else:\n            large.append(g)\n    while large:\n        g = large.pop()\n        self.probs[g] = 1\n    while small:\n        l = small.pop()\n        self.probs[l] = 1\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling.sample","title":"<code>sample</code>","text":"<p>Biased sampling of discrete value in O(1)</p> <p>integer value from range(n), where n is the length </p> Type Description <code>int</code> <p>of the weight array used to create the instance.</p> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>def sample(self) -&gt; int:\n    \"\"\"\n    Biased sampling of discrete value in O(1)\n\n    Returns: integer value from range(n), where n is the length \n        of the weight array used to create the instance.\n    \"\"\"\n    i = np.random.randint(1, self.n+1)\n    x = np.random.rand()\n    if x &lt; self.probs[i]:\n        return i-1\n    else:\n        return self.aliases[i]-1\n</code></pre>"},{"location":"reference/pathpyG/statistics/","title":"statistics","text":"<p>Functions to compute various graph statistics.</p> <p>The functions in this module allow to compute  various statistics on graphs</p> Example <pre><code>import pathpyG as pp\n\n# Generate a toy example graph.\ng = pp.Graph.from_edge_list([\n    ('b', 'c'),\n    ('a', 'b'),\n    ('c', 'd'),\n    ('d', 'a'),\n    ('b', 'd')\n])\n\n# Calculate degree distribution and raw moments\nd_dist = pp.statistics.degree_distribution(g)\nk_1 = pp.statistics.degree_raw_moment(g, k=1)\nk_2 = pp.statistics.degree_raw_moment(g, k=2)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as \n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if 'num_nodes' not in data:\n            data.num_nodes = data.edge_index.max().item()+1\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if data.edge_index.get_sparse_size(dim=0) != data.num_nodes or data.edge_index.get_sparse_size(dim=1) != data.num_nodes:\n            raise Exception('sparse size of EdgeIndex should match number of nodes!')\n\n        # sort EdgeIndex and validate\n        data.edge_index = data.edge_index.sort_by('row').values\n        data.edge_index.validate()\n\n        self.data = data\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i\n            for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes=None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can \n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index\n\n        Example:\n            ```py\n            import pathpyG as pp\n\n            g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            print(g)\n\n            g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                                    mapping=pp.IndexMap(['a', 'b', 'c']))\n            print(g)\n            ```\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else: \n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(\n            d,\n            mapping=mapping\n        )\n\n\n    @staticmethod\n    def from_edge_list(edge_list: Iterable[Tuple[str, str]], is_undirected: bool = False, mapping: IndexMap = None, num_nodes=None) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n        Example:\n            ```\n            import pathpyG as pp\n\n            l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            g = pp.Graph.from_edge_list(l)\n            print(g)\n            print(g.mapping)\n\n            l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            g = pp.Graph.from_edge_list(l)\n            print(g)\n            print(g.mapping)\n            ```\n        \"\"\"\n\n        if mapping is None:\n            node_ids = set()\n            for v, w in edge_list:\n                node_ids.add(v)\n                node_ids.add(w)\n            node_list = list(node_ids)\n            node_list.sort()\n            mapping = IndexMap(node_list)\n\n        sources = []\n        targets = []\n        for v, w in edge_list:\n            sources.append(mapping.to_idx(v))\n            targets.append(mapping.to_idx(w))\n\n        if num_nodes is None:\n            num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex([sources, targets], sparse_size=(num_nodes, num_nodes), is_undirected=is_undirected, device=config['torch']['device'])\n        return Graph(\n            Data(edge_index=edge_index, num_nodes=num_nodes),\n            mapping=mapping\n        )\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        tf = ToUndirected()\n        d = tf(self.data)\n        # unfortunately, the application of a transform creates a new edge_index of type tensor\n        # so we have to recreate the EdgeIndex tensor and sort it again\n\n        e = EdgeIndex(data=d.edge_index, is_undirected=True)\n        d.edge_index = e\n        return Graph(d, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\"\"\"\n        i, w = torch_geometric.utils.coalesce(self.data.edge_index, torch.ones(self.M).to(config[\"torch\"][\"device\"]))\n        return Graph(Data(edge_index=i, edge_weight=w), mapping=self.mapping)\n\n    @staticmethod\n    def attr_types(attr: Dict) -&gt; Dict:\n        \"\"\"\n        Return name, type, and size of all node, edge, and graph attributes.\n\n        This method returns a dictionary that contains the name (key), as well as\n        the type and size of all attributes.\n        \"\"\"\n        a = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                a[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                a[k] = str(t)\n        return a\n\n    def node_attrs(self) -&gt; List:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_id` attribute.\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_id\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; Generator[Union[int, str], None, None]:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a generator object that yields all nodes.\n        If an IndexMap is used, nodes\n        are returned as str IDs. If no IndexMap is used, nodes\n        are returned as integer indices.\n        \"\"\"\n        for i in range(self.N):\n            yield self.mapping.to_id(i)\n\n    @property\n    def edges(self) -&gt; Generator[Union[Tuple[int, int], Tuple[str, str]], None, None]:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a generator object that yields all edges.\n        If an IndexMap is used to map node indices to string IDs, edges\n        are returned as tuples of str IDs. If no mapping is used, edges\n        are returned as tuples of integer indices.\n        \"\"\"\n        for e in self.data.edge_index.t():\n            yield self.mapping.to_id(e[0].item()), self.mapping.to_id(e[1].item())\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([])\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n        \"\"\"        \n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([])\n\n    def successors(self, node: Union[int, str] | tuple) \\\n            -&gt; Generator[Union[int, str] | tuple, None, None]:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n        \"\"\"\n\n        for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n            yield self.mapping.to_id(j.item())\n\n    def predecessors(self, node: Union[str, int] | tuple) \\\n            -&gt; Generator[Union[int, str] | tuple, None, None]:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n        \"\"\"\n        for i in self.get_predecessors(self.mapping.to_idx(node)):  # type: ignore\n            yield self.mapping.to_id(i.item())\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID \n        \"\"\"\n        row = self.mapping.to_idx(v)\n        ((row_ptr, col), perm) = self.data.edge_index.get_csr()\n        row_start = row_ptr[row]\n        row_end   = row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in col[row_start:row_end]\n\n    def get_sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index, edge_attr=self.data[edge_attr], num_nodes=self.N\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return in-degrees of nodes in directed network.\"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return out-degrees of nodes in directed network.\"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n        \"\"\"\n        Return degrees of nodes.\n\n        Args:\n            mode:   `in` or `out` to calculate the in- or out-degree for\n                directed networks.\n        \"\"\"\n        if mode == \"in\":\n            d = torch_geometric.utils.degree(\n                self.data.edge_index[1], num_nodes=self.N, dtype=torch.int\n            )\n        else:\n            d = torch_geometric.utils.degree(\n                self.data.edge_index[0], num_nodes=self.N, dtype=torch.int\n            )\n        return {self.mapping.to_id(i): d[i].item() for i in range(self.N)}\n\n    def get_laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.get_laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.get_laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization:  normalization parameter passed to pyG `get_laplacian`\n                            function\n            edge_attr:      optinal name of numerical edge attribute that shall\n                            be passed to pyG `get_laplacian` function as edge weight\n        \"\"\"\n        if edge_attr is None:\n            index, weight =torch_geometric.utils.get_laplacian(\n                self.data.edge_index, normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index,\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def add_node_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n        \"\"\"Add one-hot encoding of nodes to node attribute.\n\n        Args:\n            attr_name: attribute name used to store one-hot encoding\n            dim: dimension of one-hot encoding\n        \"\"\"\n        if dim == 0:\n            dim = self.N\n        self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n            config[\"torch\"][\"device\"]\n        )[: self.N]\n\n    def add_edge_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n        \"\"\"Add one-hot encoding of edges to edge attribute.\n\n        Args:\n            attr_name: attribute name used to store one-hot encoding\n            dim: dimension of one-hot encoding\n        \"\"\"\n        if dim == 0:\n            dim = self.M\n        self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n            config[\"torch\"][\"device\"]\n        )[: self.M]\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                print(key, \"is not a graph attribute\")\n                return None\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        elif key in self.data.keys():\n            return self.data[key[0]]\n        else:\n            print(key[0], \"is not a node or edge attribute\")\n            return None\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                self.data[key] = val\n            else:\n                print(key, \"is not a graph attribute\")\n        elif self.key[0].starts_with(\"node_\"):  # type: ignore\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif self.key[0].starts_with(\"edge_\"):  # type: ignore\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            print(key[0], \"is not a node or edge attribute\")\n\n    @property\n    def N(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns the number of nodes in the graph.\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def M(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the numnber of directed edges is returned.\n        \"\"\"\n        return self.data.num_edges  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\"\"\"\n        return not is_undirected(self.data.edge_index)        \n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\"\"\"\n        return is_undirected(self.data.edge_index)\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph) -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Example: \n        ```py\n        # no node IDs\n        g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        print(g1 + g2)\n        # Graph with 3 nodes and 6 edges\n\n        # Identical node IDs\n        g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        print(g1 + g2)\n        # Graph with 3 nodes and 4 edges\n\n        # Non-overlapping node IDs\n        g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        print(g1 + g2)\n        # Graph with 6 nodes and 4 edges\n\n        # Partly overlapping node IDs\n        g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        print(g1 + g2)\n        # Graph with 5 nodes and 4 edges\n        ```\n        \"\"\"\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        # compute overlap and additional nodes in g2 over g1\n        overlap = set(m2.node_ids).intersection(m1.node_ids)\n        additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n        d2_idx_translation = {}\n        node_ids = ['']*(self.N + len(additional_nodes))\n        # keep mappings of nodes in g1\n        for v in m1.node_ids:\n            node_ids[m1.to_idx(v)] = v\n        for v in m2.node_ids:\n            d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n        # for overlapping node IDs we must correct node indices in m2\n        for v in overlap:\n            d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n        # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n        for v in additional_nodes:\n            new_idx = m2.to_idx(v) + self.N - len(overlap)\n            node_ids[new_idx] = v\n            d2_idx_translation[m2.to_idx(v)] = new_idx\n        # apply index translation to d2\n        # fast dictionary based mapping using torch\n        palette, key = zip(*d2_idx_translation.items())\n        key = torch.tensor(key)\n        palette = torch.tensor(palette)\n\n        index = torch.bucketize(d2.edge_index.ravel(), palette)\n        d2.edge_index = key[index].reshape(d2.edge_index.shape)\n        d = d1.concat(d2)\n        mapping = IndexMap(node_ids)\n        d.num_nodes = self.N + len(additional_nodes)\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr_types = Graph.attr_types(self.data.to_dict())\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.N, self.M)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.N, self.M)\n        if len(self.data.node_attrs()) &gt; 0:\n            s += \"\\nNode attributes\\n\"\n            for a in self.data.node_attrs():\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.edge_attrs()) &gt; 1:\n            s += \"\\nEdge attributes\\n\"\n            for a in self.data.edge_attrs():\n                if a != \"edge_index\":\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n            self.data.node_attrs()\n        ):\n            s += \"\\nGraph attributes\\n\"\n            for a in self.data.keys():\n                if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        return s\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.M","title":"<code>M: int</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the numnber of directed edges is returned.</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.N","title":"<code>N: int</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns the number of nodes in the graph.</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.edges","title":"<code>edges: Generator[Union[Tuple[int, int], Tuple[str, str]], None, None]</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a generator object that yields all edges. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of str IDs. If no mapping is used, edges are returned as tuples of integer indices.</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.in_degrees","title":"<code>in_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return in-degrees of nodes in directed network.</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.nodes","title":"<code>nodes: Generator[Union[int, str], None, None]</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a generator object that yields all nodes. If an IndexMap is used, nodes are returned as str IDs. If no IndexMap is used, nodes are returned as integer indices.</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.out_degrees","title":"<code>out_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return out-degrees of nodes in directed network.</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Example:  <pre><code># no node IDs\ng1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\ng1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\nprint(g1 + g2)\n# Graph with 3 nodes and 6 edges\n\n# Identical node IDs\ng1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\nprint(g1 + g2)\n# Graph with 3 nodes and 4 edges\n\n# Non-overlapping node IDs\ng1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\nprint(g1 + g2)\n# Graph with 6 nodes and 4 edges\n\n# Partly overlapping node IDs\ng1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\nprint(g1 + g2)\n# Graph with 5 nodes and 4 edges\n</code></pre></p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __add__(self, other: Graph) -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Example: \n    ```py\n    # no node IDs\n    g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n    g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n    print(g1 + g2)\n    # Graph with 3 nodes and 6 edges\n\n    # Identical node IDs\n    g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n    g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n    print(g1 + g2)\n    # Graph with 3 nodes and 4 edges\n\n    # Non-overlapping node IDs\n    g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n    g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n    print(g1 + g2)\n    # Graph with 6 nodes and 4 edges\n\n    # Partly overlapping node IDs\n    g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n    g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n    print(g1 + g2)\n    # Graph with 5 nodes and 4 edges\n    ```\n    \"\"\"\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    # compute overlap and additional nodes in g2 over g1\n    overlap = set(m2.node_ids).intersection(m1.node_ids)\n    additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n    d2_idx_translation = {}\n    node_ids = ['']*(self.N + len(additional_nodes))\n    # keep mappings of nodes in g1\n    for v in m1.node_ids:\n        node_ids[m1.to_idx(v)] = v\n    for v in m2.node_ids:\n        d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n    # for overlapping node IDs we must correct node indices in m2\n    for v in overlap:\n        d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n    # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n    for v in additional_nodes:\n        new_idx = m2.to_idx(v) + self.N - len(overlap)\n        node_ids[new_idx] = v\n        d2_idx_translation[m2.to_idx(v)] = new_idx\n    # apply index translation to d2\n    # fast dictionary based mapping using torch\n    palette, key = zip(*d2_idx_translation.items())\n    key = torch.tensor(key)\n    palette = torch.tensor(palette)\n\n    index = torch.bucketize(d2.edge_index.ravel(), palette)\n    d2.edge_index = key[index].reshape(d2.edge_index.shape)\n    d = d1.concat(d2)\n    mapping = IndexMap(node_ids)\n    d.num_nodes = self.N + len(additional_nodes)\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            print(key, \"is not a graph attribute\")\n            return None\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    elif key in self.data.keys():\n        return self.data[key[0]]\n    else:\n        print(key[0], \"is not a node or edge attribute\")\n        return None\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as  optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.IndexMap.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as \n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if 'num_nodes' not in data:\n        data.num_nodes = data.edge_index.max().item()+1\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if data.edge_index.get_sparse_size(dim=0) != data.num_nodes or data.edge_index.get_sparse_size(dim=1) != data.num_nodes:\n        raise Exception('sparse size of EdgeIndex should match number of nodes!')\n\n    # sort EdgeIndex and validate\n    data.edge_index = data.edge_index.sort_by('row').values\n    data.edge_index.validate()\n\n    self.data = data\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i\n        for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            self.data[key] = val\n        else:\n            print(key, \"is not a graph attribute\")\n    elif self.key[0].starts_with(\"node_\"):  # type: ignore\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif self.key[0].starts_with(\"edge_\"):  # type: ignore\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        print(key[0], \"is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr_types = Graph.attr_types(self.data.to_dict())\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.N, self.M)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.N, self.M)\n    if len(self.data.node_attrs()) &gt; 0:\n        s += \"\\nNode attributes\\n\"\n        for a in self.data.node_attrs():\n            s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.edge_attrs()) &gt; 1:\n        s += \"\\nEdge attributes\\n\"\n        for a in self.data.edge_attrs():\n            if a != \"edge_index\":\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n        self.data.node_attrs()\n    ):\n        s += \"\\nGraph attributes\\n\"\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    return s\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.add_edge_ohe","title":"<code>add_edge_ohe</code>","text":"<p>Add one-hot encoding of edges to edge attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attr_name</code> <code>str</code> <p>attribute name used to store one-hot encoding</p> required <code>dim</code> <code>int</code> <p>dimension of one-hot encoding</p> <code>0</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def add_edge_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n    \"\"\"Add one-hot encoding of edges to edge attribute.\n\n    Args:\n        attr_name: attribute name used to store one-hot encoding\n        dim: dimension of one-hot encoding\n    \"\"\"\n    if dim == 0:\n        dim = self.M\n    self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n        config[\"torch\"][\"device\"]\n    )[: self.M]\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.add_node_ohe","title":"<code>add_node_ohe</code>","text":"<p>Add one-hot encoding of nodes to node attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attr_name</code> <code>str</code> <p>attribute name used to store one-hot encoding</p> required <code>dim</code> <code>int</code> <p>dimension of one-hot encoding</p> <code>0</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def add_node_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n    \"\"\"Add one-hot encoding of nodes to node attribute.\n\n    Args:\n        attr_name: attribute name used to store one-hot encoding\n        dim: dimension of one-hot encoding\n    \"\"\"\n    if dim == 0:\n        dim = self.N\n    self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n        config[\"torch\"][\"device\"]\n    )[: self.N]\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.attr_types","title":"<code>attr_types</code>  <code>staticmethod</code>","text":"<p>Return name, type, and size of all node, edge, and graph attributes.</p> <p>This method returns a dictionary that contains the name (key), as well as the type and size of all attributes.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef attr_types(attr: Dict) -&gt; Dict:\n    \"\"\"\n    Return name, type, and size of all node, edge, and graph attributes.\n\n    This method returns a dictionary that contains the name (key), as well as\n    the type and size of all attributes.\n    \"\"\"\n    a = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            a[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            a[k] = str(t)\n    return a\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate the in- or out-degree for directed networks.</p> <code>'in'</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n    \"\"\"\n    Return degrees of nodes.\n\n    Args:\n        mode:   `in` or `out` to calculate the in- or out-degree for\n            directed networks.\n    \"\"\"\n    if mode == \"in\":\n        d = torch_geometric.utils.degree(\n            self.data.edge_index[1], num_nodes=self.N, dtype=torch.int\n        )\n    else:\n        d = torch_geometric.utils.degree(\n            self.data.edge_index[0], num_nodes=self.N, dtype=torch.int\n        )\n    return {self.mapping.to_id(i): d[i].item() for i in range(self.N)}\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def edge_attrs(self) -&gt; List:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can  be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.IndexMap.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index</p> <code>None</code> Example <pre><code>import pathpyG as pp\n\ng = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\nprint(g)\n\ng = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                        mapping=pp.IndexMap(['a', 'b', 'c']))\nprint(g)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes=None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can \n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        print(g)\n\n        g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                                mapping=pp.IndexMap(['a', 'b', 'c']))\n        print(g)\n        ```\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else: \n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(\n        d,\n        mapping=mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>pathpyG.core.IndexMap.IndexMap</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>num_nodes</code> <p>optional number of nodes (useful in case not all nodes have incident edges)</p> <code>None</code> Example <pre><code>import pathpyG as pp\n\nl = [('a', 'b'), ('a', 'c'), ('b', 'c')]\ng = pp.Graph.from_edge_list(l)\nprint(g)\nprint(g.mapping)\n\nl = [('a', 'b'), ('a', 'c'), ('b', 'c')]\ng = pp.Graph.from_edge_list(l)\nprint(g)\nprint(g.mapping)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(edge_list: Iterable[Tuple[str, str]], is_undirected: bool = False, mapping: IndexMap = None, num_nodes=None) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n    Example:\n        ```\n        import pathpyG as pp\n\n        l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        g = pp.Graph.from_edge_list(l)\n        print(g)\n        print(g.mapping)\n\n        l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        g = pp.Graph.from_edge_list(l)\n        print(g)\n        print(g.mapping)\n        ```\n    \"\"\"\n\n    if mapping is None:\n        node_ids = set()\n        for v, w in edge_list:\n            node_ids.add(v)\n            node_ids.add(w)\n        node_list = list(node_ids)\n        node_list.sort()\n        mapping = IndexMap(node_list)\n\n    sources = []\n    targets = []\n    for v, w in edge_list:\n        sources.append(mapping.to_idx(v))\n        targets.append(mapping.to_idx(w))\n\n    if num_nodes is None:\n        num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex([sources, targets], sparse_size=(num_nodes, num_nodes), is_undirected=is_undirected, device=config['torch']['device'])\n    return Graph(\n        Data(edge_index=edge_index, num_nodes=num_nodes),\n        mapping=mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_laplacian","title":"<code>get_laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.get_laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code>             function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall             be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.get_laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.get_laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization:  normalization parameter passed to pyG `get_laplacian`\n                        function\n        edge_attr:      optinal name of numerical edge attribute that shall\n                        be passed to pyG `get_laplacian` function as edge weight\n    \"\"\"\n    if edge_attr is None:\n        index, weight =torch_geometric.utils.get_laplacian(\n            self.data.edge_index, normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index,\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n    \"\"\"        \n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([])\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_sparse_adj_matrix","title":"<code>get_sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index, edge_attr=self.data[edge_attr], num_nodes=self.N\n        )\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([])\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\"\"\"\n    return not is_undirected(self.data.edge_index)        \n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID \n    \"\"\"\n    row = self.mapping.to_idx(v)\n    ((row_ptr, col), perm) = self.data.edge_index.get_csr()\n    row_start = row_ptr[row]\n    row_end   = row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\"\"\"\n    return is_undirected(self.data.edge_index)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_id</code> attribute.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def node_attrs(self) -&gt; List:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_id` attribute.\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_id\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) \\\n        -&gt; Generator[Union[int, str] | tuple, None, None]:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n    \"\"\"\n    for i in self.get_predecessors(self.mapping.to_idx(node)):  # type: ignore\n        yield self.mapping.to_id(i.item())\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) \\\n        -&gt; Generator[Union[int, str] | tuple, None, None]:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n    \"\"\"\n\n    for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n        yield self.mapping.to_id(j.item())\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    tf = ToUndirected()\n    d = tf(self.data)\n    # unfortunately, the application of a transform creates a new edge_index of type tensor\n    # so we have to recreate the EdgeIndex tensor and sort it again\n\n    e = EdgeIndex(data=d.edge_index, is_undirected=True)\n    d.edge_index = e\n    return Graph(d, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\"\"\"\n    i, w = torch_geometric.utils.coalesce(self.data.edge_index, torch.ones(self.M).to(config[\"torch\"][\"device\"]))\n    return Graph(Data(edge_index=i, edge_weight=w), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_central_moment","title":"<code>degree_central_moment</code>","text":"<p>Calculates the k-th central moment of the degree distribution.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.Graph.Graph</code> <p>The graph for which to calculate the k-th central moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_central_moment(graph: Graph, k: int = 1) -&gt; float:\n    \"\"\"Calculates the k-th central moment of the degree distribution.\n\n    Args:\n        graph: The graph for which to calculate the k-th central moment\n\n    \"\"\"\n    p_k = degree_distribution(graph)\n    mean = _np.mean(degree_sequence(graph))\n    m = 0.\n    for x in p_k:\n        m += (x - mean)**k * p_k[x]\n    return m\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_distribution","title":"<code>degree_distribution</code>","text":"<p>Calculates the degree distribution of a graph</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_distribution(g: Graph) -&gt; Dict[int, float]:\n    \"\"\"Calculates the degree distribution of a graph\n    \"\"\"\n    assert g.is_undirected()\n\n    cnt: defaultdict = defaultdict(float)\n    d = g.degrees()\n    for v in g.nodes:\n        cnt[d[v]] += 1.0 / g.N\n    return cnt\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_generating_function","title":"<code>degree_generating_function</code>","text":"<p>Returns the generating function of the (weighted) degree distribution of a network,     calculated for either a single argument x or a list or numpy array of arguments x</p> <p>Returns f(x) where f is the probability generating function for the degree distribution P(k) for a graph. The function is defined in the interval [0,1].  The value returned is from the range [0,1]. The following properties hold:</p> <p>[1/k! d^k/dx f]_{x=0} = P(k) with d^k/dx f being the k-th derivative of f by x</p> <p>f'(1) =  with f' being the first derivative and  the mean degree <p>[(x d/dx)^m f]_{x=1} =  with  being the m-th raw moment of P <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.Graph.Graph</code> <p>The graph for which the generating function shall be computed</p> required float, list, numpy.ndarray <p>The argument(s) for which value(s) f(x) shall be computed.</p> <p>Example: <pre><code>    # Generate simple network\n    import pathpyG as pp\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n    # Return single function value\n    val = pp.statistics.degreee_generating_func(n, 0.3)\n    print(val)\n    0.069\n\n    # Plot generating function of degree distribution\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func(n, x)\n    x = plt.plot(x, y)\n    # [Function plot]\n\n    # Plot generating function based on degree sequence\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func([1,2,1,2], x)\n    x = plt.plot(x, y)\n    # [Function plot]\n</code></pre></p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_generating_function(graph: Graph, x: float | list[float] | _np.ndarray) -&gt; float | _np.ndarray:\n    \"\"\"Returns the generating function of the (weighted) degree distribution of a network,\n        calculated for either a single argument x or a list or numpy array of arguments x\n\n\n    Returns f(x) where f is the probability generating function for the degree\n    distribution P(k) for a graph. The function is defined in the interval\n    [0,1].  The value returned is from the range [0,1]. The following properties\n    hold:\n\n    [1/k! d^k/dx f]_{x=0} = P(k)\n    with d^k/dx f being the k-th derivative of f by x\n\n    f'(1) = &lt;k&gt;\n    with f' being the first derivative and &lt;k&gt; the mean degree\n\n    [(x d/dx)^m f]_{x=1} = &lt;k^m&gt;\n    with &lt;k^m&gt; being the m-th raw moment of P\n\n    Args:\n        graph: The graph for which the generating function shall be computed\n\n    x:  float, list, numpy.ndarray\n        The argument(s) for which value(s) f(x) shall be computed.\n\n    Example:\n    ```py\n        # Generate simple network\n        import pathpyG as pp\n        import numpy as np\n        import matplotlib.pyplot as plt\n\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                    ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n        # Return single function value\n        val = pp.statistics.degreee_generating_func(n, 0.3)\n        print(val)\n        0.069\n\n        # Plot generating function of degree distribution\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func(n, x)\n        x = plt.plot(x, y)\n        # [Function plot]\n\n        # Plot generating function based on degree sequence\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func([1,2,1,2], x)\n        x = plt.plot(x, y)\n        # [Function plot]\n    ```\n    \"\"\"\n\n    p_k = degree_distribution(graph)\n\n    if isinstance(x, float):\n        x_range = [x]\n    else:\n        x_range = x\n\n    values: defaultdict = defaultdict(float)\n    for k in p_k:\n        for v in x_range:\n            values[v] += p_k[k] * v**k\n\n    _values: float | _np.ndarray\n    if len(x_range) &gt; 1:\n        _values = _np.fromiter(values.values(), dtype=float)\n    else:\n        _values = values[x]\n    return _values\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_raw_moment","title":"<code>degree_raw_moment</code>","text":"<p>Calculates the k-th raw moment of the degree distribution of a network</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.Graph.Graph</code> <p>The graph in which to calculate the k-th raw moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_raw_moment(graph: Graph, k: int = 1) -&gt; float:\n    \"\"\"Calculates the k-th raw moment of the degree distribution of a network\n\n    Args:\n        graph:  The graph in which to calculate the k-th raw moment\n\n    \"\"\"\n    p_k = degree_distribution(graph)\n    mom = 0.0\n    for x in p_k:\n        mom += x**k * p_k[x]\n    return mom\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_sequence","title":"<code>degree_sequence</code>","text":"<p>Calculates the degree sequence of a network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.Graph.Graph</code> <p>The <code>Graph</code> object for which degrees are calculated</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_sequence(graph: Graph) -&gt; _np.array:\n    \"\"\"Calculates the degree sequence of a network.\n\n    Args:\n        graph: The `Graph` object for which degrees are calculated\n    \"\"\"\n    assert graph.is_undirected()\n\n    _degrees = _np.zeros(graph.N, dtype=float)\n    d = graph.degrees()\n    for v in graph.nodes:\n        _degrees[graph.mapping.to_idx(v)] = d[v]\n    return _degrees\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/","title":"degrees","text":""},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_central_moment","title":"<code>degree_central_moment</code>","text":"<p>Calculates the k-th central moment of the degree distribution.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.Graph.Graph</code> <p>The graph for which to calculate the k-th central moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_central_moment(graph: Graph, k: int = 1) -&gt; float:\n    \"\"\"Calculates the k-th central moment of the degree distribution.\n\n    Args:\n        graph: The graph for which to calculate the k-th central moment\n\n    \"\"\"\n    p_k = degree_distribution(graph)\n    mean = _np.mean(degree_sequence(graph))\n    m = 0.\n    for x in p_k:\n        m += (x - mean)**k * p_k[x]\n    return m\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_distribution","title":"<code>degree_distribution</code>","text":"<p>Calculates the degree distribution of a graph</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_distribution(g: Graph) -&gt; Dict[int, float]:\n    \"\"\"Calculates the degree distribution of a graph\n    \"\"\"\n    assert g.is_undirected()\n\n    cnt: defaultdict = defaultdict(float)\n    d = g.degrees()\n    for v in g.nodes:\n        cnt[d[v]] += 1.0 / g.N\n    return cnt\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_generating_function","title":"<code>degree_generating_function</code>","text":"<p>Returns the generating function of the (weighted) degree distribution of a network,     calculated for either a single argument x or a list or numpy array of arguments x</p> <p>Returns f(x) where f is the probability generating function for the degree distribution P(k) for a graph. The function is defined in the interval [0,1].  The value returned is from the range [0,1]. The following properties hold:</p> <p>[1/k! d^k/dx f]_{x=0} = P(k) with d^k/dx f being the k-th derivative of f by x</p> <p>f'(1) =  with f' being the first derivative and  the mean degree <p>[(x d/dx)^m f]_{x=1} =  with  being the m-th raw moment of P <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.Graph.Graph</code> <p>The graph for which the generating function shall be computed</p> required float, list, numpy.ndarray <p>The argument(s) for which value(s) f(x) shall be computed.</p> <p>Example: <pre><code>    # Generate simple network\n    import pathpyG as pp\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n    # Return single function value\n    val = pp.statistics.degreee_generating_func(n, 0.3)\n    print(val)\n    0.069\n\n    # Plot generating function of degree distribution\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func(n, x)\n    x = plt.plot(x, y)\n    # [Function plot]\n\n    # Plot generating function based on degree sequence\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func([1,2,1,2], x)\n    x = plt.plot(x, y)\n    # [Function plot]\n</code></pre></p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_generating_function(graph: Graph, x: float | list[float] | _np.ndarray) -&gt; float | _np.ndarray:\n    \"\"\"Returns the generating function of the (weighted) degree distribution of a network,\n        calculated for either a single argument x or a list or numpy array of arguments x\n\n\n    Returns f(x) where f is the probability generating function for the degree\n    distribution P(k) for a graph. The function is defined in the interval\n    [0,1].  The value returned is from the range [0,1]. The following properties\n    hold:\n\n    [1/k! d^k/dx f]_{x=0} = P(k)\n    with d^k/dx f being the k-th derivative of f by x\n\n    f'(1) = &lt;k&gt;\n    with f' being the first derivative and &lt;k&gt; the mean degree\n\n    [(x d/dx)^m f]_{x=1} = &lt;k^m&gt;\n    with &lt;k^m&gt; being the m-th raw moment of P\n\n    Args:\n        graph: The graph for which the generating function shall be computed\n\n    x:  float, list, numpy.ndarray\n        The argument(s) for which value(s) f(x) shall be computed.\n\n    Example:\n    ```py\n        # Generate simple network\n        import pathpyG as pp\n        import numpy as np\n        import matplotlib.pyplot as plt\n\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                    ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n        # Return single function value\n        val = pp.statistics.degreee_generating_func(n, 0.3)\n        print(val)\n        0.069\n\n        # Plot generating function of degree distribution\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func(n, x)\n        x = plt.plot(x, y)\n        # [Function plot]\n\n        # Plot generating function based on degree sequence\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func([1,2,1,2], x)\n        x = plt.plot(x, y)\n        # [Function plot]\n    ```\n    \"\"\"\n\n    p_k = degree_distribution(graph)\n\n    if isinstance(x, float):\n        x_range = [x]\n    else:\n        x_range = x\n\n    values: defaultdict = defaultdict(float)\n    for k in p_k:\n        for v in x_range:\n            values[v] += p_k[k] * v**k\n\n    _values: float | _np.ndarray\n    if len(x_range) &gt; 1:\n        _values = _np.fromiter(values.values(), dtype=float)\n    else:\n        _values = values[x]\n    return _values\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_raw_moment","title":"<code>degree_raw_moment</code>","text":"<p>Calculates the k-th raw moment of the degree distribution of a network</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.Graph.Graph</code> <p>The graph in which to calculate the k-th raw moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_raw_moment(graph: Graph, k: int = 1) -&gt; float:\n    \"\"\"Calculates the k-th raw moment of the degree distribution of a network\n\n    Args:\n        graph:  The graph in which to calculate the k-th raw moment\n\n    \"\"\"\n    p_k = degree_distribution(graph)\n    mom = 0.0\n    for x in p_k:\n        mom += x**k * p_k[x]\n    return mom\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_sequence","title":"<code>degree_sequence</code>","text":"<p>Calculates the degree sequence of a network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.Graph.Graph</code> <p>The <code>Graph</code> object for which degrees are calculated</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_sequence(graph: Graph) -&gt; _np.array:\n    \"\"\"Calculates the degree sequence of a network.\n\n    Args:\n        graph: The `Graph` object for which degrees are calculated\n    \"\"\"\n    assert graph.is_undirected()\n\n    _degrees = _np.zeros(graph.N, dtype=float)\n    d = graph.degrees()\n    for v in graph.nodes:\n        _degrees[graph.mapping.to_idx(v)] = d[v]\n    return _degrees\n</code></pre>"},{"location":"reference/pathpyG/statistics/node_similarities/","title":"node_similarities","text":""},{"location":"reference/pathpyG/utils/","title":"utils","text":""},{"location":"reference/pathpyG/utils/config/","title":"config","text":""},{"location":"reference/pathpyG/utils/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/utils/dbgnn/#pathpyG.utils.dbgnn.generate_bipartite_edge_index","title":"<code>generate_bipartite_edge_index</code>","text":"<p>Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.</p> Source code in <code>src/pathpyG/utils/dbgnn.py</code> <pre><code>def generate_bipartite_edge_index(g: Graph, g2: Graph, mapping: str = 'last') -&gt; torch.Tensor:\n    \"\"\"Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.\"\"\"\n\n    if mapping == 'last':\n        bipartide_edge_index = torch.tensor(\n            [list(range(g2.N)), [v[1] for v in g2.data.node_sequence]]\n            )\n\n    elif mapping == 'first':\n        bipartide_edge_index = torch.tensor(\n            [list(range(g2.N)), [v[0] for v in g2.data.node_sequence]]\n        )\n    else:\n        bipartide_edge_index = torch.tensor(\n            [list(range(g2.N)) + list(range(g2.N)),\n            [v[0] for v in g2.data.node_sequence] + [v[1] for v in g2.data.node_sequence]]\n        )\n\n    return bipartide_edge_index\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/","title":"progress","text":"<p>Progressbar for pathpy.</p>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_console","title":"<code>tqdm_console</code>","text":"<p>Progressbar for a console environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_console(*args, **kwargs):\n    \"\"\"Progressbar for a console environment.\"\"\"\n    if len(args[0]) &gt; config['progress']['min_iter']:\n        return tq(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_disabled","title":"<code>tqdm_disabled</code>","text":"<p>Disable the progress bar and return initial iterator.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_disabled(it, *args, **kwargs):\n    \"\"\"Disable the progress bar and return initial iterator.\"\"\"\n    return it\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_notebook","title":"<code>tqdm_notebook</code>","text":"<p>Progressbar for a notebook environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_notebook(*args, **kwargs):\n    \"\"\"Progressbar for a notebook environment.\"\"\"\n    if len(args[0]) &gt; config['progress']['min_iter']:\n        return tqn(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/visualisations/","title":"visualisations","text":"<p>PathpyG visualizations.</p>"},{"location":"reference/pathpyG/visualisations/hist_plots/","title":"hist_plots","text":"<p>Histogram plot classes.</p>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.HistogramPlot","title":"<code>HistogramPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Histogram plot class for a network property.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>class HistogramPlot(PathPyPlot):\n    \"\"\"Histogram plot class for a network property.\"\"\"\n\n    _kind = \"hist\"\n\n    def __init__(\n        self, network: Graph, key: str = \"indegrees\", bins: int = 10, **kwargs: Any\n    ) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.config[\"bins\"] = bins\n        self.config[\"key\"] = key\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n\n        data: dict = {}\n\n        match self.config[\"key\"]:\n            case \"indegrees\":\n                logger.debug(\"Generate data for in-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n            case \"outdegrees\":\n                logger.debug(\"Generate data for out-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n            case _:\n                logger.error(\n                    f\"The &lt;{self.config['key']}&gt; property\",\n                    \"is currently not supported for hist plots.\",\n                )\n                raise KeyError\n\n        data[\"title\"] = self.config[\"key\"]\n        self.data[\"data\"] = data\n</code></pre>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.HistogramPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>def __init__(\n    self, network: Graph, key: str = \"indegrees\", bins: int = 10, **kwargs: Any\n) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.network = network\n    self.config = kwargs\n    self.config[\"bins\"] = bins\n    self.config[\"key\"] = key\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.HistogramPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    logger.debug(\"Generate histogram.\")\n\n    data: dict = {}\n\n    match self.config[\"key\"]:\n        case \"indegrees\":\n            logger.debug(\"Generate data for in-degrees\")\n            data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n        case \"outdegrees\":\n            logger.debug(\"Generate data for out-degrees\")\n            data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n        case _:\n            logger.error(\n                f\"The &lt;{self.config['key']}&gt; property\",\n                \"is currently not supported for hist plots.\",\n            )\n            raise KeyError\n\n    data[\"title\"] = self.config[\"key\"]\n    self.data[\"data\"] = data\n</code></pre>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.hist","title":"<code>hist</code>","text":"<p>Plot a histogram.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>def hist(\n    network: Graph, key: str = \"indegrees\", bins: int = 10, **kwargs: Any\n) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/","title":"layout","text":""},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout","title":"<code>Layout</code>","text":"<p>               Bases: <code>object</code></p> <p>Default class to create layouts</p> <p>The <code>Layout</code> class is used to generate node a layout drawer and return the calculated node positions as a dictionary, where the keywords represents the node ids and the values represents a two dimensional tuple with the x and y coordinates for the associated nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>list with node ids. The list contain a list of unique node ids.</p> required <code>**attr</code> <code>dict</code> <p>Attributes to add to node as key=value pairs. See also <code>layout</code></p> <code>{}</code> See also <p><code>layout</code></p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>class Layout(object):\n    \"\"\"Default class to create layouts\n\n    The [`Layout`][pathpyG.visualisations.layout.Layout] class is used to generate node a layout drawer and\n    return the calculated node positions as a dictionary, where the keywords\n    represents the node ids and the values represents a two dimensional tuple\n    with the x and y coordinates for the associated nodes.\n\n    Args:\n        nodes (list): list with node ids.\n            The list contain a list of unique node ids.\n        **attr (dict): Attributes to add to node as key=value pairs.\n            See also [`layout`][pathpyG.visualisations.layout.layout]\n\n    Note: See also\n        [`layout`][pathpyG.visualisations.layout.layout]\n    \"\"\"\n\n    def __init__(self, nodes, adjacency_matrix, **attr):\n        \"\"\"Initialize the Layout class\n\n        The [`Layout`][pathpyG.visualisations.layout.Layout] class is used to generate node a layout drawer and\n        return the calculated node positions as a dictionary, where the keywords\n        represents the node ids and the values represents a two dimensional tuple\n        with the x and y coordinates for the associated nodes.\n\n        Args:\n            nodes (list): list with node ids.\n                The list contain a list of unique node ids.\n            **attr (dict): Attributes to add to node as key=value pairs.\n                See also [`layout`][pathpyG.visualisations.layout.layout]\n        \"\"\"\n\n        # initialize variables\n        self.nodes = nodes\n        self.adjacency_matrix = adjacency_matrix\n\n        # rename the attributes\n        attr = self.rename_attributes(**attr)\n\n        # options for the layouts\n        self.layout_type = attr.get('layout', None)\n        self.k = attr.get('force', None,)\n        self.fixed = attr.get('fixed', None)\n        self.iterations = attr.get('iterations', 50)\n        self.threshold = attr.get('threshold', 1e-4)\n        self.weight = attr.get('weight', None)\n        self.dimension = attr.get('dimension', 2)\n        self.seed = attr.get('seed', None)\n        self.positions = attr.get('positions', None)\n        self.radius = attr.get('radius', 1.0)\n        self.direction = attr.get('direction', 1.0)\n        self.start_angle = attr.get('start_angle', 0.0)\n\n        # TODO: allow also higher dimensional layouts\n        if self.dimension &gt; 2:\n            print('Currently only plots with maximum dimension 2 are supported!')\n            self.dimension = 2\n\n    @staticmethod\n    def rename_attributes(**kwds):\n        \"\"\"Rename layout attributes.\n\n        In the style dictionary multiple keywords can be used to address\n        attributes. These keywords will be converted to an unique key word,\n        used in the remaining code.\n\n        | keys | other valid keys |\n        | ---- | ---------------- |\n        | fixed | `fixed_nodes`, `fixed_vertices`, `fixed_n`, `fixed_v` |\n        | positions | `initial_positions`, `node_positions` `vertex_positions`, `n_positions`, `v_positions` |\n        \"\"\"\n        names = {'fixed': ['fixed_nodes', 'fixed_vertices',\n                           'fixed_v', 'fixed_n'],\n                 'positions': ['initial_positions', 'node_positions',\n                               'vertex_positions', 'n_positions',\n                               'v_positions'],\n                 'layout_': ['layout_'],\n                 }\n\n        _kwds = {}\n        del_keys = []\n        for key, value in kwds.items():\n            for attr, name_list in names.items():\n                for name in name_list:\n                    if name in key and name[0] == key[0]:\n                        _kwds[key.replace(name, attr).replace(\n                            'layout_', '')] = value\n                        del_keys.append(key)\n                        break\n        # remove the replaced keys from the dict\n        for key in del_keys:\n            del kwds[key]\n\n        return {**_kwds, **kwds}\n\n    def generate_layout(self):\n        \"\"\"Function to pick and generate the right layout.\"\"\"\n        # method names\n        names_rand = ['Random', 'random', 'rand', None]\n        names_fr = ['Fruchterman-Reingold', 'fruchterman_reingold', 'fr',\n                    'spring_layout', 'spring layout', 'FR']\n        names_circular = ['circular', 'circle', 'ring', '1d-lattice', 'lattice-1d']\n        names_grid = ['grid', '2d-lattice', 'lattice-2d']\n        # check which layout should be plotted\n        if self.layout_type in names_rand:\n            self.layout = self.random()\n        elif self.layout_type in names_circular or (self.layout_type == 'lattice' and self.dimension == 1):\n            self.layout = self.circular()\n        elif self.layout_type in names_grid or (self.layout_type == 'lattice' and self.dimension == 2):\n            self.layout = self.grid()\n        elif self.layout_type in names_fr:\n            self.layout = self.fruchterman_reingold()\n\n        # print(self.layout)\n        return self.layout\n\n    def random(self):\n        \"\"\"Position nodes uniformly at random in the unit square.\n\n        For every node, a position is generated by choosing each of dimension\n        coordinates uniformly at random on the interval $[0.0, 1.0)$.\n\n        This algorithm can be enabled with the keywords: `Random`,\n        `random`, `rand`, or `None`\n\n        Keyword Args:\n            dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n            seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n                the seed used by the random number generator, if None, the a random\n                seed by created by the numpy random number generator is used.\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n        np.random.seed(self.seed)\n        layout = np.random.rand(len(self.nodes), self.dimension)\n        return dict(zip(self.nodes, layout))\n\n    def fruchterman_reingold(self):\n        \"\"\"Position nodes using Fruchterman-Reingold force-directed algorithm.\n\n        In this algorithm, the nodes are represented by steel rings and the\n        edges are springs between them. The attractive force is analogous to the\n        spring force and the repulsive force is analogous to the electrical\n        force. The basic idea is to minimize the energy of the system by moving\n        the nodes and changing the forces between them.\n\n        This algorithm can be enabled with the keywords: `Fruchterman-Reingold`,\n        `fruchterman_reingold`, `fr`, `spring_layout`, `spring layout`, `FR`\n\n        Keyword Args:\n            force (float): Optimal distance between nodes. If None the distance is set to\n                1/sqrt(n) where n is the number of nodes.  Increase this value to move\n                nodes farther apart.\n            positions (dict): Initial positions for nodes as a dictionary with node as keys and values\n                as a coordinate list or tuple.  If None, then use random initial\n                positions.\n            fixed (list): Nodes to keep fixed at initial position.\n            iterations (int): Maximum number of iterations taken. Defaults to 50.\n            threshold (float): Threshold for relative error in node position changes.  The iteration\n                stops if the error is below this threshold. Defaults to 1e-4.\n            weight (string): The edge attribute that holds the numerical value used for the edge\n                weight.  If None, then all edge weights are 1.\n            dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n            seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n                the seed used by the random number generator, if None, the a random seed\n                by created by the numpy random number generator is used.\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n\n        # convert adjacency matrix\n        self.adjacency_matrix = self.adjacency_matrix.astype(float)\n\n        if self.fixed is not None:\n            self.fixed = np.asarray([self.nodes.index(v) for v in self.fixed])\n\n        if self.positions is not None:\n            # Determine size of existing domain to adjust initial positions\n            _size = max(coord for t in layout.values() for coord in t) # type: ignore\n            if _size == 0:\n                _size = 1\n            np.random.seed(self.seed)\n            self.layout = np.random.rand(\n                len(self.nodes), self.dimension) * _size # type: ignore\n\n            for i, n in enumerate(self.nodes):\n                if n in self.positions:\n                    self.layout[i] = np.asarray(self.positions[n])\n        else:\n            self.layout = None\n            _size = 0\n\n        if self.k is None and self.fixed is not None:\n            # We must adjust k by domain size for layouts not near 1x1\n            self.k = _size / np.sqrt(len(self.nodes))\n\n        try:\n            # Sparse matrix\n            if len(self.nodes) &lt; 500:  # sparse solver for large graphs\n                raise ValueError\n            layout = self._sparse_fruchterman_reingold()\n        except:\n            layout = self._fruchterman_reingold()\n\n        layout = dict(zip(self.nodes, layout))\n\n        return layout\n\n    def _fruchterman_reingold(self):\n        \"\"\"Fruchterman-Reingold algorithm for dense matrices.\n\n        This algorithm is based on the Fruchterman-Reingold algorithm provided\n        by `networkx`. (Copyright (C) 2004-2018 by Aric Hagberg &lt;hagberg@lanl.gov&gt;\n        Dan Schult &lt;dschult@colgate.edu&gt; Pieter Swart &lt;swart@lanl.gov&gt; Richard\n        Penney &lt;rwpenney@users.sourceforge.net&gt; All rights reserved. BSD\n        license.)\n\n        \"\"\"\n        A = self.adjacency_matrix.todense()\n        k = self.k\n        try:\n            _n, _ = A.shape\n        except AttributeError:\n            print('Fruchterman-Reingold algorithm needs an adjacency matrix as input')\n            raise AttributeError\n\n        # make sure we have an array instead of a matrix\n        A = np.asarray(A)\n\n        if self.layout is None:\n            # random initial positions\n            np.random.seed(self.seed)\n            layout = np.asarray(np.random.rand(\n                _n, self.dimension), dtype=A.dtype)\n        else:\n            # make sure positions are of same type as matrix\n            layout = self.layout.astype(A.dtype) # type: ignore\n\n        # optimal distance between nodes\n        if k is None:\n            k = np.sqrt(1.0 / _n)\n        # the initial \"temperature\"  is about .1 of domain area (=1x1)\n        # this is the largest step allowed in the dynamics.\n        # We need to calculate this in case our fixed positions force our domain\n        # to be much bigger than 1x1\n        t = max(max(layout.T[0]) - min(layout.T[0]),\n                max(layout.T[1]) - min(layout.T[1])) * 0.1\n        # simple cooling scheme.\n        # linearly step down by dt on each iteration so last iteration is size dt.\n        dt = t / float(self.iterations + 1)\n        delta = np.zeros(\n            (layout.shape[0], layout.shape[0], layout.shape[1]), dtype=A.dtype)\n        # the inscrutable (but fast) version\n        # this is still O(V^2)\n        # could use multilevel methods to speed this up significantly\n        for iteration in tqdm(range(self.iterations), desc='Calculating Fruchterman-Reingold layout'):\n            # matrix of difference between points\n            delta = layout[:, np.newaxis, :] - layout[np.newaxis, :, :] # type: ignore\n            # distance between points\n            distance = np.linalg.norm(delta, axis=-1)\n            # enforce minimum distance of 0.01\n            np.clip(distance, 0.01, None, out=distance)\n            # displacement \"force\"\n            displacement = np.einsum('ijk,ij-&gt;ik',\n                                     delta,\n                                     (k * k / distance**2 - A * distance / k))\n            # update layoutitions\n            length = np.linalg.norm(displacement, axis=-1)\n            length = np.where(length &lt; 0.01, 0.1, length)\n            delta_layout = np.einsum('ij,i-&gt;ij', displacement, t / length)\n            if self.fixed is not None:\n                # don't change positions of fixed nodes\n                delta_layout[self.fixed] = 0.0\n            layout += delta_layout\n            # cool temperature\n            t -= dt\n            error = np.linalg.norm(delta_layout) / _n\n            if error &lt; self.threshold:\n                break\n        return layout\n\n    def _sparse_fruchterman_reingold(self):\n        \"\"\"Fruchterman-Reingold algorithm for sparse matrices.\n\n        This algorithm is based on the Fruchterman-Reingold algorithm provided\n        by networkx. (Copyright (C) 2004-2018 by Aric Hagberg &lt;hagberg@lanl.gov&gt;\n        Dan Schult &lt;dschult@colgate.edu&gt; Pieter Swart &lt;swart@lanl.gov&gt; Richard\n        Penney &lt;rwpenney@users.sourceforge.net&gt; All rights reserved. BSD\n        license.)\n\n        \"\"\"\n        A = self.adjacency_matrix\n        k = self.k\n        try:\n            _n, _ = A.shape\n        except AttributeError:\n            print('Fruchterman-Reingold algorithm needs an adjacency '\n                      'matrix as input')\n            raise AttributeError\n        try:\n            from scipy.sparse import spdiags, coo_matrix\n        except ImportError:\n            print('The sparse Fruchterman-Reingold algorithm needs the '\n                      'scipy package: http://scipy.org/')\n            raise ImportError\n        # make sure we have a LIst of Lists representation\n        try:\n            A = A.tolil()\n        except:\n            A = (coo_matrix(A)).tolil()\n\n        if self.layout is None:\n            # random initial positions\n            np.random.seed(self.seed)\n            layout = np.asarray(np.random.rand(\n                _n, self.dimension), dtype=A.dtype)\n        else:\n            # make sure positions are of same type as matrix\n            layout = layout.astype(A.dtype) # type: ignore\n\n        # no fixed nodes\n        if self.fixed is None:\n            self.fixed = []\n\n        # optimal distance between nodes\n        if k is None:\n            k = np.sqrt(1.0 / _n)\n        # the initial \"temperature\"  is about .1 of domain area (=1x1)\n        # this is the largest step allowed in the dynamics.\n        t = max(max(layout.T[0]) - min(layout.T[0]),\n                max(layout.T[1]) - min(layout.T[1])) * 0.1\n        # simple cooling scheme.\n        # linearly step down by dt on each iteration so last iteration is size dt.\n        dt = t / float(self.iterations + 1)\n\n        displacement = np.zeros((self.dimension, _n))\n        for iteration in range(self.iterations):\n            displacement *= 0\n            # loop over rows\n            for i in range(A.shape[0]):\n                if i in self.fixed:\n                    continue\n                # difference between this row's node position and all others\n                delta = (layout[i] - layout).T\n                # distance between points\n                distance = np.sqrt((delta**2).sum(axis=0))\n                # enforce minimum distance of 0.01\n                distance = np.where(distance &lt; 0.01, 0.01, distance)\n                # the adjacency matrix row\n                Ai = np.asarray(A.getrowview(i).toarray())\n                # displacement \"force\"\n                displacement[:, i] +=\\\n                    (delta * (k * k / distance**2 - Ai * distance / k)).sum(axis=1)\n            # update positions\n            length = np.sqrt((displacement**2).sum(axis=0))\n            length = np.where(length &lt; 0.01, 0.1, length)\n            delta_layout = (displacement * t / length).T\n            layout += delta_layout\n            # cool temperature\n            t -= dt\n            err = np.linalg.norm(delta_layout) / _n\n            if err &lt; self.threshold:\n                break\n        return layout\n\n\n    def circular(self):\n        \"\"\"Position nodes on a circle with given radius.\n\n        This algorithm can be enabled with the keywords: `circular`, `circle`, `ring`, `lattice-1d`, `1d-lattice`, `lattice`\n\n        Keyword Args:\n            radius (float): Sets the radius of the circle on which nodes\n                are positioned. Defaults to 1.0.\n            direction (float): Sets the direction in which nodes are placed on the circle. 1.0 for clockwise (default)\n                and -1.0 for counter-clockwise direction. Defaults to 1.0.\n            start_angle (float): Sets the angle of the first node relative to the 3pm position on a clock.\n                and -1.0 for counter-clockwise direction. Defaults to 90.0.\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n\n        n = len(self.nodes)\n        rad = 2.0 * np.pi / n\n        rotation = (90.0 - self.start_angle*self.direction) * np.pi / 180.0\n        layout = {}\n\n        for i in range(n):\n            x = self.radius * np.cos(rotation - i*rad*self.direction)\n            y = self.radius * np.sin(rotation - i*rad*self.direction)\n            layout[self.nodes[i]] = (x,y)\n\n        return layout\n\n\n    def grid(self):\n        \"\"\"Position nodes on a two-dimensional grid\n\n        This algorithm can be enabled with the keywords: `grid`, `lattice-2d`, `2d-lattice`, `lattice`\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n\n        n = len(self.nodes)\n        width = 1.0\n\n        # number of nodes in horizontal/vertical direction\n        k = np.floor(np.sqrt(n))\n        dist = width / k\n        layout = {}\n\n        i = 0\n        for i in range(n):\n            layout[self.nodes[i]] = ((i%k) *dist, -(np.floor(i/k))*dist)\n            i += 1\n\n        return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.__init__","title":"<code>__init__</code>","text":"<p>Initialize the Layout class</p> <p>The <code>Layout</code> class is used to generate node a layout drawer and return the calculated node positions as a dictionary, where the keywords represents the node ids and the values represents a two dimensional tuple with the x and y coordinates for the associated nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>list with node ids. The list contain a list of unique node ids.</p> required <code>**attr</code> <code>dict</code> <p>Attributes to add to node as key=value pairs. See also <code>layout</code></p> <code>{}</code> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def __init__(self, nodes, adjacency_matrix, **attr):\n    \"\"\"Initialize the Layout class\n\n    The [`Layout`][pathpyG.visualisations.layout.Layout] class is used to generate node a layout drawer and\n    return the calculated node positions as a dictionary, where the keywords\n    represents the node ids and the values represents a two dimensional tuple\n    with the x and y coordinates for the associated nodes.\n\n    Args:\n        nodes (list): list with node ids.\n            The list contain a list of unique node ids.\n        **attr (dict): Attributes to add to node as key=value pairs.\n            See also [`layout`][pathpyG.visualisations.layout.layout]\n    \"\"\"\n\n    # initialize variables\n    self.nodes = nodes\n    self.adjacency_matrix = adjacency_matrix\n\n    # rename the attributes\n    attr = self.rename_attributes(**attr)\n\n    # options for the layouts\n    self.layout_type = attr.get('layout', None)\n    self.k = attr.get('force', None,)\n    self.fixed = attr.get('fixed', None)\n    self.iterations = attr.get('iterations', 50)\n    self.threshold = attr.get('threshold', 1e-4)\n    self.weight = attr.get('weight', None)\n    self.dimension = attr.get('dimension', 2)\n    self.seed = attr.get('seed', None)\n    self.positions = attr.get('positions', None)\n    self.radius = attr.get('radius', 1.0)\n    self.direction = attr.get('direction', 1.0)\n    self.start_angle = attr.get('start_angle', 0.0)\n\n    # TODO: allow also higher dimensional layouts\n    if self.dimension &gt; 2:\n        print('Currently only plots with maximum dimension 2 are supported!')\n        self.dimension = 2\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.circular","title":"<code>circular</code>","text":"<p>Position nodes on a circle with given radius.</p> <p>This algorithm can be enabled with the keywords: <code>circular</code>, <code>circle</code>, <code>ring</code>, <code>lattice-1d</code>, <code>1d-lattice</code>, <code>lattice</code></p> <p>Other Parameters:</p> Name Type Description <code>radius</code> <code>float</code> <p>Sets the radius of the circle on which nodes are positioned. Defaults to 1.0.</p> <code>direction</code> <code>float</code> <p>Sets the direction in which nodes are placed on the circle. 1.0 for clockwise (default) and -1.0 for counter-clockwise direction. Defaults to 1.0.</p> <code>start_angle</code> <code>float</code> <p>Sets the angle of the first node relative to the 3pm position on a clock. and -1.0 for counter-clockwise direction. Defaults to 90.0.</p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def circular(self):\n    \"\"\"Position nodes on a circle with given radius.\n\n    This algorithm can be enabled with the keywords: `circular`, `circle`, `ring`, `lattice-1d`, `1d-lattice`, `lattice`\n\n    Keyword Args:\n        radius (float): Sets the radius of the circle on which nodes\n            are positioned. Defaults to 1.0.\n        direction (float): Sets the direction in which nodes are placed on the circle. 1.0 for clockwise (default)\n            and -1.0 for counter-clockwise direction. Defaults to 1.0.\n        start_angle (float): Sets the angle of the first node relative to the 3pm position on a clock.\n            and -1.0 for counter-clockwise direction. Defaults to 90.0.\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n\n    n = len(self.nodes)\n    rad = 2.0 * np.pi / n\n    rotation = (90.0 - self.start_angle*self.direction) * np.pi / 180.0\n    layout = {}\n\n    for i in range(n):\n        x = self.radius * np.cos(rotation - i*rad*self.direction)\n        y = self.radius * np.sin(rotation - i*rad*self.direction)\n        layout[self.nodes[i]] = (x,y)\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.fruchterman_reingold","title":"<code>fruchterman_reingold</code>","text":"<p>Position nodes using Fruchterman-Reingold force-directed algorithm.</p> <p>In this algorithm, the nodes are represented by steel rings and the edges are springs between them. The attractive force is analogous to the spring force and the repulsive force is analogous to the electrical force. The basic idea is to minimize the energy of the system by moving the nodes and changing the forces between them.</p> <p>This algorithm can be enabled with the keywords: <code>Fruchterman-Reingold</code>, <code>fruchterman_reingold</code>, <code>fr</code>, <code>spring_layout</code>, <code>spring layout</code>, <code>FR</code></p> <p>Other Parameters:</p> Name Type Description <code>force</code> <code>float</code> <p>Optimal distance between nodes. If None the distance is set to 1/sqrt(n) where n is the number of nodes.  Increase this value to move nodes farther apart.</p> <code>positions</code> <code>dict</code> <p>Initial positions for nodes as a dictionary with node as keys and values as a coordinate list or tuple.  If None, then use random initial positions.</p> <code>fixed</code> <code>list</code> <p>Nodes to keep fixed at initial position.</p> <code>iterations</code> <code>int</code> <p>Maximum number of iterations taken. Defaults to 50.</p> <code>threshold</code> <code>float</code> <p>Threshold for relative error in node position changes.  The iteration stops if the error is below this threshold. Defaults to 1e-4.</p> <code>weight</code> <code>string</code> <p>The edge attribute that holds the numerical value used for the edge weight.  If None, then all edge weights are 1.</p> <code>dimension</code> <code>int</code> <p>Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.</p> <code>seed</code> <code>int</code> <p>Set the random state for deterministic node layouts. If int, <code>seed</code> is the seed used by the random number generator, if None, the a random seed by created by the numpy random number generator is used.</p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def fruchterman_reingold(self):\n    \"\"\"Position nodes using Fruchterman-Reingold force-directed algorithm.\n\n    In this algorithm, the nodes are represented by steel rings and the\n    edges are springs between them. The attractive force is analogous to the\n    spring force and the repulsive force is analogous to the electrical\n    force. The basic idea is to minimize the energy of the system by moving\n    the nodes and changing the forces between them.\n\n    This algorithm can be enabled with the keywords: `Fruchterman-Reingold`,\n    `fruchterman_reingold`, `fr`, `spring_layout`, `spring layout`, `FR`\n\n    Keyword Args:\n        force (float): Optimal distance between nodes. If None the distance is set to\n            1/sqrt(n) where n is the number of nodes.  Increase this value to move\n            nodes farther apart.\n        positions (dict): Initial positions for nodes as a dictionary with node as keys and values\n            as a coordinate list or tuple.  If None, then use random initial\n            positions.\n        fixed (list): Nodes to keep fixed at initial position.\n        iterations (int): Maximum number of iterations taken. Defaults to 50.\n        threshold (float): Threshold for relative error in node position changes.  The iteration\n            stops if the error is below this threshold. Defaults to 1e-4.\n        weight (string): The edge attribute that holds the numerical value used for the edge\n            weight.  If None, then all edge weights are 1.\n        dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n        seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n            the seed used by the random number generator, if None, the a random seed\n            by created by the numpy random number generator is used.\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n\n    # convert adjacency matrix\n    self.adjacency_matrix = self.adjacency_matrix.astype(float)\n\n    if self.fixed is not None:\n        self.fixed = np.asarray([self.nodes.index(v) for v in self.fixed])\n\n    if self.positions is not None:\n        # Determine size of existing domain to adjust initial positions\n        _size = max(coord for t in layout.values() for coord in t) # type: ignore\n        if _size == 0:\n            _size = 1\n        np.random.seed(self.seed)\n        self.layout = np.random.rand(\n            len(self.nodes), self.dimension) * _size # type: ignore\n\n        for i, n in enumerate(self.nodes):\n            if n in self.positions:\n                self.layout[i] = np.asarray(self.positions[n])\n    else:\n        self.layout = None\n        _size = 0\n\n    if self.k is None and self.fixed is not None:\n        # We must adjust k by domain size for layouts not near 1x1\n        self.k = _size / np.sqrt(len(self.nodes))\n\n    try:\n        # Sparse matrix\n        if len(self.nodes) &lt; 500:  # sparse solver for large graphs\n            raise ValueError\n        layout = self._sparse_fruchterman_reingold()\n    except:\n        layout = self._fruchterman_reingold()\n\n    layout = dict(zip(self.nodes, layout))\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.generate_layout","title":"<code>generate_layout</code>","text":"<p>Function to pick and generate the right layout.</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def generate_layout(self):\n    \"\"\"Function to pick and generate the right layout.\"\"\"\n    # method names\n    names_rand = ['Random', 'random', 'rand', None]\n    names_fr = ['Fruchterman-Reingold', 'fruchterman_reingold', 'fr',\n                'spring_layout', 'spring layout', 'FR']\n    names_circular = ['circular', 'circle', 'ring', '1d-lattice', 'lattice-1d']\n    names_grid = ['grid', '2d-lattice', 'lattice-2d']\n    # check which layout should be plotted\n    if self.layout_type in names_rand:\n        self.layout = self.random()\n    elif self.layout_type in names_circular or (self.layout_type == 'lattice' and self.dimension == 1):\n        self.layout = self.circular()\n    elif self.layout_type in names_grid or (self.layout_type == 'lattice' and self.dimension == 2):\n        self.layout = self.grid()\n    elif self.layout_type in names_fr:\n        self.layout = self.fruchterman_reingold()\n\n    # print(self.layout)\n    return self.layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.grid","title":"<code>grid</code>","text":"<p>Position nodes on a two-dimensional grid</p> <p>This algorithm can be enabled with the keywords: <code>grid</code>, <code>lattice-2d</code>, <code>2d-lattice</code>, <code>lattice</code></p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def grid(self):\n    \"\"\"Position nodes on a two-dimensional grid\n\n    This algorithm can be enabled with the keywords: `grid`, `lattice-2d`, `2d-lattice`, `lattice`\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n\n    n = len(self.nodes)\n    width = 1.0\n\n    # number of nodes in horizontal/vertical direction\n    k = np.floor(np.sqrt(n))\n    dist = width / k\n    layout = {}\n\n    i = 0\n    for i in range(n):\n        layout[self.nodes[i]] = ((i%k) *dist, -(np.floor(i/k))*dist)\n        i += 1\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.random","title":"<code>random</code>","text":"<p>Position nodes uniformly at random in the unit square.</p> <p>For every node, a position is generated by choosing each of dimension coordinates uniformly at random on the interval \\([0.0, 1.0)\\).</p> <p>This algorithm can be enabled with the keywords: <code>Random</code>, <code>random</code>, <code>rand</code>, or <code>None</code></p> <p>Other Parameters:</p> Name Type Description <code>dimension</code> <code>int</code> <p>Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.</p> <code>seed</code> <code>int</code> <p>Set the random state for deterministic node layouts. If int, <code>seed</code> is the seed used by the random number generator, if None, the a random seed by created by the numpy random number generator is used.</p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def random(self):\n    \"\"\"Position nodes uniformly at random in the unit square.\n\n    For every node, a position is generated by choosing each of dimension\n    coordinates uniformly at random on the interval $[0.0, 1.0)$.\n\n    This algorithm can be enabled with the keywords: `Random`,\n    `random`, `rand`, or `None`\n\n    Keyword Args:\n        dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n        seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n            the seed used by the random number generator, if None, the a random\n            seed by created by the numpy random number generator is used.\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n    np.random.seed(self.seed)\n    layout = np.random.rand(len(self.nodes), self.dimension)\n    return dict(zip(self.nodes, layout))\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.rename_attributes","title":"<code>rename_attributes</code>  <code>staticmethod</code>","text":"<p>Rename layout attributes.</p> <p>In the style dictionary multiple keywords can be used to address attributes. These keywords will be converted to an unique key word, used in the remaining code.</p> keys other valid keys fixed <code>fixed_nodes</code>, <code>fixed_vertices</code>, <code>fixed_n</code>, <code>fixed_v</code> positions <code>initial_positions</code>, <code>node_positions</code> <code>vertex_positions</code>, <code>n_positions</code>, <code>v_positions</code> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>@staticmethod\ndef rename_attributes(**kwds):\n    \"\"\"Rename layout attributes.\n\n    In the style dictionary multiple keywords can be used to address\n    attributes. These keywords will be converted to an unique key word,\n    used in the remaining code.\n\n    | keys | other valid keys |\n    | ---- | ---------------- |\n    | fixed | `fixed_nodes`, `fixed_vertices`, `fixed_n`, `fixed_v` |\n    | positions | `initial_positions`, `node_positions` `vertex_positions`, `n_positions`, `v_positions` |\n    \"\"\"\n    names = {'fixed': ['fixed_nodes', 'fixed_vertices',\n                       'fixed_v', 'fixed_n'],\n             'positions': ['initial_positions', 'node_positions',\n                           'vertex_positions', 'n_positions',\n                           'v_positions'],\n             'layout_': ['layout_'],\n             }\n\n    _kwds = {}\n    del_keys = []\n    for key, value in kwds.items():\n        for attr, name_list in names.items():\n            for name in name_list:\n                if name in key and name[0] == key[0]:\n                    _kwds[key.replace(name, attr).replace(\n                        'layout_', '')] = value\n                    del_keys.append(key)\n                    break\n    # remove the replaced keys from the dict\n    for key in del_keys:\n        del kwds[key]\n\n    return {**_kwds, **kwds}\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.layout","title":"<code>layout</code>","text":"<p>Function to generate a layout for the network.</p> <p>This function generates a layout configuration for the nodes in the network. Thereby, different layouts and options can be chosen. The layout function is directly included in the plot function or can be separately called.</p> <p>The layout function supports different network types and layout algorithm. Currently supported networks are:</p> <ul> <li><code>cnet</code>,</li> <li><code>networkx</code>,</li> <li><code>igraph</code>,</li> <li><code>pathpyG</code></li> <li>node/edge list</li> </ul> <p>Currently supported algorithms are:</p> <ul> <li>Fruchterman-Reingold force-directed algorithm</li> <li>Uniformly at random node positions</li> </ul> <p>The appearance of the layout can be modified by keyword arguments which will be explained in more detail below.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>network object</code> <p>Network to be drawn. The network can be a <code>cnet</code>, <code>networkx</code>, <code>igraph</code>, <code>pathpy</code> object, or a tuple of a node list and edge list.</p> required <code>**kwds</code> <code>Optional dict</code> <p>Attributes used to modify the appearance of the layout. For details see below.</p> <code>{}</code>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.layout--layout","title":"Layout:","text":"<p>The layout can be modified by the following keyword arguments: Note:      All layout arguments can be entered with or without <code>layout_</code> at the beginning, e.g. <code>layout_iterations</code> is equal to <code>iterations</code></p> <p>Other Parameters:</p> Name Type Description <code>layout</code> <code>Optional dict or string</code> <p>A dictionary with the node positions on a 2-dimensional plane. The key value of the dict represents the node id while the value represents a tuple of coordinates (e.g. \\(n = (x,y)\\)). The initial layout can be placed anywhere on the 2-dimensional plane.</p> <p>Instead of a dictionary, the algorithm used for the layout can be defined via a string value. Currently, supported are:</p> <ul> <li>Random layout, where the nodes are uniformly at random placed in the     unit square. </li> <li>Fruchterman-Reingold force-directed algorithm. In this algorithm, the     nodes are represented by steel rings and the edges are springs between     them. The attractive force is analogous to the spring force and the     repulsive force is analogous to the electrical force. The basic idea is     to minimize the energy of the system by moving the nodes and changing     the forces between them. </li> </ul> <p>The algorithm can be enabled with the keywords: | Algorithms | Keywords | | ---------- | -------- | | Random | <code>Random</code>, <code>random</code>, <code>rand</code>, <code>None</code> | |Fruchterman-Reingold | <code>Fruchterman-Reingold</code>, <code>fruchterman_reingold</code>, <code>fr spring_layout</code>, <code>spring layout</code>, <code>FR</code> |</p> <code>force</code> <code>float</code> <p>Optimal distance between nodes.  If None the distance is set to 1/sqrt(n) where n is the number of nodes.  Increase this value to move nodes farther apart.</p> <code>positions</code> <code>dict</code> <p>Initial positions for nodes as a dictionary with node as keys and values as a coordinate list or tuple.  If None, then use random initial positions.</p> <code>fixed</code> <code>list</code> <p>Nodes to keep fixed at initial position.</p> <code>iterations</code> <code>int</code> <p>Maximum number of iterations taken. Defaults to 50.</p> <code>threshold</code> <code>float</code> <p>Threshold for relative error in node position changes.  The iteration stops if the error is below this threshold. Defaults to 1e-4.</p> <code>weight</code> <code>string</code> <p>or None, optional (default = None) The edge attribute that holds the numerical value used for the edge weight. If None, then all edge weights are 1.</p> <code>dimension</code> <code>int</code> <p>Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.</p> <code>seed</code> <code>int</code> <p>Set the random state for deterministic node layouts. If int, <code>seed</code> is the seed used by the random number generator, if None, the a random seed by created by the numpy random number generator is used.</p> <p>In the layout style dictionary multiple keywords can be used to address attributes. These keywords will be converted to an unique key word, used in the remaining code.</p> keys other valid keys fixed <code>fixed_nodes</code>, <code>fixed_vertices</code>, <code>fixed_n</code>, <code>fixed_v</code> positions <code>initial_positions</code>, <code>node_positions</code>, <code>vertex_positions</code>, <code>n_positions</code>, <code>v_positions</code> <p>Examples:</p> <p>For illustration purpose a similar network as in the <code>python-igraph</code> tutorial is used. Instead of <code>igraph</code>, the <code>cnet</code> module is used for creating the network.</p> <p>Create an empty network object, and add some edges.</p> <pre><code>&gt;&gt;&gt; net = Network(name = 'my tikz test network',directed=True)\n&gt;&gt;&gt; net.add_edges_from([('ab','a','b'), ('ac','a','c'), ('cd','c','d'),\n...                     ('de','d','e'), ('ec','e','c'), ('cf','c','f'),\n...                     ('fa','f','a'), ('fg','f','g'),('gg','g','g'),\n...                     ('gd','g','d')])\n</code></pre> <p>Now a layout can be generated:</p> <pre><code>&gt;&gt;&gt; layout(net)\n{'b': array([0.88878309, 0.15685131]), 'd': array([0.4659341 , 0.79839535]),\n'c': array([0.60386662, 0.40727962]), 'e': array([0.71073353, 0.65608203]),\n'g': array([0.42663927, 0.47412449]), 'f': array([0.48759769, 0.86787594]),\n'a': array([0.84154488, 0.1633732 ])}\n</code></pre> <p>Per default, the node positions are assigned uniform random. In order to create a layout, the layout methods of the packages can be used, or the position of the nodes can be directly assigned, in form of a dictionary, where the key is the <code>node_id</code> and the value is a tuple of the node position in \\(x\\) and \\(y\\).</p> <p>Let us generate a force directed layout (e.g. Fruchterman-Reingold):</p> <pre><code>&gt;&gt;&gt; layout(net, layout='fr')\n{'g': array([-0.77646408,  1.71291126]), 'c': array([-0.18639655,0.96232326]),\n'f': array([0.33394308, 0.93778681]), 'e': array([0.09740098, 1.28511973]),\n'a': array([1.37933158, 0.23171857]), 'b': array([ 2.93561876,-0.46183461]),\n'd': array([-0.29329793,  1.48971303])}\n</code></pre> <p>Note, instead of the command <code>fr</code> also the command <code>Fruchterman-Reingold</code> or any other command mentioned above can be used. For more information see table above.</p> <p>In order to keep the properties of the layout for your network separate from the network itself, you can simply set up a Python dictionary containing the keyword arguments you would pass to <code>layout</code> and then use the double asterisk (**) operator to pass your specific layout attributes to <code>layout</code>:</p> <pre><code>&gt;&gt;&gt; layout_style = {}\n&gt;&gt;&gt; layout_style['layout'] = 'Fruchterman-Reingold'\n&gt;&gt;&gt; layout_style['seed'] = 1\n&gt;&gt;&gt; layout_style['iterations'] = 100\n&gt;&gt;&gt; layout(net,**layout_style)\n{'d': array([-0.31778276, 1.78246882]), 'f': array([-0.8603259, 0.82328291]),\n'c': array([-0.4423771 , 1.21203895]), 'e': array([-0.79934355, 1.49000119]),\n'g': array([0.43694799, 1.51428788]), 'a': array([-2.15517293, 0.23948823]),\n'b': array([-3.84803812, -0.71628417])}\n</code></pre> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def layout(network, **kwds):\n    \"\"\"Function to generate a layout for the network.\n\n    This function generates a layout configuration for the nodes in the\n    network. Thereby, different layouts and options can be chosen. The layout\n    function is directly included in the plot function or can be separately\n    called.\n\n    The layout function supports different network types and layout algorithm.\n    Currently supported networks are:\n\n    - `cnet`,\n    - `networkx`,\n    - `igraph`,\n    - `pathpyG`\n    - node/edge list\n\n    Currently supported algorithms are:\n\n    - Fruchterman-Reingold force-directed algorithm\n    - Uniformly at random node positions\n\n    The appearance of the layout can be modified by keyword arguments which will\n    be explained in more detail below.\n\n    Args:\n        network (network object): Network to be drawn. The network can be a `cnet`, `networkx`, `igraph`, `pathpy` object, or a tuple of a node list and edge list.\n        **kwds (Optional dict): Attributes used to modify the appearance of the layout. For details see below.\n\n    # Layout:\n\n    The layout can be modified by the following keyword arguments:\n    Note: \n        All layout arguments can be entered with or without `layout_` at the beginning, e.g. `layout_iterations` is equal to `iterations`\n\n    Keyword Args:\n        layout (Optional dict or string): A dictionary with the node positions on a 2-dimensional plane. The\n            key value of the dict represents the node id while the value\n            represents a tuple of coordinates (e.g. $n = (x,y)$). The initial\n            layout can be placed anywhere on the 2-dimensional plane.\n\n            Instead of a dictionary, the algorithm used for the layout can be defined\n            via a string value. Currently, supported are:\n\n            - **Random layout**, where the nodes are uniformly at random placed in the\n                unit square. \n            - **Fruchterman-Reingold force-directed algorithm**. In this algorithm, the\n                nodes are represented by steel rings and the edges are springs between\n                them. The attractive force is analogous to the spring force and the\n                repulsive force is analogous to the electrical force. The basic idea is\n                to minimize the energy of the system by moving the nodes and changing\n                the forces between them. \n\n            The algorithm can be enabled with the keywords:\n            | Algorithms | Keywords |\n            | ---------- | -------- |\n            | Random | `Random`, `random`, `rand`, `None` |\n            |Fruchterman-Reingold | `Fruchterman-Reingold`, `fruchterman_reingold`, `fr spring_layout`, `spring layout`, `FR` |\n\n        force (float): Optimal distance between nodes.  If None the distance is set to\n            1/sqrt(n) where n is the number of nodes.  Increase this value to move\n            nodes farther apart.\n        positions (dict): Initial positions for nodes as a dictionary with node as keys and values\n            as a coordinate list or tuple.  If None, then use random initial\n            positions.\n        fixed (list): Nodes to keep fixed at initial position.\n        iterations (int): Maximum number of iterations taken. Defaults to 50.\n        threshold (float): Threshold for relative error in node position changes.  The iteration\n            stops if the error is below this threshold. Defaults to 1e-4.\n        weight (string):  or None, optional (default = None)\n            The edge attribute that holds the numerical value used for the edge\n            weight. If None, then all edge weights are 1.\n        dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n        seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n            the seed used by the random number generator, if None, the a random seed\n            by created by the numpy random number generator is used.\n\n    In the layout style dictionary multiple keywords can be used to address\n    attributes. These keywords will be converted to an unique key word,\n    used in the remaining code.\n\n    | keys | other valid keys |\n    | ---- | ---------------- |\n    | fixed | `fixed_nodes`, `fixed_vertices`, `fixed_n`, `fixed_v` |\n    | positions| `initial_positions`, `node_positions`, `vertex_positions`, `n_positions`, `v_positions` |\n\n    Examples:\n        For illustration purpose a similar network as in the `python-igraph` tutorial\n        is used. Instead of `igraph`, the `cnet` module is used for creating the\n        network.\n\n        Create an empty network object, and add some edges.\n\n        &gt;&gt;&gt; net = Network(name = 'my tikz test network',directed=True)\n        &gt;&gt;&gt; net.add_edges_from([('ab','a','b'), ('ac','a','c'), ('cd','c','d'),\n        ...                     ('de','d','e'), ('ec','e','c'), ('cf','c','f'),\n        ...                     ('fa','f','a'), ('fg','f','g'),('gg','g','g'),\n        ...                     ('gd','g','d')])\n\n        Now a layout can be generated:\n\n        &gt;&gt;&gt; layout(net)\n        {'b': array([0.88878309, 0.15685131]), 'd': array([0.4659341 , 0.79839535]),\n        'c': array([0.60386662, 0.40727962]), 'e': array([0.71073353, 0.65608203]),\n        'g': array([0.42663927, 0.47412449]), 'f': array([0.48759769, 0.86787594]),\n        'a': array([0.84154488, 0.1633732 ])}\n\n        Per default, the node positions are assigned uniform random. In order to\n        create a layout, the layout methods of the packages can be used, or the\n        position of the nodes can be directly assigned, in form of a dictionary,\n        where the key is the `node_id` and the value is a tuple of the node position\n        in $x$ and $y$.\n\n        Let us generate a force directed layout (e.g. Fruchterman-Reingold):\n\n        &gt;&gt;&gt; layout(net, layout='fr')\n        {'g': array([-0.77646408,  1.71291126]), 'c': array([-0.18639655,0.96232326]),\n        'f': array([0.33394308, 0.93778681]), 'e': array([0.09740098, 1.28511973]),\n        'a': array([1.37933158, 0.23171857]), 'b': array([ 2.93561876,-0.46183461]),\n        'd': array([-0.29329793,  1.48971303])}\n\n        Note, instead of the command `fr` also the command\n        `Fruchterman-Reingold` or any other command mentioned above can be\n        used. For more information see table above.\n\n        In order to keep the properties of the layout for your network separate from\n        the network itself, you can simply set up a Python dictionary containing the\n        keyword arguments you would pass to [`layout`][pathpyG.visualisations.layout.layout] and then use the\n        double asterisk (**) operator to pass your specific layout attributes to\n        [`layout`][pathpyG.visualisations.layout.layout]:\n\n        &gt;&gt;&gt; layout_style = {}\n        &gt;&gt;&gt; layout_style['layout'] = 'Fruchterman-Reingold'\n        &gt;&gt;&gt; layout_style['seed'] = 1\n        &gt;&gt;&gt; layout_style['iterations'] = 100\n        &gt;&gt;&gt; layout(net,**layout_style)\n        {'d': array([-0.31778276, 1.78246882]), 'f': array([-0.8603259, 0.82328291]),\n        'c': array([-0.4423771 , 1.21203895]), 'e': array([-0.79934355, 1.49000119]),\n        'g': array([0.43694799, 1.51428788]), 'a': array([-2.15517293, 0.23948823]),\n        'b': array([-3.84803812, -0.71628417])}\n    \"\"\"\n    # initialize variables\n    _weight = kwds.get('weight', None)\n    if _weight is None:\n        _weight = kwds.get('layout_weight', None)\n\n    # check type of network\n    if 'cnet' in str(type(network)):\n        # log.debug('The network is of type \"cnet\".')\n        nodes = list(network.nodes)\n        adjacency_matrix = network.adjacency_matrix(weight=_weight)\n\n    elif 'networkx' in str(type(network)):\n        # log.debug('The network is of type \"networkx\".')\n        nodes = list(network.nodes())\n        import networkx as nx\n        adjacency_matrix = nx.adjacency_matrix(network, weight=_weight) # type: ignore\n    elif 'igraph' in str(type(network)):\n        # log.debug('The network is of type \"igraph\".')\n        nodes = list(range(len(network.vs)))\n        from scipy.sparse import coo_matrix\n        A = np.array(network.get_adjacency(attribute=_weight).data)\n        adjacency_matrix = coo_matrix(A)\n    elif 'pathpyG' in str(type(network)):\n        # log.debug('The network is of type \"pathpy\".')\n        nodes = list(network.nodes)\n        if _weight is not None:\n            _w = True\n        else:\n            _w = False\n        adjacency_matrix = network.get_sparse_adj_matrix()\n    # elif isinstance(network, tuple):\n    #     # log.debug('The network is of type \"list\".')\n    #     nodes = network[0]\n    #     from collections import OrderedDict\n    #     edges = OrderedDict()\n    #     for e in network[1]:\n    #         edges[e] = e\n\n    else:\n        print('Type of the network could not be determined.'\n                  ' Currently only \"cnet\", \"networkx\",\"igraph\", \"pathpy\"'\n                  ' and \"node/edge list\" is supported!')\n        raise NotImplementedError\n\n    # create layout class\n    layout = Layout(nodes, adjacency_matrix, **kwds)\n    # return the layout\n    return layout.generate_layout()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/","title":"network_plots","text":"<p>Network plot classes.</p>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>class NetworkPlot(PathPyPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, network: Graph, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        self._compute_edge_data()\n        self._compute_node_data()\n        self._compute_layout()\n        self._cleanup_config()\n        self._cleanup_data()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the nodes.\"\"\"\n        # initialize values\n        nodes: dict = {}\n        attributes: set = {\"color\", \"size\", \"opacity\", \"label\"}\n        attr: defaultdict = defaultdict(dict)\n\n        # get attributes categories from pathpyg\n        categories = {a.replace(\"node_\", \"\") for a in self.network.node_attrs()}.intersection(attributes)\n\n        # add node data to data dict\n        self._get_node_data(nodes, attributes, attr, categories)\n\n        # convert needed attributes to useful values\n        attr[\"color\"] = self._convert_color(attr[\"color\"], mode=\"node\")\n        attr[\"opacity\"] = self._convert_opacity(attr[\"opacity\"], mode=\"node\")\n        attr[\"size\"] = self._convert_size(attr[\"size\"], mode=\"node\")\n        attr[\"label\"] = self._convert_label(attr[\"label\"], mode=\"node\")\n\n        # update data dict with converted attributes\n        for attribute in attr:\n            for key, value in attr[attribute].items():\n                nodes[key][attribute] = value\n\n        # save node data\n        self.data[\"nodes\"] = nodes\n\n    def _get_node_data(\n        self,\n        nodes: dict,\n        attributes: set,\n        attr: defaultdict,\n        categories: set,\n    ) -&gt; None:\n        \"\"\"Extract node data from network.\"\"\"\n        for uid in self.network.nodes:\n            nodes[uid] = {\"uid\": str(uid)}\n\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"node_{attribute}\", uid].item() if attribute in categories else None\n                )\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the edges.\"\"\"\n        # initialize values\n        edges: dict = {}\n        attributes: set = {\"weight\", \"color\", \"size\", \"opacity\"}\n        attr: defaultdict = defaultdict(dict)\n\n        # get attributes categories from pathpyg\n        categories: set = {a.replace(\"edge_\", \"\") for a in self.network.edge_attrs()}.intersection(attributes)\n\n        # add edge data to data dict\n        self._get_edge_data(edges, attributes, attr, categories)\n\n        # convert needed attributes to useful values\n        attr[\"weight\"] = self._convert_weight(attr[\"weight\"], mode=\"edge\")\n        attr[\"color\"] = self._convert_color(attr[\"color\"], mode=\"edge\")\n        attr[\"opacity\"] = self._convert_opacity(attr[\"opacity\"], mode=\"edge\")\n        attr[\"size\"] = self._convert_size(attr[\"size\"], mode=\"edge\")\n\n        # update data dict with converted attributes\n        for attribute in attr:\n            for key, value in attr[attribute].items():\n                edges[key][attribute] = value\n\n        # save edge data\n        self.data[\"edges\"] = edges\n\n    def _get_edge_data(\n        self,\n        edges: dict,\n        attributes: set,\n        attr: defaultdict,\n        categories: set,\n    ) -&gt; None:\n        \"\"\"Extract edge data from network.\"\"\"\n        for u, v in self.network.edges:\n            uid = f\"{u}-{v}\"\n            edges[uid] = {\n                \"uid\": uid,\n                \"source\": str(u),\n                \"target\": str(v),\n            }\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"edge_{attribute}\", u, v].item() if attribute in categories else None\n                )\n\n    def _convert_weight(self, weight: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert weight to float.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_weight\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (int, float)):\n            weight = {k: style for k in weight}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            weight.update(**{k: v for k, v in style.items() if k in weight})\n\n        # return all weights which are not None\n        return {k: v if v is not None else 1 for k, v in weight.items()}\n\n    def _convert_color(self, color: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert colors to hex if rgb.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_color\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (str, int, float, tuple)):\n            color = {k: style for k in color}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            color.update(**{k: v for k, v in style.items() if k in color})\n\n        # check if new attribute is a list\n        elif isinstance(style, list):\n            for i, k in enumerate(color):\n                try:\n                    color[k] = style[i]\n                except IndexError:\n                    pass\n\n        # check if numerical values are given\n        values = [v for v in color.values() if isinstance(v, (int, float))]\n\n        if values:\n            # load colormap to map numerical values to color\n            cmap = self.config.get(f\"{mode}_cmap\", Colormap())\n            cdict = {values[i]: tuple(c[:3]) for i, c in enumerate(cmap(values, bytes=True))}\n\n        # convert colors to hex if not already string\n        for key, value in color.items():\n            if isinstance(value, tuple):\n                color[key] = rgb_to_hex(value)\n            elif isinstance(value, (int, float)):\n                color[key] = rgb_to_hex(cdict[value])\n\n        # return all colors wich are not None\n        return {k: v for k, v in color.items() if v is not None}\n\n    def _convert_opacity(self, opacity: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert opacity to float.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_opacity\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (int, float)):\n            opacity = {k: style for k in opacity}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            opacity.update(**{k: v for k, v in style.items() if k in opacity})\n\n        # return all colors wich are not None\n        return {k: v for k, v in opacity.items() if v is not None}\n\n    def _convert_size(self, size: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert size to float.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_size\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (int, float)):\n            size = {k: style for k in size}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            size.update(**{k: v for k, v in style.items() if k in size})\n\n        # return all colors wich are not None\n        return {k: v for k, v in size.items() if v is not None}\n\n    def _convert_label(self, label: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert label to string.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_label\")\n\n        # check if new attribute is a single object\n        if isinstance(style, str):\n            label = {k: style for k in label}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            label.update(**{k: v for k, v in style.items() if k in label})\n\n        # check if new attribute is a list\n        elif isinstance(style, list):\n            for i, k in enumerate(label):\n                try:\n                    label[k] = style[i]\n                except IndexError:\n                    pass\n\n        # return all labels wich are not None\n        return {k: v for k, v in label.items() if v is not None}\n\n    def _compute_layout(self) -&gt; None:\n        \"\"\"Create layout.\"\"\"\n        # get layout form the config\n        layout = self.config.get(\"layout\", \"rand\")\n\n        # if no layout is considered stop this process\n        if layout is None:\n            return\n\n        # get layout dict for each node\n        if isinstance(layout, str):\n            layout = network_layout(self.network, layout=layout)\n        elif not isinstance(layout, dict):\n            logger.error(\"The provided layout is not valid!\")\n            raise AttributeError\n\n        # update x,y position of the nodes\n        for uid, (_x, _y) in layout.items():\n            self.data[\"nodes\"][uid][\"x\"] = _x\n            self.data[\"nodes\"][uid][\"y\"] = _y\n\n    def _cleanup_config(self) -&gt; None:\n        \"\"\"Clean up final config file.\"\"\"\n        try:\n            directed = self.network.is_directed()\n        except NotImplementedError:\n            directed = False\n\n        if not self.config.get(\"directed\", None):\n            self.config[\"directed\"] = directed\n\n        if not self.config.get(\"curved\", None):\n            self.config[\"curved\"] = directed\n\n    def _cleanup_data(self) -&gt; None:\n        \"\"\"Clean up final data structure.\"\"\"\n        self.data[\"nodes\"] = list(self.data[\"nodes\"].values())\n        self.data[\"edges\"] = list(self.data[\"edges\"].values())\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def __init__(self, network: Graph, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.network = network\n    self.config = kwargs\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    self._compute_edge_data()\n    self._compute_node_data()\n    self._compute_layout()\n    self._cleanup_config()\n    self._cleanup_data()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.network_plots.NetworkPlot</code></p> <p>Network plot class for a temporal network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a temporal network.\"\"\"\n\n    _kind = \"temporal\"\n\n    def __init__(self, network: TemporalGraph, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__(network, **kwargs)\n\n    def _get_edge_data(self, edges: dict, attributes: set, attr: defaultdict, categories: set) -&gt; None:\n        \"\"\"Extract edge data from temporal network.\"\"\"\n        # TODO: Fix typing issue with temporal graphs\n        for u, v, t in self.network.temporal_edges:  # type: ignore\n            uid = f\"{u}-{v}-{t}\"\n            edges[uid] = {\n                \"uid\": uid,\n                \"source\": str(u),\n                \"target\": str(v),\n                \"start\": int(t),\n                \"end\": int(t) + 1,\n            }\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"edge_{attribute}\", u, v].item() if attribute in categories else None\n                )\n\n    def _get_node_data(self, nodes: dict, attributes: set, attr: defaultdict, categories: set) -&gt; None:\n        \"\"\"Extract node data from temporal network.\"\"\"\n\n        time = {e[2] for e in self.network.temporal_edges}\n\n        if self.config.get(\"end\", None) is None:\n            self.config[\"end\"] = int(max(time) + 1)\n\n        if self.config.get(\"start\", None) is None:\n            self.config[\"start\"] = int(min(time) - 1)\n\n        for uid in self.network.nodes:\n            nodes[uid] = {\n                \"uid\": uid,\n                \"start\": int(min(time) - 1),\n                \"end\": int(max(time) + 1),\n            }\n\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"node_{attribute}\", uid].item() if attribute in categories else None\n                )\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def __init__(self, network: TemporalGraph, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.network_plot","title":"<code>network_plot</code>","text":"<p>Plot a static network.</p> <p>This function generates a static plot of the network with various output formats including interactive HTML with d3js, tex file with tikz code, PDF from the tex source, and PNG based on matplotlib. The appearance of the plot can be modified using keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.core.Graph.Graph</code> <p>A <code>Graph</code> object to be plotted.</p> required <code>**kwargs</code> <code>typing.Any</code> <p>Keyword arguments to modify the appearance of the plot. Defaults to no attributes. For details see below.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pathpyG.visualisations.network_plots.NetworkPlot</code> <p>A plot object, the type of which depends on the output format chosen.</p>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.network_plot--keyword-arguments-to-modify-the-appearance-of-the-plot","title":"Keyword Arguments to modify the appearance of the plot","text":"<p>Nodes:</p> <ul> <li> <p><code>node_size</code> : diameter of the node</p> </li> <li> <p><code>node_color</code> : The fill color of the node. Possible values are:</p> <ul> <li> <p>A single color string referred to by name, RGB or RGBA code, for   instance <code>red</code> or <code>#a98d19</code> or <code>(12,34,102)</code>.</p> </li> <li> <p>A sequence of color strings referred to by name, RGB or RGBA code,   which will be used for each point's color recursively. For   instance <code>['green', 'yellow']</code> all points will be filled in green or   yellow, alternatively.</p> </li> <li> <p>A column name or position whose values will be used to color the   marker points according to a colormap.</p> </li> </ul> </li> <li> <p><code>node_cmap</code> : Colormap for node colors. If node colors are given as int   or float values the color will be assigned based on a colormap. Per   default the color map goes from red to green. Matplotlib colormaps or   seaborn color palettes can be used to style the node colors.</p> </li> <li> <p><code>node_opacity</code> : fill opacity of the node. The default is 1. The range   of the number lies between 0 and 1. Where 0 represents a fully   transparent fill and 1 a solid fill.</p> </li> </ul> <p>Edges</p> <ul> <li> <p><code>edge_size</code> : width of the edge</p> </li> <li> <p><code>edge_color</code> : The line color of the edge. Possible values are:</p> <ul> <li> <p>A single color string referred to by name, RGB or RGBA code, for   instance <code>red</code> or <code>#a98d19</code> or <code>(12,34,102)</code>.</p> </li> <li> <p>A sequence of color strings referred to by name, RGB or RGBA   code, which will be used for each point's color recursively. For   instance <code>['green','yellow']</code> all points will be filled in green or   yellow, alternatively.</p> </li> <li> <p>A column name or position whose values will be used to color the   marker points according to a colormap.</p> </li> </ul> </li> <li> <p><code>edge_cmap</code> : Colormap for edge colors. If node colors are given as int   or float values the color will be assigned based on a colormap. Per   default the color map goes from red to green. Matplotlib colormaps or   seaborn color palettes can be used to style the edge colors.</p> </li> <li> <p><code>edge_opacity</code> : line opacity of the edge. The default is 1. The range   of the number lies between 0 and 1. Where 0 represents a fully   transparent fill and 1 a solid fill.</p> </li> </ul> <p>General</p> <ul> <li> <p><code>keep_aspect_ratio</code></p> </li> <li> <p><code>margin</code></p> </li> <li> <p><code>layout</code></p> </li> </ul> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def network_plot(network: Graph, **kwargs: Any) -&gt; NetworkPlot:\n    \"\"\"Plot a static network.\n\n    This function generates a static plot of the network with various output\n    formats including interactive HTML with d3js, tex file with tikz code, PDF\n    from the tex source, and PNG based on matplotlib. The appearance of the\n    plot can be modified using keyword arguments.\n\n    Args:\n        network (Graph): A `Graph` object to be plotted.\n        **kwargs (Any): Keyword arguments to modify the appearance of the\n            plot. Defaults to no attributes. For details see below.\n\n    Returns:\n        A plot object, the type of which depends on the output format chosen.\n\n\n    # Keyword Arguments to modify the appearance of the plot\n    **Nodes:**\n\n    - `node_size` : diameter of the node\n\n    - `node_color` : The fill color of the node. Possible values are:\n\n        - A single color string referred to by name, RGB or RGBA code, for\n          instance `red` or `#a98d19` or `(12,34,102)`.\n\n        - A sequence of color strings referred to by name, RGB or RGBA code,\n          which will be used for each point's color recursively. For\n          instance `['green', 'yellow']` all points will be filled in green or\n          yellow, alternatively.\n\n        - A column name or position whose values will be used to color the\n          marker points according to a colormap.\n\n    - `node_cmap` : Colormap for node colors. If node colors are given as int\n      or float values the color will be assigned based on a colormap. Per\n      default the color map goes from red to green. Matplotlib colormaps or\n      seaborn color palettes can be used to style the node colors.\n\n    - `node_opacity` : fill opacity of the node. The default is 1. The range\n      of the number lies between 0 and 1. Where 0 represents a fully\n      transparent fill and 1 a solid fill.\n\n\n    **Edges**\n\n    - `edge_size` : width of the edge\n\n    - `edge_color` : The line color of the edge. Possible values are:\n\n        - A single color string referred to by name, RGB or RGBA code, for\n          instance `red` or `#a98d19` or `(12,34,102)`.\n\n        - A sequence of color strings referred to by name, RGB or RGBA\n          code, which will be used for each point's color recursively. For\n          instance `['green','yellow']` all points will be filled in green or\n          yellow, alternatively.\n\n        - A column name or position whose values will be used to color the\n          marker points according to a colormap.\n\n    - `edge_cmap` : Colormap for edge colors. If node colors are given as int\n      or float values the color will be assigned based on a colormap. Per\n      default the color map goes from red to green. Matplotlib colormaps or\n      seaborn color palettes can be used to style the edge colors.\n\n    - `edge_opacity` : line opacity of the edge. The default is 1. The range\n      of the number lies between 0 and 1. Where 0 represents a fully\n      transparent fill and 1 a solid fill.\n\n\n    **General**\n\n    - `keep_aspect_ratio`\n\n    - `margin`\n\n    - `layout`\n\n    \"\"\"\n    return NetworkPlot(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.static_plot","title":"<code>static_plot</code>","text":"<p>Plot a static network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def static_plot(network: Graph, **kwargs: Any) -&gt; NetworkPlot:\n    \"\"\"Plot a static network.\"\"\"\n    return StaticNetworkPlot(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.temporal_plot","title":"<code>temporal_plot</code>","text":"<p>Plot a temporal network.</p> <p>Temporal properties:</p> <ul> <li> <p><code>start</code> : start time of the simulation</p> </li> <li> <p><code>end</code> : end time of the simulation</p> </li> <li> <p><code>delta</code> : time needed for progressing one time step</p> </li> <li> <p><code>intervals</code> : number of numeric intervals</p> </li> </ul> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def temporal_plot(network: TemporalGraph, **kwargs: Any) -&gt; NetworkPlot:\n    \"\"\"Plot a temporal network.\n\n    **Temporal properties:**\n\n    - ``start`` : start time of the simulation\n\n    - ``end`` : end time of the simulation\n\n    - ``delta`` : time needed for progressing one time step\n\n    - ``intervals`` : number of numeric intervals\n\n    \"\"\"\n    return TemporalNetworkPlot(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/","title":"plot","text":"<p>Class to plot pathpy networks.</p>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot","title":"<code>PathPyPlot</code>","text":"<p>Abstract class for assemblig plots.</p>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot--attributes","title":"Attributes","text":"<p>data : dict     data of the plot object config : dict     configuration for the plot</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>class PathPyPlot:\n    \"\"\"Abstract class for assemblig plots.\n\n    Attributes\n    ----------\n    data : dict\n        data of the plot object\n    config : dict\n        configuration for the plot\n\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize plot class.\"\"\"\n        logger.debug(\"Initalize PathPyPlot class\")\n        self.data: dict = {}\n        self.config: dict = {}\n\n    @property\n    def _kind(self) -&gt; str:\n        \"\"\"Specify kind str. Must be overridden in child class.\"\"\"\n        raise NotImplementedError\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n        plot_backend = _get_plot_backend(_backend, filename)\n        plot_backend.plot(\n            deepcopy(self.data), self._kind, **deepcopy(self.config)\n        ).save(filename, **kwargs)\n\n    def show(self, **kwargs: Any) -&gt; None:\n        \"\"\"Show the plot on the device.\"\"\"\n        _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n        plot_backend = _get_plot_backend(_backend, None)\n        plot_backend.plot(\n            deepcopy(self.data), self._kind, **deepcopy(self.config)\n        ).show(**kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize plot class.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize plot class.\"\"\"\n    logger.debug(\"Initalize PathPyPlot class\")\n    self.data: dict = {}\n    self.config: dict = {}\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n    plot_backend = _get_plot_backend(_backend, filename)\n    plot_backend.plot(\n        deepcopy(self.data), self._kind, **deepcopy(self.config)\n    ).save(filename, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:\n    \"\"\"Show the plot on the device.\"\"\"\n    _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n    plot_backend = _get_plot_backend(_backend, None)\n    plot_backend.plot(\n        deepcopy(self.data), self._kind, **deepcopy(self.config)\n    ).show(**kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/","title":"utils","text":"<p>Helper functions for plotting.</p>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.Colormap","title":"<code>Colormap</code>","text":"<p>Very simple colormap class.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>class Colormap:\n    \"\"\"Very simple colormap class.\"\"\"\n\n    def __call__(\n        self,\n        values: list,\n        alpha: Optional[float] = None,\n        bytes: bool = False,\n    ) -&gt; list:\n        \"\"\"Return color value.\"\"\"\n        vmin, vmax = min(values), max(values)\n        if vmin == vmax:\n            vmin -= 1\n            vmax += 1\n        return [\n            self.color_tuple(v)\n            for v in ((x - vmin) / (vmax - vmin) * 100 for x in values)\n        ]\n\n    @staticmethod\n    def color_tuple(n: float) -&gt; tuple:\n        \"\"\"Return color ramp from green to red.\"\"\"\n        return (int((255 * n) * 0.01), int((255 * (100 - n)) * 0.01), 0, 255)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.Colormap.__call__","title":"<code>__call__</code>","text":"<p>Return color value.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def __call__(\n    self,\n    values: list,\n    alpha: Optional[float] = None,\n    bytes: bool = False,\n) -&gt; list:\n    \"\"\"Return color value.\"\"\"\n    vmin, vmax = min(values), max(values)\n    if vmin == vmax:\n        vmin -= 1\n        vmax += 1\n    return [\n        self.color_tuple(v)\n        for v in ((x - vmin) / (vmax - vmin) * 100 for x in values)\n    ]\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.Colormap.color_tuple","title":"<code>color_tuple</code>  <code>staticmethod</code>","text":"<p>Return color ramp from green to red.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>@staticmethod\ndef color_tuple(n: float) -&gt; tuple:\n    \"\"\"Return color ramp from green to red.\"\"\"\n    return (int((255 * n) * 0.01), int((255 * (100 - n)) * 0.01), 0, 255)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.hex_to_rgb","title":"<code>hex_to_rgb</code>","text":"<p>Convert hex string to rgb color tuple.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def hex_to_rgb(value: str) -&gt; tuple:\n    \"\"\"Convert hex string to rgb color tuple.\"\"\"\n    value = value.lstrip(\"#\")\n    _l = len(value)\n    return tuple(int(value[i : i + _l // 3], 16) for i in range(0, _l, _l // 3))\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.rgb_to_hex","title":"<code>rgb_to_hex</code>","text":"<p>Convert rgb color tuple to hex string.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def rgb_to_hex(rgb: tuple) -&gt; str:\n    \"\"\"Convert rgb color tuple to hex string.\"\"\"\n    return \"#%02x%02x%02x\" % rgb\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/","title":"_d3js","text":"<p>Initialize d3js plotting functions.</p>"},{"location":"reference/pathpyG/visualisations/_d3js/#pathpyG.visualisations._d3js.plot","title":"<code>plot</code>","text":"<p>Plot function.</p> Source code in <code>src/pathpyG/visualisations/_d3js/__init__.py</code> <pre><code>def plot(data: dict, kind: str = \"network\", **kwargs: Any) -&gt; Any:\n    \"\"\"Plot function.\"\"\"\n    return PLOT_CLASSES[kind](data, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/","title":"core","text":""},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot","title":"<code>D3jsPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Base class for plotting d3js objects.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>class D3jsPlot(PathPyPlot):\n    \"\"\"Base class for plotting d3js objects.\"\"\"\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        with open(filename, \"w+\") as new:\n            new.write(self.to_html())\n\n    def show(self, **kwargs: Any) -&gt; None:\n        \"\"\"Show the plot on the device.\"\"\"\n        if config[\"environment\"][\"interactive\"]:\n            from IPython.display import display_html, HTML\n\n            display_html(HTML(self.to_html()))\n        else:\n            # create temporal file\n            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n                # save html\n                self.save(temp_file.name)\n                # open the file\n                webbrowser.open(r\"file:///\" + temp_file.name)\n\n    def to_json(self) -&gt; str:\n        \"\"\"Convert data to json.\"\"\"\n        raise NotImplementedError\n\n    def to_html(self) -&gt; str:\n        \"\"\"Convert data to html.\"\"\"\n        # generate unique dom uids\n        dom_id = \"#x\" + uuid.uuid4().hex\n\n        # get path to the pathpy templates\n        template_dir = os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"_d3js/templates\"),\n        )\n\n        # get d3js version\n        local = self.config.get(\"d3js_local\", False)\n        if local:\n            d3js = os.path.join(template_dir, \"d3.v5.min.js\")\n        else:\n            d3js = \"https://d3js.org/d3.v5.min.js\"\n\n        # get template files\n        with open(os.path.join(template_dir, f\"{self._kind}.js\")) as template:\n            js_template = template.read()\n\n        with open(os.path.join(template_dir, \"setup.js\")) as template:\n            setup_template = template.read()\n\n        with open(os.path.join(template_dir, \"styles.css\")) as template:\n            css_template = template.read()\n\n        # load custom template\n        _template = self.config.get(\"template\", None)\n        if _template and os.path.isfile(_template):\n            with open(_template) as template:\n                js_template = template.read()\n\n        # load custom css template\n        _template = self.config.get(\"css\", None)\n        if _template and os.path.isfile(_template):\n            with open(_template) as template:\n                css_template += template.read()\n\n        # update config\n        self.config[\"selector\"] = dom_id\n        data = self.to_json()\n\n        # generate html file\n        html = \"&lt;style&gt;\\n\" + css_template + \"\\n&lt;/style&gt;\\n\"\n\n        # div environment for the plot object\n        html += f'\\n&lt;div id = \"{dom_id[1:]}\"&gt; &lt;/div&gt;\\n'\n\n        # add d3js library\n        html += f'&lt;script charset=\"utf-8\" src=\"{d3js}\"&gt;&lt;/script&gt;\\n'\n\n        # start JavaScript\n        html += '&lt;script charset=\"utf-8\"&gt;\\n'\n\n        # add setup code to run d3js in multiple environments\n        html += Template(setup_template).substitute(d3js=d3js)\n\n        # start d3 environment\n        html += \"require(['d3'], function(d3){ //START\\n\"\n\n        # add data and config\n        html += f\"const data = {data}\\n\"\n        html += f\"const config = {json.dumps(self.config)}\\n\"\n\n        # add JavaScript\n        html += js_template\n\n        # end d3 environment\n        html += \"\\n}); //END\\n\"\n\n        # end JavaScript\n        html += \"\\n&lt;/script&gt;\"\n\n        return html\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    with open(filename, \"w+\") as new:\n        new.write(self.to_html())\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:\n    \"\"\"Show the plot on the device.\"\"\"\n    if config[\"environment\"][\"interactive\"]:\n        from IPython.display import display_html, HTML\n\n        display_html(HTML(self.to_html()))\n    else:\n        # create temporal file\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            # save html\n            self.save(temp_file.name)\n            # open the file\n            webbrowser.open(r\"file:///\" + temp_file.name)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.to_html","title":"<code>to_html</code>","text":"<p>Convert data to html.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def to_html(self) -&gt; str:\n    \"\"\"Convert data to html.\"\"\"\n    # generate unique dom uids\n    dom_id = \"#x\" + uuid.uuid4().hex\n\n    # get path to the pathpy templates\n    template_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)),\n        os.path.normpath(\"_d3js/templates\"),\n    )\n\n    # get d3js version\n    local = self.config.get(\"d3js_local\", False)\n    if local:\n        d3js = os.path.join(template_dir, \"d3.v5.min.js\")\n    else:\n        d3js = \"https://d3js.org/d3.v5.min.js\"\n\n    # get template files\n    with open(os.path.join(template_dir, f\"{self._kind}.js\")) as template:\n        js_template = template.read()\n\n    with open(os.path.join(template_dir, \"setup.js\")) as template:\n        setup_template = template.read()\n\n    with open(os.path.join(template_dir, \"styles.css\")) as template:\n        css_template = template.read()\n\n    # load custom template\n    _template = self.config.get(\"template\", None)\n    if _template and os.path.isfile(_template):\n        with open(_template) as template:\n            js_template = template.read()\n\n    # load custom css template\n    _template = self.config.get(\"css\", None)\n    if _template and os.path.isfile(_template):\n        with open(_template) as template:\n            css_template += template.read()\n\n    # update config\n    self.config[\"selector\"] = dom_id\n    data = self.to_json()\n\n    # generate html file\n    html = \"&lt;style&gt;\\n\" + css_template + \"\\n&lt;/style&gt;\\n\"\n\n    # div environment for the plot object\n    html += f'\\n&lt;div id = \"{dom_id[1:]}\"&gt; &lt;/div&gt;\\n'\n\n    # add d3js library\n    html += f'&lt;script charset=\"utf-8\" src=\"{d3js}\"&gt;&lt;/script&gt;\\n'\n\n    # start JavaScript\n    html += '&lt;script charset=\"utf-8\"&gt;\\n'\n\n    # add setup code to run d3js in multiple environments\n    html += Template(setup_template).substitute(d3js=d3js)\n\n    # start d3 environment\n    html += \"require(['d3'], function(d3){ //START\\n\"\n\n    # add data and config\n    html += f\"const data = {data}\\n\"\n    html += f\"const config = {json.dumps(self.config)}\\n\"\n\n    # add JavaScript\n    html += js_template\n\n    # end d3 environment\n    html += \"\\n}); //END\\n\"\n\n    # end JavaScript\n    html += \"\\n&lt;/script&gt;\"\n\n    return html\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.to_json","title":"<code>to_json</code>","text":"<p>Convert data to json.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Convert data to json.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/","title":"network_plots","text":"<p>Network plots with d3js.</p>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._d3js.core.D3jsPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>class NetworkPlot(D3jsPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.data = data\n        self.config = kwargs\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Clen up data.\"\"\"\n        self.config.pop(\"node_cmap\", None)\n        self.config.pop(\"edge_cmap\", None)\n        for node in self.data[\"nodes\"]:\n            node.pop(\"x\", None)\n            node.pop(\"y\", None)\n\n    def to_json(self) -&gt; Any:\n        \"\"\"Convert data to json.\"\"\"\n        return json.dumps(self.data)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.data = data\n    self.config = kwargs\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Clen up data.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Clen up data.\"\"\"\n    self.config.pop(\"node_cmap\", None)\n    self.config.pop(\"edge_cmap\", None)\n    for node in self.data[\"nodes\"]:\n        node.pop(\"x\", None)\n        node.pop(\"y\", None)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot.to_json","title":"<code>to_json</code>","text":"<p>Convert data to json.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>def to_json(self) -&gt; Any:\n    \"\"\"Convert data to json.\"\"\"\n    return json.dumps(self.data)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._d3js.network_plots.NetworkPlot</code></p> <p>Network plot class for a temporal network.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a temporal network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._d3js.network_plots.NetworkPlot</code></p> <p>Network plot class for a temporal network.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a temporal network.\"\"\"\n\n    _kind = \"temporal\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/","title":"_matplotlib","text":"<p>Initialize matplotlib plotting functions.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/#pathpyG.visualisations._matplotlib.plot","title":"<code>plot</code>","text":"<p>Plot function.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/__init__.py</code> <pre><code>def plot(data: dict, kind: str = \"network\", **kwargs: Any) -&gt; Any:\n    \"\"\"Plot function.\"\"\"\n    return PLOT_CLASSES[kind](data, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/","title":"core","text":"<p>Generic matplotlib plot class.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot","title":"<code>MatplotlibPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Base class for plotting matplotlib objects.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>class MatplotlibPlot(PathPyPlot):\n    \"\"\"Base class for plotting matplotlib objects.\"\"\"\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:  # type: ignore\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        self.to_fig().savefig(filename)\n\n    def show(self, **kwargs: Any) -&gt; None:  # type: ignore\n        \"\"\"Show the plot on the device.\"\"\"\n        self.to_fig().show()\n\n    def to_fig(self) -&gt; Any:  # type: ignore\n        \"\"\"Convert to matplotlib figure.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:  # type: ignore\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    self.to_fig().savefig(filename)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:  # type: ignore\n    \"\"\"Show the plot on the device.\"\"\"\n    self.to_fig().show()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.to_fig","title":"<code>to_fig</code>","text":"<p>Convert to matplotlib figure.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def to_fig(self) -&gt; Any:  # type: ignore\n    \"\"\"Convert to matplotlib figure.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/","title":"network_plots","text":"<p>Network plots with matplotlib.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._matplotlib.core.MatplotlibPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>class NetworkPlot(MatplotlibPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.data = data\n        self.config = kwargs\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Clen up data.\"\"\"\n        self._compute_node_data()\n        self._compute_edge_data()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the nodes.\"\"\"\n        default = {\n            \"uid\": None,\n            \"x\": 0,\n            \"y\": 0,\n            \"size\": 30,\n            \"color\": \"blue\",\n            \"opacity\": 1.0,\n        }\n\n        nodes: dict = {key: [] for key in default}\n\n        for node in self.data[\"nodes\"]:\n            for key, value in default.items():\n                nodes[key].append(node.get(key, value))\n\n        self.data[\"nodes\"] = nodes\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the edges.\"\"\"\n        default = {\n            \"uid\": None,\n            \"size\": 5,\n            \"color\": \"red\",\n            \"opacity\": 1.0,\n        }\n\n        edges: dict = {**{key: [] for key in default}, **{\"line\": []}}\n\n        for edge in self.data[\"edges\"]:\n            source = self.data[\"nodes\"][\"uid\"].index(edge.get(\"source\"))\n            target = self.data[\"nodes\"][\"uid\"].index(edge.get(\"target\"))\n            edges[\"line\"].append(\n                [\n                    (self.data[\"nodes\"][\"x\"][source], self.data[\"nodes\"][\"x\"][target]),\n                    (self.data[\"nodes\"][\"y\"][source], self.data[\"nodes\"][\"y\"][target]),\n                ]\n            )\n\n            for key, value in default.items():\n                edges[key].append(edge.get(key, value))\n\n        self.data[\"edges\"] = edges\n\n    def to_fig(self) -&gt; Any:\n        \"\"\"Convert data to figure.\"\"\"\n        import matplotlib.pyplot as plt\n\n        fig, ax = plt.subplots()\n        ax.set_axis_off()\n\n        # plot edges\n        for i in range(len(self.data[\"edges\"][\"uid\"])):\n            ax.plot(\n                *self.data[\"edges\"][\"line\"][i],\n                color=self.data[\"edges\"][\"color\"][i],\n                alpha=self.data[\"edges\"][\"opacity\"][i],\n                zorder=1,\n            )\n\n        # plot nodes\n        ax.scatter(\n            self.data[\"nodes\"][\"x\"],\n            self.data[\"nodes\"][\"y\"],\n            s=self.data[\"nodes\"][\"size\"],\n            c=self.data[\"nodes\"][\"color\"],\n            alpha=self.data[\"nodes\"][\"opacity\"],\n            zorder=2,\n        )\n        return plt\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.data = data\n    self.config = kwargs\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Clen up data.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Clen up data.\"\"\"\n    self._compute_node_data()\n    self._compute_edge_data()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot.to_fig","title":"<code>to_fig</code>","text":"<p>Convert data to figure.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def to_fig(self) -&gt; Any:\n    \"\"\"Convert data to figure.\"\"\"\n    import matplotlib.pyplot as plt\n\n    fig, ax = plt.subplots()\n    ax.set_axis_off()\n\n    # plot edges\n    for i in range(len(self.data[\"edges\"][\"uid\"])):\n        ax.plot(\n            *self.data[\"edges\"][\"line\"][i],\n            color=self.data[\"edges\"][\"color\"][i],\n            alpha=self.data[\"edges\"][\"opacity\"][i],\n            zorder=1,\n        )\n\n    # plot nodes\n    ax.scatter(\n        self.data[\"nodes\"][\"x\"],\n        self.data[\"nodes\"][\"y\"],\n        s=self.data[\"nodes\"][\"size\"],\n        c=self.data[\"nodes\"][\"color\"],\n        alpha=self.data[\"nodes\"][\"opacity\"],\n        zorder=2,\n    )\n    return plt\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._matplotlib.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._matplotlib.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"temporal\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/","title":"_tikz","text":"<p>Initialize tikz plotting functions.</p>"},{"location":"reference/pathpyG/visualisations/_tikz/#pathpyG.visualisations._tikz.plot","title":"<code>plot</code>","text":"<p>Plot function.</p> Source code in <code>src/pathpyG/visualisations/_tikz/__init__.py</code> <pre><code>def plot(data: dict, kind: str = \"network\", **kwargs: Any) -&gt; Any:\n    \"\"\"Plot function.\"\"\"\n    return PLOT_CLASSES[kind](data, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/","title":"core","text":""},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot","title":"<code>TikzPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Base class for plotting d3js objects.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>class TikzPlot(PathPyPlot):\n    \"\"\"Base class for plotting d3js objects.\"\"\"\n\n    def __init__(self, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize plot class.\"\"\"\n        super().__init__()\n        if kwargs:\n            self.config = kwargs\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        if filename.endswith(\"tex\"):\n            with open(filename, \"w+\") as new:\n                new.write(self.to_tex())\n        elif filename.endswith(\"pdf\"):\n            # compile temporary pdf\n            temp_file, temp_dir = self.compile_pdf()\n            # Copy a file with new name\n            shutil.copy(temp_file, filename)\n            # remove the temporal directory\n            shutil.rmtree(temp_dir)\n\n        else:\n            raise NotImplementedError\n\n    def show(self, **kwargs: Any) -&gt; None:\n        \"\"\"Show the plot on the device.\"\"\"\n        # compile temporary pdf\n        temp_file, temp_dir = self.compile_pdf()\n\n        if config[\"environment\"][\"interactive\"]:\n            from IPython.display import IFrame, display\n\n            # open the file in the notebook\n            display(IFrame(temp_file, width=600, height=300))\n        else:\n            # open the file in the webbrowser\n            webbrowser.open(r\"file:///\" + temp_file)\n\n        # Wait for .1 second before temp file is deleted\n        time.sleep(0.1)\n\n        # remove the temporal directory\n        shutil.rmtree(temp_dir)\n\n    def compile_pdf(self) -&gt; tuple:\n        \"\"\"Compile pdf from tex.\"\"\"\n        # basename\n        basename = \"default\"\n        # get current directory\n        current_dir = os.getcwd()\n\n        # template directory\n        tikz_dir = str(\n            os.path.join(\n                os.path.dirname(os.path.dirname(__file__)),\n                os.path.normpath(\"templates\"),\n                \"tikz-network.sty\",\n            )\n        )\n\n        # get temporal directory\n        temp_dir = tempfile.mkdtemp()\n\n        # copy tikz-network to temporal directory\n        shutil.copy(tikz_dir, temp_dir)\n\n        # change to output dir\n        os.chdir(temp_dir)\n\n        # save the tex file\n        self.save(basename + \".tex\")\n\n        # latex compiler\n        command = [\n            \"latexmk\",\n            \"--pdf\",\n            \"-shell-escape\",\n            \"--interaction=nonstopmode\",\n            basename + \".tex\",\n        ]\n\n        try:\n            subprocess.check_output(command, stderr=subprocess.STDOUT)\n        except Exception:\n            # If compiler does not exist, try next in the list\n            logger.error(\"No latexmk compiler found\")\n            raise AttributeError\n        finally:\n            # change back to the current directory\n            os.chdir(current_dir)\n\n        # return the name of the folder and temp pdf file\n        return (os.path.join(temp_dir, basename + \".pdf\"), temp_dir)\n\n    def to_tex(self) -&gt; str:\n        \"\"\"Convert data to tex.\"\"\"\n        # get path to the pathpy templates\n        template_dir = os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"_tikz/templates\"),\n        )\n\n        # get template files\n        with open(os.path.join(template_dir, f\"{self._kind}.tex\")) as template:\n            tex_template = template.read()\n\n        # generate data\n        data = self.to_tikz()\n\n        # fill template with data\n        tex = Template(tex_template).substitute(\n            classoptions=self.config.get(\"latex_class_options\", \"\"),\n            width=self.config.get(\"width\", \"6cm\"),\n            height=self.config.get(\"height\", \"6cm\"),\n            tikz=data,\n        )\n\n        return tex\n\n    def to_tikz(self) -&gt; str:\n        \"\"\"Convert data to tikz.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize plot class.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def __init__(self, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize plot class.\"\"\"\n    super().__init__()\n    if kwargs:\n        self.config = kwargs\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.compile_pdf","title":"<code>compile_pdf</code>","text":"<p>Compile pdf from tex.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def compile_pdf(self) -&gt; tuple:\n    \"\"\"Compile pdf from tex.\"\"\"\n    # basename\n    basename = \"default\"\n    # get current directory\n    current_dir = os.getcwd()\n\n    # template directory\n    tikz_dir = str(\n        os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"templates\"),\n            \"tikz-network.sty\",\n        )\n    )\n\n    # get temporal directory\n    temp_dir = tempfile.mkdtemp()\n\n    # copy tikz-network to temporal directory\n    shutil.copy(tikz_dir, temp_dir)\n\n    # change to output dir\n    os.chdir(temp_dir)\n\n    # save the tex file\n    self.save(basename + \".tex\")\n\n    # latex compiler\n    command = [\n        \"latexmk\",\n        \"--pdf\",\n        \"-shell-escape\",\n        \"--interaction=nonstopmode\",\n        basename + \".tex\",\n    ]\n\n    try:\n        subprocess.check_output(command, stderr=subprocess.STDOUT)\n    except Exception:\n        # If compiler does not exist, try next in the list\n        logger.error(\"No latexmk compiler found\")\n        raise AttributeError\n    finally:\n        # change back to the current directory\n        os.chdir(current_dir)\n\n    # return the name of the folder and temp pdf file\n    return (os.path.join(temp_dir, basename + \".pdf\"), temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    if filename.endswith(\"tex\"):\n        with open(filename, \"w+\") as new:\n            new.write(self.to_tex())\n    elif filename.endswith(\"pdf\"):\n        # compile temporary pdf\n        temp_file, temp_dir = self.compile_pdf()\n        # Copy a file with new name\n        shutil.copy(temp_file, filename)\n        # remove the temporal directory\n        shutil.rmtree(temp_dir)\n\n    else:\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:\n    \"\"\"Show the plot on the device.\"\"\"\n    # compile temporary pdf\n    temp_file, temp_dir = self.compile_pdf()\n\n    if config[\"environment\"][\"interactive\"]:\n        from IPython.display import IFrame, display\n\n        # open the file in the notebook\n        display(IFrame(temp_file, width=600, height=300))\n    else:\n        # open the file in the webbrowser\n        webbrowser.open(r\"file:///\" + temp_file)\n\n    # Wait for .1 second before temp file is deleted\n    time.sleep(0.1)\n\n    # remove the temporal directory\n    shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.to_tex","title":"<code>to_tex</code>","text":"<p>Convert data to tex.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def to_tex(self) -&gt; str:\n    \"\"\"Convert data to tex.\"\"\"\n    # get path to the pathpy templates\n    template_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)),\n        os.path.normpath(\"_tikz/templates\"),\n    )\n\n    # get template files\n    with open(os.path.join(template_dir, f\"{self._kind}.tex\")) as template:\n        tex_template = template.read()\n\n    # generate data\n    data = self.to_tikz()\n\n    # fill template with data\n    tex = Template(tex_template).substitute(\n        classoptions=self.config.get(\"latex_class_options\", \"\"),\n        width=self.config.get(\"width\", \"6cm\"),\n        height=self.config.get(\"height\", \"6cm\"),\n        tikz=data,\n    )\n\n    return tex\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.to_tikz","title":"<code>to_tikz</code>","text":"<p>Convert data to tikz.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def to_tikz(self) -&gt; str:\n    \"\"\"Convert data to tikz.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/","title":"network_plots","text":"<p>Network plots with tikz.</p>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._tikz.core.TikzPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>class NetworkPlot(TikzPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.data = data\n        self.config = kwargs\n        self.config[\"width\"] = self.config.pop(\"width\", 6)\n        self.config[\"height\"] = self.config.pop(\"height\", 6)\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Clen up data.\"\"\"\n        self._compute_node_data()\n        self._compute_edge_data()\n        self._update_layout()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the nodes.\"\"\"\n        default: set = {\"uid\", \"x\", \"y\", \"size\", \"color\", \"opacity\"}\n        mapping: dict = {}\n\n        for node in self.data[\"nodes\"]:\n            for key in list(node):\n                if key in mapping:\n                    node[mapping[key]] = node.pop(key)\n                if key not in default:\n                    node.pop(key, None)\n\n            color = node.get(\"color\", None)\n            if isinstance(color, str) and \"#\" in color:\n                color = hex_to_rgb(color)\n                node[\"color\"] = f\"{{{color[0]},{color[1]},{color[2]}}}\"\n                node[\"RGB\"] = True\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the edges.\"\"\"\n        default: set = {\"uid\", \"source\", \"target\", \"lw\", \"color\", \"opacity\"}\n        mapping: dict = {\"size\": \"lw\"}\n\n        for edge in self.data[\"edges\"]:\n            for key in list(edge):\n                if key in mapping:\n                    edge[mapping[key]] = edge.pop(key)\n                if key not in default:\n                    edge.pop(key, None)\n\n            color = edge.get(\"color\", None)\n            if isinstance(color, str) and \"#\" in color:\n                color = hex_to_rgb(color)\n                edge[\"color\"] = f\"{{{color[0]},{color[1]},{color[2]}}}\"\n                edge[\"RGB\"] = True\n\n    def _update_layout(self, default_size: float = 0.6) -&gt; None:\n        \"\"\"Update the layout.\"\"\"\n        layout = self.config.get(\"layout\")\n\n        if layout is None:\n            return\n\n        # get data\n        layout = {n[\"uid\"]: (n[\"x\"], n[\"y\"]) for n in self.data[\"nodes\"]}\n        sizes = {n[\"uid\"]: n.get(\"size\", default_size) for n in self.data[\"nodes\"]}\n\n        # get config values\n        width = self.config[\"width\"]\n        height = self.config[\"height\"]\n        keep_aspect_ratio = self.config.get(\"keep_aspect_ratio\", True)\n        margin = self.config.get(\"margin\", 0.0)\n        margins = {\"top\": margin, \"left\": margin, \"bottom\": margin, \"right\": margin}\n\n        # calculate the scaling ratio\n        x_ratio = float(\"inf\")\n        y_ratio = float(\"inf\")\n\n        # calculate absolute min and max coordinates\n        x_absolute = []\n        y_absolute = []\n        for uid, (_x, _y) in layout.items():\n            _s = sizes[uid] / 2\n            x_absolute.extend([_x - _s, _x + _s])\n            y_absolute.extend([_y - _s, _y + _s])\n\n        # calculate min and max center coordinates\n        x_values, y_values = zip(*layout.values())\n        x_min, x_max = min(x_values), max(x_values)\n        y_min, y_max = min(y_values), max(y_values)\n\n        # change margins\n        margins[\"left\"] += abs(x_min - min(x_absolute))\n        margins[\"bottom\"] += abs(y_min - min(y_absolute))\n        margins[\"top\"] += abs(y_max - max(y_absolute))\n        margins[\"right\"] += abs(x_max - max(x_absolute))\n\n        if x_max - x_min &gt; 0:\n            x_ratio = (width - margins[\"left\"] - margins[\"right\"]) / (x_max - x_min)\n        if y_max - y_min &gt; 0:\n            y_ratio = (height - margins[\"top\"] - margins[\"bottom\"]) / (y_max - y_min)\n\n        if keep_aspect_ratio:\n            scaling = (min(x_ratio, y_ratio), min(x_ratio, y_ratio))\n        else:\n            scaling = (x_ratio, y_ratio)\n\n        if scaling[0] == float(\"inf\"):\n            scaling = (1, scaling[1])\n        if scaling[1] == float(\"inf\"):\n            scaling = (scaling[0], 1)\n\n        x_values = []\n        y_values = []\n\n        # apply scaling to the points\n        _layout = {n: (x * scaling[0], y * scaling[1]) for n, (x, y) in layout.items()}\n\n        # find min and max values of the points\n        x_values, y_values = zip(*_layout.values())\n        x_min, x_max = min(x_values), max(x_values)\n        y_min, y_max = min(y_values), max(y_values)\n\n        # calculate the translation\n        translation = (\n            ((width - margins[\"left\"] - margins[\"right\"]) / 2 + margins[\"left\"])\n            - ((x_max - x_min) / 2 + x_min),\n            ((height - margins[\"top\"] - margins[\"bottom\"]) / 2 + margins[\"bottom\"])\n            - ((y_max - y_min) / 2 + y_min),\n        )\n\n        # apply translation to the points\n        _layout = {\n            n: (x + translation[0], y + translation[1]) for n, (x, y) in _layout.items()\n        }\n\n        # update node position for the plot\n        for node in self.data[\"nodes\"]:\n            node[\"x\"], node[\"y\"] = _layout[node[\"uid\"]]\n\n    def to_tikz(self) -&gt; str:\n        \"\"\"Convert to Tex.\"\"\"\n\n        def _add_args(args: dict):\n            string = \"\"\n            for key, value in args.items():\n                string += f\",{key}\" if value is True else f\",{key}={value}\"\n            return string\n\n        tikz = \"\"\n        for node in self.data[\"nodes\"]:\n            uid = node.pop(\"uid\")\n            string = \"\\\\Vertex[\"\n            string += _add_args(node)\n            string += \"]{{{}}}\\n\".format(uid)\n            tikz += string\n\n        for edge in self.data[\"edges\"]:\n            uid = edge.pop(\"uid\")\n            source = edge.pop(\"source\")\n            target = edge.pop(\"target\")\n            string = \"\\\\Edge[\"\n            string += _add_args(edge)\n            string += \"]({})({})\\n\".format(source, target)\n            tikz += string\n        return tikz\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.data = data\n    self.config = kwargs\n    self.config[\"width\"] = self.config.pop(\"width\", 6)\n    self.config[\"height\"] = self.config.pop(\"height\", 6)\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Clen up data.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Clen up data.\"\"\"\n    self._compute_node_data()\n    self._compute_edge_data()\n    self._update_layout()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot.to_tikz","title":"<code>to_tikz</code>","text":"<p>Convert to Tex.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def to_tikz(self) -&gt; str:\n    \"\"\"Convert to Tex.\"\"\"\n\n    def _add_args(args: dict):\n        string = \"\"\n        for key, value in args.items():\n            string += f\",{key}\" if value is True else f\",{key}={value}\"\n        return string\n\n    tikz = \"\"\n    for node in self.data[\"nodes\"]:\n        uid = node.pop(\"uid\")\n        string = \"\\\\Vertex[\"\n        string += _add_args(node)\n        string += \"]{{{}}}\\n\".format(uid)\n        tikz += string\n\n    for edge in self.data[\"edges\"]:\n        uid = edge.pop(\"uid\")\n        source = edge.pop(\"source\")\n        target = edge.pop(\"target\")\n        string = \"\\\\Edge[\"\n        string += _add_args(edge)\n        string += \"]({})({})\\n\".format(source, target)\n        tikz += string\n    return tikz\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._tikz.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._tikz.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"temporal\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"tutorial/_higher_order_scalability/","title":"higher order scalability","text":"In\u00a0[1]: Copied! <pre>import time\nimport torch\n\nimport pathpy as pp2\nimport pathpyG as pp\nfrom matplotlib import pyplot as plt\npp.config['torch']['device'] = 'cuda'\nprint('Running on', pp.config['torch']['device'])\n</pre> import time import torch  import pathpy as pp2 import pathpyG as pp from matplotlib import pyplot as plt pp.config['torch']['device'] = 'cuda' print('Running on', pp.config['torch']['device']) <pre>Running on cuda\n</pre> In\u00a0[2]: Copied! <pre>p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\n</pre> p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') In\u00a0[3]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(p, max_order=2)\ng2 = m.layers[2]\nprint(g2.N)\nprint(g2.M)\nprint(g2['edge_weight'].sum().item())\n</pre> m = pp.MultiOrderModel.from_DAGs(p, max_order=2) g2 = m.layers[2] print(g2.N) print(g2.M) print(g2['edge_weight'].sum().item()) <pre>646\n1139\n634916.0\n</pre> In\u00a0[4]: Copied! <pre>for e in g2.edges:\n    print(e, g2['edge_weight', e[0], e[1]])\n</pre> for e in g2.edges:     print(e, g2['edge_weight', e[0], e[1]]) <pre>(('Acton Town', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(2399., device='cuda:0')\n(('Acton Town', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(155., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(398., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(96., device='cuda:0')\n(('Acton Town', 'South Ealing'), ('South Ealing', 'Northfields')) tensor(1149., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(481., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(113., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(8., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(117., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(9., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(173., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(24., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(112., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(5., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2121., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1453., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(135., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(2147., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(234., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(5062., device='cuda:0')\n(('Alperton', 'Park Royal'), ('Park Royal', 'North Ealing')) tensor(232., device='cuda:0')\n(('Alperton', 'Sudbury Town'), ('Sudbury Town', 'Sudbury Hill')) tensor(117., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(1., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(180., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(46., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(665., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1404., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(3., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(33., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(56., device='cuda:0')\n(('Angel', 'Old Street'), ('Old Street', 'Moorgate')) tensor(2150., device='cuda:0')\n(('Archway', 'Highgate'), ('Highgate', 'East Finchley')) tensor(818., device='cuda:0')\n(('Archway', 'Tufnell Park'), ('Tufnell Park', 'Kentish Town')) tensor(1248., device='cuda:0')\n(('Arnos Grove', 'Bounds Green'), ('Bounds Green', 'Wood Green')) tensor(503., device='cuda:0')\n(('Arnos Grove', 'Southgate'), ('Southgate', 'Oakwood')) tensor(207., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(71., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(20., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(78., device='cuda:0')\n(('Arsenal', 'Holloway Road'), ('Holloway Road', 'Caledonian Road')) tensor(87., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(2561., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(104., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(669., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(2627., device='cuda:0')\n(('Baker Street', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Paddington')) tensor(5427., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(1379., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(157., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(639., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(290., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(463., device='cuda:0')\n(('Baker Street', 'Great Portland Street'), ('Great Portland Street', 'Euston Square')) tensor(4311., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(126., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(1391., device='cuda:0')\n(('Baker Street', \"Regent's Park\"), (\"Regent's Park\", 'Oxford Circus')) tensor(662., device='cuda:0')\n(('Baker Street', \"St. John's Wood\"), (\"St. John's Wood\", 'Swiss Cottage')) tensor(159., device='cuda:0')\n(('Balham', 'Clapham South'), ('Clapham South', 'Clapham Common')) tensor(1132., device='cuda:0')\n(('Balham', 'Tooting Bec'), ('Tooting Bec', 'Tooting Broadway')) tensor(637., device='cuda:0')\n(('Bank / Monument', 'Cannon Street'), ('Cannon Street', 'Mansion House')) tensor(274., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(110., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(2194., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(2353., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(522., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(264., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Borough')) tensor(805., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(3545., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(279., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(301., device='cuda:0')\n(('Bank / Monument', \"St. Paul's\"), (\"St. Paul's\", 'Chancery Lane')) tensor(3344., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(116., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(2188., device='cuda:0')\n(('Barbican', 'Farringdon'), ('Farringdon', \"King's Cross St. Pancras\")) tensor(2027., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1800., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(2., device='cuda:0')\n(('Barking', 'East Ham'), ('East Ham', 'Upton Park')) tensor(9., device='cuda:0')\n(('Barking', 'Upminster'), ('Upminster', 'Upminster Bridge')) tensor(561., device='cuda:0')\n(('Barking', 'Upney'), ('Upney', 'Becontree')) tensor(684., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(20., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Canning Town')) tensor(288., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Plaistow')) tensor(7., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Stratford')) tensor(2122., device='cuda:0')\n(('Barkingside', 'Fairlop'), ('Fairlop', 'Hainault')) tensor(201., device='cuda:0')\n(('Barkingside', 'Newbury Park'), ('Newbury Park', 'Gants Hill')) tensor(448., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1088., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(94., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(6., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(150., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(340., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(182., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(316., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(634., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(114., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(23., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(101., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(113., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(414., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(40., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(82., device='cuda:0')\n(('Becontree', 'Dagenham Heathway'), ('Dagenham Heathway', 'Dagenham East')) tensor(169., device='cuda:0')\n(('Becontree', 'Upney'), ('Upney', 'Barking')) tensor(623., device='cuda:0')\n(('Belsize Park', 'Chalk Farm'), ('Chalk Farm', 'Camden Town')) tensor(1156., device='cuda:0')\n(('Belsize Park', 'Hampstead'), ('Hampstead', 'Golders Green')) tensor(771., device='cuda:0')\n(('Bermondsey', 'Canada Water'), ('Canada Water', 'Canary Wharf')) tensor(1026., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(320., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Borough')) tensor(110., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(1094., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(11., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2252., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1505., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(119., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(253., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(144., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(3210., device='cuda:0')\n(('Blackfriars', 'Mansion House'), ('Mansion House', 'Cannon Street')) tensor(255., device='cuda:0')\n(('Blackfriars', 'Temple'), ('Temple', 'Embankment')) tensor(384., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(224., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(152., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2570., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(1699., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(92., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(999., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(174., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(282., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(225., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Victoria')) tensor(858., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Westminster')) tensor(1524., device='cuda:0')\n(('Bond Street', 'Marble Arch'), ('Marble Arch', 'Lancaster Gate')) tensor(835., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(226., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(519., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(93., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(3138., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(283., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(679., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(86., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(845., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(103., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(38., device='cuda:0')\n(('Boston Manor', 'Northfields'), ('Northfields', 'South Ealing')) tensor(1179., device='cuda:0')\n(('Boston Manor', 'Osterley'), ('Osterley', 'Hounslow East')) tensor(819., device='cuda:0')\n(('Bounds Green', 'Arnos Grove'), ('Arnos Grove', 'Southgate')) tensor(350., device='cuda:0')\n(('Bounds Green', 'Wood Green'), ('Wood Green', 'Turnpike Lane')) tensor(630., device='cuda:0')\n(('Bow Road', 'BromleyByBow'), ('BromleyByBow', 'West Ham')) tensor(13., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(225., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(5., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stratford')) tensor(10., device='cuda:0')\n(('Brent Cross', 'Golders Green'), ('Golders Green', 'Hampstead')) tensor(680., device='cuda:0')\n(('Brent Cross', 'Hendon Central'), ('Hendon Central', 'Colindale')) tensor(382., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(9., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Oval')) tensor(167., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(147., device='cuda:0')\n(('BromleyByBow', 'Bow Road'), ('Bow Road', 'Mile End')) tensor(87., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Barking')) tensor(16., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(3., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Plaistow')) tensor(4., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Stratford')) tensor(9., device='cuda:0')\n(('Buckhurst Hill', 'Loughton'), ('Loughton', 'Debden')) tensor(468., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(6., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'South Woodford')) tensor(934., device='cuda:0')\n(('Burnt Oak', 'Colindale'), ('Colindale', 'Hendon Central')) tensor(218., device='cuda:0')\n(('Caledonian Road', 'Holloway Road'), ('Holloway Road', 'Arsenal')) tensor(93., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(36., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(139., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(155., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(34., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(14., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(39., device='cuda:0')\n(('Camden Town', 'Chalk Farm'), ('Chalk Farm', 'Belsize Park')) tensor(1083., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(1459., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', 'Warren Street')) tensor(1639., device='cuda:0')\n(('Camden Town', 'Kentish Town'), ('Kentish Town', 'Tufnell Park')) tensor(1335., device='cuda:0')\n(('Canada Water', 'Bermondsey'), ('Bermondsey', 'London Bridge')) tensor(1333., device='cuda:0')\n(('Canada Water', 'Canary Wharf'), ('Canary Wharf', 'North Greenwich')) tensor(765., device='cuda:0')\n(('Canary Wharf', 'Canada Water'), ('Canada Water', 'Bermondsey')) tensor(1104., device='cuda:0')\n(('Canary Wharf', 'North Greenwich'), ('North Greenwich', 'Canning Town')) tensor(600., device='cuda:0')\n(('Canning Town', 'North Greenwich'), ('North Greenwich', 'Canary Wharf')) tensor(598., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Barking')) tensor(304., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(5., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Plaistow')) tensor(79., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Stratford')) tensor(222., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(198., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(78., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(42., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(59., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(96., device='cuda:0')\n(('Cannon Street', 'Mansion House'), ('Mansion House', 'Blackfriars')) tensor(268., device='cuda:0')\n(('Canons Park', 'Queensbury'), ('Queensbury', 'Kingsbury')) tensor(218., device='cuda:0')\n(('Chalfont &amp; Latimer', 'Chorleywood'), ('Chorleywood', 'Rickmansworth')) tensor(395., device='cuda:0')\n(('Chalk Farm', 'Belsize Park'), ('Belsize Park', 'Hampstead')) tensor(910., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1248., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(43., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(9., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(220., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Russell Square')) tensor(115., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(3066., device='cuda:0')\n(('Chancery Lane', \"St. Paul's\"), (\"St. Paul's\", 'Bank / Monument')) tensor(3482., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Temple')) tensor(61., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Waterloo')) tensor(231., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Westminster')) tensor(5., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(59., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(159., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(122., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(304., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(1., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(85., device='cuda:0')\n(('Chigwell', 'Grange Hill'), ('Grange Hill', 'Hainault')) tensor(204., device='cuda:0')\n(('Chigwell', 'Roding Valley'), ('Roding Valley', 'Woodford')) tensor(320., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(90., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(6., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(1., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(146., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(62., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'HarrowOnTheHill')) tensor(496., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'Moor Park')) tensor(10., device='cuda:0')\n(('Clapham Common', 'Clapham North'), ('Clapham North', 'Stockwell')) tensor(1504., device='cuda:0')\n(('Clapham Common', 'Clapham South'), ('Clapham South', 'Balham')) tensor(969., device='cuda:0')\n(('Clapham North', 'Clapham Common'), ('Clapham Common', 'Clapham South')) tensor(1148., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(8., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Oval')) tensor(964., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(686., device='cuda:0')\n(('Clapham South', 'Balham'), ('Balham', 'Tooting Bec')) tensor(782., device='cuda:0')\n(('Clapham South', 'Clapham Common'), ('Clapham Common', 'Clapham North')) tensor(1297., device='cuda:0')\n(('Cockfosters', 'Oakwood'), ('Oakwood', 'Southgate')) tensor(120., device='cuda:0')\n(('Colindale', 'Burnt Oak'), ('Burnt Oak', 'Edgware')) tensor(139., device='cuda:0')\n(('Colindale', 'Hendon Central'), ('Hendon Central', 'Brent Cross')) tensor(370., device='cuda:0')\n(('Colliers Wood', 'South Wimbledon'), ('South Wimbledon', 'Morden')) tensor(152., device='cuda:0')\n(('Colliers Wood', 'Tooting Broadway'), ('Tooting Broadway', 'Tooting Bec')) tensor(477., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(239., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Russell Square')) tensor(90., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(52., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(129., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(238., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(6., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Dagenham East', 'Dagenham Heathway'), ('Dagenham Heathway', 'Becontree')) tensor(161., device='cuda:0')\n(('Dagenham East', 'Elm Park'), ('Elm Park', 'Hornchurch')) tensor(5., device='cuda:0')\n(('Dagenham Heathway', 'Becontree'), ('Becontree', 'Upney')) tensor(418., device='cuda:0')\n(('Dagenham Heathway', 'Dagenham East'), ('Dagenham East', 'Elm Park')) tensor(5., device='cuda:0')\n(('Debden', 'Loughton'), ('Loughton', 'Buckhurst Hill')) tensor(577., device='cuda:0')\n(('Debden', 'Theydon Bois'), ('Theydon Bois', 'Epping')) tensor(217., device='cuda:0')\n(('Dollis Hill', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(118., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(2., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(2315., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(113., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Bayswater')) tensor(117., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(132., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(3451., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(94., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(60., device='cuda:0')\n(('Ealing Broadway', 'West Acton'), ('West Acton', 'North Acton')) tensor(875., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(105., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(508., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(1068., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(699., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(2570., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(49., device='cuda:0')\n(('Ealing Common', 'North Ealing'), ('North Ealing', 'Park Royal')) tensor(232., device='cuda:0')\n((\"Earl's Court\", 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(1065., device='cuda:0')\n((\"Earl's Court\", 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(3117., device='cuda:0')\n((\"Earl's Court\", 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(504., device='cuda:0')\n((\"Earl's Court\", 'West Brompton'), ('West Brompton', 'Fulham Broadway')) tensor(1757., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(70., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'West Acton')) tensor(168., device='cuda:0')\n(('East Acton', 'White City'), ('White City', \"Shepherd's Bush (Cen)\")) tensor(103., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(69., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(427., device='cuda:0')\n(('East Finchley', 'Highgate'), ('Highgate', 'Archway')) tensor(844., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upminster')) tensor(8., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upney')) tensor(7., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'West Ham')) tensor(426., device='cuda:0')\n(('East Ham', 'Upton Park'), ('Upton Park', 'Plaistow')) tensor(1., device='cuda:0')\n(('East Putney', 'Putney Bridge'), ('Putney Bridge', 'Parsons Green')) tensor(969., device='cuda:0')\n(('East Putney', 'Southfields'), ('Southfields', 'Wimbledon Park')) tensor(375., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(66., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(918., device='cuda:0')\n(('Eastcote', 'Ruislip Manor'), ('Ruislip Manor', 'Ruislip')) tensor(619., device='cuda:0')\n(('Edgware', 'Burnt Oak'), ('Burnt Oak', 'Colindale')) tensor(118., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(122., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(326., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(153., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(135., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(50., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(44., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(2860., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(253., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(2439., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(13., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(425., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(57., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(475., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(3182., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(590., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(924., device='cuda:0')\n(('Elephant &amp; Castle', 'Borough'), ('Borough', 'London Bridge')) tensor(867., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Oval')) tensor(627., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Waterloo')) tensor(217., device='cuda:0')\n(('Elephant &amp; Castle', 'Lambeth North'), ('Lambeth North', 'Waterloo')) tensor(211., device='cuda:0')\n(('Elm Park', 'Dagenham East'), ('Dagenham East', 'Dagenham Heathway')) tensor(5., device='cuda:0')\n(('Elm Park', 'Hornchurch'), ('Hornchurch', 'Upminster Bridge')) tensor(238., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Leicester Square')) tensor(114., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Piccadilly Circus')) tensor(175., device='cuda:0')\n(('Embankment', 'Temple'), ('Temple', 'Blackfriars')) tensor(412., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(105., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(23., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(276., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', 'Green Park')) tensor(549., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(132., device='cuda:0')\n(('Epping', 'Theydon Bois'), ('Theydon Bois', 'Debden')) tensor(306., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(1176., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(1482., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(703., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(131., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(326., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(683., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(576., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(100., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(88., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(2579., device='cuda:0')\n(('Euston Square', 'Great Portland Street'), ('Great Portland Street', 'Baker Street')) tensor(4039., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(1503., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(154., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(315., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(1522., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(739., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(87., device='cuda:0')\n(('Fairlop', 'Barkingside'), ('Barkingside', 'Newbury Park')) tensor(301., device='cuda:0')\n(('Fairlop', 'Hainault'), ('Hainault', 'Grange Hill')) tensor(3., device='cuda:0')\n(('Farringdon', 'Barbican'), ('Barbican', 'Moorgate')) tensor(2110., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(3., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(45., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(626., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1384., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(32., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(45., device='cuda:0')\n(('Finchley Central', 'East Finchley'), ('East Finchley', 'Highgate')) tensor(687., device='cuda:0')\n(('Finchley Central', 'West Finchley'), ('West Finchley', 'Woodside Park')) tensor(345., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1763., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(214., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(1034., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(145., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(245., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(172., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(95., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(235., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(603., device='cuda:0')\n(('Finchley Road', 'Swiss Cottage'), ('Swiss Cottage', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(338., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(96., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(85., device='cuda:0')\n(('Finchley Road', 'West Hampstead'), ('West Hampstead', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(110., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(98., device='cuda:0')\n(('Finsbury Park', 'Arsenal'), ('Arsenal', 'Holloway Road')) tensor(65., device='cuda:0')\n(('Finsbury Park', 'Highbury &amp; Islington'), ('Highbury &amp; Islington', \"King's Cross St. Pancras\")) tensor(1377., device='cuda:0')\n(('Finsbury Park', 'Manor House'), ('Manor House', 'Turnpike Lane')) tensor(960., device='cuda:0')\n(('Finsbury Park', 'Seven Sisters'), ('Seven Sisters', 'Tottenham Hale')) tensor(708., device='cuda:0')\n(('Fulham Broadway', 'Parsons Green'), ('Parsons Green', 'Putney Bridge')) tensor(1095., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', \"Earl's Court\")) tensor(1813., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', 'Kensington (Olympia)')) tensor(4., device='cuda:0')\n(('Gants Hill', 'Newbury Park'), ('Newbury Park', 'Barkingside')) tensor(471., device='cuda:0')\n(('Gants Hill', 'Redbridge'), ('Redbridge', 'Wanstead')) tensor(1094., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(1135., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(98., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(1410., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(192., device='cuda:0')\n(('Gloucester Road', 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(158., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(1378., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(2449., device='cuda:0')\n(('Golders Green', 'Brent Cross'), ('Brent Cross', 'Hendon Central')) tensor(542., device='cuda:0')\n(('Golders Green', 'Hampstead'), ('Hampstead', 'Belsize Park')) tensor(846., device='cuda:0')\n(('Goldhawk Road', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Wood Lane')) tensor(201., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(73., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(59., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(38., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(41., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Euston')) tensor(79., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(42., device='cuda:0')\n(('Grange Hill', 'Chigwell'), ('Chigwell', 'Roding Valley')) tensor(256., device='cuda:0')\n(('Grange Hill', 'Hainault'), ('Hainault', 'Fairlop')) tensor(3., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(93., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2262., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(946., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(582., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(14., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(115., device='cuda:0')\n(('Great Portland Street', 'Euston Square'), ('Euston Square', \"King's Cross St. Pancras\")) tensor(4322., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2417., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(156., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(245., device='cuda:0')\n(('Green Park', 'Hyde Park Corner'), ('Hyde Park Corner', 'Knightsbridge')) tensor(1812., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(41., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(250., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(1507., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(131., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(101., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Pimlico')) tensor(1017., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1741., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(140., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Embankment')) tensor(595., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(136., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Waterloo')) tensor(3391., device='cuda:0')\n(('Greenford', 'Northolt'), ('Northolt', 'South Ruislip')) tensor(194., device='cuda:0')\n(('Greenford', 'Perivale'), ('Perivale', 'Hanger Lane')) tensor(544., device='cuda:0')\n(('Gunnersbury', 'Kew Gardens'), ('Kew Gardens', 'Richmond')) tensor(293., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(557., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(217., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(6., device='cuda:0')\n(('Hainault', 'Fairlop'), ('Fairlop', 'Barkingside')) tensor(189., device='cuda:0')\n(('Hainault', 'Grange Hill'), ('Grange Hill', 'Chigwell')) tensor(187., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(437., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(191., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', \"Earl's Court\")) tensor(1123., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', 'West Kensington')) tensor(25., device='cuda:0')\n(('Hammersmith (Dis)', 'Ravenscourt Park'), ('Ravenscourt Park', 'Stamford Brook')) tensor(54., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(177., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(58., device='cuda:0')\n(('Hammersmith (H&amp;C)', 'Goldhawk Road'), ('Goldhawk Road', \"Shepherd's Bush Market\")) tensor(108., device='cuda:0')\n(('Hampstead', 'Belsize Park'), ('Belsize Park', 'Chalk Farm')) tensor(982., device='cuda:0')\n(('Hampstead', 'Golders Green'), ('Golders Green', 'Brent Cross')) tensor(610., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'East Acton')) tensor(80., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'West Acton')) tensor(688., device='cuda:0')\n(('Hanger Lane', 'Perivale'), ('Perivale', 'Greenford')) tensor(454., device='cuda:0')\n(('Harlesden', 'Stonebridge Park'), ('Stonebridge Park', 'Wembley Central')) tensor(333., device='cuda:0')\n(('Harlesden', 'Willesden Junction'), ('Willesden Junction', 'Kensal Green')) tensor(545., device='cuda:0')\n(('Harrow &amp; Wealdstone', 'Kenton'), ('Kenton', 'South Kenton')) tensor(118., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(1461., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(29., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(33., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(36., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(1479., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(383., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(222., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'North Harrow'), ('North Harrow', 'Pinner')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'Northwick Park'), ('Northwick Park', 'Preston Road')) tensor(21., device='cuda:0')\n(('HarrowOnTheHill', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(389., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(59., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'West Harrow'), ('West Harrow', 'Rayners Lane')) tensor(1303., device='cuda:0')\n(('Hatton Cross', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Heathrow Terminal 5')) tensor(75., device='cuda:0')\n(('Hatton Cross', 'Hounslow West'), ('Hounslow West', 'Hounslow Central')) tensor(571., device='cuda:0')\n(('Heathrow Terminal 4', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(123., device='cuda:0')\n(('Heathrow Terminal 5', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Hatton Cross')) tensor(92., device='cuda:0')\n(('Heathrow Terminals 123', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(332., device='cuda:0')\n(('Hendon Central', 'Brent Cross'), ('Brent Cross', 'Golders Green')) tensor(568., device='cuda:0')\n(('Hendon Central', 'Colindale'), ('Colindale', 'Burnt Oak')) tensor(251., device='cuda:0')\n(('High Barnet', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'Woodside Park')) tensor(159., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(97., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(15., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(379., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(34., device='cuda:0')\n(('High Street Kensington', 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(452., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(518., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(110., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(172., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(80., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(768., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(392., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(32., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(13., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(617., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(725., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(33., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(144., device='cuda:0')\n(('Highgate', 'Archway'), ('Archway', 'Tufnell Park')) tensor(1030., device='cuda:0')\n(('Highgate', 'East Finchley'), ('East Finchley', 'Finchley Central')) tensor(639., device='cuda:0')\n(('Hillingdon', 'Ickenham'), ('Ickenham', 'Ruislip')) tensor(424., device='cuda:0')\n(('Holborn', 'Chancery Lane'), ('Chancery Lane', \"St. Paul's\")) tensor(3506., device='cuda:0')\n(('Holborn', 'Covent Garden'), ('Covent Garden', 'Leicester Square')) tensor(203., device='cuda:0')\n(('Holborn', 'Russell Square'), ('Russell Square', \"King's Cross St. Pancras\")) tensor(302., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(2909., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(63., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(215., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(404., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(96., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(127., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(328., device='cuda:0')\n(('Holland Park', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'White City')) tensor(277., device='cuda:0')\n(('Holloway Road', 'Arsenal'), ('Arsenal', 'Finsbury Park')) tensor(69., device='cuda:0')\n(('Holloway Road', 'Caledonian Road'), ('Caledonian Road', \"King's Cross St. Pancras\")) tensor(243., device='cuda:0')\n(('Hornchurch', 'Elm Park'), ('Elm Park', 'Dagenham East')) tensor(4., device='cuda:0')\n(('Hornchurch', 'Upminster Bridge'), ('Upminster Bridge', 'Upminster')) tensor(437., device='cuda:0')\n(('Hounslow Central', 'Hounslow East'), ('Hounslow East', 'Osterley')) tensor(828., device='cuda:0')\n(('Hounslow Central', 'Hounslow West'), ('Hounslow West', 'Hatton Cross')) tensor(433., device='cuda:0')\n(('Hounslow East', 'Hounslow Central'), ('Hounslow Central', 'Hounslow West')) tensor(554., device='cuda:0')\n(('Hounslow East', 'Osterley'), ('Osterley', 'Boston Manor')) tensor(959., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminal 4')) tensor(69., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminals 123')) tensor(277., device='cuda:0')\n(('Hounslow West', 'Hounslow Central'), ('Hounslow Central', 'Hounslow East')) tensor(667., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Bond Street')) tensor(234., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(492., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(73., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Victoria')) tensor(20., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Westminster')) tensor(1029., device='cuda:0')\n(('Hyde Park Corner', 'Knightsbridge'), ('Knightsbridge', 'South Kensington')) tensor(1581., device='cuda:0')\n(('Ickenham', 'Hillingdon'), ('Hillingdon', 'Uxbridge')) tensor(257., device='cuda:0')\n(('Ickenham', 'Ruislip'), ('Ruislip', 'Ruislip Manor')) tensor(541., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(774., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Oval'), ('Oval', 'Stockwell')) tensor(1245., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(113., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(715., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(378., device='cuda:0')\n(('Kensal Green', \"Queen's Park\"), (\"Queen's Park\", 'Kilburn Park')) tensor(754., device='cuda:0')\n(('Kensal Green', 'Willesden Junction'), ('Willesden Junction', 'Harlesden')) tensor(470., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(47., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1547., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(11., device='cuda:0')\n(('Kentish Town', 'Tufnell Park'), ('Tufnell Park', 'Archway')) tensor(1191., device='cuda:0')\n(('Kenton', 'South Kenton'), ('South Kenton', 'North Wembley')) tensor(150., device='cuda:0')\n(('Kew Gardens', 'Gunnersbury'), ('Gunnersbury', 'Turnham Green')) tensor(510., device='cuda:0')\n(('Kilburn', 'West Hampstead'), ('West Hampstead', 'Finchley Road')) tensor(140., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(1., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(145., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(8., device='cuda:0')\n(('Kilburn Park', 'Maida Vale'), ('Maida Vale', 'Warwick Avenue')) tensor(1048., device='cuda:0')\n(('Kilburn Park', \"Queen's Park\"), (\"Queen's Park\", 'Kensal Green')) tensor(622., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Angel'), ('Angel', 'Old Street')) tensor(2221., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Caledonian Road'), ('Caledonian Road', 'Holloway Road')) tensor(246., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Camden Town')) tensor(1406., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Mornington Crescent')) tensor(85., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Warren Street')) tensor(881., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston Square'), ('Euston Square', 'Great Portland Street')) tensor(4062., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Farringdon'), ('Farringdon', 'Barbican')) tensor(2195., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Highbury &amp; Islington'), ('Highbury &amp; Islington', 'Finsbury Park')) tensor(1352., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Russell Square'), ('Russell Square', 'Holborn')) tensor(299., device='cuda:0')\n(('Kingsbury', 'Queensbury'), ('Queensbury', 'Canons Park')) tensor(189., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(334., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(66., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(16., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(1., device='cuda:0')\n(('Knightsbridge', 'Hyde Park Corner'), ('Hyde Park Corner', 'Green Park')) tensor(1733., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(1409., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(14., device='cuda:0')\n(('Ladbroke Grove', 'Latimer Road'), ('Latimer Road', 'Wood Lane')) tensor(299., device='cuda:0')\n(('Ladbroke Grove', 'Westbourne Park'), ('Westbourne Park', 'Royal Oak')) tensor(607., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(83., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(19., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(45., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(287., device='cuda:0')\n(('Lancaster Gate', 'Marble Arch'), ('Marble Arch', 'Bond Street')) tensor(839., device='cuda:0')\n(('Lancaster Gate', 'Queensway'), ('Queensway', 'Notting Hill Gate')) tensor(616., device='cuda:0')\n(('Latimer Road', 'Ladbroke Grove'), ('Ladbroke Grove', 'Westbourne Park')) tensor(446., device='cuda:0')\n(('Latimer Road', 'Wood Lane'), ('Wood Lane', \"Shepherd's Bush Market\")) tensor(240., device='cuda:0')\n(('Leicester Square', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(103., device='cuda:0')\n(('Leicester Square', 'Covent Garden'), ('Covent Garden', 'Holborn')) tensor(222., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(101., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(277., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(39., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(212., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(1851., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(1449., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Mile End')) tensor(1671., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'West Ham')) tensor(95., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2639., device='cuda:0')\n(('Leytonstone', 'Leyton'), ('Leyton', 'Stratford')) tensor(3987., device='cuda:0')\n(('Leytonstone', 'Snaresbrook'), ('Snaresbrook', 'South Woodford')) tensor(1706., device='cuda:0')\n(('Leytonstone', 'Wanstead'), ('Wanstead', 'Redbridge')) tensor(1245., device='cuda:0')\n(('Liverpool Street', 'Aldgate'), ('Aldgate', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(3609., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(2842., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(2155., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Bethnal Green'), ('Bethnal Green', 'Mile End')) tensor(3900., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(1688., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(1701., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(546., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(73., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2915., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(495., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(107., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1264., device='cuda:0')\n(('London Bridge', 'Bermondsey'), ('Bermondsey', 'Canada Water')) tensor(1250., device='cuda:0')\n(('London Bridge', 'Borough'), ('Borough', 'Elephant &amp; Castle')) tensor(795., device='cuda:0')\n(('London Bridge', 'Southwark'), ('Southwark', 'Waterloo')) tensor(4797., device='cuda:0')\n(('Loughton', 'Buckhurst Hill'), ('Buckhurst Hill', 'Woodford')) tensor(773., device='cuda:0')\n(('Loughton', 'Debden'), ('Debden', 'Theydon Bois')) tensor(301., device='cuda:0')\n(('Maida Vale', 'Kilburn Park'), ('Kilburn Park', \"Queen's Park\")) tensor(736., device='cuda:0')\n(('Maida Vale', 'Warwick Avenue'), ('Warwick Avenue', 'Paddington')) tensor(1186., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(21., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(806., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(328., device='cuda:0')\n(('Manor House', 'Turnpike Lane'), ('Turnpike Lane', 'Wood Green')) tensor(794., device='cuda:0')\n(('Mansion House', 'Blackfriars'), ('Blackfriars', 'Temple')) tensor(286., device='cuda:0')\n(('Mansion House', 'Cannon Street'), ('Cannon Street', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(104., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(145., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(161., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(658., device='cuda:0')\n(('Marble Arch', 'Lancaster Gate'), ('Lancaster Gate', 'Queensway')) tensor(725., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1060., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(1., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(4., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(601., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(104., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(15., device='cuda:0')\n(('Marylebone', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Paddington')) tensor(393., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(5., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(262., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(185., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(115., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(265., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(69., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(699., device='cuda:0')\n(('Mile End', 'Bethnal Green'), ('Bethnal Green', 'Liverpool Street')) tensor(3726., device='cuda:0')\n(('Mile End', 'Bow Road'), ('Bow Road', 'BromleyByBow')) tensor(112., device='cuda:0')\n(('Mile End', 'Stepney Green'), ('Stepney Green', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Leyton')) tensor(1541., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'West Ham')) tensor(1383., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(94., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(3., device='cuda:0')\n(('Moor Park', 'Croxley'), ('Croxley', 'Watford')) tensor(124., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(255., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(284., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(9., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(13., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(20., device='cuda:0')\n(('Moor Park', 'Northwood'), ('Northwood', 'Northwood Hills')) tensor(113., device='cuda:0')\n(('Moor Park', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(9., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(55., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(455., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(15., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(54., device='cuda:0')\n(('Moorgate', 'Barbican'), ('Barbican', 'Farringdon')) tensor(1978., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(187., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(1525., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(1624., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(26., device='cuda:0')\n(('Moorgate', 'Old Street'), ('Old Street', 'Angel')) tensor(2014., device='cuda:0')\n(('Morden', 'South Wimbledon'), ('South Wimbledon', 'Colliers Wood')) tensor(199., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(9., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(10., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(82., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', 'Warren Street')) tensor(88., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(114., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(14., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(5., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(108., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(8., device='cuda:0')\n(('Newbury Park', 'Barkingside'), ('Barkingside', 'Fairlop')) tensor(335., device='cuda:0')\n(('Newbury Park', 'Gants Hill'), ('Gants Hill', 'Redbridge')) tensor(742., device='cuda:0')\n(('North Acton', 'East Acton'), ('East Acton', 'White City')) tensor(131., device='cuda:0')\n(('North Acton', 'Hanger Lane'), ('Hanger Lane', 'Perivale')) tensor(534., device='cuda:0')\n(('North Acton', 'West Acton'), ('West Acton', 'Ealing Broadway')) tensor(1035., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(189., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(152., device='cuda:0')\n(('North Ealing', 'Park Royal'), ('Park Royal', 'Alperton')) tensor(180., device='cuda:0')\n(('North Greenwich', 'Canary Wharf'), ('Canary Wharf', 'Canada Water')) tensor(806., device='cuda:0')\n(('North Greenwich', 'Canning Town'), ('Canning Town', 'West Ham')) tensor(513., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(190., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(196., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(3., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(7., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(10., device='cuda:0')\n(('North Harrow', 'Pinner'), ('Pinner', 'Northwood Hills')) tensor(104., device='cuda:0')\n(('North Wembley', 'South Kenton'), ('South Kenton', 'Kenton')) tensor(163., device='cuda:0')\n(('North Wembley', 'Wembley Central'), ('Wembley Central', 'Stonebridge Park')) tensor(272., device='cuda:0')\n(('Northfields', 'Boston Manor'), ('Boston Manor', 'Osterley')) tensor(924., device='cuda:0')\n(('Northfields', 'South Ealing'), ('South Ealing', 'Acton Town')) tensor(1308., device='cuda:0')\n(('Northolt', 'Greenford'), ('Greenford', 'Perivale')) tensor(382., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'Ruislip Gardens')) tensor(51., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'West Ruislip')) tensor(73., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(92., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(110., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(7., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(2., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(13., device='cuda:0')\n(('Northwick Park', 'Preston Road'), ('Preston Road', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(257., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Northwood', 'Northwood Hills'), ('Northwood Hills', 'Pinner')) tensor(5., device='cuda:0')\n(('Northwood Hills', 'Northwood'), ('Northwood', 'Moor Park')) tensor(124., device='cuda:0')\n(('Northwood Hills', 'Pinner'), ('Pinner', 'North Harrow')) tensor(107., device='cuda:0')\n(('Notting Hill Gate', 'Bayswater'), ('Bayswater', 'Paddington')) tensor(656., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', \"Earl's Court\")) tensor(581., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', 'Gloucester Road')) tensor(194., device='cuda:0')\n(('Notting Hill Gate', 'Holland Park'), ('Holland Park', \"Shepherd's Bush (Cen)\")) tensor(462., device='cuda:0')\n(('Notting Hill Gate', 'Queensway'), ('Queensway', 'Lancaster Gate')) tensor(611., device='cuda:0')\n(('Oakwood', 'Southgate'), ('Southgate', 'Arnos Grove')) tensor(229., device='cuda:0')\n(('Old Street', 'Angel'), ('Angel', \"King's Cross St. Pancras\")) tensor(2078., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(296., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(3., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1828., device='cuda:0')\n(('Osterley', 'Boston Manor'), ('Boston Manor', 'Northfields')) tensor(1091., device='cuda:0')\n(('Osterley', 'Hounslow East'), ('Hounslow East', 'Hounslow Central')) tensor(679., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(691., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Waterloo')) tensor(837., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(155., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(859., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(169., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(672., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(178., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(519., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(999., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(361., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(304., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', \"Regent's Park\"), (\"Regent's Park\", 'Baker Street')) tensor(674., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(47., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(376., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Euston')) tensor(2437., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(48., device='cuda:0')\n(('Paddington', 'Bayswater'), ('Bayswater', 'Notting Hill Gate')) tensor(811., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(2429., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(891., device='cuda:0')\n(('Paddington', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Marylebone')) tensor(353., device='cuda:0')\n(('Paddington', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Baker Street')) tensor(5928., device='cuda:0')\n(('Paddington', 'Royal Oak'), ('Royal Oak', 'Westbourne Park')) tensor(686., device='cuda:0')\n(('Paddington', 'Warwick Avenue'), ('Warwick Avenue', 'Maida Vale')) tensor(976., device='cuda:0')\n(('Park Royal', 'Alperton'), ('Alperton', 'Sudbury Town')) tensor(128., device='cuda:0')\n(('Park Royal', 'North Ealing'), ('North Ealing', 'Ealing Common')) tensor(305., device='cuda:0')\n(('Parsons Green', 'Fulham Broadway'), ('Fulham Broadway', 'West Brompton')) tensor(1506., device='cuda:0')\n(('Parsons Green', 'Putney Bridge'), ('Putney Bridge', 'East Putney')) tensor(828., device='cuda:0')\n(('Perivale', 'Greenford'), ('Greenford', 'Northolt')) tensor(321., device='cuda:0')\n(('Perivale', 'Hanger Lane'), ('Hanger Lane', 'North Acton')) tensor(621., device='cuda:0')\n(('Piccadilly Circus', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(180., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Bond Street')) tensor(220., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(74., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(109., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(106., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(138., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(82., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(218., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(215., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(80., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(174., device='cuda:0')\n(('Pimlico', 'Vauxhall'), ('Vauxhall', 'Stockwell')) tensor(940., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Green Park')) tensor(1025., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(258., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(89., device='cuda:0')\n(('Pinner', 'North Harrow'), ('North Harrow', 'HarrowOnTheHill')) tensor(261., device='cuda:0')\n(('Pinner', 'Northwood Hills'), ('Northwood Hills', 'Northwood')) tensor(5., device='cuda:0')\n(('Plaistow', 'Upton Park'), ('Upton Park', 'East Ham')) tensor(1., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Barking')) tensor(9., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(4., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(97., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Stratford')) tensor(770., device='cuda:0')\n(('Preston Road', 'Northwick Park'), ('Northwick Park', 'HarrowOnTheHill')) tensor(23., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(84., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(22., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(2., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(5., device='cuda:0')\n(('Putney Bridge', 'East Putney'), ('East Putney', 'Southfields')) tensor(577., device='cuda:0')\n(('Putney Bridge', 'Parsons Green'), ('Parsons Green', 'Fulham Broadway')) tensor(1250., device='cuda:0')\n((\"Queen's Park\", 'Kensal Green'), ('Kensal Green', 'Willesden Junction')) tensor(551., device='cuda:0')\n((\"Queen's Park\", 'Kilburn Park'), ('Kilburn Park', 'Maida Vale')) tensor(903., device='cuda:0')\n(('Queensbury', 'Canons Park'), ('Canons Park', 'Stanmore')) tensor(99., device='cuda:0')\n(('Queensbury', 'Kingsbury'), ('Kingsbury', 'Wembley Park')) tensor(312., device='cuda:0')\n(('Queensway', 'Lancaster Gate'), ('Lancaster Gate', 'Marble Arch')) tensor(723., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(18., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(165., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(333., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(76., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(173., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Ravenscourt Park', 'Stamford Brook'), ('Stamford Brook', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Rayners Lane', 'Eastcote'), ('Eastcote', 'Ruislip Manor')) tensor(743., device='cuda:0')\n(('Rayners Lane', 'South Harrow'), ('South Harrow', 'Sudbury Hill')) tensor(253., device='cuda:0')\n(('Rayners Lane', 'West Harrow'), ('West Harrow', 'HarrowOnTheHill')) tensor(1408., device='cuda:0')\n(('Redbridge', 'Gants Hill'), ('Gants Hill', 'Newbury Park')) tensor(701., device='cuda:0')\n(('Redbridge', 'Wanstead'), ('Wanstead', 'Leytonstone')) tensor(1302., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(426., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(150., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(6., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(106., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(12., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(40., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(211., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(26., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(347., device='cuda:0')\n(('Richmond', 'Kew Gardens'), ('Kew Gardens', 'Gunnersbury')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'Chorleywood'), ('Chorleywood', 'Chalfont &amp; Latimer')) tensor(312., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(276., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(9., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(11., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(7., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(3., device='cuda:0')\n(('Roding Valley', 'Chigwell'), ('Chigwell', 'Grange Hill')) tensor(261., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(8., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'South Woodford')) tensor(372., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Bayswater')) tensor(47., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(92., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(54., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(684., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(8., device='cuda:0')\n(('Royal Oak', 'Westbourne Park'), ('Westbourne Park', 'Ladbroke Grove')) tensor(569., device='cuda:0')\n(('Ruislip', 'Ickenham'), ('Ickenham', 'Hillingdon')) tensor(398., device='cuda:0')\n(('Ruislip', 'Ruislip Manor'), ('Ruislip Manor', 'Eastcote')) tensor(712., device='cuda:0')\n(('Ruislip Gardens', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(78., device='cuda:0')\n(('Ruislip Manor', 'Eastcote'), ('Eastcote', 'Rayners Lane')) tensor(825., device='cuda:0')\n(('Ruislip Manor', 'Ruislip'), ('Ruislip', 'Ickenham')) tensor(496., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(119., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(90., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(327., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(59., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(40., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(91., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(86., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(53., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(151., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(66., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(387., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(335., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(153., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(561., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'Holland Park'), ('Holland Park', 'Notting Hill Gate')) tensor(468., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'White City'), ('White City', 'East Acton')) tensor(93., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Goldhawk Road'), ('Goldhawk Road', 'Hammersmith (H&amp;C)')) tensor(77., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Wood Lane'), ('Wood Lane', 'Latimer Road')) tensor(279., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(2467., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(15., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Green Park')) tensor(1713., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Pimlico')) tensor(260., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(1042., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(2080., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(7., device='cuda:0')\n(('Snaresbrook', 'South Woodford'), ('South Woodford', 'Woodford')) tensor(1415., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(8., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(1168., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(212., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(25., device='cuda:0')\n(('South Ealing', 'Northfields'), ('Northfields', 'Boston Manor')) tensor(1019., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(62., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(316., device='cuda:0')\n(('South Harrow', 'Sudbury Hill'), ('Sudbury Hill', 'Sudbury Town')) tensor(183., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', \"Earl's Court\")) tensor(3171., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', 'High Street Kensington')) tensor(414., device='cuda:0')\n(('South Kensington', 'Knightsbridge'), ('Knightsbridge', 'Hyde Park Corner')) tensor(1538., device='cuda:0')\n(('South Kensington', 'Sloane Square'), ('Sloane Square', 'Victoria')) tensor(2746., device='cuda:0')\n(('South Kenton', 'Kenton'), ('Kenton', 'Harrow &amp; Wealdstone')) tensor(119., device='cuda:0')\n(('South Kenton', 'North Wembley'), ('North Wembley', 'Wembley Central')) tensor(207., device='cuda:0')\n(('South Ruislip', 'Northolt'), ('Northolt', 'Greenford')) tensor(252., device='cuda:0')\n(('South Wimbledon', 'Colliers Wood'), ('Colliers Wood', 'Tooting Broadway')) tensor(328., device='cuda:0')\n(('South Woodford', 'Snaresbrook'), ('Snaresbrook', 'Leytonstone')) tensor(1888., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(830., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(309., device='cuda:0')\n(('Southfields', 'East Putney'), ('East Putney', 'Putney Bridge')) tensor(677., device='cuda:0')\n(('Southfields', 'Wimbledon Park'), ('Wimbledon Park', 'Wimbledon')) tensor(255., device='cuda:0')\n(('Southgate', 'Arnos Grove'), ('Arnos Grove', 'Bounds Green')) tensor(390., device='cuda:0')\n(('Southgate', 'Oakwood'), ('Oakwood', 'Cockfosters')) tensor(101., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(3604., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(1002., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Borough')) tensor(52., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(279., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(640., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(45., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(3875., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Green Park')) tensor(132., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Pimlico')) tensor(84., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1027., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Embankment')) tensor(128., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Green Park')) tensor(135., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Waterloo')) tensor(1190., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(168., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(54., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(119., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(16., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(11., device='cuda:0')\n((\"St. John's Wood\", 'Swiss Cottage'), ('Swiss Cottage', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(49., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2220., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(86., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(13., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1106., device='cuda:0')\n((\"St. Paul's\", 'Chancery Lane'), ('Chancery Lane', 'Holborn')) tensor(3317., device='cuda:0')\n(('Stamford Brook', 'Ravenscourt Park'), ('Ravenscourt Park', 'Hammersmith (Dis)')) tensor(63., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(89., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(6., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(67., device='cuda:0')\n(('Stanmore', 'Canons Park'), ('Canons Park', 'Queensbury')) tensor(110., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(132., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(5., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(24., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(214., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(25., device='cuda:0')\n(('Stockwell', 'Clapham North'), ('Clapham North', 'Clapham Common')) tensor(1366., device='cuda:0')\n(('Stockwell', 'Oval'), ('Oval', 'Kennington')) tensor(1370., device='cuda:0')\n(('Stockwell', 'Vauxhall'), ('Vauxhall', 'Pimlico')) tensor(928., device='cuda:0')\n(('Stonebridge Park', 'Harlesden'), ('Harlesden', 'Willesden Junction')) tensor(443., device='cuda:0')\n(('Stonebridge Park', 'Wembley Central'), ('Wembley Central', 'North Wembley')) tensor(257., device='cuda:0')\n(('Stratford', 'Leyton'), ('Leyton', 'Leytonstone')) tensor(3711., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(3185., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bow Road')) tensor(8., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(27., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Barking')) tensor(2374., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(7., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Canning Town')) tensor(170., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Plaistow')) tensor(707., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(5039., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(26., device='cuda:0')\n(('Sudbury Hill', 'South Harrow'), ('South Harrow', 'Rayners Lane')) tensor(290., device='cuda:0')\n(('Sudbury Hill', 'Sudbury Town'), ('Sudbury Town', 'Alperton')) tensor(143., device='cuda:0')\n(('Sudbury Town', 'Alperton'), ('Alperton', 'Park Royal')) tensor(166., device='cuda:0')\n(('Sudbury Town', 'Sudbury Hill'), ('Sudbury Hill', 'South Harrow')) tensor(190., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(180., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(4., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(8., device='cuda:0')\n(('Swiss Cottage', \"St. John's Wood\"), (\"St. John's Wood\", 'Baker Street')) tensor(175., device='cuda:0')\n(('Temple', 'Blackfriars'), ('Blackfriars', 'Mansion House')) tensor(291., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(57., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Waterloo')) tensor(44., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Westminster')) tensor(487., device='cuda:0')\n(('Theydon Bois', 'Debden'), ('Debden', 'Loughton')) tensor(447., device='cuda:0')\n(('Tooting Bec', 'Balham'), ('Balham', 'Clapham South')) tensor(939., device='cuda:0')\n(('Tooting Bec', 'Tooting Broadway'), ('Tooting Broadway', 'Colliers Wood')) tensor(404., device='cuda:0')\n(('Tooting Broadway', 'Colliers Wood'), ('Colliers Wood', 'South Wimbledon')) tensor(264., device='cuda:0')\n(('Tooting Broadway', 'Tooting Bec'), ('Tooting Bec', 'Balham')) tensor(763., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2377., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(244., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(630., device='cuda:0')\n(('Tottenham Court Road', 'Goodge Street'), ('Goodge Street', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(3254., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(104., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Russell Square')) tensor(322., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(154., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(101., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(86., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(245., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(80., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(40., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Hale', 'Blackhorse Road'), ('Blackhorse Road', 'Walthamstow Central')) tensor(197., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(24., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(138., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(566., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(133., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(26., device='cuda:0')\n(('Tottenham Hale', 'Seven Sisters'), ('Seven Sisters', 'Finsbury Park')) tensor(690., device='cuda:0')\n(('Totteridge &amp; Whetstone', 'Woodside Park'), ('Woodside Park', 'West Finchley')) tensor(259., device='cuda:0')\n(('Tower Hill', 'Aldgate'), ('Aldgate', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(2085., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(96., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(17., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(1239., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(59., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(1078., device='cuda:0')\n(('Tufnell Park', 'Archway'), ('Archway', 'Highgate')) tensor(965., device='cuda:0')\n(('Tufnell Park', 'Kentish Town'), ('Kentish Town', 'Camden Town')) tensor(1387., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(769., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(21., device='cuda:0')\n(('Turnham Green', 'Gunnersbury'), ('Gunnersbury', 'Kew Gardens')) tensor(470., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(367., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnham Green', 'Stamford Brook'), ('Stamford Brook', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnpike Lane', 'Manor House'), ('Manor House', 'Finsbury Park')) tensor(1014., device='cuda:0')\n(('Turnpike Lane', 'Wood Green'), ('Wood Green', 'Bounds Green')) tensor(618., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'Upney')) tensor(5., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'West Ham')) tensor(735., device='cuda:0')\n(('Upminster', 'Upminster Bridge'), ('Upminster Bridge', 'Hornchurch')) tensor(468., device='cuda:0')\n(('Upminster Bridge', 'Hornchurch'), ('Hornchurch', 'Elm Park')) tensor(269., device='cuda:0')\n(('Upminster Bridge', 'Upminster'), ('Upminster', 'Barking')) tensor(571., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'Upminster')) tensor(4., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'West Ham')) tensor(779., device='cuda:0')\n(('Upney', 'Becontree'), ('Becontree', 'Dagenham Heathway')) tensor(478., device='cuda:0')\n(('Upton Park', 'East Ham'), ('East Ham', 'Barking')) tensor(8., device='cuda:0')\n(('Upton Park', 'Plaistow'), ('Plaistow', 'West Ham')) tensor(464., device='cuda:0')\n(('Uxbridge', 'Hillingdon'), ('Hillingdon', 'Ickenham')) tensor(256., device='cuda:0')\n(('Vauxhall', 'Pimlico'), ('Pimlico', 'Victoria')) tensor(1094., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(152., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(680., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Oval')) tensor(173., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Bond Street')) tensor(835., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(23., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(974., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(116., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Westminster')) tensor(1201., device='cuda:0')\n(('Victoria', 'Pimlico'), ('Pimlico', 'Vauxhall')) tensor(1093., device='cuda:0')\n(('Victoria', 'Sloane Square'), ('Sloane Square', 'South Kensington')) tensor(2745., device='cuda:0')\n(('Victoria', \"St. James's Park\"), (\"St. James's Park\", 'Westminster')) tensor(1214., device='cuda:0')\n(('Walthamstow Central', 'Blackhorse Road'), ('Blackhorse Road', 'Tottenham Hale')) tensor(221., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(1544., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(15., device='cuda:0')\n(('Wanstead', 'Redbridge'), ('Redbridge', 'Gants Hill')) tensor(1049., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Camden Town')) tensor(1550., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(881., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Mornington Crescent')) tensor(73., device='cuda:0')\n(('Warren Street', 'Goodge Street'), ('Goodge Street', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(553., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(1574., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(182., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(369., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warwick Avenue', 'Maida Vale'), ('Maida Vale', 'Kilburn Park')) tensor(836., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Bayswater')) tensor(103., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(58., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(43., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(1143., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(8., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(229., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Temple')) tensor(53., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(231., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Oval')) tensor(779., device='cuda:0')\n(('Waterloo', 'Lambeth North'), ('Lambeth North', 'Elephant &amp; Castle')) tensor(226., device='cuda:0')\n(('Waterloo', 'Southwark'), ('Southwark', 'London Bridge')) tensor(4777., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', 'Green Park')) tensor(3439., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(1183., device='cuda:0')\n(('Watford', 'Croxley'), ('Croxley', 'Moor Park')) tensor(122., device='cuda:0')\n(('Wembley Central', 'North Wembley'), ('North Wembley', 'South Kenton')) tensor(199., device='cuda:0')\n(('Wembley Central', 'Stonebridge Park'), ('Stonebridge Park', 'Harlesden')) tensor(356., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(657., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(13., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(68., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(14., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(4., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(7., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(36., device='cuda:0')\n(('Wembley Park', 'Kingsbury'), ('Kingsbury', 'Queensbury')) tensor(311., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Dollis Hill')) tensor(14., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Preston Road'), ('Preston Road', 'Northwick Park')) tensor(4., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(61., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(1040., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'East Acton')) tensor(149., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(600., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(144., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1519., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(344., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(7., device='cuda:0')\n(('West Brompton', 'Fulham Broadway'), ('Fulham Broadway', 'Parsons Green')) tensor(1357., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(468., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(2., device='cuda:0')\n(('West Finchley', 'Woodside Park'), ('Woodside Park', 'Totteridge &amp; Whetstone')) tensor(221., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'East Ham')) tensor(588., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upminster')) tensor(788., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upney')) tensor(857., device='cuda:0')\n(('West Ham', 'BromleyByBow'), ('BromleyByBow', 'Bow Road')) tensor(16., device='cuda:0')\n(('West Ham', 'Canning Town'), ('Canning Town', 'North Greenwich')) tensor(490., device='cuda:0')\n(('West Ham', 'Plaistow'), ('Plaistow', 'Upton Park')) tensor(482., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Leyton')) tensor(122., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Mile End')) tensor(1283., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2023., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(267., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(19., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(4., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(13., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Hampstead', 'Kilburn'), ('Kilburn', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(660., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(779., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(13., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(31., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(853., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(270., device='cuda:0')\n(('West Kensington', 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(205., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(40., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(5., device='cuda:0')\n(('West Ruislip', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(64., device='cuda:0')\n(('Westbourne Park', 'Ladbroke Grove'), ('Ladbroke Grove', 'Latimer Road')) tensor(405., device='cuda:0')\n(('Westbourne Park', 'Royal Oak'), ('Royal Oak', 'Paddington')) tensor(780., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(5., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Temple')) tensor(525., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Bond Street')) tensor(1478., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(1051., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(353., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(101., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Victoria')) tensor(1205., device='cuda:0')\n(('Westminster', \"St. James's Park\"), (\"St. James's Park\", 'Victoria')) tensor(1204., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(372., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(319., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(3784., device='cuda:0')\n(('White City', 'East Acton'), ('East Acton', 'North Acton')) tensor(127., device='cuda:0')\n(('White City', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'Holland Park')) tensor(279., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(3522., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(2077., device='cuda:0')\n(('Whitechapel', 'Stepney Green'), ('Stepney Green', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Leyton')) tensor(2499., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'West Ham')) tensor(2098., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(512., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(27., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(8., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Kilburn'), ('Kilburn', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Junction', 'Harlesden'), ('Harlesden', 'Stonebridge Park')) tensor(405., device='cuda:0')\n(('Willesden Junction', 'Kensal Green'), ('Kensal Green', \"Queen's Park\")) tensor(678., device='cuda:0')\n(('Wimbledon', 'Wimbledon Park'), ('Wimbledon Park', 'Southfields')) tensor(299., device='cuda:0')\n(('Wimbledon Park', 'Southfields'), ('Southfields', 'East Putney')) tensor(456., device='cuda:0')\n(('Wood Green', 'Bounds Green'), ('Bounds Green', 'Arnos Grove')) tensor(479., device='cuda:0')\n(('Wood Green', 'Turnpike Lane'), ('Turnpike Lane', 'Manor House')) tensor(831., device='cuda:0')\n(('Wood Lane', 'Latimer Road'), ('Latimer Road', 'Ladbroke Grove')) tensor(346., device='cuda:0')\n(('Wood Lane', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Goldhawk Road')) tensor(133., device='cuda:0')\n(('Woodford', 'Buckhurst Hill'), ('Buckhurst Hill', 'Loughton')) tensor(683., device='cuda:0')\n(('Woodford', 'Roding Valley'), ('Roding Valley', 'Chigwell')) tensor(294., device='cuda:0')\n(('Woodford', 'South Woodford'), ('South Woodford', 'Snaresbrook')) tensor(1601., device='cuda:0')\n(('Woodside Park', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'High Barnet')) tensor(132., device='cuda:0')\n(('Woodside Park', 'West Finchley'), ('West Finchley', 'Finchley Central')) tensor(384., device='cuda:0')\n</pre> In\u00a0[5]: Copied! <pre>g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')]\n</pre> g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')] Out[5]: <pre>tensor(279., device='cuda:0')</pre> In\u00a0[6]: Copied! <pre>paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2)\ng2 = pp2.HigherOrderNetwork(paths, k=2)\nprint(g2)\n</pre> paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2) g2 = pp2.HigherOrderNetwork(paths, k=2) print(g2) <pre>2024-03-27 11:21:58 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:58 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:58 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n</pre> In\u00a0[7]: Copied! <pre>ks = range(1,10)\ntimes = []\nfor k in ks:\n    start = time.time() \n    paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)\n    g2 = pp2.HigherOrderNetwork(paths, k=k)\n    print(g2)\n    elapsed_pp = time.time()-start\n    times.append(elapsed_pp)\nplt.plot(ks, times)\n</pre> ks = range(1,10) times = [] for k in ks:     start = time.time()      paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)     g2 = pp2.HigherOrderNetwork(paths, k=k)     print(g2)     elapsed_pp = time.time()-start     times.append(elapsed_pp) plt.plot(ks, times) <pre>2024-03-27 11:21:59 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:59 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished.\nHigher-order network of order k = 1\n\nNodes:\t\t\t\t268\nLinks:\t\t\t\t646\nTotal weight (subpaths/longest paths):\t14404381.0/99956.0\n\n2024-03-27 11:22:00 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:00 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n2024-03-27 11:22:01 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:01 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished.\nHigher-order network of order k = 3\n\nNodes:\t\t\t\t1889\nLinks:\t\t\t\t1869\nTotal weight (subpaths/longest paths):\t10078001.0/230562.0\n\n2024-03-27 11:22:02 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:02 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:03 [Severity.INFO]\tfinished.\nHigher-order network of order k = 4\n\nNodes:\t\t\t\t5770\nLinks:\t\t\t\t2730\nTotal weight (subpaths/longest paths):\t8198110.0/236412.0\n\n2024-03-27 11:22:04 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:04 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:04 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:05 [Severity.INFO]\tfinished.\nHigher-order network of order k = 5\n\nNodes:\t\t\t\t19424\nLinks:\t\t\t\t3683\nTotal weight (subpaths/longest paths):\t6547275.0/243768.0\n\n2024-03-27 11:22:06 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:06 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:06 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:08 [Severity.INFO]\tfinished.\nHigher-order network of order k = 6\n\nNodes:\t\t\t\t66882\nLinks:\t\t\t\t4748\nTotal weight (subpaths/longest paths):\t5174028.0/209948.0\n\n2024-03-27 11:22:09 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:09 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:09 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:11 [Severity.INFO]\tfinished.\nHigher-order network of order k = 7\n\nNodes:\t\t\t\t242779\nLinks:\t\t\t\t5745\nTotal weight (subpaths/longest paths):\t4044268.0/176409.0\n\n2024-03-27 11:22:14 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:15 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:15 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:17 [Severity.INFO]\tfinished.\nHigher-order network of order k = 8\n\nNodes:\t\t\t\t888479\nLinks:\t\t\t\t6463\nTotal weight (subpaths/longest paths):\t3116104.0/151222.0\n\n2024-03-27 11:22:29 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:29 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:29 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:31 [Severity.INFO]\tfinished.\nHigher-order network of order k = 9\n\nNodes:\t\t\t\t3348421\nLinks:\t\t\t\t7053\nTotal weight (subpaths/longest paths):\t2349934.0/140450.0\n\n</pre> Out[7]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f081d30d9c0&gt;]</pre> In\u00a0[15]: Copied! <pre>pp.config['torch']['device'] = 'cuda:0'\n</pre> pp.config['torch']['device'] = 'cuda:0' In\u00a0[16]: Copied! <pre>ks = range(1,10)\ntimes_new_gpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_gpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_gpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_gpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[17]: Copied! <pre>pp.config['torch']['device'] = 'cpu'\n</pre> pp.config['torch']['device'] = 'cpu' In\u00a0[18]: Copied! <pre>ks = range(1,10)\ntimes_new_cpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_cpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_cpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_cpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[19]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.grid()\nplt.ylabel('time [s]')\nplt.legend()\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.grid() plt.ylabel('time [s]') plt.legend() Out[19]: <pre>&lt;matplotlib.legend.Legend at 0x7f082668d9f0&gt;</pre> In\u00a0[20]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.ylabel('time [s]')\nplt.legend()\nplt.grid()\nplt.yscale('log')\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.ylabel('time [s]') plt.legend() plt.grid() plt.yscale('log') In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_higher_order_scalability/#pathpy-20","title":"Pathpy 2.0\u00b6","text":""},{"location":"tutorial/_higher_order_scalability/#pathpyg-gpu","title":"pathpyG (GPU)\u00b6","text":""},{"location":"tutorial/_higher_order_scalability/#pathpyg-cpu","title":"pathpyG (CPU)\u00b6","text":""},{"location":"tutorial/_multi_order_concepts/","title":"multi order concepts","text":"In\u00a0[\u00a0]: Copied! <pre>def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int, edge_weights: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Do a line graph transformation on the edge index to lift the order of the graph by one.\n\n        Args:\n            edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n            num_nodes: The number of nodes in the graph.\n        \"\"\"\n\n        # Since this is a complicated function, we will use the following example to explain the steps:\n        # Example:\n        #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],\n        #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]\n\n        # Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge\n        # Example:\n        #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]\n        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n\n        # For each center node, we need to combine each outgoing edge with each incoming edge\n        # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index\n        # Example:\n        #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]\n        #   num_new_edges = 9\n        outdegree_per_dst = outdegree[edge_index[1]]\n        num_new_edges = outdegree_per_dst.sum()\n\n        # Use each edge from the edge index as node and assign the new indices in the order of the original edge index\n        # Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n        # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor\n        # Example:\n        #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]\n        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n        # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges\n        # (new higher-order nodes) that have the node as source node\n        # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and\n        # we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])\n        # Example:\n        #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]\n        ptrs = cumsum(outdegree, dim=0)[:-1]\n\n        # Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times\n        # Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively\n        # Example:\n        #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n\n        # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...)\n        # for all `outdegree` number of edges consecutively to get the correct destination nodes\n        # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\n        # Example:\n        #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n        # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.\n        # Example:\n        #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]\n        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n        # Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge\n        # Example:\n        #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts += idx_correction\n        # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n        #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</pre> def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int, edge_weights: torch.Tensor) -&gt; torch.Tensor:         \"\"\"         Do a line graph transformation on the edge index to lift the order of the graph by one.          Args:             edge_index: A **sorted** edge index tensor of shape (2, num_edges).             num_nodes: The number of nodes in the graph.         \"\"\"          # Since this is a complicated function, we will use the following example to explain the steps:         # Example:         #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],         #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]          # Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge         # Example:         #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]         outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)          # For each center node, we need to combine each outgoing edge with each incoming edge         # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index         # Example:         #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]         #   num_new_edges = 9         outdegree_per_dst = outdegree[edge_index[1]]         num_new_edges = outdegree_per_dst.sum()          # Use each edge from the edge index as node and assign the new indices in the order of the original edge index         # Each higher order node has one outgoing edge for each outgoing edge of the original destination node         # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor         # Example:         #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]         ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)          # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges         # (new higher-order nodes) that have the node as source node         # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and         # we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])         # Example:         #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]         ptrs = cumsum(outdegree, dim=0)[:-1]          # Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times         # Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively         # Example:         #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]         ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)          # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...)         # for all `outdegree` number of edges consecutively to get the correct destination nodes         # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)         # Example:         #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]         idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)         # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.         # Example:         #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]         idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]         # Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge         # Example:         #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]         ho_edge_dsts += idx_correction         # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],         #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])         return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)"},{"location":"tutorial/_multi_order_concepts/#todo-create-a-notebook-that-explains-the-new-concepts-for-order-lifting-for-dags-and-temporal-graphs","title":"TODO: Create a Notebook that explains the new concepts for order lifting for DAGs and temporal graphs.\u00b6","text":""},{"location":"tutorial/_new_pathData_test/","title":"new pathData test","text":"In\u00a0[39]: Copied! <pre>from typing import Optional\n\nfrom tqdm import trange\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.experimental import disable_dynamic_shapes\nfrom torch_geometric.nn.aggr import Aggregation\nfrom torch_geometric.utils import coalesce, degree, cumsum\nfrom torch_geometric import EdgeIndex\n\nimport pathpyG as pp\n</pre> from typing import Optional  from tqdm import trange import torch from torch import Tensor from torch_geometric.data import Data from torch_geometric.loader import DataLoader from torch_geometric.nn import MessagePassing from torch_geometric.experimental import disable_dynamic_shapes from torch_geometric.nn.aggr import Aggregation from torch_geometric.utils import coalesce, degree, cumsum from torch_geometric import EdgeIndex  import pathpyG as pp In\u00a0[40]: Copied! <pre>dags = pp.DAGData()\ndags.append(torch.tensor([[3,0,1],[0,1,2]]))\ndags.append(torch.tensor([[1,0,2],[0,2,0]]))\ndags.append(torch.tensor([[0,1],[1,2]]))\n</pre> dags = pp.DAGData() dags.append(torch.tensor([[3,0,1],[0,1,2]])) dags.append(torch.tensor([[1,0,2],[0,2,0]])) dags.append(torch.tensor([[0,1],[1,2]])) In\u00a0[41]: Copied! <pre>print(dags)\n</pre> print(dags) <pre>DAGData with 3 dags and total weight 3\n</pre> In\u00a0[50]: Copied! <pre>def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor, num_nodes: int | None = None) -&gt; torch.Tensor:\n        # Since this is a complicated function, we will use the following example to explain the steps:\n        # Example:\n        #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],\n        #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]\n\n        # Compute the outdegree of each node which we will use to get all the edge combinations that lead to a higher order edge\n        # Example:\n        #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]\n        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n\n        # For each center node, we need to combine each outgoing edge with each incoming edge\n        # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index\n        # Example:\n        #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]\n        #   num_new_edges = 9\n        outdegree_per_dst = outdegree[edge_index[1]]\n        num_new_edges = outdegree_per_dst.sum()\n\n        # We use each edge from the edge index as new node and assign the new indices in the order of the original edge index\n        # Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n        # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor\n        # Example:\n        #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]\n        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n        # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges (new higher order nodes) that have the node as source node\n        # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])\n        # Example:\n        #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]\n        ptrs = cumsum(outdegree, dim=0)[:-1]\n\n        # Use these pointers to get the start of the edges for each higher order source node and repeat it `outdegree` times\n        # Since we keep the ordering, all new higher order edges that have the same source node are indexed consecutively\n        # Example:\n        #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n\n        # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) for all `outdegree` number of edges consecutively to get the correct destination nodes\n        # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\n        # Example: \n        #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n        # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.\n        # Example:\n        #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]\n        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n        # Finally, we add this tensor to the destination nodes to get the correct destination nodes for each higher order edge\n        # Example:\n        #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts += idx_correction\n    # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n    #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</pre> def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor, num_nodes: int | None = None) -&gt; torch.Tensor:         # Since this is a complicated function, we will use the following example to explain the steps:         # Example:         #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],         #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]          # Compute the outdegree of each node which we will use to get all the edge combinations that lead to a higher order edge         # Example:         #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]         outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)          # For each center node, we need to combine each outgoing edge with each incoming edge         # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index         # Example:         #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]         #   num_new_edges = 9         outdegree_per_dst = outdegree[edge_index[1]]         num_new_edges = outdegree_per_dst.sum()          # We use each edge from the edge index as new node and assign the new indices in the order of the original edge index         # Each higher order node has one outgoing edge for each outgoing edge of the original destination node         # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor         # Example:         #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]         ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)          # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges (new higher order nodes) that have the node as source node         # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])         # Example:         #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]         ptrs = cumsum(outdegree, dim=0)[:-1]          # Use these pointers to get the start of the edges for each higher order source node and repeat it `outdegree` times         # Since we keep the ordering, all new higher order edges that have the same source node are indexed consecutively         # Example:         #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]         ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)          # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) for all `outdegree` number of edges consecutively to get the correct destination nodes         # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)         # Example:          #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]         idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)         # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.         # Example:         #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]         idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]         # Finally, we add this tensor to the destination nodes to get the correct destination nodes for each higher order edge         # Example:         #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]         ho_edge_dsts += idx_correction     # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],     #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])         return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0) In\u00a0[77]: Copied! <pre>def map_higher_order_index(edge_indices, k):\n    \"\"\"map node indices in k-th order edge index\n    to corresponding tensor of k first-order nodes\n    \"\"\" \n\n    # we need to reverse the node indices\n    # to construct an edge_index with k-th order nodes\n    \n    ei = edge_indices[k].reshape(2,-1,1)\n    \n    j = 0\n    for i in range(k-1, 0, -1):\n        src_edge, tgt_edge = ei\n        src = edge_indices[i][:,src_edge]\n        tgt = edge_indices[i][:,tgt_edge]\n        if j == 0:\n            ei = torch.cat([src, tgt], dim=2)\n        else:\n            ei = torch.cat([src[:,:,:j], tgt], dim=2)\n        j -= 1\n    return ei\n</pre> def map_higher_order_index(edge_indices, k):     \"\"\"map node indices in k-th order edge index     to corresponding tensor of k first-order nodes     \"\"\"       # we need to reverse the node indices     # to construct an edge_index with k-th order nodes          ei = edge_indices[k].reshape(2,-1,1)          j = 0     for i in range(k-1, 0, -1):         src_edge, tgt_edge = ei         src = edge_indices[i][:,src_edge]         tgt = edge_indices[i][:,tgt_edge]         if j == 0:             ei = torch.cat([src, tgt], dim=2)         else:             ei = torch.cat([src[:,:,:j], tgt], dim=2)         j -= 1     return ei In\u00a0[81]: Copied! <pre>def from_DAGs(data: pp.DAGData, max_order: int = 1) -&gt; pp.MultiOrderModel:\n    \"\"\"Creates multiple higher-order De Bruijn graphs for paths in DAGData.\"\"\"\n    m = pp.MultiOrderModel()\n\n    data_list = [Data(edge_index=dag.long()) for dag in data.dags]\n    # We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs\n    # If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards\n    # Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once\n    dag_graph = next(iter(DataLoader(data_list, batch_size=len(data.dags))))\n    dag_edge_index = dag_graph.edge_index\n    dag_edge_index = coalesce(dag_edge_index)\n\n    print(dag_edge_index)\n    print(dag_graph.ptr)\n    print(dag_graph.batch)\n\n    edge_index = pp.MultiOrderModel.map_batch_indices(dag_edge_index, dag_graph.batch, dag_graph.ptr)\n    unique_nodes = torch.unique(edge_index)\n    m.layers[1] = pp.Graph(Data(edge_index=edge_index, num_nodes=unique_nodes.size(), fo_nodes=unique_nodes.reshape(-1, 1)))\n    print(m.layers[1].data.edge_index)\n    print(m.layers[1].data.fo_nodes)\n\n    edge_indices = {}\n    edge_indices[1] = edge_index\n\n    for k in range(2, max_order+1):\n        print('=== k={0} ==='.format(k))\n        num_nodes = torch.unique(dag_edge_index).size(0)\n        print('num nodes = ', num_nodes)\n        ho_index = lift_order_edge_index(dag_edge_index, num_nodes = num_nodes)\n        edge_indices[k] = ho_index\n        print(ho_index)\n\n        # Map k-th-order edge index to nodes in (k-1)-th order edge index\n        # src_edge, tgt_edge = ho_index\n        # src = dag_edge_index[:,src_edge]\n        # tgt = dag_edge_index[:,tgt_edge]\n        # print(src)\n        # print(tgt)\n\n        #ho_edge_index, inverse = x.unique(dim=0, return_inverse=True)\n\n        # weights of the two unique higher-order edges should be N and 3*N\n        # weights of k-th element in output = sum of all w at indices where inverse is k\n        #weights = torch.zeros(ho_edge_index.size()[0], device=config['torch']['device'], dtype=torch.long).index_add(0, inverse, w)\n \n\n        #m.layers[k] = pp.Graph(data=Data(edge_index=dag_edge_index))\n\n        dag_edge_index = coalesce(ho_index)\n\n    return m, edge_indices\n</pre> def from_DAGs(data: pp.DAGData, max_order: int = 1) -&gt; pp.MultiOrderModel:     \"\"\"Creates multiple higher-order De Bruijn graphs for paths in DAGData.\"\"\"     m = pp.MultiOrderModel()      data_list = [Data(edge_index=dag.long()) for dag in data.dags]     # We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs     # If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards     # Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once     dag_graph = next(iter(DataLoader(data_list, batch_size=len(data.dags))))     dag_edge_index = dag_graph.edge_index     dag_edge_index = coalesce(dag_edge_index)      print(dag_edge_index)     print(dag_graph.ptr)     print(dag_graph.batch)      edge_index = pp.MultiOrderModel.map_batch_indices(dag_edge_index, dag_graph.batch, dag_graph.ptr)     unique_nodes = torch.unique(edge_index)     m.layers[1] = pp.Graph(Data(edge_index=edge_index, num_nodes=unique_nodes.size(), fo_nodes=unique_nodes.reshape(-1, 1)))     print(m.layers[1].data.edge_index)     print(m.layers[1].data.fo_nodes)      edge_indices = {}     edge_indices[1] = edge_index      for k in range(2, max_order+1):         print('=== k={0} ==='.format(k))         num_nodes = torch.unique(dag_edge_index).size(0)         print('num nodes = ', num_nodes)         ho_index = lift_order_edge_index(dag_edge_index, num_nodes = num_nodes)         edge_indices[k] = ho_index         print(ho_index)          # Map k-th-order edge index to nodes in (k-1)-th order edge index         # src_edge, tgt_edge = ho_index         # src = dag_edge_index[:,src_edge]         # tgt = dag_edge_index[:,tgt_edge]         # print(src)         # print(tgt)          #ho_edge_index, inverse = x.unique(dim=0, return_inverse=True)          # weights of the two unique higher-order edges should be N and 3*N         # weights of k-th element in output = sum of all w at indices where inverse is k         #weights = torch.zeros(ho_edge_index.size()[0], device=config['torch']['device'], dtype=torch.long).index_add(0, inverse, w)            #m.layers[k] = pp.Graph(data=Data(edge_index=dag_edge_index))          dag_edge_index = coalesce(ho_index)      return m, edge_indices In\u00a0[82]: Copied! <pre>m, edge_indices = from_DAGs(dags, max_order=3)\n</pre> m, edge_indices = from_DAGs(dags, max_order=3) <pre>tensor([[0, 1, 3, 4, 5, 6, 7, 8],\n        [1, 2, 0, 6, 4, 4, 8, 9]])\ntensor([ 0,  4,  7, 10])\ntensor([0, 0, 0, 0, 1, 1, 1, 2, 2, 2])\nEdgeIndex([[0, 0, 0, 1, 1, 1, 2, 3],\n           [1, 2, 1, 2, 0, 2, 0, 0]], sparse_size=(4, 4), nnz=8,\n          sort_order=row)\ntensor([[0],\n        [1],\n        [2],\n        [3]])\n=== k=2 ===\nnum nodes =  10\ntensor([[0, 2, 3, 4, 5, 6],\n        [1, 0, 5, 3, 3, 7]])\n=== k=3 ===\nnum nodes =  8\ntensor([[1, 2, 3, 4],\n        [0, 4, 2, 2]])\n</pre> In\u00a0[89]: Copied! <pre>map_higher_order_index(edge_indices, k=3)\n</pre> map_higher_order_index(edge_indices, k=3) Out[89]: <pre>tensor([[[3, 0, 1],\n         [0, 2, 0],\n         [1, 0, 2],\n         [2, 0, 2]],\n\n        [[0, 1, 2],\n         [2, 0, 2],\n         [0, 2, 0],\n         [0, 2, 0]]])</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_new_pathData_working/","title":"new pathData working","text":"In\u00a0[1]: Copied! <pre>from typing import Optional\n\nfrom tqdm import trange\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.experimental import disable_dynamic_shapes\nfrom torch_geometric.nn.aggr import Aggregation\nfrom torch_geometric.utils import coalesce, degree, cumsum\nfrom torch_geometric import EdgeIndex\n\nimport pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n</pre> from typing import Optional  from tqdm import trange import torch from torch import Tensor from torch_geometric.data import Data from torch_geometric.loader import DataLoader from torch_geometric.nn import MessagePassing from torch_geometric.experimental import disable_dynamic_shapes from torch_geometric.nn.aggr import Aggregation from torch_geometric.utils import coalesce, degree, cumsum from torch_geometric import EdgeIndex  import pathpyG as pp pp.config['torch']['device'] = 'cuda' In\u00a0[2]: Copied! <pre># Example with walks as node sequences\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c')])\ndags = pp.DAGData(mapping = g.mapping)\n\ndags.append_walk(('a', 'b', 'c', 'b'), weight=1.0)\ndags.append_walk(('a', 'c'), weight = 2.0)\nprint(dags)\n</pre> # Example with walks as node sequences g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c')]) dags = pp.DAGData(mapping = g.mapping)  dags.append_walk(('a', 'b', 'c', 'b'), weight=1.0) dags.append_walk(('a', 'c'), weight = 2.0) print(dags) <pre>DAGData with 2 dags with total weight 3.0\n</pre> In\u00a0[5]: Copied! <pre># Example with walks as edge indices (with no mapping)\ndags = pp.DAGData()\ndags.append_dag(torch.tensor([[3,0,1],[0,1,2]]))\ndags.append_dag(torch.tensor([[1,0,2],[0,2,0]]))\ndags.append_dag(torch.tensor([[0,1],[1,2]]))\nprint(dags)\n</pre> # Example with walks as edge indices (with no mapping) dags = pp.DAGData() dags.append_dag(torch.tensor([[3,0,1],[0,1,2]])) dags.append_dag(torch.tensor([[1,0,2],[0,2,0]])) dags.append_dag(torch.tensor([[0,1],[1,2]])) print(dags) <pre>DAGData with 3 dags with total weight 3.0\n</pre> In\u00a0[\u00a0]: Copied! <pre># Example with mix of walks or dags\ndags = pp.DAGData(mapping = g.mapping)\n\ndags.append_dag(torch.tensor([[0,0,1],[1,2,2]]))\ndags.append_walk(('a', 'b', 'c'))\nprint(dags)\n</pre> # Example with mix of walks or dags dags = pp.DAGData(mapping = g.mapping)  dags.append_dag(torch.tensor([[0,0,1],[1,2,2]])) dags.append_walk(('a', 'b', 'c')) print(dags) In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(dags, max_order=2)\n</pre> m = pp.MultiOrderModel.from_DAGs(dags, max_order=2) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[1].data.edge_index)\nprint(m.layers[1].data.node_sequences)\nprint(m.layers[1].mapping)\n</pre> print(m.layers[1].data.edge_index) print(m.layers[1].data.node_sequences) print(m.layers[1].mapping) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.edge_index)\nprint(m.layers[2].data.node_sequences)\nprint(m.layers[2].mapping)\n</pre> print(m.layers[2].data.edge_index) print(m.layers[2].data.node_sequences) print(m.layers[2].mapping) In\u00a0[\u00a0]: Copied! <pre># Real-world example\ndags = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nprint(dags)\n</pre> # Real-world example dags = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') print(dags) In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(dags, max_order=10)\n</pre> m = pp.MultiOrderModel.from_DAGs(dags, max_order=10) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[3].mapping)\n</pre> print(m.layers[3].mapping) In\u00a0[\u00a0]: Copied! <pre>pp.plot(m.layers[10], node_label=list(map(str, m.layers[1].data.node_sequences.tolist())))\n</pre> pp.plot(m.layers[10], node_label=list(map(str, m.layers[1].data.node_sequences.tolist()))) In\u00a0[\u00a0]: Copied! <pre>dags.map_node_seq(m.layers[10].data.node_sequences[5].tolist())\n</pre> dags.map_node_seq(m.layers[10].data.node_sequences[5].tolist()) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.edge_index)\n</pre> print(m.layers[2].data.edge_index) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.edge_weights)\n</pre> print(m.layers[2].data.edge_weights) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.node_sequences)\n</pre> print(m.layers[2].data.node_sequences) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_new_paths/","title":"new paths","text":"In\u00a0[3]: Copied! <pre>from pathpyG import PathData\n\nfrom torch import IntTensor\n\nimport pathpyG as pp\n\npp.config['torch']['device'] = 'cpu'\n</pre> from pathpyG import PathData  from torch import IntTensor  import pathpyG as pp  pp.config['torch']['device'] = 'cpu' In\u00a0[5]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c','e')])\npp.plot(g, node_label=g.mapping.node_ids.tolist(), edge_color='gray')\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c','e')]) pp.plot(g, node_label=g.mapping.node_ids.tolist(), edge_color='gray') Out[5]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f253220a0b0&gt;</pre> In\u00a0[3]: Copied! <pre>path = IntTensor([[0,1],\n                  [1,3]])\n</pre> path = IntTensor([[0,1],                   [1,3]]) Out[3]: <pre>tensor([[[0],\n         [1]],\n\n        [[1],\n         [3]]], dtype=torch.int32)</pre> In\u00a0[4]: Copied! <pre>WalkData.edge_index_kth_order(path, k=2)\n</pre> WalkData.edge_index_kth_order(path, k=2) Out[4]: <pre>tensor([[[0, 1]],\n\n        [[1, 3]]], dtype=torch.int32)</pre> In\u00a0[5]: Copied! <pre>paths_1 = WalkData(g.mapping)\npaths_1.add_walk_seq(('a', 'c', 'd'), freq=2)\npaths_1.add_walk_seq(('b', 'c', 'e'), freq=2)\nprint(paths_1.paths)\nprint(paths_1.path_freq)\n</pre> paths_1 = WalkData(g.mapping) paths_1.add_walk_seq(('a', 'c', 'd'), freq=2) paths_1.add_walk_seq(('b', 'c', 'e'), freq=2) print(paths_1.paths) print(paths_1.path_freq) <pre>{0: tensor([[0, 1],\n        [1, 3]], dtype=torch.int32), 1: tensor([[2, 1],\n        [1, 4]], dtype=torch.int32)}\n{0: 2, 1: 2}\n</pre> In\u00a0[6]: Copied! <pre>paths_1.edge_index\n</pre> paths_1.edge_index Out[6]: <pre>tensor([[0, 1, 1, 2],\n        [1, 3, 4, 1]], dtype=torch.int32)</pre> In\u00a0[7]: Copied! <pre>paths_1.edge_index_weighted\n</pre> paths_1.edge_index_weighted Out[7]: <pre>(tensor([[0, 1, 1, 2],\n         [1, 3, 4, 1]], dtype=torch.int32),\n tensor([2., 2., 2., 2.]))</pre> In\u00a0[8]: Copied! <pre>paths_1.edge_index_k_weighted(k=2)\n</pre> paths_1.edge_index_k_weighted(k=2) Out[8]: <pre>(tensor([[[0, 1],\n          [2, 1]],\n \n         [[1, 3],\n          [1, 4]]], dtype=torch.int32),\n tensor([2., 2.]))</pre> In\u00a0[9]: Copied! <pre>paths_2 = WalkData(g.mapping)\npaths_2.add_walk_seq(('a', 'c', 'd'), freq=1)\npaths_2.add_walk_seq(('a', 'c', 'e'), freq=1)\npaths_2.add_walk_seq(('b', 'c', 'd'), freq=1)\npaths_2.add_walk_seq(('b', 'c', 'e'), freq=1)\nprint(paths_2.paths)\nprint(paths_2.path_freq)\n</pre> paths_2 = WalkData(g.mapping) paths_2.add_walk_seq(('a', 'c', 'd'), freq=1) paths_2.add_walk_seq(('a', 'c', 'e'), freq=1) paths_2.add_walk_seq(('b', 'c', 'd'), freq=1) paths_2.add_walk_seq(('b', 'c', 'e'), freq=1) print(paths_2.paths) print(paths_2.path_freq) <pre>{0: tensor([[0, 1],\n        [1, 3]], dtype=torch.int32), 1: tensor([[0, 1],\n        [1, 4]], dtype=torch.int32), 2: tensor([[2, 1],\n        [1, 3]], dtype=torch.int32), 3: tensor([[2, 1],\n        [1, 4]], dtype=torch.int32)}\n{0: 1, 1: 1, 2: 1, 3: 1}\n</pre> In\u00a0[10]: Copied! <pre>paths_2.edge_index_weighted\n</pre> paths_2.edge_index_weighted Out[10]: <pre>(tensor([[0, 1, 1, 2],\n         [1, 3, 4, 1]], dtype=torch.int32),\n tensor([2., 2., 2., 2.]))</pre> In\u00a0[11]: Copied! <pre>paths_2.edge_index_k_weighted(k=2)\n</pre> paths_2.edge_index_k_weighted(k=2) Out[11]: <pre>(tensor([[[0, 1],\n          [0, 1],\n          [2, 1],\n          [2, 1]],\n \n         [[1, 3],\n          [1, 4],\n          [1, 3],\n          [1, 4]]], dtype=torch.int32),\n tensor([1., 1., 1., 1.]))</pre> In\u00a0[12]: Copied! <pre>path = IntTensor([[0,2,2],\n                  [2,3,4]])\nDAGData.edge_index_kth_order(path, k=2)\n</pre> path = IntTensor([[0,2,2],                   [2,3,4]]) DAGData.edge_index_kth_order(path, k=2) Out[12]: <pre>tensor([[[0, 2],\n         [0, 2]],\n\n        [[2, 3],\n         [2, 4]]], dtype=torch.int32)</pre> In\u00a0[13]: Copied! <pre>paths_1 = DAGData(g.mapping)\ndag = IntTensor([[0,2,2],\n                  [2,3,4]])\npaths_1.add(dag, freq=1)\ndag = IntTensor([[1,2,2],\n                  [2,3,4]])\npaths_1.add(dag, freq=1)\n</pre> paths_1 = DAGData(g.mapping) dag = IntTensor([[0,2,2],                   [2,3,4]]) paths_1.add(dag, freq=1) dag = IntTensor([[1,2,2],                   [2,3,4]]) paths_1.add(dag, freq=1) In\u00a0[14]: Copied! <pre>paths_1.edge_index_weighted\n</pre> paths_1.edge_index_weighted Out[14]: <pre>(tensor([[0, 1, 2, 2],\n         [2, 2, 3, 4]], dtype=torch.int32),\n tensor([1., 1., 2., 2.]))</pre> In\u00a0[15]: Copied! <pre>paths_1.edge_index_k_weighted(k=2)\n</pre> paths_1.edge_index_k_weighted(k=2) Out[15]: <pre>(tensor([[[0, 2],\n          [0, 2],\n          [1, 2],\n          [1, 2]],\n \n         [[2, 3],\n          [2, 4],\n          [2, 3],\n          [2, 4]]], dtype=torch.int32),\n tensor([1., 1., 1., 1.]))</pre>"},{"location":"tutorial/_new_paths/#data-on-walks","title":"Data on Walks\u00b6","text":""},{"location":"tutorial/_new_paths/#data-on-directed-acyclic-graphs","title":"Data on directed acyclic graphs\u00b6","text":""},{"location":"tutorial/_time_respecting_paths_gpu/","title":"time respecting paths gpu","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nimport torch\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\n\nfrom tqdm import tqdm\n</pre> import pathpyG as pp import torch from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index  from tqdm import tqdm In\u00a0[2]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected()\nprint(t_sp)\nprint(torch.unique(t_sp.data.t).size(0))\n</pre> t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected() print(t_sp) print(torch.unique(t_sp.data.t).size(0)) <pre>Temporal Graph with 327 nodes, 11636 unique edges and 377016 events in [1385982080.0, 1386345600.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\n1157\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 'src', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[4]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2)])\nprint(t)\n</pre> t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2)]) print(t) <pre>Temporal Graph with 5 nodes, 5 unique edges and 5 events in [0.0, 2.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\n</pre> In\u00a0[5]: Copied! <pre># new memory-efficient code copied from `temporal_shortest_paths.ipynb`\ndef lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):\n\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.t\n\n    #print(edge_index)\n    #print(timestamps)\n\n    indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)\n\n    unique_t, reverse_idx = torch.unique(timestamps, sorted=True, return_inverse=True)\n    second_order = []\n    count = 0\n\n    # lift order: find possible continuations for edges in each time stamp\n    for i in tqdm(range(unique_t.size(0))):\n        t = unique_t[i]\n        #print('timestamp index ', i)\n        #print('timestamp ', t)\n        \n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = (timestamps == t)\n        src_edges = edge_index[:,src_time_mask]\n        src_edge_idx = indices[src_time_mask]\n        #print(src_edges)\n        #print(src_edge_idx)\n\n        # find indices of all edges that can continue edges at tine t for given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)\n        dst_edges = edge_index[:,dst_time_mask]        \n        dst_edge_idx = indices[dst_time_mask]\n        #print(dst_edges)\n        #print(dst_edge_idx)\n\n        if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:\n\n            # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges        \n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n            src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n            dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n            #print(src_edges)\n            #print(dst_edges)\n            ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n            second_order.append(ho_edge_index)\n            #print(ho_edge_index) \n            \n            # #print('dst', dst)\n            # src_mask = (edge_index[:,mask][0]==dst)\n            # ctd = edge_index[:,mask][:,src_mask]\n            # #print('continuations', ctd)\n            # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]        \n            # #print('ctd indx', ctd_indices)\n            # count += ctd_indices.size(0)\n    ho_index = torch.cat(second_order, dim=1)    \n    return ho_index.size(1), ho_index\n</pre> # new memory-efficient code copied from `temporal_shortest_paths.ipynb` def lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):      # first-order edge index     edge_index, timestamps = g.data.edge_index, g.data.t      #print(edge_index)     #print(timestamps)      indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)      unique_t, reverse_idx = torch.unique(timestamps, sorted=True, return_inverse=True)     second_order = []     count = 0      # lift order: find possible continuations for edges in each time stamp     for i in tqdm(range(unique_t.size(0))):         t = unique_t[i]         #print('timestamp index ', i)         #print('timestamp ', t)                  # find indices of all source edges that occur at unique timestamp t         src_time_mask = (timestamps == t)         src_edges = edge_index[:,src_time_mask]         src_edge_idx = indices[src_time_mask]         #print(src_edges)         #print(src_edge_idx)          # find indices of all edges that can continue edges at tine t for given delta         dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)         dst_edges = edge_index[:,dst_time_mask]                 dst_edge_idx = indices[dst_time_mask]         #print(dst_edges)         #print(dst_edge_idx)          if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:              # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges                     x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()             src_edges = torch.index_select(edge_index, dim=1, index=x[0])             dst_edges = torch.index_select(edge_index, dim=1, index=x[1])             #print(src_edges)             #print(dst_edges)             ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]             second_order.append(ho_edge_index)             #print(ho_edge_index)                           # #print('dst', dst)             # src_mask = (edge_index[:,mask][0]==dst)             # ctd = edge_index[:,mask][:,src_mask]             # #print('continuations', ctd)             # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]                     # #print('ctd indx', ctd_indices)             # count += ctd_indices.size(0)     ho_index = torch.cat(second_order, dim=1)         return ho_index.size(1), ho_index In\u00a0[4]: Copied! <pre>def time_respecting_paths(g: pp.TemporalGraph, delta: int) -&gt; dict:\n    \"\"\"\n    Calculate all longest time-respecting paths in a temporal graph.\n    \"\"\"\n    paths_of_length = {}\n\n    node_sequence = torch.arange(g.data.num_nodes, device=g.data.edge_index.device).unsqueeze(1)\n    node_sequence = torch.cat([node_sequence[g.data.edge_index[0]], node_sequence[g.data.edge_index[1]][:, -1:]], dim=1)\n    edge_index = lift_order_efficient(g, delta)[1]\n    \n    # calculate degrees\n    out_degree = degree(edge_index[0], num_nodes=g.M, dtype=torch.long)\n    in_degree = degree(edge_index[1], num_nodes=g.M, dtype=torch.long)\n    # identify root nodes with in-degree zero\n    roots = torch.where(in_degree == 0)[0]\n    leafs = (out_degree == 0)\n    # print(\"Roots:\", roots)\n    # print(\"Leafs:\", leafs)\n    paths = node_sequence[roots]\n    paths_of_length[1] = paths[leafs[roots]].cpu()\n\n    paths = paths[~leafs[roots]]\n    nodes = roots[~leafs[roots]]\n\n    ptrs = cumsum(out_degree, dim=0)\n\n\n    # count all longest time-respecting paths in the temporal graph\n    step = 1\n    while nodes.size(0) &gt; 0:\n        # print(\"step\", step)\n        # print(\"Paths: \", paths)\n        # print(\"Nodes: \", nodes)\n        idx_repeat = torch.repeat_interleave(out_degree[nodes])\n        next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])\n        idx_correction = torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]\n        next_idx += idx_correction\n        next_nodes = edge_index[1][next_idx]\n        paths = torch.cat([paths[idx_repeat], node_sequence[next_nodes, 1:]], dim=1)\n        paths_of_length[step] = paths[leafs[next_nodes]].tolist()\n        paths = paths[~leafs[next_nodes]]\n        nodes = next_nodes[~leafs[next_nodes]]\n        step += 1\n\n    return paths_of_length\n</pre> def time_respecting_paths(g: pp.TemporalGraph, delta: int) -&gt; dict:     \"\"\"     Calculate all longest time-respecting paths in a temporal graph.     \"\"\"     paths_of_length = {}      node_sequence = torch.arange(g.data.num_nodes, device=g.data.edge_index.device).unsqueeze(1)     node_sequence = torch.cat([node_sequence[g.data.edge_index[0]], node_sequence[g.data.edge_index[1]][:, -1:]], dim=1)     edge_index = lift_order_efficient(g, delta)[1]          # calculate degrees     out_degree = degree(edge_index[0], num_nodes=g.M, dtype=torch.long)     in_degree = degree(edge_index[1], num_nodes=g.M, dtype=torch.long)     # identify root nodes with in-degree zero     roots = torch.where(in_degree == 0)[0]     leafs = (out_degree == 0)     # print(\"Roots:\", roots)     # print(\"Leafs:\", leafs)     paths = node_sequence[roots]     paths_of_length[1] = paths[leafs[roots]].cpu()      paths = paths[~leafs[roots]]     nodes = roots[~leafs[roots]]      ptrs = cumsum(out_degree, dim=0)       # count all longest time-respecting paths in the temporal graph     step = 1     while nodes.size(0) &gt; 0:         # print(\"step\", step)         # print(\"Paths: \", paths)         # print(\"Nodes: \", nodes)         idx_repeat = torch.repeat_interleave(out_degree[nodes])         next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])         idx_correction = torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]         next_idx += idx_correction         next_nodes = edge_index[1][next_idx]         paths = torch.cat([paths[idx_repeat], node_sequence[next_nodes, 1:]], dim=1)         paths_of_length[step] = paths[leafs[next_nodes]].tolist()         paths = paths[~leafs[next_nodes]]         nodes = next_nodes[~leafs[next_nodes]]         step += 1      return paths_of_length  In\u00a0[6]: Copied! <pre>lift_order_efficient(t_sp, delta=300)\n</pre> lift_order_efficient(t_sp, delta=300) <pre>  0%|          | 0/1157 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1157/1157 [00:08&lt;00:00, 134.85it/s]\n</pre> Out[6]: <pre>(3693050,\n tensor([[     0,      0,      0,  ..., 376991, 376991, 376991],\n         [   835,    885,    933,  ..., 376995, 377000, 377004]]))</pre> In\u00a0[7]: Copied! <pre># lift_order_efficient(t_sp, delta=300)\n</pre> # lift_order_efficient(t_sp, delta=300) In\u00a0[11]: Copied! <pre>t.data.edge_index, t.data.t\n</pre> t.data.edge_index, t.data.t Out[11]: <pre>(tensor([[0, 0, 1, 1, 3],\n         [1, 2, 2, 3, 4]]),\n tensor([0., 0., 1., 1., 2.]))</pre> In\u00a0[5]: Copied! <pre>time_respecting_paths(t_sp, delta=300)\n</pre> time_respecting_paths(t_sp, delta=300) <pre>  0%|          | 0/1157 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1157/1157 [00:07&lt;00:00, 150.48it/s]\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_xx_test/","title":"xx test","text":"In\u00a0[1]: Copied! <pre>import torch\nfrom torch_geometric.data import TemporalData\nfrom torch_geometric.utils import degree\nimport numpy as np\nimport pathpyG as pp\n\nprint('Running on', pp.config['torch']['device'])\n</pre> import torch from torch_geometric.data import TemporalData from torch_geometric.utils import degree import numpy as np import pathpyG as pp  print('Running on', pp.config['torch']['device']) <pre>Running on cpu\n</pre> In\u00a0[2]: Copied! <pre>g = pp.TemporalGraph.from_edge_list([['a', 'b', 1], ['b', 'c', 3]])\nprint(g)\n</pre> g = pp.TemporalGraph.from_edge_list([['a', 'b', 1], ['b', 'c', 3]]) print(g) <pre>Temporal Graph with 3 nodes, 2 unique edges and 2 events in [1.0, 3.0]\n\nGraph attributes\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[3]: Copied! <pre>dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=2)\npp.plot(dag)\nprint(dag.data.node_id)\nprint(dag.data.edge_index)\n</pre> dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=2) pp.plot(dag) print(dag.data.node_id) print(dag.data.edge_index) <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=2)\n      2 pp.plot(dag)\n      3 print(dag.data.node_id)\n\nAttributeError: module 'pathpyG.algorithms' has no attribute 'temporal_graph_to_event_dag'</pre> In\u00a0[30]: Copied! <pre>g = pp.TemporalGraph.from_csv('../data/ants_1_2_val_small.csv')\nprint(g)\n</pre> g = pp.TemporalGraph.from_csv('../data/ants_1_2_val_small.csv') print(g) <pre>tensor([1697, 1697, 1698, 1698, 1698, 1698, 1699, 1699, 1701, 1702, 1702, 1702,\n        1702, 1702, 1702, 1702, 1703, 1703, 1703, 1704, 1704, 1704, 1704, 1704,\n        1704, 1705, 1705, 1705, 1706, 1706, 1706, 1707, 1707, 1707, 1707, 1707,\n        1708, 1708, 1709, 1709, 1709, 1710, 1710, 1710, 1711, 1711, 1711, 1712,\n        1713, 1714, 1715, 1715, 1717, 1718, 1719, 1719, 1719, 1720, 1720, 1720,\n        1720, 1721, 1721, 1723, 1724, 1724, 1726, 1726, 1727, 1728, 1728, 1728,\n        1728, 1729, 1729, 1730, 1731, 1731, 1732, 1733, 1734, 1735, 1735, 1735,\n        1736, 1736, 1737, 1737, 1737, 1738, 1738, 1739, 1742, 1742, 1743, 1743,\n        1743, 1743, 1744, 1744, 1745, 1745, 1746, 1746, 1747, 1748, 1749],\n       device='cuda:0')\nTemporal Graph with 50 nodes 93 edges and 107 time-stamped events in [1697, 1749]\n\nNode attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([107])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([107])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([107])\n\n</pre> In\u00a0[31]: Copied! <pre>dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=30, sparsify=True)\nprint(dag)\n</pre> dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=30, sparsify=True) print(dag) <pre>Graph with 147 nodes and 159 edges\n\nNode attributes\n\tnode_idx\t\t&lt;class 'list'&gt;\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnode_name\t\t&lt;class 'list'&gt;\n\nEdge attributes\n\tedge_ts\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([159])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[32]: Copied! <pre>paths = pp.DAGData.from_temporal_dag(dag, detect_walks=False)\nprint(paths)\n</pre> paths = pp.DAGData.from_temporal_dag(dag, detect_walks=False) print(paths) <pre>PathData with 0 walks and 39 dags\n</pre> In\u00a0[35]: Copied! <pre>index, weights = paths.edge_index_k_weighted(k=2)\nprint(index)\nprint(index.size(dim=1))\nprint(weights)\n</pre> index, weights = paths.edge_index_k_weighted(k=2) print(index) print(index.size(dim=1)) print(weights) <pre>tensor([[[ 0,  1],\n         [ 0,  1],\n         [ 0,  1],\n         [ 0,  1],\n         [ 0,  1],\n         [ 0,  2],\n         [ 0,  2],\n         [ 0, 21],\n         [ 0, 21],\n         [ 0, 21],\n         [ 0, 32],\n         [ 1,  0],\n         [ 1,  0],\n         [ 1,  0],\n         [ 1,  0],\n         [ 1, 13],\n         [ 1, 13],\n         [ 1, 30],\n         [ 4,  5],\n         [ 5, 20],\n         [ 6,  7],\n         [ 6,  7],\n         [ 6,  9],\n         [ 6,  9],\n         [ 7, 39],\n         [ 7, 39],\n         [ 7, 39],\n         [ 8,  0],\n         [ 8,  0],\n         [ 8,  0],\n         [ 8,  0],\n         [ 9,  7],\n         [ 9, 24],\n         [10, 11],\n         [10, 11],\n         [10, 11],\n         [10, 11],\n         [10, 29],\n         [11,  0],\n         [11,  0],\n         [11,  0],\n         [11, 16],\n         [11, 21],\n         [11, 21],\n         [11, 22],\n         [11, 22],\n         [11, 29],\n         [11, 29],\n         [12,  1],\n         [12,  1],\n         [12, 13],\n         [12, 13],\n         [12, 30],\n         [12, 33],\n         [13,  8],\n         [20, 14],\n         [21, 11],\n         [21, 11],\n         [21, 11],\n         [22, 16],\n         [23, 24],\n         [23, 24],\n         [24,  9],\n         [25,  7],\n         [25, 26],\n         [26,  6],\n         [26,  9],\n         [26,  9],\n         [27,  8],\n         [28, 24],\n         [28, 29],\n         [28, 29],\n         [28, 29],\n         [28, 29],\n         [29, 21],\n         [29, 21],\n         [29, 21],\n         [30,  1],\n         [30, 33],\n         [31, 22],\n         [31, 22],\n         [32,  0],\n         [34, 35],\n         [34, 44],\n         [35, 34],\n         [37, 38],\n         [39,  6],\n         [39,  6],\n         [39, 45],\n         [43, 20],\n         [44, 18],\n         [45,  6],\n         [47,  9]],\n\n        [[ 1,  0],\n         [ 1, 12],\n         [ 1, 13],\n         [ 1, 30],\n         [ 1, 33],\n         [ 2,  0],\n         [ 2,  3],\n         [21, 11],\n         [21, 40],\n         [21, 42],\n         [32,  0],\n         [ 0,  2],\n         [ 0,  3],\n         [ 0, 21],\n         [ 0, 32],\n         [13,  1],\n         [13,  8],\n         [30, 33],\n         [ 5, 20],\n         [20, 43],\n         [ 7, 39],\n         [ 7, 43],\n         [ 9, 24],\n         [ 9, 36],\n         [39,  6],\n         [39, 25],\n         [39, 45],\n         [ 0,  2],\n         [ 0,  3],\n         [ 0, 21],\n         [ 0, 32],\n         [ 7, 39],\n         [24,  9],\n         [11,  0],\n         [11, 21],\n         [11, 22],\n         [11, 29],\n         [29, 42],\n         [ 0,  2],\n         [ 0,  3],\n         [ 0, 32],\n         [16, 17],\n         [21, 40],\n         [21, 42],\n         [22, 11],\n         [22, 16],\n         [29, 33],\n         [29, 42],\n         [ 1, 12],\n         [ 1, 30],\n         [13,  1],\n         [13,  8],\n         [30,  1],\n         [33, 12],\n         [ 8, 27],\n         [14, 20],\n         [11, 16],\n         [11, 22],\n         [11, 29],\n         [16, 17],\n         [24,  9],\n         [24, 28],\n         [ 9, 49],\n         [ 7, 39],\n         [26,  6],\n         [ 6, 45],\n         [ 9, 24],\n         [ 9, 36],\n         [ 8, 27],\n         [24,  9],\n         [29, 21],\n         [29, 23],\n         [29, 33],\n         [29, 42],\n         [21, 11],\n         [21, 40],\n         [21, 42],\n         [ 1, 30],\n         [33, 12],\n         [22, 11],\n         [22, 16],\n         [ 0, 46],\n         [35, 34],\n         [44, 18],\n         [34, 44],\n         [38, 37],\n         [ 6,  7],\n         [ 6, 45],\n         [45,  6],\n         [20, 14],\n         [18, 44],\n         [ 6, 45],\n         [ 9, 49]]], device='cuda:0')\n93\ntensor([ 4.,  1.,  2.,  1.,  1.,  3.,  6., 10.,  2.,  2.,  6.,  3.,  1.,  4.,\n         1.,  1.,  1.,  3.,  1.,  1.,  6.,  1.,  1.,  1.,  4.,  4.,  8.,  3.,\n         1.,  4.,  1.,  3.,  2.,  3.,  4.,  2.,  2.,  1.,  3.,  1.,  1.,  3.,\n         1.,  1.,  1.,  1.,  3.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,\n         3.,  6.,  4.,  3.,  1.,  1.,  4.,  3.,  1.,  1.,  1.,  2.,  1.,  1.,\n         3.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  3.,  1.,  1.,  6.,  1.,  1.,\n         1.,  1.,  2.,  1.,  3.,  1.,  1.,  3.,  1.], device='cuda:0')\n</pre> In\u00a0[36]: Copied! <pre>def map_edge_index(edge_index, weights, map):\n    paths = []\n    for i in range(edge_index.size(dim=1)):\n        paths.append((map[edge_index[0][i][0].item()], map[edge_index[0][i][1].item()], map[edge_index[1][i][1].item()], weights[i].item()))\n    return paths\n</pre> def map_edge_index(edge_index, weights, map):     paths = []     for i in range(edge_index.size(dim=1)):         paths.append((map[edge_index[0][i][0].item()], map[edge_index[0][i][1].item()], map[edge_index[1][i][1].item()], weights[i].item()))     return paths  In\u00a0[37]: Copied! <pre>paths = map_edge_index(index, weights, g.mapping.idx_to_id)\nwith open('ants_1_2_paths.csv', 'w') as f:\n    for p in paths:\n        f.write('{0};{1}\\n'.format(','.join(p[:-1]), p[-1]))\n</pre> paths = map_edge_index(index, weights, g.mapping.idx_to_id) with open('ants_1_2_paths.csv', 'w') as f:     for p in paths:         f.write('{0};{1}\\n'.format(','.join(p[:-1]), p[-1])) In\u00a0[5]: Copied! <pre>g1 = pp.HigherOrderGraph(paths, order=1)\nprint(g1)\n</pre> g1 = pp.HigherOrderGraph(paths, order=1) print(g1) <pre>HigherOrderGraph (k=1) with 71 nodes and 591 edges\n\tTotal edge weight = 3230.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([591])\n\nGraph attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[34]: Copied! <pre>g2 = pp.HigherOrderGraph(paths, order=2)\nprint(g2)\n</pre> g2 = pp.HigherOrderGraph(paths, order=2) print(g2) <pre>HigherOrderGraph (k=2) with 80 nodes and 93 edges\n\tTotal edge weight = 202.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([93])\n\nGraph attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[38]: Copied! <pre>g = pp.TemporalGraph.from_edge_list([['a', 'b', 1], ['b', 'c',2], ['c', 'd',3], ['c', 'e', 3]])\nprint(g)\n</pre> g = pp.TemporalGraph.from_edge_list([['a', 'b', 1], ['b', 'c',2], ['c', 'd',3], ['c', 'e', 3]]) print(g) <pre>tensor([1, 2, 3, 3], device='cuda:0')\nTemporal Graph with 5 nodes 4 edges and 4 time-stamped events in [1, 3]\n\nNode attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\n</pre> In\u00a0[39]: Copied! <pre>dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=5, sparsify=True)\nprint(dag)\nprint(dag.data['node_name'])\nprint(dag.node_index_to_id)\npp.plot(dag, edge_color='lightgray')\n</pre> dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=5, sparsify=True) print(dag) print(dag.data['node_name']) print(dag.node_index_to_id) pp.plot(dag, edge_color='lightgray') <pre>Graph with 5 nodes and 4 edges\n\nNode attributes\n\tnode_idx\t\t&lt;class 'list'&gt;\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnode_name\t\t&lt;class 'list'&gt;\n\nEdge attributes\n\tedge_ts\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n['a', 'b', 'c', 'd', 'e']\n{0: 'a-1', 1: 'b-2', 2: 'c-3', 3: 'd-4', 4: 'e-4'}\n</pre> In\u00a0[40]: Copied! <pre>x = pp.algorithms.extract_causal_trees(dag)\nprint(x)\n</pre> x = pp.algorithms.extract_causal_trees(dag) print(x) <pre>{'a-1': tensor([[0, 1, 2, 2],\n        [1, 2, 3, 4]], device='cuda:0', dtype=torch.int32)}\n</pre> In\u00a0[41]: Copied! <pre>paths = pp.DAGData.from_temporal_dag(dag)\nprint(paths)\nprint(paths.mapping)\n</pre> paths = pp.DAGData.from_temporal_dag(dag) print(paths) print(paths.mapping) <pre>PathData with 0 walks and 1 dags\n{0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n</pre> In\u00a0[42]: Copied! <pre>paths.edge_index_k_weighted(k=1)\n</pre> paths.edge_index_k_weighted(k=1) Out[42]: <pre>(tensor([[0, 1, 2, 2],\n         [1, 2, 3, 4]], device='cuda:0'),\n tensor([1., 1., 1., 1.], device='cuda:0'))</pre> In\u00a0[43]: Copied! <pre>g1 = pp.HigherOrderGraph(paths, order=1)\nprint(g1)\npp.plot(g1)\n</pre> g1 = pp.HigherOrderGraph(paths, order=1) print(g1) pp.plot(g1) <pre>HigherOrderGraph (k=1) with 5 nodes and 4 edges\n\tTotal edge weight = 4.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[44]: Copied! <pre>paths.edge_index_k_weighted(k=2)\n</pre> paths.edge_index_k_weighted(k=2) Out[44]: <pre>(tensor([[[0, 1],\n          [1, 2],\n          [1, 2]],\n \n         [[1, 2],\n          [2, 3],\n          [2, 4]]], device='cuda:0'),\n tensor([1., 1., 1.], device='cuda:0'))</pre> In\u00a0[45]: Copied! <pre>g2 = pp.HigherOrderGraph(paths, order=2)\nprint(g2)\n</pre> g2 = pp.HigherOrderGraph(paths, order=2) print(g2) <pre>HigherOrderGraph (k=2) with 4 nodes and 3 edges\n\tTotal edge weight = 3.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\n\nGraph attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[27]: Copied! <pre>pp.plot(g2)\n</pre> pp.plot(g2) In\u00a0[41]: Copied! <pre># edge_index =torch.IntTensor([[0,1,2],[1,2,3]])\n# edge_index = edge_index.reshape(edge_index.size()+(1,))\n# print(edge_index)\n\na = edge_index[0].unique(dim=0)\nb = edge_index[1].unique(dim=0)\n# intersection of a and b corresponds to all center nodes, which have at least one incoming and one outgoing edge\ncombined = torch.cat((a, b))\nuniques, counts = combined.unique(dim=0, return_counts=True)\ncenter_nodes = uniques[counts &gt; 1]\nprint(center_nodes)\nsrc = []\ndst = []\nfor v in center_nodes:\n    src_index = torch.all(edge_index[1]==v, axis=1).nonzero().flatten() # type: ignore\n    srcs = edge_index[0][src_index]\n    # get all successors of v, i.e. elements in edge_index[1] where edge_index[0] == v\n    dst_index = torch.all(edge_index[0]==v, axis=1).nonzero().flatten() # type: ignore\n    dsts = edge_index[1][dst_index]\n    for s in srcs:\n        for d in dsts:\n            src.append(torch.cat((torch.gather(s, 0, torch.tensor([0])), v)))\n            dst.append(torch.cat((v, torch.gather(d, 0, torch.tensor([d.size()[0]-1])))))\nedge_index = torch.stack((torch.stack(src), torch.stack(dst)))\nprint(edge_index)\n</pre> # edge_index =torch.IntTensor([[0,1,2],[1,2,3]]) # edge_index = edge_index.reshape(edge_index.size()+(1,)) # print(edge_index)  a = edge_index[0].unique(dim=0) b = edge_index[1].unique(dim=0) # intersection of a and b corresponds to all center nodes, which have at least one incoming and one outgoing edge combined = torch.cat((a, b)) uniques, counts = combined.unique(dim=0, return_counts=True) center_nodes = uniques[counts &gt; 1] print(center_nodes) src = [] dst = [] for v in center_nodes:     src_index = torch.all(edge_index[1]==v, axis=1).nonzero().flatten() # type: ignore     srcs = edge_index[0][src_index]     # get all successors of v, i.e. elements in edge_index[1] where edge_index[0] == v     dst_index = torch.all(edge_index[0]==v, axis=1).nonzero().flatten() # type: ignore     dsts = edge_index[1][dst_index]     for s in srcs:         for d in dsts:             src.append(torch.cat((torch.gather(s, 0, torch.tensor([0])), v)))             dst.append(torch.cat((v, torch.gather(d, 0, torch.tensor([d.size()[0]-1]))))) edge_index = torch.stack((torch.stack(src), torch.stack(dst))) print(edge_index) <pre>tensor([[1, 2]], dtype=torch.int32)\ntensor([[[0, 1, 2]],\n\n        [[1, 2, 3]]], dtype=torch.int32)\n</pre> In\u00a0[12]: Copied! <pre>g2 = pp.HigherOrderGraph(paths, order=3)\nprint(g2)\n</pre> g2 = pp.HigherOrderGraph(paths, order=3) print(g2) <pre>HigherOrderGraph (k=3) with 2 nodes and 1 edges\n\tTotal edge weight = 1.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tnode_id\t\t&lt;class 'list'&gt;\n\n</pre> In\u00a0[\u00a0]: Copied! <pre>print(g2)\n</pre> print(g2) In\u00a0[\u00a0]: Copied! <pre>pp.plot(g2)\n</pre> pp.plot(g2) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_xx_test/#toy-example","title":"Toy Example\u00b6","text":""},{"location":"tutorial/basic_concepts/","title":"Basic Concepts","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nimport torch_geometric as pyG\nfrom torch_geometric.data import Data\n\nimport pathpyG as pp\npp.config['torch']['device'] = 'cpu'\n</pre> import torch import torch_geometric as pyG from torch_geometric.data import Data  import pathpyG as pp pp.config['torch']['device'] = 'cpu' In\u00a0[2]: Copied! <pre>d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]]))\ng = pp.Graph(d)\nprint(g)\n</pre> d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]])) g = pp.Graph(d) print(g) <pre>Directed graph with 3 nodes and 3 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>If we do not need additional node or edge attributes, we can use the class function <code>Graph.from_edge_index</code> to directly create a graph based on an edge index:</p> In\u00a0[3]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]))\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]])) print(g) <pre>Directed graph with 3 nodes and 3 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>We may want to inlude isolated nodes that do not have an edge. We can do so by passing a <code>num_nodes</code> parameter. The following graph thus contains a fourth node (which we could name as <code>d</code>) that is not connected to any of the other nodes.</p> In\u00a0[4]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes=4)\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes=4) print(g) <pre>Directed graph with 4 nodes and 3 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>In both cases, the <code>Graph</code> instance has a property <code>g.data</code> that stores a <code>pyG</code> <code>Data</code> object that includes the edge index as well as any further node-, edge- or graph-level attributes.</p> In\u00a0[5]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 3], num_nodes=4)\n</pre> <p>Note that the <code>edge_index</code> is actually of type <code>pyG.EdgeIndex</code>, which is a subclass of <code>torch.Tensor</code>. Any tensor passed as an edge index in the constructor of <code>Graph</code> will automatically be converted to an <code>EdgeIndex</code> instance, as this internally allows us to provide efficient edge traveral routines based on sparse matrix operations. To support this, the edge index will be automatically sorted by row when the <code>Graph</code> object is created. To avoid this additional sort operation, you can pass an already sorted <code>EdgeIndex</code> object in the <code>Data</code> object in the constructor or using the <code>from_edge_index</code> class function.</p> In\u00a0[6]: Copied! <pre>print(g.data.edge_index)\n</pre> print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1],\n           [2, 1, 2]], sparse_size=(4, 4), nnz=3, sort_order=row)\n</pre> <p>We can use the generators <code>nodes</code> and <code>edges</code> to iterate through the nodes and edges of a graph as follows:</p> In\u00a0[7]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>0\n1\n2\n3\n(0, 2)\n(0, 1)\n(1, 2)\n</pre> <p>While the index-based representation of nodes allows for efficient tensor-based operations, it is often more convenient to use string identifiers to refer to nodes. To simplify the handling of graphs with such string node identifiers, <code>pathpyG</code> provides a class <code>IndexMap</code> that transparently maps string identifiers to integer indices. For our small example graph, we can create an <code>IndexMap</code> that associates node indices with string IDs. For our example, we can create a mapping as follows:</p> In\u00a0[8]: Copied! <pre>m = pp.IndexMap(['a', 'b', 'c', 'd'])\nprint(m)\n</pre> m = pp.IndexMap(['a', 'b', 'c', 'd']) print(m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n</pre> <p>We can use the functions <code>IndexMap.to_id</code> or <code>IndexMap.to_idx</code> to map a node to an index or an ID:</p> In\u00a0[12]: Copied! <pre>m.to_id(0)\n</pre> m.to_id(0) Out[12]: <pre>'a'</pre> In\u00a0[13]: Copied! <pre>m.to_idx('b')\n</pre> m.to_idx('b') Out[13]: <pre>1</pre> <p><code>pathpyG</code> actually makes this mapping transparent for the user. For this, we can add our mapping to the <code>Graph</code> object, either by passing it in the constructor or by setting the <code>mapping</code> attribute of an existing <code>Graph</code> instance.</p> In\u00a0[14]: Copied! <pre>g.mapping = m\n</pre> g.mapping = m <p>If we now iterate through the nodes and edges of the graph, we get:</p> In\u00a0[15]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>a\nb\nc\nd\n('a', 'c')\n('a', 'b')\n('b', 'c')\n</pre> <p>We can achieve the same result if we pass the <code>IndexMap</code> object in the constructor of a graph. This transparently applies the mapping in all future function calls.</p> In\u00a0[16]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes = 4, mapping=m)\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes = 4, mapping=m) print(g) <pre>Directed graph with 4 nodes and 3 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Above, we have created a graph based on an edge index tensor and we then additionally applied a mapping that we manually defined. We often have data in the form on an edge list, where edges are given as tuples of non-numeric node identifiers. The class function <code>Graph.from_edge_list</code> simplifies the construction of a <code>Graph</code> from such edge lists. This will automatically generate an internal integer-based representation of the edge index, as well as the associated <code>IndexMap</code>, where the integer node indices are based on the lexicographic order of node IDs.</p> In\u00a0[18]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')])\nprint(g)\nprint(g.data.edge_index)\nprint(g.mapping)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')]) print(g) print(g.data.edge_index) print(g.mapping) <pre>Directed graph with 3 nodes and 3 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[0, 0, 1],\n           [1, 2, 2]], sparse_size=(3, 3), nnz=3, sort_order=row)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n</pre> <p>We could alternatively pass a custom index mapping, e.g. mapping node <code>c</code> to idex 1 and node <code>b</code> to index 2 (thus deviating from a lexicographic order):</p> In\u00a0[19]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('a','c'), ('b','c')], mapping = pp.IndexMap(['a', 'c', 'b']))\nprint(g.data.edge_index)\nprint(g.mapping)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('a','c'), ('b','c')], mapping = pp.IndexMap(['a', 'c', 'b'])) print(g.data.edge_index) print(g.mapping) <pre>EdgeIndex([[0, 0, 2],\n           [2, 1, 1]], sparse_size=(3, 3), nnz=3, sort_order=row)\na -&gt; 0\nc -&gt; 1\nb -&gt; 2\n\n</pre> In\u00a0[20]: Copied! <pre>g.get_successors(0)\n</pre> g.get_successors(0) Out[20]: <pre>tensor([2, 1])</pre> In\u00a0[21]: Copied! <pre>g.get_predecessors(0)\n</pre> g.get_predecessors(0) Out[21]: <pre>tensor([], dtype=torch.int64)</pre> <p>Note that, even if a mapping is defined, the <code>get_successors</code> and <code>get_predecessors</code> functions always return a tensor with node indices, rather than node IDs. This is useful to support fast tensor-based operations on the list of successors and predecessors. We could always manually map the node indices using the <code>IndexMap</code> object defined in the <code>mapping</code> attribute.</p> <p>If we want to traverse graphs based on string node IDs, we can use the <code>successors</code> and <code>predecessors</code> generators of the <code>Graph</code> object, which -- if an ID-Index mapping is defined - yield the string labels of successor or predecessor nodes for a given node (also identified by its string label).</p> In\u00a0[22]: Copied! <pre>for v in g.successors('a'):\n    print(v)\n</pre> for v in g.successors('a'):     print(v) <pre>b\nc\n</pre> In\u00a0[23]: Copied! <pre>for v in g.predecessors('c'):\n    print(v)\n</pre> for v in g.predecessors('c'):     print(v) <pre>a\nb\n</pre> <p>To check (again in constant time) whether an edge exists in the graph, we can call the <code>is_edge</code> function:</p> In\u00a0[24]: Copied! <pre>g.is_edge('a', 'b')\n</pre> g.is_edge('a', 'b') Out[24]: <pre>True</pre> <p>Alternatively, we can use the following function to check (in constant time) whether node <code>b</code> is a successor of <code>a</code></p> In\u00a0[27]: Copied! <pre>'b' in g.successors('a')\n</pre> 'b' in g.successors('a') Out[27]: <pre>True</pre> <p>By default, graph objects in <code>pathpyG</code> are directed, i.e. for the graph above, the edge <code>(b,a)</code> does not exist, which we can verify as follows:</p> In\u00a0[29]: Copied! <pre>print('a' in g.successors('b'))\nprint(g.is_edge('b', 'a'))\n</pre> print('a' in g.successors('b')) print(g.is_edge('b', 'a')) <pre>False\nFalse\n</pre> <p>To calculate (directed) in- and out-degrees of nodes, we can use the properties <code>in_degrees</code> and <code>out_degrees</code>, which return a dictionary that maps node IDs to their degrees:</p> In\u00a0[31]: Copied! <pre>g.in_degrees\n</pre> g.in_degrees Out[31]: <pre>{'a': 0, 'c': 2, 'b': 1}</pre> In\u00a0[32]: Copied! <pre>g.in_degrees['b']\n</pre> g.in_degrees['b'] Out[32]: <pre>1</pre> In\u00a0[35]: Copied! <pre>g.in_degrees['a']\n</pre> g.in_degrees['a'] Out[35]: <pre>0</pre> In\u00a0[36]: Copied! <pre>g.in_degrees['c']\n</pre> g.in_degrees['c'] Out[36]: <pre>2</pre> <p>Importantly, irrespective of how we have generated the graph object, the actual node and edge data are always stored as a <code>pyG</code> data object. This allows us to use the full power of <code>torch</code> and <code>pyG</code>, including the application of transforms, splits, or any easy migration between CPU and GPU-based computation.</p> In\u00a0[37]: Copied! <pre>g.data\n</pre> g.data Out[37]: <pre>Data(edge_index=[2, 3], num_nodes=3)</pre> <p>In general, <code>pathpyG</code> will use the device specified in the <code>torch.device</code> configuration (see above) whenver it internally creates a torch tensor. Since above, we have specified the <code>cpu</code> device, the data object of the graph generated above will reside in main memory:</p> In\u00a0[39]: Copied! <pre>g.data.is_cuda\n</pre> g.data.is_cuda Out[39]: <pre>False</pre> <p>If we instead set the device to <code>cuda</code>, the <code>Data</code> object will internally be created in main memory instead.</p> In\u00a0[40]: Copied! <pre>pp.config['torch']['device'] = 'cuda'\n\ng = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')])\ng.data.is_cuda\n</pre> pp.config['torch']['device'] = 'cuda'  g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')]) g.data.is_cuda Out[40]: <pre>True</pre> In\u00a0[41]: Copied! <pre>g.data['node_class'] = torch.tensor([[0], [0], [1]], device=pp.config['torch']['device'])\ng.data['edge_weight'] = torch.tensor([[1], [2], [3]], device=pp.config['torch']['device'])\ng.data['feature'] = torch.tensor([3, 2], device=pp.config['torch']['device'])\n</pre> g.data['node_class'] = torch.tensor([[0], [0], [1]], device=pp.config['torch']['device']) g.data['edge_weight'] = torch.tensor([[1], [2], [3]], device=pp.config['torch']['device']) g.data['feature'] = torch.tensor([3, 2], device=pp.config['torch']['device']) <p>Once we have added attributes to nodes, edges, or the graph, those attributes, along with their type and shape will be shown when you print a string representation of the graph object:</p> In\u00a0[42]: Copied! <pre>print(g)\n</pre> print(g) <pre>Directed graph with 3 nodes and 3 edges\n\nNode attributes\n\tnode_class\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tfeature\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\n</pre> <p>To simplify access to attribute values, the <code>Graph</code> class provides getter and setter functions that allow to access attribute values based on node identifiers. To access the feature <code>node_feature</code> of node <code>a</code>, we can write:</p> In\u00a0[44]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[44]: <pre>tensor([0], device='cuda:0')</pre> <p>To access the weight of edge <code>(a, b)</code> we can write:</p> In\u00a0[45]: Copied! <pre>g['edge_weight', 'a', 'b']\n</pre> g['edge_weight', 'a', 'b'] Out[45]: <pre>tensor([1], device='cuda:0')</pre> <p>And finally, graph-based attributes can accessed as follows:</p> In\u00a0[46]: Copied! <pre>g['feature']\n</pre> g['feature'] Out[46]: <pre>tensor([3, 2], device='cuda:0')</pre> <p>We can also use the setter functions to change attributes:</p> In\u00a0[47]: Copied! <pre>g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda')\n</pre> g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda') In\u00a0[48]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[48]: <pre>tensor([7], device='cuda:0')</pre> <p>To create sparse adjacency matrix representations of graphs, we can use the following function:</p> In\u00a0[50]: Copied! <pre>print(g.get_sparse_adj_matrix())\n</pre> print(g.get_sparse_adj_matrix()) <pre>  (0, 1)\t1.0\n  (0, 2)\t1.0\n  (1, 2)\t1.0\n</pre> <p>This returns a <code>scipy.sparse.coo_matrix</code> object, which can be turned into a dense <code>numpy</code> matrix as follows:</p> In\u00a0[51]: Copied! <pre>print(g.get_sparse_adj_matrix().todense())\n</pre> print(g.get_sparse_adj_matrix().todense()) <pre>[[0. 1. 1.]\n [0. 0. 1.]\n [0. 0. 0.]]\n</pre> <p>By passing the name of the attribute, we can use edge attributes in the creation of the adjacency matrix. To create a sparse, weighted adjacency matrix that uses the <code>edge_weight</code> attribute of our graph object we can simply write:</p> In\u00a0[53]: Copied! <pre>print(g.get_sparse_adj_matrix(edge_attr='edge_weight').todense())\n</pre> print(g.get_sparse_adj_matrix(edge_attr='edge_weight').todense()) <pre>[[0 1 2]\n [0 0 3]\n [0 0 0]]\n</pre> <p>We can also add attributes based on one-hot-encodings of nodes and edges as follows:</p> In\u00a0[54]: Copied! <pre>g.add_node_ohe(attr_name='node_ohe_feature_1')\ng.add_node_ohe(attr_name='node_ohe_feature_2', dim=4)\ng.add_edge_ohe(attr_name='edge_ohe_feature_1', dim=5)\nprint(g)\n\nprint(g.data['node_ohe_feature_1'])\nprint(g.data['node_ohe_feature_2'])\nprint(g.data['edge_ohe_feature_1'])\n</pre> g.add_node_ohe(attr_name='node_ohe_feature_1') g.add_node_ohe(attr_name='node_ohe_feature_2', dim=4) g.add_edge_ohe(attr_name='edge_ohe_feature_1', dim=5) print(g)  print(g.data['node_ohe_feature_1']) print(g.data['node_ohe_feature_2']) print(g.data['edge_ohe_feature_1']) <pre>Directed graph with 3 nodes and 3 edges\n\nNode attributes\n\tnode_class\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\tnode_ohe_feature_1\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 3])\n\tnode_ohe_feature_2\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\tedge_ohe_feature_1\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 5])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tfeature\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\ntensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]], device='cuda:0')\ntensor([[1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 1., 0.]], device='cuda:0')\ntensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.]], device='cuda:0')\n</pre> <p>By default, graphs in <code>pathpyG</code> are directed. To represent undirected edges, we must add edges in both directions. We can use the <code>to_undirected()</code> function to make a directed graph undirected, which adds all (missing) edges that point in the opposite direction. This will also automatically duplicate and assign the corresponding edge attributes to the newly formed (directed) edges, i.e. edges are assumed to have the same attributes in both directions.</p> In\u00a0[55]: Copied! <pre>g_u = g.to_undirected()\nprint(g_u)\n</pre> g_u = g.to_undirected() print(g_u) <pre>Undirected graph with 3 nodes and 6 (directed) edges\n\nNode attributes\n\tnode_class\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\tnode_ohe_feature_1\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 3])\n\tnode_ohe_feature_2\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 1])\n\tedge_ohe_feature_1\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 5])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tfeature\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\n</pre> <p>By default, the <code>Graph</code> object can contain multiple identical edges, so the following is possible:</p> In\u00a0[56]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')])\nprint(g.data.edge_index)\n</pre> g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')]) print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1, 2],\n           [1, 1, 2, 0]], device='cuda:0', sparse_size=(3, 3), nnz=4,\n          sort_order=row)\n</pre> <p>It is often convenient, to coalesce multi-edges into weighted single-edges, i.e. in the example above we may prefer a graph where each edge occurs once in the edge index, but the edge <code>a-&gt;b</code> has a weight attribute of two, while the two other edges have one.</p> <p>In <code>pathpyG</code> we can do this by turning a graph into a weighted graph, which will coalesce edges and add an edge weight attribute that counts multi-edges in the original istance.</p> In\u00a0[58]: Copied! <pre>g_w = g.to_weighted_graph()\nprint(g_w.data.edge_index)\nprint(g_w['edge_weight', 'a', 'b'])\nprint(g_w['edge_weight', 'b', 'c'])\nprint(g_w['edge_weight', 'c', 'a'])\n</pre> g_w = g.to_weighted_graph() print(g_w.data.edge_index) print(g_w['edge_weight', 'a', 'b']) print(g_w['edge_weight', 'b', 'c']) print(g_w['edge_weight', 'c', 'a']) <pre>EdgeIndex([[0, 1, 2],\n           [1, 2, 0]], device='cuda:0', sparse_size=(3, 3), nnz=3,\n          sort_order=row)\ntensor(2., device='cuda:0')\ntensor(1., device='cuda:0')\ntensor(1., device='cuda:0')\n</pre> <p>As we will see in a separate notebook focussing on the advanced (temporal) graph visualization features of <code>pathpyG</code>, it is easy to generate (interactive) HTML plots of graphs, that are embedded into jupyter notebooks. You can simply call the <code>pp.plot</code> function on the Graph object:</p> In\u00a0[61]: Copied! <pre>pp.plot(g, edge_color='gray', node_label=g.mapping.node_ids.tolist());\n</pre> pp.plot(g, edge_color='gray', node_label=g.mapping.node_ids.tolist()); In\u00a0[64]: Copied! <pre>pp.algorithms.centrality.closeness_centrality(g)\n</pre> pp.algorithms.centrality.closeness_centrality(g) Out[64]: <pre>{'a': 0.6666666666666666, 'b': 0.6666666666666666, 'c': 0.6666666666666666}</pre> In\u00a0[65]: Copied! <pre>pp.algorithms.centrality.eigenvector_centrality(g)\n</pre> pp.algorithms.centrality.eigenvector_centrality(g) Out[65]: <pre>{'a': 0.5773502691896258, 'b': 0.5773502691896258, 'c': 0.5773502691896258}</pre> In\u00a0[66]: Copied! <pre>pp.algorithms.centrality.katz_centrality(g)\n</pre> pp.algorithms.centrality.katz_centrality(g) Out[66]: <pre>{'a': 0.5773502691896258, 'b': 0.5773502691896258, 'c': 0.5773502691896258}</pre>"},{"location":"tutorial/basic_concepts/#basic-pathpyg-concepts","title":"Basic pathpyG Concepts\u00b6","text":""},{"location":"tutorial/basic_concepts/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/basic_concepts/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>This first step of our multi-stage introductory tutorial introduces key concepts of <code>pathpyG</code>. While <code>pathpyG</code> targets GPU-accelerated analysis and learning using higher-order graph models for time series data on graphs, it can also be used to represent, analyze and interactively visualize static graphs. For this, it provides a <code>Graph</code> class that is build around the <code>torch_geometric.data.Data</code> object, which has the advantage that we can directly apply <code>pyG</code> transforms and use the <code>Graph</code> object for deep graph learning.</p> <p>In this tutorial you will learn how we can use <code>pathpyG</code> to represent static graphs. We start with basic features to create directed and undirected graphs with node-, edge-, and graph-level attributes. We also show how we can read and write graph data and how we can implement graph algorithms that are based on a traversal of nodes and edges.</p> <p>We first import the modules <code>torch</code>, <code>torch_geometric</code> and <code>pathpyG</code>. By setting the device used by <code>torch</code>, we specify whether we want to run our code on the CPU or on the GPU. For a CPU-based execution, set the <code>torch.device</code> configuration to <code>cpu</code>. Set the device to <code>cuda</code> if you want to run it on the GPU instead.</p>"},{"location":"tutorial/basic_concepts/#creating-graph-objects","title":"Creating Graph objects\u00b6","text":"<p>Let's start by generating a simple, directed graph with three nodes <code>a</code>, <code>b</code>, <code>c</code> and three edges <code>(a,b)</code>, <code>(b,c)</code> and <code>(a,b)</code>. The three nodes <code>a</code>, <code>b</code>, and <code>c</code> can be represented by integer indices $0, 1$ and $2$ respectively. Following the tensor-based representation in <code>pyG</code>, we use an <code>edge_index</code> tensor with shape <code>(2,m)</code> to represent the <code>m</code> edges of a graph. We can then add this to a <code>Data</code> object that can possibly hold additional node and edge attributes, and pass the <code>Data</code> object to the constructor of the <code>Graph</code> class.</p> <p>Using the mapping of node names to indices specified above, the following code generates a directed <code>Graph</code> with three edges <code>(a,c)</code>, <code>(b,c)</code> and <code>(a,b)</code>.</p>"},{"location":"tutorial/basic_concepts/#traversing-graphs","title":"Traversing Graphs\u00b6","text":"<p>The <code>Graph</code> object provides <code>get_successors</code> and <code>get_predecessors</code> functions, which return the indices of nodes that are connected to a node with a given index. Based on cached CSR (compressed sparse row) and CSC (compressed sparse column) representations cached for the sorted <code>EdgeIndex</code>, access to the successors and predecessors of a node works in constant time, i.e. it does not require to enumerate the <code>edge_index</code> tensor.</p> <p>For node <code>a</code> with index $0$ in our directed network we obtain:</p>"},{"location":"tutorial/basic_concepts/#node-edge-or-graph-level-attributes","title":"Node-, Edge- or Graph-Level Attributes\u00b6","text":"<p>Real-world graphs often have node-, edge-, or graph-level attributes. In <code>pathpyG</code>, we can add attributes as tensors, either by directly assigning them to the <code>pyG</code> data object of an existing graph (or by adding them to the <code>Data</code> object passed to the constructor). Following the <code>pyG</code> semantics of attribute names, we use the prefixes <code>node_</code> and <code>edge_</code> to refer to node- and edge-level attributes. Attributes without those prefixes are assumed to refer to graph-level attributes.</p>"},{"location":"tutorial/basic_concepts/#node-centralities","title":"Node Centralities\u00b6","text":"<p>To calculate node centralities, we can use a <code>networkx</code> delegate mechanism implemented in the module <code>pathpyG.algorithms.centrality</code>. Simply speaking, you can call any function implented in the networkx centrality module whose name ends with <code>_centrality</code>. The <code>pathpyG</code> graph object will be internally converted to a <code>networkx.DiGraph</code> object, the corresponding centrality function (with all of its parameters) will be called, and the result will be mapped back to nodes based on their IDs.</p> <p>In order to calculate the closeness centralities of all nodes for the graph above, we can call:</p>"},{"location":"tutorial/dbgnn/","title":"Causality-Aware GNNs","text":"In\u00a0[1]: Copied! <pre>%%capture\n!pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[2]: Copied! <pre>import pathpyG as pp\n\nimport torch\nfrom pathpyG.nn.dbgnn import DBGNN\nfrom pathpyG.utils.dbgnn import generate_bipartite_edge_index\nfrom torch_geometric.transforms import RandomNodeSplit\nfrom sklearn.metrics import balanced_accuracy_score\nimport torch_geometric\nfrom torch_geometric.data import Data\nfrom sklearn.manifold import TSNE\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy as sp\n\npp.config['torch']['device'] = 'cpu'\ndevice = pp.config['torch']['device']\n</pre> import pathpyG as pp  import torch from pathpyG.nn.dbgnn import DBGNN from pathpyG.utils.dbgnn import generate_bipartite_edge_index from torch_geometric.transforms import RandomNodeSplit from sklearn.metrics import balanced_accuracy_score import torch_geometric from torch_geometric.data import Data from sklearn.manifold import TSNE import numpy as np import matplotlib.pyplot as plt import scipy as sp  pp.config['torch']['device'] = 'cpu' device = pp.config['torch']['device'] <pre>\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[2], line 5\n      3 import torch\n      4 from pathpyG.nn.dbgnn import DBGNN\n----&gt; 5 from pathpyG.utils.dbgnn import generate_bipartite_edge_index\n      6 from torch_geometric.transforms import RandomNodeSplit\n      7 from sklearn.metrics import balanced_accuracy_score\n\nModuleNotFoundError: No module named 'pathpyG.utils.dbgnn'</pre> In\u00a0[\u00a0]: Copied! <pre>t = pp.TemporalGraph.from_csv('../data/temporal_clusters.tedges')\n</pre> t = pp.TemporalGraph.from_csv('../data/temporal_clusters.tedges') <p>This example has created in such a way that the nodes naturally form three clusters, which are highlighted in the interactive visualization below:</p> In\u00a0[\u00a0]: Copied! <pre>style = {}\nstyle['node_color'] = ['green']*10+['red']*10+['blue']*10\npp.plot(t, **style, edge_size=10);\n</pre> style = {} style['node_color'] = ['green']*10+['red']*10+['blue']*10 pp.plot(t, **style, edge_size=10); In\u00a0[\u00a0]: Copied! <pre>pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray');\n</pre> pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray'); <p>In fact, the topology of this graph corresponds to that of a random graph, i.e. there are not patterns whatsoever in the topology of links. Nevertheless, the temporal graph contains a cluster pattern in the topology of causal or time-respecting paths. In particular, the temporal ordering of time-stamped edges is such that nodes with the same cluster label are more frequently connected by time-respecting paths than nodes with different cluster labels. Hence, nodes within the same clusters can more strongly influence each other in a causal way, i.e. via multiple interactions that follow the arrow of time.</p> <p>Traditional (temporal) graph neural networks will not be able to learn from this pattern, as it is due to the specific microscopic temporal ordering of edges. Using higher-order De Bruijn graph models implemented in pathpyG, we can learn from temporal graph data that contains such patterns. Let us explain this step by step.</p> <p>Referring to the previous tutorial on causal paths in temporal graphs, we first create a node-time directed acyclic graph that captures the causal structure of the temporal graph. In this small example, we will only consider two time-stamped edges $(u,v;t)$ and $(v,w;t')$ to contribute to a causal path iff $0 &lt; t'-t \\leq 1$, i.e. we use a delta for the maximum time difference of one time step.</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2)\nprint(m)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2) print(m) <pre>MultiOrderModel with max. order 2\n</pre> <p>We can get the first and second order networks from the Multi Order Network object. The first order network is the network of nodes and edges, while the second order network is the network of first order edges as second order nodes and second order edges. The second order network is a De Bruijn graph that captures the temporal-topological patterns in the data.</p> In\u00a0[\u00a0]: Copied! <pre>g = m.layers[1]\ng2 = m.layers[2]\n</pre> g = m.layers[1] g2 = m.layers[2] In\u00a0[\u00a0]: Copied! <pre>pp.plot(g, edge_size=2);\n</pre> pp.plot(g, edge_size=2); <p>Since it does not consider patterns in the causal topology of the temporal graph, this is not a meaningful model. We can instead use a second-order De Bruijn graph model, which we can easily fit to the paths:</p> In\u00a0[\u00a0]: Copied! <pre>pp.plot(g2, edge_size=1);\n</pre> pp.plot(g2, edge_size=1); <p>In this graph, every node is a link and links correspond to causal paths of length two, i.e. temporally ordered sequences consisting of two edges that overlap in the center node. In this graph, we clearly see a cluster pattern that is due to the way in which temporal edges are ordered in time. In particular, we see three clusters, where the edges in three of the clusters correspond to causal paths of length two that connect nodes within each of the three clusters. The edges in the fourth cluster (in the center of the visualization) represent causal paths that connect nodes in different clusters.</p> In\u00a0[\u00a0]: Copied! <pre>t_shuffled = pp.TemporalGraph.from_csv('../data/temporal_clusters.tedges')\nt_shuffled.shuffle_time()\n</pre> t_shuffled = pp.TemporalGraph.from_csv('../data/temporal_clusters.tedges') t_shuffled.shuffle_time() In\u00a0[\u00a0]: Copied! <pre>g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2]\n</pre> g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2] In\u00a0[\u00a0]: Copied! <pre>pp.plot(g2_shuffled);\n</pre> pp.plot(g2_shuffled); <p>We now find that the cluster pattern in the second-order graph has vanished. In fact, there is no pattern whatsoever since the underlying (static) graph topology is random and the random shuffling of time stamps leads to random causal paths.</p> In\u00a0[\u00a0]: Copied! <pre>L = g2.get_laplacian(normalization='rw', edge_attr='edge_weight')\nL_shuffled= g2_shuffled.get_laplacian(normalization='rw',edge_attr='edge_weight')\n</pre> L = g2.get_laplacian(normalization='rw', edge_attr='edge_weight') L_shuffled= g2_shuffled.get_laplacian(normalization='rw',edge_attr='edge_weight') <p>We then calculate the eigenvalues and eigenvectors of the Laplacians, and compute the Fiedler vector, i.e. the eigenvector that corresponds to the second-smallest eigenvalue of the Laplacian.</p> In\u00a0[\u00a0]: Copied! <pre>w,v = sp.linalg.eig(L.todense(),left= False, right = True)\nw_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense())\n</pre> w,v = sp.linalg.eig(L.todense(),left= False, right = True) w_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense()) In\u00a0[\u00a0]: Copied! <pre>fiedler = v[:,np.argsort(w)[1]]\nfiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]]\n</pre> fiedler = v[:,np.argsort(w)[1]] fiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]] <p>Below, we show that the clusters in the causal topology of the temporal graph correspond to clusters in the distribution of entries in the Fiedler vector, while there is no such pattern for the Fiedler vector of the second-order graph constructed from the shuffled temporal graph:</p> In\u00a0[\u00a0]: Copied! <pre>c = []\na = []\nfor v in g2.nodes:\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c.append('green')\n        a.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c.append('red')\n        a.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c.append('blue')\n        a.append(1)\n    else:\n        c.append('black')\n        a.append(0.1)\n</pre> c = [] a = [] for v in g2.nodes:     if int(v[0])&lt;10 and int(v[1])&lt;10:         c.append('green')         a.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c.append('red')         a.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c.append('blue')         a.append(1)     else:         c.append('black')         a.append(0.1) In\u00a0[\u00a0]: Copied! <pre>c_shuffled = []\na_shuffled = []\nfor v in g2_shuffled.nodes: \n\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c_shuffled.append('green')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c_shuffled.append('red')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c_shuffled.append('blue')\n        a_shuffled.append(1)\n    else:\n        c_shuffled.append('black')\n        a_shuffled.append(0.1)\n</pre> c_shuffled = [] a_shuffled = [] for v in g2_shuffled.nodes:       if int(v[0])&lt;10 and int(v[1])&lt;10:         c_shuffled.append('green')         a_shuffled.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c_shuffled.append('red')         a_shuffled.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c_shuffled.append('blue')         a_shuffled.append(1)     else:         c_shuffled.append('black')         a_shuffled.append(0.1) <p>In the plots below, we have colored those entries of the Fiedler vectors that correspond to edges connecting nodes within one of the three clusters shown above. The Fiedler vector shows a clear pattern, which translates to the cluster pattern in the causal topology that we have planted into our synthetic temporal graph.</p> In\u00a0[\u00a0]: Copied! <pre>plt.ylim(-.2, .25)\nplt.scatter(range(g2.N), np.real(fiedler),c=c, alpha=a);\n</pre> plt.ylim(-.2, .25) plt.scatter(range(g2.N), np.real(fiedler),c=c, alpha=a); <p>No such pattern exists in the Fiedler vector of the second-order graph corresponding to the shuffled <code>TemporalGraph</code>.</p> In\u00a0[\u00a0]: Copied! <pre>plt.ylim(-.1, .1)\nplt.scatter(range(g2_shuffled.N), fiedler_shuffled, c=c_shuffled, alpha=a_shuffled);\n</pre> plt.ylim(-.1, .1) plt.scatter(range(g2_shuffled.N), fiedler_shuffled, c=c_shuffled, alpha=a_shuffled); <pre>/Users/lisi/miniconda3/envs/ppG_dev/lib/python3.11/site-packages/matplotlib/cbook.py:1699: ComplexWarning: Casting complex values to real discards the imaginary part\n  return math.isfinite(val)\n/Users/lisi/miniconda3/envs/ppG_dev/lib/python3.11/site-packages/matplotlib/collections.py:194: ComplexWarning: Casting complex values to real discards the imaginary part\n  offsets = np.asanyarray(offsets, float)\n</pre> <p>We now set up a <code>pytorch_geometric.Data</code> object that contains all of the information needed to train the DBGNN model.</p> <p>We can use a convenience function of the <code>DBGNN</code> class in <code>pathpyG</code> to simplify this step. Combining a first- and a second-order model, we use the edge indices and the weight tensors for our message passing scheme. We further construct an edge_index of a bipartite graph that uses the last node in a second-order node to map messages back to first-order nodes.</p> In\u00a0[\u00a0]: Copied! <pre>data = m.to_dbgnn_data(max_order=2, mapping='last')\ndata.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids])\n</pre> data = m.to_dbgnn_data(max_order=2, mapping='last') data.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids]) In\u00a0[\u00a0]: Copied! <pre>data = RandomNodeSplit(num_val=0, num_test=0.3)(data)\n\nmodel = DBGNN(\n        num_features =[g.N, g2.N],\n        num_classes = len(data.y.unique()),\n        hidden_dims = [16, 32, 8],\n        p_dropout = 0.4\n        ).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(),  lr=0.005)\nloss_function = torch.nn.CrossEntropyLoss()\n\ndata = data.to(device)\n</pre> data = RandomNodeSplit(num_val=0, num_test=0.3)(data)  model = DBGNN(         num_features =[g.N, g2.N],         num_classes = len(data.y.unique()),         hidden_dims = [16, 32, 8],         p_dropout = 0.4         ).to(device)  optimizer = torch.optim.Adam(model.parameters(),  lr=0.005) loss_function = torch.nn.CrossEntropyLoss()  data = data.to(device) <p>The following function evaluates the prediction of our model based on the balanced accuracy score for categorical predictions.</p> In\u00a0[\u00a0]: Copied! <pre>def test(model, data):\n    model.eval()\n\n    _, pred = model(data).max(dim=1)\n\n    metrics_train = balanced_accuracy_score(\n        data.y[data.train_mask].cpu(),\n        pred[data.train_mask].cpu().numpy()\n        )\n\n    metrics_test = balanced_accuracy_score(\n        data.y[data.test_mask].cpu(),\n        pred[data.test_mask].cpu().numpy()\n        )\n\n    return metrics_train, metrics_test\n</pre> def test(model, data):     model.eval()      _, pred = model(data).max(dim=1)      metrics_train = balanced_accuracy_score(         data.y[data.train_mask].cpu(),         pred[data.train_mask].cpu().numpy()         )      metrics_test = balanced_accuracy_score(         data.y[data.test_mask].cpu(),         pred[data.test_mask].cpu().numpy()         )      return metrics_train, metrics_test In\u00a0[\u00a0]: Copied! <pre>losses = []\nfor epoch in range(100):\n        output = model(data)\n        loss = loss_function(output[data.train_mask], data.y[data.train_mask])\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        losses.append(loss)\n\n        if epoch % 10 == 0:\n                train_ba, test_ba = test(model, data)\n                print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}')\n</pre> losses = [] for epoch in range(100):         output = model(data)         loss = loss_function(output[data.train_mask], data.y[data.train_mask])         loss.backward()         optimizer.step()         optimizer.zero_grad()         losses.append(loss)          if epoch % 10 == 0:                 train_ba, test_ba = test(model, data)                 print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}') <pre>Epoch: 0, Loss: 1.333080530166626, Train balanced accuracy: 0.3333333333333333, Test balanced accuracy: 0.3333333333333333\nEpoch: 10, Loss: 0.9498822093009949, Train balanced accuracy: 0.7222222222222222, Test balanced accuracy: 0.6666666666666666\nEpoch: 20, Loss: 0.3054783046245575, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 30, Loss: 0.008039548061788082, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 40, Loss: 0.00031461837352253497, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 50, Loss: 9.158226748695597e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 60, Loss: 3.9874685171525925e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 70, Loss: 2.476602458045818e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 80, Loss: 1.9464583601802588e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 90, Loss: 1.717707527859602e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\n</pre> In\u00a0[\u00a0]: Copied! <pre>model.eval()\nlatent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach()\nlatent = model.higher_order_layers[1].forward(latent.cpu(), data.edge_index_higher_order).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())\n\ncolors = []\nfor v, w in g2.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g2.edges:\n    src = g2.mapping.to_idx(e[0])\n    tgt = g2.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach() latent = model.higher_order_layers[1].forward(latent.cpu(), data.edge_index_higher_order).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())  colors = [] for v, w in g2.nodes:     if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g2.edges:     src = g2.mapping.to_idx(e[0])     tgt = g2.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show() In\u00a0[\u00a0]: Copied! <pre>model.eval()\nlatent = model.forward(data).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())\n\ncolors = []\nfor v in g.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g.edges:\n    src = g.mapping.to_idx(e[0])\n    tgt = g.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.forward(data).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())  colors = [] for v in g.nodes:     if data.y[g.mapping.to_idx(v)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g.edges:     src = g.mapping.to_idx(e[0])     tgt = g.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show()"},{"location":"tutorial/dbgnn/#causality-aware-graph-neural-networks","title":"Causality-Aware Graph Neural Networks\u00b6","text":""},{"location":"tutorial/dbgnn/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/dbgnn/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In previous tutorials, we have introduced causal paths in temporal graphs, and how we can use them to generate higher-order De Bruijn graph models that capture temporal-topological patterns in time series data. In this tutorial, we will show how we can use De Bruijn Graph Neural Networks, a causality-aware deep learning architecture for temporal graph data. The details of this approach are introduced in this paper. The architecture is implemented in pathpyG and can be readily applied to temporal graph data.</p> <p>Below we illustrate this mthod in a supervised node classification task, i.e. given a temporal graph we will use the temporal-topological patterns in the graph to classify nodes.</p> <p>We start by importing a few modules:</p>"},{"location":"tutorial/dbgnn/#temporal-topological-clusters-in-temporal-graphs","title":"Temporal-Topological Clusters in Temporal Graphs\u00b6","text":"<p>Let us load a small synthetic toy example for a temporal graph with 60.000 time-stamped interactions between 30 nodes. We use the <code>TemporalGraph</code> class to load this example from a file containing edges with discrete time-stamps.</p>"},{"location":"tutorial/dbgnn/#modelling-causal-structures-with-higher-order-de-bruijn-graphs","title":"Modelling Causal Structures with Higher-Order De Bruijn Graphs\u00b6","text":"<p>But what is the origin for the cluster pattern? In the visualization above, you will notice that the time-stamped edges randomly interconnect nodes within and across clusters, actually there is no correlation whatsoever between the topology of links and the cluster membership of the nodes. Hence, the notion of clusters does not correspond to the common idea of cluster patterns in static graphs, which we can highlight further by plotting the static time-aggregated network:</p>"},{"location":"tutorial/dbgnn/#comparison-to-temporal-graph-with-shuffled-time-stamps","title":"Comparison to Temporal Graph with Shuffled Time Stamps\u00b6","text":"<p>You may wonder whether this pattern is really due to the temporal ordering of time-stamped edges. It is easy to check this. We can simply randomly shuffle the time stamps of all edges, which will break any correlations in the temporal ordering that lead to patterns in the causal topology.</p> <p>We repeat the path calculation for this shuffled temporal graph and construct the second-order De Bruijn Graph model again:</p>"},{"location":"tutorial/dbgnn/#spectral-clustering-with-second-order-graph-laplacian","title":"Spectral clustering with second-order graph Laplacian\u00b6","text":"<p>To take a different perspective on cluster patterns, we can actually use <code>pathpyG</code> to apply a spectral analysis to the higher-order graph. We can simply calculate a generalization of the Laplacian matrix to the second-order graph both for the actual temporal graph and its shuffled counterpart:</p>"},{"location":"tutorial/dbgnn/#node-classification-with-causality-aware-graph-neural-networks","title":"Node Classification with Causality-Aware Graph Neural Networks\u00b6","text":"<p>Let us now explore how we can develop a causality-aware deep graph learning architecture that utilizes this pattern in the causal topology. We will follow the architecture introduced in this work. The architecture actually performs message passing in higher-order models with multiple orders at once. In a final message passing step, a bipartite graph is used to obtain vector-space representations of actual nodes in the temporal graph.</p>"},{"location":"tutorial/dbgnn/#training-the-model","title":"Training the model\u00b6","text":"<p>We are now ready to train and evaluate our causality-aware graph neural network. We will frist create a random split of the nodes, set the optimizer and the hyperparameters of our model.</p>"},{"location":"tutorial/dbgnn/#latent-space-representation-of-edges","title":"Latent space representation of edges\u00b6","text":"<p>We can inspect the model by plotting a latent space representation of the edges generated by the second-order layer of our architecture.</p>"},{"location":"tutorial/dbgnn/#causality-aware-latent-space-representation-of-nodes","title":"Causality-aware latent space representation of nodes\u00b6","text":"<p>We can further generate latent space representations of the nodes generated by the last bipartite layer of our architecture:</p>"},{"location":"tutorial/netzschleuder/","title":"Accessing Netzschleuder","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[19]: Copied! <pre>import numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.decomposition import TruncatedSVD\n\nimport torch\nfrom torch.nn import Linear, ReLU, Sigmoid, Parameter\n\nimport torch_geometric\nfrom torch_geometric.nn import Sequential, GCNConv, SimpleConv, MessagePassing\n\nimport pathpyG as pp\n\npp.config['torch']['device'] = 'cpu'\n# pp.config['torch']['device'] = 'cuda'\n</pre> import numpy as np from matplotlib import pyplot as plt  from sklearn import metrics from sklearn.decomposition import TruncatedSVD  import torch from torch.nn import Linear, ReLU, Sigmoid, Parameter  import torch_geometric from torch_geometric.nn import Sequential, GCNConv, SimpleConv, MessagePassing  import pathpyG as pp  pp.config['torch']['device'] = 'cpu' # pp.config['torch']['device'] = 'cuda' In\u00a0[2]: Copied! <pre>g = pp.io.read_netzschleuder_network('polbooks')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_network('polbooks') print(g) <pre>Undirected graph with 105 nodes and 882 (directed) edges\n\nNode attributes\n\tnode_label\t\t&lt;class 'list'&gt;\n\tnode_value\t\t&lt;class 'list'&gt;\n\tnode__pos\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\tname\t\t&lt;class 'str'&gt;\n\tdescription\t\t&lt;class 'str'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\turl\t\t&lt;class 'str'&gt;\n\ttags\t\t&lt;class 'list'&gt;\n\tcitation\t\t&lt;class 'str'&gt;\n\tdirected\t\t&lt;class 'float'&gt;\n\n</pre> <p>If we print the resulting <code>Graph</code> instance, we find that the meta information at the node- and grah-level are automatically retrieved and added to the graph.</p> <p>Let us read the famous karate club network. The record <code>karate club</code> actually contains two networks with labels <code>77</code> and <code>78</code>, which refer to two different versions of the graph data. If multiple graph data sets exist in the same record, we need to specify the name of the graph as second argument.</p> In\u00a0[3]: Copied! <pre>g = pp.io.read_netzschleuder_network('karate', '77')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_network('karate', '77') print(g) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n\nNode attributes\n\tnode_name\t\t&lt;class 'list'&gt;\n\tnode_groups\t\t&lt;class 'list'&gt;\n\tnode__pos\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\tname\t\t&lt;class 'str'&gt;\n\tdescription\t\t&lt;class 'str'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\turl\t\t&lt;class 'str'&gt;\n\ttags\t\t&lt;class 'list'&gt;\n\tcitation\t\t&lt;class 'str'&gt;\n\n</pre> In\u00a0[4]: Copied! <pre>pp.plot(g, edge_color='gray');\n</pre> pp.plot(g, edge_color='gray'); <p>We see that the nodes actually contain a <code>node_group</code> property, which maps the nodes to two groups. Those groups are often used as <code>ground truth</code> for communities in this simple illustrative graph. We will instead use it as ground truth categorical node label for a node classification experiment based on a Graph Neural Network.</p> In\u00a0[5]: Copied! <pre>print(g['node_groups'])\n</pre> print(g['node_groups']) <pre>[[1], [1], [1], [1], [1], [1], [1], [1], [1], [2], [1], [1], [1], [1], [2], [2], [1], [1], [2], [1], [2], [1], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2]]\n</pre> <p>We can plot categorical labels by passing them as node colors in the pathpy plot function.</p> In\u00a0[6]: Copied! <pre>pp.plot(g, node_color = [g['node_groups',v][0] for v in g.nodes])\n</pre> pp.plot(g, node_color = [g['node_groups',v][0] for v in g.nodes]) Out[6]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f871f7308e0&gt;</pre> <p>For convenience, let us shift the group labels to binary values 0 and 1:</p> In\u00a0[7]: Copied! <pre>g['node_groups'] = torch.tensor(g['node_groups']).float()\ng['node_groups'] -= 1\nprint(g['node_groups'])\n</pre> g['node_groups'] = torch.tensor(g['node_groups']).float() g['node_groups'] -= 1 print(g['node_groups']) <pre>tensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])\n</pre> <p>We can retrieve a data object that contains the graph and its attributes:</p> In\u00a0[8]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 154], num_nodes=34, node_name=[34], node_groups=[34, 1], node__pos=[34], name='karate (77)', description='Network of friendships among members of a university karate club. Includes metadata for faction membership after a social partition. Note: there are two versions of this network, one with 77 edges and one with 78, due to an ambiguous typo in the original study. (The most commonly used is the one with 78 edges.)[^icon]\n[^icon]: Description obtained from the [ICON](https://icon.colorado.edu) project.', citation='['W. W. Zachary, \"An information flow model for conflict and fission in small groups.\" Journal of Anthropological Research 33, 452-473 (1977)., https://doi.org/10.1086/jar.33.4.3629752']', url='https://aaronclauset.github.io/datacode.htm', tags=[3])\n</pre> <p>Let's use a one-hot encoding of nodes as a simple feature <code>x</code>, and let's use the node groups as target label <code>y</code>.</p> In\u00a0[9]: Copied! <pre>data = g.data\ng.add_node_ohe('node_feature')\ndata['x'] = data['node_feature']\ndata['y'] = data['node_groups']\n</pre> data = g.data g.add_node_ohe('node_feature') data['x'] = data['node_feature'] data['y'] = data['node_groups'] <p>It is easy to define a Graph Convolutional Network that ues the one-hot-encodings of nodes and the topology to predict binary node labels:</p> In\u00a0[10]: Copied! <pre>model = Sequential('node_ohe, edge_index', [\n    (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),\n    ReLU(inplace=True),\n    (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),\n    Sigmoid(),\n])\nmodel.to(pp.config['torch']['device'])\n</pre> model = Sequential('node_ohe, edge_index', [     (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),     ReLU(inplace=True),     (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),     Sigmoid(), ]) model.to(pp.config['torch']['device']) Out[10]: <pre>Sequential(\n  (0) - GCNConv(34, 8): node_ohe, edge_index -&gt; hidden\n  (1) - ReLU(inplace=True): hidden -&gt; hidden\n  (2) - GCNConv(8, 1): hidden, edge_index -&gt; output\n  (3) - Sigmoid(): output -&gt; output\n)</pre> <p>We next apply a <code>RandomNodeSplit</code> transformation to split the nodes in a training and test set.</p> In\u00a0[11]: Copied! <pre>transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0)\ndata = transform(data)\n</pre> transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0) data = transform(data) <p>We then train our model for 1000 epochs on the training set.</p> In\u00a0[12]: Copied! <pre>epochs = 1000\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n    \nlosses = []\n\nmodel.train()\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)\n    loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n\n    losses.append(loss.cpu().detach().numpy())\n\nplt.plot(range(epochs), losses)\nplt.grid()\n</pre> epochs = 1000  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)      losses = []  model.train() for epoch in range(epochs):     optimizer.zero_grad()     out = model(data.x, data.edge_index)     loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])     loss.backward()     optimizer.step()      losses.append(loss.cpu().detach().numpy())  plt.plot(range(epochs), losses) plt.grid() <p>We evaluate the model in the test set and calculate the adjusted mutual information for the ground truth.</p> In\u00a0[13]: Copied! <pre>model.eval()\npredicted_groups = model(data.x, data.edge_index).round().long()\nmetrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy())\n</pre> model.eval() predicted_groups = model(data.x, data.edge_index).round().long() metrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy()) Out[13]: <pre>1.0</pre> <p>We visualize node representations learned by the model. The test nodes are colored, while training nodes are greyed out.</p> In\u00a0[15]: Copied! <pre># get activations in first-layer\nembedding = model[0].forward(data.x, data.edge_index)\n\n# dimensionality reduction\nsvd = TruncatedSVD()\nlow_dim = svd.fit_transform(embedding.cpu().detach().numpy())\n\n# plot with colors corresponding to groups in validation set\ncolors = {}\nfor v in range(g.N):\n    if not data.val_mask[v]:\n        colors[v] = 'grey'\n    else:\n        if data.y[v].item() == 0.0:\n            colors[v] = 'blue'\n        else:\n            colors[v] = 'orange'\n\nplt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values());\n</pre> # get activations in first-layer embedding = model[0].forward(data.x, data.edge_index)  # dimensionality reduction svd = TruncatedSVD() low_dim = svd.fit_transform(embedding.cpu().detach().numpy())  # plot with colors corresponding to groups in validation set colors = {} for v in range(g.N):     if not data.val_mask[v]:         colors[v] = 'grey'     else:         if data.y[v].item() == 0.0:             colors[v] = 'blue'         else:             colors[v] = 'orange'  plt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values()); <p>This simple code gives you thousands of networks with various meta information at your fingertips, to wich you can directly apply graph learning models provided in pyG, or deep graoh learning architectures defined by yourself.</p>"},{"location":"tutorial/netzschleuder/#learning-in-graphs-from-the-netzschleuder-repository","title":"Learning in Graphs from the Netzschleuder Repository\u00b6","text":""},{"location":"tutorial/netzschleuder/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/netzschleuder/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>Access to a large number of graphs with different topological characteristics and from different domains is crucial for the development and evaluation of graph learning methods. Tousands of graph data sets are available scattered throughout the web, possibly using different data formats and with missing information on their actual origin. Addressing this issue the Netschleuder Online Repository by Tiago Peixoto provides a single repository of graphs in a single format, including descriptions, citations, and node-/edge- or graph-level meta-data. To facilitate the development of graph learning techniques, pathpyG provides a feature that allows to directly read networks from the netzschleuder repository via an API.</p> <p>In this brief unit, we will learn how we can retrieve network records and graph data from the netzschleuder repository. We will further demonstrate how we can conveniently apply a Graph Neural Network to predict node-level categories contained in the meta-data.</p> <p>We first need to import a few modules.</p>"},{"location":"tutorial/netzschleuder/#reading-graphs-from-the-netzschleuder-repository","title":"Reading graphs from the netzschleuder repository\u00b6","text":"<p>In the <code>pathpy.io</code> module, there is a function that allows to read graph data from the API.</p> <p>We can read a given networks from the netzschleuder database using its record name. Just browse the Netschleuder Online Repository to find the record names. In the following, we use a graph capturing co-purchase relationships between political books.</p>"},{"location":"tutorial/netzschleuder/#applying-graph-neural-networks-to-netzschleuder-data","title":"Applying Graph Neural Networks to Netzschleuder Data\u00b6","text":""},{"location":"tutorial/paths_higher_order/","title":"Paths and Higher-Order Models","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nimport pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\npp.config['torch']['device'] = 'cpu'\n</pre> import torch import pathpyG as pp from torch_geometric.data import Data from torch_geometric import EdgeIndex  pp.config['torch']['device'] = 'cpu' <p>For the following examples, we consider a simple directed graph with five nodes <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>, <code>e</code> and four edges:</p> In\u00a0[2]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\npp.plot(g, node_label=g.mapping.node_ids.tolist(), edge_color='gray');\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c', 'e')]) pp.plot(g, node_label=g.mapping.node_ids.tolist(), edge_color='gray'); In\u00a0[3]: Copied! <pre>paths = pp.PathData(g.mapping)\n\npaths.append_walk(('a', 'c', 'd'), weight=2.0)\npaths.append_walk(('b', 'c', 'e'), weight=2.0)\nprint(paths)\n</pre> paths = pp.PathData(g.mapping)  paths.append_walk(('a', 'c', 'd'), weight=2.0) paths.append_walk(('b', 'c', 'e'), weight=2.0) print(paths) <pre>PathData with 2 paths with total weight 4.0\n</pre> <p>Let us inspect how those walks are internally stored in the <code>PathData</code> object. We find that the class internally stores a list of <code>pyG.Data</code> objects, each of which contains an <code>edge_index</code> and a <code>node_sequence</code> property.</p> In\u00a0[4]: Copied! <pre>paths.paths\n</pre> paths.paths Out[4]: <pre>[Data(edge_index=[2, 2], node_sequence=[3, 1], num_nodes=3, edge_weight=[2]),\n Data(edge_index=[2, 2], node_sequence=[3, 1], num_nodes=3, edge_weight=[2])]</pre> <p>The <code>edge_index</code> tensor represents an ordered sequence of edges traversed by the walk, where the indices of nodes map to the <code>node_sequence</code> tensor. This additional mapping is neccessary since walks can traverse the same edge multiple times. Moreover, it allows to internally concatenate multiple walks into a single <code>Data</code> object, which is needed for gast GPU-based operations on path data.</p> In\u00a0[5]: Copied! <pre>paths.paths[0].edge_index\n</pre> paths.paths[0].edge_index Out[5]: <pre>tensor([[0, 1],\n        [1, 2]])</pre> <p>The <code>node_sequence</code> tensor tells us that the node 1 in the <code>edge_index</code> maps to the node in the graph with index <code>2</code>, which is node <code>c</code>.</p> In\u00a0[56]: Copied! <pre>paths.paths[0].node_sequence\n</pre> paths.paths[0].node_sequence Out[56]: <pre>tensor([[0],\n        [2],\n        [3]])</pre> <p>For the second path, we get the same edge index, but the <code>node_sequence</code> tensor maps to the sequence <code>b -&gt; c -&gt; e</code>:</p> In\u00a0[48]: Copied! <pre>paths.paths[1].edge_index\n</pre> paths.paths[1].edge_index Out[48]: <pre>tensor([[0, 1],\n        [1, 2]])</pre> In\u00a0[49]: Copied! <pre>paths.paths[1].node_sequence\n</pre> paths.paths[1].node_sequence Out[49]: <pre>tensor([[1],\n        [2],\n        [4]])</pre> <p>In way, we can see a collection of paths as a generalization of the usual way to define a graph based on the collection of edges (which are simply paths of length one). With this perspective, we would see a standard static (weighted) graph as a first-order model of our paths, which only considers the frequency at which edges are traversed.</p> <p>To generate such a first-order model, we can use the <code>MultiOderModel</code> class, extraxting the first-layer of the model, which is simply a weighted static graph where edge weights count the number of times each edge is traversed by a path. We will explain the class <code>MultiOrderModel</code>, which generalizes this concept to higher-order graph models for any order $k$ in a moment. For now, we can just use it to generate a firt-order weighted graph as follows.</p> <p>The generated graph is again based on a <code>pyG.Data</code> object that contains an edge_index and edge weights. As we can see, for the example above the edge_index is just a concatenation of the edge indices of individual walks, where the node indices have been mapped to the correct nodes.</p> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths, max_order=1)\ng = m.layers[1]\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\npp.plot(g, node_label=paths.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_PathData(paths, max_order=1) g = m.layers[1] print(g.data.edge_index) print(g.data.edge_weight) pp.plot(g, node_label=paths.mapping.node_ids.tolist()); <pre>EdgeIndex([[0, 1, 2, 2],\n           [2, 2, 3, 4]], sparse_size=(5, 5), nnz=4, sort_order=row)\ntensor([2., 2., 2., 2.])\n</pre> <p>Why are data on paths and walks interesting in the first place. The answer is that they provide a lot of information on the causal topology of complex systems, i.e. which nodes can possibly causally influence each other.</p> <p>For this, let us assume that the four walks above tell us which paths information (or whatever you may be interested in) can take in the simple graph above. That is, we observe something moving from <code>a</code> via <code>c</code> to <code>d</code> and from <code>b</code> via <code>c</code> to <code>e</code>, and each of those events occur twice. However, we never observed that something moving from <code>a</code> to <code>c</code> ended up in <code>d</code>. And neither did we observe that something moving from <code>b</code> to <code>c</code> ended up in <code>e</code>. This means that - assuming that we completely observed all walks or paths - there is no way that <code>a</code> can causally influence <code>e</code> or that <code>b</code> could causally influence <code>d</code> via the center node <code>c</code>. Note that this is not what we would assume if we consider possible paths in the topology of the underlying graph, where paths of length two exist between all faur pairs of nodes (<code>a</code>, <code>d</code>), (<code>a</code>, <code>e</code>), (<code>b</code>, <code>d</code>), (<code>b</code>, <code>e</code>).</p> <p>Hence, we can use data capturing actually observed paths or walks ion a network in contrast to which paths or walks would theoretically be possible based on the topology.</p> <p>As a contrast, consider the following four observations of walks in the same graph.</p> In\u00a0[9]: Copied! <pre>paths_2 = pp.PathData(g.mapping)\n\npaths_2.append_walk(('a', 'c', 'd'), weight=1)\npaths_2.append_walk(('a', 'c', 'e'), weight=1)\npaths_2.append_walk(('b', 'c', 'd'), weight=1)\npaths_2.append_walk(('b', 'c', 'e'), weight=1)\nprint(paths_2)\n</pre> paths_2 = pp.PathData(g.mapping)  paths_2.append_walk(('a', 'c', 'd'), weight=1) paths_2.append_walk(('a', 'c', 'e'), weight=1) paths_2.append_walk(('b', 'c', 'd'), weight=1) paths_2.append_walk(('b', 'c', 'e'), weight=1) print(paths_2) <pre>PathData with 4 paths with total weight 4\n</pre> <p>Here we have observed walks along all four possible paths of length two. It is easy to see that the weighted edge index of this <code>WalkData</code> instance is identical to the one before:</p> In\u00a0[20]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths_2, max_order=1)\ng = m.layers[1]\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_PathData(paths_2, max_order=1) g = m.layers[1] print(g.data.edge_index) print(g.data.edge_weight) pp.plot(g, node_label=g.mapping.node_ids.tolist()); <pre>EdgeIndex([[0, 1, 2, 2],\n           [2, 2, 3, 4]], sparse_size=(5, 5), nnz=4, sort_order=row)\ntensor([2, 2, 2, 2])\n</pre> <p>This is a first-order graph representation, as it only captures the (weighted) edges in the underlying path data, i.e. we could say that we only count the frequency of paths (or walks) of length one. This naturally gives rise to an <code>edge_index</code> tensor with shape $(2,m)$, where $m$ is the number of unique edges in the graph that are traversed by the paths.</p> In\u00a0[24]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths, max_order=2)\ng = m.layers[2]\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_PathData(paths, max_order=2) g = m.layers[2] pp.plot(g, node_label=g.mapping.node_ids.tolist()); <p>For $k=2$, we get the edge index of a second-order De Bruijn graph where the second-order nodes are first-order edges and second-order edges represent walks of length two in the original graph. The edge weights capture the observation frequencies of those walks. In oour example, we have two different walks of length two ($a$ -&gt; $c$ -&gt; $d$ and $b$ -&gt; $c$ -&gt; $e$), which are represented by two edges $(a-c, c-d)$ and $(b-c, c-e)$. Each of those walks appears twice so the weights of both edges are two.</p> In\u00a0[26]: Copied! <pre>print(g.mapping)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> print(g.mapping) print(g.data.edge_index) print(g.data.edge_weight) <pre>('a', 'c') -&gt; 0\n('b', 'c') -&gt; 1\n('c', 'd') -&gt; 2\n('c', 'e') -&gt; 3\n\nEdgeIndex([[0, 1],\n           [2, 3]], sparse_size=(4, 4), nnz=2, sort_order=row)\ntensor([2., 2.])\n</pre> <p>While this goes way beyond the scope of this tutorial, thanks to the tensor-based representation of paths, the construction of a higher-order De Bruijn graph model can actually be done based on efficient GPU operations, i.e. we can easily scale up the models for large graphs.</p> <p>Let us have a closer look at our examples above. While the first-order edge indices of the two path objects <code>paths</code> and <code>paths_2</code> are the same, we find that the second-order edge indices are actually different. For the paths in <code>paths_2</code> we actually have four different paths of length two, each occurring once. Hence, our second-order De Bruijn graph has four edges, each with weight one.. These edges correspond to all possible paths of length two in the underlying graph.</p> In\u00a0[29]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths_2, max_order=2)\ng = m.layers[2]\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_PathData(paths_2, max_order=2) g = m.layers[2] pp.plot(g, node_label=g.mapping.node_ids.tolist()); In\u00a0[30]: Copied! <pre>print(g.mapping)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> print(g.mapping) print(g.data.edge_index) print(g.data.edge_weight) <pre>('a', 'c') -&gt; 0\n('b', 'c') -&gt; 1\n('c', 'd') -&gt; 2\n('c', 'e') -&gt; 3\n\nEdgeIndex([[0, 0, 1, 1],\n           [2, 3, 2, 3]], sparse_size=(4, 4), nnz=4, sort_order=row)\ntensor([1, 1, 1, 1])\n</pre> <p>We thus find that the second-order De Bruijn graph representation of paths is sensitive to the differences in the causal topology, while a first-order graph is not. This is the basis to generalize network analysis and graph learning to causality-aware graph models for various kinds of time series data on graphs. In particular, as we shall see in more detail in a later tutorial, we can use paths to generate k-th order graphs that can be used to generalize Graph Neural Networks to higher-order De Bruijn Graphs.</p> <p>Note that all higher-order graphs are simply <code>Graph</code> objects, which implies that we can iterate through the nodes of a higher-order graph just like normal graphs. Node indices are automatically mapped, yielding tuples of first-order node identifiers.</p> In\u00a0[32]: Copied! <pre>for n in g.nodes:\n    print(n)\n</pre> for n in g.nodes:     print(n) <pre>('a', 'c')\n('b', 'c')\n('c', 'd')\n('c', 'e')\n</pre> <p>Edges are tuples with two elements, where each element is a k-th order node, i.e. a tuple of node IDs of length $k$.</p> In\u00a0[33]: Copied! <pre>for e in g.edges:\n    print(e)\n</pre> for e in g.edges:     print(e) <pre>(('a', 'c'), ('c', 'd'))\n(('a', 'c'), ('c', 'e'))\n(('b', 'c'), ('c', 'd'))\n(('b', 'c'), ('c', 'e'))\n</pre> <p>The weight attribute stores a tensor whose entries capture the frequencies of edges, i.e. the frequencies of paths of length $k$.</p> In\u00a0[34]: Copied! <pre>for e in g.edges:\n    print(e, g['edge_weight', e[0], e[1]].item())\n</pre> for e in g.edges:     print(e, g['edge_weight', e[0], e[1]].item()) <pre>(('a', 'c'), ('c', 'd')) 1\n(('a', 'c'), ('c', 'e')) 1\n(('b', 'c'), ('c', 'd')) 1\n(('b', 'c'), ('c', 'e')) 1\n</pre> <p>We can finally plot a higher-order De Bruijn graph in the same way as a first-order graph.</p> In\u00a0[35]: Copied! <pre>pp.plot(g, node_label=g.mapping.node_ids.tolist(), edge_color='gray');\n</pre> pp.plot(g, node_label=g.mapping.node_ids.tolist(), edge_color='gray'); <p>Let us compare this to a second-order graph model of the second path data set from above, which corresponds to a system where all paths of length two are actually realized in terms of walks.</p> In\u00a0[42]: Copied! <pre>paths_tube = pp.PathData.from_ngram('../data/tube_paths_train.ngram', sep=',', weight=True)\n</pre> paths_tube = pp.PathData.from_ngram('../data/tube_paths_train.ngram', sep=',', weight=True) <pre>PathData with 1 paths with total weight 12333.0\n</pre> <p>To plot a (first-order) graph representation of the London Tube metro network, we can use the following code:</p> In\u00a0[44]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths_tube, max_order=1)\ng = m.layers[1]\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_PathData(paths_tube, max_order=1) g = m.layers[1] pp.plot(g, node_label=g.mapping.node_ids.tolist()); <p>As we shall see in the following tutorial, the <code>MultiOrderGraph</code> class is also the basis for the GPU-based analysis and modelling of causal structures in temporal graphs. In particular, the underlying generalization of first-order static graph models to higher-order De Bruijn graphs allows us to easily build causality-aware graph neural network architectures that consider both the topology and the temoral ordering of time-stamped edges in a temporal graph.</p>"},{"location":"tutorial/paths_higher_order/#path-data-and-higher-order-de-bruijn-graphs","title":"Path Data and Higher-Order De Bruijn Graphs\u00b6","text":""},{"location":"tutorial/paths_higher_order/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/paths_higher_order/#motivation-and-learning-objective","title":"Motivation and Learning Objective\u00b6","text":"<p>While <code>pathpyG</code> is useful to handle and visualize static graphs - as the name suggests - its main advantage is that it facilitates the analysis of time series data that can be used to calculate paths in a graph. As we shall see in the following tutorial, there are various situations in which naturally have access to data on paths, including data on (random) walks or trajectories, traces of dynamical processes giving rise to node sequences or directed acyclic graphs, or time-respecting paths in temporal graphs. ``pathpyG` can be used to model patterns in such data based on higher-order De Bruijn graph models.</p> <p>In this first unit, we will show how <code>pathpyG</code> supports to represent data on paths in graphs. Lile graphs, such data are internally stored as tensors, which facilitates GPU-based operations to create higher-order De Bruijn graphs.</p> <p>We first import the modules <code>torch</code> and <code>pathpyG</code>. By setting the device used by <code>torch</code>, we can specify whether we want to run our code on the CPU or on the GPU.</p>"},{"location":"tutorial/paths_higher_order/#using-pathdata-to-store-walks-in-a-graph","title":"Using <code>PathData</code> to store walks in a graph\u00b6","text":"<p>Assume that we have time series data that captures observations of walks (or trajectoriess) in the graph above. For example, we could observe four walks of length two, two each of the following:</p> <ul> <li>2 x <code>a</code> -&gt; <code>c</code> -&gt; <code>d</code></li> <li>2 x <code>b</code> -&gt; <code>c</code> -&gt; <code>e</code></li> </ul> <p>Note that we define the length of a walk as the number of edges that are traversed, i.e. a sequence that consists of a single node, e.g. <code>a</code>, is considered a walk of length zero, while every edge in a graph is a walk of length one.</p> <p><code>pp.PathData</code> supports to store and model such data. We first create an instance of the <code>PathData</code> class. To consistently map node IDs to indices across <code>Graph</code> and <code>PathData</code> objects, we can pass the <code>IndexMap</code> object from the <code>Graph</code> above in the constructor. We then use the <code>append_walk</code> function to add observations of our two walks, where the <code>weight</code> argument is used to indicate the number of times each path has been observed.</p>"},{"location":"tutorial/paths_higher_order/#from-graphs-to-higher-order-de-bruijn-graph-models","title":"From Graphs to Higher-Order De Bruijn Graph Models\u00b6","text":"<p>As we have seen above, the use of a first-order graph model discards information in path data, which capture which nodes can possibly causally influence each other via paths. A key feature of <code>pathpyG</code> is it allows to generalize this first-order modelling perspective to $k$-th order De Bruijn graph models for paths, where the nodes in a $k$-th order De Bruijn graph model are sequences of $k$ nodes. Edges connect pairs of nodes that overlap in $k-1$ nodes and capture paths of length $k$.</p> <p>A De Bruijn graph of order $k=1$ is simply a normal (weighted) static graph consisting of nodes and edges. Pairs of nodes connected by edges overlap in $k-1=0$ nodes and capture paths of length $k=1$, i.e. simple dyadic edges in the underlying path data.</p> <p>For a De Bruijn graph with order $k=2$, in our example above, an edge connects a pair of nodes $(a,b)$ and $(b,c)$ that overlaps in the $k-1=1$ node $b$. Such an edge represents the path $a -&gt; b -&gt; c$ of length two. We can use the <code>MultiOderModel</code> class to generate a second-order De Bruijn graph representation of the path data above. We just have to set the <code>max_order</code> parameter to two and use the second layer of the resulting <code>MultiOrderModel</code> instance.</p>"},{"location":"tutorial/paths_higher_order/#loading-empirical-walks-from-n-gram-files","title":"Loading empirical walks from N-Gram Files\u00b6","text":"<p>For real data on walks in graphs it is not convenient to manually construct and add walks based on edge tensors. We can instead use the <code>from_ngram</code> function of class <code>PathData</code> to load such data from an n-gram file, i.e. a text file where each line corresponds to one observed walk consisting of comma-separated node IDs. If we set the argument <code>weight=True</code>, the last component of each line is considered to be the observation frequency of that particular walk.</p> <p>As an example, the file <code>data/tube_paths_train.ngram</code> contains observed passenger itineraries between nodes in a graph that representes the network of London Tube stations. Each of those itineraries is associated with an observation frequencies. The following is an excerpt from that file:</p> <pre><code>Southwark,Waterloo,212.0\nLiverpool Street,Bank / Monument,1271.0\nBarking,West Ham,283.0\nTufnell Park,Kentish Town,103.0\n...\n</code></pre> <p>Note that this will automatically create an internal mapping of node IDs to indices.</p>"},{"location":"tutorial/temporal_betweenness/","title":"Temporal betweenness","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\nimport torch\n\nfrom collections import deque\n\nfrom scipy.sparse.csgraph import bellman_ford, dijkstra\nimport numpy as np\nfrom time import time\nfrom collections import defaultdict\n\n\nfrom tqdm import tqdm\n</pre> import pathpyG as pp from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index import torch  from collections import deque  from scipy.sparse.csgraph import bellman_ford, dijkstra import numpy as np from time import time from collections import defaultdict   from tqdm import tqdm In\u00a0[2]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('../data/sociopatterns_highschool_2013_train.tedges')\nprint(t_sp)\nprint(torch.unique(t_sp.data.t).size(0))\n</pre> t_sp = pp.TemporalGraph.from_csv('../data/sociopatterns_highschool_2013_train.tedges') print(t_sp) print(torch.unique(t_sp.data.t).size(0)) <pre>Temporal Graph with 327 nodes, 8950 unique edges and 220378 events in [1385982080.0, 1386163840.0]\n\nGraph attributes\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\n579\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[3]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=3600, max_order=2)\nprint(m)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=3600, max_order=2) print(m) <pre>MultiOrderModel with max. order 2\n</pre> In\u00a0[4]: Copied! <pre>t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges')\nprint(t_ants)\n</pre> t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges') print(t_ants) <pre>Temporal Graph with 68 nodes, 506 unique edges and 1045 events in [899.0, 1796.0]\n\nGraph attributes\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=10)\nprint(m)\nprint(m.layers[1].data.edge_weight)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=10) print(m) print(m.layers[1].data.edge_weight) <pre>MultiOrderModel with max. order 10\ntensor([ 2.,  1.,  1.,  3.,  3.,  1.,  2.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,\n         1.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,  1.,  5.,  2.,  6.,  6.,  1.,\n         1.,  3.,  3.,  1.,  1.,  3.,  1.,  2.,  9.,  3.,  1.,  1.,  4.,  1.,\n         1.,  1.,  4.,  2.,  3.,  2.,  1.,  4.,  3.,  2.,  4.,  1.,  1.,  3.,\n         1.,  2.,  3.,  1.,  1.,  4.,  2.,  9.,  5.,  1.,  2.,  4.,  1.,  2.,\n         1.,  1.,  1.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  1.,  3.,  4.,  4.,\n         3.,  4.,  3.,  1.,  2.,  3.,  1.,  2.,  4.,  2.,  1.,  1.,  1.,  1.,\n         1.,  1.,  1.,  2.,  1.,  3.,  1.,  4.,  1.,  1.,  1.,  1.,  5.,  2.,\n         1.,  1.,  2.,  1.,  1.,  2.,  1.,  4.,  3.,  4.,  1.,  2.,  1.,  1.,\n         1.,  2.,  3.,  1.,  4.,  1.,  3.,  3.,  1.,  1.,  3.,  1.,  2.,  1.,\n         1.,  4.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  3.,  1.,  1.,\n         1.,  1.,  3.,  2.,  2.,  2.,  2.,  1.,  1.,  2.,  4.,  3.,  1.,  2.,\n         2.,  3.,  5.,  5.,  2.,  1.,  2.,  1.,  1.,  5.,  2.,  3.,  2.,  1.,\n         1.,  2.,  5.,  1.,  1.,  2.,  2.,  6.,  1.,  2.,  4.,  1.,  2.,  5.,\n         4.,  5.,  1.,  1.,  2.,  1.,  3.,  6.,  2.,  1.,  1.,  1.,  2.,  2.,\n        12.,  7.,  4.,  1.,  1.,  1.,  4.,  2.,  1.,  1.,  1.,  3.,  2.,  1.,\n         1.,  1.,  2.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n         1.,  6.,  1.,  4.,  2.,  2.,  1.,  2.,  2.,  3.,  3.,  2.,  4.,  4.,\n         1.,  7.,  5.,  1.,  2.,  2.,  1.,  2.,  4.,  4.,  5.,  6.,  4.,  1.,\n         2.,  2.,  1.,  4.,  3.,  1.,  1.,  1.,  5.,  7.,  1.,  3.,  5.,  1.,\n         1.,  4.,  1.,  1.,  2.,  1.,  6.,  4.,  2.,  2.,  1.,  4.,  1.,  1.,\n         5.,  1.,  2.,  3.,  4.,  1.,  1.,  1.,  2.,  1.,  2.,  2.,  3.,  1.,\n         2.,  7.,  1.,  7.,  1.,  2.,  1.,  2.,  1.,  3.,  1.,  3.,  3.,  1.,\n         3.,  3.,  1.,  4.,  3.,  2.,  2.,  1.,  1.,  1.,  3.,  1.,  1.,  3.,\n         1.,  1.,  3.,  1.,  6.,  1.,  3.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n         1.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  5.,  2.,  4.,  1.,  3.,  4.,\n         3.,  1.,  2.,  2.,  2.,  1.,  2.,  1.,  3.,  2.,  2.,  1.,  5.,  1.,\n         3.,  1.,  2.,  3.,  2.,  2.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  2.,\n         1.,  2.,  3.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  4.,\n         1.,  2.,  1.,  5.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,\n         2.,  1.,  2.,  2.,  2.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,\n         3.,  2.,  1.,  2.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,\n         2.,  1.,  1.,  3.,  5.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,  4.,  5.,\n         1.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  1.,  1.,  1.,  1.,  1.,\n         3.,  2.,  1.,  1.,  3.,  2.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,\n         2.,  1.,  1.,  1.,  2.,  1.,  1.,  4.,  2.,  1.,  3.,  3.,  3.,  3.,\n         1.,  1.])\n</pre> In\u00a0[3]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=3600)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=3600) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 579/579 [00:53&lt;00:00, 10.79it/s]\n 31%|\u2588\u2588\u2588       | 102/327 [26:29&lt;58:26, 15.59s/it]  \n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=3600)\n      2 print(bw)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:255, in temporal_betweenness_centrality(g, delta)\n    253 v = Q.popleft()\n    254 # for all successor events within delta\n--&gt; 255 for w in event_graph.successors(v):\n    256 \n    257     # we dicover w for the first time\n    258     if dist[w] == -1:\n    259         dist[w] = dist[v] + 1\n\nFile /workspaces/pathpyG/src/pathpyG/core/Graph.py:295, in Graph.successors(self, node)\n    283 def successors(self, node: Union[int, str] | tuple) \\\n    284         -&gt; Generator[Union[int, str] | tuple, None, None]:\n    285     \"\"\"Return all successors of a given node.\n    286 \n    287     This method returns a generator object that yields all successors of a\n   (...)\n    292         node:   Index or string ID of node for which successors shall be returned.\n    293     \"\"\" \n--&gt; 295     for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n    296         yield self.mapping.to_id(j.item())\n\nKeyboardInterrupt: </pre> In\u00a0[4]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=30)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=30) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 4581.51it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7f9453f36cb0&gt;, {0: 9.083333333333336, 7: 15.0, 10: 114.12687232787852, 1: 5.0, 6: 9.5, 12: 35.060389610389606, 22: 58.61201533244884, 49: 2.500000000000001, 2: 346.2515994755158, 27: 249.9532851737187, 4: 140.7880952380952, 42: 28.220839755359876, 28: 146.0366185070518, 65: 15.791666666666675, 29: 190.04444444444454, 24: 26.736796536796536, 5: 126.14722222222221, 3: 40.32903828197944, 35: 3.9999999999999996, 9: 7.5, 17: 78.59657287157289, 20: 68.21558441558443, 48: 27.916666666666664, 11: 99.25000000000001, 15: 53.07553688141922, 8: 5.8571428571428585, 26: 118.34098235785545, 37: -0.33333333333333304, 34: 58.120919946926136, 23: 49.347619047619034, 16: -0.1666666666666714, 32: 1.3333333333333286, 46: 2.40126050420168, 19: -1.8611111111111098, 36: 1.0000000000000004, 39: 2.0, 14: 25.33333333333333, 31: 1.5, 21: 0.5555555555555536, 33: 2.1666666666666705, 13: 0.0, 18: -5.19444444444445, 25: -1.9984014443252818e-15, 41: 14.888888888888886, 57: 1.0, 52: 13.833333333333332, 51: 2.916666666666661, 44: 2.999999999999999, 47: 1.5, 38: 0.0, 40: 0.0, 62: -7.444444444444445, 56: 0.0, 61: 0.0, 67: 2.220446049250313e-16})\n</pre> In\u00a0[7]: Copied! <pre>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt_long = pp.TemporalGraph.from_edge_list(tedges)\nc = pp.algorithms.centrality.temporal_closeness_centrality(t_long, 5)\nprint(c)\n</pre> tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),               ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),               ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),               ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),               ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)] t_long = pp.TemporalGraph.from_edge_list(tedges) c = pp.algorithms.centrality.temporal_closeness_centrality(t_long, 5) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 4453.94it/s]</pre> <pre>Created temporal event DAG with 38 nodes and 47 edges\n{'a': 12.0, 'b': 16.0, 'c': 16.0, 'd': 14.666666666666666, 'e': 14.666666666666666, 'f': 24.0, 'g': 14.666666666666666, 'h': 28.0, 'i': 24.0}\n</pre> <pre>\n</pre> In\u00a0[9]: Copied! <pre>c = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, 3600)\n</pre> c = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, 3600) <pre>  0%|          | 0/1157 [00:00&lt;?, ?it/s]</pre> <pre>  4%|\u258e         | 43/1157 [00:05&lt;02:18,  8.05it/s]\n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 c = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, 3600)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:186, in temporal_closeness_centrality(g, delta)\n    172 \"\"\"Calculates the closeness of nodes based on observed shortest paths\n    173 between all nodes. Following the definition by M. A. Beauchamp 1965\n    174 (https://doi.org/10.1002/bs.3830100205).\n   (...)\n    183 dict\n    184 \"\"\"\n    185 centralities = dict()\n--&gt; 186 dist, _ = temporal_shortest_paths(g, delta)\n    187 for x in g.nodes:\n    188     centralities[x] = sum((g.N - 1) / dist[_np.arange(g.N) != g.mapping.to_idx(x), g.mapping.to_idx(x)])\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/temporal.py:59, in temporal_shortest_paths(g, delta)\n     57 def temporal_shortest_paths(g: TemporalGraph, delta: int):\n     58     # generate temporal event DAG\n---&gt; 59     edge_index = lift_order_temporal(g, delta)\n     61     # Add indices of g.N first-order nodes as source nodes of paths in augmented TEG\n     62     src_edges_src = g.data.edge_index[0] + g.M\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/temporal.py:51, in lift_order_temporal(g, delta)\n     49         src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n     50         dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n---&gt; 51         ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n     52         second_order.append(ho_edge_index)\n     54 ho_index = torch.cat(second_order, dim=1)    \n\nKeyboardInterrupt: </pre> In\u00a0[4]: Copied! <pre>print(c)\n</pre> print(c) <pre>{'454': 41671.338095238054, '640': 42220.10476190471, '1': 31384.485714285773, '939': 43385.1666666666, '185': 46485.271428571396, '258': 42662.533333333326, '55': 41131.62698412695, '170': 43822.54999999994, '9': 55537.204761904715, '453': 42306.650000000016, '45': 54390.77142857138, '14': 42915.57142857141, '190': 51695.83809523803, '400': 37502.9365079365, '637': 40505.24126984126, '255': 43516.342857142794, '275': 53779.13333333323, '176': 52638.13333333328, '533': 36436.70952380954, '116': 46335.46666666662, '151': 46517.87142857134, '866': 51019.77619047604, '280': 40957.63095238092, '484': 38709.39523809525, '243': 42567.83809523808, '687': 43355.67142857139, '54': 44738.06666666662, '364': 43477.92142857135, '374': 41239.258730158705, '295': 37942.38968253968, '441': 44693.04761904753, '101': 46261.46984126977, '425': 40808.355411255354, '47': 34439.18333333336, '241': 40734.0880952381, '179': 51910.84285714278, '202': 47549.81666666654, '63': 48038.816666666564, '564': 38769.93809523808, '577': 34370.49047619052, '265': 42888.016666666605, '494': 40898.7698412698, '443': 42818.935714285675, '209': 33025.35238095244, '843': 39757.76984126982, '222': 31847.612698412748, '205': 43918.02142857136, '894': 39705.247619047565, '1359': 54767.9999999999, '1383': 37680.55476190476, '376': 53616.13333333324, '638': 41859.176190476144, '1238': 42806.904761904734, '1260': 38609.26666666665, '487': 46472.59365079362, '984': 45297.69999999997, '226': 42690.47619047611, '353': 46454.99999999993, '1342': 44222.67619047608, '1518': 59688.27142857133, '122': 48889.13333333324, '1067': 42078.83809523807, '1324': 41852.96666666664, '70': 44801.455555555476, '132': 47628.98809523799, '779': 42758.522222222164, '279': 42601.21428571425, '908': 36329.59523809524, '510': 29415.290476190487, '545': 44361.355555555485, '634': 49410.73333333322, '1332': 57435.76666666657, '1401': 48332.21666666656, '582': 44306.50476190468, '605': 55865.5333333332, '252': 45385.02142857135, '3': 50445.78333333325, '884': 48080.34285714278, '339': 41450.89999999998, '691': 48490.171428571346, '869': 47797.033333333246, '72': 48899.99999999993, '954': 46840.76666666663, '160': 47314.2428571428, '117': 46867.93333333327, '346': 41061.76984126978, '111': 45678.421428571404, '124': 43084.39285714283, '276': 42882.58333333332, '621': 39236.16984126983, '39': 41416.11255411249, '871': 44988.38809523805, '694': 49321.4714285713, '778': 49137.51428571418, '513': 39579.116666666654, '236': 35266.21428571434, '883': 40068.50476190471, '1594': 46784.104761904644, '1828': 41670.949999999946, '1214': 48579.43333333323, '196': 47528.471428571334, '201': 44797.83333333326, '245': 53325.838095237974, '390': 44972.08809523807, '938': 44610.77142857142, '923': 37550.54285714288, '106': 58207.29999999987, '272': 55849.23333333323, '753': 43170.54999999998, '486': 35035.81507936507, '531': 41168.10793650794, '254': 48965.199999999975, '382': 44808.699999999975, '119': 45078.038095238015, '240': 46369.36031746025, '447': 45610.11666666662, '649': 42277.54285714276, '1204': 46224.08333333323, '466': 32600.38809523813, '841': 37388.707142857165, '199': 43105.73809523804, '674': 54227.77142857136, '857': 38546.395238095225, '945': 40750.388095238064, '1218': 47321.61666666656, '1512': 51657.80476190465, '653': 49398.44365079353, '502': 44192.40476190468, '587': 29551.511904761897, '626': 41647.27619047614, '420': 45023.704761904715, '504': 40343.27619047614, '311': 46414.63809523806, '267': 44915.038095238066, '177': 48121.22222222215, '480': 40095.671428571455, '771': 23901.880158730197, '312': 46976.59999999993, '612': 43187.238095238026, '450': 36801.13095238098, '89': 47408.54999999997, '322': 49383.56666666663, '520': 33164.678571428616, '15': 45297.70000000002, '211': 47992.633333333324, '366': 37022.86269841269, '227': 45639.99999999996, '440': 48286.033333333275, '41': 47324.33333333326, '388': 47221.100000000006, '219': 42089.70476190474, '658': 48671.79999999991, '220': 42779.73809523808, '576': 39435.90952380952, '642': 46664.57142857137, '391': 37692.58571428572, '777': 35597.647619047646, '20': 39938.88095238094, '958': 50489.638095238006, '103': 29371.176984127007, '61': 47813.333333333234, '274': 36857.53412698415, '147': 51953.53333333325, '277': 32935.18492063496, '702': 30786.81904761907, '242': 44846.73333333334, '38': 52752.233333333206, '438': 37185.73333333332, '387': 46914.11666666656, '1295': 49073.866666666545, '1412': 52219.76666666659, '492': 47707.3833333333, '1345': 46802.733333333235, '1212': 51198.29999999987, '28': 45031.466666666616, '327': 45873.63333333326, '1216': 50562.59999999988, '372': 52590.526984126904, '720': 45705.19999999992, '1784': 41720.23809523804, '27': 46151.50952380945, '171': 34138.926984126985, '1336': 43007.54999999995, '1423': 52198.03333333327, '1366': 37297.11666666668, '407': 48333.3809523809, '1320': 46319.16666666659, '1805': 47327.438095237994, '1237': 41225.8047619047, '974': 29733.65793650794, '464': 45232.49999999995, '477': 42176.24999999997, '763': 36072.546825396836, '1894': 45776.221428571334, '1201': 43844.28333333326, '1228': 50051.86666666656, '786': 37304.61984126989, '886': 43075.46666666661, '797': 47585.13333333329, '959': 34756.25714285715, '1485': 41606.13809523808, '210': 46916.83333333329, '4': 42904.70476190475, '790': 30436.757142857183, '285': 53224.9333333333, '544': 43005.609523809464, '333': 50127.93333333329, '622': 35464.14285714289, '429': 45130.042857142784, '46': 39267.476190476154, '343': 37518.719047619066, '867': 36621.44285714288, '615': 44610.7714285714, '977': 42285.30476190473, '90': 46425.50476190473, '269': 44197.83809523808, '603': 46936.23809523808, '335': 43720.48095238093, '765': 43121.64999999997, '257': 41894.10476190469, '268': 39532.9333333333, '214': 43410.00476190473, '491': 43702.240476190455, '181': 39791.01666666664, '650': 40985.18571428571, '85': 46765.993650793615, '325': 43602.49999999998, '941': 39712.62142857144, '356': 40737.58095238093, '744': 37414.70952380953, '1543': 46257.07142857135, '145': 43442.992857142846, '173': 41173.02380952376, '909': 33217.84761904766, '79': 48995.083333333285, '854': 38707.45476190475, '527': 43498.49047619046, '475': 39621.94826839824, '471': 43425.269841269816, '681': 27453.98650793652, '465': 36373.57936507936, '446': 35151.33809523811, '58': 49894.29999999995, '32': 42986.204761904744, '991': 44181.53809523805, '725': 39806.15238095237, '859': 40474.45238095238, '798': 41875.088095238054, '256': 49459.63333333331, '306': 39031.514285714235, '131': 41163.70952380949, '677': 38990.11746031743, '960': 34713.56666666667, '769': 37148.47619047621, '248': 38814.18095238095, '125': 46992.89999999995, '917': 38007.71904761903, '120': 49546.566666666615, '115': 45982.68809523806, '1519': 34333.75079365083, '970': 40702.264285714264, '213': 46737.6744588744, '424': 48813.06666666662, '428': 42515.5746031746, '488': 47845.93333333331, '498': 44651.5214285714, '809': 40044.96031746028, '92': 42035.37142857144, '845': 43173.26666666668, '655': 34575.92222222225, '156': 47349.171428571295, '413': 44792.400000000016, '21': 38381.0666666667, '1232': 35705.92619047622, '290': 40728.654761904734, '71': 41315.0666666667, '65': 44592.919047619034, '791': 34942.5428571429, '874': 43733.67619047614, '448': 45072.60476190477, '496': 49872.56666666665, '921': 36919.888095238115, '497': 35312.785714285754, '627': 36676.94047619046, '194': 44672.866666666676, '927': 43220.614285714255, '232': 52527.138095238035, '172': 45822.40476190471, '165': 26068.48650793651, '87': 42138.604761904746, '253': 39907.833333333365, '706': 47116.05555555552, '134': 48729.23809523806, '624': 38011.988095238106, '548': 33913.83174603179, '893': 44520.73333333333, '920': 41900.31428571425, '836': 44773.91255411253, '80': 47968.5714285714, '743': 40576.13333333335, '826': 46025.76666666668, '184': 49569.076190476095, '601': 51230.89999999998, '1870': 34552.11904761907, '200': 45851.899999999994, '784': 39126.209523809506, '751': 34508.53477633482, '434': 23954.014285714296, '979': 35987.0365079365, '647': 36782.50238095241, '246': 36560.12380952383, '489': 43239.24285714284, '998': 42595.00476190477, '435': 38087.278571428564, '468': 21858.55058830061, '48': 42347.78809523811, '1339': 44040.27142857138, '159': 40869.921428571426, '149': 25296.729725829755, '1819': 39140.180952380964, '525': 45662.50952380946, '882': 28492.9174603175, '34': 43807.543650793574, '239': 31866.888095238148, '62': 20550.960028860038, '452': 43745.06031746028, '445': 28096.385447885485}\n</pre> In\u00a0[5]: Copied! <pre>def temporal_event_graph(g: pp.TemporalGraph, delta=1): \n\n    print(g.data.edge_index)\n\n    # generate temporal event DAG\n    edge_index = pp.algorithms.lift_order_temporal(g, delta)\n    print(edge_index)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.data.edge_index.size(1)\n    print(src_edges_src)\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.data.edge_index[1] + g.data.edge_index.size(1) + g.N\n    print(dst_edges_dst)\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    event_graph = pp.Graph.from_edge_index(edge_index) \n    return event_graph\n</pre> def temporal_event_graph(g: pp.TemporalGraph, delta=1):       print(g.data.edge_index)      # generate temporal event DAG     edge_index = pp.algorithms.lift_order_temporal(g, delta)     print(edge_index)      # Add indices of first-order nodes as src and dst of paths in augmented     # temporal event DAG     src_edges_src = g.data.edge_index[0] + g.data.edge_index.size(1)     print(src_edges_src)     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.data.edge_index[1] + g.data.edge_index.size(1) + g.N     print(dst_edges_dst)      # add edges from source to edges and from edges to destinations     src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      # create sparse scipy matrix     event_graph = pp.Graph.from_edge_index(edge_index)      return event_graph In\u00a0[10]: Copied! <pre>eg = pp.algorithms.lift_order_temporal(t_long, delta=5)\nprint(eg)\n</pre> eg = pp.algorithms.lift_order_temporal(t_long, delta=5) print(eg) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 3068.65it/s]</pre> <pre>tensor([[ 0,  1,  1,  4,  5,  8, 12],\n        [ 1,  2,  3,  5,  6, 11, 14]])\n</pre> <pre>\n</pre> In\u00a0[11]: Copied! <pre>print(temporal_event_graph(t_long, delta=5))\n</pre> print(temporal_event_graph(t_long, delta=5)) <pre>tensor([[0, 1, 2, 2, 2, 5, 0, 1, 0, 7, 2, 6, 0, 0, 2, 5, 1, 8, 2, 7],\n        [1, 2, 3, 4, 5, 0, 6, 5, 6, 5, 5, 7, 2, 1, 7, 7, 8, 1, 8, 8]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 3405.44it/s]</pre> <pre>tensor([[ 0,  1,  1,  4,  5,  8, 12],\n        [ 1,  2,  3,  5,  6, 11, 14]])\ntensor([20, 21, 22, 22, 22, 25, 20, 21, 20, 27, 22, 26, 20, 20, 22, 25, 21, 28,\n        22, 27])\ntensor([30, 31, 32, 33, 34, 29, 35, 34, 35, 34, 34, 36, 31, 30, 36, 36, 37, 30,\n        37, 37])\nDirected graph with 38 nodes and 47 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <pre>\n</pre> In\u00a0[13]: Copied! <pre>def betweenness_brandes(g: pp.Graph, sources = None):\n    bw = defaultdict(lambda: 0.0)\n\n    if sources == None:\n        sources = [v for v in g.nodes]\n\n    for s in tqdm(sources):\n        S = list()\n        P = defaultdict(list)\n\n        sigma = defaultdict(lambda: 0)  \n        sigma[s] = 1\n\n        d = defaultdict(lambda: -1)        \n        d[s] = 0\n\n        Q = [s]\n        while Q:\n            v = Q.pop(0)\n            S.append(v)\n            for w in g.successors(v):\n                if d[w] &lt; 0:\n                    Q.append(w)\n                    d[w] = d[v] + 1\n                if d[w] == d[v] + 1:\n                    # we found shortest path from s via v to w\n                    sigma[w] = sigma[w] + sigma[v]\n                    P[w].append(v)\n        delta = defaultdict(lambda: 0.0)\n        while S:\n            w = S.pop()\n            for v in P[w]:\n                delta[v] = delta[v] + sigma[v]/sigma[w] * (1 + delta[w])\n                if v != w:\n                    bw[w] = bw[w] + delta[w]\n    return bw\n</pre> def betweenness_brandes(g: pp.Graph, sources = None):     bw = defaultdict(lambda: 0.0)      if sources == None:         sources = [v for v in g.nodes]      for s in tqdm(sources):         S = list()         P = defaultdict(list)          sigma = defaultdict(lambda: 0)           sigma[s] = 1          d = defaultdict(lambda: -1)                 d[s] = 0          Q = [s]         while Q:             v = Q.pop(0)             S.append(v)             for w in g.successors(v):                 if d[w] &lt; 0:                     Q.append(w)                     d[w] = d[v] + 1                 if d[w] == d[v] + 1:                     # we found shortest path from s via v to w                     sigma[w] = sigma[w] + sigma[v]                     P[w].append(v)         delta = defaultdict(lambda: 0.0)         while S:             w = S.pop()             for v in P[w]:                 delta[v] = delta[v] + sigma[v]/sigma[w] * (1 + delta[w])                 if v != w:                     bw[w] = bw[w] + delta[w]     return bw In\u00a0[14]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'), ('b', 'c'), ('c', 'd'), ('c', 'e')])\nbetweenness_brandes(g, g.nodes)\n</pre> g = pp.Graph.from_edge_list([('a', 'c'), ('b', 'c'), ('c', 'd'), ('c', 'e')]) betweenness_brandes(g, g.nodes) <pre>5it [00:00, 3583.04it/s]\n</pre> Out[14]: <pre>defaultdict(&lt;function __main__.betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {'e': 0.0, 'd': 0.0, 'c': 4.0})</pre> In\u00a0[15]: Copied! <pre>def temporal_event_graph(g: pp.TemporalGraph, delta = 1):\n    # generate temporal event DAG\n    edge_index = pp.algorithms.lift_order_temporal(g, delta)    \n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    print(g.data.edge_index)\n    edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges]\n    print(edges)\n    src_edges_src = g.data.edge_index[0] + g.M\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    src = [f'{v}-src' for v in g.nodes]\n    tgt = [f'{v}-tgt' for v in g.nodes]\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.data.edge_index[1] + g.M + g.N\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    mapping = pp.IndexMap(edges + src + tgt)\n    event_graph = pp.Graph.from_edge_index(edge_index, mapping) \n    return event_graph\n</pre> def temporal_event_graph(g: pp.TemporalGraph, delta = 1):     # generate temporal event DAG     edge_index = pp.algorithms.lift_order_temporal(g, delta)          # Add indices of first-order nodes as src and dst of paths in augmented     # temporal event DAG     print(g.data.edge_index)     edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges]     print(edges)     src_edges_src = g.data.edge_index[0] + g.M     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      src = [f'{v}-src' for v in g.nodes]     tgt = [f'{v}-tgt' for v in g.nodes]      dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.data.edge_index[1] + g.M + g.N      # add edges from source to edges and from edges to destinations     src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      # create sparse scipy matrix     mapping = pp.IndexMap(edges + src + tgt)     event_graph = pp.Graph.from_edge_index(edge_index, mapping)      return event_graph In\u00a0[25]: Copied! <pre># def fo_node(v, g, src_indices) -&gt; int:\n#     # if v is one of the source nodes, return corresponding first-order node\n\n    \n# def fo_src(v, g, src_indices):\n#     if v in src_indices:\n#         return v - g.M\n#     else:\n#         return g.data.edge_index[0,v].item()\n\ndef temporal_betweenness_brandes(g: pp.TemporalGraph, delta=1):\n\n    print(g.data.edge_index)\n\n    # generate temporal event DAG\n    edge_index = pp.algorithms.lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n #   print(g.data.edge_index)\n    #edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges]\n#    print(edges)\n    src_edges_src = g.data.edge_index[0] + g.M\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    #src = [f'{v}-src' for v in g.nodes]\n    #tgt = [f'{v}-tgt' for v in g.nodes]\n\n    # dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    # dst_edges_dst = g.data.edge_index[1] + g.M + g.N\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    # dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges], dim=1)\n\n    # create sparse scipy matrix\n    #mapping = pp.IndexMap(edges + src + tgt)\n    event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.M+g.N)\n    print(event_graph)\n    #pp.plot(event_graph, node_label=[i for i in event_graph.nodes])\n    #print(edge_index)\n\n    # # sources = first-order source nodes in temporal event graph\n    src_indices = set(torch.unique(src_edges_src).tolist())\n    #print(src_edges_src-g.M)\n    # tgt_indices = set(torch.unique(dst_edges_dst).tolist())\n    #print(src_indices)\n    # print(tgt_indices)\n\n    e_i = g.data.edge_index.numpy()\n\n    fo_nodes = dict()\n    for v in event_graph.nodes:\n        if v in src_indices:\n            fo_nodes[v] = v - g.M\n        else: # return first-order target node otherwise\n            fo_nodes[v] = e_i[1,v]\n\n    # start from indegree zero nodes\n    #roots = torch.where((degree(g.data.edge_index[1])==0))[0]\n    #dist, _ = pp.algorithms.temporal_shortest_paths(g, delta=delta)\n    #print(dist)\n    bw = defaultdict(lambda: 0.0)\n\n    # for all first-order nodes\n    for s in tqdm(src_indices):\n        t_start = time()\n        print('source', g.mapping.to_id(fo_nodes[s]))\n\n        # for any given s, d[v] is the shortest path distance from s to v\n        # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)\n        delta_ = defaultdict(lambda: 0.0)\n\n        # for any given s, sigma[v] counts shortest paths from s to v\n        sigma = defaultdict(lambda: 0.0)          \n        sigma[s] = 1\n\n        sigma_fo = defaultdict(lambda: 0.0)       \n        sigma_fo[fo_nodes[s]] = 1\n\n        dist = defaultdict(lambda: -1)\n        dist[s] = 0\n\n        dist_fo = defaultdict(lambda: -1)\n        dist_fo[fo_nodes[s]] = 0\n                \n        # for any given s, P[v] is the set of predecessors of v on shortest paths from s\n        P = defaultdict(list)\n\n        # Q is a queue, so we append at the end and pop from the start\n        Q = deque()  \n        Q.append(s)\n\n        # S is a stack, so we append at the end and pop from the end\n        S = list()\n    \n        # dijkstra with path counting\n        while Q:\n            v = Q.popleft()\n            #print('popped ', v)\n            # for all successor events within delta\n            for w in event_graph.successors(v):\n\n                # we dicover w for the first time\n                if dist[w] == -1:\n                    dist[w] = dist[v] + 1\n                    if dist_fo[fo_nodes[w]] == -1:\n                        dist_fo[fo_nodes[w]] = dist[v] + 1\n                    S.append(w)\n                    Q.append(w)\n                # we found a shortest path to event w via event v\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[w] + sigma[v]\n                    P[w].append(v)\n                    # we found a shortest path to first-order node of event w\n                    if dist[w] == dist_fo[fo_nodes[w]]:\n                        sigma_fo[fo_nodes[w]] += sigma[v]\n        #print('S =', S)\n        #print('P', P)\n        #print('d', dist)\n        print('finished BFS ', (time()- t_start))\n        c = 0\n        for i in dist_fo:\n            if dist_fo[i] &gt;=0:\n                c+= 1\n        bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1\n        #print(bw[fo_node(s, g, src_indices)])\n\n        # We computed top. shortest path distances and shortest path counts from (first-order) source nodes to all temporal events\n        # we must now project this to the first-order target nodes of those events\n        while S:\n            w = S.pop()\n            # work backwards through paths to all targets and sum delta and sigma\n\n            # check whether shortest path from s to event w is also shortest path to first-order target of w\n            # if d[w] == d_fo[w_fo]:            \n            if dist[w] == dist_fo[fo_nodes[w]]:\n                # v_fo = fo_tgt(v, g, src_indices, tgt_indices)\n                delta_[w] += (sigma[w]/sigma_fo[fo_nodes[w]])\n            for v in P[w]:\n                delta_[v] += (sigma[v]/sigma[w]) * delta_[w]\n                bw[fo_nodes[v]] += delta_[w] * (sigma[v]/sigma[w])\n    bw_id = defaultdict(lambda: 0.0)\n    for idx in bw:\n        bw_id[g.mapping.to_id(idx)] = bw[idx]\n    return bw_id\n</pre> # def fo_node(v, g, src_indices) -&gt; int: #     # if v is one of the source nodes, return corresponding first-order node       # def fo_src(v, g, src_indices): #     if v in src_indices: #         return v - g.M #     else: #         return g.data.edge_index[0,v].item()  def temporal_betweenness_brandes(g: pp.TemporalGraph, delta=1):      print(g.data.edge_index)      # generate temporal event DAG     edge_index = pp.algorithms.lift_order_temporal(g, delta)      # Add indices of first-order nodes as src and dst of paths in augmented     # temporal event DAG  #   print(g.data.edge_index)     #edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges] #    print(edges)     src_edges_src = g.data.edge_index[0] + g.M     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      #src = [f'{v}-src' for v in g.nodes]     #tgt = [f'{v}-tgt' for v in g.nodes]      # dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     # dst_edges_dst = g.data.edge_index[1] + g.M + g.N      # add edges from source to edges and from edges to destinations     src_edges = torch.stack([src_edges_src, src_edges_dst])     # dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges], dim=1)      # create sparse scipy matrix     #mapping = pp.IndexMap(edges + src + tgt)     event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.M+g.N)     print(event_graph)     #pp.plot(event_graph, node_label=[i for i in event_graph.nodes])     #print(edge_index)      # # sources = first-order source nodes in temporal event graph     src_indices = set(torch.unique(src_edges_src).tolist())     #print(src_edges_src-g.M)     # tgt_indices = set(torch.unique(dst_edges_dst).tolist())     #print(src_indices)     # print(tgt_indices)      e_i = g.data.edge_index.numpy()      fo_nodes = dict()     for v in event_graph.nodes:         if v in src_indices:             fo_nodes[v] = v - g.M         else: # return first-order target node otherwise             fo_nodes[v] = e_i[1,v]      # start from indegree zero nodes     #roots = torch.where((degree(g.data.edge_index[1])==0))[0]     #dist, _ = pp.algorithms.temporal_shortest_paths(g, delta=delta)     #print(dist)     bw = defaultdict(lambda: 0.0)      # for all first-order nodes     for s in tqdm(src_indices):         t_start = time()         print('source', g.mapping.to_id(fo_nodes[s]))          # for any given s, d[v] is the shortest path distance from s to v         # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)         delta_ = defaultdict(lambda: 0.0)          # for any given s, sigma[v] counts shortest paths from s to v         sigma = defaultdict(lambda: 0.0)                   sigma[s] = 1          sigma_fo = defaultdict(lambda: 0.0)                sigma_fo[fo_nodes[s]] = 1          dist = defaultdict(lambda: -1)         dist[s] = 0          dist_fo = defaultdict(lambda: -1)         dist_fo[fo_nodes[s]] = 0                          # for any given s, P[v] is the set of predecessors of v on shortest paths from s         P = defaultdict(list)          # Q is a queue, so we append at the end and pop from the start         Q = deque()           Q.append(s)          # S is a stack, so we append at the end and pop from the end         S = list()              # dijkstra with path counting         while Q:             v = Q.popleft()             #print('popped ', v)             # for all successor events within delta             for w in event_graph.successors(v):                  # we dicover w for the first time                 if dist[w] == -1:                     dist[w] = dist[v] + 1                     if dist_fo[fo_nodes[w]] == -1:                         dist_fo[fo_nodes[w]] = dist[v] + 1                     S.append(w)                     Q.append(w)                 # we found a shortest path to event w via event v                 if dist[w] == dist[v] + 1:                     sigma[w] += sigma[w] + sigma[v]                     P[w].append(v)                     # we found a shortest path to first-order node of event w                     if dist[w] == dist_fo[fo_nodes[w]]:                         sigma_fo[fo_nodes[w]] += sigma[v]         #print('S =', S)         #print('P', P)         #print('d', dist)         print('finished BFS ', (time()- t_start))         c = 0         for i in dist_fo:             if dist_fo[i] &gt;=0:                 c+= 1         bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1         #print(bw[fo_node(s, g, src_indices)])          # We computed top. shortest path distances and shortest path counts from (first-order) source nodes to all temporal events         # we must now project this to the first-order target nodes of those events         while S:             w = S.pop()             # work backwards through paths to all targets and sum delta and sigma              # check whether shortest path from s to event w is also shortest path to first-order target of w             # if d[w] == d_fo[w_fo]:                         if dist[w] == dist_fo[fo_nodes[w]]:                 # v_fo = fo_tgt(v, g, src_indices, tgt_indices)                 delta_[w] += (sigma[w]/sigma_fo[fo_nodes[w]])             for v in P[w]:                 delta_[v] += (sigma[v]/sigma[w]) * delta_[w]                 bw[fo_nodes[v]] += delta_[w] * (sigma[v]/sigma[w])     bw_id = defaultdict(lambda: 0.0)     for idx in bw:         bw_id[g.mapping.to_id(idx)] = bw[idx]     return bw_id  In\u00a0[26]: Copied! <pre>temporal_betweenness_brandes(t_sp, delta=3600)\n</pre> temporal_betweenness_brandes(t_sp, delta=3600) <pre>tensor([[ 43,  43,  44,  ..., 202, 162,  76],\n        [ 45,  44,  43,  ..., 262,  76, 162]])\n</pre> <pre>  0%|          | 0/579 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 579/579 [00:39&lt;00:00, 14.52it/s]\n</pre> <pre>Directed graph with 220705 nodes and 18249204 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <pre>  0%|          | 0/327 [00:00&lt;?, ?it/s]</pre> <pre>source 454\nfinished BFS  21.46290111541748\n</pre> <pre>  0%|          | 1/327 [00:23&lt;2:06:37, 23.30s/it]</pre> <pre>source 640\nfinished BFS  20.32966423034668\n</pre> <pre>  1%|          | 2/327 [00:45&lt;2:03:25, 22.79s/it]</pre> <pre>source 1\nfinished BFS  9.732733726501465\n</pre> <pre>  1%|          | 3/327 [00:56&lt;1:32:16, 17.09s/it]</pre> <pre>source 939\n</pre> <pre>  1%|          | 3/327 [01:19&lt;2:22:30, 26.39s/it]\n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[26], line 1\n----&gt; 1 temporal_betweenness_brandes(t_sp, delta=3600)\n\nCell In[25], line 103, in temporal_betweenness_brandes(g, delta)\n    100 v = Q.popleft()\n    101 #print('popped ', v)\n    102 # for all successor events within delta\n--&gt; 103 for w in event_graph.successors(v):\n    104 \n    105     # we dicover w for the first time\n    106     if dist[w] == -1:\n    107         dist[w] = dist[v] + 1\n\nFile /workspaces/pathpyG/src/pathpyG/core/Graph.py:296, in Graph.successors(self, node)\n    285 \"\"\"Return all successors of a given node.\n    286 \n    287 This method returns a generator object that yields all successors of a\n   (...)\n    292     node:   Index or string ID of node for which successors shall be returned.\n    293 \"\"\" \n    295 for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n--&gt; 296     yield self.mapping.to_id(j.item())\n\nKeyboardInterrupt: </pre> In\u00a0[61]: Copied! <pre># Example with two shortest time-respecting paths from a to e via c or d\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\nprint(t.data.edge_index)\nprint(t.mapping)\n\nbw_1 = temporal_betweenness_brandes(t, delta=1)\n\nfor v in t.nodes:\n    print(v, bw_1[t.mapping.to_idx(v)])\n</pre> # Example with two shortest time-respecting paths from a to e via c or d t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)]) print(t.data.edge_index) print(t.mapping)  bw_1 = temporal_betweenness_brandes(t, delta=1)  for v in t.nodes:     print(v, bw_1[t.mapping.to_idx(v)]) <pre>tensor([[0, 1, 1, 2, 3],\n        [1, 2, 3, 4, 4]])\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\ne -&gt; 4\n\ntensor([[0, 1, 1, 2, 3],\n        [1, 2, 3, 4, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2574.77it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 993.62it/s]</pre> <pre>source d\nsource a\nsource b\nsource c\na 0.0\nb 3.0\nc 1.0\nd 1.0\ne 0.0\n</pre> <pre>\n</pre> In\u00a0[62]: Copied! <pre>bw = temporal_betweenness_brandes(t_long, 5)\nfor v in t_long.nodes:\n    print(v, bw[t_long.mapping.to_idx(v)])\n</pre> bw = temporal_betweenness_brandes(t_long, 5) for v in t_long.nodes:     print(v, bw[t_long.mapping.to_idx(v)]) <pre>tensor([[0, 1, 2, 2, 2, 5, 0, 1, 0, 7, 2, 6, 0, 0, 2, 5, 1, 8, 2, 7],\n        [1, 2, 3, 4, 5, 0, 6, 5, 6, 5, 5, 7, 2, 1, 7, 7, 8, 1, 8, 8]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 3854.64it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00&lt;00:00, 1022.18it/s]</pre> <pre>source a\nsource b\nsource c\nsource f\nsource g\nsource h\nsource i\na 2.0\nb 2.0\nc 4.5\nd 0.0\ne 0.0\nf 2.0\ng 0.5\nh 0.0\ni 0.0\n</pre> <pre>\n</pre> In\u00a0[32]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'd', 3), ('b', 'd', 3)])\nprint(t.data.edge_index)\nprint(t.mapping)\n\nbw_1 = temporal_betweenness_brandes(t, delta=1)\nbw_2 = temporal_betweenness_brandes(t, delta=2)\n\nfor v in t.nodes:\n    print(v, bw_1[t.mapping.to_idx(v)], bw_2[t.mapping.to_idx(v)])\n</pre> t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'd', 3), ('b', 'd', 3)]) print(t.data.edge_index) print(t.mapping)  bw_1 = temporal_betweenness_brandes(t, delta=1) bw_2 = temporal_betweenness_brandes(t, delta=2)  for v in t.nodes:     print(v, bw_1[t.mapping.to_idx(v)], bw_2[t.mapping.to_idx(v)]) <pre>tensor([[0, 1, 2, 1],\n        [1, 2, 3, 3]])\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\ntensor([[0, 1, 2, 1],\n        [1, 2, 3, 3]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 3437.95it/s]\n</pre> <pre>{4, 5, 6}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 875.52it/s]\n</pre> <pre>source a\nsource b\nsource c\ntensor([[0, 1, 2, 1],\n        [1, 2, 3, 3]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2423.05it/s]\n</pre> <pre>{4, 5, 6}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 1125.28it/s]</pre> <pre>source a\nsource b\nsource c\na 0.0 -1.0\nb 1.0 1.0\nc 1.0 0.0\nd 0.0 0.0\n</pre> <pre>\n</pre> In\u00a0[93]: Copied! <pre>pp.algorithms.temporal_shortest_paths(t, delta=2)\n</pre> pp.algorithms.temporal_shortest_paths(t, delta=2) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2388.10it/s]</pre> <pre>Created temporal event DAG with 12 nodes and 11 edges\n</pre> <pre>\n</pre> Out[93]: <pre>(array([[ 0.,  1.,  2.,  2.],\n        [inf,  0.,  1.,  1.],\n        [inf, inf,  0.,  1.],\n        [inf, inf, inf,  0.]]),\n array([[-9999,     0,     1,     3],\n        [-9999, -9999,     1,     3],\n        [-9999, -9999, -9999,     2],\n        [-9999, -9999, -9999, -9999]], dtype=int32))</pre> In\u00a0[57]: Copied! <pre>pp.algorithms.temporal_shortest_paths(t, delta=1)\n</pre> pp.algorithms.temporal_shortest_paths(t, delta=1) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 3233.02it/s]</pre> <pre>Created temporal event DAG with 12 nodes and 10 edges\n</pre> <pre>\n</pre> Out[57]: <pre>(array([[ 0.,  1.,  2.,  3.],\n        [inf,  0.,  1.,  1.],\n        [inf, inf,  0.,  1.],\n        [inf, inf, inf,  0.]]),\n array([[-9999,     0,     1,     2],\n        [-9999, -9999,     1,     3],\n        [-9999, -9999, -9999,     2],\n        [-9999, -9999, -9999, -9999]], dtype=int32))</pre> In\u00a0[313]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4)])\nprint(t.mapping)\n\ntemporal_betweenness_brandes(t, delta=1)\n# 4 = a_src\n# 5 = c_src\n# 7 = b_src\n\n# 10 = c_tgt\n# 11 = d_tgt\n# 13 = e_tgt\n</pre> t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4)]) print(t.mapping)  temporal_betweenness_brandes(t, delta=1) # 4 = a_src # 5 = c_src # 7 = b_src  # 10 = c_tgt # 11 = d_tgt # 13 = e_tgt <pre>a -&gt; 0\nc -&gt; 1\nd -&gt; 2\nb -&gt; 3\ne -&gt; 4\n\ntensor([[0, 1, 3, 1],\n        [1, 2, 1, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 3559.77it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2406.37it/s]</pre> <pre>10\n[0]\n11\n[1]\n13\n[]\n10\n[]\n11\n[1]\n13\n[3]\n10\n[2]\n11\n[]\n13\n[3]\n</pre> <pre>\n</pre> Out[313]: <pre>defaultdict(&lt;function __main__.temporal_betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {1: 0.0, 2: 0.0, 4: 0.0})</pre> In\u00a0[253]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4),('a', 'c', 1), ('c', 'e', 2), ('b', 'c', 3), ('c', 'd', 4)])\nprint(t.mapping)\n\ntemporal_betweenness_brandes(t, delta=1)\n# 4 = a_src\n# 5 = c_src\n# 7 = b_src\n\n# 10 = c_tgt\n# 11 = d_tgt\n# 13 = e_tgt\n</pre> t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4),('a', 'c', 1), ('c', 'e', 2), ('b', 'c', 3), ('c', 'd', 4)]) print(t.mapping)  temporal_betweenness_brandes(t, delta=1) # 4 = a_src # 5 = c_src # 7 = b_src  # 10 = c_tgt # 11 = d_tgt # 13 = e_tgt <pre>a -&gt; 0\nc -&gt; 1\nd -&gt; 2\nb -&gt; 3\ne -&gt; 4\n\ntensor([[0, 0, 1, 1, 3, 3, 1, 1],\n        [1, 1, 2, 4, 1, 1, 4, 2]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 2609.21it/s]\n</pre> <pre>tensor([[0, 0, 1, 1, 4, 4, 5, 5],\n        [2, 3, 2, 3, 6, 7, 6, 7]])\n{8, 9, 11}\n{17, 14, 15}\n</pre> <pre>8it [00:00, 3661.15it/s]\n</pre> Out[253]: <pre>defaultdict(&lt;function __main__.temporal_betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {4: 0.0, 2: 0.0})</pre> In\u00a0[138]: Copied! <pre>event_graph = temporal_event_graph(t, delta=1)\npp.plot(event_graph, node_label = [v for v in event_graph.nodes])\n</pre> event_graph = temporal_event_graph(t, delta=1) pp.plot(event_graph, node_label = [v for v in event_graph.nodes]) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 3337.42it/s]</pre> <pre>tensor([[0, 1, 3, 1],\n        [1, 2, 1, 4]])\n['a-c-1.0', 'c-d-2.0', 'b-c-3.0', 'c-e-4.0']\n</pre> <pre>\n</pre> Out[138]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f8a1da53880&gt;</pre> In\u00a0[179]: Copied! <pre>betweenness_brandes(event_graph, sources=['a-src', 'b-src', 'c-src'])\n</pre> betweenness_brandes(event_graph, sources=['a-src', 'b-src', 'c-src']) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2910.69it/s]\n</pre> Out[179]: <pre>defaultdict(&lt;function __main__.betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {'d-tgt': 0.0,\n             'c-tgt': 0.0,\n             'c-d-2.0': 2.0,\n             'a-c-1.0': 3.0,\n             'e-tgt': 0.0,\n             'c-e-4.0': 2.0,\n             'b-c-3.0': 3.0})</pre> In\u00a0[182]: Copied! <pre>\n</pre> <pre>tensor([[0, 1, 3, 1],\n        [1, 2, 1, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 2712.57it/s]\n</pre> <pre>tensor([[ 0,  2,  4,  5,  7,  5,  0,  1,  2,  3],\n        [ 1,  3,  0,  1,  2,  3, 10, 11, 10, 13]])\n{4, 5, 7}\n</pre> <pre>  0%|          | 0/3 [00:00&lt;?, ?it/s]\n</pre> <pre>\n---------------------------------------------------------------------------\nUnboundLocalError                         Traceback (most recent call last)\nCell In[182], line 1\n----&gt; 1 temporal_betweenness_brandes(t, delta=1)\n\nCell In[180], line 56, in temporal_betweenness_brandes(g, delta)\n     53 bw = defaultdict(lambda: 0.0)\n     54 for s in tqdm(src_indices):\n---&gt; 56     fo_src = fo_src(s, g, src_indices, tgt_indices)     \n     57     dist_eg = defaultdict(lambda: -1)\n     58     dist_eg[s] = 0\n\nUnboundLocalError: local variable 'fo_src' referenced before assignment</pre> In\u00a0[75]: Copied! <pre>temporal_betweenness_brandes(t_sp, delta=3600)\n</pre> temporal_betweenness_brandes(t_sp, delta=3600) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1157/1157 [01:15&lt;00:00, 15.43it/s]\n  8%|\u258a         | 25/327 [13:32&lt;2:43:34, 32.50s/it]</pre> <pre>Unexpected exception formatting exception. Falling back to standard exception\n</pre> <pre>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_3320/540718842.py\", line 1, in &lt;module&gt;\n    temporal_betweenness_brandes(t_sp, delta=3600)\n  File \"/tmp/ipykernel_3320/1211725645.py\", line 36, in temporal_betweenness_brandes\n    return betweenness_brandes(event_graph, src_indices)\n  File \"/tmp/ipykernel_3320/2494254184.py\", line -1, in betweenness_brandes\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n    frames.append(self.format_record(record))\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n    frame_info.lines, Colors, self.has_colors, lvals\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n    return self._sd.lines\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n    pieces = self.included_pieces\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n    pos = scope_pieces.index(self.executing_piece)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n    return only(\n  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n    raise NotOneValueFound('Expected one value, found 0')\nexecuting.executing.NotOneValueFound: Expected one value, found 0\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/temporal_graphs/","title":"Temporal Graphs","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[3]: Copied! <pre>import torch\nfrom torch_geometric.data import TemporalData\nimport pathpyG as pp\n\npp.config['torch']['device'] = 'cpu'\n</pre> import torch from torch_geometric.data import TemporalData import pathpyG as pp  pp.config['torch']['device'] = 'cpu' <p>We can create a temporal graph object from a list of time-stamped edges. Since TemporalGraph is a subclass of the <code>Graph</code> class, the inernal structures are very similar:</p> In\u00a0[2]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nprint(t.mapping)\nprint(t.N)\nprint(t.M)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) print(t.mapping) print(t.N) print(t.M) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n10\n</pre> <p>By default, all temporal graphs are directed. We can create an undirected version a temporal graph as follows:</p> In\u00a0[3]: Copied! <pre>x = t.to_undirected()\nprint(x.mapping)\nprint(x.N)\nprint(x.M)\n</pre> x = t.to_undirected() print(x.mapping) print(x.N) print(x.M) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n20\n</pre> <p>We can also create a temporal graph from an instance of <code>TemporalData</code></p> In\u00a0[4]: Copied! <pre>td = TemporalData(\n    src = torch.Tensor([0,1,2,0]),\n    dst = torch.Tensor([1,2,3,1]), \n    t = torch.Tensor([0,1,2,3]))\nprint(td)\nt2 = pp.TemporalGraph(td)\nprint(t2)\n</pre> td = TemporalData(     src = torch.Tensor([0,1,2,0]),     dst = torch.Tensor([1,2,3,1]),      t = torch.Tensor([0,1,2,3])) print(td) t2 = pp.TemporalGraph(td) print(t2) <pre>TemporalData(src=[4], dst=[4], t=[4])\nTemporal Graph with 4 nodes, 3 unique edges and 4 events in [0.0, 3.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 't', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> <p>We can restrict a temporal graph to a time window, which will return a temporal graph that only contains time-stamped edges in the given time interval.</p> In\u00a0[5]: Copied! <pre>t1 = t.get_window(0,4)\nprint(t1)\nprint(t1.start_time)\nprint(t1.end_time)\n</pre> t1 = t.get_window(0,4) print(t1) print(t1.start_time) print(t1.end_time) <pre>Temporal Graph with 3 nodes, 3 unique edges and 4 events in [1.0, 3.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\n1.0\n3.0\n</pre> <p>We can convert a temporal graph into a weighted time-aggregated static graph:</p> In\u00a0[6]: Copied! <pre>g = t.to_static_graph(weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(weighted=True) print(g) <pre>Undirected graph with 4 nodes and 6 (directed) edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>We can also aggregate the temporal graph in a given time window:</p> In\u00a0[7]: Copied! <pre>g = t.to_static_graph(time_window=(1, 3), weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(time_window=(1, 3), weighted=True) print(g) <pre>Directed graph with 2 nodes and 1 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Finally, we can perform a rolling window analysis:</p> In\u00a0[8]: Copied! <pre>r = pp.algorithms.RollingTimeWindow(t, 3, 1, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</pre> r = pp.algorithms.RollingTimeWindow(t, 3, 1, return_window=True) for g, w in r:     print('Time window ', w)     print(g)     print(g.data.edge_index)     print('---') <pre>Time window  (1.0, 4.0)\nDirected graph with 3 nodes and 3 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[0, 1, 1],\n           [1, 0, 2]], sparse_size=(3, 3), nnz=3, sort_order=row)\n---\nTime window  (2.0, 5.0)\nDirected graph with 4 nodes and 5 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[0, 1, 1, 2, 3],\n           [1, 0, 2, 1, 2]], sparse_size=(4, 4), nnz=5, sort_order=row)\n---\nTime window  (3.0, 6.0)\nUndirected graph with 4 nodes and 6 (directed) edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[0, 1, 1, 2, 2, 3],\n           [1, 0, 2, 1, 3, 2]], sparse_size=(4, 4), nnz=6, sort_order=row)\n---\nTime window  (4.0, 7.0)\nDirected graph with 4 nodes and 5 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[0, 1, 2, 2, 3],\n           [1, 0, 1, 3, 2]], sparse_size=(4, 4), nnz=5, sort_order=row)\n---\nTime window  (5.0, 8.0)\nDirected graph with 4 nodes and 3 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[1, 2, 2],\n           [0, 1, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\n---\nTime window  (6.0, 9.0)\nDirected graph with 3 nodes and 1 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[2],\n           [1]], sparse_size=(3, 3), nnz=1, sort_order=row)\n---\n</pre> <p>We can visualize a temporal graph by using the pathpyG plot function.</p> In\u00a0[11]: Copied! <pre>pp.plot(t, node_label=t.mapping.node_ids.tolist(), edge_color='lightgray');\n</pre> pp.plot(t, node_label=t.mapping.node_ids.tolist(), edge_color='lightgray'); <p>Consistent with <code>pyG</code> the sources, destinations and timestamps are stored as a <code>pyG TemporalData</code> object, which we can access in the following way.</p> In\u00a0[12]: Copied! <pre>t.data\n</pre> t.data Out[12]: <pre>TemporalData(src=[10], dst=[10], t=[10])</pre> In\u00a0[13]: Copied! <pre>print(t.data.t)\n</pre> print(t.data.t) <pre>tensor([1., 2., 3., 3., 4., 4., 4., 5., 5., 6.])\n</pre> <p>With the generator functions <code>edges</code> and <code>temporal_edges</code> we can iterate through the (temporal) edges of this graph.</p> In\u00a0[14]: Copied! <pre>for v, w in t.edges:\n    print(v, w)\n</pre> for v, w in t.edges:     print(v, w) <pre>a b\na b\nb a\nb c\nd c\na b\nc b\nc d\nb a\nc b\n</pre> In\u00a0[15]: Copied! <pre>for v, w, time in t.temporal_edges:\n    print(v, w, time)\n</pre> for v, w, time in t.temporal_edges:     print(v, w, time) <pre>a b 1.0\na b 2.0\nb a 3.0\nb c 3.0\nd c 4.0\na b 4.0\nc b 4.0\nc d 5.0\nb a 5.0\nc b 6.0\n</pre> <p>We are often interested in time-respecting paths in a temporal graph. A time-respecting path is defined as a sequence of nodes $v_0,...,v_l$ where the corresponding edges occur in the right temporal ordering and with a maximum time difference of $\\delta\\in \\N$.</p> <p>To calculate time-respecting paths in a temporal graph, we can construct a directed acyclic graph (DAG), where each time-stamped edge $(u,v;t)$ in the temporal graph is represented by a node and two nodes representing time-stamped edges $(u,v;t_1)$ and $(v,w;t_2)$ are connected by an edge iff $0 &lt; t_2-t_1 \\leq \\delta$.</p> <p>For the toy example above, we can construct such a DAG as follows:</p> In\u00a0[18]: Copied! <pre>e_i = pp.algorithms.lift_order_temporal(t, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\npp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]);\n</pre> e_i = pp.algorithms.lift_order_temporal(t, delta=1) dag = pp.Graph.from_edge_index(e_i) pp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 2968.02it/s]\n</pre> <p>For $\\delta=1$, this DAG with three connected components tells us that there are the following time-respecting paths:</p> <p>Length one: a -&gt; b b -&gt; a b -&gt; c c -&gt; b c -&gt; d d -&gt; c Length two: a -&gt; b -&gt; a (twice) b -&gt; a -&gt; b a -&gt; b -&gt; c b -&gt; c -&gt; b c -&gt; b -&gt; a d -&gt; c -&gt; d Length three: a -&gt; b -&gt; a -&gt; b b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b b -&gt; c -&gt; b -&gt; a Length four: a -&gt; b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b -&gt; a</p> <p>Based on this construction, we can can use the function <code>pp.algorithms.temporal.temporal_shortest_paths</code> to calculate shortest time-respecting path distances between any pair of nodes:</p> In\u00a0[1]: Copied! <pre>dist, pred = pp.algorithms.temporal.temporal_shortest_paths(t, delta=1)\nprint(t.mapping)\nprint(dist)\nprint(pred)\n</pre> dist, pred = pp.algorithms.temporal.temporal_shortest_paths(t, delta=1) print(t.mapping) print(dist) print(pred) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[1], line 1\n----&gt; 1 dist, pred = pp.algorithms.temporal.temporal_shortest_paths(t, delta=1)\n      2 print(t.mapping)\n      3 print(dist)\n\nNameError: name 'pp' is not defined</pre> <p>In the example above, we find that there is no time-respecting paths between the node pairs (a, d) and (b, d) and (d,a) and (d, b). The shortest temporal path from a to c requires two steps (a, b, c).</p> In\u00a0[12]: Copied! <pre>t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges')\nprint(t_ants)\n</pre> t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges') print(t_ants) <pre>Temporal Graph with 68 nodes, 506 unique edges and 1045 events in [899.0, 1796.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 't', 'src'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[14]: Copied! <pre>bw = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 5772.67it/s]</pre> <pre>{'JJJJ': 1399.0180458430464, 'WGG_': 1491.1753968253968, '_Y_B': 1461.7166666666667, 'HHHH': 996.0666666666666, 'WGRB': 1834.2047619047619, 'WYWY': 1540.441666666667, 'WY_G': 761.1371794871794, 'XXXX': 1670.8789682539682, 'LLLL': 1182.7095238095237, 'FFFF': 1062.2448773448773, 'WYG_': 1978.7333333333331, 'WW__': 1790.2027777777776, 'WRWB': 1743.196428571429, 'AAAA': 581.3047619047619, 'WGYW': 1155.8297619047619, 'WBYY': 968.8944444444444, '_R__': 880.7575396825396, 'WYBG': 1448.1039682539683, 'W__W': 1546.319877344877, 'RRRR': 924.1214285714285, 'WYRW': 1601.938095238095, 'WYYB': 865.6825396825396, 'WG_W': 1494.8178571428573, 'WRR_': 1195.2853174603176, 'W__G': 867.9182900432901, '_WRR': 622.8873015873016, 'WY_R': 1549.3750000000002, '_YYY': 1706.9047619047617, 'WRGG': 1571.4158730158733, 'WWGY': 1374.6964285714284, 'WW_W': 1325.6428571428573, 'W_W_': 842.7908730158728, 'WYYR': 798.6825396825395, 'ZZZZ': 662.777922077922, 'W_RG': 1339.8936507936507, 'WBGW': 512.55, 'WBGG': 1543.3130952380955, 'WWRY': 965.0658730158731, 'W___': 518.640909090909, 'VVVV': 394.82142857142856, 'WGGY': 402.0, 'WG__': 402.0, 'WY__': 1094.4130952380951, 'W_GY': 847.5990842490843, 'WYWW': 383.8191197691197, 'OOOO': 866.3738095238094, 'W_BG': 1306.0214285714287, 'TTTT': 549.4, 'WBWY': 1183.2944444444443, 'WWY_': 1060.354761904762, 'WBGR': 67.0, 'WGWY': 597.4166666666666, 'PPPP': 1146.8166666666664, 'WGGW': 917.4214285714285, 'EEEE': 617.1976190476189, '__YR': 134.0, 'WYYG': 548.8972582972583, 'WGGG': 207.70000000000002, 'IIII': 409.81666666666666, 'MMMM': 201.0, 'UUUU': 67.0, 'W_WG': 67.0, 'WYY_': 134.0, 'WWR_': 134.0, 'QQQQ': 415.4, 'WR__': 1117.5440476190474, 'W_GW': 167.5, 'AAAB': 0.0}\n</pre> <pre>\n</pre> In\u00a0[15]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=60)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=60) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 5538.98it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 55/55 [00:00&lt;00:00, 348.15it/s]</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7fd4a7c93c70&gt;, {'JJJJ': 50.92051282051282, 'WYWW': 1.4994192799070813, 'W__G': 55.36933797909406, '_WRR': 20.458333333333332, 'WWRY': 21.075854700854695, 'WG_W': 154.222521526766, 'WRGG': 267.4744198180881, 'WRWB': 195.86627165105418, 'WGG_': 61.6007326007326, 'RRRR': 54.96255407429851, 'WY__': 107.281573981574, 'WGRB': 397.84886221873427, 'WY_R': 250.93029554007833, 'ZZZZ': 54.500000000000014, '_YYY': 175.58314851213078, 'WYBG': 167.47651083270216, 'WW__': 225.30737327188945, 'XXXX': 58.953030303030324, 'WBGG': 76.43882783882785, 'WYG_': 218.45847326853644, 'WY_G': 29.700000000000014, 'WWY_': 26.64285714285714, '_Y_B': 343.45080062015313, 'WBWY': 74.31167045320274, 'HHHH': 88.56251085286847, 'WBYY': 78.04901433691755, 'WYWY': 65.63429027113239, 'WWGY': 328.63690030944605, 'W_W_': 25.5, 'WYRW': 125.62934300662208, 'WRR_': 81.62717938359506, 'WYYB': 70.91666666666666, 'WR__': 46.63333333333337, 'WBGW': 3.249999999999998, 'WGYW': 105.02746216189415, 'W_BG': 47.61310803891448, 'FFFF': 23.083333333333336, 'PPPP': 60.76573319153966, 'LLLL': 18.666666666666664, 'W_RG': 108.66428571428571, 'WYYR': 1.0, '_R__': 0.0, 'VVVV': 7.751515151515152, 'WGGG': 6.0, 'WG__': 38.99999999999999, 'AAAA': 0.0, 'W__W': 31.655275812911007, 'WGWY': 16.5, 'TTTT': 5.5, 'W___': 0.0, 'WGGY': 0.0, 'WYY_': -5.329070518200751e-15, 'WYYG': 0.0, 'W_WG': 0.0, 'AAAB': -8.881784197001252e-16})\n</pre> <pre>\n</pre> In\u00a0[5]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('../data/sociopatterns_highschool_2013_train.tedges')\nprint(t_sp)\n</pre> t_sp = pp.TemporalGraph.from_csv('../data/sociopatterns_highschool_2013_train.tedges') print(t_sp) <pre>Temporal Graph with 327 nodes, 8950 unique edges and 220378 events in [1385982080.0, 1386163840.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\n</pre> In\u00a0[10]: Copied! <pre>cl = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, delta=90)\nprint(cl)\n</pre> cl = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, delta=90) print(cl) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 579/579 [00:03&lt;00:00, 167.64it/s]\n</pre> <pre>{'454': 22690.26419940238, '640': 21396.136714269804, '1': 15421.540528091504, '939': 23218.083996701414, '185': 27744.815221413228, '258': 21970.263456780838, '55': 21985.766420238342, '170': 23982.576177643135, '9': 33523.14360306114, '453': 18601.595519730585, '45': 27901.334448517846, '14': 23718.652080802105, '190': 27774.70783422404, '400': 17089.97873264854, '637': 18198.998446119855, '255': 18985.709666701398, '275': 31777.652758877666, '176': 33498.07952616532, '533': 18892.149168554122, '116': 20568.19966298135, '151': 23773.0285140761, '866': 28703.609060263272, '280': 18778.269876663893, '484': 15282.17875464034, '243': 19553.83265237137, '687': 23883.627455526406, '54': 21335.61491662764, '364': 24236.42325739979, '374': 21533.12260643561, '295': 14430.1819302061, '441': 23369.877668030073, '101': 20332.38422421196, '425': 15558.391311535783, '47': 12850.704361104616, '241': 20198.491393795914, '179': 30765.953255778506, '202': 28259.002256771513, '63': 24227.702659344523, '564': 16733.66986050994, '577': 12072.16805730113, '265': 20134.62899854375, '494': 22267.016046316618, '443': 22971.005275161933, '209': 13726.632043549154, '843': 24568.610925257315, '222': 8170.856489289551, '205': 25095.554369798017, '894': 22967.436116211262, '1359': 34582.526180463574, '1383': 17158.40797603275, '376': 31185.712798928955, '638': 24113.651324921673, '1238': 15604.201430629431, '1260': 16681.98363841811, '487': 25015.220384966713, '984': 22252.147353184944, '226': 21827.007152451653, '353': 24727.618417139453, '1342': 23519.8734523387, '1518': 38406.76506206502, '122': 23727.202213365315, '1067': 20168.054523556475, '1324': 21557.129562411115, '70': 21579.725381943044, '132': 20250.779095687718, '779': 22274.400334007998, '279': 22984.13642975447, '908': 14810.626629181537, '510': 14048.880404536083, '545': 23847.16584865145, '634': 31405.563427362318, '1332': 35661.07635769562, '1401': 34190.93181481814, '582': 20654.854698866293, '605': 30705.94855304445, '252': 23852.22711633762, '3': 22680.120265450372, '884': 23951.385210739238, '339': 18621.277648375966, '691': 25308.327883058933, '869': 26202.561974864904, '72': 29004.478647789503, '954': 22539.44147232855, '160': 19890.680730622065, '117': 25562.554113829145, '346': 19439.25885558378, '111': 22511.354647863558, '124': 18848.939348503194, '276': 21888.990132402832, '621': 20408.23560440241, '39': 18747.00842340271, '871': 23049.318166973913, '694': 28313.209776754942, '778': 28565.194988908966, '513': 20123.648003070488, '236': 14335.211614321852, '883': 20302.865536681053, '1594': 30408.008768723463, '1828': 26726.063244292116, '1214': 28101.26221608126, '196': 27842.691852948705, '201': 26260.683134415125, '245': 30455.04931566171, '390': 28073.27534739718, '938': 24234.270527427354, '923': 19200.37790768787, '106': 37152.22975185675, '272': 38552.36089155283, '753': 21921.98064195561, '486': 15789.125434408757, '531': 18798.271316057326, '254': 31968.227938990523, '382': 28100.529362961515, '119': 21000.69917319896, '240': 18928.343666537377, '447': 20968.827732279686, '649': 19811.079059189036, '1204': 22878.42444016237, '466': 16170.676091620004, '841': 13897.299293783932, '199': 23383.30537823107, '674': 24470.69848014939, '857': 12533.371957138908, '945': 20212.057383272335, '1218': 24631.373828668537, '1512': 33593.56260276317, '653': 27811.58138813321, '502': 22533.82435058389, '587': 13745.76918099567, '626': 21941.482855930197, '420': 28498.06046512984, '504': 20663.202053853365, '311': 16227.322073582376, '267': 23351.99007819387, '177': 25961.609333603672, '480': 18789.964797070068, '771': 7373.39804796181, '312': 25472.974454599593, '612': 25050.02672973233, '450': 14110.929400386112, '89': 27941.292267115652, '322': 27548.778177545984, '520': 12516.181621486086, '15': 23389.364875391082, '211': 26190.603531424804, '366': 16705.013700257874, '227': 16508.471575538748, '440': 21553.337850807304, '41': 26369.132103427193, '388': 23085.60804844294, '219': 18793.11692583366, '658': 26625.656627429733, '220': 22919.62313724787, '576': 14864.251994764518, '642': 26872.367685606223, '391': 15318.122737189069, '777': 13354.284938168868, '20': 19326.08013557887, '958': 29456.47728893543, '103': 13095.94658820367, '61': 28445.772777546295, '274': 18089.384408586964, '147': 29399.244158610407, '277': 15469.416450673745, '702': 9499.652981158964, '242': 22001.687705639895, '38': 33179.75726526479, '438': 16062.835995175008, '387': 20895.257037892257, '1295': 30818.037290393968, '1412': 33802.884360711134, '492': 29025.513518833704, '1345': 31898.110138892276, '1212': 30761.71630622066, '28': 23717.75815072594, '327': 26372.377598671137, '1216': 32725.046332855152, '372': 34156.92298777491, '720': 28803.498432296536, '1784': 17951.832234123216, '27': 26276.927606941885, '171': 10379.486578501532, '1336': 23753.080773673668, '1423': 34196.04622804029, '1366': 16814.668682542313, '407': 26504.310267067216, '1320': 27547.036040700106, '1805': 31390.857141258464, '1237': 19735.285359200654, '974': 12977.46636758578, '464': 26526.73581513861, '477': 17618.948598926967, '763': 12377.179151240925, '1894': 26362.8235606891, '1201': 22534.629164073573, '1228': 31163.40871276972, '786': 12063.095870133595, '886': 22263.30324855864, '797': 26984.216357626192, '959': 11680.69410938021, '1485': 20778.45042045299, '210': 28741.518412760062, '4': 20151.217089031805, '790': 9201.362356210757, '285': 29653.20019304286, '544': 21413.787363014242, '333': 27442.273561253816, '622': 13869.574960610813, '429': 21867.697488884394, '46': 12728.234082916997, '343': 17874.839735522633, '867': 15421.510026763033, '615': 20974.68458622242, '977': 8517.367934576734, '90': 18585.505252424075, '269': 23043.70954430846, '603': 26330.60115647402, '335': 26132.18027578375, '765': 23531.3033489879, '257': 22395.111118472985, '268': 14027.690680301115, '214': 14818.222965670528, '491': 20825.4996965497, '181': 17730.448619209692, '650': 16930.70201055695, '85': 24000.38503411982, '325': 21338.669502299555, '941': 12276.214871405815, '356': 23527.87939746848, '744': 17361.761518664054, '1543': 26365.169947279206, '145': 21301.83181356518, '173': 21101.989766047038, '909': 13077.037497184303, '79': 28261.946551441513, '854': 14680.153278717122, '527': 20107.068845766324, '475': 12193.591094250865, '471': 20234.617579629095, '681': 6204.174355954503, '465': 14568.791279274072, '446': 9324.129220779221, '58': 30978.594173286536, '32': 13013.57238443117, '991': 22084.932955997334, '725': 18801.37346411425, '859': 19245.588391861784, '798': 18473.646942088333, '256': 25189.270248923087, '306': 13068.417731984744, '131': 19323.264114442347, '677': 19838.228729324037, '960': 8182.224702911468, '769': 15912.221808055812, '248': 14377.319902551477, '125': 19005.464245428288, '917': 9529.174795009667, '120': 23879.902960985415, '115': 26843.352031395363, '1519': 16453.731840924658, '970': 16502.35824278918, '213': 27014.453274446245, '424': 24096.15161198883, '428': 17568.012641494108, '488': 22638.599559905004, '498': 19332.176697372608, '809': 16731.62938107644, '92': 26802.01263359099, '845': 20977.794842195013, '655': 16291.41434446168, '156': 23986.220103065745, '413': 18101.904527312247, '21': 17734.928555394326, '1232': 18095.076953227926, '290': 22891.62694165392, '71': 22128.396973167757, '65': 20516.721425844942, '791': 11850.23982665058, '874': 14389.756835911232, '448': 19441.49207827185, '496': 29133.797199432614, '921': 15127.17744149044, '497': 14489.499511553959, '627': 10402.331378722065, '194': 21983.506607768137, '927': 21543.989850556783, '232': 27061.708223017755, '172': 20873.719019616536, '165': 3799.9942981173353, '87': 22450.463443686553, '253': 17766.883871678365, '706': 23725.101108242066, '134': 28548.665551123846, '624': 15519.762468190096, '548': 17146.71619289334, '893': 22443.360933511954, '920': 16480.752405869483, '836': 22476.384503653877, '80': 20050.060040338765, '743': 17551.815592853512, '826': 20851.783068912428, '184': 28270.85109884974, '601': 22704.59903203392, '1870': 13864.178331355017, '200': 22668.70389869951, '784': 12400.59729695147, '751': 7717.845352951413, '434': 3396.093101179865, '979': 13253.363759550157, '647': 10072.21581196581, '246': 14714.820395776693, '489': 17603.6706663395, '998': 22904.629430679994, '435': 15753.590691395675, '468': 7655.271353279834, '48': 20420.84673883565, '1339': 16531.1898013574, '159': 14149.119125168701, '149': 4376.754719622543, '1819': 18580.214650136513, '525': 16782.458750062207, '882': 7988.447957308183, '34': 21248.861107353576, '239': 9620.189603621862, '62': 3372.041919191919, '452': 19073.24167977211, '445': 4255.959491619492}\n</pre> In\u00a0[11]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=90)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=90) print(bw) <pre>  0%|          | 0/579 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 579/579 [00:02&lt;00:00, 207.42it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 327/327 [03:17&lt;00:00,  1.66it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7fd49f4e9510&gt;, {'454': 901.3632876040907, '285': 5877.071936319818, '120': 2174.55413009379, '424': 1093.2201683232392, '634': 3308.820637737278, '34': 360.37810544837, '38': 4312.235518490112, '869': 2924.858932976775, '372': 4860.795860588745, '55': 2386.5812133395143, '531': 800.1915582159259, '527': 1158.995039552147, '205': 2090.724814056637, '691': 2853.4378004474584, '1412': 67215.86398733474, '626': 543.062856704483, '720': 4146.660218757529, '272': 7164.7978277142065, '1295': 9781.702522310827, '706': 3118.5365037411198, '1345': 4729.245691033162, '106': 5608.7931444889355, '202': 5407.793515203525, '1332': 16043.349747193608, '1594': 7381.9226465172, '545': 3254.6223382115177, '1894': 1180.5655918022442, '1214': 5120.690165284648, '1519': 164.795955138651, '1237': 1637.6888499130098, '1336': 959.7276139682115, '1828': 8045.97172317332, '1212': 7307.018669406073, '1342': 10471.886656646548, '1805': 7648.526021827979, '1512': 13665.566220335613, '1216': 16233.25571798679, '1339': 2712.129280947571, '1401': 106112.56868624466, '1218': 584.5755937222589, '1423': 3355.988659976046, '1228': 21581.901813550463, '1543': 13954.947799329271, '1784': 301.8398657968867, '1819': 1647.1862407906203, '376': 3276.544129893187, '79': 6131.707390950843, '45': 5950.549659592378, '884': 8817.447636448444, '3': 3727.323176955621, '147': 2747.313653599328, '339': 6194.552905651147, '1201': 5445.6553509366395, '1518': 46485.01732423453, '1359': 42288.63081929835, '1366': 13.14741907071427, '1204': 10643.699773120836, '1324': 13381.773891317493, '1067': 15468.90802501343, '1260': 244.44397762663831, '1238': 701.7040291986609, '41': 380.02082811892757, '612': 33722.77660308658, '312': 37832.52406826749, '239': 732.7290635120661, '908': 2538.657901665586, '777': 690.6278530099146, '603': 33674.662888940475, '269': 14442.32739828392, '544': 579.0562130913598, '61': 8369.333401117654, '258': 20380.100091307362, '279': 32281.5924500491, '236': 560.5068188495386, '510': 68.44525924218365, '866': 3089.7867845941355, '151': 4404.148784664264, '54': 528.8951028751809, '210': 6050.207548874832, '448': 728.7518219568016, '492': 3600.913239820995, '92': 4688.112781975971, '9': 6093.65120340509, '496': 3640.456776861306, '71': 1044.8322659730538, '441': 905.0403872721282, '1383': 22714.31357050798, '658': 1080.266552389167, '453': 131.09879749972995, '28': 958.6391635786727, '257': 870.547681904744, '226': 1089.840675998125, '429': 948.1734045306143, '327': 1865.719559102765, '173': 2986.185724887092, '27': 6725.908398700822, '605': 1635.856770091294, '388': 929.8966558086031, '452': 2303.205939278833, '420': 1808.1972941745196, '407': 799.1450715028095, '246': 158.51369100600735, '484': 1139.6610689068275, '159': 168.698036712492, '335': 2487.1680072503964, '765': 1121.5318082701856, '390': 4630.705793962693, '90': 2392.676019705626, '391': 262.80748044698123, '280': 1611.8401227694867, '219': 353.0949333570949, '687': 675.9438286107246, '502': 491.74346889631676, '874': 245.5477408064799, '254': 6223.767164346377, '938': 3892.91337911467, '382': 3169.318085713774, '1320': 1462.021620273301, '295': 95.20753296187073, '1870': 63.12311889715693, '615': 1105.1400947463208, '440': 2183.8129134766946, '491': 1567.1345221018112, '333': 1970.9127088609903, '513': 1993.947356917777, '497': 419.64347155361867, '642': 1086.6830838485816, '220': 158.93351884010735, '201': 2068.1576935458597, '245': 2738.5722751926537, '836': 1165.033915230509, '85': 1879.6366334693819, '256': 955.0804899897935, '356': 3303.72732735017, '213': 3304.4339037096784, '14': 120.72882644931907, '923': 277.6597132760671, '116': 1817.9943312418325, '58': 4343.677852274914, '190': 990.2060469736655, '115': 4839.9240137048255, '176': 5672.815238036185, '267': 1391.0251038722836, '343': 339.61655378245337, '638': 4783.3327390149425, '435': 1147.2813241981778, '753': 196.92679327907825, '564': 30.566310115134574, '387': 1543.3154067091714, '438': 59.06072276643295, '277': 360.13170651009057, '744': 93.07583164433942, '548': 98.99705793906095, '185': 2337.7683348813516, '445': 14.514285714285686, '621': 71.10638733009861, '211': 5350.769352939446, '131': 719.0692132054506, '156': 527.4909970602919, '274': 749.321138811597, '134': 2427.930467934984, '464': 6690.2299789270655, '979': 10.215596330275778, '171': 599.7080283011186, '20': 666.3713700792867, '958': 5696.750336443307, '843': 164.98204397665003, '640': 733.297562695162, '1232': 292.14499616274253, '184': 1784.8687528339283, '504': 627.5570196308519, '582': 666.6354459868478, '694': 1989.1798574735524, '290': 762.2800600280018, '103': 1707.9594573008853, '243': 621.6160378927967, '525': 107.96946000983154, '1485': 101.13043580058338, '577': 109.27165983558247, '974': 459.53888988561465, '576': 143.53911239964359, '520': 129.7432479171051, '268': 516.8076856244423, '353': 1309.368729000263, '778': 1879.5431732606387, '653': 2493.008786780829, '170': 9281.326472789746, '275': 74257.7151961632, '649': 647.4683084083141, '255': 11605.125973061344, '122': 13205.864401748453, '117': 14700.008384651572, '779': 2381.1769949691547, '199': 1295.876249757412, '364': 12516.274156708876, '346': 915.6375533527943, '252': 3603.708579015659, '374': 2253.4877967310917, '119': 4704.006383254128, '240': 1188.1618801711413, '939': 1443.8113618868767, '425': 2252.6531711426783, '160': 942.7795907967848, '101': 3822.7552502942194, '428': 317.981901968164, '124': 597.2319195924663, '945': 355.30127871284077, '196': 6414.432230873087, '179': 5049.941463962091, '65': 1772.0156392745268, '145': 286.6113186594323, '400': 197.05008345971024, '650': 227.5439431660831, '487': 5111.174158048541, '177': 4260.075439541468, '984': 815.0051388249746, '725': 509.984850534047, '232': 8302.262275106037, '200': 5103.757948141252, '322': 10168.426940260433, '674': 2354.3970971077297, '466': 296.3459778991891, '677': 1713.9138134183484, '927': 696.4081858908828, '111': 911.0533695774541, '859': 534.042611924224, '845': 1284.4458043147997, '702': 232.33236630254254, '443': 627.3225993659227, '480': 183.69418512137977, '15': 699.9821947968517, '366': 280.82636265725915, '89': 6988.731370685156, '601': 1255.9863001221877, '253': 823.5987154726757, '743': 721.9509694941149, '242': 4087.609377810885, '194': 810.8703174060474, '413': 296.71733130445006, '494': 2659.438586904259, '1': 4977.118613133385, '311': 177.21648271735748, '80': 514.2490163805104, '172': 97.82902395243838, '488': 4085.263005930968, '450': 76.73972129059894, '87': 1128.3095570355142, '826': 3454.113370089976, '894': 6228.78989954139, '276': 1563.1492061826261, '222': 12.209318570195315, '867': 20.983690200115493, '63': 1264.026092031634, '771': 394.42962090196454, '39': 220.9677339985339, '871': 4050.6488864522858, '533': 253.04949562855788, '209': 3.8164335664326665, '655': 1304.2899121473943, '791': 18.115196797773688, '21': 2384.254711339013, '214': 4487.103676437252, '921': 83.29490314054642, '4': 2633.0059354664554, '786': 90.69358049065842, '306': 486.2668300113935, '790': 132.94736842105334, '886': 41735.81387215186, '447': 2525.9406870438465, '909': 43.08333333333332, '622': 88.55256227972325, '893': 1030.363737642025, '465': 96.56470517594234, '854': 159.20988431408765, '954': 1416.8673097512178, '991': 2733.261011223048, '477': 57.5527487160646, '797': 4425.468623567981, '959': 40.52809798431737, '72': 2849.526574757924, '325': 504.2342594584995, '70': 1376.6456361374453, '883': 1397.1341616776504, '475': 66.8700022580155, '970': 663.1876483110456, '471': 1295.4271302745137, '587': 461.050099388055, '489': 103.60175561826128, '46': 30.86552825855979, '32': 228.89036847132334, '763': 14.658346393278597, '265': 505.0563758429172, '132': 1296.8921304627027, '48': 3550.48943984021, '227': 886.457452490603, '784': 45.632757654269945, '998': 100.32663237623697, '624': 352.2288742582881, '486': 13.509687074834197, '920': 1706.4126335513656, '798': 304.9179412088871, '769': 448.87375360327013, '125': 245.66717583533637, '241': 1411.3318580741266, '248': 46.499601850748164, '47': 8.500000000000012, '468': 10.846037606069629, '181': 679.649123656061, '627': 28.898186769276023, '882': 1.5546285815395322, '941': 203.14602762120958, '857': 13.750034614543829, '637': 42.89478239767777, '751': 11.342634298009001, '446': 31.733333333333327, '647': 235.34909787705328, '809': 1825.3884546207296, '62': 2.129032258064516, '498': 98.26497859565754, '977': 23.541360448855436, '841': 74.65332404608262, '149': 46.44213745897716, '960': 0.9999999999999859, '681': 2.914335439641036e-15, '165': -1.4210854715202004e-14, '917': 1.9999999999996874, '434': 0.0})\n</pre> In\u00a0[32]: Copied! <pre>\n</pre> <pre>Undirected graph with 4 nodes and 6 (directed) edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 6 nodes and 6 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 6 nodes and 4 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[33]: Copied! <pre>pp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes])\n</pre> pp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes]) Out[33]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fb838a93490&gt;</pre> In\u00a0[34]: Copied! <pre>pp.plot(m.layers[2], node_label=[v for v in m.layers[2].nodes])\n</pre> pp.plot(m.layers[2], node_label=[v for v in m.layers[2].nodes]) Out[34]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fb838a92410&gt;</pre> In\u00a0[37]: Copied! <pre>pp.plot(m.layers[3], node_label=[v for v in m.layers[3].nodes])\n</pre> pp.plot(m.layers[3], node_label=[v for v in m.layers[3].nodes]) Out[37]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fb83807d930&gt;</pre> In\u00a0[39]: Copied! <pre>pp.plot(m.layers[4], node_label=[v for v in m.layers[4].nodes]);\n</pre> pp.plot(m.layers[4], node_label=[v for v in m.layers[4].nodes]); <p>We can read temporal graphs from CSV files that contain the source, target, and time-stamps of edges in each line:</p> In\u00a0[55]: Copied! <pre>t = pp.TemporalGraph.from_csv('../data/ants_1_1.tedges')\nprint(t)\n</pre> t = pp.TemporalGraph.from_csv('../data/ants_1_1.tedges') print(t) <pre>Temporal Graph with 89 nodes, 947 unique edges and 1911 events in [0.0, 1438.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 't', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[52]: Copied! <pre>paths = pp.algorithms.temporal_shortest_paths(t, delta=30)\n</pre> paths = pp.algorithms.temporal_shortest_paths(t, delta=30) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:01&lt;00:00, 619.46it/s]\n</pre> In\u00a0[58]: Copied! <pre>bw = pp.algorithms.centrality.temporal_closeness_centrality(t, delta=30)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_closeness_centrality(t, delta=30) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 6108.69it/s]\n</pre> <pre>{'Y_WY': 2789.0803418803416, 'WRBB': 2785.9333333333334, 'WRR_': 1081.142857142857, 'GGRR': 2852.965481577247, 'WG_R': 3049.515262515263, 'YWGW': 1545.3777777777777, 'YYGG': 2394.542857142857, 'GBGR': 1414.4860805860799, 'GRWG': 2171.3650793650795, 'YY_W': 2014.3365297301218, 'G_W_': 1371.3907285811308, 'G___small': 557.3333333333333, 'YW__': 176.0, 'YYGGmid': 3332.9682539682535, '____brood': 1977.3765567765563, 'GGWY': 3453.2349206349204, 'G_R_': 1433.5575091575088, '____topleft': 2165.771184371184, 'G_GW': 2422.661330173096, 'GYYY': 718.2158730158731, 'WBGW': 1971.4003597425594, 'Y__W': 982.6666666666667, 'YYYY': 413.6, 'GWRG': 1933.1047619047617, 'YGWW': 3152.5114774114777, 'WRWR': 2211.0761904761907, 'G___big': 352.0, 'GY__': 848.6708180708182, 'WRRY': 2440.7111111111117, 'GR_Y': 293.3333333333333, 'YWW_': 1767.2394383394376, '_W__': 2656.585103785103, '__W_': 1944.5428571428565, 'WBYG': 1343.583516483516, 'YGWY': 1660.7412698412697, '_R__': 2997.5174603174605, '____pale': 3136.1523809523806, 'WGBB': 2144.4600732600734, 'GR__': 1512.5449625320214, 'YYWR': 1731.1409394527036, '____bot': 1001.3499155127638, 'GR_Y2': 3175.9269841269834, '_WGG': 1958.2253968253958, 'W___': 1929.4289736407375, 'YWWW': 398.93333333333334, 'YYRB': 1740.7172161172157, '_WWY': 2212.292063492063, 'WGGB': 2359.0984126984126, 'Q': 2621.7873015873024, 'GRGY': 1126.5599870717517, '____corner': 2253.777777777778, 'YYRG': 1095.7428571428572, 'GGW_': 2330.4800976800975, 'GYGG': 1530.629914529915, '_Y__': 1652.9277938435825, 'WGWB': 2534.8727716727713, '__BB': 1730.7680868838759, '____bm': 1064.8000000000002, 'YY__': 1689.1285211520506, 'GRBR': 1754.9898656898652, '_WWW': 1424.7478182636075, '_WYG': 1981.0838827838822, 'GG_W': 2184.193650793651, 'WR__': 934.9978021978022, 'YY_R': 2112.4549450549443, 'GGGR': 1742.8245689638877, 'GRYY': 1162.6810654086196, 'GGWW': 1534.1047619047617, '_WYW': 2915.5587301587298, 'YYGGright': 1983.2628815628814, '____right': 1480.7504026477104, 'GBGW': 1504.3851037851034, 'WYGG': 1790.5627772296498, 'Y___': 1197.9579525737417, 'YYY_': 704.0, 'WBGG': 1990.8162393162388, 'RWGY': 1701.3416720534362, '____almost': 1693.4599061756958, '_W_Y': 1587.0571284924222, 'GGYW': 1470.0100840336133, 'G___': 1729.8146416766558, '____topright': 1286.647380665226, 'GGRY': 1905.4073260073255, 'RWWG': 1497.9301456145445, '_RYG': 504.5015873015874, 'GGGG': 1307.263478947878, 'WWBG': 1092.6931017786453, 'YYGW': 2237.888888888889, 'GBG_': 1410.0712202829845}\n</pre> In\u00a0[59]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t, delta=30)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t, delta=30) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 5972.88it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 86/86 [00:00&lt;00:00, 288.95it/s]</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7fb86ad1ac20&gt;, {'Y_WY': 66.65000000000002, 'WRR_': 16.03571428571428, 'YGWW': 283.3939578478873, 'GGRR': 211.63928571428573, 'YWGW': 6.216666666666667, 'G_GW': 134.36212121212122, 'WG_R': 168.975250954719, 'YYRB': 169.60544909428017, 'GGWY': 1718.7165771554303, '____topleft': 55.833333333333336, 'YYGGmid': 150.59735449735444, 'WGGB': 493.10410618997815, '____corner': 73.68974206371455, 'YGWY': 80.06904761904762, 'GRWG': 297.3740605276305, '____bm': 32.72777777777777, 'G_R_': 72.95192620574925, 'GR_Y2': 789.1940156557653, 'WRBB': 305.85885874100165, '_W__': 81.93484848484847, '____pale': 1073.2734366837544, 'GR__': 56.99999999999999, 'GBG_': 281.5697318519009, 'GGW_': 566.394057706365, 'WBGG': 63.72222222222224, 'GGYW': 279.5543513957306, 'YYGW': 384.16915498294793, 'GRBR': 39.28333333333333, '_WYG': 154.75528281105835, 'WGWB': 709.6708463026312, 'GGRY': 436.8124589931511, 'W___': 25.635235103124238, '____right': 30.103663003663005, '__BB': 138.19613162299913, '_Y__': 147.16903444757997, '_WGG': 101.30372156909563, 'YYWR': 47.6098615332658, '____bot': 2.0, 'WBYG': 33.38144208037825, 'GG_W': 107.11576914023713, 'Q': 904.6767045461904, 'WRRY': 107.51936464672677, 'WYGG': 385.1114573090895, '____brood': 150.27813394335135, '_WYW': 835.2570820688013, '_R__': 609.6647506098733, '__W_': 66.65154738334509, '_WWY': 217.07608701685595, '_W_Y': 520.625, 'GBGW': 81.1450354609929, 'GBGR': 119.01949427664658, 'YY_R': 200.38014858937927, 'GGGG': 200.21429898610748, 'WBGW': 25.363559608240447, 'YWW_': 8.200000000000001, 'RWWG': 139.95452637739874, '____almost': 111.97335462899981, 'YYGG': 541.2239759619857, 'WRWR': 3.506755634419301, 'G_W_': 22.333333333333332, 'WGBB': 247.32307692307694, 'GWRG': 128.73138863630572, 'Y__W': 0.0, 'YY__': 166.20315481894167, '_WWW': 171.763197511, 'GYGG': 84.68378103378103, 'GRGY': 10.257082909008458, 'G___': 103.18272382540675, 'YYGGright': 377.3777533153582, 'RWGY': 164.463475221252, 'GGWW': 342.99788730570526, 'YY_W': 86.65538322985128, 'YYY_': 5.75, 'GRYY': 77.95139793084198, 'GR_Y': -9.900299794654632, 'G___small': 0.9999999999999989, 'G___big': -2.220446049250313e-16, 'GY__': 4.000000000000001, 'WWBG': 20.212121212121207, '____topright': -18.584859584859586, 'YYYY': 0.0, 'YWWW': -23.492217906522352, 'YYRG': 9.920634920634928, 'GGGR': 16.266666666666666, 'Y___': 19.65343915343914, 'WR__': -7.402116402116404})\n</pre> <pre>\n</pre> In\u00a0[60]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=30, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=30, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 89 nodes and 947 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([89, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 947 nodes and 1780 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 1780 nodes and 2410 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 2410 nodes and 3292 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3292])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[43]: Copied! <pre>t = pp.TemporalGraph.from_csv('../data/manufacturing_email.tedges')\nprint(t)\n</pre> t = pp.TemporalGraph.from_csv('../data/manufacturing_email.tedges') print(t) <pre>Temporal Graph with 167 nodes, 5784 unique edges and 82927 events in [1262454016.0, 1285884544.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([82927])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([82927])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([82927])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 't', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[49]: Copied! <pre>dist, pred = pp.algorithms.temporal.temporal_shortest_paths(t, delta=240)\n</pre> dist, pred = pp.algorithms.temporal.temporal_shortest_paths(t, delta=240) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30598/30598 [00:33&lt;00:00, 909.07it/s] \n</pre> In\u00a0[50]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=240, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=240, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 167 nodes and 5784 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([167, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 5784 nodes and 3542 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3542])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 3542 nodes and 812 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3542, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([812])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 812 nodes and 156 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([812, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([156])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre>"},{"location":"tutorial/temporal_graphs/#temporal-graph-analysis","title":"Temporal Graph Analysis\u00b6","text":""},{"location":"tutorial/temporal_graphs/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/temporal_graphs/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In this tutorial we will introduce the representation of temporal graph data in the <code>Temporal Graph</code> class and how such data can be used to calculate time respecting paths.</p>"},{"location":"tutorial/temporal_graphs/#extracting-time-respecting-paths-in-temporal-networks","title":"Extracting Time-Respecting Paths in Temporal Networks\u00b6","text":""},{"location":"tutorial/temporal_graphs/#temporal-centralities-in-empirical-temporal-networks","title":"Temporal Centralities in Empirical Temporal Networks\u00b6","text":""},{"location":"tutorial/temporal_graphs/#higher-order-de-bruijn-graph-models-for-time-respecting-paths","title":"Higher-Order De Bruijn Graph Models for Time-Respecting Paths\u00b6","text":""},{"location":"tutorial/temporal_graphs/#analysis-of-empirical-temporal-graphs","title":"Analysis of empirical temporal graphs\u00b6","text":""},{"location":"tutorial/temporal_shortest_paths/","title":"Temporal shortest paths","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\nimport torch\n\nfrom scipy.sparse.csgraph import bellman_ford, dijkstra\nimport numpy as np\n\nfrom collections import defaultdict\n\n\nfrom tqdm import tqdm\n</pre> import pathpyG as pp from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index import torch  from scipy.sparse.csgraph import bellman_ford, dijkstra import numpy as np  from collections import defaultdict   from tqdm import tqdm In\u00a0[2]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected()\nprint(t_sp)\nprint(torch.unique(t_sp.data.t).size(0))\n</pre> t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected() print(t_sp) print(torch.unique(t_sp.data.t).size(0)) <pre>Temporal Graph with 327 nodes, 11636 unique edges and 377016 events in [1385982080.0, 1386345600.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\n1157\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 't', 'src'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[2]: Copied! <pre>t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges')\nprint(t_ants)\n</pre> t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges') print(t_ants) <pre>Temporal Graph with 68 nodes, 506 unique edges and 1045 events in [899.0, 1796.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 't', 'src'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[3]: Copied! <pre>c = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60)\nprint(c)\n</pre> c = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 5479.47it/s]</pre> <pre>Created temporal event DAG with 1181 nodes and 4023 edges\n[[ 0.  1. inf ... inf inf inf]\n [ 1.  0. inf ... inf inf inf]\n [ 5.  3.  0. ...  2. inf inf]\n ...\n [inf inf inf ...  0. inf inf]\n [inf inf inf ... inf  0. inf]\n [inf inf inf ...  1. inf  0.]]\n{'JJJJ': 1399.0180458430464, 'WGG_': 1491.1753968253968, '_Y_B': 1461.7166666666667, 'HHHH': 996.0666666666666, 'WGRB': 1834.2047619047619, 'WYWY': 1540.441666666667, 'WY_G': 761.1371794871794, 'XXXX': 1670.8789682539682, 'LLLL': 1182.7095238095237, 'FFFF': 1062.2448773448773, 'WYG_': 1978.7333333333331, 'WW__': 1790.2027777777776, 'WRWB': 1743.196428571429, 'AAAA': 581.3047619047619, 'WGYW': 1155.8297619047619, 'WBYY': 968.8944444444444, '_R__': 880.7575396825396, 'WYBG': 1448.1039682539683, 'W__W': 1546.319877344877, 'RRRR': 924.1214285714285, 'WYRW': 1601.938095238095, 'WYYB': 865.6825396825396, 'WG_W': 1494.8178571428573, 'WRR_': 1195.2853174603176, 'W__G': 867.9182900432901, '_WRR': 622.8873015873016, 'WY_R': 1549.3750000000002, '_YYY': 1706.9047619047617, 'WRGG': 1571.4158730158733, 'WWGY': 1374.6964285714284, 'WW_W': 1325.6428571428573, 'W_W_': 842.7908730158728, 'WYYR': 798.6825396825395, 'ZZZZ': 662.777922077922, 'W_RG': 1339.8936507936507, 'WBGW': 512.55, 'WBGG': 1543.3130952380955, 'WWRY': 965.0658730158731, 'W___': 518.640909090909, 'VVVV': 394.82142857142856, 'WGGY': 402.0, 'WG__': 402.0, 'WY__': 1094.4130952380951, 'W_GY': 847.5990842490843, 'WYWW': 383.8191197691197, 'OOOO': 866.3738095238094, 'W_BG': 1306.0214285714287, 'TTTT': 549.4, 'WBWY': 1183.2944444444443, 'WWY_': 1060.354761904762, 'WBGR': 67.0, 'WGWY': 597.4166666666666, 'PPPP': 1146.8166666666664, 'WGGW': 917.4214285714285, 'EEEE': 617.1976190476189, '__YR': 134.0, 'WYYG': 548.8972582972583, 'WGGG': 207.70000000000002, 'IIII': 409.81666666666666, 'MMMM': 201.0, 'UUUU': 67.0, 'W_WG': 67.0, 'WYY_': 134.0, 'WWR_': 134.0, 'QQQQ': 415.4, 'WR__': 1117.5440476190474, 'W_GW': 167.5, 'AAAB': 0.0}\n</pre> <pre>\n</pre> In\u00a0[47]: Copied! <pre>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nc = pp.algorithms.centrality.temporal_closeness_centrality(t, 5)\nprint(c)\n</pre> tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),               ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),               ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),               ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),               ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)] t = pp.TemporalGraph.from_edge_list(tedges) c = pp.algorithms.centrality.temporal_closeness_centrality(t, 5) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 5773.07it/s]</pre> <pre>Created temporal event DAG with 38 nodes and 47 edges\n(9, 38)\n(9, 9)\n[[ 0.  1.  1.  3.  3. inf  1.  2. inf]\n [inf  0.  1.  2.  2.  1. inf inf  1.]\n [ 2. inf  0.  1.  1.  1.  3.  1.  1.]\n [inf inf inf  0. inf inf inf inf inf]\n [inf inf inf inf  0. inf inf inf inf]\n [ 1. inf inf inf inf  0.  2.  1. inf]\n [inf inf inf inf inf inf  0.  1. inf]\n [inf inf inf inf inf  1. inf  0.  1.]\n [inf  1. inf inf inf inf inf inf  0.]]\n{'a': 12.0, 'b': 16.0, 'c': 16.0, 'd': 14.666666666666666, 'e': 14.666666666666666, 'f': 24.0, 'g': 14.666666666666666, 'h': 28.0, 'i': 24.0}\n</pre> <pre>\n</pre> In\u00a0[49]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2), (1,4,3)])\nprint(t)\n</pre> t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2), (1,4,3)]) print(t) <pre>Temporal Graph with 5 nodes, 6 unique edges and 6 events in [0.0, 3.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 't', 'src'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[5]: Copied! <pre>c = pp.algorithms.centrality.temporal_closeness_centrality(t, delta=1)\nprint(c)\n</pre> c = pp.algorithms.centrality.temporal_closeness_centrality(t, delta=1) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 262.99it/s]</pre> <pre>Created temporal event DAG with 17 nodes and 15 edges\n{0.0: 0.0, 1.0: 4.0, 2.0: 8.0, 3.0: 6.0, 4.0: 9.333333333333332}\n</pre> <pre>\n</pre> In\u00a0[2]: Copied! <pre># old code with explosive memory usage due to computation of all second-order edges irrespective of time stamps\ndef lift_order_not_efficient(g: pp.TemporalGraph, delta=1):\n    # first-order edge index\n    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n    print(edge_index)\n    # second-order edge index with time-respective filtering\n    null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))    \n    # Update node sequences\n    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n    # Remove non-time-respecting higher-order edges\n    time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n    non_negative_mask = time_diff &gt; 0\n    delta_mask = time_diff &lt;= delta\n    time_respecting_mask = non_negative_mask &amp; delta_mask\n    edge_index = null_model_edge_index[:, time_respecting_mask]\n    return edge_index\n</pre> # old code with explosive memory usage due to computation of all second-order edges irrespective of time stamps def lift_order_not_efficient(g: pp.TemporalGraph, delta=1):     # first-order edge index     edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)     node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)     print(edge_index)     # second-order edge index with time-respective filtering     null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))         # Update node sequences     node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)     # Remove non-time-respecting higher-order edges     time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]     non_negative_mask = time_diff &gt; 0     delta_mask = time_diff &lt;= delta     time_respecting_mask = non_negative_mask &amp; delta_mask     edge_index = null_model_edge_index[:, time_respecting_mask]     return edge_index In\u00a0[3]: Copied! <pre># new memory-efficient code\ndef lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):\n\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.t\n    # print(edge_index)\n\n    indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)\n\n    unique_t = torch.unique(timestamps, sorted=True)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for i in tqdm(range(unique_t.size(0))):\n        t = unique_t[i]\n        #print('timestamp index ', i)\n        #print('timestamp ', t)\n        \n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = (timestamps == t)\n        src_edges = edge_index[:,src_time_mask]\n        src_edge_idx = indices[src_time_mask]\n        #print(src_edges)\n        #print(src_edge_idx)\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)\n        dst_edges = edge_index[:,dst_time_mask]        \n        dst_edge_idx = indices[dst_time_mask]\n        #print(dst_edges)\n        #print(dst_edge_idx)\n\n        if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:\n\n            # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges        \n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n            src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n            dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n            #print(src_edges)\n            #print(dst_edges)\n            ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n            second_order.append(ho_edge_index)\n            #print(ho_edge_index) \n            \n            # #print('dst', dst)\n            # src_mask = (edge_index[:,mask][0]==dst)\n            # ctd = edge_index[:,mask][:,src_mask]\n            # #print('continuations', ctd)\n            # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]        \n            # #print('ctd indx', ctd_indices)\n            # count += ctd_indices.size(0)\n    ho_index = torch.cat(second_order, dim=1)    \n    return ho_index\n</pre> # new memory-efficient code def lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):      # first-order edge index     edge_index, timestamps = g.data.edge_index, g.data.t     # print(edge_index)      indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)      unique_t = torch.unique(timestamps, sorted=True)     second_order = []      # lift order: find possible continuations for edges in each time stamp     for i in tqdm(range(unique_t.size(0))):         t = unique_t[i]         #print('timestamp index ', i)         #print('timestamp ', t)                  # find indices of all source edges that occur at unique timestamp t         src_time_mask = (timestamps == t)         src_edges = edge_index[:,src_time_mask]         src_edge_idx = indices[src_time_mask]         #print(src_edges)         #print(src_edge_idx)          # find indices of all edges that can possibly continue edges occurring at time t for the given delta         dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)         dst_edges = edge_index[:,dst_time_mask]                 dst_edge_idx = indices[dst_time_mask]         #print(dst_edges)         #print(dst_edge_idx)          if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:              # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges                     x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()             src_edges = torch.index_select(edge_index, dim=1, index=x[0])             dst_edges = torch.index_select(edge_index, dim=1, index=x[1])             #print(src_edges)             #print(dst_edges)             ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]             second_order.append(ho_edge_index)             #print(ho_edge_index)                           # #print('dst', dst)             # src_mask = (edge_index[:,mask][0]==dst)             # ctd = edge_index[:,mask][:,src_mask]             # #print('continuations', ctd)             # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]                     # #print('ctd indx', ctd_indices)             # count += ctd_indices.size(0)     ho_index = torch.cat(second_order, dim=1)         return ho_index In\u00a0[5]: Copied! <pre>def fo_nodes(ho_edge, g):\n    src_edge = ho_edge[0]\n    dst_edge = ho_edge[1]\n    return g.data.edge_index[:,src_edge][0], g.data.edge_index[:,dst_edge][0], g.data.edge_index[:,dst_edge][1]\n\n\ndef temporal_shortest_paths_all(g: pp.TemporalGraph, delta: int):\n    # generate temporal event DAG\n    edge_index = lift_order_efficient(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in TEG\n    src_edges_src = g.data.edge_index[0,:] + g.data.edge_index.size(1)\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))    \n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.data.edge_index[1,:] + 2*g.data.edge_index.size(1)\n\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    event_graph = pp.Graph.from_edge_index(edge_index)\n    \n    # initialize distance matrix \n    dist = torch.full((g.N, event_graph.N), float(\"inf\"), device=g.data.edge_index.device)\n\n    # predecessor lists\n    pred = defaultdict(lambda: defaultdict(list))\n\n    # Fastest known single source SP in DAG (Cormen, Leiserson): single scan of edges in DAG\n    # trick: index of second-order nodes = topological sorting of event DAG assuming that edges are given in chronological order    \n    # scan second-order nodes in topological order and relax distances between first-order nodes\n\n    # TODO: correct algorithm\n    for src in tqdm(g.nodes):\n        dist[g.mapping.to_idx(src), g.mapping.to_idx(src) + g.data.edge_index.size(1)] = 0\n        for v in event_graph.nodes:\n            for w in event_graph.successors(v):\n                dist[g.mapping.to_idx(src), w] = min(dist[g.mapping.to_idx(src), w], dist[g.mapping.to_idx(src), v]+1)\n    \n    dist_fo = dist[:,2*g.M:] - 1\n    dist_fo.fill_diagonal_(0)\n    return dist_fo, pred\n\n\ndef temporal_shortest_paths(g: pp.TemporalGraph, delta: int):\n    # generate temporal event DAG\n    edge_index = lift_order_efficient(g, delta)    \n\n    # Add indices of g.N first-order nodes as source nodes of paths in augmented TEG\n    src_edges_src = g.M + g.data.edge_index[0,:]\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    # Add indices of g.N first-order nodes as target nodes of paths in augmented TEG\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.M + g.N + g.data.edge_index[1,:]\n\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.M + 2 * g.N)\n    m = event_graph.get_sparse_adj_matrix()\n    print(m.shape)\n    # compute shortest paths from all source nodes to all nodes \n    dist, pred = dijkstra(m, directed=True, indices = np.arange(g.M, g.M+g.N),  return_predecessors=True, unweighted=True)\n    print(dist.shape)\n    print(g.N + g.M)\n    # we are only interested in target nodes, whose indices start at G.M + G.N\n    dist_fo = dist[:,g.M+g.N:] - 1\n    np.fill_diagonal(dist_fo, 0)\n    pred_fo = pred[:,g.N+g.M:]\n    return dist_fo, pred_fo\n\n\n    \ndef temporal_closeness_centrality(g: pp.TemporalGraph, delta: int) -&gt; dict:\n\n    centralities = dict()\n    dist, _ = temporal_shortest_paths(g, delta)\n    for x in g.nodes:\n        centralities[x] = sum((g.N - 1) / dist[np.arange(g.N)!=x, g.mapping.to_idx(x)])\n\n    return centralities\n</pre> def fo_nodes(ho_edge, g):     src_edge = ho_edge[0]     dst_edge = ho_edge[1]     return g.data.edge_index[:,src_edge][0], g.data.edge_index[:,dst_edge][0], g.data.edge_index[:,dst_edge][1]   def temporal_shortest_paths_all(g: pp.TemporalGraph, delta: int):     # generate temporal event DAG     edge_index = lift_order_efficient(g, delta)      # Add indices of first-order nodes as src and dst of paths in TEG     src_edges_src = g.data.edge_index[0,:] + g.data.edge_index.size(1)     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))         dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.data.edge_index[1,:] + 2*g.data.edge_index.size(1)      src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      event_graph = pp.Graph.from_edge_index(edge_index)          # initialize distance matrix      dist = torch.full((g.N, event_graph.N), float(\"inf\"), device=g.data.edge_index.device)      # predecessor lists     pred = defaultdict(lambda: defaultdict(list))      # Fastest known single source SP in DAG (Cormen, Leiserson): single scan of edges in DAG     # trick: index of second-order nodes = topological sorting of event DAG assuming that edges are given in chronological order         # scan second-order nodes in topological order and relax distances between first-order nodes      # TODO: correct algorithm     for src in tqdm(g.nodes):         dist[g.mapping.to_idx(src), g.mapping.to_idx(src) + g.data.edge_index.size(1)] = 0         for v in event_graph.nodes:             for w in event_graph.successors(v):                 dist[g.mapping.to_idx(src), w] = min(dist[g.mapping.to_idx(src), w], dist[g.mapping.to_idx(src), v]+1)          dist_fo = dist[:,2*g.M:] - 1     dist_fo.fill_diagonal_(0)     return dist_fo, pred   def temporal_shortest_paths(g: pp.TemporalGraph, delta: int):     # generate temporal event DAG     edge_index = lift_order_efficient(g, delta)          # Add indices of g.N first-order nodes as source nodes of paths in augmented TEG     src_edges_src = g.M + g.data.edge_index[0,:]     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      # Add indices of g.N first-order nodes as target nodes of paths in augmented TEG     dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.M + g.N + g.data.edge_index[1,:]      src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.M + 2 * g.N)     m = event_graph.get_sparse_adj_matrix()     print(m.shape)     # compute shortest paths from all source nodes to all nodes      dist, pred = dijkstra(m, directed=True, indices = np.arange(g.M, g.M+g.N),  return_predecessors=True, unweighted=True)     print(dist.shape)     print(g.N + g.M)     # we are only interested in target nodes, whose indices start at G.M + G.N     dist_fo = dist[:,g.M+g.N:] - 1     np.fill_diagonal(dist_fo, 0)     pred_fo = pred[:,g.N+g.M:]     return dist_fo, pred_fo        def temporal_closeness_centrality(g: pp.TemporalGraph, delta: int) -&gt; dict:      centralities = dict()     dist, _ = temporal_shortest_paths(g, delta)     for x in g.nodes:         centralities[x] = sum((g.N - 1) / dist[np.arange(g.N)!=x, g.mapping.to_idx(x)])      return centralities In\u00a0[6]: Copied! <pre>dist, pred = temporal_shortest_paths(t_ants, delta=30)\nprint(dist.shape)\nprint(t_ants.N)\nprint(t_ants.M)\n</pre> dist, pred = temporal_shortest_paths(t_ants, delta=30) print(dist.shape) print(t_ants.N) print(t_ants.M) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 6304.91it/s]</pre> <pre>(1181, 1181)\n(68, 1181)\n1113\n(68, 68)\n68\n1045\n</pre> <pre>\n</pre> In\u00a0[11]: Copied! <pre>idx[:,1]\n</pre> idx[:,1] <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 idx[:,1]\n\nNameError: name 'idx' is not defined</pre> In\u00a0[\u00a0]: Copied! <pre>edge_index = lift_order_efficient(t)\nprint(edge_index)\n</pre> edge_index = lift_order_efficient(t) print(edge_index) In\u00a0[50]: Copied! <pre>print(t.data.edge_index)\ndist, pred = temporal_shortest_paths(t, delta=1)\n\nprint(dist)\nprint(pred)\n</pre> print(t.data.edge_index) dist, pred = temporal_shortest_paths(t, delta=1)  print(dist) print(pred) <pre>tensor([[0, 0, 1, 1, 3, 1],\n        [1, 2, 2, 3, 4, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 2955.30it/s]</pre> <pre>(16, 16)\n(5, 16)\n11\n[[ 0.  1.  1.  2.  3.]\n [inf  0.  1.  1.  1.]\n [inf inf  0. inf inf]\n [inf inf inf  0.  1.]\n [inf inf inf inf  0.]]\n[[-9999     0     1     3     4]\n [-9999 -9999     2     3     5]\n [-9999 -9999 -9999 -9999 -9999]\n [-9999 -9999 -9999 -9999     4]\n [-9999 -9999 -9999 -9999 -9999]]\n</pre> <pre>\n</pre> In\u00a0[51]: Copied! <pre>dist[:,4]\n</pre> dist[:,4] Out[51]: <pre>array([ 3.,  1., inf,  1.,  0.])</pre> In\u00a0[\u00a0]: Copied! <pre>t.mapping.node_ids\n</pre> t.mapping.node_ids In\u00a0[\u00a0]: Copied! <pre>print(temporal_closeness_centrality(t, delta=1))\nprint(t.N)\n</pre> print(temporal_closeness_centrality(t, delta=1)) print(t.N) In\u00a0[\u00a0]: Copied! <pre>temporal_shortest_paths(t_sp, delta=3600)\n</pre> temporal_shortest_paths(t_sp, delta=3600) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>edge_index[0,:]\n</pre> edge_index[0,:] In\u00a0[\u00a0]: Copied! <pre>t.data.edge_index[:,edge_index[0,:]][0]\n</pre> t.data.edge_index[:,edge_index[0,:]][0] In\u00a0[\u00a0]: Copied! <pre>t.data.edge_index[:,edge_index[1,:]][1]\n</pre> t.data.edge_index[:,edge_index[1,:]][1] In\u00a0[\u00a0]: Copied! <pre>#print(t.data.edge_index)\nprint(t_sp)\ng = temporal_shortest_paths(t_sp, delta=300)\n</pre> #print(t.data.edge_index) print(t_sp) g = temporal_shortest_paths(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>indeg = degree(g.data.edge_index[1])\nroots = torch.where(indeg==0)[0]\nprint(roots)\n</pre> indeg = degree(g.data.edge_index[1]) roots = torch.where(indeg==0)[0] print(roots) In\u00a0[\u00a0]: Copied! <pre>def traverse(g, path):\n    if g.get_successors(path[-1]).size(0) == 0:\n        pass\n    else:\n        for w in g.successors(path[-1]):\n            traverse(g, path + (w,))\n</pre> def traverse(g, path):     if g.get_successors(path[-1]).size(0) == 0:         pass     else:         for w in g.successors(path[-1]):             traverse(g, path + (w,)) In\u00a0[\u00a0]: Copied! <pre>i = 0\nfor x in roots:\n    print(x)\n    traverse(g, (x,))\n</pre> i = 0 for x in roots:     print(x)     traverse(g, (x,)) In\u00a0[\u00a0]: Copied! <pre>ho_index = lift_order_not_efficient(t, delta=1)\nprint(ho_index)\n</pre> ho_index = lift_order_not_efficient(t, delta=1) print(ho_index) In\u00a0[\u00a0]: Copied! <pre>ho_index = lift_order_efficient(t, delta=1)\nprint(ho_index)\n</pre> ho_index = lift_order_efficient(t, delta=1) print(ho_index) In\u00a0[\u00a0]: Copied! <pre>print(t.data.edge_index)\n</pre> print(t.data.edge_index) In\u00a0[\u00a0]: Copied! <pre>node_sequence = torch.arange(t.data.num_nodes, device=t.data.edge_index.device).unsqueeze(1)\nprint(node_sequence)\nnode_sequence = torch.cat([node_sequence[t.data.edge_index[0]], node_sequence[t.data.edge_index[1]][:, -1:]], dim=1)\nprint(node_sequence)\n</pre> node_sequence = torch.arange(t.data.num_nodes, device=t.data.edge_index.device).unsqueeze(1) print(node_sequence) node_sequence = torch.cat([node_sequence[t.data.edge_index[0]], node_sequence[t.data.edge_index[1]][:, -1:]], dim=1) print(node_sequence) In\u00a0[\u00a0]: Copied! <pre>lift_order_not_efficient(t_sp, delta=300)\n</pre> lift_order_not_efficient(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>lift_order_efficient(t_sp, delta=300)\n</pre> lift_order_efficient(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>lift_order_not_efficient(t_sp, delta=300)\n</pre> lift_order_not_efficient(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>x = torch.cartesian_prod(torch.tensor([0,1]), torch.tensor([1,3])).t()\n# edge 0 = 0-&gt;1\n# edge 1 = 1-&gt;2\n# edge 2 = 0-&gt;1\n\n# combination 0,1:     0-&gt;1, 1-&gt;2\n# combination 0,2:     0-&gt;1, 0-&gt;1\nprint(x)\n</pre> x = torch.cartesian_prod(torch.tensor([0,1]), torch.tensor([1,3])).t() # edge 0 = 0-&gt;1 # edge 1 = 1-&gt;2 # edge 2 = 0-&gt;1  # combination 0,1:     0-&gt;1, 1-&gt;2 # combination 0,2:     0-&gt;1, 0-&gt;1 print(x) In\u00a0[\u00a0]: Copied! <pre>src_edges = torch.index_select(t.data.edge_index, dim=1, index=x[0])\nprint(src_edges)\n</pre> src_edges = torch.index_select(t.data.edge_index, dim=1, index=x[0]) print(src_edges) In\u00a0[\u00a0]: Copied! <pre>dst_edges = torch.index_select(t.data.edge_index, dim=1, index=x[1])\nprint(dst_edges)\n</pre> dst_edges = torch.index_select(t.data.edge_index, dim=1, index=x[1]) print(dst_edges) In\u00a0[\u00a0]: Copied! <pre>#select all indices where \ntorch.where(src_edges[1,:] == dst_edges[0,:])[0]\nx[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n</pre>  #select all indices where  torch.where(src_edges[1,:] == dst_edges[0,:])[0] x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]] In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/trp_higher_order/","title":"Trp higher order","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[3]: Copied! <pre>import torch\nfrom torch_geometric.data import TemporalData\nimport pathpyG as pp\n\npp.config['torch']['device'] = 'cuda'\n</pre> import torch from torch_geometric.data import TemporalData import pathpyG as pp  pp.config['torch']['device'] = 'cuda' In\u00a0[4]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nprint(t.mapping)\nprint(t.N)\nprint(t.M)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) print(t.mapping) print(t.N) print(t.M) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n10\n</pre> In\u00a0[5]: Copied! <pre>e_i = pp.algorithms.lift_order_temporal(t, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\npp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]);\n</pre> e_i = pp.algorithms.lift_order_temporal(t, delta=1) dag = pp.Graph.from_edge_index(e_i) pp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 1826.52it/s]\n</pre> <p>For $\\delta=1$, this DAG with three connected components tells us that there are the following time-respecting paths:</p> <p>Length one: a -&gt; b b -&gt; a b -&gt; c c -&gt; b c -&gt; d d -&gt; c Length two: a -&gt; b -&gt; a (twice) b -&gt; a -&gt; b a -&gt; b -&gt; c b -&gt; c -&gt; b c -&gt; b -&gt; a d -&gt; c -&gt; d Length three: a -&gt; b -&gt; a -&gt; b b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b b -&gt; c -&gt; b -&gt; a Length four: a -&gt; b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b -&gt; a</p> <p>We can generate a multi-order model for time-respecting paths in a temporal network.</p> In\u00a0[8]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Undirected graph with 4 nodes and 6 (directed) edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 6 nodes and 6 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 6 nodes and 4 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[9]: Copied! <pre>pp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes])\n</pre> pp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes]) Out[9]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fcfb68e26b0&gt;</pre> In\u00a0[10]: Copied! <pre>pp.plot(m.layers[2], node_label=[v for v in m.layers[2].nodes])\n</pre> pp.plot(m.layers[2], node_label=[v for v in m.layers[2].nodes]) Out[10]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fcfb68e2c20&gt;</pre> In\u00a0[8]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges')\nprint(t_sp)\n</pre> t_sp = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges') print(t_sp) <pre>Temporal Graph with 68 nodes, 506 unique edges and 1045 events in [899.0, 1796.0]\n\nGraph attributes\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\n</pre> In\u00a0[9]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=180, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=180, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 68 nodes and 506 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([68, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([506])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 506 nodes and 1919 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([506, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1919])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 1919 nodes and 6164 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1919, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6164])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 6164 nodes and 18095 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6164, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([18095])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre>"},{"location":"tutorial/visualisation/","title":"Interactive Graph Visualisation","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[2]: Copied! <pre>import pathpyG as pp\nimport torch\nprint('Running on', pp.config['torch']['device'])\n</pre> import pathpyG as pp import torch print('Running on', pp.config['torch']['device']) <pre>Running on cpu\n</pre> <p>With these preparations complete, we are ready to construct our first graph. This is achieved through the <code>Graph.from_edge_list</code> constructor provided by <code>pathpyG</code>, a method that allows us to transform a list of edges into a basic graphical representation.</p> In\u00a0[3]: Copied! <pre>g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']])\npp.plot(g, node_label=g.mapping.node_ids, edge_color='gray')\n</pre> g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']]) pp.plot(g, node_label=g.mapping.node_ids, edge_color='gray') Out[3]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9c5ad5b190&gt;</pre> <p>After successfully creating a simple graph using <code>pathpyG</code>, our next step is to examine its structure. This is a crucial part of the process as it gives us an initial understanding of the complexity and scale of our graph. By printing out the number of nodes and edges, we gain insight into the size and connectivity of the graph.</p> <p>Although it may seem unnecessary for this simple graph, it's good practice to gather information about the number of nodes and edges before attempting to visualize it. This preemptive step is crucial, especially when dealing with larger graphs. Visualizing extensive networks can be a time-consuming or even unfeasible task, depending on the sheer volume of elements that need to be represented. Therefore, understanding the graph's scale upfront helps in efficiently planning the visualization process and avoiding potential complications that could arise with larger datasets.</p> In\u00a0[4]: Copied! <pre>f'Our graph has {g.N} nodes and {g.M} edges.'\n</pre> f'Our graph has {g.N} nodes and {g.M} edges.' Out[4]: <pre>'Our graph has 3 nodes and 2 edges.'</pre> In\u00a0[5]: Copied! <pre>pp.plot(g)\n</pre> pp.plot(g) Out[5]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9c5ad5aa10&gt;</pre> In\u00a0[6]: Copied! <pre>pp.plot(g,backend='matplotlib');\n</pre> pp.plot(g,backend='matplotlib'); In\u00a0[7]: Copied! <pre>pp.plot(g,backend='matplotlib',layout='fr')\n</pre> pp.plot(g,backend='matplotlib',layout='fr') Out[7]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d344610&gt;</pre> <p>Additionally, <code>pathpyG</code> offers the flexibility to incorporate custom layout algorithms. If you have developed your own method or have specific requirements for node positioning, you can directly provide the node coordinates to the visualization. This capability ensures that <code>pathpyG</code> can cater to a wide range of visualization needs, from simple and automatic layouts to highly customized and complex arrangements, making it a versatile tool in the field of data visualization.</p> In\u00a0[8]: Copied! <pre>layout = {'a':[0,0],'b':[1,1],\"c\":[2,2]}\npp.plot(g,backend='matplotlib',layout=layout)\n</pre> layout = {'a':[0,0],'b':[1,1],\"c\":[2,2]} pp.plot(g,backend='matplotlib',layout=layout) Out[8]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9c5ad5a1a0&gt;</pre> In\u00a0[9]: Copied! <pre>style = {}\nstyle['node_color'] = (255,1,255) # RGB tuple\nstyle['edge_color'] = 'green'     # Color name as str\npp.plot(g,**style)\n</pre> style = {} style['node_color'] = (255,1,255) # RGB tuple style['edge_color'] = 'green'     # Color name as str pp.plot(g,**style) Out[9]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d17ca90&gt;</pre> <p>In <code>pathpyG</code>, there are various methods for assigning styles to objects, each offering a different level of customization and control. A straightforward approach, as previously shown, involves using a single value, such as a color string (e.g., <code>'green'</code>) or an RGB tuple (e.g., <code>(255,1,255)</code>). Applying this single value uniformly alters the appearance of all elements within a specific category, providing a quick and easy way to set a general style. However, for more detailed styling, one can utilize a <code>list</code> of values. In this approach, each value in the <code>list</code> is associated with an element according to its index position. This method is particularly familiar and efficient when working with tensors, where the association of values to elements is often index-based.</p> <p>Additionally, a more tailored approach can be employed through the use of dictionaries. In this case, each element id is paired with a corresponding value in the <code>dict</code>. Elements not included in the dictionary are assigned default values, ensuring that every element is styled, albeit some with custom and others with default styles. The types of values that can be used in these styling methods are diverse, including strings, integers, floats, and tuples, each type depending on the specific styling parameter being adjusted. This flexibility in value types and assignment methods allows for a high degree of customization, enabling the creation of visually distinct and information-rich visualizations.</p> In\u00a0[10]: Copied! <pre>style = {}\nstyle['node_color'] = ['red', 'green','blue'] # list based approach\nstyle['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach\nstyle['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value\nstyle['edge_color'] = ['orange','#00FF00']    # hex based color\npp.plot(g,**style)\n</pre> style = {} style['node_color'] = ['red', 'green','blue'] # list based approach style['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach style['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value style['edge_color'] = ['orange','#00FF00']    # hex based color pp.plot(g,**style) Out[10]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d1a7f40&gt;</pre> In\u00a0[11]: Copied! <pre>from matplotlib.pyplot import get_cmap\nmy_map = get_cmap()\nmy_map\n</pre> from matplotlib.pyplot import get_cmap my_map = get_cmap() my_map Out[11]: viridis  underbad over  In\u00a0[12]: Copied! <pre>style = {}\nstyle['edge_color'] = [1, 9]      # int values\n\nstyle['node_color'] = pp.algorithms.centrality.betweenness_centrality(g)\nstyle['node_cmap'] = my_map       # new color map from matplotlib for nodes\npp.plot(g,**style)\n</pre> style = {} style['edge_color'] = [1, 9]      # int values  style['node_color'] = pp.algorithms.centrality.betweenness_centrality(g) style['node_cmap'] = my_map       # new color map from matplotlib for nodes pp.plot(g,**style) Out[12]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5e745780&gt;</pre> In\u00a0[13]: Copied! <pre>pp.plot(g,filename='test_plot.html')\n</pre> pp.plot(g,filename='test_plot.html') Out[13]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d142ef0&gt;</pre> In\u00a0[14]: Copied! <pre>n = pp.io.read_netzschleuder_network('karate', '77')\n</pre> n = pp.io.read_netzschleuder_network('karate', '77') In\u00a0[15]: Copied! <pre>pp.plot(n)\n</pre> pp.plot(n) Out[15]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d143670&gt;</pre> In\u00a0[16]: Copied! <pre>node_color = [n['node_groups',v][0] for v in n.nodes]\npp.plot(n, edge_color='gray',node_color=node_color)\n</pre> node_color = [n['node_groups',v][0] for v in n.nodes] pp.plot(n, edge_color='gray',node_color=node_color) Out[16]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d140880&gt;</pre> In\u00a0[17]: Copied! <pre>t = pp.TemporalGraph.from_edge_list(\n        [\n            (\"a\", \"b\", 1),\n            (\"b\", \"c\", 5),\n            (\"c\", \"d\", 9),\n            (\"d\", \"a\", 9),\n            (\"a\", \"b\", 10),\n            (\"b\", \"c\", 10),\n        ]\n    )\n</pre> t = pp.TemporalGraph.from_edge_list(         [             (\"a\", \"b\", 1),             (\"b\", \"c\", 5),             (\"c\", \"d\", 9),             (\"d\", \"a\", 9),             (\"a\", \"b\", 10),             (\"b\", \"c\", 10),         ]     ) In\u00a0[18]: Copied! <pre>pp.plot(t)\n</pre> pp.plot(t) Out[18]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f9b5d143550&gt;</pre> <p>Besides the standard formatting options available in <code>pathpyG</code>, temporal plots come with specific options tailored to their unique nature. These specialized settings allow for precise control over the time dimension of the visualization. With the <code>start</code> and <code>end</code> parameters, you can define the exact start time and end time of the simulation, effectively setting the temporal boundaries of your graph. This feature is crucial for focusing on a particular time frame within your dataset. Additionally, the <code>delta</code> option lets you adjust the progression speed through the time steps of your visualization. Here, a value of 1000 translates to a one-second interval, providing a way to calibrate the pace at which the temporal data unfolds. Moreover, the <code>interval</code> option offers the flexibility to either widen or narrow the time intervals considered in the visualization. This feature is particularly useful for either zooming in on finer time-scaled details or zooming out for a broader, more comprehensive view of the temporal dynamics in your network.</p> In\u00a0[19]: Copied! <pre>color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"}\npp.plot(t,node_color=color,start=-1,end=25,delta=1000)\n</pre> color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"} pp.plot(t,node_color=color,start=-1,end=25,delta=1000) Out[19]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f9b5d1415d0&gt;</pre>"},{"location":"tutorial/visualisation/#interactiv-graph-visualization","title":"Interactiv Graph Visualization\u00b6","text":""},{"location":"tutorial/visualisation/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/visualisation/#motivation","title":"Motivation\u00b6","text":"<p>This tutorial is specifically designed to guide you through the process of visualizing your data using <code>pathpyG</code>, an advanced data visualization tool. Data visualization is a crucial aspect of data analysis and interpretation, allowing for the transformation of complex datasets into visually appealing and easy-to-understand formats. pathpyG excels in this area by providing a range of functionalities that cater to both beginners and advanced users. Throughout this tutorial, you will be introduced to the basic and advanced features of pathpyG, empowering you to effectively visualize your data. This will not only enhance your understanding of your data but also enable you to communicate your findings more effectively to others.</p> <p>Visualization is a core concept of <code>pathpyG</code> because it bridges the gap between raw data and meaningful visual representations. We, as humans, are wired to process visual information much more rapidly compared to text or audio. This innate ability enables us to quickly identify patterns, outliers, and trends in visual data. Data visualization leverages this capability by graphically representing data, thereby facilitating the swift interpretation of large and complex datasets. Interactive visualizations further this advantage by allowing users to directly engage with the data, exploring and analyzing it in an intuitive and insightful manner. Whether it's understanding the intricate details of microscopic structures or grasping the dynamics of global phenomena, visualizations are instrumental in helping researchers and analysts gain deeper insights and effectively communicate their findings.</p>"},{"location":"tutorial/visualisation/#learning-objectives","title":"Learning objectives\u00b6","text":"<p>In this tutorial, you will learn to master the art of creating simple yet powerful interactive visualizations using <code>pathpyG</code>. You will learn the nuances of customizing the style of your visualizations, enabling you to tailor them to your specific needs and preferences. This customization extends to the aesthetics, layout, and interactive elements, ensuring that your visualizations are not only informative but also engaging. Additionally, the tutorial covers the essential skills needed to save your visualizations in various formats, making it easier to share your work across different platforms and audiences. Lastly, a significant part of the tutorial is dedicated to creating temporal visualizations. These types of visualizations are particularly useful in understanding and presenting data that changes over time, offering dynamic insights into trends and patterns that static visualizations cannot capture. By the end of this tutorial, you will have a comprehensive understanding of how to effectively use pathpyG to create and customize a wide range of visualizations.</p>"},{"location":"tutorial/visualisation/#lets-get-started","title":"Let's Get Started\u00b6","text":"<p>To embark on our journey of visualizing data with <code>pathpyG</code>, the initial step involves initializing and loading the required modules, a crucial process that sets the foundation for our data visualization work. This preparation ensures that all necessary tools and functionalities from <code>pathpyG</code> are at our disposal.</p> <p>In anticipation of enhancing our graphs with additional attributes, we also include the <code>torch</code> package in our setup. <code>torch</code> is renowned for its robust capabilities in data processing and machine learning, and its inclusion allows us to enrich our graphs with more complex and informative attributes.</p>"},{"location":"tutorial/visualisation/#the-plot-function","title":"The <code>plot</code> Function\u00b6","text":"<p>The <code>plot</code> function in <code>pathpyG</code> stands out as the simplest and most direct method for creating visualizations. Designed to encapsulate all the plotting capabilities of <code>pathpyG</code> in a single command, it streamlines the process of generating quick and efficient plots. This functionality is particularly beneficial for users who seek immediate visual feedback from their data without delving into more complex coding. The only prerequisite for using this function is the <code>Graph</code> object, which serves as the foundation for the visualization. Moreover, when working within an interactive environment, such as a <code>Jupyter notebook</code>, the <code>plot</code> function is particularly powerful. In such settings, invoking the <code>plot</code> command will automatically generate and display an interactive visualization. This feature is particularly beneficial as it allows for immediate visual feedback, making it an ideal tool for exploratory data analysis where quick and efficient visualization is key.</p>"},{"location":"tutorial/visualisation/#kwargs-in-the-plot-function","title":"<code>kwargs</code> in the <code>plot</code> function\u00b6","text":"<p>In <code>pathpyG</code>, the customization of your plot is managed through keyword arguments (kwargs), where each customization is specified as a keyword followed by its corresponding value. This approach is what gives the <code>plot</code> function its remarkable flexibility, allowing it to adapt to a wide variety of plotting requirements. Whether you're aiming for a simple graph or a complex, multi-faceted visualization, the keyword arguments provide the tools to tailor your plot precisely to your needs.</p> <p>However, this wealth of options can be somewhat overwhelming for beginners, given the extensive range of available choices. But worry not, as we will guide you through the most essential and basic options, ensuring you have a solid foundation to start from. By mastering these fundamental aspects, you'll be well on your way to effectively utilizing <code>pathpyG</code>'s plot function, gradually building up to more advanced features as you gain confidence and expertise.</p>"},{"location":"tutorial/visualisation/#plotting-backends","title":"Plotting Backends\u00b6","text":"<p>In the diverse world of data visualization, there is no one-size-fits-all technique, as different scenarios demand different approaches. Recognizing this, <code>pathpyG</code> offers a variety of plotting backends, each tailored for specific use cases, ensuring that users have the right tools for their unique requirements.</p> <ul> <li><p>For instance, <code>pathpyG</code> facilitates interactive visualizations, as previously demonstrated, which are immensely useful for dynamic exploration of data. This feature is particularly beneficial in educational settings, exploratory data analysis, and communication, where interaction with the data can lead to deeper understanding and insights.</p> </li> <li><p>On the other hand, <code>pathpyG</code> also integrates with matplotlib, a widely recognized package for creating static plots. This is especially efficient for visualizing large graphs where interactivity might be less critical.</p> </li> <li><p>Additionally, <code>pathpyG</code> caters to the academic and publication community by offering tikz plots, which are highly valued in formal publications for their precision and quality. (Note that for generating tikz plots, currently, the installation of <code>latexmk</code> is necessary to produce the corresponding <code>.tex</code> and <code>.pdf</code> files.)</p> </li> </ul> <p>Let's generate a static png image using the <code>matplotlib</code> backend:</p>"},{"location":"tutorial/visualisation/#quick-introduction-to-layouts","title":"Quick Introduction to Layouts\u00b6","text":"<p>An important aspect to consider is the layout of your plot. The previous plot we generated is static, meaning the positions of the nodes are fixed and do not change. This fixed arrangement presents a unique challenge, as finding the optimal placement for nodes and edges to convey information effectively is not a straightforward task. To assist with this, <code>pathpyG</code> supports simple layout functions designed to create visually appealing and coherent graphs. By default, nodes are assigned random locations for computational efficiency. However, this arrangement can be significantly improved with the use of the <code>layout</code> keyword in the <code>plot</code> function, allowing for more structured and meaningful representations of your graph.</p> <p>For example, <code>pathpyG</code> includes support for sophisticated layout algorithms, such as the Fruchterman-Reingold algorithm for force-directed layouts. This can be activated using the <code>\"fr\"</code> option, which applies a physics-based approach to arrange nodes and edges in a way that visually represents their relational dynamics. Such force-directed layouts are particularly useful for highlighting the underlying structure and relationships within the data.</p>"},{"location":"tutorial/visualisation/#styling-your-plots","title":"Styling Your Plots\u00b6","text":"<p>To enhance the effectiveness and appeal of our visualizations in <code>pathpyG</code>, styling of our plots becomes a key aspect. The ability to style your plots is not just about aesthetic appeal; it is about effectively conveying more information through visual means. Depending on the type of plot you are working with, there are multiple styling options available to tailor your visualization to your specific needs. The fundamental principle here is that the styles applied to your plot should not be dependent on the data of your model. In other words, you should be able to present the same data in different styles, depending on the context or the information you wish to highlight. To facilitate this, styles are organized in dictionaries, which are then incorporated into the <code>plot</code> function.</p> <p>For network plots, where the focus is on the topology of the data, there are several basic styling options you can adjust, including the <code>size</code>, <code>color</code>, and <code>opacity</code> of each node and edge object. These options provide a foundational level of customization, allowing you to make your graph more readable and visually appealing. However, the styling possibilities extend further, varying according to the specific kind of plot you are creating. To distinguish between the styling of edges and nodes, a prefix corresponding to each element type is added to the keyword, such as <code>node_size</code>. This distinction ensures that your styling choices are accurately applied to the intended elements of the graph, further enhancing the clarity and effectiveness of your visualization.</p>"},{"location":"tutorial/visualisation/#colormaps","title":"Colormaps\u00b6","text":"<p>In many instances, particularly when visualizing numerical data, the use of color gradients to represent values can greatly enhance the clarity and effectiveness of a plot. <code>pathpyG</code> addresses this need through its native support for <code>colormaps</code>. When the colors of node or edge elements are defined using <code>int</code> or <code>float</code> values, <code>pathpyG</code> automatically assigns colors based on these colormaps, effectively interpolating the correct color value for each element. By default, <code>pathpyG</code> offers a simple colormap that transitions from red to green, sufficient for many basic visualization needs. However, for more customized or advanced styling, users have the option to utilize any colormap from the extensive color palettes provided by <code>matplotlib</code> or <code>seaborn</code>. These libraries offer a wide range of color schemes, enabling you to select the perfect palette to convey the nuances of your data.</p>"},{"location":"tutorial/visualisation/#saving-plots","title":"Saving Plots\u00b6","text":"<p>In <code>pathpyG</code>, sharing your plots or incorporating them into various mediums is facilitated by the ability to save them as files. This functionality is conveniently accessed by simply adding the <code>filename</code> keyword within the plot function. When you specify a filename, <code>pathpyG</code> assigns the appropriate backend to use based on the file extension provided. For instance, if you save your file with an <code>.html</code> extension, <code>pathpyG</code> generates a standalone interactive visualization, perfect for web applications or interactive presentations. On the other hand, if you choose to save your plot as a <code>.png</code> file, a static image is created using the <code>matplotlib</code> backend, ideal for including in documents, reports, or presentations where interactivity is not required. Additionally, for those seeking to incorporate plots into academic papers or publications, saving the file with a <code>.tex</code> extension activates the <code>tikz</code> backend. This feature is particularly beneficial for creating high-quality, publication-ready figures.</p>"},{"location":"tutorial/visualisation/#larger-network-visualizations","title":"Larger Network Visualizations\u00b6","text":"<p>Having covered the basics, we are now well-prepared to venture into the realm of larger network visualizations using <code>pathpyG</code>.</p>"},{"location":"tutorial/visualisation/#temporal-network-visualizations","title":"Temporal Network Visualizations\u00b6","text":"<p>In the realm of network analysis, <code>pathpyG</code> particularly excels in handling and visualizing temporal graphs, a domain where both nodes and edges can change their properties over time. This dynamic aspect of temporal graphs adds a layer of complexity and richness to data analysis, capturing the evolution of relationships and properties within the network. <code>pathpyG</code> supports this advanced functionality, allowing users to apply the same versatile <code>plot</code> function used for static graphs to <code>TemporalGraph</code> data structures. This integration means that all the customization options, styling features, and layout choices previously explored for static network visualizations are also applicable to temporal graphs. The ability to utilize these tools in the context of temporal data opens up a world of possibilities for in-depth analysis and insightful visualization of networks where time plays a crucial role. Whether you're tracking changes in social networks, analyzing traffic patterns, or studying dynamic biological systems, <code>pathpyG</code>'s capabilities in temporal network visualization provide a powerful tool to uncover and illustrate the temporal dynamics inherent in these complex systems.</p>"},{"location":"tutorial/xx_temporal_centralities/","title":"Xx temporal centralities","text":"In\u00a0[2]: Copied! <pre>import torch\n\nimport pathpyG as pp\n\nprint('Running on', pp.config['torch']['device'])\n</pre> import torch  import pathpyG as pp  print('Running on', pp.config['torch']['device']) <pre>Running on cpu\n</pre> In\u00a0[3]: Copied! <pre># Put this as his in conftest as 'simple_paths_centralities'\npaths = pp.WalkData()\npaths.add(torch.tensor([[2, 1, 3], [1, 3, 5]]))  \npaths.add(torch.tensor([[0, 1], [1, 3]]))  \npaths.add(torch.tensor([[3], [4]]))\n\nsimple_paths_centralities = paths\n</pre> # Put this as his in conftest as 'simple_paths_centralities' paths = pp.WalkData() paths.add(torch.tensor([[2, 1, 3], [1, 3, 5]]))   paths.add(torch.tensor([[0, 1], [1, 3]]))   paths.add(torch.tensor([[3], [4]]))  simple_paths_centralities = paths In\u00a0[4]: Copied! <pre># paths = pp.PathData()\n# paths.add_walk(torch.tensor([[0,2,3],[2,3,4]]),freq=3) # A -&gt; C -&gt; D\n# paths.add_walk(torch.tensor([[0,2],[2,3]])) # A -&gt; C -&gt; D\n# paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E\n# paths.add_walk(torch.tensor([[4],[5]]))\n# paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E\n</pre> # paths = pp.PathData() # paths.add_walk(torch.tensor([[0,2,3],[2,3,4]]),freq=3) # A -&gt; C -&gt; D # paths.add_walk(torch.tensor([[0,2],[2,3]])) # A -&gt; C -&gt; D # paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E # paths.add_walk(torch.tensor([[4],[5]])) # paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E  In\u00a0[5]: Copied! <pre>index, edge_weights = paths.edge_index_k_weighted(k=2)\nindex, edge_weights\n</pre> index, edge_weights = paths.edge_index_k_weighted(k=2) index, edge_weights Out[5]: <pre>(tensor([[[0, 1],\n          [1, 3],\n          [2, 1]],\n \n         [[1, 3],\n          [3, 5],\n          [1, 3]]]),\n tensor([1., 1., 1.]))</pre> In\u00a0[6]: Copied! <pre>index, edge_weights = paths.edge_index_k_weighted(k=1)\n</pre> index, edge_weights = paths.edge_index_k_weighted(k=1) In\u00a0[7]: Copied! <pre>from collections import defaultdict\n\ndef node_traversals(paths):\n    \"\"\"Calculates the number of times any path traverses each of the nodes.\n\n    Parameters\n    ----------\n    paths: Paths\n\n    Returns\n    -------\n    dict\n    \"\"\"\n    traversals = defaultdict(lambda: 0)\n    for path_id, path_edgelist in paths.paths.items():\n        path_seq = paths.walk_to_node_seq(path_edgelist)\n        for node in path_seq:\n            traversals[node.item()] += paths.path_freq[path_id]\n    return traversals\n</pre> from collections import defaultdict  def node_traversals(paths):     \"\"\"Calculates the number of times any path traverses each of the nodes.      Parameters     ----------     paths: Paths      Returns     -------     dict     \"\"\"     traversals = defaultdict(lambda: 0)     for path_id, path_edgelist in paths.paths.items():         path_seq = paths.walk_to_node_seq(path_edgelist)         for node in path_seq:             traversals[node.item()] += paths.path_freq[path_id]     return traversals In\u00a0[10]: Copied! <pre>from pathpyG.algorithms.centrality import node_traversals\n</pre> from pathpyG.algorithms.centrality import node_traversals In\u00a0[11]: Copied! <pre>node_traversals(paths)\n</pre> node_traversals(paths) <pre>\n---------------------------------------------------------------------------\nRecursionError                            Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 node_traversals(paths)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\n    [... skipping similar frames: __getattr__.&lt;locals&gt;.wrapper at line 311 (2968 times)]\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:299, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    298 def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n--&gt; 299     if len(args) == 0:\n    300         raise RuntimeError(f'Did not find method {name} with no arguments')\n    301     if isinstance(args[0], TemporalGraph):\n\nRecursionError: maximum recursion depth exceeded while calling a Python object</pre> In\u00a0[13]: Copied! <pre>from pathpyG.algorithms.centrality import visitation_probabilities\n</pre> from pathpyG.algorithms.centrality import visitation_probabilities In\u00a0[14]: Copied! <pre>def test_visitation_probabilities(simple_paths_centralities):\n    traversals_dict = visitation_probabilities(simple_paths_centralities)\n    assert set(traversals_dict.keys()) == {0,1,2,3,4,5}\n    assert traversals_dict[0] == 1/9\n    assert traversals_dict[1] == 2/9\n    assert traversals_dict[2] == 1/9\n    assert traversals_dict[3] == 3/9\n    assert traversals_dict[4] == 1/9\n    assert traversals_dict[5] == 1/9\n\ntest_visitation_probabilities(simple_paths_centralities)\n</pre> def test_visitation_probabilities(simple_paths_centralities):     traversals_dict = visitation_probabilities(simple_paths_centralities)     assert set(traversals_dict.keys()) == {0,1,2,3,4,5}     assert traversals_dict[0] == 1/9     assert traversals_dict[1] == 2/9     assert traversals_dict[2] == 1/9     assert traversals_dict[3] == 3/9     assert traversals_dict[4] == 1/9     assert traversals_dict[5] == 1/9  test_visitation_probabilities(simple_paths_centralities) <pre>\n---------------------------------------------------------------------------\nRecursionError                            Traceback (most recent call last)\nCell In[14], line 11\n      8     assert traversals_dict[4] == 1/9\n      9     assert traversals_dict[5] == 1/9\n---&gt; 11 test_visitation_probabilities(simple_paths_centralities)\n\nCell In[14], line 2, in test_visitation_probabilities(simple_paths_centralities)\n      1 def test_visitation_probabilities(simple_paths_centralities):\n----&gt; 2     traversals_dict = visitation_probabilities(simple_paths_centralities)\n      3     assert set(traversals_dict.keys()) == {0,1,2,3,4,5}\n      4     assert traversals_dict[0] == 1/9\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\n    [... skipping similar frames: __getattr__.&lt;locals&gt;.wrapper at line 311 (2967 times)]\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:299, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    298 def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n--&gt; 299     if len(args) == 0:\n    300         raise RuntimeError(f'Did not find method {name} with no arguments')\n    301     if isinstance(args[0], TemporalGraph):\n\nRecursionError: maximum recursion depth exceeded while calling a Python object</pre> In\u00a0[339]: Copied! <pre>test_shortest_paths(paths)\n</pre> test_shortest_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> In\u00a0[340]: Copied! <pre># @betweenness.register(Paths)\ndef betweenness(paths, normalized=False):\n    \"\"\"Calculates the betweenness of nodes based on observed shortest paths\n    between all pairs of nodes\n\n    Parameters\n    ----------\n    paths:\n        Paths object\n    normalized: bool\n        normalize such that largest value is 1.0\n\n    Returns\n    -------\n    dict\n    \"\"\"\n    assert isinstance(paths, pp.PathData), \"argument must be an instance of pathpy.Paths\"\n    node_centralities = defaultdict(lambda: 0)\n\n    # Log.add('Calculating betweenness in paths ...', Severity.INFO)\n\n    all_paths = shortest_paths(paths)\n\n    for s in all_paths:\n        for d in all_paths[s]:\n            for p in all_paths[s][d]:\n                for x in p[1:-1]:\n                    if s != d != x:\n                        node_centralities[x.item()] += 1.0 / len(all_paths[s][d])\n    if normalized:\n        max_centr = max(node_centralities.values())\n        for v in node_centralities:\n            node_centralities[v] /= max_centr\n    # assign zero values to nodes not occurring on shortest paths\n    nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)]\n    for v in nodes:\n        node_centralities[v] += 0\n    # Log.add('finished.')\n    return node_centralities\n\nbetweenness(paths,normalized=False)\n</pre> # @betweenness.register(Paths) def betweenness(paths, normalized=False):     \"\"\"Calculates the betweenness of nodes based on observed shortest paths     between all pairs of nodes      Parameters     ----------     paths:         Paths object     normalized: bool         normalize such that largest value is 1.0      Returns     -------     dict     \"\"\"     assert isinstance(paths, pp.PathData), \"argument must be an instance of pathpy.Paths\"     node_centralities = defaultdict(lambda: 0)      # Log.add('Calculating betweenness in paths ...', Severity.INFO)      all_paths = shortest_paths(paths)      for s in all_paths:         for d in all_paths[s]:             for p in all_paths[s][d]:                 for x in p[1:-1]:                     if s != d != x:                         node_centralities[x.item()] += 1.0 / len(all_paths[s][d])     if normalized:         max_centr = max(node_centralities.values())         for v in node_centralities:             node_centralities[v] /= max_centr     # assign zero values to nodes not occurring on shortest paths     nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)]     for v in nodes:         node_centralities[v] += 0     # Log.add('finished.')     return node_centralities  betweenness(paths,normalized=False) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> Out[340]: <pre>defaultdict(&lt;function __main__.betweenness.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {1: 3.0, 3: 2.0, 0: 0, 2: 0, 4: 0, 5: 0})</pre> In\u00a0[346]: Copied! <pre>def test_betweenness_paths(simple_paths_centralities):\n    bw = betweenness(simple_paths_centralities,normalized=False)\n    # 1 is in the shortest path between 0-5,2-3,2-5\n    assert bw[1] == 3.0\n    # 1 is in the shortest path between 2-5,1-5\n    assert bw[3] == 2.0\n\ntest_betweenness_paths(paths)\n</pre> def test_betweenness_paths(simple_paths_centralities):     bw = betweenness(simple_paths_centralities,normalized=False)     # 1 is in the shortest path between 0-5,2-3,2-5     assert bw[1] == 3.0     # 1 is in the shortest path between 2-5,1-5     assert bw[3] == 2.0  test_betweenness_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> In\u00a0[347]: Copied! <pre>def distance_matrix(paths):\n    \"\"\"\n    Calculates shortest path distances between all pairs of\n    nodes based on the observed shortest paths (and subpaths)\n    \"\"\"\n    dist = defaultdict(lambda: defaultdict(lambda: _np.inf))\n    # Log.add('Calculating distance matrix based on empirical paths ...', Severity.INFO)\n    nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject\n    for v in nodes:\n        dist[v][v] = 0\n\n    p_length = 1\n    index, edge_weights = paths.edge_index_k_weighted(k=p_length)\n    sources = index[0]\n    destinations = index[-1]\n    for e, (s, d) in enumerate(zip(sources, destinations)):\n        s = s.item()\n        d = d.item()\n        dist[s][d] = p_length\n        # s_p[s][d] = set({torch.tensor([s,d])})\n    p_length += 1\n    while True: # until max path length\n        try:\n            index, edge_weights = paths.edge_index_k_weighted(k=p_length)\n            sources = index[0, :, 0]\n            destinations = index[1, :, -1]\n            for e, (s, d) in enumerate(zip(sources, destinations)):\n                s = s.item()\n                d = d.item()\n                if p_length &lt; dist[s][d]:\n                    # update shortest path length\n                    dist[s][d] = p_length\n            p_length += 1\n        except IndexError:\n            print(f\"IndexError occurred. Reached maximum path length of {p_length}\")\n            break\n    return dist\ndistance_matrix(paths)\n</pre>  def distance_matrix(paths):     \"\"\"     Calculates shortest path distances between all pairs of     nodes based on the observed shortest paths (and subpaths)     \"\"\"     dist = defaultdict(lambda: defaultdict(lambda: _np.inf))     # Log.add('Calculating distance matrix based on empirical paths ...', Severity.INFO)     nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject     for v in nodes:         dist[v][v] = 0      p_length = 1     index, edge_weights = paths.edge_index_k_weighted(k=p_length)     sources = index[0]     destinations = index[-1]     for e, (s, d) in enumerate(zip(sources, destinations)):         s = s.item()         d = d.item()         dist[s][d] = p_length         # s_p[s][d] = set({torch.tensor([s,d])})     p_length += 1     while True: # until max path length         try:             index, edge_weights = paths.edge_index_k_weighted(k=p_length)             sources = index[0, :, 0]             destinations = index[1, :, -1]             for e, (s, d) in enumerate(zip(sources, destinations)):                 s = s.item()                 d = d.item()                 if p_length &lt; dist[s][d]:                     # update shortest path length                     dist[s][d] = p_length             p_length += 1         except IndexError:             print(f\"IndexError occurred. Reached maximum path length of {p_length}\")             break     return dist distance_matrix(paths)      <pre>IndexError occurred. Reached maximum path length of 4\n</pre> Out[347]: <pre>defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {0: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {0: 0, 1: 1, 3: 2}),\n             1: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {1: 0, 3: 1, 5: 2}),\n             2: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {2: 0, 1: 1, 3: 2, 5: 3}),\n             3: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {3: 0, 4: 1, 5: 1}),\n             4: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {4: 0}),\n             5: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {5: 0})})</pre> In\u00a0[352]: Copied! <pre>def test_distance_matrix_paths(simple_paths_centralities):\n    dm = distance_matrix(simple_paths_centralities)\n    assert dm[0] == {0: 0, 1: 1, 3: 2}\n    assert dm[1] == {1: 0, 3: 1, 5: 2}\n    assert dm[2] == {2: 0, 1: 1, 3: 2, 5: 3}\n    assert dm[3] == {3: 0, 4: 1, 5: 1}\n    assert dm[4] == {4: 0}\n    assert dm[5] == {5: 0}\n\ntest_distance_matrix_paths(paths)\n</pre> def test_distance_matrix_paths(simple_paths_centralities):     dm = distance_matrix(simple_paths_centralities)     assert dm[0] == {0: 0, 1: 1, 3: 2}     assert dm[1] == {1: 0, 3: 1, 5: 2}     assert dm[2] == {2: 0, 1: 1, 3: 2, 5: 3}     assert dm[3] == {3: 0, 4: 1, 5: 1}     assert dm[4] == {4: 0}     assert dm[5] == {5: 0}  test_distance_matrix_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> In\u00a0[355]: Copied! <pre>def closeness(paths, normalized=False):\n    \"\"\"Calculates the closeness of nodes based on observed shortest paths\n    between all nodes\n\n    Parameters\n    ----------\n    paths: Paths\n    normalized: bool\n        normalize such that largest value is 1.0\n\n    Returns\n    -------\n    dict\n    \"\"\"\n    node_centralities = defaultdict(lambda: 0)\n    distances = distance_matrix(paths)\n    nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject\n\n    for x in nodes:\n        # calculate closeness centrality of x\n        for d in nodes:\n            if x != d and distances[d][x] &lt; _np.inf:\n                node_centralities[x] += 1.0 / distances[d][x]\n\n    # assign zero values to nodes not occurring\n    \n    for v in nodes:\n        node_centralities[v] += 0.0\n\n    if normalized:\n        m = max(node_centralities.values())\n        for v in nodes:\n            node_centralities[v] /= m\n\n    return node_centralities\ncloseness(paths, normalized=False)\n</pre> def closeness(paths, normalized=False):     \"\"\"Calculates the closeness of nodes based on observed shortest paths     between all nodes      Parameters     ----------     paths: Paths     normalized: bool         normalize such that largest value is 1.0      Returns     -------     dict     \"\"\"     node_centralities = defaultdict(lambda: 0)     distances = distance_matrix(paths)     nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject      for x in nodes:         # calculate closeness centrality of x         for d in nodes:             if x != d and distances[d][x] &lt; _np.inf:                 node_centralities[x] += 1.0 / distances[d][x]      # assign zero values to nodes not occurring          for v in nodes:         node_centralities[v] += 0.0      if normalized:         m = max(node_centralities.values())         for v in nodes:             node_centralities[v] /= m      return node_centralities closeness(paths, normalized=False) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> Out[355]: <pre>defaultdict(&lt;function __main__.closeness.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {1: 2.0, 3: 2.0, 4: 1.0, 5: 1.8333333333333333, 0: 0.0, 2: 0.0})</pre> In\u00a0[360]: Copied! <pre>def test_closeness_paths(simple_paths_centralities):\n    c = closeness(simple_paths_centralities, normalized=False)\n    assert c[0] == 0.0\n    # 1 reachable from 0 and 2 in one step\n    assert c[1] == 1/1 + 1/1\n    assert c[2] == 0\n    # 3 reachable from 1 in one step, from 0 and 3 in two steps\n    assert c[3] == 1 + 1/2 + 1/2\n    assert c[4] == 1\n    # 5 reachable from 3 in one step, from 1 in two steps, from 2 in three steps\n    assert c[5] == 1 + 1/2 + 1/3\ntest_closeness_paths(paths)\n</pre> def test_closeness_paths(simple_paths_centralities):     c = closeness(simple_paths_centralities, normalized=False)     assert c[0] == 0.0     # 1 reachable from 0 and 2 in one step     assert c[1] == 1/1 + 1/1     assert c[2] == 0     # 3 reachable from 1 in one step, from 0 and 3 in two steps     assert c[3] == 1 + 1/2 + 1/2     assert c[4] == 1     # 5 reachable from 3 in one step, from 1 in two steps, from 2 in three steps     assert c[5] == 1 + 1/2 + 1/3 test_closeness_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre>"},{"location":"tutorial/xx_test_random_walks/","title":"Xx test random walks","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nprint('Running on', pp.config['torch']['device'])\nimport torch\nfrom pathpyG.processes.random_walk import RandomWalk, HigherOrderRandomWalk\n</pre> import pathpyG as pp print('Running on', pp.config['torch']['device']) import torch from pathpyG.processes.random_walk import RandomWalk, HigherOrderRandomWalk  <pre>Running on cpu\n</pre> In\u00a0[2]: Copied! <pre>g = pp.io.read_netzschleuder_network('karate', '77')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_network('karate', '77') print(g) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n\nNode attributes\n\tnode__pos\t\t&lt;class 'list'&gt;\n\tnode_name\t\t&lt;class 'list'&gt;\n\tnode_groups\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\turl\t\t&lt;class 'str'&gt;\n\tcitation\t\t&lt;class 'str'&gt;\n\tdescription\t\t&lt;class 'str'&gt;\n\tname\t\t&lt;class 'str'&gt;\n\ttags\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[3]: Copied! <pre>rw = RandomWalk(g)\n</pre> rw = RandomWalk(g) In\u00a0[4]: Copied! <pre>data = rw.run_experiment(steps=100,runs=range(34))\n</pre> data = rw.run_experiment(steps=100,runs=range(34)) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 34/34 [00:00&lt;00:00, 347.70it/s]\n</pre> In\u00a0[5]: Copied! <pre>data\n</pre> data Out[5]: run_id seed time node state 0 0 0 0 0 True 1 0 0 0 1 False 2 0 0 0 2 False 3 0 0 0 3 False 4 0 0 0 4 False ... ... ... ... ... ... 7951 33 33 98 1 False 7952 33 33 99 0 True 7953 33 33 99 21 False 7954 33 33 100 3 True 7955 33 33 100 0 False <p>7956 rows \u00d7 5 columns</p> In\u00a0[7]: Copied! <pre>paths = rw.get_paths(data)\n</pre> paths = rw.get_paths(data) <pre>[0, 8, 32, 31, 32, 22, 32, 8, 33, 30, 1, 30, 32, 20, 33, 14, 32, 15, 33, 13, 1, 21, 1, 30, 33, 13, 1, 19, 1, 7, 0, 13, 33, 9, 33, 18, 33, 13, 0, 5, 6, 0, 1, 2, 7, 0, 12, 0, 12, 0, 17, 1, 30, 32, 23, 32, 22, 32, 23, 25, 24, 25, 23, 33, 23, 29, 33, 27, 24, 25, 23, 25, 24, 27, 23, 25, 23, 27, 24, 31, 33, 23, 33, 13, 2, 7, 0, 19, 0, 6, 16, 5, 10, 0, 5, 10, 0, 19, 33, 27, 24]\n[1, 0, 31, 0, 5, 6, 4, 6, 16, 6, 16, 6, 0, 1, 30, 32, 31, 32, 30, 1, 30, 33, 20, 32, 2, 8, 2, 28, 2, 0, 10, 4, 6, 4, 10, 0, 8, 32, 20, 32, 18, 32, 31, 24, 25, 31, 25, 31, 32, 2, 27, 2, 3, 1, 3, 13, 33, 29, 23, 29, 32, 29, 33, 30, 33, 23, 29, 32, 20, 33, 29, 26, 33, 28, 31, 25, 23, 29, 32, 14, 32, 14, 33, 32, 2, 28, 2, 3, 2, 32, 8, 32, 18, 33, 9, 2, 28, 33, 27, 33, 29]\n[2, 0, 19, 33, 31, 32, 30, 1, 3, 0, 21, 1, 7, 0, 19, 1, 3, 2, 27, 2, 13, 2, 27, 33, 23, 33, 29, 32, 33, 20, 32, 20, 33, 32, 33, 31, 25, 23, 27, 33, 9, 33, 30, 8, 30, 8, 0, 19, 33, 15, 32, 29, 23, 25, 24, 27, 33, 27, 2, 28, 31, 24, 25, 24, 27, 24, 25, 31, 33, 27, 24, 31, 32, 2, 32, 15, 33, 23, 25, 23, 25, 31, 0, 3, 0, 5, 0, 11, 0, 4, 6, 4, 10, 0, 11, 0, 2, 9, 33, 28, 31]\n[3, 7, 0, 5, 16, 6, 16, 6, 5, 6, 16, 6, 0, 3, 0, 3, 13, 1, 7, 0, 7, 3, 2, 1, 19, 0, 11, 0, 31, 33, 9, 33, 19, 33, 27, 23, 29, 26, 29, 32, 8, 0, 11, 0, 17, 1, 17, 1, 2, 27, 24, 31, 25, 23, 32, 20, 32, 23, 32, 22, 32, 29, 33, 26, 33, 18, 33, 20, 32, 22, 32, 29, 26, 33, 28, 2, 8, 30, 8, 2, 27, 24, 27, 23, 32, 30, 33, 20, 33, 28, 33, 27, 23, 29, 26, 33, 18, 32, 30, 32, 29]\n[4, 10, 0, 12, 3, 1, 0, 2, 0, 7, 1, 0, 19, 33, 26, 33, 13, 3, 0, 7, 0, 3, 2, 28, 31, 0, 11, 0, 6, 4, 6, 4, 10, 0, 12, 0, 11, 0, 3, 0, 31, 33, 28, 2, 8, 2, 28, 33, 8, 30, 32, 18, 32, 33, 23, 27, 33, 14, 32, 29, 23, 25, 23, 29, 33, 15, 32, 14, 33, 32, 30, 32, 8, 0, 2, 27, 23, 27, 24, 25, 23, 27, 23, 29, 26, 33, 13, 2, 32, 31, 32, 2, 28, 33, 13, 3, 0, 10, 0, 2, 9]\n[5, 6, 0, 10, 5, 10, 0, 5, 0, 11, 0, 4, 6, 16, 5, 0, 21, 1, 0, 13, 0, 1, 17, 0, 31, 32, 20, 33, 14, 33, 28, 33, 20, 32, 20, 32, 15, 32, 14, 33, 29, 26, 29, 32, 18, 32, 2, 9, 33, 26, 33, 26, 33, 26, 29, 23, 27, 33, 31, 32, 8, 30, 1, 0, 2, 13, 0, 10, 5, 6, 0, 31, 24, 31, 33, 31, 0, 2, 1, 19, 1, 17, 0, 4, 0, 17, 1, 17, 1, 13, 3, 0, 10, 0, 5, 6, 4, 0, 17, 0, 19]\n[6, 0, 10, 5, 16, 6, 4, 6, 5, 6, 0, 31, 32, 2, 7, 3, 12, 3, 0, 13, 33, 31, 25, 31, 33, 20, 33, 23, 27, 33, 18, 32, 22, 32, 30, 33, 13, 1, 0, 6, 5, 16, 6, 5, 0, 7, 0, 13, 2, 13, 2, 3, 1, 19, 1, 17, 0, 6, 5, 0, 3, 0, 6, 5, 6, 4, 6, 0, 3, 1, 21, 0, 4, 10, 5, 16, 5, 6, 16, 5, 0, 12, 0, 31, 32, 31, 25, 31, 32, 30, 33, 20, 32, 30, 33, 15, 32, 22, 32, 23, 33]\n[7, 0, 8, 2, 7, 2, 9, 33, 15, 32, 29, 23, 29, 32, 23, 25, 24, 25, 23, 27, 23, 32, 15, 32, 30, 8, 0, 7, 1, 19, 0, 17, 0, 21, 0, 4, 6, 16, 6, 0, 10, 4, 10, 5, 10, 5, 10, 0, 6, 0, 11, 0, 5, 10, 4, 6, 16, 5, 10, 5, 0, 17, 1, 30, 8, 2, 32, 33, 29, 33, 13, 3, 2, 0, 10, 0, 1, 19, 33, 27, 23, 32, 15, 32, 33, 30, 8, 0, 21, 1, 21, 1, 13, 33, 26, 33, 19, 0, 8, 2, 9]\n[8, 32, 33, 26, 29, 32, 15, 32, 20, 32, 31, 24, 27, 33, 27, 23, 25, 24, 25, 24, 25, 31, 24, 31, 24, 25, 23, 32, 29, 33, 31, 25, 24, 27, 23, 27, 2, 3, 7, 2, 32, 29, 33, 27, 33, 23, 33, 23, 27, 33, 23, 25, 24, 25, 31, 32, 14, 33, 31, 28, 31, 33, 15, 33, 27, 23, 29, 33, 20, 33, 28, 33, 13, 3, 2, 27, 24, 31, 0, 19, 33, 14, 33, 31, 0, 1, 19, 33, 32, 33, 28, 33, 13, 0, 8, 32, 8, 32, 22, 32, 8]\n[9, 33, 23, 33, 31, 25, 23, 25, 24, 31, 25, 24, 25, 24, 25, 23, 29, 23, 25, 24, 25, 31, 28, 2, 13, 0, 7, 2, 3, 0, 11, 0, 21, 0, 17, 0, 8, 30, 1, 7, 1, 3, 7, 3, 12, 3, 2, 8, 2, 0, 2, 32, 23, 29, 33, 28, 2, 7, 1, 30, 1, 0, 19, 33, 32, 8, 30, 33, 13, 0, 31, 25, 23, 27, 24, 31, 28, 2, 32, 33, 9, 2, 1, 3, 1, 21, 1, 2, 27, 23, 33, 23, 32, 30, 8, 2, 13, 1, 0, 11, 0]\n[10, 4, 10, 4, 10, 4, 10, 4, 10, 4, 0, 13, 33, 28, 31, 24, 31, 25, 24, 27, 23, 32, 15, 32, 23, 27, 24, 25, 23, 29, 23, 27, 23, 32, 22, 32, 2, 7, 0, 5, 0, 4, 6, 5, 16, 5, 16, 6, 0, 19, 33, 26, 29, 32, 8, 30, 8, 32, 14, 33, 18, 32, 20, 32, 31, 28, 31, 25, 31, 0, 5, 16, 5, 10, 4, 0, 31, 0, 10, 5, 6, 5, 16, 6, 4, 6, 16, 5, 6, 5, 6, 0, 11, 0, 4, 10, 5, 16, 5, 16, 5]\n[11, 0, 2, 9, 33, 27, 24, 27, 2, 7, 1, 21, 0, 5, 0, 1, 19, 33, 20, 32, 23, 29, 26, 29, 33, 18, 33, 13, 0, 5, 0, 6, 16, 5, 6, 4, 6, 0, 5, 10, 0, 11, 0, 4, 6, 5, 0, 31, 25, 31, 24, 25, 24, 25, 24, 27, 33, 15, 33, 30, 1, 3, 12, 0, 8, 30, 33, 29, 26, 29, 33, 31, 25, 31, 33, 23, 25, 23, 32, 8, 32, 2, 9, 33, 9, 2, 32, 15, 33, 14, 32, 8, 30, 33, 29, 32, 2, 32, 33, 9, 2]\n[12, 0, 6, 16, 6, 0, 21, 1, 30, 8, 2, 0, 4, 10, 5, 6, 5, 0, 3, 12, 0, 1, 0, 8, 30, 1, 19, 1, 21, 1, 21, 0, 17, 0, 13, 33, 29, 23, 33, 30, 1, 21, 1, 13, 33, 14, 33, 32, 2, 32, 18, 32, 18, 33, 18, 32, 15, 33, 18, 33, 32, 14, 32, 30, 1, 13, 1, 17, 0, 5, 6, 16, 6, 4, 6, 0, 8, 33, 27, 2, 9, 33, 30, 33, 13, 0, 1, 21, 0, 1, 13, 1, 17, 0, 7, 2, 27, 2, 32, 30, 32]\n[13, 3, 2, 3, 12, 3, 0, 11, 0, 1, 2, 27, 2, 1, 2, 28, 33, 29, 33, 18, 33, 31, 28, 2, 0, 17, 1, 3, 1, 21, 1, 17, 1, 17, 0, 1, 7, 1, 13, 1, 2, 8, 32, 14, 33, 31, 28, 31, 28, 2, 7, 2, 28, 2, 27, 33, 15, 32, 14, 33, 23, 33, 32, 20, 32, 8, 33, 8, 30, 1, 2, 1, 13, 0, 6, 0, 13, 1, 2, 27, 23, 29, 23, 27, 2, 27, 2, 8, 0, 13, 1, 3, 0, 5, 16, 5, 16, 5, 10, 0, 13]\n[14, 32, 8, 30, 32, 33, 23, 29, 32, 33, 8, 30, 33, 27, 24, 27, 33, 8, 0, 31, 24, 27, 24, 31, 25, 23, 32, 33, 19, 33, 19, 1, 17, 0, 5, 16, 6, 0, 8, 30, 32, 23, 25, 31, 28, 31, 0, 4, 6, 16, 6, 4, 10, 5, 10, 0, 7, 0, 19, 1, 19, 1, 2, 8, 2, 8, 30, 8, 0, 5, 16, 5, 0, 17, 0, 17, 1, 21, 0, 19, 1, 30, 33, 31, 24, 25, 24, 31, 28, 2, 13, 2, 9, 33, 19, 1, 3, 13, 0, 11, 0]\n[15, 33, 26, 33, 27, 23, 29, 23, 27, 2, 8, 33, 15, 33, 27, 23, 25, 31, 33, 9, 33, 29, 32, 23, 33, 20, 33, 31, 33, 30, 1, 21, 1, 13, 3, 1, 2, 28, 31, 25, 24, 27, 33, 8, 30, 1, 2, 13, 33, 30, 32, 31, 28, 33, 30, 8, 0, 2, 0, 31, 25, 23, 33, 27, 23, 32, 18, 33, 28, 31, 25, 23, 32, 8, 33, 20, 32, 23, 33, 8, 33, 18, 33, 31, 24, 27, 23, 27, 23, 33, 8, 0, 8, 2, 32, 14, 33, 19, 1, 0, 6]\n[16, 5, 16, 6, 5, 6, 4, 10, 0, 2, 28, 33, 19, 1, 19, 0, 7, 2, 7, 2, 7, 0, 7, 1, 2, 7, 0, 19, 1, 13, 0, 5, 10, 0, 13, 3, 13, 2, 27, 24, 27, 24, 25, 31, 0, 8, 33, 8, 32, 2, 9, 33, 18, 32, 29, 23, 25, 31, 33, 29, 33, 30, 8, 2, 13, 2, 3, 13, 33, 19, 33, 29, 32, 2, 1, 21, 0, 2, 27, 23, 32, 14, 33, 20, 32, 31, 32, 18, 33, 9, 2, 27, 24, 31, 32, 15, 33, 13, 2, 3, 1]\n[17, 0, 10, 0, 7, 0, 12, 3, 12, 3, 2, 0, 19, 33, 29, 23, 29, 23, 33, 26, 33, 20, 33, 9, 2, 1, 19, 0, 8, 30, 8, 32, 22, 32, 15, 32, 20, 33, 32, 23, 27, 2, 27, 24, 27, 23, 29, 23, 33, 29, 32, 15, 32, 14, 33, 32, 22, 32, 15, 32, 23, 29, 33, 19, 1, 21, 1, 2, 13, 1, 7, 1, 0, 31, 25, 24, 27, 23, 33, 30, 8, 32, 14, 33, 31, 0, 6, 16, 6, 16, 6, 16, 5, 16, 5, 10, 4, 6, 16, 5, 0]\n[18, 32, 20, 33, 29, 23, 29, 26, 29, 26, 29, 26, 29, 32, 2, 8, 32, 15, 33, 9, 33, 19, 1, 7, 0, 13, 2, 28, 31, 33, 26, 29, 23, 32, 15, 32, 30, 33, 26, 33, 19, 0, 10, 5, 6, 4, 10, 5, 6, 16, 6, 4, 6, 4, 0, 10, 5, 0, 17, 1, 0, 21, 1, 19, 33, 32, 22, 32, 29, 23, 32, 18, 33, 8, 30, 1, 2, 32, 20, 33, 31, 33, 20, 32, 23, 32, 30, 33, 26, 33, 28, 33, 15, 33, 26, 29, 33, 13, 33, 28, 31]\n[19, 0, 12, 0, 19, 0, 17, 0, 13, 1, 3, 12, 3, 2, 0, 2, 8, 32, 2, 27, 23, 33, 32, 31, 25, 31, 28, 33, 28, 33, 19, 0, 31, 24, 27, 24, 25, 24, 31, 33, 23, 27, 23, 33, 28, 31, 25, 31, 33, 32, 15, 33, 18, 33, 29, 33, 32, 20, 32, 15, 32, 30, 1, 30, 32, 33, 23, 27, 2, 13, 1, 21, 1, 30, 32, 2, 9, 33, 18, 33, 19, 1, 13, 2, 9, 33, 32, 29, 33, 8, 33, 32, 14, 32, 20, 32, 8, 0, 3, 1, 30]\n[20, 33, 8, 32, 23, 25, 31, 33, 8, 30, 32, 2, 8, 33, 14, 32, 8, 30, 1, 17, 0, 5, 16, 5, 0, 17, 0, 3, 12, 0, 19, 1, 17, 0, 13, 0, 6, 5, 16, 5, 0, 31, 24, 27, 24, 31, 33, 30, 1, 7, 1, 19, 1, 21, 1, 17, 0, 3, 12, 3, 13, 2, 0, 11, 0, 2, 32, 18, 33, 9, 33, 13, 0, 6, 16, 6, 0, 31, 25, 23, 32, 15, 33, 32, 31, 28, 2, 0, 11, 0, 8, 30, 32, 29, 32, 22, 32, 29, 23, 25, 31]\n[21, 1, 30, 32, 18, 32, 33, 15, 32, 8, 33, 32, 29, 33, 15, 33, 27, 2, 32, 22, 32, 30, 8, 32, 8, 2, 27, 24, 27, 24, 27, 23, 27, 2, 13, 0, 17, 0, 2, 13, 0, 21, 1, 30, 1, 2, 7, 3, 7, 1, 2, 13, 0, 17, 1, 13, 0, 1, 19, 0, 8, 30, 1, 17, 1, 21, 1, 2, 9, 33, 15, 32, 33, 20, 33, 15, 32, 20, 32, 30, 33, 13, 3, 13, 3, 13, 1, 30, 32, 31, 24, 25, 24, 27, 2, 28, 2, 8, 30, 32, 29]\n[22, 32, 8, 32, 33, 29, 32, 22, 32, 18, 32, 29, 32, 31, 24, 25, 23, 29, 33, 28, 33, 28, 2, 3, 13, 0, 7, 2, 28, 33, 14, 32, 14, 33, 15, 32, 31, 28, 31, 28, 33, 26, 33, 8, 30, 1, 30, 33, 20, 33, 32, 20, 32, 2, 27, 2, 9, 33, 26, 33, 18, 32, 20, 33, 29, 23, 29, 26, 29, 33, 27, 2, 32, 30, 8, 30, 33, 27, 23, 29, 32, 20, 32, 18, 32, 33, 26, 29, 32, 14, 32, 15, 32, 31, 33, 20, 32, 23, 33, 15, 32]\n[23, 25, 23, 32, 29, 26, 33, 9, 2, 1, 17, 1, 21, 1, 7, 0, 21, 1, 30, 32, 15, 33, 9, 33, 9, 33, 27, 24, 25, 23, 33, 27, 33, 32, 14, 32, 22, 32, 31, 28, 31, 25, 31, 32, 14, 33, 27, 23, 25, 24, 27, 24, 31, 25, 24, 25, 23, 27, 2, 27, 23, 32, 18, 33, 19, 0, 1, 7, 0, 10, 4, 10, 5, 16, 6, 16, 6, 5, 6, 16, 5, 10, 5, 16, 5, 6, 4, 10, 4, 10, 5, 16, 5, 6, 5, 10, 0, 2, 1, 19, 1]\n[24, 25, 23, 25, 31, 32, 29, 33, 30, 32, 15, 32, 23, 32, 30, 8, 30, 33, 31, 28, 2, 9, 2, 3, 2, 8, 2, 27, 23, 32, 14, 33, 19, 1, 3, 12, 3, 0, 12, 3, 13, 3, 1, 17, 1, 21, 1, 13, 3, 12, 3, 13, 1, 21, 1, 21, 1, 13, 3, 1, 7, 1, 19, 1, 2, 7, 1, 0, 5, 6, 0, 2, 7, 2, 0, 12, 3, 7, 1, 2, 3, 7, 2, 3, 12, 3, 1, 19, 0, 11, 0, 17, 1, 30, 8, 32, 20, 32, 30, 1, 17]\n[25, 31, 0, 11, 0, 31, 24, 25, 24, 31, 24, 27, 33, 19, 33, 20, 32, 14, 32, 2, 8, 2, 3, 12, 3, 1, 2, 0, 13, 2, 7, 1, 30, 32, 2, 0, 10, 0, 6, 0, 8, 32, 31, 28, 2, 13, 0, 1, 17, 0, 10, 4, 0, 2, 7, 0, 17, 0, 21, 1, 13, 2, 1, 7, 2, 1, 30, 33, 23, 29, 23, 32, 2, 7, 3, 1, 21, 0, 12, 0, 13, 1, 3, 7, 3, 0, 4, 10, 5, 10, 0, 3, 12, 3, 12, 0, 5, 6, 5, 0, 8]\n[26, 29, 23, 27, 24, 25, 24, 25, 31, 0, 2, 9, 33, 8, 32, 22, 32, 22, 32, 33, 32, 14, 33, 26, 33, 23, 29, 26, 33, 27, 33, 28, 31, 24, 31, 0, 11, 0, 13, 33, 27, 2, 9, 2, 1, 0, 2, 13, 33, 19, 33, 15, 33, 15, 32, 22, 32, 23, 25, 24, 25, 24, 31, 0, 31, 0, 13, 2, 0, 3, 0, 3, 2, 27, 24, 25, 24, 25, 24, 31, 32, 33, 32, 29, 33, 9, 2, 32, 22, 32, 14, 32, 8, 33, 14, 33, 26, 33, 31, 28, 33]\n[27, 24, 27, 2, 7, 2, 0, 12, 0, 10, 5, 10, 5, 16, 5, 16, 6, 0, 13, 0, 1, 17, 1, 7, 2, 0, 12, 0, 10, 0, 21, 1, 30, 33, 30, 32, 31, 0, 6, 4, 0, 12, 0, 19, 33, 20, 32, 29, 26, 33, 8, 0, 2, 13, 3, 1, 13, 2, 27, 24, 27, 2, 3, 7, 1, 30, 8, 30, 1, 2, 32, 22, 32, 23, 33, 8, 32, 31, 32, 33, 8, 32, 31, 33, 8, 32, 2, 0, 17, 0, 21, 0, 7, 3, 2, 1, 17, 0, 11, 0, 8]\n[28, 31, 24, 31, 33, 30, 1, 3, 2, 7, 2, 3, 2, 8, 2, 9, 33, 23, 29, 26, 33, 27, 33, 18, 33, 29, 33, 13, 0, 10, 0, 11, 0, 4, 0, 4, 10, 0, 31, 24, 27, 33, 15, 32, 22, 32, 30, 32, 29, 26, 29, 23, 33, 14, 32, 14, 32, 22, 32, 14, 32, 23, 29, 23, 29, 32, 22, 32, 14, 32, 8, 30, 8, 32, 23, 25, 31, 28, 2, 0, 7, 0, 17, 0, 7, 3, 0, 17, 0, 31, 33, 29, 23, 29, 32, 30, 32, 8, 2, 27, 33]\n[29, 26, 29, 33, 19, 33, 15, 32, 8, 2, 1, 2, 27, 23, 25, 23, 27, 23, 32, 2, 27, 33, 31, 32, 31, 0, 2, 27, 23, 27, 2, 3, 0, 2, 3, 0, 3, 13, 33, 19, 0, 4, 0, 12, 0, 3, 7, 0, 6, 0, 17, 0, 13, 2, 27, 2, 7, 2, 27, 23, 29, 33, 27, 33, 20, 33, 31, 28, 31, 25, 31, 24, 25, 24, 31, 0, 31, 32, 31, 24, 31, 28, 2, 27, 2, 1, 0, 5, 6, 0, 13, 0, 6, 0, 19, 33, 27, 2, 0, 13, 33]\n[30, 33, 9, 2, 3, 13, 3, 13, 0, 10, 5, 6, 16, 6, 4, 0, 2, 28, 2, 9, 2, 3, 13, 33, 26, 29, 33, 31, 24, 27, 24, 31, 28, 31, 33, 13, 0, 13, 3, 13, 1, 30, 1, 17, 0, 12, 3, 12, 0, 2, 3, 12, 3, 0, 10, 4, 0, 2, 13, 2, 3, 2, 9, 33, 13, 3, 2, 9, 33, 32, 23, 25, 24, 25, 23, 32, 23, 29, 32, 15, 32, 8, 0, 17, 0, 19, 1, 2, 9, 2, 13, 3, 2, 13, 33, 19, 1, 30, 32, 33, 20]\n[31, 0, 3, 2, 0, 4, 6, 0, 13, 1, 19, 33, 13, 0, 8, 33, 23, 29, 26, 29, 26, 29, 33, 27, 24, 25, 31, 0, 13, 1, 30, 1, 7, 0, 7, 2, 28, 31, 25, 23, 32, 14, 33, 28, 2, 3, 0, 7, 2, 13, 3, 1, 0, 5, 16, 5, 0, 21, 1, 0, 21, 0, 21, 1, 13, 1, 21, 0, 2, 32, 18, 33, 30, 32, 8, 2, 27, 24, 31, 33, 19, 1, 0, 17, 0, 12, 0, 4, 10, 5, 10, 4, 10, 4, 6, 0, 6, 5, 6, 16, 6]\n[32, 22, 32, 29, 26, 33, 20, 33, 9, 2, 13, 3, 0, 5, 16, 6, 16, 6, 5, 10, 5, 6, 5, 16, 6, 0, 2, 9, 2, 9, 33, 20, 33, 15, 33, 30, 8, 30, 33, 18, 33, 14, 33, 28, 2, 13, 33, 20, 32, 33, 30, 33, 23, 25, 24, 27, 23, 33, 23, 27, 33, 19, 33, 18, 32, 29, 32, 23, 27, 24, 31, 33, 18, 33, 9, 2, 32, 23, 29, 33, 31, 28, 33, 27, 23, 29, 23, 32, 22, 32, 33, 26, 29, 33, 28, 33, 27, 24, 27, 2, 7]\n[33, 15, 33, 20, 32, 2, 27, 24, 31, 28, 31, 32, 22, 32, 30, 33, 32, 30, 8, 32, 20, 32, 23, 29, 26, 33, 19, 1, 21, 0, 6, 16, 6, 0, 1, 0, 3, 0, 4, 6, 5, 16, 6, 4, 6, 16, 6, 5, 6, 4, 6, 16, 6, 4, 10, 5, 0, 13, 0, 17, 0, 6, 0, 4, 10, 0, 10, 4, 6, 16, 6, 4, 0, 7, 1, 17, 0, 8, 33, 13, 2, 32, 8, 30, 32, 14, 33, 14, 33, 9, 2, 13, 3, 1, 30, 1, 3, 1, 21, 0, 3]\n</pre> In\u00a0[14]: Copied! <pre>paths.dags[0].edge_index\n</pre> paths.dags[0].edge_index Out[14]: <pre>tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n          98,  99],\n        [  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n          99, 100]])</pre> In\u00a0[8]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(paths, max_order=3)\ng2 = m.layers[2]\nprint(g2)\n</pre> m = pp.MultiOrderModel.from_DAGs(paths, max_order=3) g2 = m.layers[2] print(g2) <pre>Directed graph with 154 nodes and 1005 edges\n\nNode attributes\n\tnode_sequences\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([154, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1005])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[9]: Copied! <pre>#print(g_ho)\n</pre> #print(g_ho) In\u00a0[10]: Copied! <pre>#for v in g_ho.nodes:\n#    print(v)\n</pre> #for v in g_ho.nodes: #    print(v) In\u00a0[9]: Copied! <pre>g2= pp.Graph.from_edge_list([\n    ['a', 'b'],\n    ['b', 'c'],\n    ['c', 'd'],\n    ['d', 'e'],\n    ['e', 'f'],\n    ['f', 'g'],\n    ['g', 'h'],\n    ['h', 'i'],\n    ['i', 'j'],\n    ['j', 'k'],\n    ['k', 'l'],\n    ['l', 'm'],\n    ['m', 'n'],\n    ['n', 'o'],\n    ['o', 'a']\n])\n</pre> g2= pp.Graph.from_edge_list([     ['a', 'b'],     ['b', 'c'],     ['c', 'd'],     ['d', 'e'],     ['e', 'f'],     ['f', 'g'],     ['g', 'h'],     ['h', 'i'],     ['i', 'j'],     ['j', 'k'],     ['k', 'l'],     ['l', 'm'],     ['m', 'n'],     ['n', 'o'],     ['o', 'a'] ]) In\u00a0[10]: Copied! <pre>g2.mapping.to_idx('b')\n</pre> g2.mapping.to_idx('b') Out[10]: <pre>1</pre> In\u00a0[11]: Copied! <pre>rw2 = RandomWalk(g2)\n</pre> rw2 = RandomWalk(g2) In\u00a0[13]: Copied! <pre>data2 = rw2.run_experiment(steps=20,runs=['a','b'])\n</pre> data2 = rw2.run_experiment(steps=20,runs=['a','b']) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 1900.02it/s]\n</pre> In\u00a0[15]: Copied! <pre>data2\n</pre> data2 Out[15]: run_id seed time node state 0 0 a 0 a True 1 0 a 0 b False 2 0 a 0 c False 3 0 a 0 d False 4 0 a 0 e False ... ... ... ... ... ... 105 1 b 18 d False 106 1 b 19 f True 107 1 b 19 e False 108 1 b 20 g True 109 1 b 20 f False <p>110 rows \u00d7 5 columns</p> In\u00a0[16]: Copied! <pre>paths2 = rw2.get_paths(data2)\n\npaths2.paths\n</pre> paths2 = rw2.get_paths(data2)  paths2.paths Out[16]: <pre>{0: tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,\n           3,  4],\n         [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,\n           4,  5]], dtype=torch.int32),\n 1: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,\n           4,  5],\n         [ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,\n           5,  6]], dtype=torch.int32)}</pre> In\u00a0[17]: Copied! <pre>pp.plot(g2);\n</pre> pp.plot(g2); In\u00a0[18]: Copied! <pre>g2.mapping.idx_to_id\n</pre> g2.mapping.idx_to_id Out[18]: <pre>{0: 'a',\n 1: 'b',\n 2: 'c',\n 3: 'd',\n 4: 'e',\n 5: 'f',\n 6: 'g',\n 7: 'h',\n 8: 'i',\n 9: 'j',\n 10: 'k',\n 11: 'l',\n 12: 'm',\n 13: 'n',\n 14: 'o'}</pre> In\u00a0[19]: Copied! <pre>g2_ho = pp.HigherOrderGraph(paths2, order = 2)\n</pre> g2_ho = pp.HigherOrderGraph(paths2, order = 2) In\u00a0[20]: Copied! <pre>pp.plot(g2_ho,node_label=[g2_ho.mapping.to_id(x) for x in range(g2_ho.N)]);\n</pre> pp.plot(g2_ho,node_label=[g2_ho.mapping.to_id(x) for x in range(g2_ho.N)]); In\u00a0[14]: Copied! <pre>g3 = pp.Graph.from_edge_list([\n    ['a','b'],\n    ['b','c'],\n    ['c','a'],\n    ['c','d'],\n    ['d','a']\n    ])\n\ng3.data['edge_weight'] = torch.tensor([[1],[1],[2],[1],[1]])\n</pre> g3 = pp.Graph.from_edge_list([     ['a','b'],     ['b','c'],     ['c','a'],     ['c','d'],     ['d','a']     ])  g3.data['edge_weight'] = torch.tensor([[1],[1],[2],[1],[1]]) In\u00a0[15]: Copied! <pre>pp.plot(g3, node_label= [g3.mapping.to_id(x) for x in range(g3.N)]);\n</pre> pp.plot(g3, node_label= [g3.mapping.to_id(x) for x in range(g3.N)]); In\u00a0[23]: Copied! <pre>g3.mapping.id_to_idx\n</pre> g3.mapping.id_to_idx Out[23]: <pre>{'a': 0, 'b': 1, 'c': 2, 'd': 3}</pre> In\u00a0[18]: Copied! <pre>paths = pp.DAGData(g3.mapping)\npaths.append_walk(['a','b','c'],weight=1)\npaths.append_walk(['b','c','a'],weight=1)\npaths.append_walk(['b','c','d'],weight=0.2)\npaths.append_walk(['c','a','b'],weight=1)\npaths.append_walk(['c','d','a'],weight=0.2)\npaths.append_walk(['d','a','b'],weight=1)\n</pre> paths = pp.DAGData(g3.mapping) paths.append_walk(['a','b','c'],weight=1) paths.append_walk(['b','c','a'],weight=1) paths.append_walk(['b','c','d'],weight=0.2) paths.append_walk(['c','a','b'],weight=1) paths.append_walk(['c','d','a'],weight=0.2) paths.append_walk(['d','a','b'],weight=1) In\u00a0[19]: Copied! <pre>paths.dags\n</pre> paths.dags Out[19]: <pre>[Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=0.20000000298023224),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=0.20000000298023224),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1)]</pre> In\u00a0[20]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(paths, max_order=3)\ng3_ho = m.layers[2]\n</pre> m = pp.MultiOrderModel.from_DAGs(paths, max_order=3) g3_ho = m.layers[2] In\u00a0[22]: Copied! <pre>pp.plot(g3_ho, node_label = [g3_ho.mapping.to_id(x) for x in range(g3_ho.N)]);\n</pre> pp.plot(g3_ho, node_label = [g3_ho.mapping.to_id(x) for x in range(g3_ho.N)]); In\u00a0[23]: Copied! <pre>rw = HigherOrderRandomWalk(g3_ho, g3, weight=True)\n</pre> rw = HigherOrderRandomWalk(g3_ho, g3, weight=True) In\u00a0[24]: Copied! <pre>data = rw.run_experiment(steps=100, runs=list(g3_ho.nodes))\n</pre> data = rw.run_experiment(steps=100, runs=list(g3_ho.nodes)) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 511.38it/s]\n</pre> In\u00a0[25]: Copied! <pre>data\n</pre> data Out[25]: run_id seed time node state 0 0 (a, b) 0 (a, b) True 1 0 (a, b) 0 (b, c) False 2 0 (a, b) 0 (c, a) False 3 0 (a, b) 0 (c, d) False 4 0 (a, b) 0 (d, a) False ... ... ... ... ... ... 1020 4 (d, a) 98 (b, c) False 1021 4 (d, a) 99 (d, a) True 1022 4 (d, a) 99 (c, d) False 1023 4 (d, a) 100 (a, b) True 1024 4 (d, a) 100 (d, a) False <p>1025 rows \u00d7 5 columns</p> In\u00a0[29]: Copied! <pre>path = rw.get_paths(data,[0,1])\nprint(path)\n</pre> path = rw.get_paths(data,[0,1]) print(path) <pre>DAGData with 2 dags with total weight 2.0\n</pre> In\u00a0[30]: Copied! <pre>path.get_walk(0)\n</pre> path.get_walk(0) Out[30]: <pre>('a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b')</pre> In\u00a0[51]: Copied! <pre>g3.mapping.idx_to_id\n</pre> g3.mapping.idx_to_id Out[51]: <pre>{0: 'a', 1: 'b', 2: 'c', 3: 'd'}</pre> In\u00a0[56]: Copied! <pre>for time,_ in rw.simulation_run(steps=50, seed=('a','b')):\n    print('Current node = {0}'.format(rw.first_order_node(rw.current_node)))\n    print(rw._first_order_visitations)\n</pre> for time,_ in rw.simulation_run(steps=50, seed=('a','b')):     print('Current node = {0}'.format(rw.first_order_node(rw.current_node)))     print(rw._first_order_visitations)  <pre>Current node = c\n[0. 1. 1. 0.]\nCurrent node = a\n[1. 1. 1. 0.]\nCurrent node = b\n[1. 2. 1. 0.]\nCurrent node = c\n[1. 2. 2. 0.]\nCurrent node = a\n[2. 2. 2. 0.]\nCurrent node = b\n[2. 3. 2. 0.]\nCurrent node = c\n[2. 3. 3. 0.]\nCurrent node = a\n[3. 3. 3. 0.]\nCurrent node = b\n[3. 4. 3. 0.]\nCurrent node = c\n[3. 4. 4. 0.]\nCurrent node = a\n[4. 4. 4. 0.]\nCurrent node = b\n[4. 5. 4. 0.]\nCurrent node = c\n[4. 5. 5. 0.]\nCurrent node = d\n[4. 5. 5. 1.]\nCurrent node = a\n[5. 5. 5. 1.]\nCurrent node = b\n[5. 6. 5. 1.]\nCurrent node = c\n[5. 6. 6. 1.]\nCurrent node = d\n[5. 6. 6. 2.]\nCurrent node = a\n[6. 6. 6. 2.]\nCurrent node = b\n[6. 7. 6. 2.]\nCurrent node = c\n[6. 7. 7. 2.]\nCurrent node = a\n[7. 7. 7. 2.]\nCurrent node = b\n[7. 8. 7. 2.]\nCurrent node = c\n[7. 8. 8. 2.]\nCurrent node = a\n[8. 8. 8. 2.]\nCurrent node = b\n[8. 9. 8. 2.]\nCurrent node = c\n[8. 9. 9. 2.]\nCurrent node = d\n[8. 9. 9. 3.]\nCurrent node = a\n[9. 9. 9. 3.]\nCurrent node = b\n[ 9. 10.  9.  3.]\nCurrent node = c\n[ 9. 10. 10.  3.]\nCurrent node = a\n[10. 10. 10.  3.]\nCurrent node = b\n[10. 11. 10.  3.]\nCurrent node = c\n[10. 11. 11.  3.]\nCurrent node = a\n[11. 11. 11.  3.]\nCurrent node = b\n[11. 12. 11.  3.]\nCurrent node = c\n[11. 12. 12.  3.]\nCurrent node = a\n[12. 12. 12.  3.]\nCurrent node = b\n[12. 13. 12.  3.]\nCurrent node = c\n[12. 13. 13.  3.]\nCurrent node = a\n[13. 13. 13.  3.]\nCurrent node = b\n[13. 14. 13.  3.]\nCurrent node = c\n[13. 14. 14.  3.]\nCurrent node = a\n[14. 14. 14.  3.]\nCurrent node = b\n[14. 15. 14.  3.]\nCurrent node = c\n[14. 15. 15.  3.]\nCurrent node = d\n[14. 15. 15.  4.]\nCurrent node = a\n[15. 15. 15.  4.]\nCurrent node = b\n[15. 16. 15.  4.]\nCurrent node = c\n[15. 16. 16.  4.]\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/xx_test_random_walks/#higher-order-random-walk","title":"Higher Order Random Walk\u00b6","text":""}]}