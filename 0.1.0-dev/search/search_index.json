{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pathpyG","text":"<p>This is the index page of the pathpyG documentation.</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#what-is-pathpyg","title":"What is pathpyG?","text":"<p>pathpyG is an Open Source package facilitating GPU-accelerated next-generation network analytics and graph learning for time series data on graphs.</p> <p>pathpyG is tailored to analyse time-stamped network data as well as sequential data that capture multiple short walks or paths observed in a graph or network. Examples for data that can be analysed with pathpyG include high-resolution time-stamped network data, dynamic social networks, user click streams on the Web, biological pathway data, directed acyclic graphs like citation networks, passenger trajectories in transportation networks, or trajectories of information propagation in social networks.</p> <p>pathpyG is fully integrated with jupyter, providing rich interactive visualisations of networks, temporal networks, and higher-order models. Visualisations can be exported to HTML5 files that can be shared and published on the Web.</p>"},{"location":"about/#what-is-the-science-behind-pathpyg","title":"What is the science behind pathpyG?","text":"<p>The theoretical foundation of this package, higher- and multi-order network models, was developed in the following peer-reviewed research articles:</p> <ol> <li>L Qarkaxhija, V Perri, I Scholtes: De Bruijn goes Neural: Causality-Aware Graph Neural Networks for Time Series Data on Dynamic Graphs, In Proceedings of the First Learning on Graphs Conference, PMLR 198:51:1-51:21, December 2022</li> <li>L Petrovic, I Scholtes: Learning the Markov order of paths in graphs, In Proceedings of WWW '22: The Web Conference 2022, Lyon, France, April 2022</li> <li>V Perri, I Scholtes: HOTVis: Higher-Order Time-Aware Visualisation of Dynamic Graphs, In Proceedings of the 28<sup>th</sup> International Symposium on Graph Drawing and Network Visualization (GD 2020), Vancouver, BC, Canada, September 15-18, 2020</li> <li>I Scholtes: When is a network a network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks, In KDD'17 - Proceedings of the 23<sup>rd</sup> ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, Nova Scotia, Canada, August 13-17, 2017</li> <li>I Scholtes, N Wider, A Garas: Higher-Order Aggregate Networks in the Analysis of Temporal Networks: Path structures and centralities, The European Physical Journal B, 89:61, March 2016</li> <li>I Scholtes, N Wider, R Pfitzner, A Garas, CJ Tessone, F Schweitzer: Causality-driven slow-down and speed-up of diffusion in non-Markovian temporal networks, Nature Communications, 5, September 2014</li> <li>R Pfitzner, I Scholtes, A Garas, CJ Tessone, F Schweitzer: Betweenness preference: Quantifying correlations in the topological dynamics of temporal networks, Phys Rev Lett, 110(19), 198701, May 2013</li> </ol> <p>A broader view on the importance of higher-order graph models for complex systems can be found in this overview article. </p>"},{"location":"contributing/","title":"Contributing","text":"<p>This project is open source and welcomes contributions. In the following sections, you will find information about how to contribute to this project, set up your environment correctly, how to document your code and more.</p>"},{"location":"contributing/#overview","title":"Overview","text":"<ul> <li>Setting up your environment</li> <li>Documentation</li> <li>Code Style</li> <li>Formatting</li> <li>Testing</li> <li>Benchmarking</li> </ul>"},{"location":"contributing/#setting-up-your-environment","title":"Setting up your environment","text":""},{"location":"contributing/#clone-the-repository","title":"Clone the Repository","text":"<p>The first step is to clone the repository. You can do this by running the following command: <pre><code>git clone https://github.com/pathpy/pathpyG\n</code></pre> If you do not have the rights to push to the repository, you can also fork the repository and clone your fork instead. From there you can create a pull request to the original repository.</p>"},{"location":"contributing/#installation","title":"Installation","text":"<p>To ensure version consistency, we use a Development Container for this project.   VSCode provides an easy-to-use extension for this. Check out their official documentation for more information. Once you've installed the extension successfully,   VSCode will recommend reopening the project in the Dev Container. You can also do this manually by clicking on the button in the bottom left corner of   VSCode and then selecting <code>Reopen in Container</code>.</p> Setup without Dev Containers <p>If you do not want to use Dev Containers, you can also install the dependencies into your virtual Python environment manually. We recommend that you follow the instructions provided on our getting started page. As last step, install the package in editable mode and include the dependencies necessary for testing, documentation and general development: <pre><code>pip install -e '.[dev,test,doc]'\n</code></pre></p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>This project uses <code>MkDocs</code> for documentation. It is a static site generator that creates the necessary <code>html</code>-files automatically from the <code>markdown</code>-files and  Group.svg Created using Figma 0.90  Jupyter notebooks in the <code>docs/</code>-directory and the <code>Python</code>-files in <code>src/</code>. The documentation is hosted on GitHub Pages.</p>"},{"location":"contributing/#hosting-the-documentation-locally","title":"Hosting the documentation locally","text":"<p>You can host the documentation locally with the following command: <pre><code>mkdocs serve\n</code></pre> The documentation is then available at <code>http://localhost:8000/</code>.</p> Actual Deployment <p>The development version of the documentation is deployed automatically to GitHub Pages when something is pushed to the <code>main</code>-branch. The workflow for deploying a new stable version needs to be triggered manually. You can find it in the <code>Actions</code>-tab of the repository. Both workflows use <code>mike</code> instead of <code>MkDocs</code> to enable versioning.</p>"},{"location":"contributing/#code-reference","title":"Code Reference","text":"<p>The <code>Code Reference</code> is generated automatically from the   Python source files. The docstrings should be formatted according to the Google Python Style Guide. Be sure to also use the advanced stuff like notes, tips and more. They can e.g. look as follows:</p> DocstringResult <pre><code>\"\"\"\nNote:\n    This is a note.\n\nTip: This is a heading\n    This is a tip.\n\"\"\"\n</code></pre> <p>Note</p> <p>This is a note.</p> <p>This is a heading</p> <p>This is a tip.</p> <p>See the documentation of the underlying griffe package for more details.</p> <p>To get an overview for each module, <code>mkdocstrings</code> automatically uses the docstrings from the <code>__init__.py</code> files in each module as description. Thus, do not forget to add a docstring to each <code>__init__.py</code> file.</p>"},{"location":"contributing/#tutorials","title":"Tutorials","text":"<p>The tutorials are written in  Group.svg Created using Figma 0.90  Jupyter notebooks. They are located in the <code>docs/</code>-directory. You can add new tutorials by adding the notebook to the <code>docs/tutorial/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The tutorials are automatically converted to <code>html</code>-files when the documentation is built.</p>"},{"location":"contributing/#adding-new-pages","title":"Adding new pages","text":"<p>You can add more pages to the documentation by adding a <code>markdown</code>-file to the <code>docs/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The pages are automatically converted to <code>html</code>-files when the documentation is built. We are using Material for MkDocs as a theme. It includes many great features like annotations, code blocks, diagrams, admonitions and more. Check out their documentation for more information.</p>"},{"location":"contributing/#code-style","title":"Code Style","text":"<p>We (soon) enforce code style guidelines with <code>pylint</code>, <code>flake8</code>, <code>mypy</code> and <code>pyright</code>. These packages are configured as defaults in the Dev Container setup via <code>VSCode</code> and the settings are saved in <code>pyproject.toml</code>. You can run them locally with the following commands:</p> <ul> <li><code>pylint</code>: A linter that checks for errors and code style violations.     <pre><code>pylint scr/ # (1)!\n</code></pre><ol> <li>This runs <code>pylint</code> on all files in <code>scr/</code>. You can also run <code>pylint</code> on a single file by specifying the path to the file instead.</li> </ol> </li> <li><code>flake8</code>: Another linter that checks for bad code smells and suspicious constructs.     <pre><code>flake8 . # (1)!\n</code></pre><ol> <li>This runs <code>flake8</code> on all files in the current directory. You can also run <code>flake8</code> on a single file or a subdirectory by specifying the path accordingly.</li> </ol> </li> <li><code>mypy</code>: A static type checker for Python.     <pre><code>mypy src/ # (1)!\n</code></pre><ol> <li>This runs <code>mypy</code> on all files in <code>src/</code>. You can also run <code>mypy</code> on a single file by specifying the path to the file instead.</li> </ol> </li> <li><code>pyright</code>: A second static type checker for Python.     <pre><code>pyright . # (1)!\n</code></pre><ol> <li>This runs <code>pyright</code> on all files in the current directory. You can also run it on a single file or a subdirectory by specifying the path accordingly.</li> </ol> </li> </ul>"},{"location":"contributing/#formatting","title":"Formatting","text":"<p>We use <code>black</code> for formatting. You can run it locally with the following command:</p> <pre><code>black . # (1)!\n</code></pre> <ol> <li>This command will format all files in the current directory. You can also run <code>black</code> on a single file or a subdirectory by specifying the path accordingly.</li> </ol> <p>We further use <code>isort</code> for sorting imports. You can run it locally with the following command: <pre><code>isort .\n</code></pre> The default keyboard shortcut for formatting in <code>VSCode</code> is <code>Alt + Shift + F</code>.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>We are using <code>pytest</code> for testing. You can run the tests locally with the following command: <pre><code>pytest\n</code></pre> The tests are located in the <code>tests/</code>-directory. We use <code>pytest-cov</code> to measure the test coverage and are aiming for 100% coverage with a hard limit of 80%. Tests will fail if the coverage drops below 80%.</p> <p>Add tests</p> <p>We are currently only at 60% coverage. So the lines above are currently pure fiction.</p>"},{"location":"contributing/#benchmarking","title":"Benchmarking","text":"<p>For optimal runtime, we continually measure the execution time of our core functions using pytest benchmarks. These benchmarks are located in <code>tests/benchmarks/</code> and are unit-tests that utilize the <code>benchmark</code> fixture from <code>pytest-benchmark</code>. All of them are marked with the benchmark decorator (<code>@pytest.mark.benchmark</code>) to exclude them from the normal unit-tests. You can run all benchmarks in the command line using <pre><code>pytest -m benchmark\n</code></pre> If you are working on runtime improvements, you can compare the runtime of your changes to the runtime of the main branch by saving the results of each run with <pre><code>pytest -m benchmark --benchmark-autosave\n</code></pre> or with a custom name <code>&lt;custom-name&gt;</code> <pre><code>pytest -m benchmark --benchmark-save=&lt;custom-name&gt;\n</code></pre> After running the benchmarks both in your current branch and in the main branch, you can compare them as follows: <pre><code>pytest-benchmark compare # (1)!\n</code></pre></p> <ol> <li>This will compare all runs that are currently saved in <code>.benchmarks/</code>. If you want to compare specific runs, you can add the number of the runs at the end of the command. The numbering usually starts with <code>0001</code>.</li> </ol> <p>Note</p> <p>Since the runtime is strongly dependent on the underlying machine, we do not keep any up-to-date results on <code>git</code> and recommend to do any comparisons locally.</p>"},{"location":"docker_installation/","title":"Docker Installation","text":"<p>  PyTorch provides a  Docker image with PyTorch preinstalled. Using this image, the Dockerfile below creates a Docker image with PathpyG installed.</p> GPUCPU <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre> <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu # CPU only\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html # CPU only\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate the code reference pages and navigation.\"\"\"\n# See for more detail: https://mkdocstrings.github.io/recipes/\n</pre> \"\"\"Generate the code reference pages and navigation.\"\"\" # See for more detail: https://mkdocstrings.github.io/recipes/ In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n</pre> nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>for path in sorted(Path(\"src\").rglob(\"*.py\")):\n    module_path = path.relative_to(\"src\").with_suffix(\"\")\n    doc_path = path.relative_to(\"src\").with_suffix(\".md\")\n    full_doc_path = Path(\"reference\", doc_path)\n\n    parts = tuple(module_path.parts)\n\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1] == \"__main__\":\n        continue\n\n    nav[parts] = doc_path.as_posix()\n\n    with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n        ident = \".\".join(parts)\n        fd.write(f\"::: {ident}\")\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path)\n</pre> for path in sorted(Path(\"src\").rglob(\"*.py\")):     module_path = path.relative_to(\"src\").with_suffix(\"\")     doc_path = path.relative_to(\"src\").with_suffix(\".md\")     full_doc_path = Path(\"reference\", doc_path)      parts = tuple(module_path.parts)      if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1] == \"__main__\":         continue      nav[parts] = doc_path.as_posix()      with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:         ident = \".\".join(parts)         fd.write(f\"::: {ident}\")      mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path) In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"getting_started/","title":"Getting Started","text":"<p>The following will guide you through the installation of the package and the first steps to use it.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>PathpyG is available for   Python versions 3.10 and above. It is not recommended to install it on your system Python. Instead, we recommend using a virtual environment such as   conda or virtualenv. You can also set up a   Docker image as described in the next section.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<p>Once you have an environment up and running, you can install the package simply via pip. But first make sure that you installed the necessary dependencies.</p>"},{"location":"getting_started/#dependencies","title":"Dependencies","text":"<p>This package is based on   PyTorch and   PyTorch Geometric. Please install both libraries before installing PathpyG. You can follow the installation instructions in their respective documentation (  PyTorch and   PyG).</p> <p>Warning</p> <p>We currently only support PyG version 2.5.0 and above.</p>"},{"location":"getting_started/#install-stable-release","title":"Install Stable Release","text":"<p>You can install the latest stable release of PathpyG via pip:</p> <p>TODO</p> <p>This is not yet available. We will release the first stable version soon.</p> <pre><code>pip install pathpyg\n</code></pre>"},{"location":"getting_started/#install-latest-development-version","title":"Install Latest Development Version","text":"<p>If you want to install the latest development version, you can do so via pip directly from the GitHub repository:</p> <pre><code>pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"plot_tutorial/","title":"Develop Custom Plot Functions","text":"<p>This tutorial guides you through the process of creating your own plotting functions in pathpyG.</p> <p>The visualization framework of pathpyg is designed in such a way that is easy to extend it according your own needs.</p> <p>For this tutorial we want to implement capabilities to plot histograms.</p> <p>You will learn:</p> <ul> <li>How to set up a generic plot function</li> <li>How to convert <code>pathpyG</code> data to plot data</li> <li>How to plot with <code>d3js</code> </li> <li>How to plot with <code>tikz</code></li> <li>How to plot with <code>matplotlib</code></li> </ul>"},{"location":"plot_tutorial/#structure","title":"Structure","text":"<p>Plotting commands and functions are located under <code>/src/pathpyG/visualisation/</code></p> <pre><code>\ud83d\udcc1 visualisation\n\u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u251c\u2500\u2500 \ud83d\udcc1 _d3js\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc1 _matplotlib\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc1 _tikz\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc4 layout.py\n\u251c\u2500\u2500 \ud83d\udcc4 network_plots.py\n\u251c\u2500\u2500 \ud83d\udcc4 plot.py\n\u2514\u2500\u2500 \ud83d\udcc4 utils.py\n</code></pre> <p>Folders with <code>_...</code> indicate the supported backends. We will have a look at them later.</p> <p>The <code>layout.py</code> file includes algorithms to calculate the positions of the nodes.</p> <p>In the <code>utils.py</code> file are useful helper functions collected. E.g. among others a function that converts <code>hex_to_rgb</code>, <code>rgb_to_hex</code>, or a simple <code>Colormap</code> class. If your plot needs generic functions which might be helpful for other plots as well, this would be a good place to store them.</p> <p>The <code>network_plots.py</code> file includes all plots related to network visualization. We will create in this tutorial a similar collection for histograms.</p> <p>Finally, the <code>plot.py</code> file contains our generic <code>PathPyPlot</code> class which we will use to build our own class. </p> <p>This abstract class has a property <code>_kind</code> which will specify the type of plot for the generic plot function. Similar to <code>pandas</code> we should be able to call:</p> <pre><code>pp.plot(graph, kind=\"hist\")\n</code></pre> <p>This abstract class has two dict variables <code>self.data</code> and <code>self.config</code>. The <code>self.data</code> variable is used to store the data needed for the plot, while the <code>self.config</code> stores all the configurations passed to the plot.</p> <p>Furthermore this class has three abstract methods we have to define later for our supported backends: <code>generate</code> to generate the plot, <code>save</code> to save the plot to a file, <code>show</code> to show the current plot.</p>"},{"location":"plot_tutorial/#lets-get-started","title":"Let's get started","text":"<p>In order to get started, we have to create a new python file where we will store our histogram plots. So let's generate a new file <code>hist_plots.py</code></p> <pre><code>touch hist_plots.py\n</code></pre> <p>We start with creating a function which allows us later to plot a histogram.</p> <p>This function will take a <code>Graph</code> object as input and has the parameters <code>key</code> and <code>bins</code> as well as a dict of <code>kwargs</code> for furthermore specifications.</p> <p>We will use the <code>key</code> variable to define the data type of the histogram e.g. <code>by='betweenes'</code> to get the betweenes centrality plotted. With the <code>bins</code> parameters we will change the amount of bins in the histogram. all other options will by passed to the function as keyword arguments and can be backend specific.</p> <pre><code>\"\"\"Histogram plot classes.\"\"\"\nfrom __future__ import annotations\n\nimport logging\n\nfrom typing import TYPE_CHECKING, Any\n\n# pseudo load class for type checking\nif TYPE_CHECKING:\n    from pathpyG.core.graph import Graph\n\n# create logger\nlogger = logging.getLogger(\"pathpyG\")\n\n\ndef hist(network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre> <p>pathpyG is using logging to print out messages and errors. It's a good habit to use it also for your plotting function.</p> <p>Our <code>hist</code> function will be callable via the package. e.g. <code>pp.hist(...)</code>. Itself it will return a plotting class which we have to create.</p> <pre><code>from pathpyG.visualisations.plot import PathPyPlot\n\nclass HistogramPlot(PathPyPlot):\n    \"\"\"Histogram plot class for a network properties.\"\"\"\n\n    _kind = \"hist\"\n\n    def __init__(self, network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.config['bins'] = bins\n        self.config['key'] = key\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n</code></pre> <p>The <code>HistogramPlot</code> plotting class is a child from our abstract <code>PathPyPlot</code> function. We will overwrite the abstract <code>generate()</code> function in order to get the data needed for our plot.</p> <p>By convention we assume <code>d3js</code> will be the default plot backend, hence the final data generated by this function should provide the necessary data structure for this backend. </p> <p>For other backends, this data might be needed to be converted e.g. keywords might be different. We will address this later in our tutorial.</p>"},{"location":"plot_tutorial/#testing-testing-testing","title":"Testing, Testing, Testing","text":"<p>Before we start developing our histogram plot, we should set up a test environment so that we can directly develop the unit test next to our plot function.</p> <p>Therefore we are going to our testing folder an create a new test file.</p> <pre><code>cd ../../../tests/\ntouch test_hist.py\n</code></pre> <p>Now we can create a simple test environment with a simple graph and call our <code>hist(...)</code> function.</p> <pre><code>from pathpyG.core.graph import Graph\nfrom pathpyG.visualisations.hist_plots import hist\n\n\ndef test_hist_plot() -&gt; None:\n    \"\"\"Test to plot a histogram.\"\"\"\n    net = Graph.from_edge_list([[\"a\", \"b\"], [\"b\", \"c\"], [\"a\", \"c\"]])\n    hist(net)\n</code></pre> <p>Note: If you only want to run this function and not all other test you can use:</p> <pre><code>pytest -s -k 'test_hist_plot'\n</code></pre>"},{"location":"plot_tutorial/#generating-the-plot-data","title":"Generating the plot data","text":"<p>To plot our histogram we first have to generate the required data from our graph.</p> <p>In the future we might want to add more options for histograms, hence we use the <code>match</code>-<code>case</code> function form python.</p> <pre><code>    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n\n        data: dict = {}\n\n        match self.config[\"key\"]:\n            case \"indegrees\":\n                logger.debug(\"Generate data for in-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n            case \"outdegrees\":\n                logger.debug(\"Generate data for out-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n            case _:\n                logger.error(\n                    f\"The &lt;{self.config['key']}&gt; property\",\n                    \"is currently not supported for hist plots.\",\n                )\n                raise KeyError\n\n        data[\"title\"] = self.config[\"key\"]\n        self.data[\"data\"] = data\n</code></pre> <p>First we initialize a dictionary <code>data</code> to store our values. In this case we are interested in the in and out-degrees of our graph, which are already implemented in <code>pathpyG</code> (state 2023-11-26). </p> <p>If the keyword is not supported the function will raise a <code>KeyError</code>.</p> <p>To provide a default title for our plot we also store the keyword in the data dict. If further data is required for the plot it can be stored here.</p> <p>Finally, we add the data dict to our <code>self.data</code> variable of the plotting class. This variable will be used later in the backend classes.</p> <p>With this our basic histogram plot function is finished. We are now able to call the plot function, get the data from our graph and create a data-set which can be passed down to the backend for visualization.</p>"},{"location":"plot_tutorial/#the-matplotlib-backend","title":"The matplotlib backend","text":"<p>Let's open the <code>_matplotlib</code> folder located under <code>/src/pathpyG/visualisation/_matplotlib</code>, where all matplotlib functions are stored.</p> <pre><code>\ud83d\udcc1 _matplotlib\n\u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u251c\u2500\u2500 \ud83d\udcc4 core.py\n\u2514\u2500\u2500 \ud83d\udcc4 network_plots.py\n</code></pre> <p>The <code>_init_.py</code> holds the configuration for the plot function, which we will modify later. The <code>core.py</code> file contains the generic <code>MatplotlibPlot</code> class, which provides <code>save</code> and <code>show</code> functionalities for our plots. We do not need to modify these functions. Instead, we have to generate a translation function from our generic data dict (see above) to a histogram in matplotlib. To do so, lets create first a new python file named <code>hist_plots.py</code></p> <pre><code>cd _matplotlib\ntouch hist_plots.py\n</code></pre> <p>Here we will add our missing piece for a functional matplotlib plot.</p> <pre><code>\"\"\"Histogram plot classes.\"\"\"\nfrom __future__ import annotations\n\nimport logging\n\nfrom typing import TYPE_CHECKING, Any\n\n# pseudo load class for type checking\nif TYPE_CHECKING:\n    from pathpyG.core.graph import Graph\n\n# create logger\nlogger = logging.getLogger(\"pathpyG\")\n\n\ndef hist(network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre>"},{"location":"tutorial/","title":"Overview","text":"<p>In this tutorial, we will introduce basic concepts of pathpyG. pathpyG can be used as a wrapper around pytorch-geometric that facilitates network analysis, graph learning, and interactive data visualization. However, its real power comes into play when modelling causal path structures in time series data on networks, such as trajectories on graphs or temporal graphs with time-stamped interactions. pathpyG allows to compute causal paths in temporal graphs and model them based on higher-order De Bruijn graphs, a higher-dimensional generalization of standard graph models for relational data.</p> <p>The following introductory video explains the basic idea of higher-order De Bruijn graph models for causal path structures in time series data:</p> <p>The science behind pathpyG has been published in outlets like SIGKDD, WWW, Learning on Graphs, Nature Communications, Nature Physics, and Physical Review Letters. Please check here for more details on key scientific works that have laid the foundations for this package.</p> <p>Different from previous versions of pathpy, the latest version pathpyG fully utilizes the power of torch and tensor-based representations of sparse graph models to failitate the use of higher-order De Bruijn graph models. pathpyG's data structures naturally generalize the concepts of pytorch-geometric, which makes it easy to apply it in (temnporal) graph learning tasks.</p> <p>Finally, pathpyG comes with an implementation of De Bruijn Graph Neural Networks (DBGNN), a causality-aware deep learning architecture for temporal graph data. In the tutorial, we illustrate this temporal graph learning approach in a simple toy example.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>pathpyG<ul> <li>algorithms<ul> <li>centrality</li> <li>components</li> <li>generative_models</li> <li>lift_order</li> <li>rolling_time_window</li> <li>shortest_paths</li> <li>temporal</li> <li>weisfeiler_leman</li> </ul> </li> <li>core<ul> <li>graph</li> <li>index_map</li> <li>multi_order_model</li> <li>path_data</li> <li>temporal_graph</li> </ul> </li> <li>io<ul> <li>graphtool</li> <li>netzschleuder</li> <li>pandas</li> </ul> </li> <li>nn<ul> <li>dbgnn</li> </ul> </li> <li>processes<ul> <li>process</li> <li>random_walk</li> <li>sampling</li> </ul> </li> <li>statistics<ul> <li>clustering</li> <li>degrees</li> <li>node_similarities</li> </ul> </li> <li>utils<ul> <li>config</li> <li>convert</li> <li>dbgnn</li> <li>progress</li> </ul> </li> <li>visualisations<ul> <li>_d3js<ul> <li>core</li> <li>network_plots</li> </ul> </li> <li>_matplotlib<ul> <li>core</li> <li>network_plots</li> </ul> </li> <li>_tikz<ul> <li>core</li> <li>network_plots</li> </ul> </li> <li>hist_plots</li> <li>layout</li> <li>network_plots</li> <li>plot</li> <li>utils</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/pathpyG/","title":"pathpyG","text":"<p>pathpyG is an Open Source package facilitating next-generation network analytics and graph learning for time series data on graphs.</p> <p>Building on the industry-proven data structures and concepts of <code>pytorch</code> and <code>torch_geometric</code>, pathpyG makes it easier than ever to apply machine learning to temporal graph data.</p> <p>pathpyG is jointly developed at University of Wuerzburg, Princeton University, and University of Zurich. The research behind pathpyG has been funded by the Swiss National Science Foundation via  grant 176938.</p>"},{"location":"reference/pathpyG/algorithms/","title":"algorithms","text":"<p>Algorithms for temporal path calculation and graph metrics.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG and configure your torch device if you want to use GPU .\nimport pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n\n# Generate a toy example for a temporal graph.\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)\n])\n\n# Extract DAG capturing causal interaction sequences in temporal graph.\ne_i = pp.algorithms.lift_order_temporal(g, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\nprint(dag)\n\n# Calculate shortest time-respecting pathas\ndist, pred = pp.algorithms.temporal.temporal_shortest_paths(g, delta=1)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if \"num_nodes\" not in data:\n            data.num_nodes = data.edge_index.max().item() + 1\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if (\n            data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n            or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n        ):\n            raise Exception(\"sparse size of EdgeIndex should match number of nodes!\")\n\n        # sort EdgeIndex and validate\n        data.edge_index = data.edge_index.sort_by(\"row\").values\n        data.edge_index.validate()\n\n        self.data = data\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n        # create node_sequence mapping for higher-order graphs\n        if \"node_sequence\" not in self.data:\n            self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n        Examples:\n            You can create a graph from an edge index tensor as follows:\n\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            &gt;&gt;&gt; print(g)\n            Directed graph with 3 nodes and 3 edges ...\n\n            You can also include a mapping of node IDs:\n\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n            &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n            &gt;&gt;&gt; print(g.mapping)\n            a -&gt; 0\n            b -&gt; 1\n            c -&gt; 2\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else:\n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(d, mapping=mapping)\n\n    @staticmethod\n    def from_edge_list(\n        edge_list: Iterable[Tuple[str, str]],\n        is_undirected: bool = False,\n        mapping: Optional[IndexMap] = None,\n        num_nodes: Optional[int] = None,\n    ) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n            &gt;&gt;&gt; print(list(g.edges))\n            [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        \"\"\"\n\n        if mapping is None:\n            edge_array = np.array(edge_list)\n            node_ids = np.unique(edge_array)\n            if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n                node_ids = np.sort(node_ids.astype(int)).astype(str)\n            mapping = IndexMap(node_ids)\n\n        if num_nodes is None:\n            num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex(\n            mapping.to_idxs(edge_list).T.contiguous(),\n            sparse_size=(num_nodes, num_nodes),\n            is_undirected=is_undirected,\n        )\n        return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            &gt;&gt;&gt; g_u = g.to_undirected()\n            &gt;&gt;&gt; print(g_u)\n            Undirected graph with 3 nodes and 6 (directed) edges\n        \"\"\"\n        tf = ToUndirected()\n        d = tf(self.data)\n        # unfortunately, the application of a transform creates a new edge_index of type tensor\n        # so we have to recreate the EdgeIndex tensor and sort it again\n\n        e = EdgeIndex(data=d.edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True)\n        d.edge_index = e\n        d.num_nodes = self.data.num_nodes\n        return Graph(d, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n        If the graph contains multiple edges between the same nodes, this method will coalesce\n        them into a single edge with an additional weight attribute called `edge_weight` that\n        contains the number of coalesced edges. The method returns a new graph instance with\n        the coalesced edges.\n\n        Returns:\n            Graph: Graph with coalesced edges\n        \"\"\"\n        i, w = torch_geometric.utils.coalesce(\n            self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n\n    def node_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_sequence` attribute.\n\n        Returns:\n            list: list of node attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n\n        Returns:\n            list: list of edge attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; list:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a list object that contains all nodes.\n        If an IndexMap is used, nodes are returned as string IDs.\n        If no IndexMap is used, nodes are returned as integer indices.\n\n        Returns:\n            list: list of all nodes using IDs or indices (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(np.arange(self.n)).tolist()\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    @property\n    def edges(self) -&gt; list:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a list object that contains all edges, where each\n        edge is a tuple of two elements. If an IndexMap is used to map node\n        indices to string IDs, edges are returned as tuples of string IDs.\n        If no mapping is used, edges are returned as tuples of integer indices.\n\n        Returns:\n            list: list object yielding all edges using IDs or indices (if no mapping is used)\n        \"\"\"\n        edge_list = self.mapping.to_ids(self.data.edge_index.t()).tolist()\n        if self.order &gt; 1:\n            return [tuple(map(tuple, x)) for x in edge_list]\n        return list(map(tuple, edge_list))\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n        \"\"\"\n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def successors(self, node: Union[int, str] | tuple) -&gt; list:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n\n        Returns:\n            list: list with all successors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n\n        node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n\n        Returns:\n            list: list with all predecessors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID\n\n        Returns:\n            bool: True if edge exists, False otherwise\n        \"\"\"\n        row = self.mapping.to_idx(v)\n        row_start = self.row_ptr[row]\n        row_end = self.row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in self.col[row_start:row_end]\n\n    def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor())\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return in-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing in-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return out-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing out-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n        \"\"\"\n        Return degrees of nodes.\n\n        Args:\n            mode: `in` or `out` to calculate the in- or out-degree for\n                directed networks.\n\n        Returns:\n            dict: dictionary containing degrees of nodes\n        \"\"\"\n        if mode == \"in\":\n            d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n        else:\n            d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n        return {self.mapping.to_id(i): d[i].item() for i in range(self.n)}\n\n    def weighted_outdegrees(self) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the weighted outdegrees of each node in the graph.\n\n        Args:\n            graph (Graph): pathpy graph object.\n\n        Returns:\n            tensor: Weighted outdegrees of nodes.\n        \"\"\"\n        weighted_outdegree = scatter(\n            self.data.edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\"\n        )\n        return weighted_outdegree\n\n    def transition_probabilities(self) -&gt; torch.Tensor:\n        \"\"\"\n        Compute transition probabilities based on weighted outdegrees.\n\n        Returns:\n            tensor: Transition probabilities.\n        \"\"\"\n        weighted_outdegree = self.weighted_outdegrees()\n        source_ids = self.data.edge_index[0]\n        return self.data.edge_weight / weighted_outdegree[source_ids]\n\n    def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization: normalization parameter passed to pyG `get_laplacian`\n                function\n            edge_attr: optinal name of numerical edge attribute that shall\n                be passed to pyG `get_laplacian` function as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(), normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(),\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key.startswith(\"node_\"):\n                if val.size(0) != self.n:\n                    raise ValueError(\"Attribute must have same length as number of nodes\")\n                self.data[key] = val\n            elif key.startswith(\"edge_\"):\n                if val.size(0) != self.m:\n                    raise ValueError(\"Attribute must have same length as number of edges\")\n                self.data[key] = val\n            else:\n                self.data[key] = val\n        elif key[0].startswith(\"node_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif key[0].startswith(\"edge_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n\n    @property\n    def n(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns:\n            int: number of nodes in the graph\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def m(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the number of directed edges is returned.\n\n        Returns:\n            int: number of edges in the graph\n        \"\"\"\n        return self.data.num_edges  # type: ignore\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"\n        Return order of graph.\n\n        Returns:\n            int: order of the (De Bruijn) graph\n        \"\"\"\n        return self.data.node_sequence.size(1)  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\n\n        Returns:\n            bool: True if graph is directed, False otherwise\n        \"\"\"\n        return not self.data.edge_index.is_undirected\n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\n\n        Returns:\n            bool: True if graph is undirected, False otherwise\n        \"\"\"\n        return self.data.edge_index.is_undirected\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\n\n        Returns:\n            bool: True if graph contains self-loops, False otherwise\n        \"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph) -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Examples:\n            Adding two graphs without node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 6 edges\n\n            Adding two graphs with identical node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 4 edges\n\n            Adding two graphs with non-overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 6 nodes and 4 edges\n\n            Adding two graphs with partly overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 5 nodes and 4 edges\n        \"\"\"\n\n        if self.order &gt; 1:\n            raise NotImplementedError(\"Add operator can only be applied to order 1 graphs\")\n\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        # compute overlap and additional nodes in g2 over g1\n        overlap = set(m2.node_ids).intersection(m1.node_ids)\n        additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n        d2_idx_translation = {}\n        node_ids = [\"\"] * (self.n + len(additional_nodes))\n        # keep mappings of nodes in g1\n        for v in m1.node_ids:\n            node_ids[m1.to_idx(v)] = v\n        for v in m2.node_ids:\n            d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n        # for overlapping node IDs we must correct node indices in m2\n        for v in overlap:\n            d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n        # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n        for v in additional_nodes:\n            new_idx = m2.to_idx(v) + self.n - len(overlap)\n            node_ids[new_idx] = v\n            d2_idx_translation[m2.to_idx(v)] = new_idx\n        # apply index translation to d2\n        # fast dictionary based mapping using torch\n        palette, key = zip(*d2_idx_translation.items())\n        key = torch.tensor(key)\n        palette = torch.tensor(palette)\n\n        index = torch.bucketize(d2.edge_index.ravel(), palette)\n        d2.edge_index = key[index].reshape(d2.edge_index.shape)\n        d = d1.concat(d2)\n        mapping = IndexMap(node_ids)\n        d.num_nodes = self.n + len(additional_nodes)\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.n, self.m)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.edges","title":"<code>edges: list</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a list object that contains all edges, where each edge is a tuple of two elements. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of string IDs. If no mapping is used, edges are returned as tuples of integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list object yielding all edges using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.in_degrees","title":"<code>in_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return in-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing in-degrees of nodes</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.m","title":"<code>m: int</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the number of directed edges is returned.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of edges in the graph</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.n","title":"<code>n: int</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of nodes in the graph</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.nodes","title":"<code>nodes: list</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a list object that contains all nodes. If an IndexMap is used, nodes are returned as string IDs. If no IndexMap is used, nodes are returned as integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list of all nodes using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.order","title":"<code>order: int</code>  <code>property</code>","text":"<p>Return order of graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>order of the (De Bruijn) graph</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.out_degrees","title":"<code>out_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return out-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing out-degrees of nodes</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Examples:</p> <p>Adding two graphs without node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 6 edges\n</code></pre> <p>Adding two graphs with identical node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 4 edges\n</code></pre> <p>Adding two graphs with non-overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 6 nodes and 4 edges\n</code></pre> <p>Adding two graphs with partly overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 5 nodes and 4 edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __add__(self, other: Graph) -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Examples:\n        Adding two graphs without node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 6 edges\n\n        Adding two graphs with identical node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 4 edges\n\n        Adding two graphs with non-overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 6 nodes and 4 edges\n\n        Adding two graphs with partly overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 5 nodes and 4 edges\n    \"\"\"\n\n    if self.order &gt; 1:\n        raise NotImplementedError(\"Add operator can only be applied to order 1 graphs\")\n\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    # compute overlap and additional nodes in g2 over g1\n    overlap = set(m2.node_ids).intersection(m1.node_ids)\n    additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n    d2_idx_translation = {}\n    node_ids = [\"\"] * (self.n + len(additional_nodes))\n    # keep mappings of nodes in g1\n    for v in m1.node_ids:\n        node_ids[m1.to_idx(v)] = v\n    for v in m2.node_ids:\n        d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n    # for overlapping node IDs we must correct node indices in m2\n    for v in overlap:\n        d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n    # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n    for v in additional_nodes:\n        new_idx = m2.to_idx(v) + self.n - len(overlap)\n        node_ids[new_idx] = v\n        d2_idx_translation[m2.to_idx(v)] = new_idx\n    # apply index translation to d2\n    # fast dictionary based mapping using torch\n    palette, key = zip(*d2_idx_translation.items())\n    key = torch.tensor(key)\n    palette = torch.tensor(palette)\n\n    index = torch.bucketize(d2.edge_index.ravel(), palette)\n    d2.edge_index = key[index].reshape(d2.edge_index.shape)\n    d = d1.concat(d2)\n    mapping = IndexMap(node_ids)\n    d.num_nodes = self.n + len(additional_nodes)\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if \"num_nodes\" not in data:\n        data.num_nodes = data.edge_index.max().item() + 1\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if (\n        data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n        or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n    ):\n        raise Exception(\"sparse size of EdgeIndex should match number of nodes!\")\n\n    # sort EdgeIndex and validate\n    data.edge_index = data.edge_index.sort_by(\"row\").values\n    data.edge_index.validate()\n\n    self.data = data\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    # create node_sequence mapping for higher-order graphs\n    if \"node_sequence\" not in self.data:\n        self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key.startswith(\"node_\"):\n            if val.size(0) != self.n:\n                raise ValueError(\"Attribute must have same length as number of nodes\")\n            self.data[key] = val\n        elif key.startswith(\"edge_\"):\n            if val.size(0) != self.m:\n                raise ValueError(\"Attribute must have same length as number of edges\")\n            self.data[key] = val\n        else:\n            self.data[key] = val\n    elif key[0].startswith(\"node_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif key[0].startswith(\"edge_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.n, self.m)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate the in- or out-degree for directed networks.</p> <code>'in'</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing degrees of nodes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n    \"\"\"\n    Return degrees of nodes.\n\n    Args:\n        mode: `in` or `out` to calculate the in- or out-degree for\n            directed networks.\n\n    Returns:\n        dict: dictionary containing degrees of nodes\n    \"\"\"\n    if mode == \"in\":\n        d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n    else:\n        d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n    return {self.mapping.to_id(i): d[i].item() for i in range(self.n)}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of edge attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def edge_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n\n    Returns:\n        list: list of edge attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <code>int</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.</p> <code>None</code> <p>Examples:</p> <p>You can create a graph from an edge index tensor as follows:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n&gt;&gt;&gt; print(g)\nDirected graph with 3 nodes and 3 edges ...\n</code></pre> <p>You can also include a mapping of node IDs:</p> <pre><code>&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n&gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n&gt;&gt;&gt; print(g.mapping)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n    Examples:\n        You can create a graph from an edge index tensor as follows:\n\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        &gt;&gt;&gt; print(g)\n        Directed graph with 3 nodes and 3 edges ...\n\n        You can also include a mapping of node IDs:\n\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n        &gt;&gt;&gt; print(g.mapping)\n        a -&gt; 0\n        b -&gt; 1\n        c -&gt; 2\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else:\n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>num_nodes</code> <code>typing.Optional[int]</code> <p>optional number of nodes (useful in case not all nodes have incident edges)</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n&gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n&gt;&gt;&gt; print(list(g.edges))\n[('a', 'b'), ('a', 'c'), ('b', 'c')]\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(\n    edge_list: Iterable[Tuple[str, str]],\n    is_undirected: bool = False,\n    mapping: Optional[IndexMap] = None,\n    num_nodes: Optional[int] = None,\n) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n        &gt;&gt;&gt; print(list(g.edges))\n        [('a', 'b'), ('a', 'c'), ('b', 'c')]\n    \"\"\"\n\n    if mapping is None:\n        edge_array = np.array(edge_list)\n        node_ids = np.unique(edge_array)\n        if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n            node_ids = np.sort(node_ids.astype(int)).astype(str)\n        mapping = IndexMap(node_ids)\n\n    if num_nodes is None:\n        num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex(\n        mapping.to_idxs(edge_list).T.contiguous(),\n        sparse_size=(num_nodes, num_nodes),\n        is_undirected=is_undirected,\n    )\n    return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all predecessor nodes of the node indexed by <code>col_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n    \"\"\"\n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all successor nodes of the node indexed by <code>row_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph contains self-loops, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\n\n    Returns:\n        bool: True if graph contains self-loops, False otherwise\n    \"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is directed, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\n\n    Returns:\n        bool: True if graph is directed, False otherwise\n    \"\"\"\n    return not self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if edge exists, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID\n\n    Returns:\n        bool: True if edge exists, False otherwise\n    \"\"\"\n    row = self.mapping.to_idx(v)\n    row_start = self.row_ptr[row]\n    row_end = self.row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in self.col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is undirected, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\n\n    Returns:\n        bool: True if graph is undirected, False otherwise\n    \"\"\"\n    return self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.laplacian","title":"<code>laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code> function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: Laplacian matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization: normalization parameter passed to pyG `get_laplacian`\n            function\n        edge_attr: optinal name of numerical edge attribute that shall\n            be passed to pyG `get_laplacian` function as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(), normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(),\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_sequence</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of node attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def node_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_sequence` attribute.\n\n    Returns:\n        list: list of node attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all predecessors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n\n    Returns:\n        list: list with all predecessors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n    node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.sparse_adj_matrix","title":"<code>sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor())\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n        )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all successors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) -&gt; list:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n\n    Returns:\n        list: list with all successors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n\n    node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n&gt;&gt;&gt; g_u = g.to_undirected()\n&gt;&gt;&gt; print(g_u)\nUndirected graph with 3 nodes and 6 (directed) edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        &gt;&gt;&gt; g_u = g.to_undirected()\n        &gt;&gt;&gt; print(g_u)\n        Undirected graph with 3 nodes and 6 (directed) edges\n    \"\"\"\n    tf = ToUndirected()\n    d = tf(self.data)\n    # unfortunately, the application of a transform creates a new edge_index of type tensor\n    # so we have to recreate the EdgeIndex tensor and sort it again\n\n    e = EdgeIndex(data=d.edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True)\n    d.edge_index = e\n    d.num_nodes = self.data.num_nodes\n    return Graph(d, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> <p>If the graph contains multiple edges between the same nodes, this method will coalesce them into a single edge with an additional weight attribute called <code>edge_weight</code> that contains the number of coalesced edges. The method returns a new graph instance with the coalesced edges.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>Graph with coalesced edges</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n    If the graph contains multiple edges between the same nodes, this method will coalesce\n    them into a single edge with an additional weight attribute called `edge_weight` that\n    contains the number of coalesced edges. The method returns a new graph instance with\n    the coalesced edges.\n\n    Returns:\n        Graph: Graph with coalesced edges\n    \"\"\"\n    i, w = torch_geometric.utils.coalesce(\n        self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n    )\n    return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Compute transition probabilities based on weighted outdegrees.</p> <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Transition probabilities.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def transition_probabilities(self) -&gt; torch.Tensor:\n    \"\"\"\n    Compute transition probabilities based on weighted outdegrees.\n\n    Returns:\n        tensor: Transition probabilities.\n    \"\"\"\n    weighted_outdegree = self.weighted_outdegrees()\n    source_ids = self.data.edge_index[0]\n    return self.data.edge_weight / weighted_outdegree[source_ids]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.weighted_outdegrees","title":"<code>weighted_outdegrees</code>","text":"<p>Compute the weighted outdegrees of each node in the graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>pathpy graph object.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Weighted outdegrees of nodes.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def weighted_outdegrees(self) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the weighted outdegrees of each node in the graph.\n\n    Args:\n        graph (Graph): pathpy graph object.\n\n    Returns:\n        tensor: Weighted outdegrees of nodes.\n    \"\"\"\n    weighted_outdegree = scatter(\n        self.data.edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\"\n    )\n    return weighted_outdegree\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph","title":"<code>TemporalGraph</code>","text":"<p>               Bases: <code>pathpyG.Graph</code></p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>class TemporalGraph(Graph):\n    def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n        \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n        Args:\n            data: xxx\n            mapping: xxx\n\n        Example:\n            ```py\n            from pytorch_geometric.data import TemporalData\n            import pathpyG as pp\n\n            d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n            t = pp.TemporalGraph(d, mapping)\n            print(t)\n            ```\n        \"\"\"\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = data.edge_index = EdgeIndex(\n                data=data.edge_index.contiguous(), sparse_size=(data.num_nodes, data.num_nodes)\n            )\n\n        # reorder temporal data\n        self.data = data.sort_by_time()\n\n        if mapping is not None:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n\n        # create mapping between edge index and edge tuples\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        self.start_time = self.data.time[0].item()\n        self.end_time = self.data.time[-1].item()\n\n    @staticmethod\n    def from_edge_list(edge_list, num_nodes: Optional[int] = None) -&gt; TemporalGraph:\n        edge_array = np.array(edge_list)\n        ts = edge_array[:, 2].astype(np.number)\n\n        index_map = IndexMap(np.unique(edge_array[:, :2]))\n        edge_index = index_map.to_idxs(edge_array[:, :2].T)\n\n        if not num_nodes:\n            num_nodes = index_map.num_ids()\n\n        return TemporalGraph(\n            data=Data(\n                edge_index=edge_index,\n                time=torch.Tensor(ts),\n                num_nodes=num_nodes,\n            ),\n            mapping=index_map,\n        )\n\n    @property\n    def temporal_edges(self) -&gt; Generator[Tuple[int, int, int], None, None]:\n        \"\"\"Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.\"\"\"\n        return [(*self.mapping.to_ids(e), t.item()) for e, t in zip(self.data.edge_index.t(), self.data.time)]\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"Return order 1, since all temporal graphs must be order one.\"\"\"\n        return 1\n\n    def shuffle_time(self) -&gt; None:\n        \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n        self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n\n    def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n        \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n        Args:\n            weighted: whether or not to return a weighted time-aggregated graph\n            time_window: A tuple with start and end time of the aggregation window\n\n        Returns:\n            Graph: A static graph object\n        \"\"\"\n        if time_window is not None:\n            idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n            edge_index = self.data.edge_index[:, idx]\n        else:\n            edge_index = self.data.edge_index\n\n        n = edge_index.max().item() + 1\n\n        if weighted:\n            i, w = torch_geometric.utils.coalesce(\n                edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n            )\n            return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n        else:\n            return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n\n    def to_undirected(self) -&gt; TemporalGraph:\n        \"\"\"Return an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        rev_edge_index = self.data.edge_index.flip([0])\n        edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n        times = torch.cat([self.data.time, self.data.time])\n        return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n\n    def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n        \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given batch defined by start and (non-inclusive) end, where start\n        and end refer to the index of the first and last event in the time-ordered list of events.\"\"\"\n\n        return TemporalGraph(\n            data=Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx]),\n            mapping=self.mapping,\n        )\n\n    def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n        \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given time window defined by start and (non-inclusive) end, where start\n        and end refer to the time stamps\"\"\"\n\n        return TemporalGraph(data=self.data.snapshot(start_time, end_time), mapping=self.mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the graph\n        \"\"\"\n        s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n            self.data.num_nodes,\n            self.data.edge_index.unique(dim=1).size(dim=1),\n            self.data.edge_index.size(1),\n            self.start_time,\n            self.end_time,\n        )\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.order","title":"<code>order: int</code>  <code>property</code>","text":"<p>Return order 1, since all temporal graphs must be order one.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.temporal_edges","title":"<code>temporal_edges: Generator[Tuple[int, int, int], None, None]</code>  <code>property</code>","text":"<p>Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__init__","title":"<code>__init__</code>","text":"<p>Creates an instance of a temporal graph from a <code>TemporalData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>xxx</p> required <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>xxx</p> <code>None</code> Example <pre><code>from pytorch_geometric.data import TemporalData\nimport pathpyG as pp\n\nd = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\nt = pp.TemporalGraph(d, mapping)\nprint(t)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n    \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n    Args:\n        data: xxx\n        mapping: xxx\n\n    Example:\n        ```py\n        from pytorch_geometric.data import TemporalData\n        import pathpyG as pp\n\n        d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n        t = pp.TemporalGraph(d, mapping)\n        print(t)\n        ```\n    \"\"\"\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = data.edge_index = EdgeIndex(\n            data=data.edge_index.contiguous(), sparse_size=(data.num_nodes, data.num_nodes)\n        )\n\n    # reorder temporal data\n    self.data = data.sort_by_time()\n\n    if mapping is not None:\n        self.mapping = mapping\n    else:\n        self.mapping = IndexMap()\n\n    # create mapping between edge index and edge tuples\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    self.start_time = self.data.time[0].item()\n    self.end_time = self.data.time[-1].item()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the graph\n    \"\"\"\n    s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n        self.data.num_nodes,\n        self.data.edge_index.unique(dim=1).size(dim=1),\n        self.data.edge_index.size(1),\n        self.start_time,\n        self.end_time,\n    )\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.get_batch","title":"<code>get_batch</code>","text":"<p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given batch defined by start and (non-inclusive) end, where start and end refer to the index of the first and last event in the time-ordered list of events.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n    \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given batch defined by start and (non-inclusive) end, where start\n    and end refer to the index of the first and last event in the time-ordered list of events.\"\"\"\n\n    return TemporalGraph(\n        data=Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx]),\n        mapping=self.mapping,\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.get_window","title":"<code>get_window</code>","text":"<p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given time window defined by start and (non-inclusive) end, where start and end refer to the time stamps</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n    \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given time window defined by start and (non-inclusive) end, where start\n    and end refer to the time stamps\"\"\"\n\n    return TemporalGraph(data=self.data.snapshot(start_time, end_time), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.shuffle_time","title":"<code>shuffle_time</code>","text":"<p>Randomly shuffle the temporal order of edges by randomly permuting timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def shuffle_time(self) -&gt; None:\n    \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n    self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to_static_graph","title":"<code>to_static_graph</code>","text":"<p>Return weighted time-aggregated instance of <code>Graph</code> graph.</p> <p>Parameters:</p> Name Type Description Default <code>weighted</code> <code>bool</code> <p>whether or not to return a weighted time-aggregated graph</p> <code>False</code> <code>time_window</code> <code>typing.Optional[typing.Tuple[int, int]]</code> <p>A tuple with start and end time of the aggregation window</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.Graph</code> <p>A static graph object</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n    \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n    Args:\n        weighted: whether or not to return a weighted time-aggregated graph\n        time_window: A tuple with start and end time of the aggregation window\n\n    Returns:\n        Graph: A static graph object\n    \"\"\"\n    if time_window is not None:\n        idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n        edge_index = self.data.edge_index[:, idx]\n    else:\n        edge_index = self.data.edge_index\n\n    n = edge_index.max().item() + 1\n\n    if weighted:\n        i, w = torch_geometric.utils.coalesce(\n            edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n    else:\n        return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_undirected(self) -&gt; TemporalGraph:\n    \"\"\"Return an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    rev_edge_index = self.data.edge_index.flip([0])\n    edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n    times = torch.cat([self.data.time, self.data.time])\n    return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.temporal_shortest_paths","title":"<code>temporal_shortest_paths</code>","text":"<p>Compute shortest time-respecting paths in a temporal graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to compute shortest paths on.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events in a path.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Tuple of two numpy arrays:</p> <code>numpy.ndarray</code> <ul> <li>dist: Shortest time-respecting path distances between all first-order nodes.</li> </ul> <code>typing.Tuple[numpy.ndarray, numpy.ndarray]</code> <ul> <li>pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.</li> </ul> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def temporal_shortest_paths(g: TemporalGraph, delta: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute shortest time-respecting paths in a temporal graph.\n\n    Args:\n        g: Temporal graph to compute shortest paths on.\n        delta: Maximum time difference between events in a path.\n\n    Returns:\n        Tuple of two numpy arrays:\n        - dist: Shortest time-respecting path distances between all first-order nodes.\n        - pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n    dst_edges_dst = g.data.edge_index[1] + g.m + g.n\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.m + 2 * g.n)\n    m = event_graph.sparse_adj_matrix()\n\n    # print(f\"Created temporal event DAG with {event_graph.n} nodes and {event_graph.m} edges\")\n\n    # run disjktra for all source nodes\n    dist, pred = dijkstra(\n        m, directed=True, indices=np.arange(g.m, g.m + g.n), return_predecessors=True, unweighted=True\n    )\n\n    # limit to first-order destinations and correct distances\n    dist_fo = dist[:, g.m + g.n :] - 1\n    np.fill_diagonal(dist_fo, 0)\n\n    # limit to first-order destinations and correct predecessors\n    pred_fo = pred[:, g.n + g.m :]\n    pred_fo[pred_fo == -9999] = -1\n    idx_map = np.concatenate([to_numpy(g.data.edge_index[0].cpu()), [-1]])\n    pred_fo = idx_map[pred_fo]\n    np.fill_diagonal(pred_fo, np.arange(g.n))\n\n    return dist_fo, pred_fo\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.to_numpy","title":"<code>to_numpy</code>","text":"<p>Convert a tensor or tensor subclasses like <code>torch_geometric.Edge_Index</code> to numpy.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>torch.Tensor</code> <p>Tensor or tensor subclass.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Numpy array.</p> Source code in <code>src/pathpyG/utils/convert.py</code> <pre><code>def to_numpy(tensor: torch.Tensor) -&gt; np.ndarray:\n    \"\"\"\n    Convert a tensor or tensor subclasses like `torch_geometric.Edge_Index` to numpy.\n\n    Args:\n        tensor: Tensor or tensor subclass.\n\n    Returns:\n        Numpy array.\n    \"\"\"\n    if isinstance(tensor, (EdgeIndex, Index)):\n        return tensor.as_tensor().numpy()\n    return tensor.numpy()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/","title":"centrality","text":"<p>Algorithms to calculate centralities in (temporal) graphs.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG and configure your torch device if you want to use GPU acceleration.\nimport pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n\n# Generate toy example for temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)\n])    \n\nbw_t = pp.algorithms.temporal_betweenness_centrality(g, delta=1)\ncl_t = pp.algorithms.temporal_closeness_centrality(g, delta=1)\n\nstatic_graph = g.to_static_graph()\nbw_s = pp.algorithms.betweenness_centrality(static_graph)\nbw_s = pp.algorithms.closeness_centrality(static_graph)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.__getattr__","title":"<code>__getattr__</code>","text":"<p>Map to corresponding functions in centrality module of networkx.</p> <p>Any call to a function that is not implemented in the module centrality and whose first argument is of type Graph will be delegated to the corresponding function in the networkx module <code>centrality</code>. Please refer to the networkx documentation for a reference of available functions.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>the name of the function that shall be called</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def __getattr__(name: str) -&gt; Any:\n    \"\"\"Map to corresponding functions in centrality module of networkx.\n\n    Any call to a function that is not implemented in the module centrality\n    and whose first argument is of type Graph will be delegated to the\n    corresponding function in the networkx module `centrality`. Please\n    refer to the [networkx documentation](https://networkx.org/documentation/stable/reference/algorithms/centrality.html)\n    for a reference of available functions.\n\n    Args:\n        name: the name of the function that shall be called\n    \"\"\"\n\n    def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n        if len(args) == 0:\n            raise RuntimeError(f\"Did not find method {name} with no arguments\")\n        if isinstance(args[0], TemporalGraph):\n            raise NotImplementedError(f\"Missing implementation of {name} for temporal graphs\")\n        # if first argument is of type Graph, delegate to networkx function\n        if isinstance(args[0], Graph):\n            g = to_networkx(args[0].data)\n            r = getattr(centrality, name)(g, *args[1:], **kwargs)\n            if name.index(\"centrality\") &gt; 0 and isinstance(r, dict):\n                return map_to_nodes(args[0], r)\n            return r\n        else:\n            return wrapper(*args, **kwargs)\n            # raise RuntimeError(f'Did not find method {name} that accepts first argument of type {type(args[0])}')\n\n    return wrapper\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.betweenness_centrality","title":"<code>betweenness_centrality</code>","text":"<p>Calculate the betweenness centrality of nodes based on the fast algorithm proposed by Brandes:</p> <p>U. Brandes: A faster algorithm for betweenness centrality, The Journal of Mathematical Sociology, 2001</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.graph.Graph</code> <p><code>Graph</code> object for which betweenness centrality will be computed</p> required <code>sources</code> <p>optional list of source nodes for BFS-based shortest path calculation</p> <code>None</code> Example <pre><code>import pathpyG as pp\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                    ('b', 'd'), ('c', 'e'), ('d', 'e')])\nbw = pp.algorithms.betweenness_centrality(g)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def betweenness_centrality(g: Graph, sources=None) -&gt; dict[str, float]:\n    \"\"\"Calculate the betweenness centrality of nodes based on the fast algorithm\n    proposed by Brandes:\n\n    U. Brandes: A faster algorithm for betweenness centrality, The Journal of\n    Mathematical Sociology, 2001\n\n    Args:\n        g: `Graph` object for which betweenness centrality will be computed\n        sources: optional list of source nodes for BFS-based shortest path calculation\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                            ('b', 'd'), ('c', 'e'), ('d', 'e')])\n        bw = pp.algorithms.betweenness_centrality(g)\n        ```\n    \"\"\"\n    bw = defaultdict(lambda: 0.0)\n\n    if sources == None:\n        sources = [v for v in g.nodes]\n\n    for s in sources:\n        S = list()\n        P = defaultdict(list)\n\n        sigma = defaultdict(lambda: 0)\n        sigma[s] = 1\n\n        d = defaultdict(lambda: -1)\n        d[s] = 0\n\n        Q = [s]\n        while Q:\n            v = Q.pop(0)\n            S.append(v)\n            for w in g.successors(v):\n                if d[w] &lt; 0:\n                    Q.append(w)\n                    d[w] = d[v] + 1\n                if d[w] == d[v] + 1:\n                    # we found shortest path from s via v to w\n                    sigma[w] = sigma[w] + sigma[v]\n                    P[w].append(v)\n        delta = defaultdict(lambda: 0.0)\n        while S:\n            w = S.pop()\n            for v in P[w]:\n                delta[v] = delta[v] + sigma[v] / sigma[w] * (1 + delta[w])\n                if v != w:\n                    bw[w] = bw[w] + delta[w]\n    return bw\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.map_to_nodes","title":"<code>map_to_nodes</code>","text":"<p>Map node-level centralities in dictionary to node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.graph.Graph</code> <p>Graph object</p> required <code>c</code> <code>typing.Dict</code> <p>dictionary mapping node indices to metrics</p> required Example <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n...                               node_id=['a', 'b', 'c'])\n&gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n&gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n&gt;&gt;&gt; print(c_mapped)\n{'a': 0.5, 'b': 2.7, 'c': 0.3}\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def map_to_nodes(g: Graph, c: Dict) -&gt; Dict:\n    \"\"\"Map node-level centralities in dictionary to node IDs.\n\n    Args:\n        g: Graph object\n        c: dictionary mapping node indices to metrics\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        ...                               node_id=['a', 'b', 'c'])\n        &gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n        &gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n        &gt;&gt;&gt; print(c_mapped)\n        {'a': 0.5, 'b': 2.7, 'c': 0.3}\n        ```\n    \"\"\"\n    return {g.mapping.to_id(i): c[i] for i in c}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_node_traversals","title":"<code>path_node_traversals</code>","text":"<p>Calculate the number of times any path traverses each of the nodes.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>pathpyG.core.path_data.PathData</code> <p><code>PathData</code> object that contains observations of paths in a graph</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_node_traversals(paths: PathData) -&gt; dict:\n    \"\"\"Calculate the number of times any path traverses each of the nodes.\n\n    Args:\n        paths: `PathData` object that contains observations of paths in a graph\n    \"\"\"\n    unique_node_seq, traversal_counts = torch.unique(paths.data.node_sequence, return_counts=True)\n    return {paths.mapping.to_id(node): count.item() for node, count in zip(unique_node_seq, traversal_counts)}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_visitation_probabilities","title":"<code>path_visitation_probabilities</code>","text":"<p>Calculate the probabilities that a randomly chosen path passes through each of the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be assigned a visitation probability of 0.05. This measure can be interpreted as ground truth for the notion of importance captured by PageRank applied to a graphical abstraction of the paths.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>pathpyG.core.path_data.PathData</code> <p>PathData object that contains path data</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_visitation_probabilities(paths: PathData) -&gt; dict:\n    \"\"\"Calculate the probabilities that a randomly chosen path passes through each of\n    the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be\n    assigned a visitation probability of 0.05. This measure can be interpreted as ground\n    truth for the notion of importance captured by PageRank applied to a graphical\n    abstraction of the paths.\n\n    Args:\n        paths: PathData object that contains path data\n    \"\"\"\n    # if not isinstance(paths, PathData):\n    #    assert False, \"`paths` must be an instance of Paths\"\n    # Log.add('Calculating visitation probabilities...', Severity.INFO)\n\n    # entries capture the probability that a given node is visited on an arbitrary path\n    # Note: this is identical to the subpath count of zero-length paths\n    # (i.e. the relative frequencies of nodes across all pathways)\n    visit_probabilities = path_node_traversals(paths)\n\n    # total number of visits\n    visits = 0.0\n    for v in visit_probabilities:\n        visits += visit_probabilities[v]\n\n    for v in visit_probabilities:\n        visit_probabilities[v] /= visits\n    return visit_probabilities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_betweenness_centrality","title":"<code>temporal_betweenness_centrality</code>","text":"<p>Calculate the temporal betweenness of nodes in a temporal graph.</p> <p>The temporal betweenness centrality definition is based on shortest time-respecting paths with a given maximum time difference delta, where the length of a path is given as the number of traversed edges (i.e. not the temporal duration of a path or the earliest arrival at a node).</p> <p>The algorithm is an adaptation of Brandes' fast algorithm for betweenness centrality based on the following work:</p> <p>S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal Betweenness, arXiv:2006.08668v2</p> <p>Different from the algorithm proposed above, the temporal betweenness centrality implemented in pathpyG is based on a directed acyclic event graph representation of a temporal graph and it considers a maximum waiting time of delta. The complexity is in O(nm) where n is the number of nodes in the temporal graph and m is the number of time-stamped edges.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> <code>1</code> Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\nbw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_betweenness_centrality(g: TemporalGraph, delta: int = 1) -&gt; dict[str, float]:\n    \"\"\"Calculate the temporal betweenness of nodes in a temporal graph.\n\n    The temporal betweenness centrality definition is based on shortest\n    time-respecting paths with a given maximum time difference delta, where\n    the length of a path is given as the number of traversed edges (i.e. not\n    the temporal duration of a path or the earliest arrival at a node).\n\n    The algorithm is an adaptation of Brandes' fast algorithm for betweenness\n    centrality based on the following work:\n\n    S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal\n    Betweenness, arXiv:2006.08668v2\n\n    Different from the algorithm proposed above, the temporal betweenness centrality\n    implemented in pathpyG is based on a directed acyclic event graph representation of\n    a temporal graph and it considers a maximum waiting time of delta. The complexity\n    is in O(nm) where n is the number of nodes in the temporal graph and m is the number\n    of time-stamped edges.\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        bw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    # add edges from first-order source nodes to edge events\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges], dim=1)\n    src_indices = torch.unique(src_edges_src).tolist()\n\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.m + g.n)\n\n    e_i = to_numpy(g.data.edge_index)\n\n    fo_nodes = dict()\n    for v in range(g.m + g.n):\n        if v &lt; g.m:  # return first-order target node otherwise\n            fo_nodes[v] = e_i[1, v]\n        else:\n            fo_nodes[v] = v - g.m\n\n    bw: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n    # for all first-order nodes\n    for s in tqdm(src_indices):\n\n        # for any given s, d[v] is the shortest path distance from s to v\n        # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)\n        delta_: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n        # for any given s, sigma[v] counts shortest paths from s to v\n        sigma: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma[s] = 1.0\n\n        sigma_fo: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma_fo[fo_nodes[s]] = 1.0\n\n        dist: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist[s] = 0\n\n        dist_fo: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist_fo[fo_nodes[s]] = 0\n\n        # for any given s, P[v] is the set of predecessors of v on shortest paths from s\n        P = defaultdict(set)\n\n        # Q is a queue, so we append at the right and pop from the left\n        Q: deque = deque()\n        Q.append(s)\n\n        # S is a stack, so we append at the end and pop from the end\n        S = list()\n\n        # dijkstra with path counting\n        while Q:\n            v = Q.popleft()\n            # for all successor events within delta\n            for w in event_graph.successors(v):\n\n                # we dicover w for the first time\n                if dist[w] == -1:\n                    dist[w] = dist[v] + 1\n                    if dist_fo[fo_nodes[w]] == -1:\n                        dist_fo[fo_nodes[w]] = dist[v] + 1\n                    S.append(w)\n                    Q.append(w)\n                # we found a shortest path to event w via event v\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[v]\n                    P[w].add(v)\n                    # we found a shortest path to first-order node of event w\n                    if dist[w] == dist_fo[fo_nodes[w]]:\n                        sigma_fo[fo_nodes[w]] += sigma[v]\n\n        c = 0.0\n        for i in dist_fo:\n            if dist_fo[i] &gt;= 0:\n                c += 1.0\n        bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1.0\n\n        while S:\n            w = S.pop()\n            # work backwards through paths to all targets and sum delta and sigma\n            if dist[w] == dist_fo[fo_nodes[w]]:\n                x = sigma[w] / sigma_fo[fo_nodes[w]]\n                if isnan(x):\n                    x = 0.0\n                delta_[w] += x\n            for v in P[w]:\n                x = sigma[v] / sigma[w]\n                if isnan(x):\n                    x = 0.0\n                delta_[v] += x * delta_[w]\n                bw[fo_nodes[v]] += delta_[w] * x\n\n    # map index-based centralities to node IDs\n    bw_id = defaultdict(lambda: 0.0)\n    for idx in bw:\n        bw_id[g.mapping.to_id(idx)] = bw[idx]\n    return bw_id\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_closeness_centrality","title":"<code>temporal_closeness_centrality</code>","text":"<p>Calculates the temporal closeness centrality of nodes based on observed shortest time-respecting paths between all nodes.</p> <p>Following the definition by M. A. Beauchamp 1965 (https://doi.org/10.1002/bs.3830100205).</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> required Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\ncl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_closeness_centrality(g: TemporalGraph, delta: int) -&gt; dict[str, float]:\n    \"\"\"Calculates the temporal closeness centrality of nodes based on\n    observed shortest time-respecting paths between all nodes.\n\n    Following the definition by M. A. Beauchamp 1965\n    (https://doi.org/10.1002/bs.3830100205).\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        cl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    centralities = dict()\n    dist, _ = temporal_shortest_paths(g, delta)\n    for x in g.nodes:\n        centralities[x] = sum((g.n - 1) / dist[_np.arange(g.n) != g.mapping.to_idx(x), g.mapping.to_idx(x)])\n\n    return centralities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/components/","title":"components","text":"<p>Algorithms to calculate connected components</p>"},{"location":"reference/pathpyG/algorithms/generative_models/","title":"generative_models","text":"<p>Algorithms to generate random graphs</p> <p>The functions in this module allow to generate graphs based on different probabilistic generative models.</p> Example <pre><code>import pathpyG as pp\n\ng = pp.algorithms.generative_models.erdos_renyi_gnm(n=100, m=200)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnm","title":"<code>erdos_renyi_gnm</code>","text":"<p>Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>the number of nodes of the graph</p> required <code>m</code> <code>int</code> <p>the number of random edges to be generated</p> required <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>optional given mapping of n nodes to node IDs. If this is not given a mapping is created</p> <code>None</code> <code>self_loops</code> <code>bool</code> <p>whether or not to allow self-loops (v,v) to be generated</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>whether or not multiple identical edges are allowed</p> <code>False</code> <code>directed</code> <code>bool</code> <p>whether or not to generate a directed graph</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>graph object</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnm(n: int, m: int, mapping: IndexMap | None = None,\n                    self_loops: bool = False, multi_edges: bool = False,\n                    directed: bool = False) -&gt; Graph:\n    \"\"\"Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.\n\n    Args:\n        n: the number of nodes of the graph\n        m: the number of random edges to be generated\n        mapping: optional given mapping of n nodes to node IDs. If this is not given a mapping is created\n        self_loops: whether or not to allow self-loops (v,v) to be generated\n        multi_edges: whether or not multiple identical edges are allowed\n        directed: whether or not to generate a directed graph\n\n    Returns:\n        Graph: graph object\n    \"\"\"\n    assert m &lt;= max_edges(n, directed=directed, self_loops=self_loops, multi_edges=multi_edges)\n\n    edges = set()\n    edges_added: int = 0\n\n    if mapping is None:\n        # make sure that we have indices for all n nodes even if not all\n        # nodes have incident edges\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    # Add m edges at random\n    while edges_added &lt; m:\n\n        # Choose two random nodes (with replacement if self-loops are included)\n        v, w = _np.random.choice(n, size=2, replace=self_loops)\n\n        # avoid multi-edges\n        if multi_edges or (mapping.to_id(v), mapping.to_id(w)) not in edges:\n            edges.add((mapping.to_id(v), mapping.to_id(w)))\n            if not directed and v != w:\n                edges.add((mapping.to_id(w), mapping.to_id(v)))\n            edges_added += 1\n\n    return Graph.from_edge_list(list(edges), is_undirected=not directed, mapping=mapping, num_nodes=n)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnm_randomize","title":"<code>erdos_renyi_gnm_randomize</code>","text":"<p>Generate a random graph whose number of nodes, edges, edge directedness and node IDs match the corresponding values of a given network instance. Useful to generate a randomized version of a network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>A given network used to determine number of nodes, edges, node uids, and edge directedness</p> required <code>self_loops</code> <code>bool</code> <p>Whether or not the generated network can contain loops.</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>Whether or not multiple edges can be added to the same node pair</p> <code>False</code> <p>Example: <pre><code>    # Generate undirected network\n    import pathpyG as pp\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('d', 'e')])\n    r = pp.algorithms.generative_models.G_nm_randomize(g)\n</code></pre></p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnm_randomize(graph: Graph, self_loops: bool = False, multi_edges: bool = False) -&gt; Graph:\n    \"\"\"Generate a random graph whose number of nodes, edges, edge directedness and node IDs\n    match the corresponding values of a given network instance. Useful to generate a randomized\n    version of a network.\n\n    Args:\n        graph: A given network used to determine number of nodes, edges, node uids, and edge directedness\n        self_loops: Whether or not the generated network can contain loops.\n        multi_edges: Whether or not multiple edges can be added to the same node pair\n\n    Example:\n    ```py\n        # Generate undirected network\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('d', 'e')])\n        r = pp.algorithms.generative_models.G_nm_randomize(g)\n    ```\n    \"\"\"\n    if graph.is_undirected():\n        m = int(graph.m / 2)\n    else:\n        m = graph.m\n    return erdos_renyi_gnm(\n        graph.n, m, directed=graph.is_directed(), \n        self_loops=self_loops,\n        multi_edges=multi_edges,\n        mapping=graph.mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp","title":"<code>erdos_renyi_gnp</code>","text":"<p>Generate an Erd\u00f6s-Renyi random graph with n nodes and  link probability p, using the G(n,p) model by Edgar Nelson Gilbert.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>the number of nodes of the graph</p> required <code>p</code> <code>float</code> <p>the link probability</p> required <code>self_loops</code> <code>bool</code> <p>whether or not to allow self-loops (v,v) to be generated</p> <code>False</code> <code>directed</code> <code>bool</code> <p>whether or not to generate a directed graph</p> <code>False</code> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp(n: int, p: float, mapping: IndexMap | None = None,\n                    self_loops: bool = False, directed: bool = False) -&gt; Graph:\n    \"\"\"Generate an Erd\u00f6s-Renyi random graph with n nodes and \n    link probability p, using the G(n,p) model by Edgar Nelson Gilbert.\n\n    Args:\n        n: the number of nodes of the graph\n        p: the link probability\n        self_loops: whether or not to allow self-loops (v,v) to be generated\n        directed: whether or not to generate a directed graph\n    \"\"\"\n    edges = set()\n\n    if mapping is None:\n        # make sure that we have indices for all n nodes even if not all\n        # nodes have incident edges\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    # connect pairs of nodes with probability p\n    for s in range(n):\n        if directed:\n            x = n\n        else:\n            x = s + 1\n        for t in range(x):\n            if not self_loops and t == s:\n                continue\n            if _np.random.random() &lt;= p:\n                edges.add((mapping.to_id(s), mapping.to_id(t)))\n                if not directed and s != t:\n                    edges.add((mapping.to_id(t), mapping.to_id(s)))\n\n    return Graph.from_edge_list(list(edges), is_undirected=not directed, mapping=mapping, num_nodes=n)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_likelihood","title":"<code>erdos_renyi_gnp_likelihood</code>","text":"<p>Calculate the likelihood of parameter p for a G(n,p) model and a given graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_likelihood(p: float, graph: Graph) -&gt; float:\n    \"\"\"Calculate the likelihood of parameter p for a G(n,p) model and a given graph\"\"\"\n    assert graph.is_directed is False\n    return p**graph.n * (1 - p) ** (scipy.special.binom(graph.n, 2) - graph.m / 2)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_log_likelihood","title":"<code>erdos_renyi_gnp_log_likelihood</code>","text":"<p>Calculate the log-likelihood of parameter p for a G(n,p) model and a given graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_log_likelihood(p: float, graph: Graph) -&gt; float:\n    \"\"\"Calculate the log-likelihood of parameter p for a G(n,p) model and a given graph\"\"\"\n    return (graph.m / 2) * _np.log10(p) + (scipy.special.binom(graph.n, 2) - (graph.m / 2)) * _np.log10(1 - p)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_mle","title":"<code>erdos_renyi_gnp_mle</code>","text":"<p>Calculate the maximum likelihood estimate of parameter p for a G(n,p) model and a given undirected graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_mle(graph: Graph) -&gt; float:\n    \"\"\"Calculate the maximum likelihood estimate of parameter p for a G(n,p) model and a given undirected graph\"\"\"\n    assert graph.is_directed() is False\n    return (graph.m / 2) / scipy.special.binom(graph.n, 2)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_randomize","title":"<code>erdos_renyi_gnp_randomize</code>","text":"<p>Randomize a given graph based on the Erd\u00f6s-Renyi random graph G(n,p) model.</p> <p>The number of nodes, expected number of edges, edge directedness and node uids of the generated graph match the corresponding values of the graph given as parameter.</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_randomize(graph: Graph, self_loops: bool = False) -&gt; Graph:\n    \"\"\"Randomize a given graph based on the Erd\u00f6s-Renyi random graph G(n,p) model.\n\n    The number of nodes, expected number of edges, edge directedness and node uids of the\n    generated graph match the corresponding values of the graph given as parameter.\n    \"\"\"\n    if graph.is_directed():\n        m = graph.m\n    else:\n        m = int(graph.m / 2)\n    M = max_edges(graph.n, directed=graph.is_directed(), self_loops=self_loops)\n    p = m / M\n    return erdos_renyi_gnp(n=graph.n, p=p, directed=graph.is_directed(), \n                           self_loops=self_loops, mapping=graph.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.generate_degree_sequence","title":"<code>generate_degree_sequence</code>","text":"<p>Generates a random graphic degree sequence drawn from a given degree distribution</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def generate_degree_sequence(\n    n: int,\n    distribution: Dict[float, float] | scipy.stats.rv_continuous | scipy.stats.rv_discrete,\n    **distribution_args: Any,\n) -&gt; _np.ndarray:\n    \"\"\"Generates a random graphic degree sequence drawn from a given degree distribution\"\"\"\n    s = _np.array([1])\n    # create rv_discrete object with custom distribution and generate degree sequence\n    if isinstance(distribution, dict):\n        degrees = [k for k in distribution]\n        probs = [distribution[k] for k in degrees]\n\n        dist = scipy.stats.rv_discrete(name=\"custom\", values=(degrees, probs))\n\n        while not is_graphic_erdos_gallai(s):\n            s = dist.rvs(size=n, **distribution_args)\n        return s\n    # use scipy rv objects to generate graphic degree sequence\n    elif hasattr(distribution, \"rvs\"):\n        while not is_graphic_erdos_gallai(s):\n            s = distribution.rvs(size=n, **distribution_args)\n            # Check if the distribution is discrete\n            if s.dtype != int:\n                s = _np.rint(s)\n        return s\n    else:\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.is_graphic_erdos_gallai","title":"<code>is_graphic_erdos_gallai</code>","text":"<p>Check Erd\u00f6s and Gallai condition.</p> <p>Checks whether the condition by Erd\u00f6s and Gallai (1967) for a graphic degree sequence is fulfilled.</p> <p>Parameters:</p> Name Type Description Default <code>degrees</code> <code>list[int] | numpy.ndarray</code> <p>List of integer node degrees to be tested.</p> required Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def is_graphic_erdos_gallai(degrees: list[int] | _np.ndarray) -&gt; bool:\n    \"\"\"Check Erd\u00f6s and Gallai condition.\n\n    Checks whether the condition by Erd\u00f6s and Gallai (1967) for a graphic degree\n    sequence is fulfilled.\n\n    Args:\n        degrees: List of integer node degrees to be tested.\n    \"\"\"\n    degree_sequence = sorted(degrees, reverse=True)\n    S = sum(degree_sequence)\n    n = len(degree_sequence)\n    if S % 2 != 0:\n        return False\n    for r in range(1, n):\n        M = 0\n        S = 0\n        for i in range(1, r + 1):\n            S += degree_sequence[i - 1]\n        for i in range(r + 1, n + 1):\n            M += min(r, degree_sequence[i - 1])\n        if S &gt; r * (r - 1) + M:\n            return False\n    return True\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.k_regular_random","title":"<code>k_regular_random</code>","text":"<p>Generate a random graph in which all nodes have exactly degree k</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>degree of all nodes in the generated network.</p> required <code>node_ids</code> <code>typing.Optional[list]</code> <p>Optional list of node uids that will be used.</p> <code>None</code> <p>Examples:</p> <pre><code>Generate random undirected network with given degree sequence\n\n&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n&gt;&gt;&gt; print(random_network.summary())\n...\n\nNetwork generation fails for non-graphic sequences\n\n&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n&gt;&gt;&gt; print(random_network)\nNone\n</code></pre> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def k_regular_random(k: int, n: Optional[int] = None, node_ids: Optional[list] = None) -&gt; Optional[Graph]:\n    \"\"\"Generate a random graph in which all nodes have exactly degree k\n\n    Args:\n        k: degree of all nodes in the generated network.\n        node_ids: Optional list of node uids that will be used.\n\n    Examples:\n\n        Generate random undirected network with given degree sequence\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n        &gt;&gt;&gt; print(random_network.summary())\n        ...\n\n        Network generation fails for non-graphic sequences\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n        &gt;&gt;&gt; print(random_network)\n        None\n    \"\"\"\n    if k &lt; 0:\n        msg = 'Degree parameter k must be non-negative'\n        raise ValueError(msg)\n    if n is None and node_ids is None:\n        msg = 'You must either pass a list of node ids or a number of nodes to generate'\n        raise ValueError(msg)\n\n    if n is None:\n        n = len(node_ids)\n\n    return molloy_reed([k]*n, multiedge=False, relax=False, node_ids=node_ids)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.max_edges","title":"<code>max_edges</code>","text":"<p>Returns the maximum number of edges that a directed or undirected network with n nodes can possible have (with or without loops).</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of nodes in the network</p> required <code>directed</code> <code>bool</code> <p>If True, return the maximum number of edges in a directed network.</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>If True, multiple edges between each node pair are allowed. In this case np.inf is returned.</p> <code>False</code> <code>self_loops</code> <code>bool</code> <p>If True, include self-loops.</p> <code>False</code> <p>Examples:</p> <p>Compute maximum number of edges in undirected network without self-loops and 100 nodes</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100)\n4950\n</code></pre> <p>Directed networks without self-loops</p> <pre><code>&gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True)\n9900\n</code></pre> <p>Directed networks with self-loops </p> <pre><code>&gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True, loops=True)\n10000\n</code></pre> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def max_edges(n: int, directed: bool = False, multi_edges: bool = False, self_loops: bool = False) -&gt; int | float:\n    \"\"\"Returns the maximum number of edges that a directed or undirected network with n nodes can\n    possible have (with or without loops).\n\n    Args:\n        n: The number of nodes in the network\n        directed: If True, return the maximum number of edges in a directed network.\n        multi_edges: If True, multiple edges between each node pair are allowed. In this case np.inf is returned.\n        self_loops: If True, include self-loops.\n\n    Examples:\n        Compute maximum number of edges in undirected network without self-loops and 100 nodes\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100)\n        4950\n\n        Directed networks without self-loops\n\n        &gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True)\n        9900\n\n        Directed networks with self-loops \n\n        &gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True, loops=True)\n        10000\n    \"\"\"\n\n    if multi_edges:\n        return _np.inf\n    elif self_loops and directed:\n        return int(n**2)\n    elif self_loops and not directed:\n        return int(n * (n + 1) / 2)\n    elif not self_loops and not directed:\n        return int(n * (n - 1) / 2)\n    else:  # not loops and directed:\n        return int(n * (n - 1))\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.molloy_reed","title":"<code>molloy_reed</code>","text":"<p>Generate Molloy-Reed graph.</p> <p>Generates a random undirected network with given degree sequence based on the Molloy-Reed algorithm. The condition proposed by Erd\u00f6s and Gallai (1967) is used to test whether the degree sequence is graphic, i.e. whether a network with the given degree sequence exists.</p> <p>Parameters:</p> Name Type Description Default <code>degrees</code> <p>List of integer node degrees. The number of nodes of the generated</p> required <code>relax</code> <code>bool</code> <p>If True, we conceptually allow self-loops and multi-edges, but do not</p> <code>False</code> <code>node_ids</code> <p>Optional list of node IDs that will be used for Indexmapping.</p> <code>None</code> <p>Examples:</p> <p>Generate random undirected network with given degree sequence</p> <p>import pathpyG as pp random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0]) print(random_network.summary()) ...</p> <p>Network generation fails for non-graphic degree sequence</p> <p>import pathpyG as pp random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0]) print(random_network) None</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def molloy_reed(degree_sequence: _np.array | Dict[int, float],\n                multiedge: bool = False,\n                relax: bool = False,\n                node_ids: Optional[list] = None) -&gt; Graph:\n    \"\"\"Generate Molloy-Reed graph.\n\n    Generates a random undirected network with given degree sequence based on\n    the Molloy-Reed algorithm. The condition proposed by Erd\u00f6s and Gallai (1967)\n    is used to test whether the degree sequence is graphic, i.e. whether a network\n    with the given degree sequence exists.\n\n    Args:\n        degrees: List of integer node degrees. The number of nodes of the generated\n        network corresponds to len(degrees).\n\n        relax: If True, we conceptually allow self-loops and multi-edges, but do not\n        add them to the network. This implies that the generated graph may not\n        have exactly sum(degrees)/2 edges, but it ensures that the algorithm\n        always finishes.\n\n        node_ids : Optional list of node IDs that will be used for Indexmapping.\n\n    Examples:\n\n    Generate random undirected network with given degree sequence\n\n    &gt;&gt;&gt; import pathpyG as pp\n    &gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n    &gt;&gt;&gt; print(random_network.summary())\n    ...\n\n    Network generation fails for non-graphic degree sequence\n\n    &gt;&gt;&gt; import pathpyG as pp\n    &gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n    &gt;&gt;&gt; print(random_network)\n    None\n\n    \"\"\"\n\n    # assume that we are given a graphical degree sequence\n    if not is_graphic_erdos_gallai(degree_sequence):\n        return None\n\n    # create empty network with n nodes\n    n = len(degree_sequence)\n    edges = list()\n\n    if node_ids is None or len(node_ids) != n:\n        node_ids = []\n        for i in range(n):\n            node_ids.append(str(i))\n\n    # generate edge stubs based on degree sequence\n    stubs = []\n    for i in range(n):\n        for _ in range(int(degree_sequence[i])):\n            stubs.append(str(node_ids[i]))\n\n    # connect randomly chosen pairs of stubs\n    while (len(stubs) &gt; 0):\n        v, w = _np.random.choice(stubs, 2, replace=False)\n\n        if v == w or (multiedge is False and relax is False and (v, w) in edges):\n            # remove random edge and add stubs\n            if len(edges) &gt; 0:\n                edge = random.choice(edges)\n                stubs.append(edge[0])\n                stubs.append(edge[1])\n                edges.remove(edge)\n        else:\n            if not (v, w) in edges:\n                edges.append((v, w))\n            stubs.remove(v)\n            stubs.remove(w)\n\n    return Graph.from_edge_list(edges)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.molloy_reed_randomize","title":"<code>molloy_reed_randomize</code>","text":"<p>Generates a random realization of a given network based on the observed degree sequence.</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def molloy_reed_randomize(g: Graph) -&gt; Optional[Graph]:\n    \"\"\"Generates a random realization of a given network based on the observed degree sequence.\n    \"\"\"\n    if g.is_directed:\n        raise NotImplementedError('molloy_reed_randomize is only implemented for undirected graphs')\n    # degrees are listed in order of node indices\n    degrees = degree(g.data.edge_index[1], num_nodes=g.n, dtype=torch.int).tolist()\n\n    return molloy_reed(degrees, node_ids=g.mapping.node_ids.tolist())\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.stochastic_block_model","title":"<code>stochastic_block_model</code>","text":"<p>Generate a random undirected graph based on the stochastic block model</p> <p>Parameters:</p> Name Type Description Default <code>M</code> <code>numpy.matrix</code> <p>n x n stochastic block matrix, where entry M[i,j] gives probability of edge to be generated between nodes in blocks i and j</p> required <code>z</code> <code>numpy.array</code> <p>n-dimensional block assignment vector, where z[i] gives block assignment of i-th node</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of node IDs to indices. If not given, a standard mapping based on integer IDs will be created</p> <code>None</code> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def stochastic_block_model(M: _np.matrix, z: _np.array, mapping: Optional[IndexMap] = None) -&gt; Graph:\n    \"\"\"Generate a random undirected graph based on the stochastic block model\n\n    Args:\n        M: n x n stochastic block matrix, where entry M[i,j] gives probability of edge to be generated\n            between nodes in blocks i and j\n        z: n-dimensional block assignment vector, where z[i] gives block assignment of i-th node\n        mapping: optional mapping of node IDs to indices. If not given, a standard\n            mapping based on integer IDs will be created\n    \"\"\"\n    # the number of nodes is implicitly given by the length of block assignment vector z\n    n = len(z)\n\n    # we can use pre-defined node names, if not given, we use contiguous numbers\n    if mapping is None:\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    edges = []\n\n    # randomly generate links with probabilities given by entries of the stochastic block matrix M\n    for u in range(n):\n        for v in range(u):\n            if _np.random.random() &lt;= M[z[u], z[v]]:\n                edges.append((mapping.to_id(u), mapping.to_id(v)))\n                edges.append((mapping.to_id(v), mapping.to_id(u)))\n\n    g = Graph.from_edge_list(edges, mapping=mapping, num_nodes=n)\n    g.data.node_label = torch.tensor(z)\n    return g\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.watts_strogatz","title":"<code>watts_strogatz</code>","text":"<p>Generate a Watts-Strogatz small-world graph.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of nodes in the graph.</p> required <code>s</code> <code>int</code> <p>The number of edges to attach from a new node to existing nodes.</p> required <code>p</code> <code>float</code> <p>The probability of rewiring each edge.</p> <code>0.0</code> <code>undirected</code> <code>bool</code> <p>If True, the graph will be undirected.</p> <code>True</code> <code>allow_duplicate_edges</code> <code>bool</code> <p>If True, allow duplicate edges in the graph. This is faster but may result in fewer edges than requested in the undirected case or duplicates in the directed case.</p> <code>True</code> <code>allow_self_loops</code> <code>bool</code> <p>If True, allow self-loops in the graph. This is faster but may result in fewer edges than requested in the undirected case.</p> <code>True</code> <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>A mapping from the node indices to node names.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>A Watts-Strogatz small-world graph.</p> <p>Examples:</p> <pre><code>g = Watts_Strogatz(100, 4, 0.1, mapping=pp.IndexMap([f\"n_{i}\" for i in range(100)])\n</code></pre> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def watts_strogatz(\n    n: int,\n    s: int,\n    p: float = 0.0,\n    undirected: bool = True,\n    allow_duplicate_edges: bool = True,\n    allow_self_loops: bool = True,\n    mapping: IndexMap | None = None,\n) -&gt; Graph:\n    \"\"\"Generate a Watts-Strogatz small-world graph.\n\n    Args:\n        n: The number of nodes in the graph.\n        s: The number of edges to attach from a new node to existing nodes.\n        p: The probability of rewiring each edge.\n        undirected: If True, the graph will be undirected.\n        allow_duplicate_edges: If True, allow duplicate edges in the graph.\n            This is faster but may result in fewer edges than requested in the undirected case\n            or duplicates in the directed case.\n        allow_self_loops: If True, allow self-loops in the graph.\n            This is faster but may result in fewer edges than requested in the undirected case.\n        mapping: A mapping from the node indices to node names.\n\n    Returns:\n        Graph: A Watts-Strogatz small-world graph.\n\n    Examples:\n        ```py\n        g = Watts_Strogatz(100, 4, 0.1, mapping=pp.IndexMap([f\"n_{i}\" for i in range(100)])\n        ```\n    \"\"\"\n\n    nodes = torch.arange(n)\n\n    # construct a ring lattice (dimension 1)\n    edges = (\n        torch.stack([torch.stack((nodes, torch.roll(nodes, shifts=-i, dims=0))) for i in range(1, s + 1)], dim=0)\n        .permute(1, 0, 2)\n        .reshape(2, -1)\n    )\n\n    if not allow_duplicate_edges:\n        if n * (n - 1) &lt; edges.shape[1]:\n            raise ValueError(\n                \"The number of edges is greater than the number of possible edges in the graph. Set `allow_duplicate_edges=True` to allow this.\"\n            )\n        elif n * (n - 1) * 0.5 &lt; edges.shape[1] and p &gt; 0.3:\n            warnings.warn(\n                \"Avoding duplicate in graphs with high connectivity and high rewiring probability may be slow. Consider setting `allow_duplicate_edges=True`.\"\n            )\n\n    # Rewire each link with probability p\n    rand_vals = torch.rand(edges.shape[1])\n    rewire_mask = rand_vals &lt; p\n\n    # Generate random nodes excluding the current node for each edge that needs to be rewired, also avoid duplicate edges\n    edges[1, rewire_mask] = torch.randint(n, (rewire_mask.sum(),))\n\n    # In the undirected case, make sure the edges all point in the same direction\n    # to avoid duplicate edges pointing in opposite directions\n    if undirected:\n        edges = edges.sort(dim=0)[0]\n    final_edges = edges\n\n    if not allow_duplicate_edges:\n        # Remove duplicate edges\n        final_edges, counts = edges.unique(dim=1, return_counts=True)\n        if final_edges.shape[0] &lt; edges.shape[1]:\n            for i, edge in enumerate(final_edges[:, counts &gt; 1].T):\n                for _ in range(counts[counts &gt; 1][i] - 1):\n                    while True:\n                        new_edge = torch.tensor([edge[0], torch.randint(n, (1,))]).sort()[0].unsqueeze(1)\n                        # Check if the new edge is already in the final edges\n                        # and add it if not\n                        if (new_edge != final_edges).any(dim=0).all():\n                            final_edges = torch.cat((final_edges, new_edge), dim=1)\n                            break\n\n    if not allow_self_loops:\n        self_loop_edges = final_edges[:, final_edges[0] == final_edges[1]]\n        final_edges = final_edges[:, final_edges[0] != final_edges[1]]\n        for self_loop_edge in self_loop_edges.T:\n            while True:\n                new_edge = torch.tensor([self_loop_edge[0], torch.randint(n, (1,))]).sort()[0].unsqueeze(1)\n                # Check if the new edge is already in the final edges\n                # and add it if not\n                if (new_edge != final_edges).any(dim=0).all() and new_edge[0] != new_edge[1]:\n                    final_edges = torch.cat((final_edges, new_edge), dim=1)\n                    break\n\n    g = Graph.from_edge_index(final_edges, mapping=mapping)\n    if undirected:\n        g = g.to_undirected()\n    return g\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/","title":"lift_order","text":"<p>Utility functions for lifting the order of a graph (line-graph transformation).</p>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.aggregate_edge_index","title":"<code>aggregate_edge_index</code>","text":"<p>Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object containing the (higher-order) edge index without duplicates and the node sequences.</p> <p>This method can be seen as a higher-order generalization of the <code>torch_geometric.utils.coalesce</code> method. It is used for example to generate the DeBruijn graph of a given order from the corresponding line graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of a (higher-order) graph where each source and destination node corresponds to a node which is an edge in the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of first order nodes that each node in the edge index corresponds to.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights corresponding to the edge index.</p> <code>None</code> <p>Returns:</p> Type Description <code>pathpyG.core.graph.Graph</code> <p>A graph object containing the aggregated edge index, the node sequences, the edge weights and the inverse index.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def aggregate_edge_index(\n    edge_index: torch.Tensor, node_sequence: torch.Tensor, edge_weight: torch.Tensor | None = None, aggr: str = \"sum\"\n) -&gt; Graph:\n    \"\"\"\n    Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object\n    containing the (higher-order) edge index without duplicates and the node sequences.\n\n    This method can be seen as a higher-order generalization of the `torch_geometric.utils.coalesce` method.\n    It is used for example to generate the DeBruijn graph of a given order from the corresponding line graph.\n\n    Args:\n        edge_index: The edge index of a (higher-order) graph where each source and destination node\n            corresponds to a node which is an edge in the (k-1)-th order graph.\n        node_sequence: The node sequences of first order nodes that each node in the edge index corresponds to.\n        edge_weight: The edge weights corresponding to the edge index.\n\n    Returns:\n        A graph object containing the aggregated edge index, the node sequences, the edge weights and the inverse index.\n    \"\"\"\n    if edge_weight is None:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n\n    unique_nodes, inverse_idx = torch.unique(node_sequence, dim=0, return_inverse=True)\n    # If first order, then the indices in the node sequence are the inverse idx we would need already\n    if node_sequence.size(1) == 1:\n        mapped_edge_index = node_sequence.squeeze()[edge_index]\n    else:\n        mapped_edge_index = inverse_idx[edge_index]\n    aggregated_edge_index, edge_weight = coalesce(\n        mapped_edge_index,\n        edge_attr=edge_weight,\n        num_nodes=unique_nodes.size(0),\n        reduce=aggr,\n    )\n    data = Data(\n        edge_index=aggregated_edge_index,\n        num_nodes=unique_nodes.size(0),\n        node_sequence=unique_nodes,\n        edge_weight=edge_weight,\n        inverse_idx=inverse_idx,\n    )\n    return Graph(data)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.aggregate_node_attributes","title":"<code>aggregate_node_attributes</code>","text":"<p>Aggregate the node attributes of each pair of nodes in the edge index</p> <p>This method aggregates the node attributes of each pair of nodes in the edge index using the aggregation method specified. The method returns an attribute for each edge. The aggregation methods are: - \"src\": Use the attribute of the source node for each edge. - \"dst\": Use the attribute of the destination node for each edge. - \"max\": Use the maximum of the attributes of the source and destination nodes for each edge. - \"mul\": Use the product of the attributes of the source and destination nodes for each edge. - \"add\": Use the sum of the attributes of the source and destination nodes for each edge.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of the graph.</p> required <code>node_attribute</code> <code>torch.Tensor</code> <p>The node attribute tensor.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".</p> <code>'src'</code> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>The aggregated node attributes for each edge.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def aggregate_node_attributes(\n    edge_index: torch.Tensor, node_attribute: torch.Tensor, aggr: str = \"src\"\n) -&gt; torch.Tensor:\n    \"\"\"\n    Aggregate the node attributes of each pair of nodes in the edge index\n\n    This method aggregates the node attributes of each pair of nodes in the edge index\n    using the aggregation method specified. The method returns an attribute for each edge.\n    The aggregation methods are:\n    - \"src\": Use the attribute of the source node for each edge.\n    - \"dst\": Use the attribute of the destination node for each edge.\n    - \"max\": Use the maximum of the attributes of the source and destination nodes for each edge.\n    - \"mul\": Use the product of the attributes of the source and destination nodes for each edge.\n    - \"add\": Use the sum of the attributes of the source and destination nodes for each edge.\n\n    Args:\n        edge_index: The edge index of the graph.\n        node_attribute: The node attribute tensor.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".\n\n    Returns:\n        The aggregated node attributes for each edge.\n    \"\"\"\n    if aggr == \"src\":\n        aggr_attributes = node_attribute[edge_index[0]]\n    elif aggr == \"dst\":\n        aggr_attributes = node_attribute[edge_index[1]]\n    elif aggr == \"max\":\n        aggr_attributes = torch.maximum(node_attribute[edge_index[0]], node_attribute[edge_index[1]])\n    elif aggr == \"mul\":\n        aggr_attributes = node_attribute[edge_index[0]] * node_attribute[edge_index[1]]\n    elif aggr == \"add\":\n        aggr_attributes = node_attribute[edge_index[0]] + node_attribute[edge_index[1]]\n    else:\n        raise ValueError(f\"Unknown aggregation method {aggr}\")\n    return aggr_attributes\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.lift_order_edge_index","title":"<code>lift_order_edge_index</code>","text":"<p>Line graph transformation.</p> <p>Do a line graph transformation on the edge index to lift the order of the graph by one. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>num_nodes</code> <code>int</code> <p>The number of nodes in the graph.</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>The edge index of the lifted (line) graph.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int) -&gt; torch.Tensor:\n    \"\"\"Line graph transformation.\n\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        num_nodes: The number of nodes in the graph.\n\n    Returns:\n        The edge index of the lifted (line) graph.\n    \"\"\"\n    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n    # Map outdegree to each destination node to create an edge for each combination\n    # of incoming and outgoing edges for each destination node\n    outdegree_per_dst = outdegree[edge_index[1]]\n    num_new_edges = outdegree_per_dst.sum()\n    # Create sources of the new higher-order edges\n    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n    # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n    # of all previous nodes in the ordered sequence of nodes\n    ptrs = cumsum(outdegree, dim=0)[:-1]\n    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n    idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n    ho_edge_dsts += idx_correction\n    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.lift_order_edge_index_weighted","title":"<code>lift_order_edge_index_weighted</code>","text":"<p>Weighted line graph transformation.</p> <p>Do a line graph transformation on the edge index to lift the order of the graph by one. Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>edge_weight</code> <code>torch.Tensor</code> <p>The edge weights of the (k-1)th order graph.</p> required <code>num_nodes</code> <code>int</code> <p>The number of nodes in the graph.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".</p> <code>'src'</code> <p>Returns:</p> Type Description <code>tuple[torch.Tensor, torch.Tensor]</code> <p>A tuple containing the edge index of the lifted (line) graph and the aggregated edge weights.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def lift_order_edge_index_weighted(\n    edge_index: torch.Tensor, edge_weight: torch.Tensor, num_nodes: int, aggr: str = \"src\"\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Weighted line graph transformation.\n\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        edge_weight: The edge weights of the (k-1)th order graph.\n        num_nodes: The number of nodes in the graph.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".\n\n    Returns:\n        A tuple containing the edge index of the lifted (line) graph and the aggregated edge weights.\n    \"\"\"\n    ho_index = lift_order_edge_index(edge_index, num_nodes)\n    ho_edge_weight = aggregate_node_attributes(ho_index, edge_weight, aggr)\n\n    return ho_index, ho_edge_weight\n</code></pre>"},{"location":"reference/pathpyG/algorithms/rolling_time_window/","title":"rolling_time_window","text":"<p>Iterator interface for rolling time window analysis in temporal graphs.</p>"},{"location":"reference/pathpyG/algorithms/rolling_time_window/#pathpyG.algorithms.rolling_time_window.RollingTimeWindow","title":"<code>RollingTimeWindow</code>","text":"<p>An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.</p> Source code in <code>src/pathpyG/algorithms/rolling_time_window.py</code> <pre><code>class RollingTimeWindow:\n    \"\"\"An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.\"\"\"\n\n    def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n        \"\"\"Initialize a RollingTimeWindow instance that can be used to\n        iterate through a sequence of time-slice networks for a given\n        TemporalNetwork instance.\n\n        Args:\n            temporal_graph: TemporalGraphinstance that will be used to generate the\n                sequence of time-slice networks.\n            window_size: The width of the rolling time window used to create time-slice networks.\n            step_size: The step size in time units by which the starting\n                time of the rolling window will be incremented on each iteration.\n            return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n            weighted: Whether or not to return a weighted graph\n\n        Example:\n            ```py\n            tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n            t = pp.TemporalGraph.from_edge_list(tedges)\n            r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n            for g, w in r:\n                print('Time window ', w)\n                print(g)\n                print(g.data.edge_index)\n                print('---')\n            ```\n        \"\"\"\n        self.g = temporal_graph\n        self.window_size = window_size\n        self.step_size = step_size\n        self.current_time = self.g.start_time\n        self.return_window = return_window\n        self.weighted = weighted\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.current_time &lt;= self.g.end_time:\n            time_window = (self.current_time, self.current_time + self.window_size)\n            s = self.g.to_static_graph(weighted=self.weighted, time_window=time_window)\n            self.current_time += self.step_size\n            if self.return_window:\n                return s, time_window\n            else:\n                return s\n        else:\n            raise StopIteration()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/rolling_time_window/#pathpyG.algorithms.rolling_time_window.RollingTimeWindow.__init__","title":"<code>__init__</code>","text":"<p>Initialize a RollingTimeWindow instance that can be used to iterate through a sequence of time-slice networks for a given TemporalNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>temporal_graph</code> <p>TemporalGraphinstance that will be used to generate the sequence of time-slice networks.</p> required <code>window_size</code> <p>The width of the rolling time window used to create time-slice networks.</p> required <code>step_size</code> <p>The step size in time units by which the starting time of the rolling window will be incremented on each iteration.</p> <code>1</code> <code>return_window</code> <p>Whether or not the iterator shall return the current time window as a second return value. Default is False.</p> <code>False</code> <code>weighted</code> <p>Whether or not to return a weighted graph</p> <code>True</code> Example <pre><code>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n  ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n  ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n  ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n  ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nr = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</code></pre> Source code in <code>src/pathpyG/algorithms/rolling_time_window.py</code> <pre><code>def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n    \"\"\"Initialize a RollingTimeWindow instance that can be used to\n    iterate through a sequence of time-slice networks for a given\n    TemporalNetwork instance.\n\n    Args:\n        temporal_graph: TemporalGraphinstance that will be used to generate the\n            sequence of time-slice networks.\n        window_size: The width of the rolling time window used to create time-slice networks.\n        step_size: The step size in time units by which the starting\n            time of the rolling window will be incremented on each iteration.\n        return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n        weighted: Whether or not to return a weighted graph\n\n    Example:\n        ```py\n        tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n          ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n          ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n          ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n          ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n        t = pp.TemporalGraph.from_edge_list(tedges)\n        r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n        for g, w in r:\n            print('Time window ', w)\n            print(g)\n            print(g.data.edge_index)\n            print('---')\n        ```\n    \"\"\"\n    self.g = temporal_graph\n    self.window_size = window_size\n    self.step_size = step_size\n    self.current_time = self.g.start_time\n    self.return_window = return_window\n    self.weighted = weighted\n</code></pre>"},{"location":"reference/pathpyG/algorithms/shortest_paths/","title":"shortest_paths","text":"<p>Algorithms to calculate shortest paths in static networks</p> <p>The functions  in this module allow to compute shortest paths in static networks.</p>"},{"location":"reference/pathpyG/algorithms/temporal/","title":"temporal","text":"<p>Algorithms for the analysis of time-respecting paths in temporal graphs.</p>"},{"location":"reference/pathpyG/algorithms/temporal/#pathpyG.algorithms.temporal.temporal_shortest_paths","title":"<code>temporal_shortest_paths</code>","text":"<p>Compute shortest time-respecting paths in a temporal graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to compute shortest paths on.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events in a path.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Tuple of two numpy arrays:</p> <code>numpy.ndarray</code> <ul> <li>dist: Shortest time-respecting path distances between all first-order nodes.</li> </ul> <code>typing.Tuple[numpy.ndarray, numpy.ndarray]</code> <ul> <li>pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.</li> </ul> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def temporal_shortest_paths(g: TemporalGraph, delta: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute shortest time-respecting paths in a temporal graph.\n\n    Args:\n        g: Temporal graph to compute shortest paths on.\n        delta: Maximum time difference between events in a path.\n\n    Returns:\n        Tuple of two numpy arrays:\n        - dist: Shortest time-respecting path distances between all first-order nodes.\n        - pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n    dst_edges_dst = g.data.edge_index[1] + g.m + g.n\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.m + 2 * g.n)\n    m = event_graph.sparse_adj_matrix()\n\n    # print(f\"Created temporal event DAG with {event_graph.n} nodes and {event_graph.m} edges\")\n\n    # run disjktra for all source nodes\n    dist, pred = dijkstra(\n        m, directed=True, indices=np.arange(g.m, g.m + g.n), return_predecessors=True, unweighted=True\n    )\n\n    # limit to first-order destinations and correct distances\n    dist_fo = dist[:, g.m + g.n :] - 1\n    np.fill_diagonal(dist_fo, 0)\n\n    # limit to first-order destinations and correct predecessors\n    pred_fo = pred[:, g.n + g.m :]\n    pred_fo[pred_fo == -9999] = -1\n    idx_map = np.concatenate([to_numpy(g.data.edge_index[0].cpu()), [-1]])\n    pred_fo = idx_map[pred_fo]\n    np.fill_diagonal(pred_fo, np.arange(g.n))\n\n    return dist_fo, pred_fo\n</code></pre>"},{"location":"reference/pathpyG/algorithms/weisfeiler_leman/","title":"weisfeiler_leman","text":""},{"location":"reference/pathpyG/algorithms/weisfeiler_leman/#pathpyG.algorithms.weisfeiler_leman.WeisfeilerLeman_test","title":"<code>WeisfeilerLeman_test</code>","text":"<p>Run Weisfeiler-Leman isomorphism test on two graphs.</p> <p>The algorithm heuristically checks whether two graphs are isomorphic. If it returns False, we can be sure that the graphs are non-isomoprhic. If the test returns True we did not find conclusive evidence that they are not isomorphic, i.e. the graphs may or may not be isomophic.</p> <p>The two graphs must have IndexMap mappings that assign different node IDs to the nodes in both graphs. The function will raise an error if the node labels of both graphs overlap.</p> <p>The function returns a tuple (bool, list, list), where the first entry is the result of the test and the two lists represent the fingerprints of the two graphs. If the test yields true the fingerprints are identical. If the test fails, the fingerprints do not correspond.</p> <p>Parameters:</p> Name Type Description Default <code>g1</code> <code>pathpyG.core.graph.Graph</code> <p>pp.Graph</p> required <code>g2</code> <code>pathpyG.core.graph.Graph</code> <p>pp.Graph</p> required Source code in <code>src/pathpyG/algorithms/weisfeiler_leman.py</code> <pre><code>def WeisfeilerLeman_test(\n    g1: Graph, g2: Graph, features_g1: dict = None, features_g2: dict = None\n) -&gt; Tuple[bool, List[str], List[str]]:\n    \"\"\"Run Weisfeiler-Leman isomorphism test on two graphs.\n\n    The algorithm heuristically checks whether two graphs are isomorphic. If it returns False,\n    we can be sure that the graphs are non-isomoprhic. If the test returns True we did not find\n    conclusive evidence that they are not isomorphic, i.e. the graphs may or may not be isomophic.\n\n    The two graphs must have IndexMap mappings that assign different node IDs to the nodes\n    in both graphs. The function will raise an error if the node labels of both graphs overlap.\n\n    The function returns a tuple (bool, list, list), where the first entry is the result of the test\n    and the two lists represent the fingerprints of the two graphs. If the test yields true the fingerprints\n    are identical. If the test fails, the fingerprints do not correspond.\n\n    Args:\n        g1: pp.Graph\n        g2: pp.Graph\n    \"\"\"\n    if g1.mapping is None or g2.mapping is None:\n        raise Exception(\"Graphs must contain IndexMap that assigns node IDs\")\n    if len(set(g1.mapping.node_ids).intersection(g2.mapping.node_ids)) &gt; 0:\n        raise Exception(\"node identifiers of graphs must not overlap\")\n    g_combined = g1 + g2\n    # initialize labels of all nodes to zero\n    if features_g1 is None or features_g2 is None:\n        fingerprint: Dict[str | int, str] = {v: \"0\" for v in g_combined.nodes}\n    else:\n        fingerprint = features_g1.copy()\n        fingerprint.update(features_g2)\n    labels = {}\n    label_count = 1\n    stop = False\n    while not stop:\n        new_fingerprint = {}\n        for node in g_combined.nodes:\n            # create new label based on own label and sorted labels of all neighbors\n            n_label = [fingerprint[x] for x in g_combined.successors(node)]\n            n_label.sort()\n            label = str(fingerprint[node]) + str(n_label)\n            # previously unknown label\n            if label not in labels:\n                # create a new label based on next consecutive number\n                labels[label] = label_count\n                label_count += 1\n            new_fingerprint[node] = labels[label]\n        if len(set(fingerprint.values())) == len(set(new_fingerprint.values())):\n            # we processed all nodes in both graphs without encountering a new label, so we stop\n            stop = True\n        else:\n            # update fingerprint and continue\n            fingerprint = new_fingerprint.copy()\n\n    # Reduce fingerprints to nodes of g1 and g2 respectively\n    fingerprint_1 = [fingerprint[v] for v in g1.nodes]\n    fingerprint_1_sorted = fingerprint_1.copy()\n    fingerprint_1_sorted.sort()\n    fingerprint_2 = [fingerprint[v] for v in g2.nodes]\n    fingerprint_2_sorted = fingerprint_2.copy()\n    fingerprint_2_sorted.sort()\n\n    # perform WL-test\n    if fingerprint_1_sorted == fingerprint_2_sorted:\n        return True, fingerprint_1, fingerprint_2\n    return False, fingerprint_1, fingerprint_2\n</code></pre>"},{"location":"reference/pathpyG/core/","title":"core","text":"<p>Core classes for (temporal) graphs, paths, and higher-order De Bruijn graphs.</p> <p>The classes in the <code>core</code> module can be used to implement integrated pipelines to preprocess time-stamped network data, do inference and model selection of higher-order De Bruijn graph models and address temporal graph learning tasks based on time-aware graph neural networks.</p> Example <pre><code>import pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n\n# Generate toy example temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)])\n\n# Create Multi-Order model that models time-respecting paths\nm = pp.MultiOrderModel.from_temporal_graph(g, delta=1, max_order=3)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\n</code></pre>"},{"location":"reference/pathpyG/core/graph/","title":"graph","text":""},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if \"num_nodes\" not in data:\n            data.num_nodes = data.edge_index.max().item() + 1\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if (\n            data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n            or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n        ):\n            raise Exception(\"sparse size of EdgeIndex should match number of nodes!\")\n\n        # sort EdgeIndex and validate\n        data.edge_index = data.edge_index.sort_by(\"row\").values\n        data.edge_index.validate()\n\n        self.data = data\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n        # create node_sequence mapping for higher-order graphs\n        if \"node_sequence\" not in self.data:\n            self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n        Examples:\n            You can create a graph from an edge index tensor as follows:\n\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            &gt;&gt;&gt; print(g)\n            Directed graph with 3 nodes and 3 edges ...\n\n            You can also include a mapping of node IDs:\n\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n            &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n            &gt;&gt;&gt; print(g.mapping)\n            a -&gt; 0\n            b -&gt; 1\n            c -&gt; 2\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else:\n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(d, mapping=mapping)\n\n    @staticmethod\n    def from_edge_list(\n        edge_list: Iterable[Tuple[str, str]],\n        is_undirected: bool = False,\n        mapping: Optional[IndexMap] = None,\n        num_nodes: Optional[int] = None,\n    ) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n            &gt;&gt;&gt; print(list(g.edges))\n            [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        \"\"\"\n\n        if mapping is None:\n            edge_array = np.array(edge_list)\n            node_ids = np.unique(edge_array)\n            if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n                node_ids = np.sort(node_ids.astype(int)).astype(str)\n            mapping = IndexMap(node_ids)\n\n        if num_nodes is None:\n            num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex(\n            mapping.to_idxs(edge_list).T.contiguous(),\n            sparse_size=(num_nodes, num_nodes),\n            is_undirected=is_undirected,\n        )\n        return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            &gt;&gt;&gt; g_u = g.to_undirected()\n            &gt;&gt;&gt; print(g_u)\n            Undirected graph with 3 nodes and 6 (directed) edges\n        \"\"\"\n        tf = ToUndirected()\n        d = tf(self.data)\n        # unfortunately, the application of a transform creates a new edge_index of type tensor\n        # so we have to recreate the EdgeIndex tensor and sort it again\n\n        e = EdgeIndex(data=d.edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True)\n        d.edge_index = e\n        d.num_nodes = self.data.num_nodes\n        return Graph(d, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n        If the graph contains multiple edges between the same nodes, this method will coalesce\n        them into a single edge with an additional weight attribute called `edge_weight` that\n        contains the number of coalesced edges. The method returns a new graph instance with\n        the coalesced edges.\n\n        Returns:\n            Graph: Graph with coalesced edges\n        \"\"\"\n        i, w = torch_geometric.utils.coalesce(\n            self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n\n    def node_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_sequence` attribute.\n\n        Returns:\n            list: list of node attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n\n        Returns:\n            list: list of edge attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; list:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a list object that contains all nodes.\n        If an IndexMap is used, nodes are returned as string IDs.\n        If no IndexMap is used, nodes are returned as integer indices.\n\n        Returns:\n            list: list of all nodes using IDs or indices (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(np.arange(self.n)).tolist()\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    @property\n    def edges(self) -&gt; list:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a list object that contains all edges, where each\n        edge is a tuple of two elements. If an IndexMap is used to map node\n        indices to string IDs, edges are returned as tuples of string IDs.\n        If no mapping is used, edges are returned as tuples of integer indices.\n\n        Returns:\n            list: list object yielding all edges using IDs or indices (if no mapping is used)\n        \"\"\"\n        edge_list = self.mapping.to_ids(self.data.edge_index.t()).tolist()\n        if self.order &gt; 1:\n            return [tuple(map(tuple, x)) for x in edge_list]\n        return list(map(tuple, edge_list))\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n        \"\"\"\n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def successors(self, node: Union[int, str] | tuple) -&gt; list:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n\n        Returns:\n            list: list with all successors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n\n        node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n\n        Returns:\n            list: list with all predecessors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID\n\n        Returns:\n            bool: True if edge exists, False otherwise\n        \"\"\"\n        row = self.mapping.to_idx(v)\n        row_start = self.row_ptr[row]\n        row_end = self.row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in self.col[row_start:row_end]\n\n    def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor())\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return in-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing in-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return out-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing out-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n        \"\"\"\n        Return degrees of nodes.\n\n        Args:\n            mode: `in` or `out` to calculate the in- or out-degree for\n                directed networks.\n\n        Returns:\n            dict: dictionary containing degrees of nodes\n        \"\"\"\n        if mode == \"in\":\n            d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n        else:\n            d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n        return {self.mapping.to_id(i): d[i].item() for i in range(self.n)}\n\n    def weighted_outdegrees(self) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the weighted outdegrees of each node in the graph.\n\n        Args:\n            graph (Graph): pathpy graph object.\n\n        Returns:\n            tensor: Weighted outdegrees of nodes.\n        \"\"\"\n        weighted_outdegree = scatter(\n            self.data.edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\"\n        )\n        return weighted_outdegree\n\n    def transition_probabilities(self) -&gt; torch.Tensor:\n        \"\"\"\n        Compute transition probabilities based on weighted outdegrees.\n\n        Returns:\n            tensor: Transition probabilities.\n        \"\"\"\n        weighted_outdegree = self.weighted_outdegrees()\n        source_ids = self.data.edge_index[0]\n        return self.data.edge_weight / weighted_outdegree[source_ids]\n\n    def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization: normalization parameter passed to pyG `get_laplacian`\n                function\n            edge_attr: optinal name of numerical edge attribute that shall\n                be passed to pyG `get_laplacian` function as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(), normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(),\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key.startswith(\"node_\"):\n                if val.size(0) != self.n:\n                    raise ValueError(\"Attribute must have same length as number of nodes\")\n                self.data[key] = val\n            elif key.startswith(\"edge_\"):\n                if val.size(0) != self.m:\n                    raise ValueError(\"Attribute must have same length as number of edges\")\n                self.data[key] = val\n            else:\n                self.data[key] = val\n        elif key[0].startswith(\"node_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif key[0].startswith(\"edge_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n\n    @property\n    def n(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns:\n            int: number of nodes in the graph\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def m(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the number of directed edges is returned.\n\n        Returns:\n            int: number of edges in the graph\n        \"\"\"\n        return self.data.num_edges  # type: ignore\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"\n        Return order of graph.\n\n        Returns:\n            int: order of the (De Bruijn) graph\n        \"\"\"\n        return self.data.node_sequence.size(1)  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\n\n        Returns:\n            bool: True if graph is directed, False otherwise\n        \"\"\"\n        return not self.data.edge_index.is_undirected\n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\n\n        Returns:\n            bool: True if graph is undirected, False otherwise\n        \"\"\"\n        return self.data.edge_index.is_undirected\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\n\n        Returns:\n            bool: True if graph contains self-loops, False otherwise\n        \"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph) -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Examples:\n            Adding two graphs without node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 6 edges\n\n            Adding two graphs with identical node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 4 edges\n\n            Adding two graphs with non-overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 6 nodes and 4 edges\n\n            Adding two graphs with partly overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 5 nodes and 4 edges\n        \"\"\"\n\n        if self.order &gt; 1:\n            raise NotImplementedError(\"Add operator can only be applied to order 1 graphs\")\n\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        # compute overlap and additional nodes in g2 over g1\n        overlap = set(m2.node_ids).intersection(m1.node_ids)\n        additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n        d2_idx_translation = {}\n        node_ids = [\"\"] * (self.n + len(additional_nodes))\n        # keep mappings of nodes in g1\n        for v in m1.node_ids:\n            node_ids[m1.to_idx(v)] = v\n        for v in m2.node_ids:\n            d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n        # for overlapping node IDs we must correct node indices in m2\n        for v in overlap:\n            d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n        # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n        for v in additional_nodes:\n            new_idx = m2.to_idx(v) + self.n - len(overlap)\n            node_ids[new_idx] = v\n            d2_idx_translation[m2.to_idx(v)] = new_idx\n        # apply index translation to d2\n        # fast dictionary based mapping using torch\n        palette, key = zip(*d2_idx_translation.items())\n        key = torch.tensor(key)\n        palette = torch.tensor(palette)\n\n        index = torch.bucketize(d2.edge_index.ravel(), palette)\n        d2.edge_index = key[index].reshape(d2.edge_index.shape)\n        d = d1.concat(d2)\n        mapping = IndexMap(node_ids)\n        d.num_nodes = self.n + len(additional_nodes)\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.n, self.m)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.edges","title":"<code>edges: list</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a list object that contains all edges, where each edge is a tuple of two elements. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of string IDs. If no mapping is used, edges are returned as tuples of integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list object yielding all edges using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.in_degrees","title":"<code>in_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return in-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing in-degrees of nodes</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.m","title":"<code>m: int</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the number of directed edges is returned.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of edges in the graph</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.n","title":"<code>n: int</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of nodes in the graph</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.nodes","title":"<code>nodes: list</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a list object that contains all nodes. If an IndexMap is used, nodes are returned as string IDs. If no IndexMap is used, nodes are returned as integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list of all nodes using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.order","title":"<code>order: int</code>  <code>property</code>","text":"<p>Return order of graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>order of the (De Bruijn) graph</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.out_degrees","title":"<code>out_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return out-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing out-degrees of nodes</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Examples:</p> <p>Adding two graphs without node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 6 edges\n</code></pre> <p>Adding two graphs with identical node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 4 edges\n</code></pre> <p>Adding two graphs with non-overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 6 nodes and 4 edges\n</code></pre> <p>Adding two graphs with partly overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 5 nodes and 4 edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __add__(self, other: Graph) -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Examples:\n        Adding two graphs without node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 6 edges\n\n        Adding two graphs with identical node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 4 edges\n\n        Adding two graphs with non-overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 6 nodes and 4 edges\n\n        Adding two graphs with partly overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 5 nodes and 4 edges\n    \"\"\"\n\n    if self.order &gt; 1:\n        raise NotImplementedError(\"Add operator can only be applied to order 1 graphs\")\n\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    # compute overlap and additional nodes in g2 over g1\n    overlap = set(m2.node_ids).intersection(m1.node_ids)\n    additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n    d2_idx_translation = {}\n    node_ids = [\"\"] * (self.n + len(additional_nodes))\n    # keep mappings of nodes in g1\n    for v in m1.node_ids:\n        node_ids[m1.to_idx(v)] = v\n    for v in m2.node_ids:\n        d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n    # for overlapping node IDs we must correct node indices in m2\n    for v in overlap:\n        d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n    # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n    for v in additional_nodes:\n        new_idx = m2.to_idx(v) + self.n - len(overlap)\n        node_ids[new_idx] = v\n        d2_idx_translation[m2.to_idx(v)] = new_idx\n    # apply index translation to d2\n    # fast dictionary based mapping using torch\n    palette, key = zip(*d2_idx_translation.items())\n    key = torch.tensor(key)\n    palette = torch.tensor(palette)\n\n    index = torch.bucketize(d2.edge_index.ravel(), palette)\n    d2.edge_index = key[index].reshape(d2.edge_index.shape)\n    d = d1.concat(d2)\n    mapping = IndexMap(node_ids)\n    d.num_nodes = self.n + len(additional_nodes)\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if \"num_nodes\" not in data:\n        data.num_nodes = data.edge_index.max().item() + 1\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if (\n        data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n        or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n    ):\n        raise Exception(\"sparse size of EdgeIndex should match number of nodes!\")\n\n    # sort EdgeIndex and validate\n    data.edge_index = data.edge_index.sort_by(\"row\").values\n    data.edge_index.validate()\n\n    self.data = data\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    # create node_sequence mapping for higher-order graphs\n    if \"node_sequence\" not in self.data:\n        self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key.startswith(\"node_\"):\n            if val.size(0) != self.n:\n                raise ValueError(\"Attribute must have same length as number of nodes\")\n            self.data[key] = val\n        elif key.startswith(\"edge_\"):\n            if val.size(0) != self.m:\n                raise ValueError(\"Attribute must have same length as number of edges\")\n            self.data[key] = val\n        else:\n            self.data[key] = val\n    elif key[0].startswith(\"node_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif key[0].startswith(\"edge_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.n, self.m)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate the in- or out-degree for directed networks.</p> <code>'in'</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing degrees of nodes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n    \"\"\"\n    Return degrees of nodes.\n\n    Args:\n        mode: `in` or `out` to calculate the in- or out-degree for\n            directed networks.\n\n    Returns:\n        dict: dictionary containing degrees of nodes\n    \"\"\"\n    if mode == \"in\":\n        d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n    else:\n        d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n    return {self.mapping.to_id(i): d[i].item() for i in range(self.n)}\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of edge attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def edge_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n\n    Returns:\n        list: list of edge attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <code>int</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.</p> <code>None</code> <p>Examples:</p> <p>You can create a graph from an edge index tensor as follows:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n&gt;&gt;&gt; print(g)\nDirected graph with 3 nodes and 3 edges ...\n</code></pre> <p>You can also include a mapping of node IDs:</p> <pre><code>&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n&gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n&gt;&gt;&gt; print(g.mapping)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n    Examples:\n        You can create a graph from an edge index tensor as follows:\n\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        &gt;&gt;&gt; print(g)\n        Directed graph with 3 nodes and 3 edges ...\n\n        You can also include a mapping of node IDs:\n\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n        &gt;&gt;&gt; print(g.mapping)\n        a -&gt; 0\n        b -&gt; 1\n        c -&gt; 2\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else:\n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>num_nodes</code> <code>typing.Optional[int]</code> <p>optional number of nodes (useful in case not all nodes have incident edges)</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n&gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n&gt;&gt;&gt; print(list(g.edges))\n[('a', 'b'), ('a', 'c'), ('b', 'c')]\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(\n    edge_list: Iterable[Tuple[str, str]],\n    is_undirected: bool = False,\n    mapping: Optional[IndexMap] = None,\n    num_nodes: Optional[int] = None,\n) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n        &gt;&gt;&gt; print(list(g.edges))\n        [('a', 'b'), ('a', 'c'), ('b', 'c')]\n    \"\"\"\n\n    if mapping is None:\n        edge_array = np.array(edge_list)\n        node_ids = np.unique(edge_array)\n        if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n            node_ids = np.sort(node_ids.astype(int)).astype(str)\n        mapping = IndexMap(node_ids)\n\n    if num_nodes is None:\n        num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex(\n        mapping.to_idxs(edge_list).T.contiguous(),\n        sparse_size=(num_nodes, num_nodes),\n        is_undirected=is_undirected,\n    )\n    return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all predecessor nodes of the node indexed by <code>col_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n    \"\"\"\n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all successor nodes of the node indexed by <code>row_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph contains self-loops, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\n\n    Returns:\n        bool: True if graph contains self-loops, False otherwise\n    \"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is directed, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\n\n    Returns:\n        bool: True if graph is directed, False otherwise\n    \"\"\"\n    return not self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if edge exists, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID\n\n    Returns:\n        bool: True if edge exists, False otherwise\n    \"\"\"\n    row = self.mapping.to_idx(v)\n    row_start = self.row_ptr[row]\n    row_end = self.row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in self.col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is undirected, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\n\n    Returns:\n        bool: True if graph is undirected, False otherwise\n    \"\"\"\n    return self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.laplacian","title":"<code>laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code> function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: Laplacian matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization: normalization parameter passed to pyG `get_laplacian`\n            function\n        edge_attr: optinal name of numerical edge attribute that shall\n            be passed to pyG `get_laplacian` function as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(), normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(),\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_sequence</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of node attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def node_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_sequence` attribute.\n\n    Returns:\n        list: list of node attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all predecessors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n\n    Returns:\n        list: list with all predecessors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n    node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.sparse_adj_matrix","title":"<code>sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor())\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all successors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) -&gt; list:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n\n    Returns:\n        list: list with all successors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n\n    node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n&gt;&gt;&gt; g_u = g.to_undirected()\n&gt;&gt;&gt; print(g_u)\nUndirected graph with 3 nodes and 6 (directed) edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        &gt;&gt;&gt; g_u = g.to_undirected()\n        &gt;&gt;&gt; print(g_u)\n        Undirected graph with 3 nodes and 6 (directed) edges\n    \"\"\"\n    tf = ToUndirected()\n    d = tf(self.data)\n    # unfortunately, the application of a transform creates a new edge_index of type tensor\n    # so we have to recreate the EdgeIndex tensor and sort it again\n\n    e = EdgeIndex(data=d.edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True)\n    d.edge_index = e\n    d.num_nodes = self.data.num_nodes\n    return Graph(d, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> <p>If the graph contains multiple edges between the same nodes, this method will coalesce them into a single edge with an additional weight attribute called <code>edge_weight</code> that contains the number of coalesced edges. The method returns a new graph instance with the coalesced edges.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>Graph with coalesced edges</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n    If the graph contains multiple edges between the same nodes, this method will coalesce\n    them into a single edge with an additional weight attribute called `edge_weight` that\n    contains the number of coalesced edges. The method returns a new graph instance with\n    the coalesced edges.\n\n    Returns:\n        Graph: Graph with coalesced edges\n    \"\"\"\n    i, w = torch_geometric.utils.coalesce(\n        self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n    )\n    return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Compute transition probabilities based on weighted outdegrees.</p> <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Transition probabilities.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def transition_probabilities(self) -&gt; torch.Tensor:\n    \"\"\"\n    Compute transition probabilities based on weighted outdegrees.\n\n    Returns:\n        tensor: Transition probabilities.\n    \"\"\"\n    weighted_outdegree = self.weighted_outdegrees()\n    source_ids = self.data.edge_index[0]\n    return self.data.edge_weight / weighted_outdegree[source_ids]\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.weighted_outdegrees","title":"<code>weighted_outdegrees</code>","text":"<p>Compute the weighted outdegrees of each node in the graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>pathpy graph object.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Weighted outdegrees of nodes.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def weighted_outdegrees(self) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the weighted outdegrees of each node in the graph.\n\n    Args:\n        graph (Graph): pathpy graph object.\n\n    Returns:\n        tensor: Weighted outdegrees of nodes.\n    \"\"\"\n    weighted_outdegree = scatter(\n        self.data.edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\"\n    )\n    return weighted_outdegree\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/","title":"index_map","text":"<p>IndexMap class for mapping node indices to IDs.</p>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap","title":"<code>IndexMap</code>","text":"<p>Maps node indices to IDs.</p> <p>This class keeps a mapping from any node ID, e.g. names (strings) or higher-order IDs (tuples), to an index of the corresponding node in the initial list of IDs, enabling fast lookup of node IDs from a <code>torch_geometric.data.Data</code> object.</p> <p>Attributes:</p> Name Type Description <code>node_ids</code> <code>numpy.ndarray | None</code> <p><code>numpy.ndarray</code> storing the node IDs, enabling fast lookup of multiple node IDs from indices.</p> <code>id_to_idx</code> <code>dict</code> <p><code>dict</code> mapping each node ID to its index.</p> <code>id_shape</code> <code>tuple</code> <p><code>tuple</code> storing the shape of the ID. The default shape is (-1,) for first-order IDs. For higher-order IDs, the shape will be <code>(-1, k)</code> with order <code>k</code>.</p> <p>Examples:</p> <p>Initialize an <code>IndexMap</code> object with a list of string IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\n</code></pre> <p>Add additional IDs to the mapping:</p> <pre><code>&gt;&gt;&gt; index_map.add_id(\"D\")\n&gt;&gt;&gt; print(index_map.to_idx(\"D\"))\n3\n</code></pre> <p>Map indices to IDs. Use <code>to_id</code> for single indices and <code>to_ids</code> for multiple indices. Note that the shape of the given index list will be preserved in the output:</p> <pre><code>&gt;&gt;&gt; print(index_map.to_id(1))\nB\n&gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n['A' 'C']\n</code></pre> <p>Map IDs to indices. Works analogously to the reversed mapping and can, e.g., be used to create an <code>edge_index</code> tensor from a list of edges given by source and destination node IDs:</p> <pre><code>&gt;&gt;&gt; edge_index = index_map.to_idxs([[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]).T\n</code></pre> <p>Create a higher-order ID mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n&gt;&gt;&gt; print(index_map)\n('A', 'B') -&gt; 0\n('A', 'C') -&gt; 1\n('B', 'C') -&gt; 2\n</code></pre> <p>The methods above work analogously for higher-order IDs:</p> <pre><code>&gt;&gt;&gt; print(index_map.to_id(1))\n('A', 'C')\n&gt;&gt;&gt; print(index_map.to_ids([[0], [2]]))\n[[('A', 'B')], [('B', 'C')]]\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>class IndexMap:\n    \"\"\"Maps node indices to IDs.\n\n    This class keeps a mapping from any node ID, e.g. names (strings) or higher-order IDs (tuples),\n    to an index of the corresponding node in the initial list of IDs, enabling fast lookup of node IDs\n    from a `torch_geometric.data.Data` object.\n\n    Attributes:\n        node_ids: `numpy.ndarray` storing the node IDs, enabling fast lookup of multiple node IDs from indices.\n        id_to_idx: `dict` mapping each node ID to its index.\n        id_shape: `tuple` storing the shape of the ID. The default shape is (-1,) for first-order IDs.\n            For higher-order IDs, the shape will be `(-1, k)` with order `k`.\n\n    Examples:\n        Initialize an `IndexMap` object with a list of string IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n\n        Add additional IDs to the mapping:\n\n        &gt;&gt;&gt; index_map.add_id(\"D\")\n        &gt;&gt;&gt; print(index_map.to_idx(\"D\"))\n        3\n\n        Map indices to IDs. Use `to_id` for single indices and `to_ids` for multiple indices.\n        Note that the shape of the given index list will be preserved in the output:\n\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        B\n        &gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n        ['A' 'C']\n\n        Map IDs to indices. Works analogously to the reversed mapping and can, e.g., be used to\n        create an `edge_index` tensor from a list of edges given by source and destination node IDs:\n\n        &gt;&gt;&gt; edge_index = index_map.to_idxs([[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]).T\n\n        Create a higher-order ID mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n        &gt;&gt;&gt; print(index_map)\n        ('A', 'B') -&gt; 0\n        ('A', 'C') -&gt; 1\n        ('B', 'C') -&gt; 2\n\n        The methods above work analogously for higher-order IDs:\n\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        ('A', 'C')\n        &gt;&gt;&gt; print(index_map.to_ids([[0], [2]]))\n        [[('A', 'B')], [('B', 'C')]]\n    \"\"\"\n\n    def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n        \"\"\"Initialize mapping from indices to node IDs.\n\n        The mapping will keep the ordering of the IDs as provided by `node_ids`. If the IDs are not unique,\n        an error will be raised.\n\n        Args:\n            node_ids: List of node IDs to initialize mapping.\n\n        Raises:\n            ValueError: If IDs are not unique.\n\n        Examples:\n            Initialize an `IndexMap` object with a list of string IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"C\", \"B\"])\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            C -&gt; 1\n            B -&gt; 2\n\n            Handle non-unique IDs and sort IDs lexicographically:\n\n            &gt;&gt;&gt; node_ids = [\"A\", \"C\", \"B\", \"A\"]\n            &gt;&gt;&gt; index_map = IndexMap(np.unique(node_ids))\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n        \"\"\"\n        self.node_ids: np.ndarray | None = None\n        self.id_to_idx: dict = {}\n        self.id_shape: tuple = (-1,)  # If the index map is higher order, this will be the shape of the ID\n        if node_ids is not None:\n            self.add_ids(node_ids)\n\n    @property\n    def has_ids(self) -&gt; bool:\n        \"\"\"Return whether mapping has IDs.\n\n        Returns:\n            Whether mapping has IDs.\n\n        Examples:\n            Check if mapping has IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.has_ids)\n            False\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.has_ids)\n            True\n        \"\"\"\n        return self.node_ids is not None\n\n    def num_ids(self) -&gt; int:\n        \"\"\"Return number of IDs. If mapping is not defined, return 0.\n\n        Returns:\n            Number of IDs.\n\n        Examples:\n            Get number of IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.num_ids())\n            0\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.num_ids())\n            3\n\n            &gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n            &gt;&gt;&gt; print(index_map.num_ids())\n            3\n        \"\"\"\n        if self.node_ids is None:\n            return 0\n        else:\n            return len(self.node_ids)\n\n    def add_id(self, node_id: Any) -&gt; None:\n        \"\"\"Assigns additional ID to the next consecutive index.\n\n        Args:\n            node_id: ID to assign.\n\n        Raises:\n            ValueError: If ID is already present in the mapping.\n\n        Examples:\n            Add an additional ID to the mapping:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; index_map.add_id(\"D\")\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n            D -&gt; 3\n        \"\"\"\n        if node_id not in self.id_to_idx:\n            idx = self.num_ids()\n            if isinstance(node_id, (list, tuple)):\n                node_id = np.array(node_id)\n                self.id_shape = (-1, *node_id.shape)\n            self.node_ids = (\n                np.concatenate((self.node_ids, np.array([node_id])))\n                if self.node_ids is not None\n                else np.array([node_id])\n            )\n            self.id_to_idx[node_id] = idx\n        else:\n            raise ValueError(\"ID already present in the mapping.\")\n\n    def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n        \"\"\"Assigns additional IDs to next consecutive indices. The order of IDs is preserved.\n\n        Args:\n            node_ids: IDs to assign\n\n        Raises:\n            ValueError: If IDs are not unique or already present in the mapping.\n\n        Examples:\n            Add additional IDs to the mapping:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; index_map.add_ids([\"E\", \"D\"])\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n            E -&gt; 3\n            D -&gt; 4\n        \"\"\"\n        cur_num_ids = self.num_ids()\n        if isinstance(node_ids, list) and isinstance(node_ids[0], (list, tuple)):\n            self.id_shape = (-1, *np.array(node_ids[0]).shape)\n\n        if not isinstance(node_ids, np.ndarray):\n            node_ids = np.array(node_ids)\n\n        all_ids = np.concatenate((self.node_ids, node_ids)) if self.node_ids is not None else node_ids\n        unique_ids = np.unique(all_ids, axis=0 if self.id_shape != (-1,) else None)\n\n        if len(unique_ids) != len(all_ids):\n            raise ValueError(\"IDs are not unique or already present in the mapping.\")\n\n        self.node_ids = all_ids\n        self.id_to_idx.update(\n            {tuple(v) if self.id_shape != (-1,) else v: i + cur_num_ids for i, v in enumerate(node_ids)}\n        )\n\n    def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n        \"\"\"Map index to ID if mapping is defined, return index otherwise.\n\n        Args:\n            idx: Index to map.\n\n        Returns:\n            ID if mapping is defined, index otherwise.\n\n        Examples:\n            Map index to ID:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_id(1))\n            B\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_id(1))\n            1\n        \"\"\"\n        if self.has_ids:\n            if self.id_shape == (-1,):\n                return self.node_ids[idx]  # type: ignore\n            else:\n                return tuple(self.node_ids[idx])  # type: ignore\n        else:\n            return idx\n\n    def to_ids(self, idxs: list | tuple | np.ndarray) -&gt; np.ndarray:\n        \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise. The shape of the given index\n        list will be preserved in the output.\n\n        Args:\n            idxs: Indices to map.\n\n        Returns:\n            IDs if mapping is defined, indices otherwise.\n\n        Examples:\n            Map list of indices to IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n            ['A' 'C']\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_ids(torch.tensor([0, 2])))\n            tensor([0 2])\n\n            Map edge_index tensor to array of edges:\n\n            &gt;&gt;&gt; edge_index = torch.tensor([[0, 2, 2, 3], [1, 1, 3, 0]])\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\", \"D\"])\n            &gt;&gt;&gt; print(index_map.to_ids(edge_index.T))\n            [['A' 'B']\n             ['C' 'B']\n             ['C' 'D']\n             ['D' 'A']]\n        \"\"\"\n        if self.has_ids:\n            if not isinstance(idxs, np.ndarray):\n                idxs = np.array(idxs)\n            return self.node_ids[idxs]  # type: ignore\n        else:\n            return idxs  # type: ignore\n\n    def to_idx(self, node: str | int | tuple[str] | tuple[int]) -&gt; int | tuple[int]:\n        \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\n\n        Args:\n            node: ID or index to map.\n\n        Returns:\n            Index if mapping is defined, argument otherwise.\n\n        Examples:\n            Map ID to index:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_idx(\"B\"))\n            1\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_idx(1))\n            1\n        \"\"\"\n        n: str | int | tuple[str] | tuple[int] = node\n        if self.has_ids:\n            if self.id_shape != (-1,):\n                n = tuple(n)\n            return self.id_to_idx[n]\n        else:\n            return n\n\n    def to_idxs(self, nodes: list | tuple | np.ndarray) -&gt; torch.Tensor:\n        \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise. The shape\n        of the given argument list will be preserved in the output.\n\n        Args:\n            nodes: IDs or indices to map.\n\n        Returns:\n            Indices if mapping is defined, arguments otherwise.\n\n        Examples:\n            Map list of IDs to indices:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_idxs([\"B\", \"A\"]))\n            tensor([1, 0])\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_idxs(torch.tensor([1, 0])))\n            tensor([1, 0])\n\n            Map list of edges to edge_index tensor:\n\n            &gt;&gt;&gt; edges = [[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]\n            &gt;&gt;&gt; index_map = IndexMap(np.unique(edges))\n            &gt;&gt;&gt; print(index_map.to_idxs(edges).T)\n            tensor([[0, 1, 2],\n                    [1, 2, 3]])\n        \"\"\"\n        if self.has_ids:\n            if not isinstance(nodes, np.ndarray):\n                nodes = np.array(nodes)\n\n            shape = nodes.shape\n            if self.id_shape == (-1,):\n                return torch.tensor([self.id_to_idx[node] for node in nodes.flatten()]).reshape(shape)\n            else:\n                return torch.tensor([self.id_to_idx[tuple(node)] for node in nodes.reshape(self.id_shape)]).reshape(\n                    shape[: -len(self.id_shape) + 1]\n                )\n        else:\n            return torch.tensor(nodes)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of the mapping.\n\n        Returns:\n            String representation of the mapping.\n\n        Examples:\n            Print string representation of the mapping:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n        \"\"\"\n        s = \"\"\n        for v in self.id_to_idx:\n            s += str(v) + \" -&gt; \" + str(self.to_idx(v)) + \"\\n\"\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.has_ids","title":"<code>has_ids: bool</code>  <code>property</code>","text":"<p>Return whether mapping has IDs.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether mapping has IDs.</p> <p>Examples:</p> <p>Check if mapping has IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.has_ids)\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.has_ids)\nTrue\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.__init__","title":"<code>__init__</code>","text":"<p>Initialize mapping from indices to node IDs.</p> <p>The mapping will keep the ordering of the IDs as provided by <code>node_ids</code>. If the IDs are not unique, an error will be raised.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>typing.Union[typing.List[str], None]</code> <p>List of node IDs to initialize mapping.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If IDs are not unique.</p> <p>Examples:</p> <p>Initialize an <code>IndexMap</code> object with a list of string IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"C\", \"B\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nC -&gt; 1\nB -&gt; 2\n</code></pre> <p>Handle non-unique IDs and sort IDs lexicographically:</p> <pre><code>&gt;&gt;&gt; node_ids = [\"A\", \"C\", \"B\", \"A\"]\n&gt;&gt;&gt; index_map = IndexMap(np.unique(node_ids))\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n    \"\"\"Initialize mapping from indices to node IDs.\n\n    The mapping will keep the ordering of the IDs as provided by `node_ids`. If the IDs are not unique,\n    an error will be raised.\n\n    Args:\n        node_ids: List of node IDs to initialize mapping.\n\n    Raises:\n        ValueError: If IDs are not unique.\n\n    Examples:\n        Initialize an `IndexMap` object with a list of string IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"C\", \"B\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        C -&gt; 1\n        B -&gt; 2\n\n        Handle non-unique IDs and sort IDs lexicographically:\n\n        &gt;&gt;&gt; node_ids = [\"A\", \"C\", \"B\", \"A\"]\n        &gt;&gt;&gt; index_map = IndexMap(np.unique(node_ids))\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n    \"\"\"\n    self.node_ids: np.ndarray | None = None\n    self.id_to_idx: dict = {}\n    self.id_shape: tuple = (-1,)  # If the index map is higher order, this will be the shape of the ID\n    if node_ids is not None:\n        self.add_ids(node_ids)\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.__str__","title":"<code>__str__</code>","text":"<p>Return string representation of the mapping.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the mapping.</p> <p>Examples:</p> <p>Print string representation of the mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of the mapping.\n\n    Returns:\n        String representation of the mapping.\n\n    Examples:\n        Print string representation of the mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n    \"\"\"\n    s = \"\"\n    for v in self.id_to_idx:\n        s += str(v) + \" -&gt; \" + str(self.to_idx(v)) + \"\\n\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.add_id","title":"<code>add_id</code>","text":"<p>Assigns additional ID to the next consecutive index.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>typing.Any</code> <p>ID to assign.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If ID is already present in the mapping.</p> <p>Examples:</p> <p>Add an additional ID to the mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; index_map.add_id(\"D\")\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\nD -&gt; 3\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def add_id(self, node_id: Any) -&gt; None:\n    \"\"\"Assigns additional ID to the next consecutive index.\n\n    Args:\n        node_id: ID to assign.\n\n    Raises:\n        ValueError: If ID is already present in the mapping.\n\n    Examples:\n        Add an additional ID to the mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; index_map.add_id(\"D\")\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n        D -&gt; 3\n    \"\"\"\n    if node_id not in self.id_to_idx:\n        idx = self.num_ids()\n        if isinstance(node_id, (list, tuple)):\n            node_id = np.array(node_id)\n            self.id_shape = (-1, *node_id.shape)\n        self.node_ids = (\n            np.concatenate((self.node_ids, np.array([node_id])))\n            if self.node_ids is not None\n            else np.array([node_id])\n        )\n        self.id_to_idx[node_id] = idx\n    else:\n        raise ValueError(\"ID already present in the mapping.\")\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.add_ids","title":"<code>add_ids</code>","text":"<p>Assigns additional IDs to next consecutive indices. The order of IDs is preserved.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>list | numpy.ndarray</code> <p>IDs to assign</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If IDs are not unique or already present in the mapping.</p> <p>Examples:</p> <p>Add additional IDs to the mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; index_map.add_ids([\"E\", \"D\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\nE -&gt; 3\nD -&gt; 4\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n    \"\"\"Assigns additional IDs to next consecutive indices. The order of IDs is preserved.\n\n    Args:\n        node_ids: IDs to assign\n\n    Raises:\n        ValueError: If IDs are not unique or already present in the mapping.\n\n    Examples:\n        Add additional IDs to the mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; index_map.add_ids([\"E\", \"D\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n        E -&gt; 3\n        D -&gt; 4\n    \"\"\"\n    cur_num_ids = self.num_ids()\n    if isinstance(node_ids, list) and isinstance(node_ids[0], (list, tuple)):\n        self.id_shape = (-1, *np.array(node_ids[0]).shape)\n\n    if not isinstance(node_ids, np.ndarray):\n        node_ids = np.array(node_ids)\n\n    all_ids = np.concatenate((self.node_ids, node_ids)) if self.node_ids is not None else node_ids\n    unique_ids = np.unique(all_ids, axis=0 if self.id_shape != (-1,) else None)\n\n    if len(unique_ids) != len(all_ids):\n        raise ValueError(\"IDs are not unique or already present in the mapping.\")\n\n    self.node_ids = all_ids\n    self.id_to_idx.update(\n        {tuple(v) if self.id_shape != (-1,) else v: i + cur_num_ids for i, v in enumerate(node_ids)}\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.num_ids","title":"<code>num_ids</code>","text":"<p>Return number of IDs. If mapping is not defined, return 0.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of IDs.</p> <p>Examples:</p> <p>Get number of IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.num_ids())\n0\n</code></pre> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.num_ids())\n3\n</code></pre> <pre><code>&gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n&gt;&gt;&gt; print(index_map.num_ids())\n3\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def num_ids(self) -&gt; int:\n    \"\"\"Return number of IDs. If mapping is not defined, return 0.\n\n    Returns:\n        Number of IDs.\n\n    Examples:\n        Get number of IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.num_ids())\n        0\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.num_ids())\n        3\n\n        &gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n        &gt;&gt;&gt; print(index_map.num_ids())\n        3\n    \"\"\"\n    if self.node_ids is None:\n        return 0\n    else:\n        return len(self.node_ids)\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_id","title":"<code>to_id</code>","text":"<p>Map index to ID if mapping is defined, return index otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index to map.</p> required <p>Returns:</p> Type Description <code>typing.Union[int, str, tuple]</code> <p>ID if mapping is defined, index otherwise.</p> <p>Examples:</p> <p>Map index to ID:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_id(1))\nB\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_id(1))\n1\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n    \"\"\"Map index to ID if mapping is defined, return index otherwise.\n\n    Args:\n        idx: Index to map.\n\n    Returns:\n        ID if mapping is defined, index otherwise.\n\n    Examples:\n        Map index to ID:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        B\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        1\n    \"\"\"\n    if self.has_ids:\n        if self.id_shape == (-1,):\n            return self.node_ids[idx]  # type: ignore\n        else:\n            return tuple(self.node_ids[idx])  # type: ignore\n    else:\n        return idx\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_ids","title":"<code>to_ids</code>","text":"<p>Map list of indices to IDs if mapping is defined, return indices otherwise. The shape of the given index list will be preserved in the output.</p> <p>Parameters:</p> Name Type Description Default <code>idxs</code> <code>list | tuple | numpy.ndarray</code> <p>Indices to map.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>IDs if mapping is defined, indices otherwise.</p> <p>Examples:</p> <p>Map list of indices to IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n['A' 'C']\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_ids(torch.tensor([0, 2])))\ntensor([0 2])\n</code></pre> <p>Map edge_index tensor to array of edges:</p> <pre><code>&gt;&gt;&gt; edge_index = torch.tensor([[0, 2, 2, 3], [1, 1, 3, 0]])\n&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\", \"D\"])\n&gt;&gt;&gt; print(index_map.to_ids(edge_index.T))\n[['A' 'B']\n ['C' 'B']\n ['C' 'D']\n ['D' 'A']]\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_ids(self, idxs: list | tuple | np.ndarray) -&gt; np.ndarray:\n    \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise. The shape of the given index\n    list will be preserved in the output.\n\n    Args:\n        idxs: Indices to map.\n\n    Returns:\n        IDs if mapping is defined, indices otherwise.\n\n    Examples:\n        Map list of indices to IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n        ['A' 'C']\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_ids(torch.tensor([0, 2])))\n        tensor([0 2])\n\n        Map edge_index tensor to array of edges:\n\n        &gt;&gt;&gt; edge_index = torch.tensor([[0, 2, 2, 3], [1, 1, 3, 0]])\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\", \"D\"])\n        &gt;&gt;&gt; print(index_map.to_ids(edge_index.T))\n        [['A' 'B']\n         ['C' 'B']\n         ['C' 'D']\n         ['D' 'A']]\n    \"\"\"\n    if self.has_ids:\n        if not isinstance(idxs, np.ndarray):\n            idxs = np.array(idxs)\n        return self.node_ids[idxs]  # type: ignore\n    else:\n        return idxs  # type: ignore\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_idx","title":"<code>to_idx</code>","text":"<p>Map argument (ID or index) to index if mapping is defined, return argument otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str | int | tuple[str] | tuple[int]</code> <p>ID or index to map.</p> required <p>Returns:</p> Type Description <code>int | tuple[int]</code> <p>Index if mapping is defined, argument otherwise.</p> <p>Examples:</p> <p>Map ID to index:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_idx(\"B\"))\n1\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_idx(1))\n1\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_idx(self, node: str | int | tuple[str] | tuple[int]) -&gt; int | tuple[int]:\n    \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\n\n    Args:\n        node: ID or index to map.\n\n    Returns:\n        Index if mapping is defined, argument otherwise.\n\n    Examples:\n        Map ID to index:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_idx(\"B\"))\n        1\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_idx(1))\n        1\n    \"\"\"\n    n: str | int | tuple[str] | tuple[int] = node\n    if self.has_ids:\n        if self.id_shape != (-1,):\n            n = tuple(n)\n        return self.id_to_idx[n]\n    else:\n        return n\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_idxs","title":"<code>to_idxs</code>","text":"<p>Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise. The shape of the given argument list will be preserved in the output.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list | tuple | numpy.ndarray</code> <p>IDs or indices to map.</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Indices if mapping is defined, arguments otherwise.</p> <p>Examples:</p> <p>Map list of IDs to indices:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_idxs([\"B\", \"A\"]))\ntensor([1, 0])\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_idxs(torch.tensor([1, 0])))\ntensor([1, 0])\n</code></pre> <p>Map list of edges to edge_index tensor:</p> <pre><code>&gt;&gt;&gt; edges = [[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]\n&gt;&gt;&gt; index_map = IndexMap(np.unique(edges))\n&gt;&gt;&gt; print(index_map.to_idxs(edges).T)\ntensor([[0, 1, 2],\n        [1, 2, 3]])\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_idxs(self, nodes: list | tuple | np.ndarray) -&gt; torch.Tensor:\n    \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise. The shape\n    of the given argument list will be preserved in the output.\n\n    Args:\n        nodes: IDs or indices to map.\n\n    Returns:\n        Indices if mapping is defined, arguments otherwise.\n\n    Examples:\n        Map list of IDs to indices:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_idxs([\"B\", \"A\"]))\n        tensor([1, 0])\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_idxs(torch.tensor([1, 0])))\n        tensor([1, 0])\n\n        Map list of edges to edge_index tensor:\n\n        &gt;&gt;&gt; edges = [[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]\n        &gt;&gt;&gt; index_map = IndexMap(np.unique(edges))\n        &gt;&gt;&gt; print(index_map.to_idxs(edges).T)\n        tensor([[0, 1, 2],\n                [1, 2, 3]])\n    \"\"\"\n    if self.has_ids:\n        if not isinstance(nodes, np.ndarray):\n            nodes = np.array(nodes)\n\n        shape = nodes.shape\n        if self.id_shape == (-1,):\n            return torch.tensor([self.id_to_idx[node] for node in nodes.flatten()]).reshape(shape)\n        else:\n            return torch.tensor([self.id_to_idx[tuple(node)] for node in nodes.reshape(self.id_shape)]).reshape(\n                shape[: -len(self.id_shape) + 1]\n            )\n    else:\n        return torch.tensor(nodes)\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/","title":"multi_order_model","text":""},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel","title":"<code>MultiOrderModel</code>","text":"<p>MultiOrderModel based on torch_geometric.Data.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>class MultiOrderModel:\n    \"\"\"MultiOrderModel based on torch_geometric.Data.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.layers: dict[int, Graph] = {}\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the higher-order graph.\"\"\"\n        max_order = max(list(self.layers.keys())) if self.layers else 0\n        s = f\"MultiOrderModel with max. order {max_order}\"\n        return s\n\n    @staticmethod\n    def iterate_lift_order(\n        edge_index: torch.Tensor,\n        node_sequence: torch.Tensor,\n        mapping: IndexMap,\n        edge_weight: torch.Tensor | None = None,\n        aggr: str = \"src\",\n        save: bool = True,\n    ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n        \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n        This is a helper function that should not be called directly.\n        Only use for edge_indices after the special cases have been handled e.g.\n        in the from_temporal_graph (filtering non-time-respecting paths of order 2).\n\n        Args:\n            edge_index: The edge index of the (k-1)-th order graph.\n            node_sequence: The node sequences of the (k-1)-th order graph.\n            edge_weight: The edge weights of the (k-1)-th order graph.\n            k: The order of the graph that should be computed.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n            save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n        \"\"\"\n        # Lift order\n        if edge_weight is None:\n            ho_index = lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n        else:\n            ho_index, edge_weight = lift_order_edge_index_weighted(\n                edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n            )\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n        # Aggregate\n        if save:\n            gk = aggregate_edge_index(ho_index, node_sequence, edge_weight)\n            gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n        else:\n            gk = None\n        return ho_index, node_sequence, edge_weight, gk\n\n    @staticmethod\n    def from_temporal_graph(\n        g: TemporalGraph, delta: float | int = 1, max_order: int = 1, weight: str = \"edge_weight\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\n\n        Args:\n            g: The temporal graph.\n            delta: The maximum time difference between two consecutive edges in a path.\n            max_order: The maximum order of the MultiOrderModel that should be computed.\n            weight: The edge attribute to use as edge weight.\n            cached: Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.\n\n        Returns:\n            MultiOrderModel: The MultiOrderModel.\n        \"\"\"\n        m = MultiOrderModel()\n        if not g.data.is_sorted_by_time():\n            data = g.data.sort_by_time()\n        else:\n            data = g.data\n        edge_index = data.edge_index\n        node_sequence = torch.arange(data.num_nodes, device=edge_index.device).unsqueeze(1)\n        if weight in data:\n            edge_weight = data[weight]\n        else:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n        if cached or max_order == 1:\n            m.layers[1] = aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[1].mapping = g.mapping\n\n        if max_order &gt; 1:\n            node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n            edge_index = lift_order_temporal(g, delta)\n            edge_weight = aggregate_node_attributes(edge_index, edge_weight, \"src\")\n\n            # Aggregate\n            if cached or max_order == 2:\n                m.layers[2] = aggregate_edge_index(\n                    edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n                )\n                m.layers[2].mapping = IndexMap(\n                    [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n                )\n\n            for k in range(3, max_order + 1):\n                edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                    edge_index=edge_index,\n                    node_sequence=node_sequence,\n                    mapping=g.mapping,\n                    edge_weight=edge_weight,\n                    aggr=\"src\",\n                    save=cached or k == max_order,\n                )\n                if cached or k == max_order:\n                    m.layers[k] = gk\n\n        return m\n\n    @staticmethod\n    def from_PathData(\n        path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"\n        Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n        Args:\n            path_data: `PathData` object containing paths as list of PyG Data objects\n                with sorted edge indices, node sequences and num_nodes.\n            max_order: The maximum order of the MultiOrderModel that should be computed\n            mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n            cached: Whether to save the aggregated higher-order graphs smaller than max order\n                in the MultiOrderModel.\n\n        Returns:\n            MultiOrderModel: The MultiOrderModel.\n        \"\"\"\n        m = MultiOrderModel()\n\n        # We assume that paths are sorted\n        path_graph = path_data.data\n        edge_index = path_graph.edge_index\n        node_sequence = path_graph.node_sequence\n        edge_weight = path_graph.dag_weight.repeat_interleave(path_graph.dag_num_edges)\n        if mode == \"diffusion\":\n            edge_weight = (\n                edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n            )\n            aggr = \"mul\"\n        elif mode == \"propagation\":\n            aggr = \"src\"\n\n        m.layers[1] = aggregate_edge_index(edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight)\n        m.layers[1].mapping = path_data.mapping\n\n        for k in range(2, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=m.layers[1].mapping,\n                edge_weight=edge_weight,\n                aggr=aggr,\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n        return m\n\n    def get_mon_dof(self, max_order: int = None, assumption: str = \"paths\") -&gt; int:\n        \"\"\"\n        The degrees of freedom for the kth layer of a multi-order model. This depends on the number of different paths of exactly length `k` in the graph.\n        Therefore, we can obtain these values by summing the entries of the `k`-th power of the binary adjacency matrix of the graph.\n        Finally, we must consider that, due the conservation of probablility, all non-zero rows of the transition matrix of the higher-order network must sum to one.\n        This poses one additional constraint per row that respects the condition, which should be removed from the total count of degrees of freedom.\n\n        Args:\n            m (MultiOrderModel): The multi-order model.\n            max_order (int, optional): The maximum order up to which model layers\n                shall be taken into account. Defaults to None, meaning it considers\n                all available layers.\n            assumption (str, optional): If set to 'paths', only paths in the\n                first-order network topology will be considered for the degree of\n                freedom calculation. If set to 'ngrams', all possible n-grams will\n                be considered, independent of whether they are valid paths in the\n                first-order network or not. Defaults to 'paths'.\n\n        Returns:\n            int: The degrees of freedom for the multi-order model.\n\n        Raises:\n            AssertionError: If max_order is larger than the maximum order of\n                the multi-order network.\n            ValueError: If the assumption is not 'paths' or 'ngrams'.\n        \"\"\"\n        if max_order is None:\n            max_order = max(self.layers)\n\n        assert max_order &lt;= max(\n            self.layers\n        ), \"Error: max_order cannot be larger than maximum order of multi-order network\"\n\n        dof = self.layers[1].data.num_nodes - 1  # Degrees of freedom for zeroth order\n\n        if assumption == \"paths\":\n            # COMPUTING CONTRIBUTION FROM NUM PATHS AND NONZERO OUTDEGREES SEPARATELY\n            # TODO: CAN IT BE DONE TOGETHER?\n\n            edge_index = self.layers[1].data.edge_index\n            # Adding dof from Number of paths of length k\n            for k in range(1, max_order + 1):\n                if k &gt; 1:\n                    num_nodes = 0 if edge_index.numel() == 0 else edge_index.max().item() + 1\n                    edge_index = lift_order_edge_index(edge_index, num_nodes)\n                # counting number of len k paths\n                num_len_k_paths = edge_index.shape[1]  # edge_index.max().item() +1  # Number of paths of length k\n                dof += num_len_k_paths\n\n            # removing dof from total probability of nonzero degree nodes\n            for k in range(1, max_order + 1):\n                if k == 1:\n                    # edge_index of temporal graph is sorted by time by default\n                    # For matrix multiplication, we need to sort it by row\n                    edge_index_adj = self.layers[1].data.edge_index.sort_by(\"row\")[0]\n                    edge_index = edge_index_adj\n                else:\n                    edge_index, _ = edge_index.matmul(edge_index_adj)\n                num_nonzero_outdegrees = torch.unique(edge_index[0]).size(0)\n                dof -= num_nonzero_outdegrees\n\n        elif assumption == \"ngrams\":\n            for order in range(1, max_order + 1):\n                dof += (self.layers[1].data.num_nodes ** order) * (self.layers[1].data.num_nodes - 1)\n        else:\n            raise ValueError(\n                f\"Unknown assumption {assumption} in input. The only accepted values are 'path' and 'ngram'\"\n            )\n\n        return int(dof)\n\n    def get_zeroth_order_log_likelihood(self, dag_graph: Data) -&gt; float:\n        \"\"\"\n        Compute the zeroth order log likelihood.\n\n        Args:\n            dag_graph (Data): Input DAG graph data.\n\n        Returns:\n            float: Zeroth order log likelihood.\n        \"\"\"\n        # Get frequencies\n        # getting the index of the last edge of each path (to be used to extract weights)\n        frequencies = dag_graph.dag_weight\n\n        # Get ixs starting nodes\n        # Q: Is dag_graph.path_index[:-1] enough to get the start_ixs?\n        mask = torch.ones(dag_graph.num_nodes, dtype=bool)\n        mask[dag_graph.edge_index[1]] = False\n        start_ixs = dag_graph.node_sequence.squeeze()[mask]\n\n        # Compute node emission probabilities\n        # TODOL modify once we have zeroth order in mon\n        _, counts = torch.unique(dag_graph.node_sequence, return_counts=True)\n        # WARNING: Only works if all nodes in the first-order graph are also in `node_sequence`\n        # Otherwise the missing nodes will not be included in `counts` which can lead to elements at the wrong index.\n        node_emission_probabilities = counts / counts.sum()\n        return torch.mul(frequencies, torch.log(node_emission_probabilities[start_ixs])).sum().item()\n\n    def get_intermediate_order_log_likelihood(self, dag_graph: Data, order: int) -&gt; float:\n        \"\"\"\n        Compute the intermediate order log likelihood.\n\n        Args:\n            m (MultiOrderModel): Multi-order model.\n            dag_graph (Data): Input DAG graph data.\n            order (int): Order of the intermediate log likelihood.\n\n        Returns:\n            float: Intermediate order log likelihood.\n        \"\"\"\n        # Get frequencies\n        frequencies = dag_graph.dag_weight\n\n        # Get intermediate HO nodes ixs\n        mask = torch.ones(dag_graph.num_nodes, dtype=bool)\n        mask[dag_graph.edge_index[1]] = False\n        ixs = torch.where(mask)[0]\n        num_ixs = ixs.shape[0]\n        ho_intermediate_ixs = ixs - torch.arange(num_ixs) * order\n\n        # computing loglikelihood of subpaths\n        transition_probabilities = self.layers[order].transition_probabilities()[\n            self.layers[order + 1].data.inverse_idx[ho_intermediate_ixs]\n        ]\n        log_transition_probabilities = torch.log(transition_probabilities)\n        llh_by_subpath = torch.mul(frequencies, log_transition_probabilities)\n        return llh_by_subpath.sum().item()\n\n    def get_mon_log_likelihood(self, dag_graph: Data, max_order: int = 1) -&gt; float:\n        \"\"\"\n        Compute the likelihood of the walks given a multi-order model.\n\n        Args:\n            m (MultiOrderModel): The multi-order model.\n            dag_graph (Data): Dataset containing the walks.\n            max_order (int, optional): The maximum order up to which model layers\n                shall be taken into account. Defaults to 1.\n\n        Returns:\n            float: The log likelihood of the walks given the multi-order model.\n        \"\"\"\n        llh = 0\n\n        # Adding likelihood of zeroth order\n        llh += self.get_zeroth_order_log_likelihood(dag_graph)\n\n        # Adding the likelihood for all the intermediate orders\n        for order in range(1, max_order):\n            llh += self.get_intermediate_order_log_likelihood(dag_graph, order)\n\n        # Adding the likelihood of highest/stationary order\n        if max_order &gt; 0:\n            transition_probabilities = self.layers[max_order].transition_probabilities()\n            log_transition_probabilities = torch.log(transition_probabilities)\n            llh_by_subpath = log_transition_probabilities * self.layers[max_order].data.edge_weight\n            llh += llh_by_subpath.sum().item()\n        else:\n            # Compute likelihood for zeroth order (to be modified)\n            # TODO: modify once we have zeroth order in mon\n            # (then won t need to compute emission probs from dag_graph -- which also hinders us from computing the lh that a new set of paths was generated by the model)\n            frequencies = dag_graph.dag_weight\n            counts = torch.bincount(\n                dag_graph.node_sequence.squeeze(), frequencies.repeat_interleave(dag_graph.dag_num_nodes)\n            )\n            node_emission_probabilities = counts / counts.sum()\n            llh = torch.mul(torch.log(node_emission_probabilities), counts).sum().item()\n\n        return llh\n\n    def likelihood_ratio_test(\n        self,\n        dag_graph: Data,\n        max_order_null: int = 0,\n        max_order: int = 1,\n        assumption: str = \"paths\",\n        significance_threshold: float = 0.01,\n    ) -&gt; tuple:\n        \"\"\"\n        Perform a likelihood ratio test to compare two models of different order.\n\n        Args:\n            dag_graph (Data): The input DAG graph data.\n            max_order_null (int, optional): The maximum order of the null hypothesis model.\n                Defaults to 0.\n            max_order (int, optional): The maximum order of the alternative hypothesis model.\n                Defaults to 1.\n            assumption (str, optional): The assumption to use for the degrees of freedom calculation.\n                Can be 'paths' or 'ngrams'. Defaults to 'paths'.\n            significance_threshold (float, optional): The significance threshold for the test.\n                Defaults to 0.01.\n\n        Returns:\n            tuple: A tuple containing a boolean indicating whether the null hypothesis is rejected\n                and the p-value of the test.\n        \"\"\"\n        assert (\n            max_order_null &lt; max_order\n        ), \"Error: order of null hypothesis must be smaller than order of alternative hypothesis\"\n        assert max_order &lt;= max(\n            self.layers\n        ), f\"Error: order of hypotheses ({max_order_null} and {max_order}) must be smaller than the maximum order of the MultiOrderModel {max(self.layers)}\"\n        # let L0 be the likelihood for the null model and L1 be the likelihood for the alternative model\n\n        # we first compute a test statistic x = -2 * log (L0/L1) = -2 * (log L0 - log L1)\n        x = -2 * (\n            self.get_mon_log_likelihood(dag_graph, max_order=max_order_null)\n            - self.get_mon_log_likelihood(dag_graph, max_order=max_order)\n        )\n\n        # we calculate the additional degrees of freedom in the alternative model\n        dof_diff = self.get_mon_dof(max_order, assumption=assumption) - self.get_mon_dof(\n            max_order_null, assumption=assumption\n        )\n\n        # if the p-value is *below* the significance threshold, we reject the null hypothesis\n        p = 1 - chi2.cdf(x, dof_diff)\n        return (p &lt; significance_threshold), p\n\n    def estimate_order(self, dag_data: PathData, max_order: int = None, significance_threshold: float = 0.01) -&gt; int:\n        \"\"\"\n        Selects the optimal maximum order of a multi-order network model for the\n        observed paths, based on a likelihood ratio test with p-value threshold of p\n        By default, all orders up to the maximum order of the multi-order model will be tested.\n\n        Args:\n            dag_data (DAGData): The path statistics data for which to estimate the optimal order.\n            max_order (int, optional): The maximum order to consider during the estimation process.\n                If not provided, the maximum order of the multi-order model is used.\n            significance_threshold (float, optional): The p-value threshold for the likelihood ratio test.\n                An order is accepted if the improvement in likelihood is significant at this threshold.\n\n        Returns:\n            int: The estimated optimal maximum order for the multi-order network model.\n\n        Raises:\n            AssertionError: If the provided max_order is larger than the maximum order of the multi-order model\n                or if the input DAGData does not have the same set of nodes as the multi-order network\n        \"\"\"\n        if max_order is None:\n            max_order = max(self.layers)  # THIS\n        assert max_order &lt;= max(\n            self.layers\n        ), \"Error: maxOrder cannot be larger than maximum order of multi-order network\"\n        assert max_order &gt; 1, \"Error: max_order must be larger than one\"\n\n        assert set(dag_data.mapping.node_ids).intersection(set(self.layers[1].mapping.node_ids)) == set(\n            dag_data.mapping.node_ids\n        ), \"Input DAGData doesn t have the same set of nodes as those of the multi-order network\"\n\n        max_accepted_order = 1\n        dag_graph = dag_data.data\n\n        # Test for highest order that passes\n        # likelihood ratio test against null model\n        for k in range(2, max_order + 1):\n            if self.likelihood_ratio_test(\n                dag_graph, max_order_null=k - 1, max_order=k, significance_threshold=significance_threshold\n            )[0]:\n                max_accepted_order = k\n\n        return max_accepted_order\n\n    def to_dbgnn_data(self, max_order: int = 2, mapping: str = \"last\") -&gt; Data:\n        \"\"\"\n        Convert the MultiOrderModel to a De Bruijn graph for the given maximum order\n        that can be used in `pathpyG.nn.dbgnn.DBGNN`.\n\n        Args:\n            max_order: The maximum order of the De Bruijn graph to be computed.\n            mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n\n        Returns:\n            Data: The De Bruijn graph data.\n        \"\"\"\n        if max_order not in self.layers:\n            raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n        g = self.layers[1]\n        g_max_order = self.layers[max_order]\n        num_nodes = g.data.num_nodes\n        num_ho_nodes = g_max_order.data.num_nodes\n        if g.data.x is not None:\n            x = g.data.x\n        else:\n            x = torch.eye(num_nodes, num_nodes)\n        x_max_order = torch.eye(num_ho_nodes, num_ho_nodes)\n        edge_index = g.data.edge_index\n        edge_index_max_order = g_max_order.data.edge_index\n        edge_weight = g.data.edge_weight\n        edge_weight_max_order = g_max_order.data.edge_weight\n        bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping)\n\n        if g.data.y is not None:\n            y = g.data.y\n\n        return Data(\n            num_nodes=num_nodes,\n            num_ho_nodes=num_ho_nodes,\n            x=x,\n            x_h=x_max_order,\n            edge_index=edge_index,\n            edge_index_higher_order=edge_index_max_order,\n            edge_weights=edge_weight.float(),\n            edge_weights_higher_order=edge_weight_max_order.float(),\n            bipartite_edge_index=bipartite_edge_index,\n            y=y if \"y\" in locals() else None,\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the higher-order graph.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the higher-order graph.\"\"\"\n    max_order = max(list(self.layers.keys())) if self.layers else 0\n    s = f\"MultiOrderModel with max. order {max_order}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.estimate_order","title":"<code>estimate_order</code>","text":"<p>Selects the optimal maximum order of a multi-order network model for the observed paths, based on a likelihood ratio test with p-value threshold of p By default, all orders up to the maximum order of the multi-order model will be tested.</p> <p>Parameters:</p> Name Type Description Default <code>dag_data</code> <code>DAGData</code> <p>The path statistics data for which to estimate the optimal order.</p> required <code>max_order</code> <code>int</code> <p>The maximum order to consider during the estimation process. If not provided, the maximum order of the multi-order model is used.</p> <code>None</code> <code>significance_threshold</code> <code>float</code> <p>The p-value threshold for the likelihood ratio test. An order is accepted if the improvement in likelihood is significant at this threshold.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The estimated optimal maximum order for the multi-order network model.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the provided max_order is larger than the maximum order of the multi-order model or if the input DAGData does not have the same set of nodes as the multi-order network</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def estimate_order(self, dag_data: PathData, max_order: int = None, significance_threshold: float = 0.01) -&gt; int:\n    \"\"\"\n    Selects the optimal maximum order of a multi-order network model for the\n    observed paths, based on a likelihood ratio test with p-value threshold of p\n    By default, all orders up to the maximum order of the multi-order model will be tested.\n\n    Args:\n        dag_data (DAGData): The path statistics data for which to estimate the optimal order.\n        max_order (int, optional): The maximum order to consider during the estimation process.\n            If not provided, the maximum order of the multi-order model is used.\n        significance_threshold (float, optional): The p-value threshold for the likelihood ratio test.\n            An order is accepted if the improvement in likelihood is significant at this threshold.\n\n    Returns:\n        int: The estimated optimal maximum order for the multi-order network model.\n\n    Raises:\n        AssertionError: If the provided max_order is larger than the maximum order of the multi-order model\n            or if the input DAGData does not have the same set of nodes as the multi-order network\n    \"\"\"\n    if max_order is None:\n        max_order = max(self.layers)  # THIS\n    assert max_order &lt;= max(\n        self.layers\n    ), \"Error: maxOrder cannot be larger than maximum order of multi-order network\"\n    assert max_order &gt; 1, \"Error: max_order must be larger than one\"\n\n    assert set(dag_data.mapping.node_ids).intersection(set(self.layers[1].mapping.node_ids)) == set(\n        dag_data.mapping.node_ids\n    ), \"Input DAGData doesn t have the same set of nodes as those of the multi-order network\"\n\n    max_accepted_order = 1\n    dag_graph = dag_data.data\n\n    # Test for highest order that passes\n    # likelihood ratio test against null model\n    for k in range(2, max_order + 1):\n        if self.likelihood_ratio_test(\n            dag_graph, max_order_null=k - 1, max_order=k, significance_threshold=significance_threshold\n        )[0]:\n            max_accepted_order = k\n\n    return max_accepted_order\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.from_PathData","title":"<code>from_PathData</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graphs modelling paths in PathData.</p> <p>Parameters:</p> Name Type Description Default <code>path_data</code> <code>pathpyG.core.path_data.PathData</code> <p><code>PathData</code> object containing paths as list of PyG Data objects with sorted edge indices, node sequences and num_nodes.</p> required <code>max_order</code> <code>int</code> <p>The maximum order of the MultiOrderModel that should be computed</p> <code>1</code> <code>mode</code> <code>str</code> <p>The process that we assume. Can be \"diffusion\" or \"propagation\".</p> <code>'propagation'</code> <code>cached</code> <code>bool</code> <p>Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>MultiOrderModel</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The MultiOrderModel.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>@staticmethod\ndef from_PathData(\n    path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"\n    Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n    Args:\n        path_data: `PathData` object containing paths as list of PyG Data objects\n            with sorted edge indices, node sequences and num_nodes.\n        max_order: The maximum order of the MultiOrderModel that should be computed\n        mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n        cached: Whether to save the aggregated higher-order graphs smaller than max order\n            in the MultiOrderModel.\n\n    Returns:\n        MultiOrderModel: The MultiOrderModel.\n    \"\"\"\n    m = MultiOrderModel()\n\n    # We assume that paths are sorted\n    path_graph = path_data.data\n    edge_index = path_graph.edge_index\n    node_sequence = path_graph.node_sequence\n    edge_weight = path_graph.dag_weight.repeat_interleave(path_graph.dag_num_edges)\n    if mode == \"diffusion\":\n        edge_weight = (\n            edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n        )\n        aggr = \"mul\"\n    elif mode == \"propagation\":\n        aggr = \"src\"\n\n    m.layers[1] = aggregate_edge_index(edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight)\n    m.layers[1].mapping = path_data.mapping\n\n    for k in range(2, max_order + 1):\n        edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n            edge_index=edge_index,\n            node_sequence=node_sequence,\n            mapping=m.layers[1].mapping,\n            edge_weight=edge_weight,\n            aggr=aggr,\n            save=cached or k == max_order,\n        )\n        if cached or k == max_order:\n            m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.from_temporal_graph","title":"<code>from_temporal_graph</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>The temporal graph.</p> required <code>delta</code> <code>float | int</code> <p>The maximum time difference between two consecutive edges in a path.</p> <code>1</code> <code>max_order</code> <code>int</code> <p>The maximum order of the MultiOrderModel that should be computed.</p> <code>1</code> <code>weight</code> <code>str</code> <p>The edge attribute to use as edge weight.</p> <code>'edge_weight'</code> <code>cached</code> <code>bool</code> <p>Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>MultiOrderModel</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The MultiOrderModel.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>@staticmethod\ndef from_temporal_graph(\n    g: TemporalGraph, delta: float | int = 1, max_order: int = 1, weight: str = \"edge_weight\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\n\n    Args:\n        g: The temporal graph.\n        delta: The maximum time difference between two consecutive edges in a path.\n        max_order: The maximum order of the MultiOrderModel that should be computed.\n        weight: The edge attribute to use as edge weight.\n        cached: Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.\n\n    Returns:\n        MultiOrderModel: The MultiOrderModel.\n    \"\"\"\n    m = MultiOrderModel()\n    if not g.data.is_sorted_by_time():\n        data = g.data.sort_by_time()\n    else:\n        data = g.data\n    edge_index = data.edge_index\n    node_sequence = torch.arange(data.num_nodes, device=edge_index.device).unsqueeze(1)\n    if weight in data:\n        edge_weight = data[weight]\n    else:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n    if cached or max_order == 1:\n        m.layers[1] = aggregate_edge_index(\n            edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n        )\n        m.layers[1].mapping = g.mapping\n\n    if max_order &gt; 1:\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n        edge_index = lift_order_temporal(g, delta)\n        edge_weight = aggregate_node_attributes(edge_index, edge_weight, \"src\")\n\n        # Aggregate\n        if cached or max_order == 2:\n            m.layers[2] = aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[2].mapping = IndexMap(\n                [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n            )\n\n        for k in range(3, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=g.mapping,\n                edge_weight=edge_weight,\n                aggr=\"src\",\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_intermediate_order_log_likelihood","title":"<code>get_intermediate_order_log_likelihood</code>","text":"<p>Compute the intermediate order log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>Multi-order model.</p> required <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>Input DAG graph data.</p> required <code>order</code> <code>int</code> <p>Order of the intermediate log likelihood.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Intermediate order log likelihood.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_intermediate_order_log_likelihood(self, dag_graph: Data, order: int) -&gt; float:\n    \"\"\"\n    Compute the intermediate order log likelihood.\n\n    Args:\n        m (MultiOrderModel): Multi-order model.\n        dag_graph (Data): Input DAG graph data.\n        order (int): Order of the intermediate log likelihood.\n\n    Returns:\n        float: Intermediate order log likelihood.\n    \"\"\"\n    # Get frequencies\n    frequencies = dag_graph.dag_weight\n\n    # Get intermediate HO nodes ixs\n    mask = torch.ones(dag_graph.num_nodes, dtype=bool)\n    mask[dag_graph.edge_index[1]] = False\n    ixs = torch.where(mask)[0]\n    num_ixs = ixs.shape[0]\n    ho_intermediate_ixs = ixs - torch.arange(num_ixs) * order\n\n    # computing loglikelihood of subpaths\n    transition_probabilities = self.layers[order].transition_probabilities()[\n        self.layers[order + 1].data.inverse_idx[ho_intermediate_ixs]\n    ]\n    log_transition_probabilities = torch.log(transition_probabilities)\n    llh_by_subpath = torch.mul(frequencies, log_transition_probabilities)\n    return llh_by_subpath.sum().item()\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_mon_dof","title":"<code>get_mon_dof</code>","text":"<p>The degrees of freedom for the kth layer of a multi-order model. This depends on the number of different paths of exactly length <code>k</code> in the graph. Therefore, we can obtain these values by summing the entries of the <code>k</code>-th power of the binary adjacency matrix of the graph. Finally, we must consider that, due the conservation of probablility, all non-zero rows of the transition matrix of the higher-order network must sum to one. This poses one additional constraint per row that respects the condition, which should be removed from the total count of degrees of freedom.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The multi-order model.</p> required <code>max_order</code> <code>int</code> <p>The maximum order up to which model layers shall be taken into account. Defaults to None, meaning it considers all available layers.</p> <code>None</code> <code>assumption</code> <code>str</code> <p>If set to 'paths', only paths in the first-order network topology will be considered for the degree of freedom calculation. If set to 'ngrams', all possible n-grams will be considered, independent of whether they are valid paths in the first-order network or not. Defaults to 'paths'.</p> <code>'paths'</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The degrees of freedom for the multi-order model.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If max_order is larger than the maximum order of the multi-order network.</p> <code>ValueError</code> <p>If the assumption is not 'paths' or 'ngrams'.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_mon_dof(self, max_order: int = None, assumption: str = \"paths\") -&gt; int:\n    \"\"\"\n    The degrees of freedom for the kth layer of a multi-order model. This depends on the number of different paths of exactly length `k` in the graph.\n    Therefore, we can obtain these values by summing the entries of the `k`-th power of the binary adjacency matrix of the graph.\n    Finally, we must consider that, due the conservation of probablility, all non-zero rows of the transition matrix of the higher-order network must sum to one.\n    This poses one additional constraint per row that respects the condition, which should be removed from the total count of degrees of freedom.\n\n    Args:\n        m (MultiOrderModel): The multi-order model.\n        max_order (int, optional): The maximum order up to which model layers\n            shall be taken into account. Defaults to None, meaning it considers\n            all available layers.\n        assumption (str, optional): If set to 'paths', only paths in the\n            first-order network topology will be considered for the degree of\n            freedom calculation. If set to 'ngrams', all possible n-grams will\n            be considered, independent of whether they are valid paths in the\n            first-order network or not. Defaults to 'paths'.\n\n    Returns:\n        int: The degrees of freedom for the multi-order model.\n\n    Raises:\n        AssertionError: If max_order is larger than the maximum order of\n            the multi-order network.\n        ValueError: If the assumption is not 'paths' or 'ngrams'.\n    \"\"\"\n    if max_order is None:\n        max_order = max(self.layers)\n\n    assert max_order &lt;= max(\n        self.layers\n    ), \"Error: max_order cannot be larger than maximum order of multi-order network\"\n\n    dof = self.layers[1].data.num_nodes - 1  # Degrees of freedom for zeroth order\n\n    if assumption == \"paths\":\n        # COMPUTING CONTRIBUTION FROM NUM PATHS AND NONZERO OUTDEGREES SEPARATELY\n        # TODO: CAN IT BE DONE TOGETHER?\n\n        edge_index = self.layers[1].data.edge_index\n        # Adding dof from Number of paths of length k\n        for k in range(1, max_order + 1):\n            if k &gt; 1:\n                num_nodes = 0 if edge_index.numel() == 0 else edge_index.max().item() + 1\n                edge_index = lift_order_edge_index(edge_index, num_nodes)\n            # counting number of len k paths\n            num_len_k_paths = edge_index.shape[1]  # edge_index.max().item() +1  # Number of paths of length k\n            dof += num_len_k_paths\n\n        # removing dof from total probability of nonzero degree nodes\n        for k in range(1, max_order + 1):\n            if k == 1:\n                # edge_index of temporal graph is sorted by time by default\n                # For matrix multiplication, we need to sort it by row\n                edge_index_adj = self.layers[1].data.edge_index.sort_by(\"row\")[0]\n                edge_index = edge_index_adj\n            else:\n                edge_index, _ = edge_index.matmul(edge_index_adj)\n            num_nonzero_outdegrees = torch.unique(edge_index[0]).size(0)\n            dof -= num_nonzero_outdegrees\n\n    elif assumption == \"ngrams\":\n        for order in range(1, max_order + 1):\n            dof += (self.layers[1].data.num_nodes ** order) * (self.layers[1].data.num_nodes - 1)\n    else:\n        raise ValueError(\n            f\"Unknown assumption {assumption} in input. The only accepted values are 'path' and 'ngram'\"\n        )\n\n    return int(dof)\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_mon_log_likelihood","title":"<code>get_mon_log_likelihood</code>","text":"<p>Compute the likelihood of the walks given a multi-order model.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The multi-order model.</p> required <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>Dataset containing the walks.</p> required <code>max_order</code> <code>int</code> <p>The maximum order up to which model layers shall be taken into account. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The log likelihood of the walks given the multi-order model.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_mon_log_likelihood(self, dag_graph: Data, max_order: int = 1) -&gt; float:\n    \"\"\"\n    Compute the likelihood of the walks given a multi-order model.\n\n    Args:\n        m (MultiOrderModel): The multi-order model.\n        dag_graph (Data): Dataset containing the walks.\n        max_order (int, optional): The maximum order up to which model layers\n            shall be taken into account. Defaults to 1.\n\n    Returns:\n        float: The log likelihood of the walks given the multi-order model.\n    \"\"\"\n    llh = 0\n\n    # Adding likelihood of zeroth order\n    llh += self.get_zeroth_order_log_likelihood(dag_graph)\n\n    # Adding the likelihood for all the intermediate orders\n    for order in range(1, max_order):\n        llh += self.get_intermediate_order_log_likelihood(dag_graph, order)\n\n    # Adding the likelihood of highest/stationary order\n    if max_order &gt; 0:\n        transition_probabilities = self.layers[max_order].transition_probabilities()\n        log_transition_probabilities = torch.log(transition_probabilities)\n        llh_by_subpath = log_transition_probabilities * self.layers[max_order].data.edge_weight\n        llh += llh_by_subpath.sum().item()\n    else:\n        # Compute likelihood for zeroth order (to be modified)\n        # TODO: modify once we have zeroth order in mon\n        # (then won t need to compute emission probs from dag_graph -- which also hinders us from computing the lh that a new set of paths was generated by the model)\n        frequencies = dag_graph.dag_weight\n        counts = torch.bincount(\n            dag_graph.node_sequence.squeeze(), frequencies.repeat_interleave(dag_graph.dag_num_nodes)\n        )\n        node_emission_probabilities = counts / counts.sum()\n        llh = torch.mul(torch.log(node_emission_probabilities), counts).sum().item()\n\n    return llh\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_zeroth_order_log_likelihood","title":"<code>get_zeroth_order_log_likelihood</code>","text":"<p>Compute the zeroth order log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>Input DAG graph data.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Zeroth order log likelihood.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_zeroth_order_log_likelihood(self, dag_graph: Data) -&gt; float:\n    \"\"\"\n    Compute the zeroth order log likelihood.\n\n    Args:\n        dag_graph (Data): Input DAG graph data.\n\n    Returns:\n        float: Zeroth order log likelihood.\n    \"\"\"\n    # Get frequencies\n    # getting the index of the last edge of each path (to be used to extract weights)\n    frequencies = dag_graph.dag_weight\n\n    # Get ixs starting nodes\n    # Q: Is dag_graph.path_index[:-1] enough to get the start_ixs?\n    mask = torch.ones(dag_graph.num_nodes, dtype=bool)\n    mask[dag_graph.edge_index[1]] = False\n    start_ixs = dag_graph.node_sequence.squeeze()[mask]\n\n    # Compute node emission probabilities\n    # TODOL modify once we have zeroth order in mon\n    _, counts = torch.unique(dag_graph.node_sequence, return_counts=True)\n    # WARNING: Only works if all nodes in the first-order graph are also in `node_sequence`\n    # Otherwise the missing nodes will not be included in `counts` which can lead to elements at the wrong index.\n    node_emission_probabilities = counts / counts.sum()\n    return torch.mul(frequencies, torch.log(node_emission_probabilities[start_ixs])).sum().item()\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.iterate_lift_order","title":"<code>iterate_lift_order</code>  <code>staticmethod</code>","text":"<p>Lift order by one and save the result in the layers dictionary of the object. This is a helper function that should not be called directly. Only use for edge_indices after the special cases have been handled e.g. in the from_temporal_graph (filtering non-time-respecting paths of order 2).</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of the (k-1)-th order graph.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights of the (k-1)-th order graph.</p> <code>None</code> <code>k</code> <p>The order of the graph that should be computed.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> <code>save</code> <code>bool</code> <p>Whether to compute the aggregated graph and later save it in the layers dictionary.</p> <code>True</code> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>@staticmethod\ndef iterate_lift_order(\n    edge_index: torch.Tensor,\n    node_sequence: torch.Tensor,\n    mapping: IndexMap,\n    edge_weight: torch.Tensor | None = None,\n    aggr: str = \"src\",\n    save: bool = True,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n    \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n    This is a helper function that should not be called directly.\n    Only use for edge_indices after the special cases have been handled e.g.\n    in the from_temporal_graph (filtering non-time-respecting paths of order 2).\n\n    Args:\n        edge_index: The edge index of the (k-1)-th order graph.\n        node_sequence: The node sequences of the (k-1)-th order graph.\n        edge_weight: The edge weights of the (k-1)-th order graph.\n        k: The order of the graph that should be computed.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n    \"\"\"\n    # Lift order\n    if edge_weight is None:\n        ho_index = lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n    else:\n        ho_index, edge_weight = lift_order_edge_index_weighted(\n            edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n        )\n    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n    # Aggregate\n    if save:\n        gk = aggregate_edge_index(ho_index, node_sequence, edge_weight)\n        gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n    else:\n        gk = None\n    return ho_index, node_sequence, edge_weight, gk\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.likelihood_ratio_test","title":"<code>likelihood_ratio_test</code>","text":"<p>Perform a likelihood ratio test to compare two models of different order.</p> <p>Parameters:</p> Name Type Description Default <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>The input DAG graph data.</p> required <code>max_order_null</code> <code>int</code> <p>The maximum order of the null hypothesis model. Defaults to 0.</p> <code>0</code> <code>max_order</code> <code>int</code> <p>The maximum order of the alternative hypothesis model. Defaults to 1.</p> <code>1</code> <code>assumption</code> <code>str</code> <p>The assumption to use for the degrees of freedom calculation. Can be 'paths' or 'ngrams'. Defaults to 'paths'.</p> <code>'paths'</code> <code>significance_threshold</code> <code>float</code> <p>The significance threshold for the test. Defaults to 0.01.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>A tuple containing a boolean indicating whether the null hypothesis is rejected and the p-value of the test.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def likelihood_ratio_test(\n    self,\n    dag_graph: Data,\n    max_order_null: int = 0,\n    max_order: int = 1,\n    assumption: str = \"paths\",\n    significance_threshold: float = 0.01,\n) -&gt; tuple:\n    \"\"\"\n    Perform a likelihood ratio test to compare two models of different order.\n\n    Args:\n        dag_graph (Data): The input DAG graph data.\n        max_order_null (int, optional): The maximum order of the null hypothesis model.\n            Defaults to 0.\n        max_order (int, optional): The maximum order of the alternative hypothesis model.\n            Defaults to 1.\n        assumption (str, optional): The assumption to use for the degrees of freedom calculation.\n            Can be 'paths' or 'ngrams'. Defaults to 'paths'.\n        significance_threshold (float, optional): The significance threshold for the test.\n            Defaults to 0.01.\n\n    Returns:\n        tuple: A tuple containing a boolean indicating whether the null hypothesis is rejected\n            and the p-value of the test.\n    \"\"\"\n    assert (\n        max_order_null &lt; max_order\n    ), \"Error: order of null hypothesis must be smaller than order of alternative hypothesis\"\n    assert max_order &lt;= max(\n        self.layers\n    ), f\"Error: order of hypotheses ({max_order_null} and {max_order}) must be smaller than the maximum order of the MultiOrderModel {max(self.layers)}\"\n    # let L0 be the likelihood for the null model and L1 be the likelihood for the alternative model\n\n    # we first compute a test statistic x = -2 * log (L0/L1) = -2 * (log L0 - log L1)\n    x = -2 * (\n        self.get_mon_log_likelihood(dag_graph, max_order=max_order_null)\n        - self.get_mon_log_likelihood(dag_graph, max_order=max_order)\n    )\n\n    # we calculate the additional degrees of freedom in the alternative model\n    dof_diff = self.get_mon_dof(max_order, assumption=assumption) - self.get_mon_dof(\n        max_order_null, assumption=assumption\n    )\n\n    # if the p-value is *below* the significance threshold, we reject the null hypothesis\n    p = 1 - chi2.cdf(x, dof_diff)\n    return (p &lt; significance_threshold), p\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.to_dbgnn_data","title":"<code>to_dbgnn_data</code>","text":"<p>Convert the MultiOrderModel to a De Bruijn graph for the given maximum order that can be used in <code>pathpyG.nn.dbgnn.DBGNN</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_order</code> <code>int</code> <p>The maximum order of the De Bruijn graph to be computed.</p> <code>2</code> <code>mapping</code> <code>str</code> <p>The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".</p> <code>'last'</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>torch_geometric.data.Data</code> <p>The De Bruijn graph data.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def to_dbgnn_data(self, max_order: int = 2, mapping: str = \"last\") -&gt; Data:\n    \"\"\"\n    Convert the MultiOrderModel to a De Bruijn graph for the given maximum order\n    that can be used in `pathpyG.nn.dbgnn.DBGNN`.\n\n    Args:\n        max_order: The maximum order of the De Bruijn graph to be computed.\n        mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n\n    Returns:\n        Data: The De Bruijn graph data.\n    \"\"\"\n    if max_order not in self.layers:\n        raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n    g = self.layers[1]\n    g_max_order = self.layers[max_order]\n    num_nodes = g.data.num_nodes\n    num_ho_nodes = g_max_order.data.num_nodes\n    if g.data.x is not None:\n        x = g.data.x\n    else:\n        x = torch.eye(num_nodes, num_nodes)\n    x_max_order = torch.eye(num_ho_nodes, num_ho_nodes)\n    edge_index = g.data.edge_index\n    edge_index_max_order = g_max_order.data.edge_index\n    edge_weight = g.data.edge_weight\n    edge_weight_max_order = g_max_order.data.edge_weight\n    bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping)\n\n    if g.data.y is not None:\n        y = g.data.y\n\n    return Data(\n        num_nodes=num_nodes,\n        num_ho_nodes=num_ho_nodes,\n        x=x,\n        x_h=x_max_order,\n        edge_index=edge_index,\n        edge_index_higher_order=edge_index_max_order,\n        edge_weights=edge_weight.float(),\n        edge_weights_higher_order=edge_weight_max_order.float(),\n        bipartite_edge_index=bipartite_edge_index,\n        y=y if \"y\" in locals() else None,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/","title":"path_data","text":""},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData","title":"<code>PathData</code>","text":"<p>Class that can be used to store multiple observations of node sequences representing paths or walks</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; # Generate toy example graph\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'c'),\n&gt;&gt;&gt;                      ('b', 'c'),\n&gt;&gt;&gt;                      ('c', 'd'),\n&gt;&gt;&gt;                      ('c', 'e')])\n&gt;&gt;&gt; # Store observations of walks using the index mapping\n&gt;&gt;&gt; # from the graph above\n&gt;&gt;&gt; paths = pp.PathData(g.mapping)\n&gt;&gt;&gt; paths.append_walk(('a', 'c', 'd'), weight=2.0)\n&gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=2.0)\n&gt;&gt;&gt; print(paths)\nPathData with 2 paths with total weight 4.0\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>class PathData:\n    \"\"\"Class that can be used to store multiple observations of\n    node sequences representing paths or walks\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; # Generate toy example graph\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'c'),\n        &gt;&gt;&gt;                      ('b', 'c'),\n        &gt;&gt;&gt;                      ('c', 'd'),\n        &gt;&gt;&gt;                      ('c', 'e')])\n        &gt;&gt;&gt; # Store observations of walks using the index mapping\n        &gt;&gt;&gt; # from the graph above\n        &gt;&gt;&gt; paths = pp.PathData(g.mapping)\n        &gt;&gt;&gt; paths.append_walk(('a', 'c', 'd'), weight=2.0)\n        &gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=2.0)\n        &gt;&gt;&gt; print(paths)\n        PathData with 2 paths with total weight 4.0\n    \"\"\"\n\n    def __init__(self, mapping: IndexMap | None = None) -&gt; None:\n        if mapping:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n        self.data: Data = Data(\n            edge_index=torch.empty((2, 0), dtype=torch.long),\n            node_sequence=torch.empty((0, 1), dtype=torch.long),\n            dag_weight=torch.empty(0, dtype=torch.float),\n            dag_num_edges=torch.empty(0, dtype=torch.long),\n            dag_num_nodes=torch.empty(0, dtype=torch.long),\n        )\n        self.data.num_nodes = 0\n\n    @property\n    def num_paths(self) -&gt; int:\n        \"\"\"Return the number of stored paths.\"\"\"\n        return len(self.data.dag_num_edges)\n\n    def _append_data(\n        self,\n        edge_index: torch.Tensor,\n        node_sequence: torch.Tensor,\n        weights: torch.Tensor,\n        num_edges: torch.Tensor,\n        num_nodes: torch.Tensor,\n    ) -&gt; None:\n        \"\"\"\n        Append a edge_index and node_sequence to the PathData object and\n        reassign the indices so that there is no overlap.\n\n        Args:\n            edge_index: Edge index of the new path(s)\n            node_sequence: Node sequence of the new path(s)\n            weights: Weights of the new path(s)\n            num_edges: Number of edges in the new path(s)\n            num_nodes: Number of nodes in the new path(s)\n        \"\"\"\n        new_edge_index = edge_index + self.data.num_nodes\n        self.data.edge_index = torch.cat([self.data.edge_index, new_edge_index], dim=1)\n        self.data.node_sequence = torch.cat([self.data.node_sequence, node_sequence])\n        self.data.dag_weight = torch.cat([self.data.dag_weight, weights])\n        self.data.dag_num_edges = torch.cat([self.data.dag_num_edges, num_edges])\n        self.data.dag_num_nodes = torch.cat([self.data.dag_num_nodes, num_nodes])\n        self.data.num_nodes += num_nodes.sum().item()\n\n    def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n        \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n        Args:\n            node_seq: List or tuple of node IDs\n            weight: Weight of the walk\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n            &gt;&gt;&gt; walks = pp.PathData(mapping)\n            &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n            &gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=1.0)\n        \"\"\"\n        idx_seq = self.mapping.to_idxs(node_seq).unsqueeze(1)\n        idx = torch.arange(len(node_seq), device=self.data.edge_index.device)\n        edge_index = torch.stack([idx[:-1], idx[1:]])\n\n        self._append_data(\n            edge_index=edge_index,\n            node_sequence=idx_seq,\n            weights=torch.tensor([weight], device=self.data.edge_index.device),\n            num_edges=torch.tensor([edge_index.shape[1]], device=self.data.edge_index.device),\n            num_nodes=torch.tensor([len(node_seq)], device=self.data.edge_index.device),\n        )\n\n    def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n        \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\n\n        Args:\n            node_seqs: List or tuple of lists or tuples of node IDs\n            weights: List or tuple of weights for each walk\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n            &gt;&gt;&gt; walks = pp.PathData(mapping)\n            &gt;&gt;&gt; walks.append_walks([['a', 'c', 'd'], ['b', 'c', 'e']], [2.0, 1.0])\n        \"\"\"\n        idx_seqs = torch.cat([self.mapping.to_idxs(seq) for seq in node_seqs]).unsqueeze(1)\n        dag_num_nodes = torch.tensor([len(seq) for seq in node_seqs], device=self.data.edge_index.device)\n\n        big_idx = torch.arange(dag_num_nodes.sum(), device=self.data.edge_index.device)\n        big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n\n        # remove the edges that connect different walks\n        mask = torch.ones(big_edge_index.size(1), dtype=torch.bool, device=self.data.edge_index.device)\n        cum_sum = cumsum(dag_num_nodes, 0)\n        mask[cum_sum[1:-1] - 1] = False\n        big_edge_index = big_edge_index[:, mask]\n\n        weights = torch.Tensor(weights, device=self.data.edge_index.device)\n\n        self._append_data(\n            edge_index=big_edge_index,\n            node_sequence=idx_seqs,\n            weights=weights,\n            num_edges=dag_num_nodes - 1,\n            num_nodes=dag_num_nodes,\n        )\n\n    def get_walk(self, i: int) -&gt; tuple:\n        \"\"\"Return the i-th walk (based on when it was appended) as a tuple of node IDs\n\n        Args:\n            i: Index of the walk to retrieve\n\n        Returns:\n            Tuple of node IDs representing the i-th walk\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n            &gt;&gt;&gt; walks = pp.PathData(mapping)\n            &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n            &gt;&gt;&gt; walks.get_walk(0)\n            ('a', 'c', 'd')\n        \"\"\"\n        start = self.data.dag_num_nodes[:i].sum().item()\n        end = start + self.data.dag_num_nodes[i].item()\n        return tuple(self.mapping.to_ids(self.data.node_sequence[start:end].squeeze()))\n\n    def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n        \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n        return self.mapping.to_ids(node_seq).tolist()\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the PathData object.\"\"\"\n        weight = self.data.dag_weight.sum().item()\n        s = f\"PathData with {self.num_paths} paths with total weight {weight}\"\n        return s\n\n    @staticmethod\n    def from_ngram(file: str, sep: str = \",\", weight: bool = True) -&gt; PathData:\n        with open(file, \"r\", encoding=\"utf-8\") as f:\n            if weight:\n                paths_and_weights = [line.split(sep) for line in f]\n                paths = [path[:-1] for path in paths_and_weights]\n                weights = [float(path[-1]) for path in paths_and_weights]\n            else:\n                paths = [line.split(sep) for line in f]\n                weights = [1.0] * len(paths)\n\n        mapping = IndexMap()\n        mapping.add_ids(np.unique(np.hstack(paths)))\n\n        pathdata = PathData(mapping)\n        pathdata.append_walks(node_seqs=paths, weights=weights)\n\n        return pathdata\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.num_paths","title":"<code>num_paths: int</code>  <code>property</code>","text":"<p>Return the number of stored paths.</p>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the PathData object.</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the PathData object.\"\"\"\n    weight = self.data.dag_weight.sum().item()\n    s = f\"PathData with {self.num_paths} paths with total weight {weight}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.append_walk","title":"<code>append_walk</code>","text":"<p>Add an observation of a walk based on a list or tuple of node IDs or indices</p> <p>Parameters:</p> Name Type Description Default <code>node_seq</code> <code>list | tuple</code> <p>List or tuple of node IDs</p> required <code>weight</code> <code>float</code> <p>Weight of the walk</p> <code>1.0</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n&gt;&gt;&gt; walks = pp.PathData(mapping)\n&gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n&gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=1.0)\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n    \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n    Args:\n        node_seq: List or tuple of node IDs\n        weight: Weight of the walk\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n        &gt;&gt;&gt; walks = pp.PathData(mapping)\n        &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n        &gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=1.0)\n    \"\"\"\n    idx_seq = self.mapping.to_idxs(node_seq).unsqueeze(1)\n    idx = torch.arange(len(node_seq), device=self.data.edge_index.device)\n    edge_index = torch.stack([idx[:-1], idx[1:]])\n\n    self._append_data(\n        edge_index=edge_index,\n        node_sequence=idx_seq,\n        weights=torch.tensor([weight], device=self.data.edge_index.device),\n        num_edges=torch.tensor([edge_index.shape[1]], device=self.data.edge_index.device),\n        num_nodes=torch.tensor([len(node_seq)], device=self.data.edge_index.device),\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.append_walks","title":"<code>append_walks</code>","text":"<p>Add multiple observations of walks based on lists or tuples of node IDs or indices</p> <p>Parameters:</p> Name Type Description Default <code>node_seqs</code> <code>list | tuple</code> <p>List or tuple of lists or tuples of node IDs</p> required <code>weights</code> <code>list | tuple</code> <p>List or tuple of weights for each walk</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n&gt;&gt;&gt; walks = pp.PathData(mapping)\n&gt;&gt;&gt; walks.append_walks([['a', 'c', 'd'], ['b', 'c', 'e']], [2.0, 1.0])\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n    \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\n\n    Args:\n        node_seqs: List or tuple of lists or tuples of node IDs\n        weights: List or tuple of weights for each walk\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n        &gt;&gt;&gt; walks = pp.PathData(mapping)\n        &gt;&gt;&gt; walks.append_walks([['a', 'c', 'd'], ['b', 'c', 'e']], [2.0, 1.0])\n    \"\"\"\n    idx_seqs = torch.cat([self.mapping.to_idxs(seq) for seq in node_seqs]).unsqueeze(1)\n    dag_num_nodes = torch.tensor([len(seq) for seq in node_seqs], device=self.data.edge_index.device)\n\n    big_idx = torch.arange(dag_num_nodes.sum(), device=self.data.edge_index.device)\n    big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n\n    # remove the edges that connect different walks\n    mask = torch.ones(big_edge_index.size(1), dtype=torch.bool, device=self.data.edge_index.device)\n    cum_sum = cumsum(dag_num_nodes, 0)\n    mask[cum_sum[1:-1] - 1] = False\n    big_edge_index = big_edge_index[:, mask]\n\n    weights = torch.Tensor(weights, device=self.data.edge_index.device)\n\n    self._append_data(\n        edge_index=big_edge_index,\n        node_sequence=idx_seqs,\n        weights=weights,\n        num_edges=dag_num_nodes - 1,\n        num_nodes=dag_num_nodes,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.get_walk","title":"<code>get_walk</code>","text":"<p>Return the i-th walk (based on when it was appended) as a tuple of node IDs</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>Index of the walk to retrieve</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple of node IDs representing the i-th walk</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n&gt;&gt;&gt; walks = pp.PathData(mapping)\n&gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n&gt;&gt;&gt; walks.get_walk(0)\n('a', 'c', 'd')\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def get_walk(self, i: int) -&gt; tuple:\n    \"\"\"Return the i-th walk (based on when it was appended) as a tuple of node IDs\n\n    Args:\n        i: Index of the walk to retrieve\n\n    Returns:\n        Tuple of node IDs representing the i-th walk\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n        &gt;&gt;&gt; walks = pp.PathData(mapping)\n        &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n        &gt;&gt;&gt; walks.get_walk(0)\n        ('a', 'c', 'd')\n    \"\"\"\n    start = self.data.dag_num_nodes[:i].sum().item()\n    end = start + self.data.dag_num_nodes[i].item()\n    return tuple(self.mapping.to_ids(self.data.node_sequence[start:end].squeeze()))\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.map_node_seq","title":"<code>map_node_seq</code>","text":"<p>Map a sequence of node indices (e.g. representing a higher-order node) to node IDs</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n    \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n    return self.mapping.to_ids(node_seq).tolist()\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/","title":"temporal_graph","text":""},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph","title":"<code>TemporalGraph</code>","text":"<p>               Bases: <code>pathpyG.Graph</code></p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>class TemporalGraph(Graph):\n    def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n        \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n        Args:\n            data: xxx\n            mapping: xxx\n\n        Example:\n            ```py\n            from pytorch_geometric.data import TemporalData\n            import pathpyG as pp\n\n            d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n            t = pp.TemporalGraph(d, mapping)\n            print(t)\n            ```\n        \"\"\"\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = data.edge_index = EdgeIndex(\n                data=data.edge_index.contiguous(), sparse_size=(data.num_nodes, data.num_nodes)\n            )\n\n        # reorder temporal data\n        self.data = data.sort_by_time()\n\n        if mapping is not None:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n\n        # create mapping between edge index and edge tuples\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        self.start_time = self.data.time[0].item()\n        self.end_time = self.data.time[-1].item()\n\n    @staticmethod\n    def from_edge_list(edge_list, num_nodes: Optional[int] = None) -&gt; TemporalGraph:\n        edge_array = np.array(edge_list)\n        ts = edge_array[:, 2].astype(np.number)\n\n        index_map = IndexMap(np.unique(edge_array[:, :2]))\n        edge_index = index_map.to_idxs(edge_array[:, :2].T)\n\n        if not num_nodes:\n            num_nodes = index_map.num_ids()\n\n        return TemporalGraph(\n            data=Data(\n                edge_index=edge_index,\n                time=torch.Tensor(ts),\n                num_nodes=num_nodes,\n            ),\n            mapping=index_map,\n        )\n\n    @property\n    def temporal_edges(self) -&gt; Generator[Tuple[int, int, int], None, None]:\n        \"\"\"Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.\"\"\"\n        return [(*self.mapping.to_ids(e), t.item()) for e, t in zip(self.data.edge_index.t(), self.data.time)]\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"Return order 1, since all temporal graphs must be order one.\"\"\"\n        return 1\n\n    def shuffle_time(self) -&gt; None:\n        \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n        self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n\n    def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n        \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n        Args:\n            weighted: whether or not to return a weighted time-aggregated graph\n            time_window: A tuple with start and end time of the aggregation window\n\n        Returns:\n            Graph: A static graph object\n        \"\"\"\n        if time_window is not None:\n            idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n            edge_index = self.data.edge_index[:, idx]\n        else:\n            edge_index = self.data.edge_index\n\n        n = edge_index.max().item() + 1\n\n        if weighted:\n            i, w = torch_geometric.utils.coalesce(\n                edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n            )\n            return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n        else:\n            return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n\n    def to_undirected(self) -&gt; TemporalGraph:\n        \"\"\"Return an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        rev_edge_index = self.data.edge_index.flip([0])\n        edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n        times = torch.cat([self.data.time, self.data.time])\n        return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n\n    def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n        \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given batch defined by start and (non-inclusive) end, where start\n        and end refer to the index of the first and last event in the time-ordered list of events.\"\"\"\n\n        return TemporalGraph(\n            data=Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx]),\n            mapping=self.mapping,\n        )\n\n    def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n        \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given time window defined by start and (non-inclusive) end, where start\n        and end refer to the time stamps\"\"\"\n\n        return TemporalGraph(data=self.data.snapshot(start_time, end_time), mapping=self.mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the graph\n        \"\"\"\n        s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n            self.data.num_nodes,\n            self.data.edge_index.unique(dim=1).size(dim=1),\n            self.data.edge_index.size(1),\n            self.start_time,\n            self.end_time,\n        )\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.order","title":"<code>order: int</code>  <code>property</code>","text":"<p>Return order 1, since all temporal graphs must be order one.</p>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.temporal_edges","title":"<code>temporal_edges: Generator[Tuple[int, int, int], None, None]</code>  <code>property</code>","text":"<p>Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.</p>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.__init__","title":"<code>__init__</code>","text":"<p>Creates an instance of a temporal graph from a <code>TemporalData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>xxx</p> required <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>xxx</p> <code>None</code> Example <pre><code>from pytorch_geometric.data import TemporalData\nimport pathpyG as pp\n\nd = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\nt = pp.TemporalGraph(d, mapping)\nprint(t)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n    \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n    Args:\n        data: xxx\n        mapping: xxx\n\n    Example:\n        ```py\n        from pytorch_geometric.data import TemporalData\n        import pathpyG as pp\n\n        d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n        t = pp.TemporalGraph(d, mapping)\n        print(t)\n        ```\n    \"\"\"\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = data.edge_index = EdgeIndex(\n            data=data.edge_index.contiguous(), sparse_size=(data.num_nodes, data.num_nodes)\n        )\n\n    # reorder temporal data\n    self.data = data.sort_by_time()\n\n    if mapping is not None:\n        self.mapping = mapping\n    else:\n        self.mapping = IndexMap()\n\n    # create mapping between edge index and edge tuples\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    self.start_time = self.data.time[0].item()\n    self.end_time = self.data.time[-1].item()\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the graph\n    \"\"\"\n    s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n        self.data.num_nodes,\n        self.data.edge_index.unique(dim=1).size(dim=1),\n        self.data.edge_index.size(1),\n        self.start_time,\n        self.end_time,\n    )\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.get_batch","title":"<code>get_batch</code>","text":"<p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given batch defined by start and (non-inclusive) end, where start and end refer to the index of the first and last event in the time-ordered list of events.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n    \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given batch defined by start and (non-inclusive) end, where start\n    and end refer to the index of the first and last event in the time-ordered list of events.\"\"\"\n\n    return TemporalGraph(\n        data=Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx]),\n        mapping=self.mapping,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.get_window","title":"<code>get_window</code>","text":"<p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given time window defined by start and (non-inclusive) end, where start and end refer to the time stamps</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n    \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given time window defined by start and (non-inclusive) end, where start\n    and end refer to the time stamps\"\"\"\n\n    return TemporalGraph(data=self.data.snapshot(start_time, end_time), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.shuffle_time","title":"<code>shuffle_time</code>","text":"<p>Randomly shuffle the temporal order of edges by randomly permuting timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def shuffle_time(self) -&gt; None:\n    \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n    self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.to_static_graph","title":"<code>to_static_graph</code>","text":"<p>Return weighted time-aggregated instance of <code>Graph</code> graph.</p> <p>Parameters:</p> Name Type Description Default <code>weighted</code> <code>bool</code> <p>whether or not to return a weighted time-aggregated graph</p> <code>False</code> <code>time_window</code> <code>typing.Optional[typing.Tuple[int, int]]</code> <p>A tuple with start and end time of the aggregation window</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.Graph</code> <p>A static graph object</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n    \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n    Args:\n        weighted: whether or not to return a weighted time-aggregated graph\n        time_window: A tuple with start and end time of the aggregation window\n\n    Returns:\n        Graph: A static graph object\n    \"\"\"\n    if time_window is not None:\n        idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n        edge_index = self.data.edge_index[:, idx]\n    else:\n        edge_index = self.data.edge_index\n\n    n = edge_index.max().item() + 1\n\n    if weighted:\n        i, w = torch_geometric.utils.coalesce(\n            edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n    else:\n        return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_undirected(self) -&gt; TemporalGraph:\n    \"\"\"Return an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    rev_edge_index = self.data.edge_index.flip([0])\n    edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n    times = torch.cat([self.data.time, self.data.time])\n    return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/io/","title":"io","text":""},{"location":"reference/pathpyG/io/graphtool/","title":"graphtool","text":""},{"location":"reference/pathpyG/io/graphtool/#pathpyG.io.graphtool.parse_graphtool_format","title":"<code>parse_graphtool_format</code>","text":"<p>Decodes data in graphtool binary format and returns a <code>Graph</code>. For a documentation of the graphtool binary format, see see doc at https://graph-tool.skewed.de/static/doc/gt_format.html</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>Array of bytes to be decoded</p> required <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>a static graph</p> Source code in <code>src/pathpyG/io/graphtool.py</code> <pre><code>def parse_graphtool_format(data: bytes, id_node_attr=None) -&gt; Graph:\n    \"\"\"\n    Decodes data in graphtool binary format and returns a [`Graph`][pathpyG.Graph]. For a documentation of\n    the graphtool binary format, see see doc at https://graph-tool.skewed.de/static/doc/gt_format.html\n\n    Args:\n        data: Array of bytes to be decoded\n\n    Returns:\n        Graph: a static graph\n    \"\"\"\n\n    # check magic bytes\n    if data[0:6] != b\"\\xe2\\x9b\\xbe\\x20\\x67\\x74\":\n        print(\"Invalid graphtool file. Wrong magic bytes.\")\n        raise Exception(\"Invalid graphtool file. Wrong magic bytes.\")\n    ptr = 6\n\n    # read graphtool version byte\n    graphtool_version = int(data[ptr])\n    ptr += 1\n\n    # read endianness\n    if bool(data[ptr]):\n        graphtool_endianness = \"&gt;\"\n    else:\n        graphtool_endianness = \"&lt;\"\n    ptr += 1\n\n    # read length of comment\n    str_len = struct.unpack(graphtool_endianness + \"Q\", data[ptr : ptr + 8])[0]\n    ptr += 8\n\n    # read string comment\n    comment = data[ptr : ptr + str_len].decode(\"ascii\")\n    ptr += str_len\n\n    # read network directedness\n    directed = bool(data[ptr])\n    ptr += 1\n\n    # read number of nodes\n    n_nodes = struct.unpack(graphtool_endianness + \"Q\", data[ptr : ptr + 8])[0]\n    ptr += 8\n\n    # create pandas dataframe\n    network_dict = {}\n    # n = Network(directed = directed, multiedges=True)\n\n    # determine binary representation of neighbour lists\n    if n_nodes &lt; 2**8:\n        fmt = \"B\"\n        d = 1\n    elif n_nodes &lt; 2**16:\n        fmt = \"H\"\n        d = 2\n    elif n_nodes &lt; 2**32:\n        fmt = \"I\"\n        d = 4\n    else:\n        fmt = \"Q\"\n        d = 8\n\n    sources = []\n    targets = []\n    # parse lists of out-neighbors for all n nodes\n    n_edges = 0\n    for v in range(n_nodes):\n        # read number of neighbors\n        num_neighbors = struct.unpack(graphtool_endianness + \"Q\", data[ptr : ptr + 8])[0]\n        ptr += 8\n\n        # add edges to record\n        for _ in range(num_neighbors):\n            w = struct.unpack(graphtool_endianness + fmt, data[ptr : ptr + d])[0]\n            ptr += d\n            sources.append(v)\n            targets.append(w)\n            n_edges += 1\n\n    # collect attributes from property maps\n    graph_attr = dict()\n    node_attr = dict()\n    edge_attr = dict()\n\n    # parse property maps\n    property_maps = struct.unpack(graphtool_endianness + \"Q\", data[ptr : ptr + 8])[0]\n    ptr += 8\n\n    for _ in range(property_maps):\n        key_type = struct.unpack(graphtool_endianness + \"B\", data[ptr : ptr + 1])[0]\n        ptr += 1\n\n        property_len = struct.unpack(graphtool_endianness + \"Q\", data[ptr : ptr + 8])[0]\n        ptr += 8\n\n        property_name = data[ptr : ptr + property_len].decode(\"ascii\")\n        ptr += property_len\n\n        property_type = struct.unpack(graphtool_endianness + \"B\", data[ptr : ptr + 1])[0]\n        ptr += 1\n\n        if key_type == 0:  # graph-level property\n            res = _parse_property_value(data, ptr, property_type, graphtool_endianness)\n            graph_attr[property_name] = res[0]\n            ptr += res[1]\n        elif key_type == 1:  # node-level property\n            if property_name not in node_attr:\n                node_attr[property_name] = []\n            for v in range(n_nodes):\n                res = _parse_property_value(data, ptr, property_type, graphtool_endianness)\n                node_attr[property_name].append([res[0]])\n                ptr += res[1]\n        elif key_type == 2:  # edge-level property\n            if property_name not in edge_attr:\n                edge_attr[property_name] = []\n            for e in range(n_edges):\n                res = _parse_property_value(data, ptr, property_type, graphtool_endianness)\n                edge_attr[property_name].append(res[0])\n                ptr += res[1]\n        else:\n            print(\"Unknown key type {0}\".format(key_type))\n\n    # LOG.info('Version \\t= {0}'.format(graphtool_version))\n    # LOG.info('Endianness \\t= {0}'.format(graphtool_endianness))\n    # LOG.info('comment size \\t= {0}'.format(str_len))\n    # LOG.info('comment \\t= {0}'.format(comment))\n    # LOG.info('directed \\t= {0}'.format(directed))\n    # LOG.info('nodes \\t\\t= {0}'.format(n_nodes))\n\n    # add edge properties to data frame\n    # for p in edge_attribute_names:\n    #     # due to use of default_dict, this will add NA values to edges which have missing properties\n    #     network_data[p] = [ edge_attributes[e][p] for e in range(n_edges) ]\n\n    # create graph from pandas dataframe\n\n    # if 'time' in edge_attribute_names and not ignore_temporal:\n    #     raise Exception('')\n    #     n = to_temporal_network(network_data, directed=directed, **network_attributes)\n    # else:\n\n    if id_node_attr:\n        mapping = pp.IndexMap(node_attr[id_node_attr])\n    else:\n        mapping = None\n\n    g = Graph.from_edge_index(torch.LongTensor([sources, targets]).to(config[\"torch\"][\"device\"]), mapping=mapping)\n    for a in node_attr:\n        if not a.startswith(\"node_\"):\n            # print(node_attr[a])\n            # g.data['node_{0}'.format(a)] = torch.tensor(node_attr[a], dtype=torch.float).to(config['torch']['device'])\n            g.data[\"node_{0}\".format(a)] = node_attr[a]\n    for a in edge_attr:\n        if not a.startswith(\"edge_\"):\n            g.data[\"edge_{0}\".format(a)] = torch.tensor(edge_attr[a], dtype=torch.float).to(config[\"torch\"][\"device\"])\n    for a in graph_attr:\n        g.data[a] = graph_attr[a]\n\n    if not directed:\n        return g.to_undirected()\n    return g\n</code></pre>"},{"location":"reference/pathpyG/io/graphtool/#pathpyG.io.graphtool.read_graphtool","title":"<code>read_graphtool</code>","text":"<p>Read a file in graphtool binary format.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>Path to graphtool file to be read</p> required Source code in <code>src/pathpyG/io/graphtool.py</code> <pre><code>def read_graphtool(file: str, multiedges: bool = False) -&gt; Graph:\n    \"\"\"\n    Read a file in graphtool binary format.\n\n    Args:\n        file: Path to graphtool file to be read\n    \"\"\"\n    with open(file, \"rb\") as f:\n        if \".zst\" in file:\n            try:\n                import zstandard as zstd\n\n                dctx = zstd.ZstdDecompressor()\n                data = f.read()\n                return parse_graphtool_format(dctx.decompress(data, max_output_size=len(data)))\n            except ModuleNotFoundError:\n                msg = 'Package zstandard is required to decompress graphtool files. Please install module, e.g., using \"pip install zstandard\".'\n                # LOG.error(msg)\n                raise Exception(msg)\n        else:\n            return parse_graphtool_format(f.read(), multiedges)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/","title":"netzschleuder","text":""},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.list_netzschleuder_records","title":"<code>list_netzschleuder_records</code>","text":"<p>Read a list of data sets available at the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <code>**kwargs</code> <code>typing.Any</code> <p>Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters. For supported parameters see https://networks.skewed.de/api</p> <code>{}</code> <p>Examples:</p> <p>Return a list of all data sets</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; pp.io.list_netzschleuder_records()\n['karate', 'reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a list of all data sets with a given tag</p> <pre><code>&gt;&gt;&gt; pp.io.list_netzschleuder_records(tags='temporal')\n['reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a dictionary containing all data set names (keys) as well as all network attributes</p> <pre><code>&gt;&gt;&gt; pp.io.list_netzschleuder_records(full=True)\n{ 'reality_mining': [...], 'karate': [...] }\n</code></pre> <p>Returns:</p> Type Description <code>typing.Union[list, dict]</code> <p>Either a list of data set names or a dictionary containing all data set names and network attributes.</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def list_netzschleuder_records(base_url: str = \"https://networks.skewed.de\", **kwargs: Any) -&gt; Union[list, dict]:\n    \"\"\"\n    Read a list of data sets available at the netzschleuder repository.\n\n    Args:\n        base_url: Base URL of netzschleuder repository\n        **kwargs: Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters.\n            For supported parameters see https://networks.skewed.de/api\n\n\n    Examples:\n        Return a list of all data sets\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; pp.io.list_netzschleuder_records()\n        ['karate', 'reality_mining', 'sp_hypertext', ...]\n\n        Return a list of all data sets with a given tag\n\n        &gt;&gt;&gt; pp.io.list_netzschleuder_records(tags='temporal')\n        ['reality_mining', 'sp_hypertext', ...]\n\n        Return a dictionary containing all data set names (keys) as well as all network attributes\n\n        &gt;&gt;&gt; pp.io.list_netzschleuder_records(full=True)\n        { 'reality_mining': [...], 'karate': [...] }\n\n\n    Returns:\n        Either a list of data set names or a dictionary containing all data set names and network attributes.\n\n    \"\"\"\n    url = \"/api/nets\"\n    for k, v in kwargs.items():\n        url += \"?{0}={1}\".format(k, v)\n    try:\n        f = request.urlopen(base_url + url).read()\n        return json.loads(f)\n    except HTTPError:\n        msg = \"Could not connect to netzschleuder repository at {0}\".format(base_url)\n        # LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_graph","title":"<code>read_netzschleuder_graph</code>","text":"<p>Read a pathpyG graph or temporal graph from the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the network data set to read from</p> required <code>net</code> <code>typing.Optional[str]</code> <p>Identifier of the network within the data set to read. For data sets containing a single network only, this can be set to None.</p> <code>None</code> <code>ignore_temporal</code> <p>If False, this function will return a static or temporal network depending on whether edges contain a time attribute. If True, pathpy will not interpret time attributes and thus always return a static network.</p> required <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <code>format</code> <p>for 'csv' a zipped csv file will be downloaded, for 'gt' the binary graphtool format will be retrieved via the API</p> <code>'csv'</code> <p>Examples:</p> <p>Read network '77' from karate club data set</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; n = pp.io.read_netzschleuder_network('karate', '77')\n&gt;&gt;&gt; print(type(n))\n&gt;&gt;&gt; pp.plot(n)\npp.Graph\n</code></pre> <p>Returns:</p> Type Description <code>pathpyG.core.graph.Graph</code> <p>an instance of Graph</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_graph(\n    name: str,\n    net: Optional[str] = None,\n    multiedges: bool = False,\n    time_attr: Optional[str] = None,\n    base_url: str = \"https://networks.skewed.de\",\n    format=\"csv\",\n) -&gt; Graph:\n    \"\"\"Read a pathpyG graph or temporal graph from the netzschleuder repository.\n\n    Args:\n        name: Name of the network data set to read from\n        net: Identifier of the network within the data set to read. For data sets\n            containing a single network only, this can be set to None.\n        ignore_temporal: If False, this function will return a static or temporal network depending\n            on whether edges contain a time attribute. If True, pathpy will not interpret\n            time attributes and thus always return a static network.\n        base_url: Base URL of netzschleuder repository\n        format: for 'csv' a zipped csv file will be downloaded, for 'gt' the binary graphtool format will be retrieved via the API\n\n    Examples:\n        Read network '77' from karate club data set\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; n = pp.io.read_netzschleuder_network('karate', '77')\n        &gt;&gt;&gt; print(type(n))\n        &gt;&gt;&gt; pp.plot(n)\n        pp.Graph\n\n\n    Returns:\n        an instance of Graph\n\n    \"\"\"\n    # build URL\n\n    try:\n        # retrieve properties of data record via API\n        properties = json.loads(request.urlopen(f\"{base_url}/api/net/{name}\").read())\n        # print(properties)\n\n        timestamps = \"Timestamps\" in properties[\"tags\"]\n\n        if not net:\n            analyses = properties[\"analyses\"]\n            net = name\n        else:\n            analyses = properties[\"analyses\"][net]\n\n        try:\n            is_directed = analyses[\"is_directed\"]\n            num_nodes = analyses[\"num_vertices\"]\n        except KeyError:\n            raise Exception(f\"Record {name} contains multiple networks, please specify network name.\")\n\n        if format == \"csv\":\n            url = f\"{base_url}/net/{name}/files/{net}.csv.zip\"\n            try:\n                response = request.urlopen(url)\n\n                # decompress zip into temporary folder\n                data = BytesIO(response.read())\n\n                with zipfile.ZipFile(data, \"r\") as zip_ref:\n                    with tempfile.TemporaryDirectory() as temp_dir:\n                        zip_ref.extractall(path=temp_dir)\n\n                        # the gprop file contains lines with property name/value pairs\n                        # gprops = pd.read_csv(f'{temp_dir}/gprops.csv', header=0, sep=',', skip_blank_lines=True, skipinitialspace=True)\n\n                        # nodes.csv contains node indices with node properties (like name)\n                        edges = pd.read_csv(\n                            f\"{temp_dir}/edges.csv\", header=0, sep=\",\", skip_blank_lines=True, skipinitialspace=True\n                        )\n\n                        # rename columns\n                        edges.rename(columns={\"# source\": \"v\", \"target\": \"w\"}, inplace=True)\n                        if timestamps and time_attr:\n                            edges.rename(columns={time_attr: \"t\"}, inplace=True)\n\n                        # construct graph and assign edge attributes\n                        if timestamps:\n                            g = df_to_temporal_graph(df=edges, is_undirected=not is_directed, num_nodes=num_nodes)\n                        else:\n                            g = df_to_graph(df=edges, multiedges=True, num_nodes=num_nodes)\n                            if not is_directed:\n                                g = g.to_undirected()\n\n                        node_attrs = pd.read_csv(\n                            f\"{temp_dir}/nodes.csv\", header=0, sep=\",\", skip_blank_lines=True, skipinitialspace=True\n                        )\n                        node_attrs.rename(columns={\"# index\": \"index\"}, inplace=True)\n\n                        add_node_attributes(node_attrs, g)\n\n                        # add graph-level attributes\n                        for x in analyses:\n                            g.data[\"analyses_\" + x] = analyses[x]\n\n                        return g\n            except HTTPError:\n                msg = f\"Could not retrieve netzschleuder record at {url}\"\n                raise Exception(msg)\n\n        elif format == \"gt\":\n            try:\n                import zstandard as zstd\n\n                url = f\"/net/{name}/files/{net}.gt.zst\"\n                try:\n                    f = request.urlopen(base_url + url)\n                    # decompress data\n                    dctx = zstd.ZstdDecompressor()\n                    reader = dctx.stream_reader(f)\n                    decompressed = reader.readall()\n\n                    # parse graphtool binary format\n                    return parse_graphtool_format(bytes(decompressed))\n                except HTTPError:\n                    msg = f\"Could not retrieve netzschleuder record at {url}\"\n                    raise Exception(msg)\n            except ModuleNotFoundError:\n                msg = 'Package zstandard is required to decompress graphtool files. Please install module, e.g., using \"pip install zstandard.'\n                # LOG.error(msg)\n                raise Exception(msg)\n    except HTTPError:\n        msg = f\"Could not retrieve netzschleuder record at {base_url}/api/net/{name}\"\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_record","title":"<code>read_netzschleuder_record</code>","text":"<p>Read metadata of a single data record with given name from the netzschleuder repository</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the data set for which to retrieve the metadata</p> required <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <p>Examples:</p> <p>Retrieve metadata of karate club network</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; metdata = pp.io.read_netzschleuder_record('karate')\n&gt;&gt;&gt; print(metadata)\n{\n    'analyses': {'77': {'average_degree': 4.52... } }\n}\n</code></pre> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing key-value pairs of metadata</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_record(name: str, base_url: str = \"https://networks.skewed.de\") -&gt; dict:\n    \"\"\"\n    Read metadata of a single data record with given name from the netzschleuder repository\n\n    Args:\n        name: Name of the data set for which to retrieve the metadata\n        base_url: Base URL of netzschleuder repository\n\n    Examples:\n        Retrieve metadata of karate club network\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; metdata = pp.io.read_netzschleuder_record('karate')\n        &gt;&gt;&gt; print(metadata)\n        {\n            'analyses': {'77': {'average_degree': 4.52... } }\n        }\n\n    Returns:\n        Dictionary containing key-value pairs of metadata\n    \"\"\"\n    url = \"/api/net/{0}\".format(name)\n    try:\n        return json.loads(request.urlopen(base_url + url).read())\n    except HTTPError:\n        msg = \"Could not connect to netzschleuder repository at {0}\".format(base_url)\n        # LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/","title":"pandas","text":""},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.add_edge_attributes","title":"<code>add_edge_attributes</code>","text":"<p>Add edge attributes from pandas data frame to existing graph, where source/target node IDs are given in columns <code>v</code> and <code>w</code>  and edge attributes x are given in columns <code>edge_x</code></p> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def add_edge_attributes(df: pd.DataFrame, g: Graph) -&gt; None:\n    \"\"\"Add edge attributes from pandas data frame to existing graph, where source/target node\n    IDs are given in columns `v` and `w`  and edge attributes x are given in columns `edge_x`\n    \"\"\"\n\n    if \"v\" not in df or \"w\" not in df:\n        print(\"data frame must have columns `v` and `w`\")\n        return\n\n    attributed_edges = list(zip(df[\"v\"], df[\"w\"]))\n\n    # check for duplicated edge attributes\n    if len(set(attributed_edges)) &lt; len(attributed_edges):\n        print(\"data frame contains multiple attribute values for single edge\")\n        return\n\n    # check for difference between edges in graph and edges in attributes\n    if set(attributed_edges) != set([(v, w) for v, w in g.edges]):\n        print(\"Mismatch between edges in DataFrame and edges in graph\")\n        return\n\n    # extract indices of source/target node of edges\n    src = [g.mapping.to_idx(x) for x in df[\"v\"]]\n    tgt = [g.mapping.to_idx(x) for x in df[\"w\"]]\n\n    # find indices of edges in edge_index\n    edge_idx = []\n    for i in range(len(src)):\n        x = torch.where((g.data.edge_index[0, :] == src[i]) &amp; (g.data.edge_index[1, :] == tgt[i]))[0].item()\n        edge_idx.append(x)\n    for attr in df.columns:\n        if attr != \"v\" and attr != \"w\":\n            prefix = \"\"\n            if not attr.startswith(\"edge_\"):\n                prefix = \"edge_\"\n\n            # eval values for array-valued attributes\n            try:\n                values = np.array([eval(x) for x in df[attr].values])\n                g.data[prefix + attr] = torch.from_numpy(values[edge_idx]).to(device=g.data.edge_index.device)\n                continue\n            except:\n                pass\n\n            # try to directly construct tensor for scalar values\n            try:\n                g.data[prefix + attr] = torch.from_numpy(df[attr].values[edge_idx]).to(device=g.data.edge_index.device)\n                continue\n            except:\n                pass\n\n            # numpy array of strings\n            try:\n                g.data[prefix + attr] = np.array(df[attr].values.astype(str)[edge_idx])\n            except:\n                t = df[attr].dtype\n                print(f\"Could not assign edge attribute {attr} of type {t}\")\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.add_node_attributes","title":"<code>add_node_attributes</code>","text":"<p>Add node attributes from pandas data frame to existing graph, where node IDs or indices are given in column <code>v</code> and node attributes x are given in columns <code>node_x</code></p> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def add_node_attributes(df: pd.DataFrame, g: Graph):\n    \"\"\"Add node attributes from pandas data frame to existing graph, where node\n    IDs or indices are given in column `v` and node attributes x are given in columns `node_x`\n    \"\"\"\n    if \"v\" in df:\n        print(\"Mapping node attributes based on node names in column `v`\")\n        attributed_nodes = list(df[\"v\"])\n    elif \"index\" in df:\n        print(\"Mapping node attributes based on node indices in column `index`\")\n        attributed_nodes = list(df[\"index\"])\n    else:\n        print(\"Data frame must either have `index` or `v` column\")\n        return\n\n    # check for duplicated node attributes\n    if len(set(attributed_nodes)) &lt; len(attributed_nodes):\n        print(\"data frame cannot contain multiple attribute values for single node\")\n        return\n\n    # check for difference between nodes in graph and nodes in attributes\n    if \"v\" in df:\n        if set(attributed_nodes) != set([v for v in g.nodes]):\n            print(\"Mismatch between nodes in DataFrame and nodes in graph\")\n            return\n\n        # get indices of nodes in tensor\n        node_idx = [g.mapping.to_idx(x) for x in df[\"v\"]]\n    else:\n        if set(attributed_nodes) != set([i for i in range(g.n)]):\n            print(\"Mismatch between nodes in DataFrame and nodes in graph\")\n            return\n\n        # get indices of nodes in tensor\n        node_idx = attributed_nodes\n\n    # assign node property tensors\n    for attr in df.columns:\n\n        # skip node column\n        if attr == \"v\" or attr == \"index\":\n            continue\n\n        # prefix attribute names that are not already prefixed\n        prefix = \"\"\n        if not attr.startswith(\"node_\"):\n            prefix = \"node_\"\n\n        # eval values for array-valued attributes\n        try:\n            values = np.array([eval(x) for x in df[attr].values])\n            g.data[prefix + attr] = torch.from_numpy(values[node_idx]).to(device=g.data.edge_index.device)\n            continue\n        except:\n            pass\n\n        # try to directly construct tensor for scalar values\n        try:\n            g.data[prefix + attr] = torch.from_numpy(df[attr].values[node_idx]).to(device=g.data.edge_index.device)\n            continue\n        except:\n            pass\n\n        # numpy array of strings\n        try:\n            g.data[prefix + attr] = np.array(df[attr].values.astype(str)[node_idx])\n        except:\n            t = df[attr].dtype\n            print(f\"Could not assign node attribute {attr} of type {t}\")\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.df_to_graph","title":"<code>df_to_graph</code>","text":"<p>Reads a network from a pandas data frame.</p> <p>The data frame is expected to have a minimum of two columns that give the source and target nodes of edges. Additional columns in the data frame will be mapped to edge attributes.</p> <p>Args:</p> <pre><code>df: pandas.DataFrame\n\n    A data frame with rows containing edges and optional edge attributes. If the\n    data frame contains column names, the source and target columns must be called\n    'v' and 'w' respectively. If no column names are used the first two columns\n    are interpreted as source and target.\n\nis_undirected: Optional[bool]=True\n\n    whether or not to interpret edges as undirected\n\nmultiedges: Optional[bool]=False\n\n    whether or not to allow multiple edges between the same node pair. By\n    default multi edges are ignored.\n</code></pre> Example <pre><code>import pathpyG as pp\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'v': ['a', 'b', 'c'],\n    'w': ['b', 'c', 'a'],\n    'edge_weight': [1.0, 5.0, 2.0]\n    })\ng = pp.io.df_to_graph(df)\nprint(n)\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def df_to_graph(df: pd.DataFrame, is_undirected: bool = False, multiedges: bool = False, **kwargs: Any) -&gt; Graph:\n    \"\"\"Reads a network from a pandas data frame.\n\n    The data frame is expected to have a minimum of two columns\n    that give the source and target nodes of edges. Additional columns in the\n    data frame will be mapped to edge attributes.\n\n    Args:\n\n        df: pandas.DataFrame\n\n            A data frame with rows containing edges and optional edge attributes. If the\n            data frame contains column names, the source and target columns must be called\n            'v' and 'w' respectively. If no column names are used the first two columns\n            are interpreted as source and target.\n\n        is_undirected: Optional[bool]=True\n\n            whether or not to interpret edges as undirected\n\n        multiedges: Optional[bool]=False\n\n            whether or not to allow multiple edges between the same node pair. By\n            default multi edges are ignored.\n\n    Example:\n        ```py\n\n        import pathpyG as pp\n        import pandas as pd\n\n        df = pd.DataFrame({\n            'v': ['a', 'b', 'c'],\n            'w': ['b', 'c', 'a'],\n            'edge_weight': [1.0, 5.0, 2.0]\n            })\n        g = pp.io.df_to_graph(df)\n        print(n)\n        ```\n    \"\"\"\n\n    # assign column names if no header is present\n    no_header = all(isinstance(x, int) for x in df.columns.values.tolist())\n\n    if no_header:\n        # interpret first two columns as source and target\n        col_names = [\"v\", \"w\"]\n        # interpret remaining columns as edge attributes\n        for i in range(2, len(df.columns.values.tolist())):\n            col_names += [\"edge_attr_{0}\".format(i - 2)]\n        df.columns = col_names\n\n    df[\"v\"] = df[\"v\"].astype(str)\n    df[\"w\"] = df[\"w\"].astype(str)\n\n    edges: list = []\n    edge_set: set = set()\n\n    # counter for multiple edges\n    counter: Counter = Counter()\n\n    for row in df.to_dict(orient=\"records\"):\n        _v, _w = row.pop(\"v\"), row.pop(\"w\")\n\n        # check if edge was already generated\n        if (_v, _w) in edge_set and not multiedges:\n            counter[(_v, _w)] += 1\n        else:\n            # add edge\n            edges.append((_v, _w))\n            edge_set.add((_v, _w))\n\n    # check for multi-edges\n    if len(counter) &gt; 0:\n        print(\n            \"%i edges existed already \"\n            \"and were not considered. \"\n            \"To capture those edges, consider creating \"\n            \"a multiedge and/or directed network.\",\n            sum(counter.values()),\n        )\n\n    # create graph\n    g = Graph.from_edge_list(edges, is_undirected=is_undirected, **kwargs)\n\n    # assign edge attributes\n    add_edge_attributes(df, g)\n    return g\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.df_to_temporal_graph","title":"<code>df_to_temporal_graph</code>","text":"<p>Reads a temporal graph from a pandas data frame.</p> <p>The data frame is expected to have a minimum of two columns <code>v</code> and <code>w</code> that give the source and target nodes of edges. Additional column names to be used can be configured in <code>config.cfg</code> as <code>v_synonyms</code> and <code>w</code> synonyms. The time information on edges can either be stored in an additional <code>timestamp</code> column (for instantaneous interactions) or in two columns <code>start</code>, <code>end</code> or <code>timestamp</code>, <code>duration</code> respectively for networks where edges appear and exist for a certain time. Synonyms for those column names can be configured in config.cfg.  Each row in the data frame is mapped to one temporal edge. Additional columns in the data frame will be mapped to edge attributes.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>pandas.DataFrame with rows containing time-stamped edges and optional edge</p> required <code>timestamp_format</code> <p>timestamp format</p> <code>'%Y-%m-%d %H:%M:%S'</code> <code>time_rescale</code> <p>time stamp rescaling factor</p> <code>1</code> <code>**kwargs</code> <code>typing.Any</code> <p>Arbitrary keyword arguments that will be set as network-level attributes.</p> <code>{}</code> <p>Example: <pre><code>import pathpyG as pp\nimport pandas as pd\ndf = pd.DataFrame({\n    'v': ['a', 'b', 'c'],\n    'w': ['b', 'c', 'a'],\n    't': [1, 2, 3]})\ng = pp.io.df_to_temporal_graph(df)\nprint(g)\n\ndf = pd.DataFrame([\n    ['a', 'b', 'c'],\n    ['b', 'c', 'a'],\n    [1, 2, 3]\n    ])\ng = pp.io.df_to_temporal_graph(df)\nprint(g)\n</code></pre></p> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def df_to_temporal_graph(\n    df: pd.DataFrame, is_undirected: bool = False, timestamp_format=\"%Y-%m-%d %H:%M:%S\", time_rescale=1, **kwargs: Any\n) -&gt; TemporalGraph:\n    \"\"\"Reads a temporal graph from a pandas data frame.\n\n    The data frame is expected to have a minimum of two columns `v` and `w`\n    that give the source and target nodes of edges. Additional column names to\n    be used can be configured in `config.cfg` as `v_synonyms` and `w`\n    synonyms. The time information on edges can either be stored in an\n    additional `timestamp` column (for instantaneous interactions) or in two\n    columns `start`, `end` or `timestamp`, `duration` respectively for networks\n    where edges appear and exist for a certain time. Synonyms for those column\n    names can be configured in config.cfg.  Each row in the data frame is\n    mapped to one temporal edge. Additional columns in the data frame will be\n    mapped to edge attributes.\n\n    Args:\n        df: pandas.DataFrame with rows containing time-stamped edges and optional edge\n        attributes.\n        timestamp_format: timestamp format\n        time_rescale: time stamp rescaling factor\n        **kwargs: Arbitrary keyword arguments that will be set as network-level attributes.\n\n    Example:\n    ```py\n\n    import pathpyG as pp\n    import pandas as pd\n    df = pd.DataFrame({\n        'v': ['a', 'b', 'c'],\n        'w': ['b', 'c', 'a'],\n        't': [1, 2, 3]})\n    g = pp.io.df_to_temporal_graph(df)\n    print(g)\n\n    df = pd.DataFrame([\n        ['a', 'b', 'c'],\n        ['b', 'c', 'a'],\n        [1, 2, 3]\n        ])\n    g = pp.io.df_to_temporal_graph(df)\n    print(g)\n    ```\n    \"\"\"\n    # assign column names if no header is present\n    no_header = all(isinstance(x, int) for x in df.columns.values.tolist())\n\n    if no_header:\n        # interpret first two columns as source and target\n        col_names = [\"v\", \"w\", \"t\"]\n        # interpret remaining columns as edge attributes\n        for i in range(3, len(df.columns.values.tolist())):\n            col_names += [\"edge_attr_{0}\".format(i - 2)]\n        df.columns = col_names\n\n    tedges = []\n    for row in df.to_dict(orient=\"records\"):\n        _v, _w, _t = str(row.pop(\"v\")), str(row.pop(\"w\")), str(row.pop(\"t\"))\n        try:\n            t = float(_t)\n        except:\n            # if time stamp is a string, use timestamp_format to convert\n            # it to UNIX timestamp\n            x = datetime.datetime.strptime(_t, timestamp_format)\n            t = int(mktime(x.timetuple()))\n        tedges.append((_v, _w, int(t / time_rescale)))\n\n    g = TemporalGraph.from_edge_list(tedges, **kwargs)\n\n    if is_undirected:\n        return g.to_undirected()\n    else:\n        return g\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.graph_to_df","title":"<code>graph_to_df</code>","text":"<p>Returns a pandas data frame for a given graph.</p> <p>Returns a pandas dataframe data that contains all edges including edge attributes. Node and network-level attributes are not included. To facilitate the import into network analysis tools that only support integer node identifiers, node uids can be replaced by a consecutive, zero-based index.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph to export as pandas DataFrame</p> required <code>node_indices</code> <code>typing.Optional[bool]</code> <p>whether nodes should be exported as integer indices</p> <code>False</code> <p>Example: <pre><code>import pathpyG as pp\n\nn = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\ndf = pp.io.to_dataframe(n)\nprint(df)\n</code></pre></p> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def graph_to_df(graph: Graph, node_indices: Optional[bool] = False) -&gt; pd.DataFrame:\n    \"\"\"Returns a pandas data frame for a given graph.\n\n    Returns a pandas dataframe data that contains all edges including edge\n    attributes. Node and network-level attributes are not included. To\n    facilitate the import into network analysis tools that only support integer\n    node identifiers, node uids can be replaced by a consecutive, zero-based\n    index.\n\n    Args:\n        graph: The graph to export as pandas DataFrame\n        node_indices: whether nodes should be exported as integer indices\n\n    Example:\n    ```py\n    import pathpyG as pp\n\n    n = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n    df = pp.io.to_dataframe(n)\n    print(df)\n    ```\n    \"\"\"\n    df = pd.DataFrame()\n\n    for v, w in graph.edges:\n        if node_indices:\n            v = graph.mapping.to_idx(v)\n            w = graph.mapping.to_idx(w)\n        edge_frame = pd.DataFrame.from_dict({\"v\": [v], \"w\": [w]})\n        df = pd.concat([df, edge_frame], ignore_index=True, sort=False)\n\n    edge_attribute_df = pd.DataFrame.from_dict({a: graph.data[a] for a in graph.edge_attrs()})\n    df = pd.concat([df, edge_attribute_df], axis=1)\n    return df\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.read_csv_graph","title":"<code>read_csv_graph</code>","text":"<p>Reads a Graph or TemporalGraph from a csv file. To read a temporal graph, the csv file must have a header with column <code>t</code> containing time stamps of edges</p> <p>Parameters:</p> Name Type Description Default <code>loops</code> <p>whether or not to add self_loops</p> required <code>directed</code> <p>whether or not to intepret edges as directed</p> required <code>multiedges</code> <code>bool</code> <p>whether or not to add multiple edges</p> <code>False</code> <code>sep</code> <code>str</code> <p>character separating columns in the csv file</p> <code>','</code> <code>header</code> <code>bool</code> <p>whether or not the first line of the csv file is interpreted as header with column names</p> <code>True</code> <code>timestamp_format</code> <p>format of timestamps</p> required <code>time_rescale</code> <p>rescaling of timestamps</p> required Example <pre><code>import pathpyG as pp\n\ng = pp.io.read_csv('example_graph.csv')\ng = pp.io.read_csv('example_temporal_graph.csv')\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def read_csv_graph(\n    filename: str,\n    sep: str = \",\",\n    header: bool = True,\n    is_undirected: bool = False,\n    multiedges: bool = False,\n    **kwargs: Any,\n) -&gt; Graph:\n    \"\"\"Reads a Graph or TemporalGraph from a csv file. To read a temporal graph, the csv file must have\n    a header with column `t` containing time stamps of edges\n\n    Args:\n        loops:  whether or not to add self_loops\n        directed: whether or not to intepret edges as directed\n        multiedges: whether or not to add multiple edges\n        sep: character separating columns in the csv file\n        header: whether or not the first line of the csv file is interpreted as header with column names\n        timestamp_format: format of timestamps\n        time_rescale: rescaling of timestamps\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.io.read_csv('example_graph.csv')\n        g = pp.io.read_csv('example_temporal_graph.csv')\n        ```\n    \"\"\"\n    if header:\n        df = pd.read_csv(filename, header=0, sep=sep)\n    else:\n        df = pd.read_csv(filename, header=None, sep=sep)\n\n    return df_to_graph(df, is_undirected=is_undirected, multiedges=multiedges, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.read_csv_temporal_graph","title":"<code>read_csv_temporal_graph</code>","text":"<p>Reads a TemporalGraph from a csv file that minimally has three columns containin source, target and time.</p> <p>Parameters:</p> Name Type Description Default <code>sep</code> <code>str</code> <p>character separating columns in the csv file</p> <code>','</code> <code>header</code> <code>bool</code> <p>whether or not the first line of the csv file is interpreted as header with column names</p> <code>True</code> <code>directed</code> <p>whether or not to intepret edges as directed</p> required <code>timestamp_format</code> <code>str</code> <p>format of timestamps</p> <code>'%Y-%m-%d %H:%M:%S'</code> <code>time_rescale</code> <code>int</code> <p>rescaling of timestamps</p> <code>1</code> Example <pre><code>import pathpyG as pp\n\ng = pp.io.read_csv('example_temporal_graph.csv')\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def read_csv_temporal_graph(\n    filename: str,\n    sep: str = \",\",\n    header: bool = True,\n    is_undirected: bool = True,\n    timestamp_format: str = \"%Y-%m-%d %H:%M:%S\",\n    time_rescale: int = 1,\n    **kwargs: Any,\n) -&gt; TemporalGraph:\n    \"\"\"Reads a TemporalGraph from a csv file that minimally has three columns\n    containin source, target and time.\n\n    Args:\n        sep: character separating columns in the csv file\n        header: whether or not the first line of the csv file is interpreted as header with column names\n        directed: whether or not to intepret edges as directed\n        timestamp_format: format of timestamps\n        time_rescale: rescaling of timestamps\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.io.read_csv('example_temporal_graph.csv')\n        ```\n    \"\"\"\n    if header:\n        df = pd.read_csv(filename, header=0, sep=sep)\n    else:\n        df = pd.read_csv(filename, header=None, sep=sep)\n    return df_to_temporal_graph(\n        df, is_undirected=is_undirected, timestamp_format=timestamp_format, time_rescale=time_rescale, **kwargs\n    )\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.temporal_graph_to_df","title":"<code>temporal_graph_to_df</code>","text":"<p>Returns a pandas data frame for a given temporal graph.</p> <p>Returns a pandas dataframe data that contains all edges including edge attributes. Node and network-level attributes are not included. To facilitate the import into network analysis tools that only support integer node identifiers, node uids can be replaced by a consecutive, zero-based index.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>The graph to export as pandas DataFrame</p> required <code>node_indices</code> <code>typing.Optional[bool]</code> <p>whether nodes should be exported as integer indices</p> <code>False</code> <p>Example: <pre><code>import pathpyG as pp\n\nn = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ndf = pp.io.to_df(n)\nprint(df)\n</code></pre></p> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def temporal_graph_to_df(graph: TemporalGraph, node_indices: Optional[bool] = False) -&gt; pd.DataFrame:\n    \"\"\"Returns a pandas data frame for a given temporal graph.\n\n    Returns a pandas dataframe data that contains all edges including edge\n    attributes. Node and network-level attributes are not included. To\n    facilitate the import into network analysis tools that only support integer\n    node identifiers, node uids can be replaced by a consecutive, zero-based\n    index.\n\n    Args:\n        graph: The graph to export as pandas DataFrame\n        node_indices: whether nodes should be exported as integer indices\n\n    Example:\n    ```py\n    import pathpyG as pp\n\n    n = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n    df = pp.io.to_df(n)\n    print(df)\n    ```\n    \"\"\"\n    df = pd.DataFrame()\n\n    # export temporal graph\n    for v, w, t in graph.temporal_edges:\n        if node_indices:\n            v = graph.mapping.to_idx(v)\n            w = graph.mapping.to_idx(w)\n        edge_frame = pd.DataFrame.from_dict({\"v\": [v], \"w\": [w], \"t\": [t]})\n        # data = pd.DataFrame.from_dict(\n        #    {k: [v] for k, v in edge.attributes.items()})\n        # edge_frame = pd.concat([edge_frame, data], axis=1)\n        df = pd.concat([edge_frame, df], ignore_index=True, sort=False)\n    return df\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.write_csv","title":"<code>write_csv</code>","text":"<p>Stores all edges including edge attributes in a csv file.</p> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def write_csv(\n    graph: Union[Graph, TemporalGraph], path_or_buf: Any = None, node_indices: bool = False, **pdargs: Any\n) -&gt; None:\n    \"\"\"Stores all edges including edge attributes in a csv file.\"\"\"\n    if isinstance(graph, TemporalGraph):\n        frame = temporal_graph_to_df(graph=graph, node_indices=node_indices)\n    else:\n        frame = graph_to_df(graph=graph, node_indices=node_indices)\n    frame.to_csv(path_or_buf=path_or_buf, index=False, **pdargs)\n</code></pre>"},{"location":"reference/pathpyG/nn/","title":"nn","text":""},{"location":"reference/pathpyG/nn/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/nn/dbgnn/#pathpyG.nn.dbgnn.DBGNN","title":"<code>DBGNN</code>","text":"<p>               Bases: <code>torch.nn.Module</code></p> <p>Implementation of time-aware graph neural network DBGNN (Reference paper).</p> <p>Parameters:</p> Name Type Description Default <code>num_classes</code> <code>int</code> <p>number of classes</p> required <code>num_features</code> <code>list[int]</code> <p>number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]</p> required <code>hidden_dims</code> <code>list[int]</code> <p>number of hidden dimensions per each layer in the first/higher order network</p> required <code>p_dropout</code> <code>float</code> <p>drop-out probability</p> <code>0.0</code> Source code in <code>src/pathpyG/nn/dbgnn.py</code> <pre><code>class DBGNN(Module):\n    \"\"\"Implementation of time-aware graph neural network DBGNN ([Reference paper](https://openreview.net/pdf?id=Dbkqs1EhTr)).\n\n    Args:\n        num_classes: number of classes\n        num_features: number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]\n        hidden_dims: number of hidden dimensions per each layer in the first/higher order network\n        p_dropout: drop-out probability\n    \"\"\"\n\n    def __init__(self, num_classes: int, num_features: list[int], hidden_dims: list[int], p_dropout: float = 0.0):\n        super().__init__()\n\n        self.num_features = num_features\n        self.num_classes = num_classes\n        self.hidden_dims = hidden_dims\n        self.p_dropout = p_dropout\n\n        # higher-order layers\n        self.higher_order_layers = ModuleList()\n        self.higher_order_layers.append(GCNConv(self.num_features[1], self.hidden_dims[0]))\n\n        # first-order layers\n        self.first_order_layers = ModuleList()\n        self.first_order_layers.append(GCNConv(self.num_features[0], self.hidden_dims[0]))\n\n        for dim in range(1, len(self.hidden_dims) - 1):\n            # higher-order layers\n            self.higher_order_layers.append(GCNConv(self.hidden_dims[dim - 1], self.hidden_dims[dim]))\n            # first-order layers\n            self.first_order_layers.append(GCNConv(self.hidden_dims[dim - 1], self.hidden_dims[dim]))\n\n        self.bipartite_layer = BipartiteGraphOperator(self.hidden_dims[-2], self.hidden_dims[-1])\n\n        # Linear layer\n        self.lin = torch.nn.Linear(self.hidden_dims[-1], num_classes)\n\n    def forward(self, data):\n\n        x = data.x\n        x_h = data.x_h\n\n        # First-order convolutions\n        for layer in self.first_order_layers:\n            x = F.dropout(x, p=self.p_dropout, training=self.training)\n            x = F.elu(layer(x, data.edge_index, data.edge_weights))\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Second-order convolutions\n        for layer in self.higher_order_layers:\n            x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n            x_h = F.elu(layer(x_h, data.edge_index_higher_order, data.edge_weights_higher_order))\n        x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n\n        # Bipartite message passing\n        x = torch.nn.functional.elu(\n            self.bipartite_layer((x_h, x), data.bipartite_edge_index, N=data.num_ho_nodes, M=data.num_nodes)\n        )\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Linear layer\n        x = self.lin(x)\n\n        return x\n</code></pre>"},{"location":"reference/pathpyG/processes/","title":"processes","text":"<p>Module for pathpy processes.</p>"},{"location":"reference/pathpyG/processes/process/","title":"process","text":"<p>Base classes for simulation of dynamical processes</p>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess","title":"<code>BaseProcess</code>","text":"<p>Abstract base class for all implementations of discrete-time dynamical processes.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>class BaseProcess:\n    \"\"\"Abstract base class for all implementations of discrete-time dynamical processes.\"\"\"\n\n    def __init__(self, network: Graph):\n        \"\"\"initialize process.\"\"\"\n        self._network = network\n        self.init(self.random_seed())\n\n    @property\n    def network(self) -&gt; Graph:\n        return self._network\n\n    @abc.abstractmethod\n    def init(self, seed: Any) -&gt; None:\n        \"\"\"Abstract method to initialize the process with a given seed state.\"\"\"\n\n    @abc.abstractmethod\n    def random_seed(self) -&gt; Any:\n        \"\"\"Abstract method to generate a random seed state for the process.\"\"\"\n\n    @abc.abstractmethod\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"Abstract method to simulate a single step of the process. Returns\n        an iterable of node uids whose state has been changed in this step.\"\"\"\n\n    @abc.abstractproperty\n    def time(self) -&gt; int:\n        \"\"\"Abstract property returning the current time.\"\"\"\n\n    @abc.abstractmethod\n    def state_to_color(self, Any) -&gt; Union[Tuple[int, int, int], str]:\n        \"\"\"Abstract method mapping node states to RGB colors or color names.\"\"\"\n\n    @abc.abstractmethod\n    def node_state(self, v: str) -&gt; Any:\n        \"\"\"Abstract method returning the current state of a given node.\"\"\"\n\n    def simulation_run(self, steps: int, seed: Optional[Any] = None) -&gt; Tuple[int, Set[str]]:\n        \"\"\"Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.\"\"\"\n        if seed == None:\n            self.init(self.random_seed())\n        else:\n            self.init(seed)\n        for _ in range(steps):\n            ret = self.step()\n            if ret is not None:\n                yield self.time, ret\n            else:\n                return None\n\n    def run_experiment(self, steps: int, runs: Optional[Union[int, Iterable[Any]]] = 1) -&gt; DataFrame:\n        \"\"\"Perform one or more simulation runs of the process with a given number of steps.\"\"\"\n\n        # Generate initializations for different runs\n        seeds: List = list()\n        if type(runs) == int:\n            for s in range(runs):\n                seeds.append(self.random_seed())\n        else:\n            for s in runs:\n                seeds.append(s)\n\n        results = list()\n        run_id: int = 0\n        for seed in tqdm(seeds):\n\n            # initialize seed state and record initial state\n            self.init(seed)\n            for v in self.network.nodes:\n                results.append(\n                    {\"run_id\": run_id, \"seed\": seed, \"time\": self.time, \"node\": v, \"state\": self.node_state(v)}\n                )\n\n            # simulate the given number of steps\n            for time, updated_nodes in self.simulation_run(steps, seed):\n                # print(updated_nodes)\n                # record the new state of each changed node\n                for v in updated_nodes:\n                    results.append(\n                        {\"run_id\": run_id, \"seed\": seed, \"time\": time, \"node\": v, \"state\": self.node_state(v)}\n                    )\n            run_id += 1\n\n        return DataFrame.from_dict(results)\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.__init__","title":"<code>__init__</code>","text":"<p>initialize process.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def __init__(self, network: Graph):\n    \"\"\"initialize process.\"\"\"\n    self._network = network\n    self.init(self.random_seed())\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.init","title":"<code>init</code>  <code>abstractmethod</code>","text":"<p>Abstract method to initialize the process with a given seed state.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef init(self, seed: Any) -&gt; None:\n    \"\"\"Abstract method to initialize the process with a given seed state.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.node_state","title":"<code>node_state</code>  <code>abstractmethod</code>","text":"<p>Abstract method returning the current state of a given node.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef node_state(self, v: str) -&gt; Any:\n    \"\"\"Abstract method returning the current state of a given node.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.random_seed","title":"<code>random_seed</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate a random seed state for the process.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef random_seed(self) -&gt; Any:\n    \"\"\"Abstract method to generate a random seed state for the process.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.run_experiment","title":"<code>run_experiment</code>","text":"<p>Perform one or more simulation runs of the process with a given number of steps.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def run_experiment(self, steps: int, runs: Optional[Union[int, Iterable[Any]]] = 1) -&gt; DataFrame:\n    \"\"\"Perform one or more simulation runs of the process with a given number of steps.\"\"\"\n\n    # Generate initializations for different runs\n    seeds: List = list()\n    if type(runs) == int:\n        for s in range(runs):\n            seeds.append(self.random_seed())\n    else:\n        for s in runs:\n            seeds.append(s)\n\n    results = list()\n    run_id: int = 0\n    for seed in tqdm(seeds):\n\n        # initialize seed state and record initial state\n        self.init(seed)\n        for v in self.network.nodes:\n            results.append(\n                {\"run_id\": run_id, \"seed\": seed, \"time\": self.time, \"node\": v, \"state\": self.node_state(v)}\n            )\n\n        # simulate the given number of steps\n        for time, updated_nodes in self.simulation_run(steps, seed):\n            # print(updated_nodes)\n            # record the new state of each changed node\n            for v in updated_nodes:\n                results.append(\n                    {\"run_id\": run_id, \"seed\": seed, \"time\": time, \"node\": v, \"state\": self.node_state(v)}\n                )\n        run_id += 1\n\n    return DataFrame.from_dict(results)\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.simulation_run","title":"<code>simulation_run</code>","text":"<p>Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def simulation_run(self, steps: int, seed: Optional[Any] = None) -&gt; Tuple[int, Set[str]]:\n    \"\"\"Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.\"\"\"\n    if seed == None:\n        self.init(self.random_seed())\n    else:\n        self.init(seed)\n    for _ in range(steps):\n        ret = self.step()\n        if ret is not None:\n            yield self.time, ret\n        else:\n            return None\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.state_to_color","title":"<code>state_to_color</code>  <code>abstractmethod</code>","text":"<p>Abstract method mapping node states to RGB colors or color names.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef state_to_color(self, Any) -&gt; Union[Tuple[int, int, int], str]:\n    \"\"\"Abstract method mapping node states to RGB colors or color names.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.step","title":"<code>step</code>  <code>abstractmethod</code>","text":"<p>Abstract method to simulate a single step of the process. Returns an iterable of node uids whose state has been changed in this step.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef step(self) -&gt; Iterable[str]:\n    \"\"\"Abstract method to simulate a single step of the process. Returns\n    an iterable of node uids whose state has been changed in this step.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.time","title":"<code>time</code>","text":"<p>Abstract property returning the current time.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractproperty\ndef time(self) -&gt; int:\n    \"\"\"Abstract property returning the current time.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/","title":"random_walk","text":"<p>Classes to simlate random walks on static, temporal, and higher-order networks.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk","title":"<code>HigherOrderRandomWalk</code>","text":"<p>               Bases: <code>pathpyG.processes.random_walk.RandomWalk</code></p> <p>Class that implements a biased random walk process in a higher-order network.</p> <p>Instances of this class can be used to simulate random walk processes in higher-order networks for arbitrary orders k. The random walk process can include weighted edges as well as a restart probability, i.e. a per-step probability to teleport to a randomly chosen higher-order node.</p> <p>Different from the class RandomWalk, instances of class HigherOrderRandomWalk automatically project states to the corresponding first-order network, i.e. paths and visualisations are given in terms of the nodes in the first-order network, while the dynamics of the random walk is governed by the underlying higher-order network.</p> <p>The implementation follows the general concept to simulate discrete-time (stochastic) processes as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface to iterate through the steps of a single random walk process, or use the <code>run_experiment</code> function to simulate multiple runs of a random walk with different start nodes (i.e. seeds).</p> <p>The <code>run_experiment</code> function returns a pandas DataFrame object that contains all node state changes during the process' evolution. This data frame can be converted to Path and PathCollection objects and it can be visualized using the plot function.</p> <p>Examples:</p> <p>Generate and visualize a single random walk with 10 steps on a higher-order network</p> <pre><code>&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n&gt;&gt;&gt; paths = pp.WalkData(g3.mapping)\n&gt;&gt;&gt; paths.add_walk_seq(['a','b','c'],freq=1)\n&gt;&gt;&gt; paths.add_walk_seq(['b','c','a'],freq=1)\n&gt;&gt;&gt; paths.add_walk_seq(['b','c','d'],freq=0.2)\n&gt;&gt;&gt; paths.add_walk_seq(['c','a','b'],freq=1)\n&gt;&gt;&gt; paths.add_walk_seq(['c','d','a'],freq=0.2)\n&gt;&gt;&gt; paths.add_walk_seq(['d','a','b'],freq=1)\n&gt;&gt;&gt; g_ho = pp.HigherOrderGraph(paths, order =2)\n</code></pre> <pre><code>&gt;&gt;&gt; rw = pp.processes.HigherOrderRandomWalk(g_ho, weight=True)\n&gt;&gt;&gt; data = rw.run_experiment(steps=10, runs=[('b','c')])\n&gt;&gt;&gt; rw.plot(data)\n[interactive visualization in first-order network]\n</code></pre> <p>Use <code>plot</code> function of base class to visualize random walk in second-order network</p> <pre><code>&gt;&gt;&gt; pp.processes.RandomWalk.plot(rw, data)\n[interactive visualization in second-order network]\n</code></pre> <p>Generate a single random walk with 10 steps starting from node 'b-c' and return a first-order path</p> <pre><code>&gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['b-c']))\n&gt;&gt;&gt; pprint([v.uid for v in p.nodes ])\n[ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n</code></pre> <p>Use <code>get_path</code> function of base class to return path with second-order nodes</p> <pre><code>&gt;&gt;&gt; p = pp.processes.RandomWalk.get_path(rw2, data)\n&gt;&gt;&gt; print([ v.uid for v in p.nodes ])\n</code></pre> <p>Generate one random walk with 10 steps starting from each node and return a WalkData instance with first-order paths</p> <pre><code>&gt;&gt;&gt; paths = rw.get_paths(rw.run_experiment(steps=10, runs=g_ho.nodes))\n&gt;&gt;&gt; pprint([v.uid for v in p.nodes ])\n[ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n[ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n[ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n[ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n</code></pre> <p>Simulate a random walk using the iterator interface, which provides full access to the state after each simulation step</p> <pre><code>&gt;&gt;&gt; for time, _ in rw2.simulation_run(steps=50, seed='b-c'):\n&gt;&gt;&gt;     print('Current node = {0}'.format(rw2.first_order_node(rw2.current_node)))\n&gt;&gt;&gt;     print(rw2._first_order_visitation_frequencies)\nCurrent node = b\n[0.33333333 0.33333333 0.33333333 0.        ]\nCurrent node = c\n[0.32142857 0.32142857 0.35714286 0.        ]\nCurrent node = a\n[0.34482759 0.31034483 0.34482759 0.        ]\nCurrent node = b\n[0.33333333 0.33333333 0.33333333 0.        ]\nCurrent node = c\n[0.32258065 0.32258065 0.35483871 0.        ]\nCurrent node = a\n</code></pre> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>class HigherOrderRandomWalk(RandomWalk):\n    \"\"\"Class that implements a biased random walk process in a higher-order network.\n\n    Instances of this class can be used to simulate random walk processes in higher-order networks for\n    arbitrary orders k. The random walk process can include weighted edges as well as a\n    restart probability, i.e. a per-step probability to teleport to a\n    randomly chosen higher-order node.\n\n    Different from the class RandomWalk, instances of class HigherOrderRandomWalk automatically project states to the corresponding first-order network, i.e. paths and visualisations are given\n    in terms of the nodes in the first-order network, while the dynamics of the random walk is governed by the underlying higher-order network.\n\n    The implementation follows the general concept to simulate discrete-time (stochastic) processes\n    as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface\n    to iterate through the steps of a single random walk process, or use the `run_experiment` function\n    to simulate multiple runs of a random walk with different start nodes (i.e. seeds).\n\n    The `run_experiment` function returns a pandas DataFrame object that contains all node state changes\n    during the process' evolution. This data frame can be converted to Path and PathCollection objects\n    and it can be visualized using the plot function.\n\n    Examples:\n        Generate and visualize a single random walk with 10 steps on a higher-order network\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n        &gt;&gt;&gt; paths = pp.WalkData(g3.mapping)\n        &gt;&gt;&gt; paths.add_walk_seq(['a','b','c'],freq=1)\n        &gt;&gt;&gt; paths.add_walk_seq(['b','c','a'],freq=1)\n        &gt;&gt;&gt; paths.add_walk_seq(['b','c','d'],freq=0.2)\n        &gt;&gt;&gt; paths.add_walk_seq(['c','a','b'],freq=1)\n        &gt;&gt;&gt; paths.add_walk_seq(['c','d','a'],freq=0.2)\n        &gt;&gt;&gt; paths.add_walk_seq(['d','a','b'],freq=1)\n        &gt;&gt;&gt; g_ho = pp.HigherOrderGraph(paths, order =2)\n\n        &gt;&gt;&gt; rw = pp.processes.HigherOrderRandomWalk(g_ho, weight=True)\n        &gt;&gt;&gt; data = rw.run_experiment(steps=10, runs=[('b','c')])\n        &gt;&gt;&gt; rw.plot(data)\n        [interactive visualization in first-order network]\n\n        Use `plot` function of base class to visualize random walk in second-order network\n\n        &gt;&gt;&gt; pp.processes.RandomWalk.plot(rw, data)\n        [interactive visualization in second-order network]\n\n        Generate a single random walk with 10 steps starting from node 'b-c' and\n        return a first-order path\n\n        &gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['b-c']))\n        &gt;&gt;&gt; pprint([v.uid for v in p.nodes ])\n        [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n\n        Use `get_path` function of base class to return path with second-order nodes\n\n        &gt;&gt;&gt; p = pp.processes.RandomWalk.get_path(rw2, data)\n        &gt;&gt;&gt; print([ v.uid for v in p.nodes ])\n\n        Generate one random walk with 10 steps starting from each node and\n        return a WalkData instance with first-order paths\n\n        &gt;&gt;&gt; paths = rw.get_paths(rw.run_experiment(steps=10, runs=g_ho.nodes))\n        &gt;&gt;&gt; pprint([v.uid for v in p.nodes ])\n        [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n        [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n        [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n        [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n\n        Simulate a random walk using the iterator interface, which provides full access\n        to the state after each simulation step\n\n        &gt;&gt;&gt; for time, _ in rw2.simulation_run(steps=50, seed='b-c'):\n        &gt;&gt;&gt;     print('Current node = {0}'.format(rw2.first_order_node(rw2.current_node)))\n        &gt;&gt;&gt;     print(rw2._first_order_visitation_frequencies)\n        Current node = b\n        [0.33333333 0.33333333 0.33333333 0.        ]\n        Current node = c\n        [0.32142857 0.32142857 0.35714286 0.        ]\n        Current node = a\n        [0.34482759 0.31034483 0.34482759 0.        ]\n        Current node = b\n        [0.33333333 0.33333333 0.33333333 0.        ]\n        Current node = c\n        [0.32258065 0.32258065 0.35483871 0.        ]\n        Current node = a\n    \"\"\"\n\n    def __init__(\n        self, higher_order_network: Graph, first_order_network, weight: Optional[Weight] = None, restart_prob: float = 0\n    ) -&gt; None:\n        \"\"\"Creates a biased random walk process in a network.\n\n        Args:\n            higher_order_network: The higher-order network instance on which to perform the random walk process.\n            first_order_network: The first-order network instance to be used for mapping the process to first-order nodes\n            weight: If specified, the given numerical edge attribute will be used to bias\n                the random walk transition probabilities.\n            restart_probability: The per-step probability that a random walker restarts in a random (higher-order) node\n        \"\"\"\n        self._first_order_network = first_order_network\n        RandomWalk.__init__(self, higher_order_network, weight, restart_prob)\n\n    def init(self, seed) -&gt; None:\n\n        # set number of times each first-order node has been visited\n        self._first_order_visitations = np.ravel(np.zeros(shape=(1, self._first_order_network.n)))\n        self._first_order_visitations[self._first_order_network.mapping.to_idx(seed[-1])] = 1\n        RandomWalk.init(self, seed)\n\n    @property\n    def first_order_visitation_frequencies(self) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n        the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n        \"\"\"\n        return np.nan_to_num(self._first_order_visitations / (self._t + 1))\n\n    def first_order_stationary_state(self, **kwargs) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n        the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n        \"\"\"\n        first_order_stationary_state = np.ravel(np.zeros(shape=(1, self._first_order_network.n)))\n        higher_order_stationary_dist = RandomWalk.stationary_state(self, **kwargs)\n        for v in self._network.nodes:\n            # newly visited node in first_order network\n            v1 = v.relations[-1]\n            first_order_stationary_state[self._first_order_network.mapping.to_idx[v1]] += higher_order_stationary_dist[\n                self._network.mapping.to_idx[v]\n            ]\n        return first_order_stationary_state\n\n    @property\n    def first_order_total_variation_distance(self) -&gt; float:\n        \"\"\"Returns the total variation distance between stationary\n        visitation probabilities and the current visitation frequencies, projected\n        to nodes in the first_order_network.\n\n        Computes the total variation distance between the current (first-order) node visitation\n        probabilities and the (first-order) stationary node visitation probabilities. This quantity converges to zero for HigherOrderRandomWalk.time -&gt; np.infty and its magnitude indicates the\n        current relaxation of the higher-order random walk process.\n        \"\"\"\n        return self.TVD(self.first_order_stationary_state(), self.first_order_visitation_frequencies)\n\n    def first_order_node(self, higher_order_node: tuple) -&gt; str:\n        \"\"\"\n        Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.\n\n        Args:\n            higher_order_node: Tuple that represents the higher-order node\n\n        Returns:\n            String of the corresponding first-order node\n        \"\"\"\n        return higher_order_node[-1]\n\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"\n        Function that will be called for each step of the random walk. This function\n        returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.\n\n        Use the `first_order_node` function to map those nodes to nodes in the first-order network\n        \"\"\"\n        (current_node, previous_node) = RandomWalk.step(self)\n\n        self._first_order_visitations[self._first_order_network.mapping.to_idx(current_node[-1])] += 1\n\n        return (current_node, previous_node)\n\n    def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = 0) -&gt; PathData:\n        \"\"\"Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.\n\n        Args:\n            data: Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n            run_uid: Uid of the random walk simulations to be returned as WalkData (default: 0).\n\n        Returns:\n            WalkData object containing the sequences of nodes traversed by the random walks\n        \"\"\"\n        # list of traversed nodes starting with seed node\n\n        if not run_ids:  # generate paths for all run_ids in the data frame\n            runs = data[\"run_id\"].unique()\n        else:\n            runs = run_ids\n\n        paths = PathData(mapping=self._first_order_network.mapping)\n        for run in runs:\n            walk_steps = list(data.loc[(data[\"run_id\"] == run) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n            # for higher-order random walk, seed node is a higher-order node\n            # consisting of one or more edges\n            seed = walk_steps[0]\n            walk = [v for v in seed]\n\n            # map higher-order nodes to first-order nodes\n            for i in range(1, len(walk_steps)):\n                walk.append(walk_steps[i][-1])\n            paths.append_walk(walk)\n        return paths\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_total_variation_distance","title":"<code>first_order_total_variation_distance: float</code>  <code>property</code>","text":"<p>Returns the total variation distance between stationary visitation probabilities and the current visitation frequencies, projected to nodes in the first_order_network.</p> <p>Computes the total variation distance between the current (first-order) node visitation probabilities and the (first-order) stationary node visitation probabilities. This quantity converges to zero for HigherOrderRandomWalk.time -&gt; np.infty and its magnitude indicates the current relaxation of the higher-order random walk process.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_visitation_frequencies","title":"<code>first_order_visitation_frequencies: np.array</code>  <code>property</code>","text":"<p>Returns current normalized visitation frequencies of first-order nodes based on the history of the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.__init__","title":"<code>__init__</code>","text":"<p>Creates a biased random walk process in a network.</p> <p>Parameters:</p> Name Type Description Default <code>higher_order_network</code> <code>pathpyG.Graph</code> <p>The higher-order network instance on which to perform the random walk process.</p> required <code>first_order_network</code> <p>The first-order network instance to be used for mapping the process to first-order nodes</p> required <code>weight</code> <code>typing.Optional[pathpyG.processes.random_walk.Weight]</code> <p>If specified, the given numerical edge attribute will be used to bias the random walk transition probabilities.</p> <code>None</code> <code>restart_probability</code> <p>The per-step probability that a random walker restarts in a random (higher-order) node</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def __init__(\n    self, higher_order_network: Graph, first_order_network, weight: Optional[Weight] = None, restart_prob: float = 0\n) -&gt; None:\n    \"\"\"Creates a biased random walk process in a network.\n\n    Args:\n        higher_order_network: The higher-order network instance on which to perform the random walk process.\n        first_order_network: The first-order network instance to be used for mapping the process to first-order nodes\n        weight: If specified, the given numerical edge attribute will be used to bias\n            the random walk transition probabilities.\n        restart_probability: The per-step probability that a random walker restarts in a random (higher-order) node\n    \"\"\"\n    self._first_order_network = first_order_network\n    RandomWalk.__init__(self, higher_order_network, weight, restart_prob)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_node","title":"<code>first_order_node</code>","text":"<p>Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.</p> <p>Parameters:</p> Name Type Description Default <code>higher_order_node</code> <code>tuple</code> <p>Tuple that represents the higher-order node</p> required <p>Returns:</p> Type Description <code>str</code> <p>String of the corresponding first-order node</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def first_order_node(self, higher_order_node: tuple) -&gt; str:\n    \"\"\"\n    Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.\n\n    Args:\n        higher_order_node: Tuple that represents the higher-order node\n\n    Returns:\n        String of the corresponding first-order node\n    \"\"\"\n    return higher_order_node[-1]\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_stationary_state","title":"<code>first_order_stationary_state</code>","text":"<p>Returns current normalized visitation frequencies of first-order nodes based on the history of the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def first_order_stationary_state(self, **kwargs) -&gt; np.array:\n    \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n    the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n    \"\"\"\n    first_order_stationary_state = np.ravel(np.zeros(shape=(1, self._first_order_network.n)))\n    higher_order_stationary_dist = RandomWalk.stationary_state(self, **kwargs)\n    for v in self._network.nodes:\n        # newly visited node in first_order network\n        v1 = v.relations[-1]\n        first_order_stationary_state[self._first_order_network.mapping.to_idx[v1]] += higher_order_stationary_dist[\n            self._network.mapping.to_idx[v]\n        ]\n    return first_order_stationary_state\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.get_paths","title":"<code>get_paths</code>","text":"<p>Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pandas.DataFrame</code> <p>Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of <code>run_experiment</code></p> required <code>run_uid</code> <p>Uid of the random walk simulations to be returned as WalkData (default: 0).</p> required <p>Returns:</p> Type Description <code>pathpyG.PathData</code> <p>WalkData object containing the sequences of nodes traversed by the random walks</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = 0) -&gt; PathData:\n    \"\"\"Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.\n\n    Args:\n        data: Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n        run_uid: Uid of the random walk simulations to be returned as WalkData (default: 0).\n\n    Returns:\n        WalkData object containing the sequences of nodes traversed by the random walks\n    \"\"\"\n    # list of traversed nodes starting with seed node\n\n    if not run_ids:  # generate paths for all run_ids in the data frame\n        runs = data[\"run_id\"].unique()\n    else:\n        runs = run_ids\n\n    paths = PathData(mapping=self._first_order_network.mapping)\n    for run in runs:\n        walk_steps = list(data.loc[(data[\"run_id\"] == run) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n        # for higher-order random walk, seed node is a higher-order node\n        # consisting of one or more edges\n        seed = walk_steps[0]\n        walk = [v for v in seed]\n\n        # map higher-order nodes to first-order nodes\n        for i in range(1, len(walk_steps)):\n            walk.append(walk_steps[i][-1])\n        paths.append_walk(walk)\n    return paths\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.step","title":"<code>step</code>","text":"<p>Function that will be called for each step of the random walk. This function returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.</p> <p>Use the <code>first_order_node</code> function to map those nodes to nodes in the first-order network</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def step(self) -&gt; Iterable[str]:\n    \"\"\"\n    Function that will be called for each step of the random walk. This function\n    returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.\n\n    Use the `first_order_node` function to map those nodes to nodes in the first-order network\n    \"\"\"\n    (current_node, previous_node) = RandomWalk.step(self)\n\n    self._first_order_visitations[self._first_order_network.mapping.to_idx(current_node[-1])] += 1\n\n    return (current_node, previous_node)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk","title":"<code>RandomWalk</code>","text":"<p>               Bases: <code>pathpyG.processes.process.BaseProcess</code></p> <p>Class that implements a biased random walk process in a network.</p> <p>Instances of this class can be used to simulate random walk processes in any instance of the class Graph. The random walk process can include weighted edges as well as a restart probability, i.e. a per-step probability to teleport to a randomly chosen node.</p> <p>Since any instance of HigherOrderGraph is also an instance of Graph, this class can be directly be applied to simulate random walks in higher-order networks. However, the state space of such a random walk is given by the higher-order nodes. If you wish to simulate a higher-order random walk while projecting states to the corresponding first-order network, you should use the class HigherOrderRandomWalk instead.</p> <p>The implementation follows the general concept to simulate discrete-time (stochastic) processes as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface to iterate through the steps of a single random walk process, or use the <code>run_experiment</code> function to simulate multiple runs of a random walk with different start nodes (i.e. seeds).</p> <p>The <code>run_experiment</code> function returns a pandas DataFrame object that contains all node state changes during the process' evolution. This data frame can be converted to Path and PathCollection objects and it can be visualized using the plot function.</p> <p>Examples:</p> <p>Generate and visualize a single biased random walk with 10 steps on a network</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n&gt;&gt;&gt; rw = pp.processes.RandomWalk(g, weight='edge_weight')\n&gt;&gt;&gt; data = rw.run_experiment(steps=10, seed='a')\n&gt;&gt;&gt; rw.plot(data)\n[interactive visualization]\n</code></pre> <p>Generate a single random walk with 10 steps starting from node 'a' and return a WalkData instance</p> <pre><code>&gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['a']))\n</code></pre> <p>Generate one random walk with 10 steps starting from each node and return a PathCollection instance</p> <pre><code>&gt;&gt;&gt; pc = rw.get_paths(rw.run_experiment(steps=10, runs=g.nodes))\n[ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n[ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n[ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n[ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n</code></pre> <p>Simulate a random walk using the iterator interface, which provides full access to the state after each simulation step</p> <pre><code>&gt;&gt;&gt; for time, _ in rw.simulation_run(steps=5, seed='a'):\n&gt;&gt;&gt;     print('Current node = {0}'.format(rw.current_node))\n&gt;&gt;&gt;     print(rw.visitation_frequencies)\nCurrent node = b\n[0.5 0.5 0.  0. ]\nCurrent node = c\n[0.33333333 0.33333333 0.33333333 0. ]\nCurrent node = d\n[0.25 0.25 0.25 0.25]\nCurrent node = a\n[0.4 0.2 0.2 0.2]\nCurrent node = b\n[0.33333333 0.33333333 0.16666667 0.16666667]\nCurrent node = a\n[0.42857143 0.28571429 0.14285714 0.14285714]\nCurrent node = c\n[0.375 0.25  0.25  0.125]\nCurrent node = a\n[0.44444444 0.22222222 0.22222222 0.11111111]\nCurrent node = b\n[0.4 0.3 0.2 0.1]\nCurrent node = a\n[0.45454545 0.27272727 0.18181818 0.09090909]\n</code></pre> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>class RandomWalk(BaseProcess):\n    \"\"\"Class that implements a biased random walk process in a network.\n\n    Instances of this class can be used to simulate random walk processes in any instance\n    of the class Graph. The random walk process can include weighted edges as well as a\n    restart probability, i.e. a per-step probability to teleport to a\n    randomly chosen node.\n\n    Since any instance of HigherOrderGraph is also an instance of Graph, this class\n    can be directly be applied to simulate random walks in higher-order networks. However,\n    the state space of such a random walk is given by the higher-order nodes. If you wish to\n    simulate a higher-order random walk while projecting states to the corresponding first-order\n    network, you should use the class HigherOrderRandomWalk instead.\n\n    The implementation follows the general concept to simulate discrete-time (stochastic) processes\n    as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface\n    to iterate through the steps of a single random walk process, or use the `run_experiment` function\n    to simulate multiple runs of a random walk with different start nodes (i.e. seeds).\n\n    The `run_experiment` function returns a pandas DataFrame object that contains all node state changes\n    during the process' evolution. This data frame can be converted to Path and PathCollection objects\n    and it can be visualized using the plot function.\n\n    Examples:\n        Generate and visualize a single biased random walk with 10 steps on a network\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n        &gt;&gt;&gt; rw = pp.processes.RandomWalk(g, weight='edge_weight')\n        &gt;&gt;&gt; data = rw.run_experiment(steps=10, seed='a')\n        &gt;&gt;&gt; rw.plot(data)\n        [interactive visualization]\n\n        Generate a single random walk with 10 steps starting from node 'a' and\n        return a WalkData instance\n\n        &gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['a']))\n\n        Generate one random walk with 10 steps starting from each node and\n        return a PathCollection instance\n\n        &gt;&gt;&gt; pc = rw.get_paths(rw.run_experiment(steps=10, runs=g.nodes))\n        [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n        [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n        [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n        [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n\n        Simulate a random walk using the iterator interface, which provides full access\n        to the state after each simulation step\n\n        &gt;&gt;&gt; for time, _ in rw.simulation_run(steps=5, seed='a'):\n        &gt;&gt;&gt;     print('Current node = {0}'.format(rw.current_node))\n        &gt;&gt;&gt;     print(rw.visitation_frequencies)\n        Current node = b\n        [0.5 0.5 0.  0. ]\n        Current node = c\n        [0.33333333 0.33333333 0.33333333 0. ]\n        Current node = d\n        [0.25 0.25 0.25 0.25]\n        Current node = a\n        [0.4 0.2 0.2 0.2]\n        Current node = b\n        [0.33333333 0.33333333 0.16666667 0.16666667]\n        Current node = a\n        [0.42857143 0.28571429 0.14285714 0.14285714]\n        Current node = c\n        [0.375 0.25  0.25  0.125]\n        Current node = a\n        [0.44444444 0.22222222 0.22222222 0.11111111]\n        Current node = b\n        [0.4 0.3 0.2 0.1]\n        Current node = a\n        [0.45454545 0.27272727 0.18181818 0.09090909]\n    \"\"\"\n\n    def __init__(self, network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n        \"\"\"Creates a biased random walk process in a network.\n\n        Args:\n            network: The network instance on which to perform the random walk process. Can also\n                be an instance of HigherOrderNetwork.\n            weight: If specified, the given numerical edge attribute will be used to bias\n                the random walk transition probabilities.\n            restart_probability: The per-step probability that a random walker restarts in a random node\n        \"\"\"\n\n        # transition matrix of random walk\n        self._transition_matrix = RandomWalk.compute_transition_matrix(network, weight, restart_prob)\n\n        # initialize Vose Alias Samplers\n\n        self.samplers = {\n            v: VoseAliasSampling(\n                np.nan_to_num(np.ravel(self._transition_matrix[network.mapping.to_idx(v), :].todense()))\n            )\n            for v in network.nodes\n        }\n\n        # compute eigenvectors and eigenvalues of transition matrix\n        if network.n &gt; 2:\n            _, eigenvectors = spl.eigs(self._transition_matrix.transpose(), k=1, which=\"LM\")\n            pi = eigenvectors.reshape(\n                eigenvectors.size,\n            )\n        else:\n            eigenvals, eigenvectors = spla.eig(self._transition_matrix.transpose().toarray())\n            x = np.argsort(-eigenvals)\n            pi = eigenvectors[x][:, 0]\n\n        # calculate stationary visitation probabilities\n        self._stationary_probabilities = np.real(pi / np.sum(pi))\n\n        self._network = network\n        self.init(self.random_seed())\n\n    def init(self, seed: str) -&gt; None:\n        \"\"\"\n        Initializes the random walk state with a given seed/source node\n\n        Args:\n            seed: Id of node in which the random walk will start\n        \"\"\"\n        # reset currently visited node (or higher-order node)\n        self._current_node = seed\n\n        # set time\n        self._t = 0\n\n        # set number of times each node has been visited\n        self._visitations = np.ravel(np.zeros(shape=(1, self._network.n)))\n        self._visitations[self._network.mapping.to_idx(seed)] = 1\n\n    def random_seed(self) -&gt; Any:\n        \"\"\"\n        Returns a random node from the network, chosen uniformly at random\n        \"\"\"\n        x = np.random.choice(range(self._network.n))\n        return self._network.mapping.to_id(x)\n\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"\n        Function that will be called for each step of the random walk. This function\n        returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.\n        \"\"\"\n\n        # determine next node\n        next_node = self.network.mapping.to_id(self.samplers[self._current_node].sample())\n        # TODO: assertion will not hold if restart_prob &gt; 0\n        # assert (self._current_node, next_node) in self._network.edges, 'Assertion Error: {0} not in edge list'.format(\n        #     (self._current_node, next_node))\n\n        previous_node = self._current_node\n        self._current_node = next_node\n\n        # increment visitations and current time\n        self._visitations[self._network.mapping.to_idx(self._current_node)] += 1\n        self._t += 1\n\n        # return tuple of changed nodes, where the first node is the currently visited node\n        return (self._current_node, previous_node)\n\n    def node_state(self, v) -&gt; bool:\n        \"\"\"\n        Returns a boolean variable indicating whether the walker is currently\n        visiting (first-order) node v\n        \"\"\"\n        if v in self._network.nodes:\n            return v == self._current_node\n        # TODO: Error here!\n        elif type(self._network) == HigherOrderGraph:\n            return v == self._network.mapping.to_id(self._current_node)[-1]\n        else:\n            raise NotImplementedError(\"Random walk not implemented for network of type {0}\".format(type(self._network)))\n\n    @property\n    def time(self) -&gt; int:\n        \"\"\"\n        The current time of the random walk process, i.e. the number of steps taken since the start node.\n        \"\"\"\n        return self._t\n\n    def state_to_color(self, state: bool) -&gt; str:\n        \"\"\"\n        Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.\n\n        Args:\n            state: Current visitation state\n        \"\"\"\n        if state:\n            return \"red\"\n        else:\n            return \"blue\"\n\n    @staticmethod\n    def compute_transition_matrix(\n        network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0\n    ) -&gt; sp.sparse.csr_matrix:\n        \"\"\"Returns the transition matrix of a (biased) random walk in the given network.\n\n        Returns a transition matrix that describes a random walk process in the\n        given network.\n\n        Args:\n            network: The network for which the transition matrix will be created.\n            weight: If specified, the numerical edge attribute that shall be used in the biased\n                transition probabilities of the random walk.\n\n        \"\"\"\n        if weight is None or weight is False:\n            A = network.sparse_adj_matrix().todense()\n        elif weight is True:\n            A = network.sparse_adj_matrix(edge_attr=\"edge_weight\").todense()\n        else:\n            A = network.sparse_adj_matrix(edge_attr=weight).todense()\n        D = A.sum(axis=1)\n        n = network.n\n        T = sp.sparse.lil_matrix((n, n))\n        zero_deg = 0\n        for i in range(n):\n            if D[i] == 0:\n                zero_deg += 1\n            for j in range(n):\n                if D[i] &gt; 0:\n                    T[i, j] = restart_prob * (1.0 / n) + (1 - restart_prob) * A[i, j] / D[i]\n                else:\n                    if restart_prob &gt; 0:\n                        T[i, j] = 1.0 / n\n                    else:\n                        T[i, j] = 0.0\n        # if zero_deg &gt; 0:\n        #     LOG.warning(\n        #         'Network contains {0} nodes with zero out-degree'.format(zero_deg))\n        return T.tocsr()\n\n    @property\n    def transition_matrix(self) -&gt; sp.sparse.csr_matrix:\n        \"\"\"Returns the transition matrix of the random walk\"\"\"\n        return self._transition_matrix\n\n    def transition_probabilities(self, node: str) -&gt; np.array:\n        \"\"\"Returns a vector that contains transition probabilities.\n\n        Returns a vector that contains transition probabilities from a given\n        node to all other nodes in the network.\n        \"\"\"\n        return np.nan_to_num(np.ravel(self._transition_matrix[self._network.mapping.to_idx(node), :].todense()))\n\n    def visitation_probabilities(self, t, seed: str) -&gt; np.ndarray:\n        \"\"\"Calculates visitation probabilities of nodes after t steps for a given start node\n\n        Initially, all visitation probabilities are zero except for the start node.\n        \"\"\"\n        assert seed in self._network.nodes\n\n        initial_dist = np.zeros(self._network.n)\n        initial_dist[self._network.mapping.to_idx(seed)] = 1.0\n        return np.dot(initial_dist, (self._transition_matrix**t).todense())\n\n    def transition_matrix_pd(self) -&gt; DataFrame:\n        \"\"\"\n        Returns the transition matrix as pandas DataFrame with proper row/column labels.\n        \"\"\"\n        return DataFrame(\n            self.transition_matrix.todense(),\n            columns=[v for v in self._network.nodes],\n            index=[v for v in self._network.nodes],\n        )\n\n    @property\n    def current_node(self) -&gt; str:\n        return self._current_node\n\n    def get_path(self, data: DataFrame, run_id: Optional[int] = 0, first_order: Optional[bool] = True) -&gt; PathData:\n        \"\"\"Returns a path that represents the sequence of (first-order) nodes traversed\n        by a single random walk.\n\n        Args:\n            data: Pandas `DataFrame` containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n            run_uid: Uid of the random walk simulation to be returns as Path (default: 0).\n\n        Returns:\n            Path object containing the sequence of nodes traversed by the random walk\n        \"\"\"\n        # list of traversed nodes starting with seed node\n        walk_steps = list(data.loc[(data[\"run_id\"] == run_id) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n        # generate Path\n        path = PathData(self._network.mapping)\n        path.append_walk([walk_steps[i] for i in range(len(walk_steps))])\n        return path\n\n    def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = None) -&gt; PathData:\n        \"\"\"Return a PathData object where each path is one random walk trajectory\n\n        Args:\n            data: Pandas `DataFrame` containing the trajectory of one or more random walks, generated by `run_experiment`\n            run_ids: UIDs of random walk simulation runs to be included in the `PathData`. If None (default), all runs will be included.\n        \"\"\"\n\n        if not run_ids:  # generate paths for all run_ids in the data frame\n            runs = data[\"run_id\"].unique()\n        else:\n            runs = run_ids\n\n        walks = PathData(self._network.mapping)\n        for id in runs:\n            walk_steps = list(data.loc[(data[\"run_id\"] == id) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n            # add walk to PathData\n            walks.append_walk(walk_steps)\n\n        return walks\n\n    def stationary_state(self, **kwargs: Any) -&gt; np.array:\n        \"\"\"Compute stationary visitation probabilities of random walk.\n\n        Computes stationary visitation probabilities of nodes based on the\n        leading eigenvector of the transition matrix.\n\n        Args:\n            kwargs: Arbitrary key-value pairs to bee passed to the\n            scipy.sparse.linalg.eigs function.\n        \"\"\"\n        _p = self._stationary_probabilities\n        if kwargs:\n            _, eigenvectors = sp.sparse.linalg.eigs(self._transition_matrix.transpose(), k=1, which=\"LM\", **kwargs)\n            pi = eigenvectors.reshape(\n                eigenvectors.size,\n            )\n            _p = np.real(pi / np.sum(pi))\n        return _p\n\n    @property\n    def visitation_frequencies(self) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of nodes based on the history of\n        the random walk. Initially, all visitation probabilities are zero except for the start node.\n        \"\"\"\n        return np.nan_to_num(self._visitations / (self._t + 1))\n\n    @property\n    def total_variation_distance(self) -&gt; float:\n        \"\"\"Returns the total variation distance between stationary\n        visitation probabilities and the current visitation frequencies\n\n        Computes the total variation distance between the current visitation\n        probabilities and the stationary probabilities. This quantity converges\n        to zero for RandomWalk.t -&gt; np.infty and its magnitude indicates the\n        current relaxation of the random walk process.\n        \"\"\"\n        return self.TVD(self.stationary_state(), self.visitation_frequencies)\n\n    @staticmethod\n    def TVD(a: np.array, b: np.array) -&gt; float:\n        \"\"\"Calculates the total variation distance between two probability vectors\"\"\"\n        return np.abs(a - b).sum() / 2.0\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.time","title":"<code>time: int</code>  <code>property</code>","text":"<p>The current time of the random walk process, i.e. the number of steps taken since the start node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.total_variation_distance","title":"<code>total_variation_distance: float</code>  <code>property</code>","text":"<p>Returns the total variation distance between stationary visitation probabilities and the current visitation frequencies</p> <p>Computes the total variation distance between the current visitation probabilities and the stationary probabilities. This quantity converges to zero for RandomWalk.t -&gt; np.infty and its magnitude indicates the current relaxation of the random walk process.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_matrix","title":"<code>transition_matrix: sp.sparse.csr_matrix</code>  <code>property</code>","text":"<p>Returns the transition matrix of the random walk</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.visitation_frequencies","title":"<code>visitation_frequencies: np.array</code>  <code>property</code>","text":"<p>Returns current normalized visitation frequencies of nodes based on the history of the random walk. Initially, all visitation probabilities are zero except for the start node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.TVD","title":"<code>TVD</code>  <code>staticmethod</code>","text":"<p>Calculates the total variation distance between two probability vectors</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>@staticmethod\ndef TVD(a: np.array, b: np.array) -&gt; float:\n    \"\"\"Calculates the total variation distance between two probability vectors\"\"\"\n    return np.abs(a - b).sum() / 2.0\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.__init__","title":"<code>__init__</code>","text":"<p>Creates a biased random walk process in a network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.Graph</code> <p>The network instance on which to perform the random walk process. Can also be an instance of HigherOrderNetwork.</p> required <code>weight</code> <code>typing.Optional[pathpyG.processes.random_walk.Weight]</code> <p>If specified, the given numerical edge attribute will be used to bias the random walk transition probabilities.</p> <code>None</code> <code>restart_probability</code> <p>The per-step probability that a random walker restarts in a random node</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def __init__(self, network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n    \"\"\"Creates a biased random walk process in a network.\n\n    Args:\n        network: The network instance on which to perform the random walk process. Can also\n            be an instance of HigherOrderNetwork.\n        weight: If specified, the given numerical edge attribute will be used to bias\n            the random walk transition probabilities.\n        restart_probability: The per-step probability that a random walker restarts in a random node\n    \"\"\"\n\n    # transition matrix of random walk\n    self._transition_matrix = RandomWalk.compute_transition_matrix(network, weight, restart_prob)\n\n    # initialize Vose Alias Samplers\n\n    self.samplers = {\n        v: VoseAliasSampling(\n            np.nan_to_num(np.ravel(self._transition_matrix[network.mapping.to_idx(v), :].todense()))\n        )\n        for v in network.nodes\n    }\n\n    # compute eigenvectors and eigenvalues of transition matrix\n    if network.n &gt; 2:\n        _, eigenvectors = spl.eigs(self._transition_matrix.transpose(), k=1, which=\"LM\")\n        pi = eigenvectors.reshape(\n            eigenvectors.size,\n        )\n    else:\n        eigenvals, eigenvectors = spla.eig(self._transition_matrix.transpose().toarray())\n        x = np.argsort(-eigenvals)\n        pi = eigenvectors[x][:, 0]\n\n    # calculate stationary visitation probabilities\n    self._stationary_probabilities = np.real(pi / np.sum(pi))\n\n    self._network = network\n    self.init(self.random_seed())\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.compute_transition_matrix","title":"<code>compute_transition_matrix</code>  <code>staticmethod</code>","text":"<p>Returns the transition matrix of a (biased) random walk in the given network.</p> <p>Returns a transition matrix that describes a random walk process in the given network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.Graph</code> <p>The network for which the transition matrix will be created.</p> required <code>weight</code> <code>typing.Optional[pathpyG.processes.random_walk.Weight]</code> <p>If specified, the numerical edge attribute that shall be used in the biased transition probabilities of the random walk.</p> <code>None</code> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>@staticmethod\ndef compute_transition_matrix(\n    network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0\n) -&gt; sp.sparse.csr_matrix:\n    \"\"\"Returns the transition matrix of a (biased) random walk in the given network.\n\n    Returns a transition matrix that describes a random walk process in the\n    given network.\n\n    Args:\n        network: The network for which the transition matrix will be created.\n        weight: If specified, the numerical edge attribute that shall be used in the biased\n            transition probabilities of the random walk.\n\n    \"\"\"\n    if weight is None or weight is False:\n        A = network.sparse_adj_matrix().todense()\n    elif weight is True:\n        A = network.sparse_adj_matrix(edge_attr=\"edge_weight\").todense()\n    else:\n        A = network.sparse_adj_matrix(edge_attr=weight).todense()\n    D = A.sum(axis=1)\n    n = network.n\n    T = sp.sparse.lil_matrix((n, n))\n    zero_deg = 0\n    for i in range(n):\n        if D[i] == 0:\n            zero_deg += 1\n        for j in range(n):\n            if D[i] &gt; 0:\n                T[i, j] = restart_prob * (1.0 / n) + (1 - restart_prob) * A[i, j] / D[i]\n            else:\n                if restart_prob &gt; 0:\n                    T[i, j] = 1.0 / n\n                else:\n                    T[i, j] = 0.0\n    # if zero_deg &gt; 0:\n    #     LOG.warning(\n    #         'Network contains {0} nodes with zero out-degree'.format(zero_deg))\n    return T.tocsr()\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_path","title":"<code>get_path</code>","text":"<p>Returns a path that represents the sequence of (first-order) nodes traversed by a single random walk.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pandas.DataFrame</code> <p>Pandas <code>DataFrame</code> containing the trajectory of one or more (higher-order) random walks, generated by a call of <code>run_experiment</code></p> required <code>run_uid</code> <p>Uid of the random walk simulation to be returns as Path (default: 0).</p> required <p>Returns:</p> Type Description <code>pathpyG.PathData</code> <p>Path object containing the sequence of nodes traversed by the random walk</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_path(self, data: DataFrame, run_id: Optional[int] = 0, first_order: Optional[bool] = True) -&gt; PathData:\n    \"\"\"Returns a path that represents the sequence of (first-order) nodes traversed\n    by a single random walk.\n\n    Args:\n        data: Pandas `DataFrame` containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n        run_uid: Uid of the random walk simulation to be returns as Path (default: 0).\n\n    Returns:\n        Path object containing the sequence of nodes traversed by the random walk\n    \"\"\"\n    # list of traversed nodes starting with seed node\n    walk_steps = list(data.loc[(data[\"run_id\"] == run_id) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n    # generate Path\n    path = PathData(self._network.mapping)\n    path.append_walk([walk_steps[i] for i in range(len(walk_steps))])\n    return path\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_paths","title":"<code>get_paths</code>","text":"<p>Return a PathData object where each path is one random walk trajectory</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pandas.DataFrame</code> <p>Pandas <code>DataFrame</code> containing the trajectory of one or more random walks, generated by <code>run_experiment</code></p> required <code>run_ids</code> <code>typing.Optional[typing.Iterable]</code> <p>UIDs of random walk simulation runs to be included in the <code>PathData</code>. If None (default), all runs will be included.</p> <code>None</code> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = None) -&gt; PathData:\n    \"\"\"Return a PathData object where each path is one random walk trajectory\n\n    Args:\n        data: Pandas `DataFrame` containing the trajectory of one or more random walks, generated by `run_experiment`\n        run_ids: UIDs of random walk simulation runs to be included in the `PathData`. If None (default), all runs will be included.\n    \"\"\"\n\n    if not run_ids:  # generate paths for all run_ids in the data frame\n        runs = data[\"run_id\"].unique()\n    else:\n        runs = run_ids\n\n    walks = PathData(self._network.mapping)\n    for id in runs:\n        walk_steps = list(data.loc[(data[\"run_id\"] == id) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n        # add walk to PathData\n        walks.append_walk(walk_steps)\n\n    return walks\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.init","title":"<code>init</code>","text":"<p>Initializes the random walk state with a given seed/source node</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>str</code> <p>Id of node in which the random walk will start</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def init(self, seed: str) -&gt; None:\n    \"\"\"\n    Initializes the random walk state with a given seed/source node\n\n    Args:\n        seed: Id of node in which the random walk will start\n    \"\"\"\n    # reset currently visited node (or higher-order node)\n    self._current_node = seed\n\n    # set time\n    self._t = 0\n\n    # set number of times each node has been visited\n    self._visitations = np.ravel(np.zeros(shape=(1, self._network.n)))\n    self._visitations[self._network.mapping.to_idx(seed)] = 1\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.node_state","title":"<code>node_state</code>","text":"<p>Returns a boolean variable indicating whether the walker is currently visiting (first-order) node v</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def node_state(self, v) -&gt; bool:\n    \"\"\"\n    Returns a boolean variable indicating whether the walker is currently\n    visiting (first-order) node v\n    \"\"\"\n    if v in self._network.nodes:\n        return v == self._current_node\n    # TODO: Error here!\n    elif type(self._network) == HigherOrderGraph:\n        return v == self._network.mapping.to_id(self._current_node)[-1]\n    else:\n        raise NotImplementedError(\"Random walk not implemented for network of type {0}\".format(type(self._network)))\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.random_seed","title":"<code>random_seed</code>","text":"<p>Returns a random node from the network, chosen uniformly at random</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def random_seed(self) -&gt; Any:\n    \"\"\"\n    Returns a random node from the network, chosen uniformly at random\n    \"\"\"\n    x = np.random.choice(range(self._network.n))\n    return self._network.mapping.to_id(x)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.state_to_color","title":"<code>state_to_color</code>","text":"<p>Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>bool</code> <p>Current visitation state</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def state_to_color(self, state: bool) -&gt; str:\n    \"\"\"\n    Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.\n\n    Args:\n        state: Current visitation state\n    \"\"\"\n    if state:\n        return \"red\"\n    else:\n        return \"blue\"\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.stationary_state","title":"<code>stationary_state</code>","text":"<p>Compute stationary visitation probabilities of random walk.</p> <p>Computes stationary visitation probabilities of nodes based on the leading eigenvector of the transition matrix.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>typing.Any</code> <p>Arbitrary key-value pairs to bee passed to the</p> <code>{}</code> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def stationary_state(self, **kwargs: Any) -&gt; np.array:\n    \"\"\"Compute stationary visitation probabilities of random walk.\n\n    Computes stationary visitation probabilities of nodes based on the\n    leading eigenvector of the transition matrix.\n\n    Args:\n        kwargs: Arbitrary key-value pairs to bee passed to the\n        scipy.sparse.linalg.eigs function.\n    \"\"\"\n    _p = self._stationary_probabilities\n    if kwargs:\n        _, eigenvectors = sp.sparse.linalg.eigs(self._transition_matrix.transpose(), k=1, which=\"LM\", **kwargs)\n        pi = eigenvectors.reshape(\n            eigenvectors.size,\n        )\n        _p = np.real(pi / np.sum(pi))\n    return _p\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.step","title":"<code>step</code>","text":"<p>Function that will be called for each step of the random walk. This function returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def step(self) -&gt; Iterable[str]:\n    \"\"\"\n    Function that will be called for each step of the random walk. This function\n    returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.\n    \"\"\"\n\n    # determine next node\n    next_node = self.network.mapping.to_id(self.samplers[self._current_node].sample())\n    # TODO: assertion will not hold if restart_prob &gt; 0\n    # assert (self._current_node, next_node) in self._network.edges, 'Assertion Error: {0} not in edge list'.format(\n    #     (self._current_node, next_node))\n\n    previous_node = self._current_node\n    self._current_node = next_node\n\n    # increment visitations and current time\n    self._visitations[self._network.mapping.to_idx(self._current_node)] += 1\n    self._t += 1\n\n    # return tuple of changed nodes, where the first node is the currently visited node\n    return (self._current_node, previous_node)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_matrix_pd","title":"<code>transition_matrix_pd</code>","text":"<p>Returns the transition matrix as pandas DataFrame with proper row/column labels.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def transition_matrix_pd(self) -&gt; DataFrame:\n    \"\"\"\n    Returns the transition matrix as pandas DataFrame with proper row/column labels.\n    \"\"\"\n    return DataFrame(\n        self.transition_matrix.todense(),\n        columns=[v for v in self._network.nodes],\n        index=[v for v in self._network.nodes],\n    )\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Returns a vector that contains transition probabilities.</p> <p>Returns a vector that contains transition probabilities from a given node to all other nodes in the network.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def transition_probabilities(self, node: str) -&gt; np.array:\n    \"\"\"Returns a vector that contains transition probabilities.\n\n    Returns a vector that contains transition probabilities from a given\n    node to all other nodes in the network.\n    \"\"\"\n    return np.nan_to_num(np.ravel(self._transition_matrix[self._network.mapping.to_idx(node), :].todense()))\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.visitation_probabilities","title":"<code>visitation_probabilities</code>","text":"<p>Calculates visitation probabilities of nodes after t steps for a given start node</p> <p>Initially, all visitation probabilities are zero except for the start node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def visitation_probabilities(self, t, seed: str) -&gt; np.ndarray:\n    \"\"\"Calculates visitation probabilities of nodes after t steps for a given start node\n\n    Initially, all visitation probabilities are zero except for the start node.\n    \"\"\"\n    assert seed in self._network.nodes\n\n    initial_dist = np.zeros(self._network.n)\n    initial_dist[self._network.mapping.to_idx(seed)] = 1.0\n    return np.dot(initial_dist, (self._transition_matrix**t).todense())\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/","title":"sampling","text":"<p>Classes for efficient random sampling from discrete distributions</p>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling","title":"<code>VoseAliasSampling</code>","text":"<p>Implementation of fast biased sampling of discrete values [0, ..., n]</p> <p>For a concise explanation see https://www.keithschwarz.com/darts-dice-coins/</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>typing.Union[numpy.array, list]</code> <p>relative weights of the n events, where weights[i] is the relative statistical weight of event i. The weights do not need to be normalized.</p> <p>For an array with length n, generated random values will be from range(n).</p> required <p>Examples:</p> <p>Create a VoseAliasSampling instance</p> <pre><code>&gt;&gt;&gt; from pathpy.processes import VoseAliasSampling\n&gt;&gt;&gt; sampler = VoseAliasSampling([1,1,2])\n</code></pre> <p>Fast biased sampling in O(1)</p> <pre><code>&gt;&gt;&gt; [ sampler.sample() for i in range(10) ]\n[ 0 2 0 1 2 1 2 1 2 0 2 2 ]\n</code></pre> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>class VoseAliasSampling:\n    \"\"\"\n    Implementation of fast biased sampling of discrete values [0, ..., n]\n\n    For a concise explanation see https://www.keithschwarz.com/darts-dice-coins/\n\n    Args:\n        weights: relative weights of the n events, where weights[i] is the relative\n            statistical weight of event i. The weights do not need to be\n            normalized.\n\n            For an array with length n, generated random values\n            will be from range(n).\n\n    Examples:\n        Create a VoseAliasSampling instance\n\n        &gt;&gt;&gt; from pathpy.processes import VoseAliasSampling\n        &gt;&gt;&gt; sampler = VoseAliasSampling([1,1,2])\n\n        Fast biased sampling in O(1)\n\n        &gt;&gt;&gt; [ sampler.sample() for i in range(10) ]\n        [ 0 2 0 1 2 1 2 1 2 0 2 2 ]\n    \"\"\"\n\n    def __init__(self, weights: Union[np.array, list]) -&gt; None:\n        \"\"\"\n        Initializes probability and alias tables\n        \"\"\"\n        self.n = len(weights)\n        self.probs = dict()\n        self.scaled_probs = dict()\n        self.aliases = dict()\n\n        small = list()\n        large = list()\n\n        for i in range(1, self.n + 1):\n            self.probs[i] = weights[i - 1]\n            self.scaled_probs[i] = self.n * weights[i - 1]\n            if self.scaled_probs[i] &gt; 1:\n                large.append(i)\n            elif self.scaled_probs[i] &lt;= 1:\n                small.append(i)\n\n        while small and large:\n            l = small.pop()\n            g = large.pop()\n\n            self.probs[l] = self.scaled_probs[l]\n            self.aliases[l] = g\n            self.scaled_probs[g] = self.scaled_probs[l] + self.scaled_probs[g] - 1\n\n            if self.scaled_probs[g] &lt; 1:\n                small.append(g)\n            else:\n                large.append(g)\n        while large:\n            g = large.pop()\n            self.probs[g] = 1\n        while small:\n            l = small.pop()\n            self.probs[l] = 1\n\n    def sample(self) -&gt; int:\n        \"\"\"\n        Biased sampling of discrete value in O(1)\n\n        Returns: integer value from range(n), where n is the length\n            of the weight array used to create the instance.\n        \"\"\"\n        i = np.random.randint(1, self.n + 1)\n        x = np.random.rand()\n        if x &lt; self.probs[i]:\n            return i - 1\n        else:\n            return self.aliases[i] - 1\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling.__init__","title":"<code>__init__</code>","text":"<p>Initializes probability and alias tables</p> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>def __init__(self, weights: Union[np.array, list]) -&gt; None:\n    \"\"\"\n    Initializes probability and alias tables\n    \"\"\"\n    self.n = len(weights)\n    self.probs = dict()\n    self.scaled_probs = dict()\n    self.aliases = dict()\n\n    small = list()\n    large = list()\n\n    for i in range(1, self.n + 1):\n        self.probs[i] = weights[i - 1]\n        self.scaled_probs[i] = self.n * weights[i - 1]\n        if self.scaled_probs[i] &gt; 1:\n            large.append(i)\n        elif self.scaled_probs[i] &lt;= 1:\n            small.append(i)\n\n    while small and large:\n        l = small.pop()\n        g = large.pop()\n\n        self.probs[l] = self.scaled_probs[l]\n        self.aliases[l] = g\n        self.scaled_probs[g] = self.scaled_probs[l] + self.scaled_probs[g] - 1\n\n        if self.scaled_probs[g] &lt; 1:\n            small.append(g)\n        else:\n            large.append(g)\n    while large:\n        g = large.pop()\n        self.probs[g] = 1\n    while small:\n        l = small.pop()\n        self.probs[l] = 1\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling.sample","title":"<code>sample</code>","text":"<p>Biased sampling of discrete value in O(1)</p> <p>integer value from range(n), where n is the length</p> Type Description <code>int</code> <p>of the weight array used to create the instance.</p> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>def sample(self) -&gt; int:\n    \"\"\"\n    Biased sampling of discrete value in O(1)\n\n    Returns: integer value from range(n), where n is the length\n        of the weight array used to create the instance.\n    \"\"\"\n    i = np.random.randint(1, self.n + 1)\n    x = np.random.rand()\n    if x &lt; self.probs[i]:\n        return i - 1\n    else:\n        return self.aliases[i] - 1\n</code></pre>"},{"location":"reference/pathpyG/statistics/","title":"statistics","text":"<p>Functions to compute various graph statistics.</p> <p>The functions in this module allow to compute  various statistics on graphs</p> Example <pre><code>import pathpyG as pp\n\n# Generate a toy example graph.\ng = pp.Graph.from_edge_list([\n    ('b', 'c'),\n    ('a', 'b'),\n    ('c', 'd'),\n    ('d', 'a'),\n    ('b', 'd')\n])\n\n# Calculate degree distribution and raw moments\nd_dist = pp.statistics.degree_distribution(g)\nk_1 = pp.statistics.degree_raw_moment(g, k=1)\nk_2 = pp.statistics.degree_raw_moment(g, k=2)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if \"num_nodes\" not in data:\n            data.num_nodes = data.edge_index.max().item() + 1\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if (\n            data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n            or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n        ):\n            raise Exception(\"sparse size of EdgeIndex should match number of nodes!\")\n\n        # sort EdgeIndex and validate\n        data.edge_index = data.edge_index.sort_by(\"row\").values\n        data.edge_index.validate()\n\n        self.data = data\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n        # create node_sequence mapping for higher-order graphs\n        if \"node_sequence\" not in self.data:\n            self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n        Examples:\n            You can create a graph from an edge index tensor as follows:\n\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            &gt;&gt;&gt; print(g)\n            Directed graph with 3 nodes and 3 edges ...\n\n            You can also include a mapping of node IDs:\n\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n            &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n            &gt;&gt;&gt; print(g.mapping)\n            a -&gt; 0\n            b -&gt; 1\n            c -&gt; 2\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else:\n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(d, mapping=mapping)\n\n    @staticmethod\n    def from_edge_list(\n        edge_list: Iterable[Tuple[str, str]],\n        is_undirected: bool = False,\n        mapping: Optional[IndexMap] = None,\n        num_nodes: Optional[int] = None,\n    ) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n            &gt;&gt;&gt; print(list(g.edges))\n            [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        \"\"\"\n\n        if mapping is None:\n            edge_array = np.array(edge_list)\n            node_ids = np.unique(edge_array)\n            if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n                node_ids = np.sort(node_ids.astype(int)).astype(str)\n            mapping = IndexMap(node_ids)\n\n        if num_nodes is None:\n            num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex(\n            mapping.to_idxs(edge_list).T.contiguous(),\n            sparse_size=(num_nodes, num_nodes),\n            is_undirected=is_undirected,\n        )\n        return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            &gt;&gt;&gt; g_u = g.to_undirected()\n            &gt;&gt;&gt; print(g_u)\n            Undirected graph with 3 nodes and 6 (directed) edges\n        \"\"\"\n        tf = ToUndirected()\n        d = tf(self.data)\n        # unfortunately, the application of a transform creates a new edge_index of type tensor\n        # so we have to recreate the EdgeIndex tensor and sort it again\n\n        e = EdgeIndex(data=d.edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True)\n        d.edge_index = e\n        d.num_nodes = self.data.num_nodes\n        return Graph(d, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n        If the graph contains multiple edges between the same nodes, this method will coalesce\n        them into a single edge with an additional weight attribute called `edge_weight` that\n        contains the number of coalesced edges. The method returns a new graph instance with\n        the coalesced edges.\n\n        Returns:\n            Graph: Graph with coalesced edges\n        \"\"\"\n        i, w = torch_geometric.utils.coalesce(\n            self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n\n    def node_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_sequence` attribute.\n\n        Returns:\n            list: list of node attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n\n        Returns:\n            list: list of edge attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; list:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a list object that contains all nodes.\n        If an IndexMap is used, nodes are returned as string IDs.\n        If no IndexMap is used, nodes are returned as integer indices.\n\n        Returns:\n            list: list of all nodes using IDs or indices (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(np.arange(self.n)).tolist()\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    @property\n    def edges(self) -&gt; list:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a list object that contains all edges, where each\n        edge is a tuple of two elements. If an IndexMap is used to map node\n        indices to string IDs, edges are returned as tuples of string IDs.\n        If no mapping is used, edges are returned as tuples of integer indices.\n\n        Returns:\n            list: list object yielding all edges using IDs or indices (if no mapping is used)\n        \"\"\"\n        edge_list = self.mapping.to_ids(self.data.edge_index.t()).tolist()\n        if self.order &gt; 1:\n            return [tuple(map(tuple, x)) for x in edge_list]\n        return list(map(tuple, edge_list))\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n        \"\"\"\n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def successors(self, node: Union[int, str] | tuple) -&gt; list:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n\n        Returns:\n            list: list with all successors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n\n        node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n\n        Returns:\n            list: list with all predecessors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID\n\n        Returns:\n            bool: True if edge exists, False otherwise\n        \"\"\"\n        row = self.mapping.to_idx(v)\n        row_start = self.row_ptr[row]\n        row_end = self.row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in self.col[row_start:row_end]\n\n    def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor())\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return in-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing in-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return out-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing out-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n        \"\"\"\n        Return degrees of nodes.\n\n        Args:\n            mode: `in` or `out` to calculate the in- or out-degree for\n                directed networks.\n\n        Returns:\n            dict: dictionary containing degrees of nodes\n        \"\"\"\n        if mode == \"in\":\n            d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n        else:\n            d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n        return {self.mapping.to_id(i): d[i].item() for i in range(self.n)}\n\n    def weighted_outdegrees(self) -&gt; torch.Tensor:\n        \"\"\"\n        Compute the weighted outdegrees of each node in the graph.\n\n        Args:\n            graph (Graph): pathpy graph object.\n\n        Returns:\n            tensor: Weighted outdegrees of nodes.\n        \"\"\"\n        weighted_outdegree = scatter(\n            self.data.edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\"\n        )\n        return weighted_outdegree\n\n    def transition_probabilities(self) -&gt; torch.Tensor:\n        \"\"\"\n        Compute transition probabilities based on weighted outdegrees.\n\n        Returns:\n            tensor: Transition probabilities.\n        \"\"\"\n        weighted_outdegree = self.weighted_outdegrees()\n        source_ids = self.data.edge_index[0]\n        return self.data.edge_weight / weighted_outdegree[source_ids]\n\n    def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization: normalization parameter passed to pyG `get_laplacian`\n                function\n            edge_attr: optinal name of numerical edge attribute that shall\n                be passed to pyG `get_laplacian` function as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(), normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(),\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key.startswith(\"node_\"):\n                if val.size(0) != self.n:\n                    raise ValueError(\"Attribute must have same length as number of nodes\")\n                self.data[key] = val\n            elif key.startswith(\"edge_\"):\n                if val.size(0) != self.m:\n                    raise ValueError(\"Attribute must have same length as number of edges\")\n                self.data[key] = val\n            else:\n                self.data[key] = val\n        elif key[0].startswith(\"node_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif key[0].startswith(\"edge_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n\n    @property\n    def n(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns:\n            int: number of nodes in the graph\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def m(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the number of directed edges is returned.\n\n        Returns:\n            int: number of edges in the graph\n        \"\"\"\n        return self.data.num_edges  # type: ignore\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"\n        Return order of graph.\n\n        Returns:\n            int: order of the (De Bruijn) graph\n        \"\"\"\n        return self.data.node_sequence.size(1)  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\n\n        Returns:\n            bool: True if graph is directed, False otherwise\n        \"\"\"\n        return not self.data.edge_index.is_undirected\n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\n\n        Returns:\n            bool: True if graph is undirected, False otherwise\n        \"\"\"\n        return self.data.edge_index.is_undirected\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\n\n        Returns:\n            bool: True if graph contains self-loops, False otherwise\n        \"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph) -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Examples:\n            Adding two graphs without node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 6 edges\n\n            Adding two graphs with identical node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 4 edges\n\n            Adding two graphs with non-overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 6 nodes and 4 edges\n\n            Adding two graphs with partly overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 5 nodes and 4 edges\n        \"\"\"\n\n        if self.order &gt; 1:\n            raise NotImplementedError(\"Add operator can only be applied to order 1 graphs\")\n\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        # compute overlap and additional nodes in g2 over g1\n        overlap = set(m2.node_ids).intersection(m1.node_ids)\n        additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n        d2_idx_translation = {}\n        node_ids = [\"\"] * (self.n + len(additional_nodes))\n        # keep mappings of nodes in g1\n        for v in m1.node_ids:\n            node_ids[m1.to_idx(v)] = v\n        for v in m2.node_ids:\n            d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n        # for overlapping node IDs we must correct node indices in m2\n        for v in overlap:\n            d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n        # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n        for v in additional_nodes:\n            new_idx = m2.to_idx(v) + self.n - len(overlap)\n            node_ids[new_idx] = v\n            d2_idx_translation[m2.to_idx(v)] = new_idx\n        # apply index translation to d2\n        # fast dictionary based mapping using torch\n        palette, key = zip(*d2_idx_translation.items())\n        key = torch.tensor(key)\n        palette = torch.tensor(palette)\n\n        index = torch.bucketize(d2.edge_index.ravel(), palette)\n        d2.edge_index = key[index].reshape(d2.edge_index.shape)\n        d = d1.concat(d2)\n        mapping = IndexMap(node_ids)\n        d.num_nodes = self.n + len(additional_nodes)\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.n, self.m)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.edges","title":"<code>edges: list</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a list object that contains all edges, where each edge is a tuple of two elements. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of string IDs. If no mapping is used, edges are returned as tuples of integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list object yielding all edges using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.in_degrees","title":"<code>in_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return in-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing in-degrees of nodes</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.m","title":"<code>m: int</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the number of directed edges is returned.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of edges in the graph</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.n","title":"<code>n: int</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of nodes in the graph</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.nodes","title":"<code>nodes: list</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a list object that contains all nodes. If an IndexMap is used, nodes are returned as string IDs. If no IndexMap is used, nodes are returned as integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list of all nodes using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.order","title":"<code>order: int</code>  <code>property</code>","text":"<p>Return order of graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>order of the (De Bruijn) graph</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.out_degrees","title":"<code>out_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return out-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing out-degrees of nodes</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Examples:</p> <p>Adding two graphs without node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 6 edges\n</code></pre> <p>Adding two graphs with identical node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 4 edges\n</code></pre> <p>Adding two graphs with non-overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 6 nodes and 4 edges\n</code></pre> <p>Adding two graphs with partly overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 5 nodes and 4 edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __add__(self, other: Graph) -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indiced will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Examples:\n        Adding two graphs without node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 6 edges\n\n        Adding two graphs with identical node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 4 edges\n\n        Adding two graphs with non-overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 6 nodes and 4 edges\n\n        Adding two graphs with partly overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 5 nodes and 4 edges\n    \"\"\"\n\n    if self.order &gt; 1:\n        raise NotImplementedError(\"Add operator can only be applied to order 1 graphs\")\n\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    # compute overlap and additional nodes in g2 over g1\n    overlap = set(m2.node_ids).intersection(m1.node_ids)\n    additional_nodes = set(m2.node_ids).difference(m1.node_ids)\n\n    d2_idx_translation = {}\n    node_ids = [\"\"] * (self.n + len(additional_nodes))\n    # keep mappings of nodes in g1\n    for v in m1.node_ids:\n        node_ids[m1.to_idx(v)] = v\n    for v in m2.node_ids:\n        d2_idx_translation[m2.to_idx(v)] = m2.to_idx(v)\n    # for overlapping node IDs we must correct node indices in m2\n    for v in overlap:\n        d2_idx_translation[m2.to_idx(v)] = m1.to_idx(v)\n    # add mapping for nodes in g2 that are not in g1 and correct indices in g2\n    for v in additional_nodes:\n        new_idx = m2.to_idx(v) + self.n - len(overlap)\n        node_ids[new_idx] = v\n        d2_idx_translation[m2.to_idx(v)] = new_idx\n    # apply index translation to d2\n    # fast dictionary based mapping using torch\n    palette, key = zip(*d2_idx_translation.items())\n    key = torch.tensor(key)\n    palette = torch.tensor(palette)\n\n    index = torch.bucketize(d2.edge_index.ravel(), palette)\n    d2.edge_index = key[index].reshape(d2.edge_index.shape)\n    d = d1.concat(d2)\n    mapping = IndexMap(node_ids)\n    d.num_nodes = self.n + len(additional_nodes)\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if \"num_nodes\" not in data:\n        data.num_nodes = data.edge_index.max().item() + 1\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if (\n        data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n        or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n    ):\n        raise Exception(\"sparse size of EdgeIndex should match number of nodes!\")\n\n    # sort EdgeIndex and validate\n    data.edge_index = data.edge_index.sort_by(\"row\").values\n    data.edge_index.validate()\n\n    self.data = data\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    # create node_sequence mapping for higher-order graphs\n    if \"node_sequence\" not in self.data:\n        self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key.startswith(\"node_\"):\n            if val.size(0) != self.n:\n                raise ValueError(\"Attribute must have same length as number of nodes\")\n            self.data[key] = val\n        elif key.startswith(\"edge_\"):\n            if val.size(0) != self.m:\n                raise ValueError(\"Attribute must have same length as number of edges\")\n            self.data[key] = val\n        else:\n            self.data[key] = val\n    elif key[0].startswith(\"node_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif key[0].startswith(\"edge_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.n, self.m)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate the in- or out-degree for directed networks.</p> <code>'in'</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing degrees of nodes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n    \"\"\"\n    Return degrees of nodes.\n\n    Args:\n        mode: `in` or `out` to calculate the in- or out-degree for\n            directed networks.\n\n    Returns:\n        dict: dictionary containing degrees of nodes\n    \"\"\"\n    if mode == \"in\":\n        d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n    else:\n        d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n    return {self.mapping.to_id(i): d[i].item() for i in range(self.n)}\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of edge attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def edge_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n\n    Returns:\n        list: list of edge attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <code>int</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.</p> <code>None</code> <p>Examples:</p> <p>You can create a graph from an edge index tensor as follows:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n&gt;&gt;&gt; print(g)\nDirected graph with 3 nodes and 3 edges ...\n</code></pre> <p>You can also include a mapping of node IDs:</p> <pre><code>&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n&gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n&gt;&gt;&gt; print(g.mapping)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n    Examples:\n        You can create a graph from an edge index tensor as follows:\n\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        &gt;&gt;&gt; print(g)\n        Directed graph with 3 nodes and 3 edges ...\n\n        You can also include a mapping of node IDs:\n\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n        &gt;&gt;&gt; print(g.mapping)\n        a -&gt; 0\n        b -&gt; 1\n        c -&gt; 2\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else:\n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>num_nodes</code> <code>typing.Optional[int]</code> <p>optional number of nodes (useful in case not all nodes have incident edges)</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n&gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n&gt;&gt;&gt; print(list(g.edges))\n[('a', 'b'), ('a', 'c'), ('b', 'c')]\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(\n    edge_list: Iterable[Tuple[str, str]],\n    is_undirected: bool = False,\n    mapping: Optional[IndexMap] = None,\n    num_nodes: Optional[int] = None,\n) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        num_nodes: optional number of nodes (useful in case not all nodes have incident edges)\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n        &gt;&gt;&gt; print(list(g.edges))\n        [('a', 'b'), ('a', 'c'), ('b', 'c')]\n    \"\"\"\n\n    if mapping is None:\n        edge_array = np.array(edge_list)\n        node_ids = np.unique(edge_array)\n        if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n            node_ids = np.sort(node_ids.astype(int)).astype(str)\n        mapping = IndexMap(node_ids)\n\n    if num_nodes is None:\n        num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex(\n        mapping.to_idxs(edge_list).T.contiguous(),\n        sparse_size=(num_nodes, num_nodes),\n        is_undirected=is_undirected,\n    )\n    return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all predecessor nodes of the node indexed by <code>col_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n    \"\"\"\n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all successor nodes of the node indexed by <code>row_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph contains self-loops, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\n\n    Returns:\n        bool: True if graph contains self-loops, False otherwise\n    \"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is directed, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\n\n    Returns:\n        bool: True if graph is directed, False otherwise\n    \"\"\"\n    return not self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if edge exists, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID\n\n    Returns:\n        bool: True if edge exists, False otherwise\n    \"\"\"\n    row = self.mapping.to_idx(v)\n    row_start = self.row_ptr[row]\n    row_end = self.row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in self.col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is undirected, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\n\n    Returns:\n        bool: True if graph is undirected, False otherwise\n    \"\"\"\n    return self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.laplacian","title":"<code>laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code> function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: Laplacian matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization: normalization parameter passed to pyG `get_laplacian`\n            function\n        edge_attr: optinal name of numerical edge attribute that shall\n            be passed to pyG `get_laplacian` function as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(), normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(),\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_sequence</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of node attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def node_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_sequence` attribute.\n\n    Returns:\n        list: list of node attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all predecessors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n\n    Returns:\n        list: list with all predecessors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n    node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.sparse_adj_matrix","title":"<code>sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor())\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n        )\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all successors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) -&gt; list:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n\n    Returns:\n        list: list with all successors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n\n    node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n&gt;&gt;&gt; g_u = g.to_undirected()\n&gt;&gt;&gt; print(g_u)\nUndirected graph with 3 nodes and 6 (directed) edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        &gt;&gt;&gt; g_u = g.to_undirected()\n        &gt;&gt;&gt; print(g_u)\n        Undirected graph with 3 nodes and 6 (directed) edges\n    \"\"\"\n    tf = ToUndirected()\n    d = tf(self.data)\n    # unfortunately, the application of a transform creates a new edge_index of type tensor\n    # so we have to recreate the EdgeIndex tensor and sort it again\n\n    e = EdgeIndex(data=d.edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True)\n    d.edge_index = e\n    d.num_nodes = self.data.num_nodes\n    return Graph(d, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> <p>If the graph contains multiple edges between the same nodes, this method will coalesce them into a single edge with an additional weight attribute called <code>edge_weight</code> that contains the number of coalesced edges. The method returns a new graph instance with the coalesced edges.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>Graph with coalesced edges</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n    If the graph contains multiple edges between the same nodes, this method will coalesce\n    them into a single edge with an additional weight attribute called `edge_weight` that\n    contains the number of coalesced edges. The method returns a new graph instance with\n    the coalesced edges.\n\n    Returns:\n        Graph: Graph with coalesced edges\n    \"\"\"\n    i, w = torch_geometric.utils.coalesce(\n        self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n    )\n    return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Compute transition probabilities based on weighted outdegrees.</p> <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Transition probabilities.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def transition_probabilities(self) -&gt; torch.Tensor:\n    \"\"\"\n    Compute transition probabilities based on weighted outdegrees.\n\n    Returns:\n        tensor: Transition probabilities.\n    \"\"\"\n    weighted_outdegree = self.weighted_outdegrees()\n    source_ids = self.data.edge_index[0]\n    return self.data.edge_weight / weighted_outdegree[source_ids]\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.weighted_outdegrees","title":"<code>weighted_outdegrees</code>","text":"<p>Compute the weighted outdegrees of each node in the graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>pathpy graph object.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Weighted outdegrees of nodes.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def weighted_outdegrees(self) -&gt; torch.Tensor:\n    \"\"\"\n    Compute the weighted outdegrees of each node in the graph.\n\n    Args:\n        graph (Graph): pathpy graph object.\n\n    Returns:\n        tensor: Weighted outdegrees of nodes.\n    \"\"\"\n    weighted_outdegree = scatter(\n        self.data.edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\"\n    )\n    return weighted_outdegree\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.closed_triads","title":"<code>closed_triads</code>","text":"<p>Calculates the set of edges that represent a closed triad around a given node v.</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.closed_triads--parameters","title":"Parameters","text":"<p>network : Network</p> <pre><code>The network in which to calculate the list of closed triads\n</code></pre> Source code in <code>src/pathpyG/statistics/clustering.py</code> <pre><code>def closed_triads(g: Graph, v: str) -&gt; Set:\n    \"\"\"Calculates the set of edges that represent a closed triad\n    around a given node v.\n\n    Parameters\n    ----------\n\n    network : Network\n\n        The network in which to calculate the list of closed triads\n\n    \"\"\"\n    c_triads: set = set()\n    edges = set()\n\n    # Collect all edges of successors\n    for x in g.successors(v):\n        for y in g.successors(x):\n            edges.add((x, y))\n\n    for x, y in edges:\n        if y in g.successors(v):\n            c_triads.add((x, y))\n    return c_triads\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_assortativity","title":"<code>degree_assortativity</code>","text":"<p>Calculate the degree assortativity</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_assortativity(g: Graph, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculate the degree assortativity\"\"\"\n\n    A = g.sparse_adj_matrix().todense()\n    m = _np.sum(A)\n\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n    elif not g.is_directed():\n        m = m / 2.0\n\n    cov = 0.0\n    var = 0.0\n    for i in g.nodes:\n        for j in g.nodes:\n            cov += (A[g.mapping.to_idx(i), g.mapping.to_idx(j)] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n            if i != j:\n                var -= (d[i] * d[j]) / (2 * m) * d[i] * d[j]\n            else:\n                var += (d[i] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n    return cov / var\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_central_moment","title":"<code>degree_central_moment</code>","text":"<p>Calculates the k-th central moment of the degree distribution.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which to calculate the k-th central moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_central_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th central moment of the degree distribution.\n\n    Args:\n        graph: The graph for which to calculate the k-th central moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mean = _np.mean(degree_sequence(graph, mode=mode))\n    m = 0.0\n    for x in p_k:\n        m += (x - mean) ** k * p_k[x]\n    return m\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_distribution","title":"<code>degree_distribution</code>","text":"<p>Calculates the degree distribution of a graph</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_distribution(g: Graph, mode: str = \"total\") -&gt; Dict[int, float]:\n    \"\"\"Calculates the degree distribution of a graph\"\"\"\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n\n    cnt: defaultdict = defaultdict(float)\n    for v in g.nodes:\n        cnt[d[v]] += 1.0 / g.n\n    return cnt\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_generating_function","title":"<code>degree_generating_function</code>","text":"<p>Returns the generating function of the degree distribution of a network,     calculated for either a single argument x or a list or numpy array of arguments x</p> <p>Returns f(x) where f is the probability generating function for the degree distribution P(k) for a graph. The function is defined in the interval [0,1].  The value returned is from the range [0,1]. The following properties hold:</p> <p>[1/k! d^k/dx f]_{x=0} = P(k) with d^k/dx f being the k-th derivative of f by x</p> <p>f'(1) =  with f' being the first derivative and  the mean degree <p>[(x d/dx)^m f]_{x=1} =  with  being the m-th raw moment of P <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which the generating function shall be computed</p> required float, list, numpy.ndarray <p>The argument(s) for which value(s) f(x) shall be computed.</p> <p>Example: <pre><code>    # Generate simple network\n    import pathpyG as pp\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n    # Return single function value\n    val = pp.statistics.degreee_generating_func(n, 0.3)\n    print(val)\n    0.069\n\n    # Plot generating function of degree distribution\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func(n, x)\n    x = plt.plot(x, y)\n    # [Function plot]\n\n    # Plot generating function based on degree sequence\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func([1,2,1,2], x)\n    x = plt.plot(x, y)\n    # [Function plot]\n</code></pre></p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_generating_function(\n    graph: Graph, x: float | list[float] | _np.ndarray, mode: str = \"total\"\n) -&gt; float | _np.ndarray:\n    \"\"\"Returns the generating function of the degree distribution of a network,\n        calculated for either a single argument x or a list or numpy array of arguments x\n\n\n    Returns f(x) where f is the probability generating function for the degree\n    distribution P(k) for a graph. The function is defined in the interval\n    [0,1].  The value returned is from the range [0,1]. The following properties\n    hold:\n\n    [1/k! d^k/dx f]_{x=0} = P(k)\n    with d^k/dx f being the k-th derivative of f by x\n\n    f'(1) = &lt;k&gt;\n    with f' being the first derivative and &lt;k&gt; the mean degree\n\n    [(x d/dx)^m f]_{x=1} = &lt;k^m&gt;\n    with &lt;k^m&gt; being the m-th raw moment of P\n\n    Args:\n        graph: The graph for which the generating function shall be computed\n\n    x:  float, list, numpy.ndarray\n        The argument(s) for which value(s) f(x) shall be computed.\n\n    Example:\n    ```py\n        # Generate simple network\n        import pathpyG as pp\n        import numpy as np\n        import matplotlib.pyplot as plt\n\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                    ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n        # Return single function value\n        val = pp.statistics.degreee_generating_func(n, 0.3)\n        print(val)\n        0.069\n\n        # Plot generating function of degree distribution\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func(n, x)\n        x = plt.plot(x, y)\n        # [Function plot]\n\n        # Plot generating function based on degree sequence\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func([1,2,1,2], x)\n        x = plt.plot(x, y)\n        # [Function plot]\n    ```\n    \"\"\"\n\n    p_k = degree_distribution(graph, mode=mode)\n\n    if isinstance(x, float):\n        x_range = [x]\n    else:\n        x_range = x\n\n    values: defaultdict = defaultdict(float)\n    for k in p_k:\n        for v in x_range:\n            values[v] += p_k[k] * v**k\n\n    _values: float | _np.ndarray\n    if len(x_range) &gt; 1:\n        _values = _np.fromiter(values.values(), dtype=float)\n    else:\n        _values = values[x]\n    return _values\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_raw_moment","title":"<code>degree_raw_moment</code>","text":"<p>Calculates the k-th raw moment of the degree distribution of a network</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph in which to calculate the k-th raw moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_raw_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th raw moment of the degree distribution of a network\n\n    Args:\n        graph:  The graph in which to calculate the k-th raw moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mom = 0.0\n    for x in p_k:\n        mom += x**k * p_k[x]\n    return mom\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_sequence","title":"<code>degree_sequence</code>","text":"<p>Calculates the degree sequence of an undirected network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <p>The <code>Graph</code> object for which degrees are calculated</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_sequence(g: Graph, mode: str = \"total\") -&gt; _np.array:\n    \"\"\"Calculates the degree sequence of an undirected network.\n\n    Args:\n        graph: The `Graph` object for which degrees are calculated\n    \"\"\"\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n\n    _degrees = _np.zeros(g.n, dtype=float)\n    for v in g.nodes:\n        _degrees[g.mapping.to_idx(v)] = d[v]\n    return _degrees\n</code></pre>"},{"location":"reference/pathpyG/statistics/clustering/","title":"clustering","text":""},{"location":"reference/pathpyG/statistics/clustering/#pathpyG.statistics.clustering.closed_triads","title":"<code>closed_triads</code>","text":"<p>Calculates the set of edges that represent a closed triad around a given node v.</p>"},{"location":"reference/pathpyG/statistics/clustering/#pathpyG.statistics.clustering.closed_triads--parameters","title":"Parameters","text":"<p>network : Network</p> <pre><code>The network in which to calculate the list of closed triads\n</code></pre> Source code in <code>src/pathpyG/statistics/clustering.py</code> <pre><code>def closed_triads(g: Graph, v: str) -&gt; Set:\n    \"\"\"Calculates the set of edges that represent a closed triad\n    around a given node v.\n\n    Parameters\n    ----------\n\n    network : Network\n\n        The network in which to calculate the list of closed triads\n\n    \"\"\"\n    c_triads: set = set()\n    edges = set()\n\n    # Collect all edges of successors\n    for x in g.successors(v):\n        for y in g.successors(x):\n            edges.add((x, y))\n\n    for x, y in edges:\n        if y in g.successors(v):\n            c_triads.add((x, y))\n    return c_triads\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/","title":"degrees","text":""},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_assortativity","title":"<code>degree_assortativity</code>","text":"<p>Calculate the degree assortativity</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_assortativity(g: Graph, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculate the degree assortativity\"\"\"\n\n    A = g.sparse_adj_matrix().todense()\n    m = _np.sum(A)\n\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n    elif not g.is_directed():\n        m = m / 2.0\n\n    cov = 0.0\n    var = 0.0\n    for i in g.nodes:\n        for j in g.nodes:\n            cov += (A[g.mapping.to_idx(i), g.mapping.to_idx(j)] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n            if i != j:\n                var -= (d[i] * d[j]) / (2 * m) * d[i] * d[j]\n            else:\n                var += (d[i] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n    return cov / var\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_central_moment","title":"<code>degree_central_moment</code>","text":"<p>Calculates the k-th central moment of the degree distribution.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which to calculate the k-th central moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_central_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th central moment of the degree distribution.\n\n    Args:\n        graph: The graph for which to calculate the k-th central moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mean = _np.mean(degree_sequence(graph, mode=mode))\n    m = 0.0\n    for x in p_k:\n        m += (x - mean) ** k * p_k[x]\n    return m\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_distribution","title":"<code>degree_distribution</code>","text":"<p>Calculates the degree distribution of a graph</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_distribution(g: Graph, mode: str = \"total\") -&gt; Dict[int, float]:\n    \"\"\"Calculates the degree distribution of a graph\"\"\"\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n\n    cnt: defaultdict = defaultdict(float)\n    for v in g.nodes:\n        cnt[d[v]] += 1.0 / g.n\n    return cnt\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_generating_function","title":"<code>degree_generating_function</code>","text":"<p>Returns the generating function of the degree distribution of a network,     calculated for either a single argument x or a list or numpy array of arguments x</p> <p>Returns f(x) where f is the probability generating function for the degree distribution P(k) for a graph. The function is defined in the interval [0,1].  The value returned is from the range [0,1]. The following properties hold:</p> <p>[1/k! d^k/dx f]_{x=0} = P(k) with d^k/dx f being the k-th derivative of f by x</p> <p>f'(1) =  with f' being the first derivative and  the mean degree <p>[(x d/dx)^m f]_{x=1} =  with  being the m-th raw moment of P <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which the generating function shall be computed</p> required float, list, numpy.ndarray <p>The argument(s) for which value(s) f(x) shall be computed.</p> <p>Example: <pre><code>    # Generate simple network\n    import pathpyG as pp\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n    # Return single function value\n    val = pp.statistics.degreee_generating_func(n, 0.3)\n    print(val)\n    0.069\n\n    # Plot generating function of degree distribution\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func(n, x)\n    x = plt.plot(x, y)\n    # [Function plot]\n\n    # Plot generating function based on degree sequence\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func([1,2,1,2], x)\n    x = plt.plot(x, y)\n    # [Function plot]\n</code></pre></p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_generating_function(\n    graph: Graph, x: float | list[float] | _np.ndarray, mode: str = \"total\"\n) -&gt; float | _np.ndarray:\n    \"\"\"Returns the generating function of the degree distribution of a network,\n        calculated for either a single argument x or a list or numpy array of arguments x\n\n\n    Returns f(x) where f is the probability generating function for the degree\n    distribution P(k) for a graph. The function is defined in the interval\n    [0,1].  The value returned is from the range [0,1]. The following properties\n    hold:\n\n    [1/k! d^k/dx f]_{x=0} = P(k)\n    with d^k/dx f being the k-th derivative of f by x\n\n    f'(1) = &lt;k&gt;\n    with f' being the first derivative and &lt;k&gt; the mean degree\n\n    [(x d/dx)^m f]_{x=1} = &lt;k^m&gt;\n    with &lt;k^m&gt; being the m-th raw moment of P\n\n    Args:\n        graph: The graph for which the generating function shall be computed\n\n    x:  float, list, numpy.ndarray\n        The argument(s) for which value(s) f(x) shall be computed.\n\n    Example:\n    ```py\n        # Generate simple network\n        import pathpyG as pp\n        import numpy as np\n        import matplotlib.pyplot as plt\n\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                    ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n        # Return single function value\n        val = pp.statistics.degreee_generating_func(n, 0.3)\n        print(val)\n        0.069\n\n        # Plot generating function of degree distribution\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func(n, x)\n        x = plt.plot(x, y)\n        # [Function plot]\n\n        # Plot generating function based on degree sequence\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func([1,2,1,2], x)\n        x = plt.plot(x, y)\n        # [Function plot]\n    ```\n    \"\"\"\n\n    p_k = degree_distribution(graph, mode=mode)\n\n    if isinstance(x, float):\n        x_range = [x]\n    else:\n        x_range = x\n\n    values: defaultdict = defaultdict(float)\n    for k in p_k:\n        for v in x_range:\n            values[v] += p_k[k] * v**k\n\n    _values: float | _np.ndarray\n    if len(x_range) &gt; 1:\n        _values = _np.fromiter(values.values(), dtype=float)\n    else:\n        _values = values[x]\n    return _values\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_raw_moment","title":"<code>degree_raw_moment</code>","text":"<p>Calculates the k-th raw moment of the degree distribution of a network</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph in which to calculate the k-th raw moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_raw_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th raw moment of the degree distribution of a network\n\n    Args:\n        graph:  The graph in which to calculate the k-th raw moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mom = 0.0\n    for x in p_k:\n        mom += x**k * p_k[x]\n    return mom\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_sequence","title":"<code>degree_sequence</code>","text":"<p>Calculates the degree sequence of an undirected network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <p>The <code>Graph</code> object for which degrees are calculated</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_sequence(g: Graph, mode: str = \"total\") -&gt; _np.array:\n    \"\"\"Calculates the degree sequence of an undirected network.\n\n    Args:\n        graph: The `Graph` object for which degrees are calculated\n    \"\"\"\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n\n    _degrees = _np.zeros(g.n, dtype=float)\n    for v in g.nodes:\n        _degrees[g.mapping.to_idx(v)] = d[v]\n    return _degrees\n</code></pre>"},{"location":"reference/pathpyG/statistics/node_similarities/","title":"node_similarities","text":""},{"location":"reference/pathpyG/utils/","title":"utils","text":""},{"location":"reference/pathpyG/utils/config/","title":"config","text":""},{"location":"reference/pathpyG/utils/convert/","title":"convert","text":"<p>Utility functions for converting between different data types.</p>"},{"location":"reference/pathpyG/utils/convert/#pathpyG.utils.convert.to_numpy","title":"<code>to_numpy</code>","text":"<p>Convert a tensor or tensor subclasses like <code>torch_geometric.Edge_Index</code> to numpy.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>torch.Tensor</code> <p>Tensor or tensor subclass.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Numpy array.</p> Source code in <code>src/pathpyG/utils/convert.py</code> <pre><code>def to_numpy(tensor: torch.Tensor) -&gt; np.ndarray:\n    \"\"\"\n    Convert a tensor or tensor subclasses like `torch_geometric.Edge_Index` to numpy.\n\n    Args:\n        tensor: Tensor or tensor subclass.\n\n    Returns:\n        Numpy array.\n    \"\"\"\n    if isinstance(tensor, (EdgeIndex, Index)):\n        return tensor.as_tensor().numpy()\n    return tensor.numpy()\n</code></pre>"},{"location":"reference/pathpyG/utils/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/utils/dbgnn/#pathpyG.utils.dbgnn.generate_bipartite_edge_index","title":"<code>generate_bipartite_edge_index</code>","text":"<p>Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.</p> Source code in <code>src/pathpyG/utils/dbgnn.py</code> <pre><code>def generate_bipartite_edge_index(g: Graph, g2: Graph, mapping: str = \"last\") -&gt; torch.Tensor:\n    \"\"\"Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.\"\"\"\n\n    if mapping == \"last\":\n        bipartide_edge_index = torch.tensor([list(range(g2.n)), [v[1] for v in g2.data.node_sequence]])\n\n    elif mapping == \"first\":\n        bipartide_edge_index = torch.tensor([list(range(g2.n)), [v[0] for v in g2.data.node_sequence]])\n    else:\n        bipartide_edge_index = torch.tensor(\n            [\n                list(range(g2.n)) + list(range(g2.n)),\n                [v[0] for v in g2.data.node_sequence] + [v[1] for v in g2.data.node_sequence],\n            ]\n        )\n\n    return bipartide_edge_index\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/","title":"progress","text":"<p>Progressbar for pathpy.</p>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_console","title":"<code>tqdm_console</code>","text":"<p>Progressbar for a console environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_console(*args, **kwargs):\n    \"\"\"Progressbar for a console environment.\"\"\"\n    if len(args[0]) &gt; config[\"progress\"][\"min_iter\"]:\n        return tq(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_disabled","title":"<code>tqdm_disabled</code>","text":"<p>Disable the progress bar and return initial iterator.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_disabled(it, *args, **kwargs):\n    \"\"\"Disable the progress bar and return initial iterator.\"\"\"\n    return it\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_notebook","title":"<code>tqdm_notebook</code>","text":"<p>Progressbar for a notebook environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_notebook(*args, **kwargs):\n    \"\"\"Progressbar for a notebook environment.\"\"\"\n    if len(args[0]) &gt; config[\"progress\"][\"min_iter\"]:\n        return tqn(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/visualisations/","title":"visualisations","text":"<p>PathpyG visualizations.</p>"},{"location":"reference/pathpyG/visualisations/hist_plots/","title":"hist_plots","text":"<p>Histogram plot classes.</p>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.HistogramPlot","title":"<code>HistogramPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Histogram plot class for a network property.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>class HistogramPlot(PathPyPlot):\n    \"\"\"Histogram plot class for a network property.\"\"\"\n\n    _kind = \"hist\"\n\n    def __init__(self, network: Graph, key: str = \"indegrees\", bins: int = 10, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.config[\"bins\"] = bins\n        self.config[\"key\"] = key\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n\n        data: dict = {}\n\n        match self.config[\"key\"]:\n            case \"indegrees\":\n                logger.debug(\"Generate data for in-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n            case \"outdegrees\":\n                logger.debug(\"Generate data for out-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n            case _:\n                logger.error(\n                    f\"The &lt;{self.config['key']}&gt; property\",\n                    \"is currently not supported for hist plots.\",\n                )\n                raise KeyError\n\n        data[\"title\"] = self.config[\"key\"]\n        self.data[\"data\"] = data\n</code></pre>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.HistogramPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>def __init__(self, network: Graph, key: str = \"indegrees\", bins: int = 10, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.network = network\n    self.config = kwargs\n    self.config[\"bins\"] = bins\n    self.config[\"key\"] = key\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.HistogramPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    logger.debug(\"Generate histogram.\")\n\n    data: dict = {}\n\n    match self.config[\"key\"]:\n        case \"indegrees\":\n            logger.debug(\"Generate data for in-degrees\")\n            data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n        case \"outdegrees\":\n            logger.debug(\"Generate data for out-degrees\")\n            data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n        case _:\n            logger.error(\n                f\"The &lt;{self.config['key']}&gt; property\",\n                \"is currently not supported for hist plots.\",\n            )\n            raise KeyError\n\n    data[\"title\"] = self.config[\"key\"]\n    self.data[\"data\"] = data\n</code></pre>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.hist","title":"<code>hist</code>","text":"<p>Plot a histogram.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>def hist(network: Graph, key: str = \"indegrees\", bins: int = 10, **kwargs: Any) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/","title":"layout","text":""},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout","title":"<code>Layout</code>","text":"<p>               Bases: <code>object</code></p> <p>Default class to create layouts</p> <p>The <code>Layout</code> class is used to generate node a layout drawer and return the calculated node positions as a dictionary, where the keywords represents the node ids and the values represents a two dimensional tuple with the x and y coordinates for the associated nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>list with node ids. The list contain a list of unique node ids.</p> required <code>**attr</code> <code>dict</code> <p>Attributes to add to node as key=value pairs. See also <code>layout</code></p> <code>{}</code> See also <p><code>layout</code></p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>class Layout(object):\n    \"\"\"Default class to create layouts\n\n    The [`Layout`][pathpyG.visualisations.layout.Layout] class is used to generate node a layout drawer and\n    return the calculated node positions as a dictionary, where the keywords\n    represents the node ids and the values represents a two dimensional tuple\n    with the x and y coordinates for the associated nodes.\n\n    Args:\n        nodes (list): list with node ids.\n            The list contain a list of unique node ids.\n        **attr (dict): Attributes to add to node as key=value pairs.\n            See also [`layout`][pathpyG.visualisations.layout.layout]\n\n    Note: See also\n        [`layout`][pathpyG.visualisations.layout.layout]\n    \"\"\"\n\n    def __init__(self, nodes, adjacency_matrix, **attr):\n        \"\"\"Initialize the Layout class\n\n        The [`Layout`][pathpyG.visualisations.layout.Layout] class is used to generate node a layout drawer and\n        return the calculated node positions as a dictionary, where the keywords\n        represents the node ids and the values represents a two dimensional tuple\n        with the x and y coordinates for the associated nodes.\n\n        Args:\n            nodes (list): list with node ids.\n                The list contain a list of unique node ids.\n            **attr (dict): Attributes to add to node as key=value pairs.\n                See also [`layout`][pathpyG.visualisations.layout.layout]\n        \"\"\"\n\n        # initialize variables\n        self.nodes = nodes\n        self.adjacency_matrix = adjacency_matrix\n\n        # rename the attributes\n        attr = self.rename_attributes(**attr)\n\n        # options for the layouts\n        self.layout_type = attr.get(\"layout\", None)\n        self.k = attr.get(\n            \"force\",\n            None,\n        )\n        self.fixed = attr.get(\"fixed\", None)\n        self.iterations = attr.get(\"iterations\", 50)\n        self.threshold = attr.get(\"threshold\", 1e-4)\n        self.weight = attr.get(\"weight\", None)\n        self.dimension = attr.get(\"dimension\", 2)\n        self.seed = attr.get(\"seed\", None)\n        self.positions = attr.get(\"positions\", None)\n        self.radius = attr.get(\"radius\", 1.0)\n        self.direction = attr.get(\"direction\", 1.0)\n        self.start_angle = attr.get(\"start_angle\", 0.0)\n\n        # TODO: allow also higher dimensional layouts\n        if self.dimension &gt; 2:\n            print(\"Currently only plots with maximum dimension 2 are supported!\")\n            self.dimension = 2\n\n    @staticmethod\n    def rename_attributes(**kwds):\n        \"\"\"Rename layout attributes.\n\n        In the style dictionary multiple keywords can be used to address\n        attributes. These keywords will be converted to an unique key word,\n        used in the remaining code.\n\n        | keys | other valid keys |\n        | ---- | ---------------- |\n        | fixed | `fixed_nodes`, `fixed_vertices`, `fixed_n`, `fixed_v` |\n        | positions | `initial_positions`, `node_positions` `vertex_positions`, `n_positions`, `v_positions` |\n        \"\"\"\n        names = {\n            \"fixed\": [\"fixed_nodes\", \"fixed_vertices\", \"fixed_v\", \"fixed_n\"],\n            \"positions\": [\"initial_positions\", \"node_positions\", \"vertex_positions\", \"n_positions\", \"v_positions\"],\n            \"layout_\": [\"layout_\"],\n        }\n\n        _kwds = {}\n        del_keys = []\n        for key, value in kwds.items():\n            for attr, name_list in names.items():\n                for name in name_list:\n                    if name in key and name[0] == key[0]:\n                        _kwds[key.replace(name, attr).replace(\"layout_\", \"\")] = value\n                        del_keys.append(key)\n                        break\n        # remove the replaced keys from the dict\n        for key in del_keys:\n            del kwds[key]\n\n        return {**_kwds, **kwds}\n\n    def generate_layout(self):\n        \"\"\"Function to pick and generate the right layout.\"\"\"\n        # method names\n        names_rand = [\"Random\", \"random\", \"rand\", None]\n        names_fr = [\"Fruchterman-Reingold\", \"fruchterman_reingold\", \"fr\", \"spring_layout\", \"spring layout\", \"FR\"]\n        names_circular = [\"circular\", \"circle\", \"ring\", \"1d-lattice\", \"lattice-1d\"]\n        names_grid = [\"grid\", \"2d-lattice\", \"lattice-2d\"]\n        # check which layout should be plotted\n        if self.layout_type in names_rand:\n            self.layout = self.random()\n        elif self.layout_type in names_circular or (self.layout_type == \"lattice\" and self.dimension == 1):\n            self.layout = self.circular()\n        elif self.layout_type in names_grid or (self.layout_type == \"lattice\" and self.dimension == 2):\n            self.layout = self.grid()\n        elif self.layout_type in names_fr:\n            self.layout = self.fruchterman_reingold()\n\n        # print(self.layout)\n        return self.layout\n\n    def random(self):\n        \"\"\"Position nodes uniformly at random in the unit square.\n\n        For every node, a position is generated by choosing each of dimension\n        coordinates uniformly at random on the interval $[0.0, 1.0)$.\n\n        This algorithm can be enabled with the keywords: `Random`,\n        `random`, `rand`, or `None`\n\n        Keyword Args:\n            dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n            seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n                the seed used by the random number generator, if None, the a random\n                seed by created by the numpy random number generator is used.\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n        np.random.seed(self.seed)\n        layout = np.random.rand(len(self.nodes), self.dimension)\n        return dict(zip(self.nodes, layout))\n\n    def fruchterman_reingold(self):\n        \"\"\"Position nodes using Fruchterman-Reingold force-directed algorithm.\n\n        In this algorithm, the nodes are represented by steel rings and the\n        edges are springs between them. The attractive force is analogous to the\n        spring force and the repulsive force is analogous to the electrical\n        force. The basic idea is to minimize the energy of the system by moving\n        the nodes and changing the forces between them.\n\n        This algorithm can be enabled with the keywords: `Fruchterman-Reingold`,\n        `fruchterman_reingold`, `fr`, `spring_layout`, `spring layout`, `FR`\n\n        Keyword Args:\n            force (float): Optimal distance between nodes. If None the distance is set to\n                1/sqrt(n) where n is the number of nodes.  Increase this value to move\n                nodes farther apart.\n            positions (dict): Initial positions for nodes as a dictionary with node as keys and values\n                as a coordinate list or tuple.  If None, then use random initial\n                positions.\n            fixed (list): Nodes to keep fixed at initial position.\n            iterations (int): Maximum number of iterations taken. Defaults to 50.\n            threshold (float): Threshold for relative error in node position changes.  The iteration\n                stops if the error is below this threshold. Defaults to 1e-4.\n            weight (string): The edge attribute that holds the numerical value used for the edge\n                weight.  If None, then all edge weights are 1.\n            dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n            seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n                the seed used by the random number generator, if None, the a random seed\n                by created by the numpy random number generator is used.\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n\n        # convert adjacency matrix\n        self.adjacency_matrix = self.adjacency_matrix.astype(float)\n\n        if self.fixed is not None:\n            self.fixed = np.asarray([self.nodes.index(v) for v in self.fixed])\n\n        if self.positions is not None:\n            # Determine size of existing domain to adjust initial positions\n            _size = max(coord for t in layout.values() for coord in t)  # type: ignore\n            if _size == 0:\n                _size = 1\n            np.random.seed(self.seed)\n            self.layout = np.random.rand(len(self.nodes), self.dimension) * _size  # type: ignore\n\n            for i, n in enumerate(self.nodes):\n                if n in self.positions:\n                    self.layout[i] = np.asarray(self.positions[n])\n        else:\n            self.layout = None\n            _size = 0\n\n        if self.k is None and self.fixed is not None:\n            # We must adjust k by domain size for layouts not near 1x1\n            self.k = _size / np.sqrt(len(self.nodes))\n\n        try:\n            # Sparse matrix\n            if len(self.nodes) &lt; 500:  # sparse solver for large graphs\n                raise ValueError\n            layout = self._sparse_fruchterman_reingold()\n        except:\n            layout = self._fruchterman_reingold()\n\n        layout = dict(zip(self.nodes, layout))\n\n        return layout\n\n    def _fruchterman_reingold(self):\n        \"\"\"Fruchterman-Reingold algorithm for dense matrices.\n\n        This algorithm is based on the Fruchterman-Reingold algorithm provided\n        by `networkx`. (Copyright (C) 2004-2018 by Aric Hagberg &lt;hagberg@lanl.gov&gt;\n        Dan Schult &lt;dschult@colgate.edu&gt; Pieter Swart &lt;swart@lanl.gov&gt; Richard\n        Penney &lt;rwpenney@users.sourceforge.net&gt; All rights reserved. BSD\n        license.)\n\n        \"\"\"\n        A = self.adjacency_matrix.todense()\n        k = self.k\n        try:\n            _n, _ = A.shape\n        except AttributeError:\n            print(\"Fruchterman-Reingold algorithm needs an adjacency matrix as input\")\n            raise AttributeError\n\n        # make sure we have an array instead of a matrix\n        A = np.asarray(A)\n\n        if self.layout is None:\n            # random initial positions\n            np.random.seed(self.seed)\n            layout = np.asarray(np.random.rand(_n, self.dimension), dtype=A.dtype)\n        else:\n            # make sure positions are of same type as matrix\n            layout = self.layout.astype(A.dtype)  # type: ignore\n\n        # optimal distance between nodes\n        if k is None:\n            k = np.sqrt(1.0 / _n)\n        # the initial \"temperature\"  is about .1 of domain area (=1x1)\n        # this is the largest step allowed in the dynamics.\n        # We need to calculate this in case our fixed positions force our domain\n        # to be much bigger than 1x1\n        t = max(max(layout.T[0]) - min(layout.T[0]), max(layout.T[1]) - min(layout.T[1])) * 0.1\n        # simple cooling scheme.\n        # linearly step down by dt on each iteration so last iteration is size dt.\n        dt = t / float(self.iterations + 1)\n        delta = np.zeros((layout.shape[0], layout.shape[0], layout.shape[1]), dtype=A.dtype)\n        # the inscrutable (but fast) version\n        # this is still O(V^2)\n        # could use multilevel methods to speed this up significantly\n        for iteration in tqdm(range(self.iterations), desc=\"Calculating Fruchterman-Reingold layout\"):\n            # matrix of difference between points\n            delta = layout[:, np.newaxis, :] - layout[np.newaxis, :, :]  # type: ignore\n            # distance between points\n            distance = np.linalg.norm(delta, axis=-1)\n            # enforce minimum distance of 0.01\n            np.clip(distance, 0.01, None, out=distance)\n            # displacement \"force\"\n            displacement = np.einsum(\"ijk,ij-&gt;ik\", delta, (k * k / distance**2 - A * distance / k))\n            # update layoutitions\n            length = np.linalg.norm(displacement, axis=-1)\n            length = np.where(length &lt; 0.01, 0.1, length)\n            delta_layout = np.einsum(\"ij,i-&gt;ij\", displacement, t / length)\n            if self.fixed is not None:\n                # don't change positions of fixed nodes\n                delta_layout[self.fixed] = 0.0\n            layout += delta_layout\n            # cool temperature\n            t -= dt\n            error = np.linalg.norm(delta_layout) / _n\n            if error &lt; self.threshold:\n                break\n        return layout\n\n    def _sparse_fruchterman_reingold(self):\n        \"\"\"Fruchterman-Reingold algorithm for sparse matrices.\n\n        This algorithm is based on the Fruchterman-Reingold algorithm provided\n        by networkx. (Copyright (C) 2004-2018 by Aric Hagberg &lt;hagberg@lanl.gov&gt;\n        Dan Schult &lt;dschult@colgate.edu&gt; Pieter Swart &lt;swart@lanl.gov&gt; Richard\n        Penney &lt;rwpenney@users.sourceforge.net&gt; All rights reserved. BSD\n        license.)\n\n        \"\"\"\n        A = self.adjacency_matrix\n        k = self.k\n        try:\n            _n, _ = A.shape\n        except AttributeError:\n            print(\"Fruchterman-Reingold algorithm needs an adjacency \" \"matrix as input\")\n            raise AttributeError\n        try:\n            from scipy.sparse import spdiags, coo_matrix\n        except ImportError:\n            print(\"The sparse Fruchterman-Reingold algorithm needs the \" \"scipy package: http://scipy.org/\")\n            raise ImportError\n        # make sure we have a LIst of Lists representation\n        try:\n            A = A.tolil()\n        except:\n            A = (coo_matrix(A)).tolil()\n\n        if self.layout is None:\n            # random initial positions\n            np.random.seed(self.seed)\n            layout = np.asarray(np.random.rand(_n, self.dimension), dtype=A.dtype)\n        else:\n            # make sure positions are of same type as matrix\n            layout = layout.astype(A.dtype)  # type: ignore\n\n        # no fixed nodes\n        if self.fixed is None:\n            self.fixed = []\n\n        # optimal distance between nodes\n        if k is None:\n            k = np.sqrt(1.0 / _n)\n        # the initial \"temperature\"  is about .1 of domain area (=1x1)\n        # this is the largest step allowed in the dynamics.\n        t = max(max(layout.T[0]) - min(layout.T[0]), max(layout.T[1]) - min(layout.T[1])) * 0.1\n        # simple cooling scheme.\n        # linearly step down by dt on each iteration so last iteration is size dt.\n        dt = t / float(self.iterations + 1)\n\n        displacement = np.zeros((self.dimension, _n))\n        for iteration in range(self.iterations):\n            displacement *= 0\n            # loop over rows\n            for i in range(A.shape[0]):\n                if i in self.fixed:\n                    continue\n                # difference between this row's node position and all others\n                delta = (layout[i] - layout).T\n                # distance between points\n                distance = np.sqrt((delta**2).sum(axis=0))\n                # enforce minimum distance of 0.01\n                distance = np.where(distance &lt; 0.01, 0.01, distance)\n                # the adjacency matrix row\n                Ai = np.asarray(A.getrowview(i).toarray())\n                # displacement \"force\"\n                displacement[:, i] += (delta * (k * k / distance**2 - Ai * distance / k)).sum(axis=1)\n            # update positions\n            length = np.sqrt((displacement**2).sum(axis=0))\n            length = np.where(length &lt; 0.01, 0.1, length)\n            delta_layout = (displacement * t / length).T\n            layout += delta_layout\n            # cool temperature\n            t -= dt\n            err = np.linalg.norm(delta_layout) / _n\n            if err &lt; self.threshold:\n                break\n        return layout\n\n    def circular(self):\n        \"\"\"Position nodes on a circle with given radius.\n\n        This algorithm can be enabled with the keywords: `circular`, `circle`, `ring`, `lattice-1d`, `1d-lattice`, `lattice`\n\n        Keyword Args:\n            radius (float): Sets the radius of the circle on which nodes\n                are positioned. Defaults to 1.0.\n            direction (float): Sets the direction in which nodes are placed on the circle. 1.0 for clockwise (default)\n                and -1.0 for counter-clockwise direction. Defaults to 1.0.\n            start_angle (float): Sets the angle of the first node relative to the 3pm position on a clock.\n                and -1.0 for counter-clockwise direction. Defaults to 90.0.\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n\n        n = len(self.nodes)\n        rad = 2.0 * np.pi / n\n        rotation = (90.0 - self.start_angle * self.direction) * np.pi / 180.0\n        layout = {}\n\n        for i in range(n):\n            x = self.radius * np.cos(rotation - i * rad * self.direction)\n            y = self.radius * np.sin(rotation - i * rad * self.direction)\n            layout[self.nodes[i]] = (x, y)\n\n        return layout\n\n    def grid(self):\n        \"\"\"Position nodes on a two-dimensional grid\n\n        This algorithm can be enabled with the keywords: `grid`, `lattice-2d`, `2d-lattice`, `lattice`\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n\n        n = len(self.nodes)\n        width = 1.0\n\n        # number of nodes in horizontal/vertical direction\n        k = np.floor(np.sqrt(n))\n        dist = width / k\n        layout = {}\n\n        i = 0\n        for i in range(n):\n            layout[self.nodes[i]] = ((i % k) * dist, -(np.floor(i / k)) * dist)\n            i += 1\n\n        return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.__init__","title":"<code>__init__</code>","text":"<p>Initialize the Layout class</p> <p>The <code>Layout</code> class is used to generate node a layout drawer and return the calculated node positions as a dictionary, where the keywords represents the node ids and the values represents a two dimensional tuple with the x and y coordinates for the associated nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>list with node ids. The list contain a list of unique node ids.</p> required <code>**attr</code> <code>dict</code> <p>Attributes to add to node as key=value pairs. See also <code>layout</code></p> <code>{}</code> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def __init__(self, nodes, adjacency_matrix, **attr):\n    \"\"\"Initialize the Layout class\n\n    The [`Layout`][pathpyG.visualisations.layout.Layout] class is used to generate node a layout drawer and\n    return the calculated node positions as a dictionary, where the keywords\n    represents the node ids and the values represents a two dimensional tuple\n    with the x and y coordinates for the associated nodes.\n\n    Args:\n        nodes (list): list with node ids.\n            The list contain a list of unique node ids.\n        **attr (dict): Attributes to add to node as key=value pairs.\n            See also [`layout`][pathpyG.visualisations.layout.layout]\n    \"\"\"\n\n    # initialize variables\n    self.nodes = nodes\n    self.adjacency_matrix = adjacency_matrix\n\n    # rename the attributes\n    attr = self.rename_attributes(**attr)\n\n    # options for the layouts\n    self.layout_type = attr.get(\"layout\", None)\n    self.k = attr.get(\n        \"force\",\n        None,\n    )\n    self.fixed = attr.get(\"fixed\", None)\n    self.iterations = attr.get(\"iterations\", 50)\n    self.threshold = attr.get(\"threshold\", 1e-4)\n    self.weight = attr.get(\"weight\", None)\n    self.dimension = attr.get(\"dimension\", 2)\n    self.seed = attr.get(\"seed\", None)\n    self.positions = attr.get(\"positions\", None)\n    self.radius = attr.get(\"radius\", 1.0)\n    self.direction = attr.get(\"direction\", 1.0)\n    self.start_angle = attr.get(\"start_angle\", 0.0)\n\n    # TODO: allow also higher dimensional layouts\n    if self.dimension &gt; 2:\n        print(\"Currently only plots with maximum dimension 2 are supported!\")\n        self.dimension = 2\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.circular","title":"<code>circular</code>","text":"<p>Position nodes on a circle with given radius.</p> <p>This algorithm can be enabled with the keywords: <code>circular</code>, <code>circle</code>, <code>ring</code>, <code>lattice-1d</code>, <code>1d-lattice</code>, <code>lattice</code></p> <p>Other Parameters:</p> Name Type Description <code>radius</code> <code>float</code> <p>Sets the radius of the circle on which nodes are positioned. Defaults to 1.0.</p> <code>direction</code> <code>float</code> <p>Sets the direction in which nodes are placed on the circle. 1.0 for clockwise (default) and -1.0 for counter-clockwise direction. Defaults to 1.0.</p> <code>start_angle</code> <code>float</code> <p>Sets the angle of the first node relative to the 3pm position on a clock. and -1.0 for counter-clockwise direction. Defaults to 90.0.</p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def circular(self):\n    \"\"\"Position nodes on a circle with given radius.\n\n    This algorithm can be enabled with the keywords: `circular`, `circle`, `ring`, `lattice-1d`, `1d-lattice`, `lattice`\n\n    Keyword Args:\n        radius (float): Sets the radius of the circle on which nodes\n            are positioned. Defaults to 1.0.\n        direction (float): Sets the direction in which nodes are placed on the circle. 1.0 for clockwise (default)\n            and -1.0 for counter-clockwise direction. Defaults to 1.0.\n        start_angle (float): Sets the angle of the first node relative to the 3pm position on a clock.\n            and -1.0 for counter-clockwise direction. Defaults to 90.0.\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n\n    n = len(self.nodes)\n    rad = 2.0 * np.pi / n\n    rotation = (90.0 - self.start_angle * self.direction) * np.pi / 180.0\n    layout = {}\n\n    for i in range(n):\n        x = self.radius * np.cos(rotation - i * rad * self.direction)\n        y = self.radius * np.sin(rotation - i * rad * self.direction)\n        layout[self.nodes[i]] = (x, y)\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.fruchterman_reingold","title":"<code>fruchterman_reingold</code>","text":"<p>Position nodes using Fruchterman-Reingold force-directed algorithm.</p> <p>In this algorithm, the nodes are represented by steel rings and the edges are springs between them. The attractive force is analogous to the spring force and the repulsive force is analogous to the electrical force. The basic idea is to minimize the energy of the system by moving the nodes and changing the forces between them.</p> <p>This algorithm can be enabled with the keywords: <code>Fruchterman-Reingold</code>, <code>fruchterman_reingold</code>, <code>fr</code>, <code>spring_layout</code>, <code>spring layout</code>, <code>FR</code></p> <p>Other Parameters:</p> Name Type Description <code>force</code> <code>float</code> <p>Optimal distance between nodes. If None the distance is set to 1/sqrt(n) where n is the number of nodes.  Increase this value to move nodes farther apart.</p> <code>positions</code> <code>dict</code> <p>Initial positions for nodes as a dictionary with node as keys and values as a coordinate list or tuple.  If None, then use random initial positions.</p> <code>fixed</code> <code>list</code> <p>Nodes to keep fixed at initial position.</p> <code>iterations</code> <code>int</code> <p>Maximum number of iterations taken. Defaults to 50.</p> <code>threshold</code> <code>float</code> <p>Threshold for relative error in node position changes.  The iteration stops if the error is below this threshold. Defaults to 1e-4.</p> <code>weight</code> <code>string</code> <p>The edge attribute that holds the numerical value used for the edge weight.  If None, then all edge weights are 1.</p> <code>dimension</code> <code>int</code> <p>Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.</p> <code>seed</code> <code>int</code> <p>Set the random state for deterministic node layouts. If int, <code>seed</code> is the seed used by the random number generator, if None, the a random seed by created by the numpy random number generator is used.</p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def fruchterman_reingold(self):\n    \"\"\"Position nodes using Fruchterman-Reingold force-directed algorithm.\n\n    In this algorithm, the nodes are represented by steel rings and the\n    edges are springs between them. The attractive force is analogous to the\n    spring force and the repulsive force is analogous to the electrical\n    force. The basic idea is to minimize the energy of the system by moving\n    the nodes and changing the forces between them.\n\n    This algorithm can be enabled with the keywords: `Fruchterman-Reingold`,\n    `fruchterman_reingold`, `fr`, `spring_layout`, `spring layout`, `FR`\n\n    Keyword Args:\n        force (float): Optimal distance between nodes. If None the distance is set to\n            1/sqrt(n) where n is the number of nodes.  Increase this value to move\n            nodes farther apart.\n        positions (dict): Initial positions for nodes as a dictionary with node as keys and values\n            as a coordinate list or tuple.  If None, then use random initial\n            positions.\n        fixed (list): Nodes to keep fixed at initial position.\n        iterations (int): Maximum number of iterations taken. Defaults to 50.\n        threshold (float): Threshold for relative error in node position changes.  The iteration\n            stops if the error is below this threshold. Defaults to 1e-4.\n        weight (string): The edge attribute that holds the numerical value used for the edge\n            weight.  If None, then all edge weights are 1.\n        dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n        seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n            the seed used by the random number generator, if None, the a random seed\n            by created by the numpy random number generator is used.\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n\n    # convert adjacency matrix\n    self.adjacency_matrix = self.adjacency_matrix.astype(float)\n\n    if self.fixed is not None:\n        self.fixed = np.asarray([self.nodes.index(v) for v in self.fixed])\n\n    if self.positions is not None:\n        # Determine size of existing domain to adjust initial positions\n        _size = max(coord for t in layout.values() for coord in t)  # type: ignore\n        if _size == 0:\n            _size = 1\n        np.random.seed(self.seed)\n        self.layout = np.random.rand(len(self.nodes), self.dimension) * _size  # type: ignore\n\n        for i, n in enumerate(self.nodes):\n            if n in self.positions:\n                self.layout[i] = np.asarray(self.positions[n])\n    else:\n        self.layout = None\n        _size = 0\n\n    if self.k is None and self.fixed is not None:\n        # We must adjust k by domain size for layouts not near 1x1\n        self.k = _size / np.sqrt(len(self.nodes))\n\n    try:\n        # Sparse matrix\n        if len(self.nodes) &lt; 500:  # sparse solver for large graphs\n            raise ValueError\n        layout = self._sparse_fruchterman_reingold()\n    except:\n        layout = self._fruchterman_reingold()\n\n    layout = dict(zip(self.nodes, layout))\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.generate_layout","title":"<code>generate_layout</code>","text":"<p>Function to pick and generate the right layout.</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def generate_layout(self):\n    \"\"\"Function to pick and generate the right layout.\"\"\"\n    # method names\n    names_rand = [\"Random\", \"random\", \"rand\", None]\n    names_fr = [\"Fruchterman-Reingold\", \"fruchterman_reingold\", \"fr\", \"spring_layout\", \"spring layout\", \"FR\"]\n    names_circular = [\"circular\", \"circle\", \"ring\", \"1d-lattice\", \"lattice-1d\"]\n    names_grid = [\"grid\", \"2d-lattice\", \"lattice-2d\"]\n    # check which layout should be plotted\n    if self.layout_type in names_rand:\n        self.layout = self.random()\n    elif self.layout_type in names_circular or (self.layout_type == \"lattice\" and self.dimension == 1):\n        self.layout = self.circular()\n    elif self.layout_type in names_grid or (self.layout_type == \"lattice\" and self.dimension == 2):\n        self.layout = self.grid()\n    elif self.layout_type in names_fr:\n        self.layout = self.fruchterman_reingold()\n\n    # print(self.layout)\n    return self.layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.grid","title":"<code>grid</code>","text":"<p>Position nodes on a two-dimensional grid</p> <p>This algorithm can be enabled with the keywords: <code>grid</code>, <code>lattice-2d</code>, <code>2d-lattice</code>, <code>lattice</code></p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def grid(self):\n    \"\"\"Position nodes on a two-dimensional grid\n\n    This algorithm can be enabled with the keywords: `grid`, `lattice-2d`, `2d-lattice`, `lattice`\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n\n    n = len(self.nodes)\n    width = 1.0\n\n    # number of nodes in horizontal/vertical direction\n    k = np.floor(np.sqrt(n))\n    dist = width / k\n    layout = {}\n\n    i = 0\n    for i in range(n):\n        layout[self.nodes[i]] = ((i % k) * dist, -(np.floor(i / k)) * dist)\n        i += 1\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.random","title":"<code>random</code>","text":"<p>Position nodes uniformly at random in the unit square.</p> <p>For every node, a position is generated by choosing each of dimension coordinates uniformly at random on the interval \\([0.0, 1.0)\\).</p> <p>This algorithm can be enabled with the keywords: <code>Random</code>, <code>random</code>, <code>rand</code>, or <code>None</code></p> <p>Other Parameters:</p> Name Type Description <code>dimension</code> <code>int</code> <p>Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.</p> <code>seed</code> <code>int</code> <p>Set the random state for deterministic node layouts. If int, <code>seed</code> is the seed used by the random number generator, if None, the a random seed by created by the numpy random number generator is used.</p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def random(self):\n    \"\"\"Position nodes uniformly at random in the unit square.\n\n    For every node, a position is generated by choosing each of dimension\n    coordinates uniformly at random on the interval $[0.0, 1.0)$.\n\n    This algorithm can be enabled with the keywords: `Random`,\n    `random`, `rand`, or `None`\n\n    Keyword Args:\n        dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n        seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n            the seed used by the random number generator, if None, the a random\n            seed by created by the numpy random number generator is used.\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n    np.random.seed(self.seed)\n    layout = np.random.rand(len(self.nodes), self.dimension)\n    return dict(zip(self.nodes, layout))\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.rename_attributes","title":"<code>rename_attributes</code>  <code>staticmethod</code>","text":"<p>Rename layout attributes.</p> <p>In the style dictionary multiple keywords can be used to address attributes. These keywords will be converted to an unique key word, used in the remaining code.</p> keys other valid keys fixed <code>fixed_nodes</code>, <code>fixed_vertices</code>, <code>fixed_n</code>, <code>fixed_v</code> positions <code>initial_positions</code>, <code>node_positions</code> <code>vertex_positions</code>, <code>n_positions</code>, <code>v_positions</code> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>@staticmethod\ndef rename_attributes(**kwds):\n    \"\"\"Rename layout attributes.\n\n    In the style dictionary multiple keywords can be used to address\n    attributes. These keywords will be converted to an unique key word,\n    used in the remaining code.\n\n    | keys | other valid keys |\n    | ---- | ---------------- |\n    | fixed | `fixed_nodes`, `fixed_vertices`, `fixed_n`, `fixed_v` |\n    | positions | `initial_positions`, `node_positions` `vertex_positions`, `n_positions`, `v_positions` |\n    \"\"\"\n    names = {\n        \"fixed\": [\"fixed_nodes\", \"fixed_vertices\", \"fixed_v\", \"fixed_n\"],\n        \"positions\": [\"initial_positions\", \"node_positions\", \"vertex_positions\", \"n_positions\", \"v_positions\"],\n        \"layout_\": [\"layout_\"],\n    }\n\n    _kwds = {}\n    del_keys = []\n    for key, value in kwds.items():\n        for attr, name_list in names.items():\n            for name in name_list:\n                if name in key and name[0] == key[0]:\n                    _kwds[key.replace(name, attr).replace(\"layout_\", \"\")] = value\n                    del_keys.append(key)\n                    break\n    # remove the replaced keys from the dict\n    for key in del_keys:\n        del kwds[key]\n\n    return {**_kwds, **kwds}\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.layout","title":"<code>layout</code>","text":"<p>Function to generate a layout for the network.</p> <p>This function generates a layout configuration for the nodes in the network. Thereby, different layouts and options can be chosen. The layout function is directly included in the plot function or can be separately called.</p> <p>The layout function supports different network types and layout algorithm. Currently supported networks are:</p> <ul> <li><code>cnet</code>,</li> <li><code>networkx</code>,</li> <li><code>igraph</code>,</li> <li><code>pathpyG</code></li> <li>node/edge list</li> </ul> <p>Currently supported algorithms are:</p> <ul> <li>Fruchterman-Reingold force-directed algorithm</li> <li>Uniformly at random node positions</li> </ul> <p>The appearance of the layout can be modified by keyword arguments which will be explained in more detail below.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>network object</code> <p>Network to be drawn. The network can be a <code>cnet</code>, <code>networkx</code>, <code>igraph</code>, <code>pathpy</code> object, or a tuple of a node list and edge list.</p> required <code>**kwds</code> <code>Optional dict</code> <p>Attributes used to modify the appearance of the layout. For details see below.</p> <code>{}</code>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.layout--layout","title":"Layout:","text":"<p>The layout can be modified by the following keyword arguments: Note:     All layout arguments can be entered with or without <code>layout_</code> at the beginning, e.g. <code>layout_iterations</code> is equal to <code>iterations</code></p> <p>Other Parameters:</p> Name Type Description <code>layout</code> <code>Optional dict or string</code> <p>A dictionary with the node positions on a 2-dimensional plane. The key value of the dict represents the node id while the value represents a tuple of coordinates (e.g. \\(n = (x,y)\\)). The initial layout can be placed anywhere on the 2-dimensional plane.</p> <p>Instead of a dictionary, the algorithm used for the layout can be defined via a string value. Currently, supported are:</p> <ul> <li>Random layout, where the nodes are uniformly at random placed in the     unit square.</li> <li>Fruchterman-Reingold force-directed algorithm. In this algorithm, the     nodes are represented by steel rings and the edges are springs between     them. The attractive force is analogous to the spring force and the     repulsive force is analogous to the electrical force. The basic idea is     to minimize the energy of the system by moving the nodes and changing     the forces between them.</li> </ul> <p>The algorithm can be enabled with the keywords: | Algorithms | Keywords | | ---------- | -------- | | Random | <code>Random</code>, <code>random</code>, <code>rand</code>, <code>None</code> | |Fruchterman-Reingold | <code>Fruchterman-Reingold</code>, <code>fruchterman_reingold</code>, <code>fr spring_layout</code>, <code>spring layout</code>, <code>FR</code> |</p> <code>force</code> <code>float</code> <p>Optimal distance between nodes.  If None the distance is set to 1/sqrt(n) where n is the number of nodes.  Increase this value to move nodes farther apart.</p> <code>positions</code> <code>dict</code> <p>Initial positions for nodes as a dictionary with node as keys and values as a coordinate list or tuple.  If None, then use random initial positions.</p> <code>fixed</code> <code>list</code> <p>Nodes to keep fixed at initial position.</p> <code>iterations</code> <code>int</code> <p>Maximum number of iterations taken. Defaults to 50.</p> <code>threshold</code> <code>float</code> <p>Threshold for relative error in node position changes.  The iteration stops if the error is below this threshold. Defaults to 1e-4.</p> <code>weight</code> <code>string</code> <p>or None, optional (default = None) The edge attribute that holds the numerical value used for the edge weight. If None, then all edge weights are 1.</p> <code>dimension</code> <code>int</code> <p>Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.</p> <code>seed</code> <code>int</code> <p>Set the random state for deterministic node layouts. If int, <code>seed</code> is the seed used by the random number generator, if None, the a random seed by created by the numpy random number generator is used.</p> <p>In the layout style dictionary multiple keywords can be used to address attributes. These keywords will be converted to an unique key word, used in the remaining code.</p> keys other valid keys fixed <code>fixed_nodes</code>, <code>fixed_vertices</code>, <code>fixed_n</code>, <code>fixed_v</code> positions <code>initial_positions</code>, <code>node_positions</code>, <code>vertex_positions</code>, <code>n_positions</code>, <code>v_positions</code> <p>Examples:</p> <p>For illustration purpose a similar network as in the <code>python-igraph</code> tutorial is used. Instead of <code>igraph</code>, the <code>cnet</code> module is used for creating the network.</p> <p>Create an empty network object, and add some edges.</p> <pre><code>&gt;&gt;&gt; net = Network(name = 'my tikz test network',directed=True)\n&gt;&gt;&gt; net.add_edges_from([('ab','a','b'), ('ac','a','c'), ('cd','c','d'),\n...                     ('de','d','e'), ('ec','e','c'), ('cf','c','f'),\n...                     ('fa','f','a'), ('fg','f','g'),('gg','g','g'),\n...                     ('gd','g','d')])\n</code></pre> <p>Now a layout can be generated:</p> <pre><code>&gt;&gt;&gt; layout(net)\n{'b': array([0.88878309, 0.15685131]), 'd': array([0.4659341 , 0.79839535]),\n'c': array([0.60386662, 0.40727962]), 'e': array([0.71073353, 0.65608203]),\n'g': array([0.42663927, 0.47412449]), 'f': array([0.48759769, 0.86787594]),\n'a': array([0.84154488, 0.1633732 ])}\n</code></pre> <p>Per default, the node positions are assigned uniform random. In order to create a layout, the layout methods of the packages can be used, or the position of the nodes can be directly assigned, in form of a dictionary, where the key is the <code>node_id</code> and the value is a tuple of the node position in \\(x\\) and \\(y\\).</p> <p>Let us generate a force directed layout (e.g. Fruchterman-Reingold):</p> <pre><code>&gt;&gt;&gt; layout(net, layout='fr')\n{'g': array([-0.77646408,  1.71291126]), 'c': array([-0.18639655,0.96232326]),\n'f': array([0.33394308, 0.93778681]), 'e': array([0.09740098, 1.28511973]),\n'a': array([1.37933158, 0.23171857]), 'b': array([ 2.93561876,-0.46183461]),\n'd': array([-0.29329793,  1.48971303])}\n</code></pre> <p>Note, instead of the command <code>fr</code> also the command <code>Fruchterman-Reingold</code> or any other command mentioned above can be used. For more information see table above.</p> <p>In order to keep the properties of the layout for your network separate from the network itself, you can simply set up a Python dictionary containing the keyword arguments you would pass to <code>layout</code> and then use the double asterisk (**) operator to pass your specific layout attributes to <code>layout</code>:</p> <pre><code>&gt;&gt;&gt; layout_style = {}\n&gt;&gt;&gt; layout_style['layout'] = 'Fruchterman-Reingold'\n&gt;&gt;&gt; layout_style['seed'] = 1\n&gt;&gt;&gt; layout_style['iterations'] = 100\n&gt;&gt;&gt; layout(net,**layout_style)\n{'d': array([-0.31778276, 1.78246882]), 'f': array([-0.8603259, 0.82328291]),\n'c': array([-0.4423771 , 1.21203895]), 'e': array([-0.79934355, 1.49000119]),\n'g': array([0.43694799, 1.51428788]), 'a': array([-2.15517293, 0.23948823]),\n'b': array([-3.84803812, -0.71628417])}\n</code></pre> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def layout(network, **kwds):\n    \"\"\"Function to generate a layout for the network.\n\n    This function generates a layout configuration for the nodes in the\n    network. Thereby, different layouts and options can be chosen. The layout\n    function is directly included in the plot function or can be separately\n    called.\n\n    The layout function supports different network types and layout algorithm.\n    Currently supported networks are:\n\n    - `cnet`,\n    - `networkx`,\n    - `igraph`,\n    - `pathpyG`\n    - node/edge list\n\n    Currently supported algorithms are:\n\n    - Fruchterman-Reingold force-directed algorithm\n    - Uniformly at random node positions\n\n    The appearance of the layout can be modified by keyword arguments which will\n    be explained in more detail below.\n\n    Args:\n        network (network object): Network to be drawn. The network can be a `cnet`, `networkx`, `igraph`, `pathpy` object, or a tuple of a node list and edge list.\n        **kwds (Optional dict): Attributes used to modify the appearance of the layout. For details see below.\n\n    # Layout:\n\n    The layout can be modified by the following keyword arguments:\n    Note:\n        All layout arguments can be entered with or without `layout_` at the beginning, e.g. `layout_iterations` is equal to `iterations`\n\n    Keyword Args:\n        layout (Optional dict or string): A dictionary with the node positions on a 2-dimensional plane. The\n            key value of the dict represents the node id while the value\n            represents a tuple of coordinates (e.g. $n = (x,y)$). The initial\n            layout can be placed anywhere on the 2-dimensional plane.\n\n            Instead of a dictionary, the algorithm used for the layout can be defined\n            via a string value. Currently, supported are:\n\n            - **Random layout**, where the nodes are uniformly at random placed in the\n                unit square.\n            - **Fruchterman-Reingold force-directed algorithm**. In this algorithm, the\n                nodes are represented by steel rings and the edges are springs between\n                them. The attractive force is analogous to the spring force and the\n                repulsive force is analogous to the electrical force. The basic idea is\n                to minimize the energy of the system by moving the nodes and changing\n                the forces between them.\n\n            The algorithm can be enabled with the keywords:\n            | Algorithms | Keywords |\n            | ---------- | -------- |\n            | Random | `Random`, `random`, `rand`, `None` |\n            |Fruchterman-Reingold | `Fruchterman-Reingold`, `fruchterman_reingold`, `fr spring_layout`, `spring layout`, `FR` |\n\n        force (float): Optimal distance between nodes.  If None the distance is set to\n            1/sqrt(n) where n is the number of nodes.  Increase this value to move\n            nodes farther apart.\n        positions (dict): Initial positions for nodes as a dictionary with node as keys and values\n            as a coordinate list or tuple.  If None, then use random initial\n            positions.\n        fixed (list): Nodes to keep fixed at initial position.\n        iterations (int): Maximum number of iterations taken. Defaults to 50.\n        threshold (float): Threshold for relative error in node position changes.  The iteration\n            stops if the error is below this threshold. Defaults to 1e-4.\n        weight (string):  or None, optional (default = None)\n            The edge attribute that holds the numerical value used for the edge\n            weight. If None, then all edge weights are 1.\n        dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n        seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n            the seed used by the random number generator, if None, the a random seed\n            by created by the numpy random number generator is used.\n\n    In the layout style dictionary multiple keywords can be used to address\n    attributes. These keywords will be converted to an unique key word,\n    used in the remaining code.\n\n    | keys | other valid keys |\n    | ---- | ---------------- |\n    | fixed | `fixed_nodes`, `fixed_vertices`, `fixed_n`, `fixed_v` |\n    | positions| `initial_positions`, `node_positions`, `vertex_positions`, `n_positions`, `v_positions` |\n\n    Examples:\n        For illustration purpose a similar network as in the `python-igraph` tutorial\n        is used. Instead of `igraph`, the `cnet` module is used for creating the\n        network.\n\n        Create an empty network object, and add some edges.\n\n        &gt;&gt;&gt; net = Network(name = 'my tikz test network',directed=True)\n        &gt;&gt;&gt; net.add_edges_from([('ab','a','b'), ('ac','a','c'), ('cd','c','d'),\n        ...                     ('de','d','e'), ('ec','e','c'), ('cf','c','f'),\n        ...                     ('fa','f','a'), ('fg','f','g'),('gg','g','g'),\n        ...                     ('gd','g','d')])\n\n        Now a layout can be generated:\n\n        &gt;&gt;&gt; layout(net)\n        {'b': array([0.88878309, 0.15685131]), 'd': array([0.4659341 , 0.79839535]),\n        'c': array([0.60386662, 0.40727962]), 'e': array([0.71073353, 0.65608203]),\n        'g': array([0.42663927, 0.47412449]), 'f': array([0.48759769, 0.86787594]),\n        'a': array([0.84154488, 0.1633732 ])}\n\n        Per default, the node positions are assigned uniform random. In order to\n        create a layout, the layout methods of the packages can be used, or the\n        position of the nodes can be directly assigned, in form of a dictionary,\n        where the key is the `node_id` and the value is a tuple of the node position\n        in $x$ and $y$.\n\n        Let us generate a force directed layout (e.g. Fruchterman-Reingold):\n\n        &gt;&gt;&gt; layout(net, layout='fr')\n        {'g': array([-0.77646408,  1.71291126]), 'c': array([-0.18639655,0.96232326]),\n        'f': array([0.33394308, 0.93778681]), 'e': array([0.09740098, 1.28511973]),\n        'a': array([1.37933158, 0.23171857]), 'b': array([ 2.93561876,-0.46183461]),\n        'd': array([-0.29329793,  1.48971303])}\n\n        Note, instead of the command `fr` also the command\n        `Fruchterman-Reingold` or any other command mentioned above can be\n        used. For more information see table above.\n\n        In order to keep the properties of the layout for your network separate from\n        the network itself, you can simply set up a Python dictionary containing the\n        keyword arguments you would pass to [`layout`][pathpyG.visualisations.layout.layout] and then use the\n        double asterisk (**) operator to pass your specific layout attributes to\n        [`layout`][pathpyG.visualisations.layout.layout]:\n\n        &gt;&gt;&gt; layout_style = {}\n        &gt;&gt;&gt; layout_style['layout'] = 'Fruchterman-Reingold'\n        &gt;&gt;&gt; layout_style['seed'] = 1\n        &gt;&gt;&gt; layout_style['iterations'] = 100\n        &gt;&gt;&gt; layout(net,**layout_style)\n        {'d': array([-0.31778276, 1.78246882]), 'f': array([-0.8603259, 0.82328291]),\n        'c': array([-0.4423771 , 1.21203895]), 'e': array([-0.79934355, 1.49000119]),\n        'g': array([0.43694799, 1.51428788]), 'a': array([-2.15517293, 0.23948823]),\n        'b': array([-3.84803812, -0.71628417])}\n    \"\"\"\n    # initialize variables\n    _weight = kwds.get(\"weight\", None)\n    if _weight is None:\n        _weight = kwds.get(\"layout_weight\", None)\n\n    # check type of network\n    if \"cnet\" in str(type(network)):\n        # log.debug('The network is of type \"cnet\".')\n        nodes = list(network.nodes)\n        adjacency_matrix = network.adjacency_matrix(weight=_weight)\n\n    elif \"networkx\" in str(type(network)):\n        # log.debug('The network is of type \"networkx\".')\n        nodes = list(network.nodes())\n        import networkx as nx\n\n        adjacency_matrix = nx.adjacency_matrix(network, weight=_weight)  # type: ignore\n    elif \"igraph\" in str(type(network)):\n        # log.debug('The network is of type \"igraph\".')\n        nodes = list(range(len(network.vs)))\n        from scipy.sparse import coo_matrix\n\n        A = np.array(network.get_adjacency(attribute=_weight).data)\n        adjacency_matrix = coo_matrix(A)\n    elif \"pathpyG\" in str(type(network)):\n        # log.debug('The network is of type \"pathpy\".')\n        nodes = list(network.nodes)\n        if _weight is not None:\n            _w = True\n        else:\n            _w = False\n        adjacency_matrix = network.sparse_adj_matrix()\n    # elif isinstance(network, tuple):\n    #     # log.debug('The network is of type \"list\".')\n    #     nodes = network[0]\n    #     from collections import OrderedDict\n    #     edges = OrderedDict()\n    #     for e in network[1]:\n    #         edges[e] = e\n\n    else:\n        print(\n            \"Type of the network could not be determined.\"\n            ' Currently only \"cnet\", \"networkx\",\"igraph\", \"pathpy\"'\n            ' and \"node/edge list\" is supported!'\n        )\n        raise NotImplementedError\n\n    # create layout class\n    layout = Layout(nodes, adjacency_matrix, **kwds)\n    # return the layout\n    return layout.generate_layout()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/","title":"network_plots","text":"<p>Network plot classes.</p>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>class NetworkPlot(PathPyPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, network: Graph, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        self._compute_edge_data()\n        self._compute_node_data()\n        self._compute_layout()\n        self._cleanup_config()\n        self._cleanup_data()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the nodes.\"\"\"\n        # initialize values\n        nodes: dict = {}\n        attributes: set = {\"color\", \"size\", \"opacity\", \"label\"}\n        attr: defaultdict = defaultdict(dict)\n\n        # get attributes categories from pathpyg\n        categories = {a.replace(\"node_\", \"\") for a in self.network.node_attrs()}.intersection(attributes)\n\n        # add node data to data dict\n        self._get_node_data(nodes, attributes, attr, categories)\n\n        # convert needed attributes to useful values\n        attr[\"color\"] = self._convert_color(attr[\"color\"], mode=\"node\")\n        attr[\"opacity\"] = self._convert_opacity(attr[\"opacity\"], mode=\"node\")\n        attr[\"size\"] = self._convert_size(attr[\"size\"], mode=\"node\")\n        attr[\"label\"] = self._convert_label(attr[\"label\"], mode=\"node\")\n\n        # update data dict with converted attributes\n        for attribute in attr:\n            for key, value in attr[attribute].items():\n                nodes[key][attribute] = value\n\n        # save node data\n        self.data[\"nodes\"] = nodes\n\n    def _get_node_data(\n        self,\n        nodes: dict,\n        attributes: set,\n        attr: defaultdict,\n        categories: set,\n    ) -&gt; None:\n        \"\"\"Extract node data from network.\"\"\"\n        for uid in self.network.nodes:\n            nodes[uid] = {\"uid\": str(uid)}\n\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"node_{attribute}\", uid].item() if attribute in categories else None\n                )\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the edges.\"\"\"\n        # initialize values\n        edges: dict = {}\n        attributes: set = {\"weight\", \"color\", \"size\", \"opacity\"}\n        attr: defaultdict = defaultdict(dict)\n\n        # get attributes categories from pathpyg\n        categories: set = {a.replace(\"edge_\", \"\") for a in self.network.edge_attrs()}.intersection(attributes)\n\n        # add edge data to data dict\n        self._get_edge_data(edges, attributes, attr, categories)\n\n        # convert needed attributes to useful values\n        attr[\"weight\"] = self._convert_weight(attr[\"weight\"], mode=\"edge\")\n        attr[\"color\"] = self._convert_color(attr[\"color\"], mode=\"edge\")\n        attr[\"opacity\"] = self._convert_opacity(attr[\"opacity\"], mode=\"edge\")\n        attr[\"size\"] = self._convert_size(attr[\"size\"], mode=\"edge\")\n\n        # update data dict with converted attributes\n        for attribute in attr:\n            for key, value in attr[attribute].items():\n                edges[key][attribute] = value\n\n        # save edge data\n        self.data[\"edges\"] = edges\n\n    def _get_edge_data(\n        self,\n        edges: dict,\n        attributes: set,\n        attr: defaultdict,\n        categories: set,\n    ) -&gt; None:\n        \"\"\"Extract edge data from network.\"\"\"\n        for u, v in self.network.edges:\n            uid = f\"{u}-{v}\"\n            edges[uid] = {\n                \"uid\": uid,\n                \"source\": str(u),\n                \"target\": str(v),\n            }\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"edge_{attribute}\", u, v].item() if attribute in categories else None\n                )\n\n    def _convert_weight(self, weight: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert weight to float.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_weight\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (int, float)):\n            weight = {k: style for k in weight}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            weight.update(**{k: v for k, v in style.items() if k in weight})\n\n        # return all weights which are not None\n        return {k: v if v is not None else 1 for k, v in weight.items()}\n\n    def _convert_color(self, color: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert colors to hex if rgb.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_color\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (str, int, float, tuple)):\n            color = {k: style for k in color}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            color.update(**{k: v for k, v in style.items() if k in color})\n\n        # check if new attribute is a list\n        elif isinstance(style, list):\n            for i, k in enumerate(color):\n                try:\n                    color[k] = style[i]\n                except IndexError:\n                    pass\n\n        # check if numerical values are given\n        values = [v for v in color.values() if isinstance(v, (int, float))]\n\n        if values:\n            # load colormap to map numerical values to color\n            cmap = self.config.get(f\"{mode}_cmap\", Colormap())\n            cdict = {values[i]: tuple(c[:3]) for i, c in enumerate(cmap(values, bytes=True))}\n\n        # convert colors to hex if not already string\n        for key, value in color.items():\n            if isinstance(value, tuple):\n                color[key] = rgb_to_hex(value)\n            elif isinstance(value, (int, float)):\n                color[key] = rgb_to_hex(cdict[value])\n\n        # return all colors wich are not None\n        return {k: v for k, v in color.items() if v is not None}\n\n    def _convert_opacity(self, opacity: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert opacity to float.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_opacity\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (int, float)):\n            opacity = {k: style for k in opacity}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            opacity.update(**{k: v for k, v in style.items() if k in opacity})\n\n        # return all colors wich are not None\n        return {k: v for k, v in opacity.items() if v is not None}\n\n    def _convert_size(self, size: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert size to float.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_size\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (int, float)):\n            size = {k: style for k in size}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            size.update(**{k: v for k, v in style.items() if k in size})\n\n        # return all colors wich are not None\n        return {k: v for k, v in size.items() if v is not None}\n\n    def _convert_label(self, label: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert label to string.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_label\")\n\n        # check if new attribute is a single object\n        if isinstance(style, str):\n            label = {k: style for k in label}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            label.update(**{k: v for k, v in style.items() if k in label})\n\n        # check if new attribute is a list\n        elif isinstance(style, list):\n            for i, k in enumerate(label):\n                try:\n                    label[k] = style[i]\n                except IndexError:\n                    pass\n\n        # return all labels wich are not None\n        return {k: v for k, v in label.items() if v is not None}\n\n    def _compute_layout(self) -&gt; None:\n        \"\"\"Create layout.\"\"\"\n        # get layout form the config\n        layout = self.config.get(\"layout\", \"rand\")\n\n        # if no layout is considered stop this process\n        if layout is None:\n            return\n\n        # get layout dict for each node\n        if isinstance(layout, str):\n            layout = network_layout(self.network, layout=layout)\n        elif not isinstance(layout, dict):\n            logger.error(\"The provided layout is not valid!\")\n            raise AttributeError\n\n        # update x,y position of the nodes\n        for uid, (_x, _y) in layout.items():\n            self.data[\"nodes\"][uid][\"x\"] = _x\n            self.data[\"nodes\"][uid][\"y\"] = _y\n\n    def _cleanup_config(self) -&gt; None:\n        \"\"\"Clean up final config file.\"\"\"\n        try:\n            directed = self.network.is_directed()\n        except NotImplementedError:\n            directed = False\n\n        if not self.config.get(\"directed\", None):\n            self.config[\"directed\"] = directed\n\n        if not self.config.get(\"curved\", None):\n            self.config[\"curved\"] = directed\n\n    def _cleanup_data(self) -&gt; None:\n        \"\"\"Clean up final data structure.\"\"\"\n        self.data[\"nodes\"] = list(self.data[\"nodes\"].values())\n        self.data[\"edges\"] = list(self.data[\"edges\"].values())\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def __init__(self, network: Graph, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.network = network\n    self.config = kwargs\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    self._compute_edge_data()\n    self._compute_node_data()\n    self._compute_layout()\n    self._cleanup_config()\n    self._cleanup_data()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.network_plots.NetworkPlot</code></p> <p>Network plot class for a temporal network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a temporal network.\"\"\"\n\n    _kind = \"temporal\"\n\n    def __init__(self, network: TemporalGraph, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__(network, **kwargs)\n\n    def _get_edge_data(self, edges: dict, attributes: set, attr: defaultdict, categories: set) -&gt; None:\n        \"\"\"Extract edge data from temporal network.\"\"\"\n        # TODO: Fix typing issue with temporal graphs\n        for u, v, t in self.network.temporal_edges:  # type: ignore\n            uid = f\"{u}-{v}-{t}\"\n            edges[uid] = {\n                \"uid\": uid,\n                \"source\": str(u),\n                \"target\": str(v),\n                \"start\": int(t),\n                \"end\": int(t) + 1,\n            }\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"edge_{attribute}\", u, v].item() if attribute in categories else None\n                )\n\n    def _get_node_data(self, nodes: dict, attributes: set, attr: defaultdict, categories: set) -&gt; None:\n        \"\"\"Extract node data from temporal network.\"\"\"\n\n        time = {e[2] for e in self.network.temporal_edges}\n\n        if self.config.get(\"end\", None) is None:\n            self.config[\"end\"] = int(max(time) + 1)\n\n        if self.config.get(\"start\", None) is None:\n            self.config[\"start\"] = int(min(time) - 1)\n\n        for uid in self.network.nodes:\n            nodes[uid] = {\n                \"uid\": uid,\n                \"start\": int(min(time) - 1),\n                \"end\": int(max(time) + 1),\n            }\n\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"node_{attribute}\", uid].item() if attribute in categories else None\n                )\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def __init__(self, network: TemporalGraph, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.network_plot","title":"<code>network_plot</code>","text":"<p>Plot a static network.</p> <p>This function generates a static plot of the network with various output formats including interactive HTML with d3js, tex file with tikz code, PDF from the tex source, and PNG based on matplotlib. The appearance of the plot can be modified using keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.core.graph.Graph</code> <p>A <code>Graph</code> object to be plotted.</p> required <code>**kwargs</code> <code>typing.Any</code> <p>Keyword arguments to modify the appearance of the plot. Defaults to no attributes. For details see below.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pathpyG.visualisations.network_plots.NetworkPlot</code> <p>A plot object, the type of which depends on the output format chosen.</p>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.network_plot--keyword-arguments-to-modify-the-appearance-of-the-plot","title":"Keyword Arguments to modify the appearance of the plot","text":"<p>Nodes:</p> <ul> <li> <p><code>node_size</code> : diameter of the node</p> </li> <li> <p><code>node_color</code> : The fill color of the node. Possible values are:</p> <ul> <li> <p>A single color string referred to by name, RGB or RGBA code, for   instance <code>red</code> or <code>#a98d19</code> or <code>(12,34,102)</code>.</p> </li> <li> <p>A sequence of color strings referred to by name, RGB or RGBA code,   which will be used for each point's color recursively. For   instance <code>['green', 'yellow']</code> all points will be filled in green or   yellow, alternatively.</p> </li> <li> <p>A column name or position whose values will be used to color the   marker points according to a colormap.</p> </li> </ul> </li> <li> <p><code>node_cmap</code> : Colormap for node colors. If node colors are given as int   or float values the color will be assigned based on a colormap. Per   default the color map goes from red to green. Matplotlib colormaps or   seaborn color palettes can be used to style the node colors.</p> </li> <li> <p><code>node_opacity</code> : fill opacity of the node. The default is 1. The range   of the number lies between 0 and 1. Where 0 represents a fully   transparent fill and 1 a solid fill.</p> </li> </ul> <p>Edges</p> <ul> <li> <p><code>edge_size</code> : width of the edge</p> </li> <li> <p><code>edge_color</code> : The line color of the edge. Possible values are:</p> <ul> <li> <p>A single color string referred to by name, RGB or RGBA code, for   instance <code>red</code> or <code>#a98d19</code> or <code>(12,34,102)</code>.</p> </li> <li> <p>A sequence of color strings referred to by name, RGB or RGBA   code, which will be used for each point's color recursively. For   instance <code>['green','yellow']</code> all points will be filled in green or   yellow, alternatively.</p> </li> <li> <p>A column name or position whose values will be used to color the   marker points according to a colormap.</p> </li> </ul> </li> <li> <p><code>edge_cmap</code> : Colormap for edge colors. If node colors are given as int   or float values the color will be assigned based on a colormap. Per   default the color map goes from red to green. Matplotlib colormaps or   seaborn color palettes can be used to style the edge colors.</p> </li> <li> <p><code>edge_opacity</code> : line opacity of the edge. The default is 1. The range   of the number lies between 0 and 1. Where 0 represents a fully   transparent fill and 1 a solid fill.</p> </li> </ul> <p>General</p> <ul> <li> <p><code>keep_aspect_ratio</code></p> </li> <li> <p><code>margin</code></p> </li> <li> <p><code>layout</code></p> </li> </ul> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def network_plot(network: Graph, **kwargs: Any) -&gt; NetworkPlot:\n    \"\"\"Plot a static network.\n\n    This function generates a static plot of the network with various output\n    formats including interactive HTML with d3js, tex file with tikz code, PDF\n    from the tex source, and PNG based on matplotlib. The appearance of the\n    plot can be modified using keyword arguments.\n\n    Args:\n        network (Graph): A `Graph` object to be plotted.\n        **kwargs (Any): Keyword arguments to modify the appearance of the\n            plot. Defaults to no attributes. For details see below.\n\n    Returns:\n        A plot object, the type of which depends on the output format chosen.\n\n\n    # Keyword Arguments to modify the appearance of the plot\n    **Nodes:**\n\n    - `node_size` : diameter of the node\n\n    - `node_color` : The fill color of the node. Possible values are:\n\n        - A single color string referred to by name, RGB or RGBA code, for\n          instance `red` or `#a98d19` or `(12,34,102)`.\n\n        - A sequence of color strings referred to by name, RGB or RGBA code,\n          which will be used for each point's color recursively. For\n          instance `['green', 'yellow']` all points will be filled in green or\n          yellow, alternatively.\n\n        - A column name or position whose values will be used to color the\n          marker points according to a colormap.\n\n    - `node_cmap` : Colormap for node colors. If node colors are given as int\n      or float values the color will be assigned based on a colormap. Per\n      default the color map goes from red to green. Matplotlib colormaps or\n      seaborn color palettes can be used to style the node colors.\n\n    - `node_opacity` : fill opacity of the node. The default is 1. The range\n      of the number lies between 0 and 1. Where 0 represents a fully\n      transparent fill and 1 a solid fill.\n\n\n    **Edges**\n\n    - `edge_size` : width of the edge\n\n    - `edge_color` : The line color of the edge. Possible values are:\n\n        - A single color string referred to by name, RGB or RGBA code, for\n          instance `red` or `#a98d19` or `(12,34,102)`.\n\n        - A sequence of color strings referred to by name, RGB or RGBA\n          code, which will be used for each point's color recursively. For\n          instance `['green','yellow']` all points will be filled in green or\n          yellow, alternatively.\n\n        - A column name or position whose values will be used to color the\n          marker points according to a colormap.\n\n    - `edge_cmap` : Colormap for edge colors. If node colors are given as int\n      or float values the color will be assigned based on a colormap. Per\n      default the color map goes from red to green. Matplotlib colormaps or\n      seaborn color palettes can be used to style the edge colors.\n\n    - `edge_opacity` : line opacity of the edge. The default is 1. The range\n      of the number lies between 0 and 1. Where 0 represents a fully\n      transparent fill and 1 a solid fill.\n\n\n    **General**\n\n    - `keep_aspect_ratio`\n\n    - `margin`\n\n    - `layout`\n\n    \"\"\"\n    return NetworkPlot(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.static_plot","title":"<code>static_plot</code>","text":"<p>Plot a static network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def static_plot(network: Graph, **kwargs: Any) -&gt; NetworkPlot:\n    \"\"\"Plot a static network.\"\"\"\n    return StaticNetworkPlot(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.temporal_plot","title":"<code>temporal_plot</code>","text":"<p>Plot a temporal network.</p> <p>Temporal properties:</p> <ul> <li> <p><code>start</code> : start time of the simulation</p> </li> <li> <p><code>end</code> : end time of the simulation</p> </li> <li> <p><code>delta</code> : time needed for progressing one time step</p> </li> <li> <p><code>intervals</code> : number of numeric intervals</p> </li> </ul> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def temporal_plot(network: TemporalGraph, **kwargs: Any) -&gt; NetworkPlot:\n    \"\"\"Plot a temporal network.\n\n    **Temporal properties:**\n\n    - ``start`` : start time of the simulation\n\n    - ``end`` : end time of the simulation\n\n    - ``delta`` : time needed for progressing one time step\n\n    - ``intervals`` : number of numeric intervals\n\n    \"\"\"\n    return TemporalNetworkPlot(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/","title":"plot","text":"<p>Class to plot pathpy networks.</p>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot","title":"<code>PathPyPlot</code>","text":"<p>Abstract class for assemblig plots.</p>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot--attributes","title":"Attributes","text":"<p>data : dict     data of the plot object config : dict     configuration for the plot</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>class PathPyPlot:\n    \"\"\"Abstract class for assemblig plots.\n\n    Attributes\n    ----------\n    data : dict\n        data of the plot object\n    config : dict\n        configuration for the plot\n\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize plot class.\"\"\"\n        logger.debug(\"Initalize PathPyPlot class\")\n        self.data: dict = {}\n        self.config: dict = {}\n\n    @property\n    def _kind(self) -&gt; str:\n        \"\"\"Specify kind str. Must be overridden in child class.\"\"\"\n        raise NotImplementedError\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n        plot_backend = _get_plot_backend(_backend, filename)\n        plot_backend.plot(deepcopy(self.data), self._kind, **deepcopy(self.config)).save(filename, **kwargs)\n\n    def show(self, **kwargs: Any) -&gt; None:\n        \"\"\"Show the plot on the device.\"\"\"\n        _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n        plot_backend = _get_plot_backend(_backend, None)\n        plot_backend.plot(deepcopy(self.data), self._kind, **deepcopy(self.config)).show(**kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize plot class.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize plot class.\"\"\"\n    logger.debug(\"Initalize PathPyPlot class\")\n    self.data: dict = {}\n    self.config: dict = {}\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n    plot_backend = _get_plot_backend(_backend, filename)\n    plot_backend.plot(deepcopy(self.data), self._kind, **deepcopy(self.config)).save(filename, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:\n    \"\"\"Show the plot on the device.\"\"\"\n    _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n    plot_backend = _get_plot_backend(_backend, None)\n    plot_backend.plot(deepcopy(self.data), self._kind, **deepcopy(self.config)).show(**kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/","title":"utils","text":"<p>Helper functions for plotting.</p>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.Colormap","title":"<code>Colormap</code>","text":"<p>Very simple colormap class.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>class Colormap:\n    \"\"\"Very simple colormap class.\"\"\"\n\n    def __call__(\n        self,\n        values: list,\n        alpha: Optional[float] = None,\n        bytes: bool = False,\n    ) -&gt; list:\n        \"\"\"Return color value.\"\"\"\n        vmin, vmax = min(values), max(values)\n        if vmin == vmax:\n            vmin -= 1\n            vmax += 1\n        return [self.color_tuple(v) for v in ((x - vmin) / (vmax - vmin) * 100 for x in values)]\n\n    @staticmethod\n    def color_tuple(n: float) -&gt; tuple:\n        \"\"\"Return color ramp from green to red.\"\"\"\n        return (int((255 * n) * 0.01), int((255 * (100 - n)) * 0.01), 0, 255)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.Colormap.__call__","title":"<code>__call__</code>","text":"<p>Return color value.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def __call__(\n    self,\n    values: list,\n    alpha: Optional[float] = None,\n    bytes: bool = False,\n) -&gt; list:\n    \"\"\"Return color value.\"\"\"\n    vmin, vmax = min(values), max(values)\n    if vmin == vmax:\n        vmin -= 1\n        vmax += 1\n    return [self.color_tuple(v) for v in ((x - vmin) / (vmax - vmin) * 100 for x in values)]\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.Colormap.color_tuple","title":"<code>color_tuple</code>  <code>staticmethod</code>","text":"<p>Return color ramp from green to red.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>@staticmethod\ndef color_tuple(n: float) -&gt; tuple:\n    \"\"\"Return color ramp from green to red.\"\"\"\n    return (int((255 * n) * 0.01), int((255 * (100 - n)) * 0.01), 0, 255)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.hex_to_rgb","title":"<code>hex_to_rgb</code>","text":"<p>Convert hex string to rgb color tuple.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def hex_to_rgb(value: str) -&gt; tuple:\n    \"\"\"Convert hex string to rgb color tuple.\"\"\"\n    value = value.lstrip(\"#\")\n    _l = len(value)\n    return tuple(int(value[i : i + _l // 3], 16) for i in range(0, _l, _l // 3))\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.rgb_to_hex","title":"<code>rgb_to_hex</code>","text":"<p>Convert rgb color tuple to hex string.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def rgb_to_hex(rgb: tuple) -&gt; str:\n    \"\"\"Convert rgb color tuple to hex string.\"\"\"\n    return \"#%02x%02x%02x\" % rgb\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/","title":"_d3js","text":"<p>Initialize d3js plotting functions.</p>"},{"location":"reference/pathpyG/visualisations/_d3js/#pathpyG.visualisations._d3js.plot","title":"<code>plot</code>","text":"<p>Plot function.</p> Source code in <code>src/pathpyG/visualisations/_d3js/__init__.py</code> <pre><code>def plot(data: dict, kind: str = \"network\", **kwargs: Any) -&gt; Any:\n    \"\"\"Plot function.\"\"\"\n    return PLOT_CLASSES[kind](data, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/","title":"core","text":""},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot","title":"<code>D3jsPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Base class for plotting d3js objects.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>class D3jsPlot(PathPyPlot):\n    \"\"\"Base class for plotting d3js objects.\"\"\"\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        with open(filename, \"w+\") as new:\n            new.write(self.to_html())\n\n    def show(self, **kwargs: Any) -&gt; None:\n        \"\"\"Show the plot on the device.\"\"\"\n        if config[\"environment\"][\"interactive\"]:\n            from IPython.display import display_html, HTML\n\n            display_html(HTML(self.to_html()))\n        else:\n            # create temporal file\n            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n                # save html\n                self.save(temp_file.name)\n                # open the file\n                webbrowser.open(r\"file:///\" + temp_file.name)\n\n    def to_json(self) -&gt; str:\n        \"\"\"Convert data to json.\"\"\"\n        raise NotImplementedError\n\n    def to_html(self) -&gt; str:\n        \"\"\"Convert data to html.\"\"\"\n        # generate unique dom uids\n        dom_id = \"#x\" + uuid.uuid4().hex\n\n        # get path to the pathpy templates\n        template_dir = os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"_d3js/templates\"),\n        )\n\n        # get d3js version\n        local = self.config.get(\"d3js_local\", False)\n        if local:\n            d3js = os.path.join(template_dir, \"d3.v5.min.js\")\n        else:\n            d3js = \"https://d3js.org/d3.v5.min.js\"\n\n        # get template files\n        with open(os.path.join(template_dir, f\"{self._kind}.js\")) as template:\n            js_template = template.read()\n\n        with open(os.path.join(template_dir, \"setup.js\")) as template:\n            setup_template = template.read()\n\n        with open(os.path.join(template_dir, \"styles.css\")) as template:\n            css_template = template.read()\n\n        # load custom template\n        _template = self.config.get(\"template\", None)\n        if _template and os.path.isfile(_template):\n            with open(_template) as template:\n                js_template = template.read()\n\n        # load custom css template\n        _template = self.config.get(\"css\", None)\n        if _template and os.path.isfile(_template):\n            with open(_template) as template:\n                css_template += template.read()\n\n        # update config\n        self.config[\"selector\"] = dom_id\n        data = self.to_json()\n\n        # generate html file\n        html = \"&lt;style&gt;\\n\" + css_template + \"\\n&lt;/style&gt;\\n\"\n\n        # div environment for the plot object\n        html += f'\\n&lt;div id = \"{dom_id[1:]}\"&gt; &lt;/div&gt;\\n'\n\n        # add d3js library\n        html += f'&lt;script charset=\"utf-8\" src=\"{d3js}\"&gt;&lt;/script&gt;\\n'\n\n        # start JavaScript\n        html += '&lt;script charset=\"utf-8\"&gt;\\n'\n\n        # add setup code to run d3js in multiple environments\n        html += Template(setup_template).substitute(d3js=d3js)\n\n        # start d3 environment\n        html += \"require(['d3'], function(d3){ //START\\n\"\n\n        # add data and config\n        html += f\"const data = {data}\\n\"\n        html += f\"const config = {json.dumps(self.config)}\\n\"\n\n        # add JavaScript\n        html += js_template\n\n        # end d3 environment\n        html += \"\\n}); //END\\n\"\n\n        # end JavaScript\n        html += \"\\n&lt;/script&gt;\"\n\n        return html\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    with open(filename, \"w+\") as new:\n        new.write(self.to_html())\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:\n    \"\"\"Show the plot on the device.\"\"\"\n    if config[\"environment\"][\"interactive\"]:\n        from IPython.display import display_html, HTML\n\n        display_html(HTML(self.to_html()))\n    else:\n        # create temporal file\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            # save html\n            self.save(temp_file.name)\n            # open the file\n            webbrowser.open(r\"file:///\" + temp_file.name)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.to_html","title":"<code>to_html</code>","text":"<p>Convert data to html.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def to_html(self) -&gt; str:\n    \"\"\"Convert data to html.\"\"\"\n    # generate unique dom uids\n    dom_id = \"#x\" + uuid.uuid4().hex\n\n    # get path to the pathpy templates\n    template_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)),\n        os.path.normpath(\"_d3js/templates\"),\n    )\n\n    # get d3js version\n    local = self.config.get(\"d3js_local\", False)\n    if local:\n        d3js = os.path.join(template_dir, \"d3.v5.min.js\")\n    else:\n        d3js = \"https://d3js.org/d3.v5.min.js\"\n\n    # get template files\n    with open(os.path.join(template_dir, f\"{self._kind}.js\")) as template:\n        js_template = template.read()\n\n    with open(os.path.join(template_dir, \"setup.js\")) as template:\n        setup_template = template.read()\n\n    with open(os.path.join(template_dir, \"styles.css\")) as template:\n        css_template = template.read()\n\n    # load custom template\n    _template = self.config.get(\"template\", None)\n    if _template and os.path.isfile(_template):\n        with open(_template) as template:\n            js_template = template.read()\n\n    # load custom css template\n    _template = self.config.get(\"css\", None)\n    if _template and os.path.isfile(_template):\n        with open(_template) as template:\n            css_template += template.read()\n\n    # update config\n    self.config[\"selector\"] = dom_id\n    data = self.to_json()\n\n    # generate html file\n    html = \"&lt;style&gt;\\n\" + css_template + \"\\n&lt;/style&gt;\\n\"\n\n    # div environment for the plot object\n    html += f'\\n&lt;div id = \"{dom_id[1:]}\"&gt; &lt;/div&gt;\\n'\n\n    # add d3js library\n    html += f'&lt;script charset=\"utf-8\" src=\"{d3js}\"&gt;&lt;/script&gt;\\n'\n\n    # start JavaScript\n    html += '&lt;script charset=\"utf-8\"&gt;\\n'\n\n    # add setup code to run d3js in multiple environments\n    html += Template(setup_template).substitute(d3js=d3js)\n\n    # start d3 environment\n    html += \"require(['d3'], function(d3){ //START\\n\"\n\n    # add data and config\n    html += f\"const data = {data}\\n\"\n    html += f\"const config = {json.dumps(self.config)}\\n\"\n\n    # add JavaScript\n    html += js_template\n\n    # end d3 environment\n    html += \"\\n}); //END\\n\"\n\n    # end JavaScript\n    html += \"\\n&lt;/script&gt;\"\n\n    return html\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.to_json","title":"<code>to_json</code>","text":"<p>Convert data to json.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Convert data to json.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/","title":"network_plots","text":"<p>Network plots with d3js.</p>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._d3js.core.D3jsPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>class NetworkPlot(D3jsPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.data = data\n        self.config = kwargs\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Clen up data.\"\"\"\n        self.config.pop(\"node_cmap\", None)\n        self.config.pop(\"edge_cmap\", None)\n        for node in self.data[\"nodes\"]:\n            node.pop(\"x\", None)\n            node.pop(\"y\", None)\n\n    def to_json(self) -&gt; Any:\n        \"\"\"Convert data to json.\"\"\"\n        return json.dumps(self.data)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.data = data\n    self.config = kwargs\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Clen up data.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Clen up data.\"\"\"\n    self.config.pop(\"node_cmap\", None)\n    self.config.pop(\"edge_cmap\", None)\n    for node in self.data[\"nodes\"]:\n        node.pop(\"x\", None)\n        node.pop(\"y\", None)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot.to_json","title":"<code>to_json</code>","text":"<p>Convert data to json.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>def to_json(self) -&gt; Any:\n    \"\"\"Convert data to json.\"\"\"\n    return json.dumps(self.data)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._d3js.network_plots.NetworkPlot</code></p> <p>Network plot class for a temporal network.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a temporal network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._d3js.network_plots.NetworkPlot</code></p> <p>Network plot class for a temporal network.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a temporal network.\"\"\"\n\n    _kind = \"temporal\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/","title":"_matplotlib","text":"<p>Initialize matplotlib plotting functions.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/#pathpyG.visualisations._matplotlib.plot","title":"<code>plot</code>","text":"<p>Plot function.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/__init__.py</code> <pre><code>def plot(data: dict, kind: str = \"network\", **kwargs: Any) -&gt; Any:\n    \"\"\"Plot function.\"\"\"\n    return PLOT_CLASSES[kind](data, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/","title":"core","text":"<p>Generic matplotlib plot class.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot","title":"<code>MatplotlibPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Base class for plotting matplotlib objects.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>class MatplotlibPlot(PathPyPlot):\n    \"\"\"Base class for plotting matplotlib objects.\"\"\"\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:  # type: ignore\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        self.to_fig().savefig(filename)\n\n    def show(self, **kwargs: Any) -&gt; None:  # type: ignore\n        \"\"\"Show the plot on the device.\"\"\"\n        self.to_fig().show()\n\n    def to_fig(self) -&gt; Any:  # type: ignore\n        \"\"\"Convert to matplotlib figure.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:  # type: ignore\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    self.to_fig().savefig(filename)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:  # type: ignore\n    \"\"\"Show the plot on the device.\"\"\"\n    self.to_fig().show()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.to_fig","title":"<code>to_fig</code>","text":"<p>Convert to matplotlib figure.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def to_fig(self) -&gt; Any:  # type: ignore\n    \"\"\"Convert to matplotlib figure.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/","title":"network_plots","text":"<p>Network plots with matplotlib.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._matplotlib.core.MatplotlibPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>class NetworkPlot(MatplotlibPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.data = data\n        self.config = kwargs\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Clen up data.\"\"\"\n        self._compute_node_data()\n        self._compute_edge_data()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the nodes.\"\"\"\n        default = {\n            \"uid\": None,\n            \"x\": 0,\n            \"y\": 0,\n            \"size\": 30,\n            \"color\": \"blue\",\n            \"opacity\": 1.0,\n        }\n\n        nodes: dict = {key: [] for key in default}\n\n        for node in self.data[\"nodes\"]:\n            for key, value in default.items():\n                nodes[key].append(node.get(key, value))\n\n        self.data[\"nodes\"] = nodes\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the edges.\"\"\"\n        default = {\n            \"uid\": None,\n            \"size\": 5,\n            \"color\": \"red\",\n            \"opacity\": 1.0,\n        }\n\n        edges: dict = {**{key: [] for key in default}, **{\"line\": []}}\n\n        for edge in self.data[\"edges\"]:\n            source = self.data[\"nodes\"][\"uid\"].index(edge.get(\"source\"))\n            target = self.data[\"nodes\"][\"uid\"].index(edge.get(\"target\"))\n            edges[\"line\"].append(\n                [\n                    (self.data[\"nodes\"][\"x\"][source], self.data[\"nodes\"][\"x\"][target]),\n                    (self.data[\"nodes\"][\"y\"][source], self.data[\"nodes\"][\"y\"][target]),\n                ]\n            )\n\n            for key, value in default.items():\n                edges[key].append(edge.get(key, value))\n\n        self.data[\"edges\"] = edges\n\n    def to_fig(self) -&gt; Any:\n        \"\"\"Convert data to figure.\"\"\"\n        import matplotlib.pyplot as plt\n\n        fig, ax = plt.subplots()\n        ax.set_axis_off()\n\n        # plot edges\n        for i in range(len(self.data[\"edges\"][\"uid\"])):\n            ax.plot(\n                *self.data[\"edges\"][\"line\"][i],\n                color=self.data[\"edges\"][\"color\"][i],\n                alpha=self.data[\"edges\"][\"opacity\"][i],\n                zorder=1,\n            )\n\n        # plot nodes\n        ax.scatter(\n            self.data[\"nodes\"][\"x\"],\n            self.data[\"nodes\"][\"y\"],\n            s=self.data[\"nodes\"][\"size\"],\n            c=self.data[\"nodes\"][\"color\"],\n            alpha=self.data[\"nodes\"][\"opacity\"],\n            zorder=2,\n        )\n        return plt\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.data = data\n    self.config = kwargs\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Clen up data.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Clen up data.\"\"\"\n    self._compute_node_data()\n    self._compute_edge_data()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot.to_fig","title":"<code>to_fig</code>","text":"<p>Convert data to figure.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def to_fig(self) -&gt; Any:\n    \"\"\"Convert data to figure.\"\"\"\n    import matplotlib.pyplot as plt\n\n    fig, ax = plt.subplots()\n    ax.set_axis_off()\n\n    # plot edges\n    for i in range(len(self.data[\"edges\"][\"uid\"])):\n        ax.plot(\n            *self.data[\"edges\"][\"line\"][i],\n            color=self.data[\"edges\"][\"color\"][i],\n            alpha=self.data[\"edges\"][\"opacity\"][i],\n            zorder=1,\n        )\n\n    # plot nodes\n    ax.scatter(\n        self.data[\"nodes\"][\"x\"],\n        self.data[\"nodes\"][\"y\"],\n        s=self.data[\"nodes\"][\"size\"],\n        c=self.data[\"nodes\"][\"color\"],\n        alpha=self.data[\"nodes\"][\"opacity\"],\n        zorder=2,\n    )\n    return plt\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._matplotlib.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._matplotlib.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"temporal\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/","title":"_tikz","text":"<p>Initialize tikz plotting functions.</p>"},{"location":"reference/pathpyG/visualisations/_tikz/#pathpyG.visualisations._tikz.plot","title":"<code>plot</code>","text":"<p>Plot function.</p> Source code in <code>src/pathpyG/visualisations/_tikz/__init__.py</code> <pre><code>def plot(data: dict, kind: str = \"network\", **kwargs: Any) -&gt; Any:\n    \"\"\"Plot function.\"\"\"\n    return PLOT_CLASSES[kind](data, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/","title":"core","text":""},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot","title":"<code>TikzPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Base class for plotting d3js objects.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>class TikzPlot(PathPyPlot):\n    \"\"\"Base class for plotting d3js objects.\"\"\"\n\n    def __init__(self, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize plot class.\"\"\"\n        super().__init__()\n        if kwargs:\n            self.config = kwargs\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        if filename.endswith(\"tex\"):\n            with open(filename, \"w+\") as new:\n                new.write(self.to_tex())\n        elif filename.endswith(\"pdf\"):\n            # compile temporary pdf\n            temp_file, temp_dir = self.compile_pdf()\n            # Copy a file with new name\n            shutil.copy(temp_file, filename)\n            # remove the temporal directory\n            shutil.rmtree(temp_dir)\n\n        else:\n            raise NotImplementedError\n\n    def show(self, **kwargs: Any) -&gt; None:\n        \"\"\"Show the plot on the device.\"\"\"\n        # compile temporary pdf\n        temp_file, temp_dir = self.compile_pdf()\n\n        if config[\"environment\"][\"interactive\"]:\n            from IPython.display import IFrame, display\n\n            # open the file in the notebook\n            display(IFrame(temp_file, width=600, height=300))\n        else:\n            # open the file in the webbrowser\n            webbrowser.open(r\"file:///\" + temp_file)\n\n        # Wait for .1 second before temp file is deleted\n        time.sleep(0.1)\n\n        # remove the temporal directory\n        shutil.rmtree(temp_dir)\n\n    def compile_pdf(self) -&gt; tuple:\n        \"\"\"Compile pdf from tex.\"\"\"\n        # basename\n        basename = \"default\"\n        # get current directory\n        current_dir = os.getcwd()\n\n        # template directory\n        tikz_dir = str(\n            os.path.join(\n                os.path.dirname(os.path.dirname(__file__)),\n                os.path.normpath(\"templates\"),\n                \"tikz-network.sty\",\n            )\n        )\n\n        # get temporal directory\n        temp_dir = tempfile.mkdtemp()\n\n        # copy tikz-network to temporal directory\n        shutil.copy(tikz_dir, temp_dir)\n\n        # change to output dir\n        os.chdir(temp_dir)\n\n        # save the tex file\n        self.save(basename + \".tex\")\n\n        # latex compiler\n        command = [\n            \"latexmk\",\n            \"--pdf\",\n            \"-shell-escape\",\n            \"--interaction=nonstopmode\",\n            basename + \".tex\",\n        ]\n\n        try:\n            subprocess.check_output(command, stderr=subprocess.STDOUT)\n        except Exception:\n            # If compiler does not exist, try next in the list\n            logger.error(\"No latexmk compiler found\")\n            raise AttributeError\n        finally:\n            # change back to the current directory\n            os.chdir(current_dir)\n\n        # return the name of the folder and temp pdf file\n        return (os.path.join(temp_dir, basename + \".pdf\"), temp_dir)\n\n    def to_tex(self) -&gt; str:\n        \"\"\"Convert data to tex.\"\"\"\n        # get path to the pathpy templates\n        template_dir = os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"_tikz/templates\"),\n        )\n\n        # get template files\n        with open(os.path.join(template_dir, f\"{self._kind}.tex\")) as template:\n            tex_template = template.read()\n\n        # generate data\n        data = self.to_tikz()\n\n        # fill template with data\n        tex = Template(tex_template).substitute(\n            classoptions=self.config.get(\"latex_class_options\", \"\"),\n            width=self.config.get(\"width\", \"6cm\"),\n            height=self.config.get(\"height\", \"6cm\"),\n            tikz=data,\n        )\n\n        return tex\n\n    def to_tikz(self) -&gt; str:\n        \"\"\"Convert data to tikz.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize plot class.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def __init__(self, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize plot class.\"\"\"\n    super().__init__()\n    if kwargs:\n        self.config = kwargs\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.compile_pdf","title":"<code>compile_pdf</code>","text":"<p>Compile pdf from tex.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def compile_pdf(self) -&gt; tuple:\n    \"\"\"Compile pdf from tex.\"\"\"\n    # basename\n    basename = \"default\"\n    # get current directory\n    current_dir = os.getcwd()\n\n    # template directory\n    tikz_dir = str(\n        os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"templates\"),\n            \"tikz-network.sty\",\n        )\n    )\n\n    # get temporal directory\n    temp_dir = tempfile.mkdtemp()\n\n    # copy tikz-network to temporal directory\n    shutil.copy(tikz_dir, temp_dir)\n\n    # change to output dir\n    os.chdir(temp_dir)\n\n    # save the tex file\n    self.save(basename + \".tex\")\n\n    # latex compiler\n    command = [\n        \"latexmk\",\n        \"--pdf\",\n        \"-shell-escape\",\n        \"--interaction=nonstopmode\",\n        basename + \".tex\",\n    ]\n\n    try:\n        subprocess.check_output(command, stderr=subprocess.STDOUT)\n    except Exception:\n        # If compiler does not exist, try next in the list\n        logger.error(\"No latexmk compiler found\")\n        raise AttributeError\n    finally:\n        # change back to the current directory\n        os.chdir(current_dir)\n\n    # return the name of the folder and temp pdf file\n    return (os.path.join(temp_dir, basename + \".pdf\"), temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    if filename.endswith(\"tex\"):\n        with open(filename, \"w+\") as new:\n            new.write(self.to_tex())\n    elif filename.endswith(\"pdf\"):\n        # compile temporary pdf\n        temp_file, temp_dir = self.compile_pdf()\n        # Copy a file with new name\n        shutil.copy(temp_file, filename)\n        # remove the temporal directory\n        shutil.rmtree(temp_dir)\n\n    else:\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:\n    \"\"\"Show the plot on the device.\"\"\"\n    # compile temporary pdf\n    temp_file, temp_dir = self.compile_pdf()\n\n    if config[\"environment\"][\"interactive\"]:\n        from IPython.display import IFrame, display\n\n        # open the file in the notebook\n        display(IFrame(temp_file, width=600, height=300))\n    else:\n        # open the file in the webbrowser\n        webbrowser.open(r\"file:///\" + temp_file)\n\n    # Wait for .1 second before temp file is deleted\n    time.sleep(0.1)\n\n    # remove the temporal directory\n    shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.to_tex","title":"<code>to_tex</code>","text":"<p>Convert data to tex.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def to_tex(self) -&gt; str:\n    \"\"\"Convert data to tex.\"\"\"\n    # get path to the pathpy templates\n    template_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)),\n        os.path.normpath(\"_tikz/templates\"),\n    )\n\n    # get template files\n    with open(os.path.join(template_dir, f\"{self._kind}.tex\")) as template:\n        tex_template = template.read()\n\n    # generate data\n    data = self.to_tikz()\n\n    # fill template with data\n    tex = Template(tex_template).substitute(\n        classoptions=self.config.get(\"latex_class_options\", \"\"),\n        width=self.config.get(\"width\", \"6cm\"),\n        height=self.config.get(\"height\", \"6cm\"),\n        tikz=data,\n    )\n\n    return tex\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.to_tikz","title":"<code>to_tikz</code>","text":"<p>Convert data to tikz.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def to_tikz(self) -&gt; str:\n    \"\"\"Convert data to tikz.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/","title":"network_plots","text":"<p>Network plots with tikz.</p>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._tikz.core.TikzPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>class NetworkPlot(TikzPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.data = data\n        self.config = kwargs\n        self.config[\"width\"] = self.config.pop(\"width\", 6)\n        self.config[\"height\"] = self.config.pop(\"height\", 6)\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Clen up data.\"\"\"\n        self._compute_node_data()\n        self._compute_edge_data()\n        self._update_layout()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the nodes.\"\"\"\n        default: set = {\"uid\", \"x\", \"y\", \"size\", \"color\", \"opacity\"}\n        mapping: dict = {}\n\n        for node in self.data[\"nodes\"]:\n            for key in list(node):\n                if key in mapping:\n                    node[mapping[key]] = node.pop(key)\n                if key not in default:\n                    node.pop(key, None)\n\n            color = node.get(\"color\", None)\n            if isinstance(color, str) and \"#\" in color:\n                color = hex_to_rgb(color)\n                node[\"color\"] = f\"{{{color[0]},{color[1]},{color[2]}}}\"\n                node[\"RGB\"] = True\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the edges.\"\"\"\n        default: set = {\"uid\", \"source\", \"target\", \"lw\", \"color\", \"opacity\"}\n        mapping: dict = {\"size\": \"lw\"}\n\n        for edge in self.data[\"edges\"]:\n            for key in list(edge):\n                if key in mapping:\n                    edge[mapping[key]] = edge.pop(key)\n                if key not in default:\n                    edge.pop(key, None)\n\n            color = edge.get(\"color\", None)\n            if isinstance(color, str) and \"#\" in color:\n                color = hex_to_rgb(color)\n                edge[\"color\"] = f\"{{{color[0]},{color[1]},{color[2]}}}\"\n                edge[\"RGB\"] = True\n\n    def _update_layout(self, default_size: float = 0.6) -&gt; None:\n        \"\"\"Update the layout.\"\"\"\n        layout = self.config.get(\"layout\")\n\n        if layout is None:\n            return\n\n        # get data\n        layout = {n[\"uid\"]: (n[\"x\"], n[\"y\"]) for n in self.data[\"nodes\"]}\n        sizes = {n[\"uid\"]: n.get(\"size\", default_size) for n in self.data[\"nodes\"]}\n\n        # get config values\n        width = self.config[\"width\"]\n        height = self.config[\"height\"]\n        keep_aspect_ratio = self.config.get(\"keep_aspect_ratio\", True)\n        margin = self.config.get(\"margin\", 0.0)\n        margins = {\"top\": margin, \"left\": margin, \"bottom\": margin, \"right\": margin}\n\n        # calculate the scaling ratio\n        x_ratio = float(\"inf\")\n        y_ratio = float(\"inf\")\n\n        # calculate absolute min and max coordinates\n        x_absolute = []\n        y_absolute = []\n        for uid, (_x, _y) in layout.items():\n            _s = sizes[uid] / 2\n            x_absolute.extend([_x - _s, _x + _s])\n            y_absolute.extend([_y - _s, _y + _s])\n\n        # calculate min and max center coordinates\n        x_values, y_values = zip(*layout.values())\n        x_min, x_max = min(x_values), max(x_values)\n        y_min, y_max = min(y_values), max(y_values)\n\n        # change margins\n        margins[\"left\"] += abs(x_min - min(x_absolute))\n        margins[\"bottom\"] += abs(y_min - min(y_absolute))\n        margins[\"top\"] += abs(y_max - max(y_absolute))\n        margins[\"right\"] += abs(x_max - max(x_absolute))\n\n        if x_max - x_min &gt; 0:\n            x_ratio = (width - margins[\"left\"] - margins[\"right\"]) / (x_max - x_min)\n        if y_max - y_min &gt; 0:\n            y_ratio = (height - margins[\"top\"] - margins[\"bottom\"]) / (y_max - y_min)\n\n        if keep_aspect_ratio:\n            scaling = (min(x_ratio, y_ratio), min(x_ratio, y_ratio))\n        else:\n            scaling = (x_ratio, y_ratio)\n\n        if scaling[0] == float(\"inf\"):\n            scaling = (1, scaling[1])\n        if scaling[1] == float(\"inf\"):\n            scaling = (scaling[0], 1)\n\n        x_values = []\n        y_values = []\n\n        # apply scaling to the points\n        _layout = {n: (x * scaling[0], y * scaling[1]) for n, (x, y) in layout.items()}\n\n        # find min and max values of the points\n        x_values, y_values = zip(*_layout.values())\n        x_min, x_max = min(x_values), max(x_values)\n        y_min, y_max = min(y_values), max(y_values)\n\n        # calculate the translation\n        translation = (\n            ((width - margins[\"left\"] - margins[\"right\"]) / 2 + margins[\"left\"]) - ((x_max - x_min) / 2 + x_min),\n            ((height - margins[\"top\"] - margins[\"bottom\"]) / 2 + margins[\"bottom\"]) - ((y_max - y_min) / 2 + y_min),\n        )\n\n        # apply translation to the points\n        _layout = {n: (x + translation[0], y + translation[1]) for n, (x, y) in _layout.items()}\n\n        # update node position for the plot\n        for node in self.data[\"nodes\"]:\n            node[\"x\"], node[\"y\"] = _layout[node[\"uid\"]]\n\n    def to_tikz(self) -&gt; str:\n        \"\"\"Convert to Tex.\"\"\"\n\n        def _add_args(args: dict):\n            string = \"\"\n            for key, value in args.items():\n                string += f\",{key}\" if value is True else f\",{key}={value}\"\n            return string\n\n        tikz = \"\"\n        for node in self.data[\"nodes\"]:\n            uid = node.pop(\"uid\")\n            string = \"\\\\Vertex[\"\n            string += _add_args(node)\n            string += \"]{{{}}}\\n\".format(uid)\n            tikz += string\n\n        for edge in self.data[\"edges\"]:\n            uid = edge.pop(\"uid\")\n            source = edge.pop(\"source\")\n            target = edge.pop(\"target\")\n            string = \"\\\\Edge[\"\n            string += _add_args(edge)\n            string += \"]({})({})\\n\".format(source, target)\n            tikz += string\n        return tikz\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.data = data\n    self.config = kwargs\n    self.config[\"width\"] = self.config.pop(\"width\", 6)\n    self.config[\"height\"] = self.config.pop(\"height\", 6)\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Clen up data.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Clen up data.\"\"\"\n    self._compute_node_data()\n    self._compute_edge_data()\n    self._update_layout()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot.to_tikz","title":"<code>to_tikz</code>","text":"<p>Convert to Tex.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def to_tikz(self) -&gt; str:\n    \"\"\"Convert to Tex.\"\"\"\n\n    def _add_args(args: dict):\n        string = \"\"\n        for key, value in args.items():\n            string += f\",{key}\" if value is True else f\",{key}={value}\"\n        return string\n\n    tikz = \"\"\n    for node in self.data[\"nodes\"]:\n        uid = node.pop(\"uid\")\n        string = \"\\\\Vertex[\"\n        string += _add_args(node)\n        string += \"]{{{}}}\\n\".format(uid)\n        tikz += string\n\n    for edge in self.data[\"edges\"]:\n        uid = edge.pop(\"uid\")\n        source = edge.pop(\"source\")\n        target = edge.pop(\"target\")\n        string = \"\\\\Edge[\"\n        string += _add_args(edge)\n        string += \"]({})({})\\n\".format(source, target)\n        tikz += string\n    return tikz\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._tikz.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._tikz.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"temporal\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"tutorial/_higher_order_scalability/","title":"higher order scalability","text":"In\u00a0[1]: Copied! <pre>import time\nimport torch\n\nimport pathpy as pp2\nimport pathpyG as pp\nfrom matplotlib import pyplot as plt\npp.config['torch']['device'] = 'cuda'\nprint('Running on', pp.config['torch']['device'])\n</pre> import time import torch  import pathpy as pp2 import pathpyG as pp from matplotlib import pyplot as plt pp.config['torch']['device'] = 'cuda' print('Running on', pp.config['torch']['device']) <pre>Running on cuda\n</pre> In\u00a0[2]: Copied! <pre>p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\n</pre> p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') In\u00a0[3]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(p, max_order=2)\ng2 = m.layers[2]\nprint(g2.n)\nprint(g2.m)\nprint(g2['edge_weight'].sum().item())\n</pre> m = pp.MultiOrderModel.from_DAGs(p, max_order=2) g2 = m.layers[2] print(g2.n) print(g2.m) print(g2['edge_weight'].sum().item()) <pre>646\n1139\n634916.0\n</pre> In\u00a0[4]: Copied! <pre>for e in g2.edges:\n    print(e, g2['edge_weight', e[0], e[1]])\n</pre> for e in g2.edges:     print(e, g2['edge_weight', e[0], e[1]]) <pre>(('Acton Town', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(2399., device='cuda:0')\n(('Acton Town', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(155., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(398., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(96., device='cuda:0')\n(('Acton Town', 'South Ealing'), ('South Ealing', 'Northfields')) tensor(1149., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(481., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(113., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(8., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(117., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(9., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(173., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(24., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(112., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(5., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2121., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1453., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(135., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(2147., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(234., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(5062., device='cuda:0')\n(('Alperton', 'Park Royal'), ('Park Royal', 'North Ealing')) tensor(232., device='cuda:0')\n(('Alperton', 'Sudbury Town'), ('Sudbury Town', 'Sudbury Hill')) tensor(117., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(1., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(180., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(46., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(665., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1404., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(3., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(33., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(56., device='cuda:0')\n(('Angel', 'Old Street'), ('Old Street', 'Moorgate')) tensor(2150., device='cuda:0')\n(('Archway', 'Highgate'), ('Highgate', 'East Finchley')) tensor(818., device='cuda:0')\n(('Archway', 'Tufnell Park'), ('Tufnell Park', 'Kentish Town')) tensor(1248., device='cuda:0')\n(('Arnos Grove', 'Bounds Green'), ('Bounds Green', 'Wood Green')) tensor(503., device='cuda:0')\n(('Arnos Grove', 'Southgate'), ('Southgate', 'Oakwood')) tensor(207., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(71., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(20., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(78., device='cuda:0')\n(('Arsenal', 'Holloway Road'), ('Holloway Road', 'Caledonian Road')) tensor(87., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(2561., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(104., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(669., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(2627., device='cuda:0')\n(('Baker Street', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Paddington')) tensor(5427., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(1379., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(157., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(639., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(290., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(463., device='cuda:0')\n(('Baker Street', 'Great Portland Street'), ('Great Portland Street', 'Euston Square')) tensor(4311., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(126., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(1391., device='cuda:0')\n(('Baker Street', \"Regent's Park\"), (\"Regent's Park\", 'Oxford Circus')) tensor(662., device='cuda:0')\n(('Baker Street', \"St. John's Wood\"), (\"St. John's Wood\", 'Swiss Cottage')) tensor(159., device='cuda:0')\n(('Balham', 'Clapham South'), ('Clapham South', 'Clapham Common')) tensor(1132., device='cuda:0')\n(('Balham', 'Tooting Bec'), ('Tooting Bec', 'Tooting Broadway')) tensor(637., device='cuda:0')\n(('Bank / Monument', 'Cannon Street'), ('Cannon Street', 'Mansion House')) tensor(274., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(110., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(2194., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(2353., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(522., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(264., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Borough')) tensor(805., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(3545., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(279., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(301., device='cuda:0')\n(('Bank / Monument', \"St. Paul's\"), (\"St. Paul's\", 'Chancery Lane')) tensor(3344., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(116., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(2188., device='cuda:0')\n(('Barbican', 'Farringdon'), ('Farringdon', \"King's Cross St. Pancras\")) tensor(2027., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1800., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(2., device='cuda:0')\n(('Barking', 'East Ham'), ('East Ham', 'Upton Park')) tensor(9., device='cuda:0')\n(('Barking', 'Upminster'), ('Upminster', 'Upminster Bridge')) tensor(561., device='cuda:0')\n(('Barking', 'Upney'), ('Upney', 'Becontree')) tensor(684., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(20., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Canning Town')) tensor(288., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Plaistow')) tensor(7., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Stratford')) tensor(2122., device='cuda:0')\n(('Barkingside', 'Fairlop'), ('Fairlop', 'Hainault')) tensor(201., device='cuda:0')\n(('Barkingside', 'Newbury Park'), ('Newbury Park', 'Gants Hill')) tensor(448., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1088., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(94., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(6., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(150., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(340., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(182., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(316., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(634., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(114., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(23., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(101., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(113., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(414., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(40., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(82., device='cuda:0')\n(('Becontree', 'Dagenham Heathway'), ('Dagenham Heathway', 'Dagenham East')) tensor(169., device='cuda:0')\n(('Becontree', 'Upney'), ('Upney', 'Barking')) tensor(623., device='cuda:0')\n(('Belsize Park', 'Chalk Farm'), ('Chalk Farm', 'Camden Town')) tensor(1156., device='cuda:0')\n(('Belsize Park', 'Hampstead'), ('Hampstead', 'Golders Green')) tensor(771., device='cuda:0')\n(('Bermondsey', 'Canada Water'), ('Canada Water', 'Canary Wharf')) tensor(1026., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(320., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Borough')) tensor(110., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(1094., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(11., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2252., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1505., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(119., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(253., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(144., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(3210., device='cuda:0')\n(('Blackfriars', 'Mansion House'), ('Mansion House', 'Cannon Street')) tensor(255., device='cuda:0')\n(('Blackfriars', 'Temple'), ('Temple', 'Embankment')) tensor(384., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(224., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(152., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2570., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(1699., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(92., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(999., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(174., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(282., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(225., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Victoria')) tensor(858., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Westminster')) tensor(1524., device='cuda:0')\n(('Bond Street', 'Marble Arch'), ('Marble Arch', 'Lancaster Gate')) tensor(835., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(226., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(519., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(93., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(3138., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(283., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(679., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(86., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(845., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(103., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(38., device='cuda:0')\n(('Boston Manor', 'Northfields'), ('Northfields', 'South Ealing')) tensor(1179., device='cuda:0')\n(('Boston Manor', 'Osterley'), ('Osterley', 'Hounslow East')) tensor(819., device='cuda:0')\n(('Bounds Green', 'Arnos Grove'), ('Arnos Grove', 'Southgate')) tensor(350., device='cuda:0')\n(('Bounds Green', 'Wood Green'), ('Wood Green', 'Turnpike Lane')) tensor(630., device='cuda:0')\n(('Bow Road', 'BromleyByBow'), ('BromleyByBow', 'West Ham')) tensor(13., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(225., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(5., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stratford')) tensor(10., device='cuda:0')\n(('Brent Cross', 'Golders Green'), ('Golders Green', 'Hampstead')) tensor(680., device='cuda:0')\n(('Brent Cross', 'Hendon Central'), ('Hendon Central', 'Colindale')) tensor(382., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(9., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Oval')) tensor(167., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(147., device='cuda:0')\n(('BromleyByBow', 'Bow Road'), ('Bow Road', 'Mile End')) tensor(87., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Barking')) tensor(16., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(3., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Plaistow')) tensor(4., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Stratford')) tensor(9., device='cuda:0')\n(('Buckhurst Hill', 'Loughton'), ('Loughton', 'Debden')) tensor(468., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(6., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'South Woodford')) tensor(934., device='cuda:0')\n(('Burnt Oak', 'Colindale'), ('Colindale', 'Hendon Central')) tensor(218., device='cuda:0')\n(('Caledonian Road', 'Holloway Road'), ('Holloway Road', 'Arsenal')) tensor(93., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(36., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(139., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(155., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(34., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(14., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(39., device='cuda:0')\n(('Camden Town', 'Chalk Farm'), ('Chalk Farm', 'Belsize Park')) tensor(1083., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(1459., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', 'Warren Street')) tensor(1639., device='cuda:0')\n(('Camden Town', 'Kentish Town'), ('Kentish Town', 'Tufnell Park')) tensor(1335., device='cuda:0')\n(('Canada Water', 'Bermondsey'), ('Bermondsey', 'London Bridge')) tensor(1333., device='cuda:0')\n(('Canada Water', 'Canary Wharf'), ('Canary Wharf', 'North Greenwich')) tensor(765., device='cuda:0')\n(('Canary Wharf', 'Canada Water'), ('Canada Water', 'Bermondsey')) tensor(1104., device='cuda:0')\n(('Canary Wharf', 'North Greenwich'), ('North Greenwich', 'Canning Town')) tensor(600., device='cuda:0')\n(('Canning Town', 'North Greenwich'), ('North Greenwich', 'Canary Wharf')) tensor(598., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Barking')) tensor(304., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(5., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Plaistow')) tensor(79., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Stratford')) tensor(222., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(198., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(78., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(42., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(59., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(96., device='cuda:0')\n(('Cannon Street', 'Mansion House'), ('Mansion House', 'Blackfriars')) tensor(268., device='cuda:0')\n(('Canons Park', 'Queensbury'), ('Queensbury', 'Kingsbury')) tensor(218., device='cuda:0')\n(('Chalfont &amp; Latimer', 'Chorleywood'), ('Chorleywood', 'Rickmansworth')) tensor(395., device='cuda:0')\n(('Chalk Farm', 'Belsize Park'), ('Belsize Park', 'Hampstead')) tensor(910., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1248., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(43., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(9., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(220., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Russell Square')) tensor(115., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(3066., device='cuda:0')\n(('Chancery Lane', \"St. Paul's\"), (\"St. Paul's\", 'Bank / Monument')) tensor(3482., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Temple')) tensor(61., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Waterloo')) tensor(231., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Westminster')) tensor(5., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(59., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(159., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(122., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(304., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(1., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(85., device='cuda:0')\n(('Chigwell', 'Grange Hill'), ('Grange Hill', 'Hainault')) tensor(204., device='cuda:0')\n(('Chigwell', 'Roding Valley'), ('Roding Valley', 'Woodford')) tensor(320., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(90., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(6., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(1., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(146., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(62., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'HarrowOnTheHill')) tensor(496., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'Moor Park')) tensor(10., device='cuda:0')\n(('Clapham Common', 'Clapham North'), ('Clapham North', 'Stockwell')) tensor(1504., device='cuda:0')\n(('Clapham Common', 'Clapham South'), ('Clapham South', 'Balham')) tensor(969., device='cuda:0')\n(('Clapham North', 'Clapham Common'), ('Clapham Common', 'Clapham South')) tensor(1148., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(8., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Oval')) tensor(964., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(686., device='cuda:0')\n(('Clapham South', 'Balham'), ('Balham', 'Tooting Bec')) tensor(782., device='cuda:0')\n(('Clapham South', 'Clapham Common'), ('Clapham Common', 'Clapham North')) tensor(1297., device='cuda:0')\n(('Cockfosters', 'Oakwood'), ('Oakwood', 'Southgate')) tensor(120., device='cuda:0')\n(('Colindale', 'Burnt Oak'), ('Burnt Oak', 'Edgware')) tensor(139., device='cuda:0')\n(('Colindale', 'Hendon Central'), ('Hendon Central', 'Brent Cross')) tensor(370., device='cuda:0')\n(('Colliers Wood', 'South Wimbledon'), ('South Wimbledon', 'Morden')) tensor(152., device='cuda:0')\n(('Colliers Wood', 'Tooting Broadway'), ('Tooting Broadway', 'Tooting Bec')) tensor(477., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(239., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Russell Square')) tensor(90., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(52., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(129., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(238., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(6., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Dagenham East', 'Dagenham Heathway'), ('Dagenham Heathway', 'Becontree')) tensor(161., device='cuda:0')\n(('Dagenham East', 'Elm Park'), ('Elm Park', 'Hornchurch')) tensor(5., device='cuda:0')\n(('Dagenham Heathway', 'Becontree'), ('Becontree', 'Upney')) tensor(418., device='cuda:0')\n(('Dagenham Heathway', 'Dagenham East'), ('Dagenham East', 'Elm Park')) tensor(5., device='cuda:0')\n(('Debden', 'Loughton'), ('Loughton', 'Buckhurst Hill')) tensor(577., device='cuda:0')\n(('Debden', 'Theydon Bois'), ('Theydon Bois', 'Epping')) tensor(217., device='cuda:0')\n(('Dollis Hill', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(118., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(2., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(2315., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(113., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Bayswater')) tensor(117., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(132., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(3451., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(94., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(60., device='cuda:0')\n(('Ealing Broadway', 'West Acton'), ('West Acton', 'North Acton')) tensor(875., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(105., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(508., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(1068., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(699., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(2570., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(49., device='cuda:0')\n(('Ealing Common', 'North Ealing'), ('North Ealing', 'Park Royal')) tensor(232., device='cuda:0')\n((\"Earl's Court\", 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(1065., device='cuda:0')\n((\"Earl's Court\", 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(3117., device='cuda:0')\n((\"Earl's Court\", 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(504., device='cuda:0')\n((\"Earl's Court\", 'West Brompton'), ('West Brompton', 'Fulham Broadway')) tensor(1757., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(70., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'West Acton')) tensor(168., device='cuda:0')\n(('East Acton', 'White City'), ('White City', \"Shepherd's Bush (Cen)\")) tensor(103., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(69., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(427., device='cuda:0')\n(('East Finchley', 'Highgate'), ('Highgate', 'Archway')) tensor(844., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upminster')) tensor(8., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upney')) tensor(7., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'West Ham')) tensor(426., device='cuda:0')\n(('East Ham', 'Upton Park'), ('Upton Park', 'Plaistow')) tensor(1., device='cuda:0')\n(('East Putney', 'Putney Bridge'), ('Putney Bridge', 'Parsons Green')) tensor(969., device='cuda:0')\n(('East Putney', 'Southfields'), ('Southfields', 'Wimbledon Park')) tensor(375., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(66., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(918., device='cuda:0')\n(('Eastcote', 'Ruislip Manor'), ('Ruislip Manor', 'Ruislip')) tensor(619., device='cuda:0')\n(('Edgware', 'Burnt Oak'), ('Burnt Oak', 'Colindale')) tensor(118., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(122., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(326., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(153., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(135., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(50., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(44., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(2860., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(253., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(2439., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(13., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(425., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(57., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(475., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(3182., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(590., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(924., device='cuda:0')\n(('Elephant &amp; Castle', 'Borough'), ('Borough', 'London Bridge')) tensor(867., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Oval')) tensor(627., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Waterloo')) tensor(217., device='cuda:0')\n(('Elephant &amp; Castle', 'Lambeth North'), ('Lambeth North', 'Waterloo')) tensor(211., device='cuda:0')\n(('Elm Park', 'Dagenham East'), ('Dagenham East', 'Dagenham Heathway')) tensor(5., device='cuda:0')\n(('Elm Park', 'Hornchurch'), ('Hornchurch', 'Upminster Bridge')) tensor(238., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Leicester Square')) tensor(114., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Piccadilly Circus')) tensor(175., device='cuda:0')\n(('Embankment', 'Temple'), ('Temple', 'Blackfriars')) tensor(412., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(105., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(23., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(276., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', 'Green Park')) tensor(549., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(132., device='cuda:0')\n(('Epping', 'Theydon Bois'), ('Theydon Bois', 'Debden')) tensor(306., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(1176., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(1482., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(703., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(131., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(326., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(683., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(576., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(100., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(88., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(2579., device='cuda:0')\n(('Euston Square', 'Great Portland Street'), ('Great Portland Street', 'Baker Street')) tensor(4039., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(1503., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(154., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(315., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(1522., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(739., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(87., device='cuda:0')\n(('Fairlop', 'Barkingside'), ('Barkingside', 'Newbury Park')) tensor(301., device='cuda:0')\n(('Fairlop', 'Hainault'), ('Hainault', 'Grange Hill')) tensor(3., device='cuda:0')\n(('Farringdon', 'Barbican'), ('Barbican', 'Moorgate')) tensor(2110., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(3., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(45., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(626., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1384., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(32., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(45., device='cuda:0')\n(('Finchley Central', 'East Finchley'), ('East Finchley', 'Highgate')) tensor(687., device='cuda:0')\n(('Finchley Central', 'West Finchley'), ('West Finchley', 'Woodside Park')) tensor(345., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1763., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(214., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(1034., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(145., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(245., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(172., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(95., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(235., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(603., device='cuda:0')\n(('Finchley Road', 'Swiss Cottage'), ('Swiss Cottage', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(338., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(96., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(85., device='cuda:0')\n(('Finchley Road', 'West Hampstead'), ('West Hampstead', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(110., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(98., device='cuda:0')\n(('Finsbury Park', 'Arsenal'), ('Arsenal', 'Holloway Road')) tensor(65., device='cuda:0')\n(('Finsbury Park', 'Highbury &amp; Islington'), ('Highbury &amp; Islington', \"King's Cross St. Pancras\")) tensor(1377., device='cuda:0')\n(('Finsbury Park', 'Manor House'), ('Manor House', 'Turnpike Lane')) tensor(960., device='cuda:0')\n(('Finsbury Park', 'Seven Sisters'), ('Seven Sisters', 'Tottenham Hale')) tensor(708., device='cuda:0')\n(('Fulham Broadway', 'Parsons Green'), ('Parsons Green', 'Putney Bridge')) tensor(1095., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', \"Earl's Court\")) tensor(1813., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', 'Kensington (Olympia)')) tensor(4., device='cuda:0')\n(('Gants Hill', 'Newbury Park'), ('Newbury Park', 'Barkingside')) tensor(471., device='cuda:0')\n(('Gants Hill', 'Redbridge'), ('Redbridge', 'Wanstead')) tensor(1094., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(1135., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(98., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(1410., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(192., device='cuda:0')\n(('Gloucester Road', 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(158., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(1378., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(2449., device='cuda:0')\n(('Golders Green', 'Brent Cross'), ('Brent Cross', 'Hendon Central')) tensor(542., device='cuda:0')\n(('Golders Green', 'Hampstead'), ('Hampstead', 'Belsize Park')) tensor(846., device='cuda:0')\n(('Goldhawk Road', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Wood Lane')) tensor(201., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(73., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(59., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(38., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(41., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Euston')) tensor(79., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(42., device='cuda:0')\n(('Grange Hill', 'Chigwell'), ('Chigwell', 'Roding Valley')) tensor(256., device='cuda:0')\n(('Grange Hill', 'Hainault'), ('Hainault', 'Fairlop')) tensor(3., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(93., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2262., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(946., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(582., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(14., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(115., device='cuda:0')\n(('Great Portland Street', 'Euston Square'), ('Euston Square', \"King's Cross St. Pancras\")) tensor(4322., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2417., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(156., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(245., device='cuda:0')\n(('Green Park', 'Hyde Park Corner'), ('Hyde Park Corner', 'Knightsbridge')) tensor(1812., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(41., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(250., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(1507., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(131., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(101., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Pimlico')) tensor(1017., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1741., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(140., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Embankment')) tensor(595., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(136., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Waterloo')) tensor(3391., device='cuda:0')\n(('Greenford', 'Northolt'), ('Northolt', 'South Ruislip')) tensor(194., device='cuda:0')\n(('Greenford', 'Perivale'), ('Perivale', 'Hanger Lane')) tensor(544., device='cuda:0')\n(('Gunnersbury', 'Kew Gardens'), ('Kew Gardens', 'Richmond')) tensor(293., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(557., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(217., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(6., device='cuda:0')\n(('Hainault', 'Fairlop'), ('Fairlop', 'Barkingside')) tensor(189., device='cuda:0')\n(('Hainault', 'Grange Hill'), ('Grange Hill', 'Chigwell')) tensor(187., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(437., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(191., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', \"Earl's Court\")) tensor(1123., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', 'West Kensington')) tensor(25., device='cuda:0')\n(('Hammersmith (Dis)', 'Ravenscourt Park'), ('Ravenscourt Park', 'Stamford Brook')) tensor(54., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(177., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(58., device='cuda:0')\n(('Hammersmith (H&amp;C)', 'Goldhawk Road'), ('Goldhawk Road', \"Shepherd's Bush Market\")) tensor(108., device='cuda:0')\n(('Hampstead', 'Belsize Park'), ('Belsize Park', 'Chalk Farm')) tensor(982., device='cuda:0')\n(('Hampstead', 'Golders Green'), ('Golders Green', 'Brent Cross')) tensor(610., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'East Acton')) tensor(80., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'West Acton')) tensor(688., device='cuda:0')\n(('Hanger Lane', 'Perivale'), ('Perivale', 'Greenford')) tensor(454., device='cuda:0')\n(('Harlesden', 'Stonebridge Park'), ('Stonebridge Park', 'Wembley Central')) tensor(333., device='cuda:0')\n(('Harlesden', 'Willesden Junction'), ('Willesden Junction', 'Kensal Green')) tensor(545., device='cuda:0')\n(('Harrow &amp; Wealdstone', 'Kenton'), ('Kenton', 'South Kenton')) tensor(118., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(1461., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(29., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(33., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(36., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(1479., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(383., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(222., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'North Harrow'), ('North Harrow', 'Pinner')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'Northwick Park'), ('Northwick Park', 'Preston Road')) tensor(21., device='cuda:0')\n(('HarrowOnTheHill', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(389., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(59., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'West Harrow'), ('West Harrow', 'Rayners Lane')) tensor(1303., device='cuda:0')\n(('Hatton Cross', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Heathrow Terminal 5')) tensor(75., device='cuda:0')\n(('Hatton Cross', 'Hounslow West'), ('Hounslow West', 'Hounslow Central')) tensor(571., device='cuda:0')\n(('Heathrow Terminal 4', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(123., device='cuda:0')\n(('Heathrow Terminal 5', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Hatton Cross')) tensor(92., device='cuda:0')\n(('Heathrow Terminals 123', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(332., device='cuda:0')\n(('Hendon Central', 'Brent Cross'), ('Brent Cross', 'Golders Green')) tensor(568., device='cuda:0')\n(('Hendon Central', 'Colindale'), ('Colindale', 'Burnt Oak')) tensor(251., device='cuda:0')\n(('High Barnet', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'Woodside Park')) tensor(159., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(97., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(15., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(379., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(34., device='cuda:0')\n(('High Street Kensington', 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(452., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(518., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(110., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(172., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(80., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(768., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(392., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(32., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(13., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(617., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(725., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(33., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(144., device='cuda:0')\n(('Highgate', 'Archway'), ('Archway', 'Tufnell Park')) tensor(1030., device='cuda:0')\n(('Highgate', 'East Finchley'), ('East Finchley', 'Finchley Central')) tensor(639., device='cuda:0')\n(('Hillingdon', 'Ickenham'), ('Ickenham', 'Ruislip')) tensor(424., device='cuda:0')\n(('Holborn', 'Chancery Lane'), ('Chancery Lane', \"St. Paul's\")) tensor(3506., device='cuda:0')\n(('Holborn', 'Covent Garden'), ('Covent Garden', 'Leicester Square')) tensor(203., device='cuda:0')\n(('Holborn', 'Russell Square'), ('Russell Square', \"King's Cross St. Pancras\")) tensor(302., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(2909., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(63., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(215., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(404., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(96., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(127., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(328., device='cuda:0')\n(('Holland Park', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'White City')) tensor(277., device='cuda:0')\n(('Holloway Road', 'Arsenal'), ('Arsenal', 'Finsbury Park')) tensor(69., device='cuda:0')\n(('Holloway Road', 'Caledonian Road'), ('Caledonian Road', \"King's Cross St. Pancras\")) tensor(243., device='cuda:0')\n(('Hornchurch', 'Elm Park'), ('Elm Park', 'Dagenham East')) tensor(4., device='cuda:0')\n(('Hornchurch', 'Upminster Bridge'), ('Upminster Bridge', 'Upminster')) tensor(437., device='cuda:0')\n(('Hounslow Central', 'Hounslow East'), ('Hounslow East', 'Osterley')) tensor(828., device='cuda:0')\n(('Hounslow Central', 'Hounslow West'), ('Hounslow West', 'Hatton Cross')) tensor(433., device='cuda:0')\n(('Hounslow East', 'Hounslow Central'), ('Hounslow Central', 'Hounslow West')) tensor(554., device='cuda:0')\n(('Hounslow East', 'Osterley'), ('Osterley', 'Boston Manor')) tensor(959., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminal 4')) tensor(69., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminals 123')) tensor(277., device='cuda:0')\n(('Hounslow West', 'Hounslow Central'), ('Hounslow Central', 'Hounslow East')) tensor(667., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Bond Street')) tensor(234., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(492., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(73., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Victoria')) tensor(20., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Westminster')) tensor(1029., device='cuda:0')\n(('Hyde Park Corner', 'Knightsbridge'), ('Knightsbridge', 'South Kensington')) tensor(1581., device='cuda:0')\n(('Ickenham', 'Hillingdon'), ('Hillingdon', 'Uxbridge')) tensor(257., device='cuda:0')\n(('Ickenham', 'Ruislip'), ('Ruislip', 'Ruislip Manor')) tensor(541., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(774., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Oval'), ('Oval', 'Stockwell')) tensor(1245., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(113., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(715., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(378., device='cuda:0')\n(('Kensal Green', \"Queen's Park\"), (\"Queen's Park\", 'Kilburn Park')) tensor(754., device='cuda:0')\n(('Kensal Green', 'Willesden Junction'), ('Willesden Junction', 'Harlesden')) tensor(470., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(47., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1547., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(11., device='cuda:0')\n(('Kentish Town', 'Tufnell Park'), ('Tufnell Park', 'Archway')) tensor(1191., device='cuda:0')\n(('Kenton', 'South Kenton'), ('South Kenton', 'North Wembley')) tensor(150., device='cuda:0')\n(('Kew Gardens', 'Gunnersbury'), ('Gunnersbury', 'Turnham Green')) tensor(510., device='cuda:0')\n(('Kilburn', 'West Hampstead'), ('West Hampstead', 'Finchley Road')) tensor(140., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(1., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(145., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(8., device='cuda:0')\n(('Kilburn Park', 'Maida Vale'), ('Maida Vale', 'Warwick Avenue')) tensor(1048., device='cuda:0')\n(('Kilburn Park', \"Queen's Park\"), (\"Queen's Park\", 'Kensal Green')) tensor(622., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Angel'), ('Angel', 'Old Street')) tensor(2221., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Caledonian Road'), ('Caledonian Road', 'Holloway Road')) tensor(246., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Camden Town')) tensor(1406., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Mornington Crescent')) tensor(85., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Warren Street')) tensor(881., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston Square'), ('Euston Square', 'Great Portland Street')) tensor(4062., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Farringdon'), ('Farringdon', 'Barbican')) tensor(2195., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Highbury &amp; Islington'), ('Highbury &amp; Islington', 'Finsbury Park')) tensor(1352., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Russell Square'), ('Russell Square', 'Holborn')) tensor(299., device='cuda:0')\n(('Kingsbury', 'Queensbury'), ('Queensbury', 'Canons Park')) tensor(189., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(334., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(66., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(16., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(1., device='cuda:0')\n(('Knightsbridge', 'Hyde Park Corner'), ('Hyde Park Corner', 'Green Park')) tensor(1733., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(1409., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(14., device='cuda:0')\n(('Ladbroke Grove', 'Latimer Road'), ('Latimer Road', 'Wood Lane')) tensor(299., device='cuda:0')\n(('Ladbroke Grove', 'Westbourne Park'), ('Westbourne Park', 'Royal Oak')) tensor(607., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(83., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(19., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(45., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(287., device='cuda:0')\n(('Lancaster Gate', 'Marble Arch'), ('Marble Arch', 'Bond Street')) tensor(839., device='cuda:0')\n(('Lancaster Gate', 'Queensway'), ('Queensway', 'Notting Hill Gate')) tensor(616., device='cuda:0')\n(('Latimer Road', 'Ladbroke Grove'), ('Ladbroke Grove', 'Westbourne Park')) tensor(446., device='cuda:0')\n(('Latimer Road', 'Wood Lane'), ('Wood Lane', \"Shepherd's Bush Market\")) tensor(240., device='cuda:0')\n(('Leicester Square', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(103., device='cuda:0')\n(('Leicester Square', 'Covent Garden'), ('Covent Garden', 'Holborn')) tensor(222., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(101., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(277., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(39., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(212., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(1851., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(1449., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Mile End')) tensor(1671., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'West Ham')) tensor(95., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2639., device='cuda:0')\n(('Leytonstone', 'Leyton'), ('Leyton', 'Stratford')) tensor(3987., device='cuda:0')\n(('Leytonstone', 'Snaresbrook'), ('Snaresbrook', 'South Woodford')) tensor(1706., device='cuda:0')\n(('Leytonstone', 'Wanstead'), ('Wanstead', 'Redbridge')) tensor(1245., device='cuda:0')\n(('Liverpool Street', 'Aldgate'), ('Aldgate', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(3609., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(2842., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(2155., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Bethnal Green'), ('Bethnal Green', 'Mile End')) tensor(3900., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(1688., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(1701., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(546., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(73., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2915., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(495., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(107., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1264., device='cuda:0')\n(('London Bridge', 'Bermondsey'), ('Bermondsey', 'Canada Water')) tensor(1250., device='cuda:0')\n(('London Bridge', 'Borough'), ('Borough', 'Elephant &amp; Castle')) tensor(795., device='cuda:0')\n(('London Bridge', 'Southwark'), ('Southwark', 'Waterloo')) tensor(4797., device='cuda:0')\n(('Loughton', 'Buckhurst Hill'), ('Buckhurst Hill', 'Woodford')) tensor(773., device='cuda:0')\n(('Loughton', 'Debden'), ('Debden', 'Theydon Bois')) tensor(301., device='cuda:0')\n(('Maida Vale', 'Kilburn Park'), ('Kilburn Park', \"Queen's Park\")) tensor(736., device='cuda:0')\n(('Maida Vale', 'Warwick Avenue'), ('Warwick Avenue', 'Paddington')) tensor(1186., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(21., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(806., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(328., device='cuda:0')\n(('Manor House', 'Turnpike Lane'), ('Turnpike Lane', 'Wood Green')) tensor(794., device='cuda:0')\n(('Mansion House', 'Blackfriars'), ('Blackfriars', 'Temple')) tensor(286., device='cuda:0')\n(('Mansion House', 'Cannon Street'), ('Cannon Street', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(104., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(145., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(161., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(658., device='cuda:0')\n(('Marble Arch', 'Lancaster Gate'), ('Lancaster Gate', 'Queensway')) tensor(725., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1060., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(1., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(4., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(601., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(104., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(15., device='cuda:0')\n(('Marylebone', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Paddington')) tensor(393., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(5., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(262., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(185., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(115., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(265., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(69., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(699., device='cuda:0')\n(('Mile End', 'Bethnal Green'), ('Bethnal Green', 'Liverpool Street')) tensor(3726., device='cuda:0')\n(('Mile End', 'Bow Road'), ('Bow Road', 'BromleyByBow')) tensor(112., device='cuda:0')\n(('Mile End', 'Stepney Green'), ('Stepney Green', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Leyton')) tensor(1541., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'West Ham')) tensor(1383., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(94., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(3., device='cuda:0')\n(('Moor Park', 'Croxley'), ('Croxley', 'Watford')) tensor(124., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(255., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(284., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(9., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(13., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(20., device='cuda:0')\n(('Moor Park', 'Northwood'), ('Northwood', 'Northwood Hills')) tensor(113., device='cuda:0')\n(('Moor Park', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(9., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(55., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(455., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(15., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(54., device='cuda:0')\n(('Moorgate', 'Barbican'), ('Barbican', 'Farringdon')) tensor(1978., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(187., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(1525., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(1624., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(26., device='cuda:0')\n(('Moorgate', 'Old Street'), ('Old Street', 'Angel')) tensor(2014., device='cuda:0')\n(('Morden', 'South Wimbledon'), ('South Wimbledon', 'Colliers Wood')) tensor(199., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(9., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(10., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(82., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', 'Warren Street')) tensor(88., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(114., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(14., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(5., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(108., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(8., device='cuda:0')\n(('Newbury Park', 'Barkingside'), ('Barkingside', 'Fairlop')) tensor(335., device='cuda:0')\n(('Newbury Park', 'Gants Hill'), ('Gants Hill', 'Redbridge')) tensor(742., device='cuda:0')\n(('North Acton', 'East Acton'), ('East Acton', 'White City')) tensor(131., device='cuda:0')\n(('North Acton', 'Hanger Lane'), ('Hanger Lane', 'Perivale')) tensor(534., device='cuda:0')\n(('North Acton', 'West Acton'), ('West Acton', 'Ealing Broadway')) tensor(1035., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(189., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(152., device='cuda:0')\n(('North Ealing', 'Park Royal'), ('Park Royal', 'Alperton')) tensor(180., device='cuda:0')\n(('North Greenwich', 'Canary Wharf'), ('Canary Wharf', 'Canada Water')) tensor(806., device='cuda:0')\n(('North Greenwich', 'Canning Town'), ('Canning Town', 'West Ham')) tensor(513., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(190., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(196., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(3., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(7., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(10., device='cuda:0')\n(('North Harrow', 'Pinner'), ('Pinner', 'Northwood Hills')) tensor(104., device='cuda:0')\n(('North Wembley', 'South Kenton'), ('South Kenton', 'Kenton')) tensor(163., device='cuda:0')\n(('North Wembley', 'Wembley Central'), ('Wembley Central', 'Stonebridge Park')) tensor(272., device='cuda:0')\n(('Northfields', 'Boston Manor'), ('Boston Manor', 'Osterley')) tensor(924., device='cuda:0')\n(('Northfields', 'South Ealing'), ('South Ealing', 'Acton Town')) tensor(1308., device='cuda:0')\n(('Northolt', 'Greenford'), ('Greenford', 'Perivale')) tensor(382., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'Ruislip Gardens')) tensor(51., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'West Ruislip')) tensor(73., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(92., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(110., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(7., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(2., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(13., device='cuda:0')\n(('Northwick Park', 'Preston Road'), ('Preston Road', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(257., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Northwood', 'Northwood Hills'), ('Northwood Hills', 'Pinner')) tensor(5., device='cuda:0')\n(('Northwood Hills', 'Northwood'), ('Northwood', 'Moor Park')) tensor(124., device='cuda:0')\n(('Northwood Hills', 'Pinner'), ('Pinner', 'North Harrow')) tensor(107., device='cuda:0')\n(('Notting Hill Gate', 'Bayswater'), ('Bayswater', 'Paddington')) tensor(656., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', \"Earl's Court\")) tensor(581., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', 'Gloucester Road')) tensor(194., device='cuda:0')\n(('Notting Hill Gate', 'Holland Park'), ('Holland Park', \"Shepherd's Bush (Cen)\")) tensor(462., device='cuda:0')\n(('Notting Hill Gate', 'Queensway'), ('Queensway', 'Lancaster Gate')) tensor(611., device='cuda:0')\n(('Oakwood', 'Southgate'), ('Southgate', 'Arnos Grove')) tensor(229., device='cuda:0')\n(('Old Street', 'Angel'), ('Angel', \"King's Cross St. Pancras\")) tensor(2078., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(296., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(3., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1828., device='cuda:0')\n(('Osterley', 'Boston Manor'), ('Boston Manor', 'Northfields')) tensor(1091., device='cuda:0')\n(('Osterley', 'Hounslow East'), ('Hounslow East', 'Hounslow Central')) tensor(679., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(691., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Waterloo')) tensor(837., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(155., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(859., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(169., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(672., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(178., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(519., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(999., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(361., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(304., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', \"Regent's Park\"), (\"Regent's Park\", 'Baker Street')) tensor(674., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(47., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(376., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Euston')) tensor(2437., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(48., device='cuda:0')\n(('Paddington', 'Bayswater'), ('Bayswater', 'Notting Hill Gate')) tensor(811., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(2429., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(891., device='cuda:0')\n(('Paddington', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Marylebone')) tensor(353., device='cuda:0')\n(('Paddington', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Baker Street')) tensor(5928., device='cuda:0')\n(('Paddington', 'Royal Oak'), ('Royal Oak', 'Westbourne Park')) tensor(686., device='cuda:0')\n(('Paddington', 'Warwick Avenue'), ('Warwick Avenue', 'Maida Vale')) tensor(976., device='cuda:0')\n(('Park Royal', 'Alperton'), ('Alperton', 'Sudbury Town')) tensor(128., device='cuda:0')\n(('Park Royal', 'North Ealing'), ('North Ealing', 'Ealing Common')) tensor(305., device='cuda:0')\n(('Parsons Green', 'Fulham Broadway'), ('Fulham Broadway', 'West Brompton')) tensor(1506., device='cuda:0')\n(('Parsons Green', 'Putney Bridge'), ('Putney Bridge', 'East Putney')) tensor(828., device='cuda:0')\n(('Perivale', 'Greenford'), ('Greenford', 'Northolt')) tensor(321., device='cuda:0')\n(('Perivale', 'Hanger Lane'), ('Hanger Lane', 'North Acton')) tensor(621., device='cuda:0')\n(('Piccadilly Circus', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(180., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Bond Street')) tensor(220., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(74., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(109., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(106., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(138., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(82., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(218., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(215., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(80., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(174., device='cuda:0')\n(('Pimlico', 'Vauxhall'), ('Vauxhall', 'Stockwell')) tensor(940., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Green Park')) tensor(1025., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(258., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(89., device='cuda:0')\n(('Pinner', 'North Harrow'), ('North Harrow', 'HarrowOnTheHill')) tensor(261., device='cuda:0')\n(('Pinner', 'Northwood Hills'), ('Northwood Hills', 'Northwood')) tensor(5., device='cuda:0')\n(('Plaistow', 'Upton Park'), ('Upton Park', 'East Ham')) tensor(1., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Barking')) tensor(9., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(4., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(97., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Stratford')) tensor(770., device='cuda:0')\n(('Preston Road', 'Northwick Park'), ('Northwick Park', 'HarrowOnTheHill')) tensor(23., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(84., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(22., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(2., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(5., device='cuda:0')\n(('Putney Bridge', 'East Putney'), ('East Putney', 'Southfields')) tensor(577., device='cuda:0')\n(('Putney Bridge', 'Parsons Green'), ('Parsons Green', 'Fulham Broadway')) tensor(1250., device='cuda:0')\n((\"Queen's Park\", 'Kensal Green'), ('Kensal Green', 'Willesden Junction')) tensor(551., device='cuda:0')\n((\"Queen's Park\", 'Kilburn Park'), ('Kilburn Park', 'Maida Vale')) tensor(903., device='cuda:0')\n(('Queensbury', 'Canons Park'), ('Canons Park', 'Stanmore')) tensor(99., device='cuda:0')\n(('Queensbury', 'Kingsbury'), ('Kingsbury', 'Wembley Park')) tensor(312., device='cuda:0')\n(('Queensway', 'Lancaster Gate'), ('Lancaster Gate', 'Marble Arch')) tensor(723., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(18., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(165., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(333., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(76., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(173., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Ravenscourt Park', 'Stamford Brook'), ('Stamford Brook', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Rayners Lane', 'Eastcote'), ('Eastcote', 'Ruislip Manor')) tensor(743., device='cuda:0')\n(('Rayners Lane', 'South Harrow'), ('South Harrow', 'Sudbury Hill')) tensor(253., device='cuda:0')\n(('Rayners Lane', 'West Harrow'), ('West Harrow', 'HarrowOnTheHill')) tensor(1408., device='cuda:0')\n(('Redbridge', 'Gants Hill'), ('Gants Hill', 'Newbury Park')) tensor(701., device='cuda:0')\n(('Redbridge', 'Wanstead'), ('Wanstead', 'Leytonstone')) tensor(1302., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(426., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(150., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(6., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(106., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(12., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(40., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(211., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(26., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(347., device='cuda:0')\n(('Richmond', 'Kew Gardens'), ('Kew Gardens', 'Gunnersbury')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'Chorleywood'), ('Chorleywood', 'Chalfont &amp; Latimer')) tensor(312., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(276., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(9., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(11., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(7., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(3., device='cuda:0')\n(('Roding Valley', 'Chigwell'), ('Chigwell', 'Grange Hill')) tensor(261., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(8., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'South Woodford')) tensor(372., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Bayswater')) tensor(47., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(92., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(54., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(684., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(8., device='cuda:0')\n(('Royal Oak', 'Westbourne Park'), ('Westbourne Park', 'Ladbroke Grove')) tensor(569., device='cuda:0')\n(('Ruislip', 'Ickenham'), ('Ickenham', 'Hillingdon')) tensor(398., device='cuda:0')\n(('Ruislip', 'Ruislip Manor'), ('Ruislip Manor', 'Eastcote')) tensor(712., device='cuda:0')\n(('Ruislip Gardens', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(78., device='cuda:0')\n(('Ruislip Manor', 'Eastcote'), ('Eastcote', 'Rayners Lane')) tensor(825., device='cuda:0')\n(('Ruislip Manor', 'Ruislip'), ('Ruislip', 'Ickenham')) tensor(496., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(119., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(90., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(327., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(59., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(40., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(91., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(86., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(53., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(151., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(66., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(387., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(335., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(153., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(561., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'Holland Park'), ('Holland Park', 'Notting Hill Gate')) tensor(468., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'White City'), ('White City', 'East Acton')) tensor(93., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Goldhawk Road'), ('Goldhawk Road', 'Hammersmith (H&amp;C)')) tensor(77., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Wood Lane'), ('Wood Lane', 'Latimer Road')) tensor(279., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(2467., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(15., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Green Park')) tensor(1713., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Pimlico')) tensor(260., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(1042., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(2080., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(7., device='cuda:0')\n(('Snaresbrook', 'South Woodford'), ('South Woodford', 'Woodford')) tensor(1415., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(8., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(1168., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(212., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(25., device='cuda:0')\n(('South Ealing', 'Northfields'), ('Northfields', 'Boston Manor')) tensor(1019., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(62., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(316., device='cuda:0')\n(('South Harrow', 'Sudbury Hill'), ('Sudbury Hill', 'Sudbury Town')) tensor(183., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', \"Earl's Court\")) tensor(3171., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', 'High Street Kensington')) tensor(414., device='cuda:0')\n(('South Kensington', 'Knightsbridge'), ('Knightsbridge', 'Hyde Park Corner')) tensor(1538., device='cuda:0')\n(('South Kensington', 'Sloane Square'), ('Sloane Square', 'Victoria')) tensor(2746., device='cuda:0')\n(('South Kenton', 'Kenton'), ('Kenton', 'Harrow &amp; Wealdstone')) tensor(119., device='cuda:0')\n(('South Kenton', 'North Wembley'), ('North Wembley', 'Wembley Central')) tensor(207., device='cuda:0')\n(('South Ruislip', 'Northolt'), ('Northolt', 'Greenford')) tensor(252., device='cuda:0')\n(('South Wimbledon', 'Colliers Wood'), ('Colliers Wood', 'Tooting Broadway')) tensor(328., device='cuda:0')\n(('South Woodford', 'Snaresbrook'), ('Snaresbrook', 'Leytonstone')) tensor(1888., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(830., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(309., device='cuda:0')\n(('Southfields', 'East Putney'), ('East Putney', 'Putney Bridge')) tensor(677., device='cuda:0')\n(('Southfields', 'Wimbledon Park'), ('Wimbledon Park', 'Wimbledon')) tensor(255., device='cuda:0')\n(('Southgate', 'Arnos Grove'), ('Arnos Grove', 'Bounds Green')) tensor(390., device='cuda:0')\n(('Southgate', 'Oakwood'), ('Oakwood', 'Cockfosters')) tensor(101., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(3604., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(1002., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Borough')) tensor(52., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(279., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(640., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(45., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(3875., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Green Park')) tensor(132., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Pimlico')) tensor(84., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1027., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Embankment')) tensor(128., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Green Park')) tensor(135., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Waterloo')) tensor(1190., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(168., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(54., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(119., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(16., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(11., device='cuda:0')\n((\"St. John's Wood\", 'Swiss Cottage'), ('Swiss Cottage', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(49., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2220., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(86., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(13., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1106., device='cuda:0')\n((\"St. Paul's\", 'Chancery Lane'), ('Chancery Lane', 'Holborn')) tensor(3317., device='cuda:0')\n(('Stamford Brook', 'Ravenscourt Park'), ('Ravenscourt Park', 'Hammersmith (Dis)')) tensor(63., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(89., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(6., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(67., device='cuda:0')\n(('Stanmore', 'Canons Park'), ('Canons Park', 'Queensbury')) tensor(110., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(132., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(5., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(24., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(214., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(25., device='cuda:0')\n(('Stockwell', 'Clapham North'), ('Clapham North', 'Clapham Common')) tensor(1366., device='cuda:0')\n(('Stockwell', 'Oval'), ('Oval', 'Kennington')) tensor(1370., device='cuda:0')\n(('Stockwell', 'Vauxhall'), ('Vauxhall', 'Pimlico')) tensor(928., device='cuda:0')\n(('Stonebridge Park', 'Harlesden'), ('Harlesden', 'Willesden Junction')) tensor(443., device='cuda:0')\n(('Stonebridge Park', 'Wembley Central'), ('Wembley Central', 'North Wembley')) tensor(257., device='cuda:0')\n(('Stratford', 'Leyton'), ('Leyton', 'Leytonstone')) tensor(3711., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(3185., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bow Road')) tensor(8., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(27., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Barking')) tensor(2374., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(7., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Canning Town')) tensor(170., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Plaistow')) tensor(707., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(5039., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(26., device='cuda:0')\n(('Sudbury Hill', 'South Harrow'), ('South Harrow', 'Rayners Lane')) tensor(290., device='cuda:0')\n(('Sudbury Hill', 'Sudbury Town'), ('Sudbury Town', 'Alperton')) tensor(143., device='cuda:0')\n(('Sudbury Town', 'Alperton'), ('Alperton', 'Park Royal')) tensor(166., device='cuda:0')\n(('Sudbury Town', 'Sudbury Hill'), ('Sudbury Hill', 'South Harrow')) tensor(190., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(180., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(4., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(8., device='cuda:0')\n(('Swiss Cottage', \"St. John's Wood\"), (\"St. John's Wood\", 'Baker Street')) tensor(175., device='cuda:0')\n(('Temple', 'Blackfriars'), ('Blackfriars', 'Mansion House')) tensor(291., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(57., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Waterloo')) tensor(44., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Westminster')) tensor(487., device='cuda:0')\n(('Theydon Bois', 'Debden'), ('Debden', 'Loughton')) tensor(447., device='cuda:0')\n(('Tooting Bec', 'Balham'), ('Balham', 'Clapham South')) tensor(939., device='cuda:0')\n(('Tooting Bec', 'Tooting Broadway'), ('Tooting Broadway', 'Colliers Wood')) tensor(404., device='cuda:0')\n(('Tooting Broadway', 'Colliers Wood'), ('Colliers Wood', 'South Wimbledon')) tensor(264., device='cuda:0')\n(('Tooting Broadway', 'Tooting Bec'), ('Tooting Bec', 'Balham')) tensor(763., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2377., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(244., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(630., device='cuda:0')\n(('Tottenham Court Road', 'Goodge Street'), ('Goodge Street', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(3254., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(104., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Russell Square')) tensor(322., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(154., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(101., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(86., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(245., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(80., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(40., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Hale', 'Blackhorse Road'), ('Blackhorse Road', 'Walthamstow Central')) tensor(197., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(24., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(138., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(566., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(133., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(26., device='cuda:0')\n(('Tottenham Hale', 'Seven Sisters'), ('Seven Sisters', 'Finsbury Park')) tensor(690., device='cuda:0')\n(('Totteridge &amp; Whetstone', 'Woodside Park'), ('Woodside Park', 'West Finchley')) tensor(259., device='cuda:0')\n(('Tower Hill', 'Aldgate'), ('Aldgate', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(2085., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(96., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(17., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(1239., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(59., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(1078., device='cuda:0')\n(('Tufnell Park', 'Archway'), ('Archway', 'Highgate')) tensor(965., device='cuda:0')\n(('Tufnell Park', 'Kentish Town'), ('Kentish Town', 'Camden Town')) tensor(1387., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(769., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(21., device='cuda:0')\n(('Turnham Green', 'Gunnersbury'), ('Gunnersbury', 'Kew Gardens')) tensor(470., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(367., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnham Green', 'Stamford Brook'), ('Stamford Brook', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnpike Lane', 'Manor House'), ('Manor House', 'Finsbury Park')) tensor(1014., device='cuda:0')\n(('Turnpike Lane', 'Wood Green'), ('Wood Green', 'Bounds Green')) tensor(618., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'Upney')) tensor(5., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'West Ham')) tensor(735., device='cuda:0')\n(('Upminster', 'Upminster Bridge'), ('Upminster Bridge', 'Hornchurch')) tensor(468., device='cuda:0')\n(('Upminster Bridge', 'Hornchurch'), ('Hornchurch', 'Elm Park')) tensor(269., device='cuda:0')\n(('Upminster Bridge', 'Upminster'), ('Upminster', 'Barking')) tensor(571., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'Upminster')) tensor(4., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'West Ham')) tensor(779., device='cuda:0')\n(('Upney', 'Becontree'), ('Becontree', 'Dagenham Heathway')) tensor(478., device='cuda:0')\n(('Upton Park', 'East Ham'), ('East Ham', 'Barking')) tensor(8., device='cuda:0')\n(('Upton Park', 'Plaistow'), ('Plaistow', 'West Ham')) tensor(464., device='cuda:0')\n(('Uxbridge', 'Hillingdon'), ('Hillingdon', 'Ickenham')) tensor(256., device='cuda:0')\n(('Vauxhall', 'Pimlico'), ('Pimlico', 'Victoria')) tensor(1094., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(152., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(680., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Oval')) tensor(173., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Bond Street')) tensor(835., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(23., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(974., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(116., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Westminster')) tensor(1201., device='cuda:0')\n(('Victoria', 'Pimlico'), ('Pimlico', 'Vauxhall')) tensor(1093., device='cuda:0')\n(('Victoria', 'Sloane Square'), ('Sloane Square', 'South Kensington')) tensor(2745., device='cuda:0')\n(('Victoria', \"St. James's Park\"), (\"St. James's Park\", 'Westminster')) tensor(1214., device='cuda:0')\n(('Walthamstow Central', 'Blackhorse Road'), ('Blackhorse Road', 'Tottenham Hale')) tensor(221., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(1544., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(15., device='cuda:0')\n(('Wanstead', 'Redbridge'), ('Redbridge', 'Gants Hill')) tensor(1049., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Camden Town')) tensor(1550., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(881., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Mornington Crescent')) tensor(73., device='cuda:0')\n(('Warren Street', 'Goodge Street'), ('Goodge Street', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(553., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(1574., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(182., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(369., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warwick Avenue', 'Maida Vale'), ('Maida Vale', 'Kilburn Park')) tensor(836., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Bayswater')) tensor(103., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(58., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(43., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(1143., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(8., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(229., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Temple')) tensor(53., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(231., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Oval')) tensor(779., device='cuda:0')\n(('Waterloo', 'Lambeth North'), ('Lambeth North', 'Elephant &amp; Castle')) tensor(226., device='cuda:0')\n(('Waterloo', 'Southwark'), ('Southwark', 'London Bridge')) tensor(4777., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', 'Green Park')) tensor(3439., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(1183., device='cuda:0')\n(('Watford', 'Croxley'), ('Croxley', 'Moor Park')) tensor(122., device='cuda:0')\n(('Wembley Central', 'North Wembley'), ('North Wembley', 'South Kenton')) tensor(199., device='cuda:0')\n(('Wembley Central', 'Stonebridge Park'), ('Stonebridge Park', 'Harlesden')) tensor(356., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(657., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(13., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(68., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(14., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(4., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(7., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(36., device='cuda:0')\n(('Wembley Park', 'Kingsbury'), ('Kingsbury', 'Queensbury')) tensor(311., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Dollis Hill')) tensor(14., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Preston Road'), ('Preston Road', 'Northwick Park')) tensor(4., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(61., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(1040., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'East Acton')) tensor(149., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(600., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(144., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1519., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(344., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(7., device='cuda:0')\n(('West Brompton', 'Fulham Broadway'), ('Fulham Broadway', 'Parsons Green')) tensor(1357., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(468., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(2., device='cuda:0')\n(('West Finchley', 'Woodside Park'), ('Woodside Park', 'Totteridge &amp; Whetstone')) tensor(221., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'East Ham')) tensor(588., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upminster')) tensor(788., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upney')) tensor(857., device='cuda:0')\n(('West Ham', 'BromleyByBow'), ('BromleyByBow', 'Bow Road')) tensor(16., device='cuda:0')\n(('West Ham', 'Canning Town'), ('Canning Town', 'North Greenwich')) tensor(490., device='cuda:0')\n(('West Ham', 'Plaistow'), ('Plaistow', 'Upton Park')) tensor(482., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Leyton')) tensor(122., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Mile End')) tensor(1283., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2023., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(267., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(19., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(4., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(13., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Hampstead', 'Kilburn'), ('Kilburn', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(660., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(779., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(13., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(31., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(853., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(270., device='cuda:0')\n(('West Kensington', 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(205., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(40., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(5., device='cuda:0')\n(('West Ruislip', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(64., device='cuda:0')\n(('Westbourne Park', 'Ladbroke Grove'), ('Ladbroke Grove', 'Latimer Road')) tensor(405., device='cuda:0')\n(('Westbourne Park', 'Royal Oak'), ('Royal Oak', 'Paddington')) tensor(780., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(5., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Temple')) tensor(525., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Bond Street')) tensor(1478., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(1051., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(353., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(101., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Victoria')) tensor(1205., device='cuda:0')\n(('Westminster', \"St. James's Park\"), (\"St. James's Park\", 'Victoria')) tensor(1204., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(372., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(319., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(3784., device='cuda:0')\n(('White City', 'East Acton'), ('East Acton', 'North Acton')) tensor(127., device='cuda:0')\n(('White City', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'Holland Park')) tensor(279., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(3522., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(2077., device='cuda:0')\n(('Whitechapel', 'Stepney Green'), ('Stepney Green', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Leyton')) tensor(2499., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'West Ham')) tensor(2098., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(512., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(27., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(8., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Kilburn'), ('Kilburn', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Junction', 'Harlesden'), ('Harlesden', 'Stonebridge Park')) tensor(405., device='cuda:0')\n(('Willesden Junction', 'Kensal Green'), ('Kensal Green', \"Queen's Park\")) tensor(678., device='cuda:0')\n(('Wimbledon', 'Wimbledon Park'), ('Wimbledon Park', 'Southfields')) tensor(299., device='cuda:0')\n(('Wimbledon Park', 'Southfields'), ('Southfields', 'East Putney')) tensor(456., device='cuda:0')\n(('Wood Green', 'Bounds Green'), ('Bounds Green', 'Arnos Grove')) tensor(479., device='cuda:0')\n(('Wood Green', 'Turnpike Lane'), ('Turnpike Lane', 'Manor House')) tensor(831., device='cuda:0')\n(('Wood Lane', 'Latimer Road'), ('Latimer Road', 'Ladbroke Grove')) tensor(346., device='cuda:0')\n(('Wood Lane', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Goldhawk Road')) tensor(133., device='cuda:0')\n(('Woodford', 'Buckhurst Hill'), ('Buckhurst Hill', 'Loughton')) tensor(683., device='cuda:0')\n(('Woodford', 'Roding Valley'), ('Roding Valley', 'Chigwell')) tensor(294., device='cuda:0')\n(('Woodford', 'South Woodford'), ('South Woodford', 'Snaresbrook')) tensor(1601., device='cuda:0')\n(('Woodside Park', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'High Barnet')) tensor(132., device='cuda:0')\n(('Woodside Park', 'West Finchley'), ('West Finchley', 'Finchley Central')) tensor(384., device='cuda:0')\n</pre> In\u00a0[5]: Copied! <pre>g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')]\n</pre> g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')] Out[5]: <pre>tensor(279., device='cuda:0')</pre> In\u00a0[6]: Copied! <pre>paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2)\ng2 = pp2.HigherOrderNetwork(paths, k=2)\nprint(g2)\n</pre> paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2) g2 = pp2.HigherOrderNetwork(paths, k=2) print(g2) <pre>2024-03-27 11:21:58 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:58 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:58 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n</pre> In\u00a0[7]: Copied! <pre>ks = range(1,10)\ntimes = []\nfor k in ks:\n    start = time.time() \n    paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)\n    g2 = pp2.HigherOrderNetwork(paths, k=k)\n    print(g2)\n    elapsed_pp = time.time()-start\n    times.append(elapsed_pp)\nplt.plot(ks, times)\n</pre> ks = range(1,10) times = [] for k in ks:     start = time.time()      paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)     g2 = pp2.HigherOrderNetwork(paths, k=k)     print(g2)     elapsed_pp = time.time()-start     times.append(elapsed_pp) plt.plot(ks, times) <pre>2024-03-27 11:21:59 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:59 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished.\nHigher-order network of order k = 1\n\nNodes:\t\t\t\t268\nLinks:\t\t\t\t646\nTotal weight (subpaths/longest paths):\t14404381.0/99956.0\n\n2024-03-27 11:22:00 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:00 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n2024-03-27 11:22:01 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:01 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished.\nHigher-order network of order k = 3\n\nNodes:\t\t\t\t1889\nLinks:\t\t\t\t1869\nTotal weight (subpaths/longest paths):\t10078001.0/230562.0\n\n2024-03-27 11:22:02 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:02 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:03 [Severity.INFO]\tfinished.\nHigher-order network of order k = 4\n\nNodes:\t\t\t\t5770\nLinks:\t\t\t\t2730\nTotal weight (subpaths/longest paths):\t8198110.0/236412.0\n\n2024-03-27 11:22:04 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:04 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:04 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:05 [Severity.INFO]\tfinished.\nHigher-order network of order k = 5\n\nNodes:\t\t\t\t19424\nLinks:\t\t\t\t3683\nTotal weight (subpaths/longest paths):\t6547275.0/243768.0\n\n2024-03-27 11:22:06 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:06 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:06 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:08 [Severity.INFO]\tfinished.\nHigher-order network of order k = 6\n\nNodes:\t\t\t\t66882\nLinks:\t\t\t\t4748\nTotal weight (subpaths/longest paths):\t5174028.0/209948.0\n\n2024-03-27 11:22:09 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:09 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:09 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:11 [Severity.INFO]\tfinished.\nHigher-order network of order k = 7\n\nNodes:\t\t\t\t242779\nLinks:\t\t\t\t5745\nTotal weight (subpaths/longest paths):\t4044268.0/176409.0\n\n2024-03-27 11:22:14 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:15 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:15 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:17 [Severity.INFO]\tfinished.\nHigher-order network of order k = 8\n\nNodes:\t\t\t\t888479\nLinks:\t\t\t\t6463\nTotal weight (subpaths/longest paths):\t3116104.0/151222.0\n\n2024-03-27 11:22:29 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:29 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:29 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:31 [Severity.INFO]\tfinished.\nHigher-order network of order k = 9\n\nNodes:\t\t\t\t3348421\nLinks:\t\t\t\t7053\nTotal weight (subpaths/longest paths):\t2349934.0/140450.0\n\n</pre> Out[7]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f081d30d9c0&gt;]</pre> In\u00a0[15]: Copied! <pre>pp.config['torch']['device'] = 'cuda:0'\n</pre> pp.config['torch']['device'] = 'cuda:0' In\u00a0[16]: Copied! <pre>ks = range(1,10)\ntimes_new_gpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_gpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_gpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_gpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[17]: Copied! <pre>pp.config['torch']['device'] = 'cpu'\n</pre> pp.config['torch']['device'] = 'cpu' In\u00a0[18]: Copied! <pre>ks = range(1,10)\ntimes_new_cpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_cpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_cpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_cpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[19]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.grid()\nplt.ylabel('time [s]')\nplt.legend()\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.grid() plt.ylabel('time [s]') plt.legend() Out[19]: <pre>&lt;matplotlib.legend.Legend at 0x7f082668d9f0&gt;</pre> In\u00a0[20]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.ylabel('time [s]')\nplt.legend()\nplt.grid()\nplt.yscale('log')\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.ylabel('time [s]') plt.legend() plt.grid() plt.yscale('log') In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_higher_order_scalability/#pathpy-20","title":"Pathpy 2.0\u00b6","text":""},{"location":"tutorial/_higher_order_scalability/#pathpyg-gpu","title":"pathpyG (GPU)\u00b6","text":""},{"location":"tutorial/_higher_order_scalability/#pathpyg-cpu","title":"pathpyG (CPU)\u00b6","text":""},{"location":"tutorial/_lift_order/","title":"lift order","text":"In\u00a0[74]: Copied! <pre>import torch\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\nimport pathpyG as pp\nfrom torch_geometric.data import Data\n</pre> import torch from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index import pathpyG as pp from torch_geometric.data import Data <p>Explanation for order lifting</p> <p>NB: Turns out everything depends from the initial sorting (even more than it seems from just looking at the code). The initial sorting by source id leads to sorted ho source indices. Notice that each node has get edges (ho-nodes) with consective indices (with length equal to its outdegree).</p> In\u00a0[104]: Copied! <pre># num_nodes = 3\n# edge_index = torch.tensor([[2,1,1],[1,0,2]])\nnum_nodes = 6\nedge_index = torch.tensor([[0,1,3,4,2,2,5],[2,2,5,5,3,4,0]])\n</pre> # num_nodes = 3 # edge_index = torch.tensor([[2,1,1],[1,0,2]]) num_nodes = 6 edge_index = torch.tensor([[0,1,3,4,2,2,5],[2,2,5,5,3,4,0]]) In\u00a0[105]: Copied! <pre>data = Data(edge_index = edge_index)\n\ng = pp.Graph(data,pp.IndexMap(list(\"012345\")))\npp.plot(g,  node_label=g.mapping.node_ids.tolist())\n</pre> data = Data(edge_index = edge_index)  g = pp.Graph(data,pp.IndexMap(list(\"012345\"))) pp.plot(g,  node_label=g.mapping.node_ids.tolist()) Out[105]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fb91dba23e0&gt;</pre> In\u00a0[138]: Copied! <pre>pp.plot(ho_graph)\n</pre> pp.plot(ho_graph) Out[138]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fb91dcf54b0&gt;</pre> <p>first we need to sort the edge index by the source indexes</p> In\u00a0[106]: Copied! <pre>edge_index = sort_edge_index(edge_index, num_nodes=num_nodes)\nedge_index\n</pre> edge_index = sort_edge_index(edge_index, num_nodes=num_nodes) edge_index Out[106]: <pre>tensor([[0, 1, 2, 2, 3, 4, 5],\n        [2, 2, 3, 4, 5, 5, 0]])</pre> <p>Then we compute the outdegrees.</p> In\u00a0[107]: Copied! <pre>outdegree = degree(edge_index[0], dtype = torch.long, num_nodes=num_nodes)\noutdegree\n</pre> outdegree = degree(edge_index[0], dtype = torch.long, num_nodes=num_nodes) outdegree Out[107]: <pre>tensor([1, 1, 2, 1, 1, 1])</pre> <p>The 'outdegree_per_dst' gives us the number of out edges we would find by arriving to the node through one of the edges that has it as target. Indeed, edge_index[1] is a list of all the instubs. Associating each in-stub with the outdegree of the corresponding node gives us all 2-paths grouped by the in-edge (in edge is a x-v edge, where v is the node of which we know the outdegree -- Notice that at this time the node x of the x-edge is not considered).</p> In\u00a0[108]: Copied! <pre>outdegree_per_dst = outdegree[edge_index[1]]\noutdegree_per_dst\n\n# nodes 0,2,1\n</pre> outdegree_per_dst = outdegree[edge_index[1]] outdegree_per_dst  # nodes 0,2,1 Out[108]: <pre>tensor([2, 2, 1, 1, 1, 1, 1])</pre> <p>From 'outdegree_per_dst' we can unpack the information per in-edge contained in the outdegree_per_dst by using the torch funtion 'repeat_interleave'. 'repeat_interleave' works like this: If the repeats is tensor([n1, n2, n3, \u2026]), then the output will be tensor([0, 0, \u2026, 1, 1, \u2026, 2, 2, \u2026, \u2026]) where 0 appears n1 times, 1 appears n2 times, 2 appears n3 times, etc. From the line grap perspective, we can see it as creating the indexes of (lifted, new) source-higher-order nodes. In other words, for each (unknow) starting x, a new higher-order node-index is created and repeated a number of time given by the outdegree of v, giving the amount of times x-v appears as a source higher-order node.</p> In\u00a0[109]: Copied! <pre>torch.repeat_interleave(torch.tensor([1,2,3]))\n</pre> torch.repeat_interleave(torch.tensor([1,2,3])) Out[109]: <pre>tensor([0, 1, 1, 2, 2, 2])</pre> In\u00a0[110]: Copied! <pre>ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\nho_edge_srcs\n\n# 123 124 - 023 024 - 234 - 234\n</pre> ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst) ho_edge_srcs  # 123 124 - 023 024 - 234 - 234   Out[110]: <pre>tensor([0, 0, 1, 1, 2, 3, 4, 5, 6])</pre> <p>Finally, we define 'num_new_edges' as the total number of x-v-w. This comes from taking each incident edge x-v and considering all the w it can reach (given by its outdegree)</p> <p>...i.e, the number of two paths.</p> In\u00a0[111]: Copied! <pre>num_new_edges = outdegree_per_dst.sum()\nnum_new_edges\n</pre> num_new_edges = outdegree_per_dst.sum() num_new_edges Out[111]: <pre>tensor(9)</pre> <p>At the end of this first part of the process, we have take the edges incident to each node and have then repeated their index a number of time equals to the outdegree of that node</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Then, Create destination nodes that start the indexing after the cumulative sum of the outdegree of all previous nodes in the ordered sequence of nodes</p> <p>This cumsum tells us the number of times we need each index (in teh out-indices?). i.e., If the first node has oudegree two, we need to allocate the index twice the next node, needs the number reached by the previous plus the outdegree of the next node.</p> <p>!!!</p> <p>ptrs for each node v (Notice it is applied on the outdegree vector which is in R^|V|) stores a starting index for the edges outgoing from it (i.e. the destination ho-nodes). Notice that the indexes of the edges outgoing from v (in position with index i) end where the ones of the next node (at position i+1) start.</p> In\u00a0[112]: Copied! <pre>ptrs = cumsum(outdegree, dim=0)[:-1] # position in the first order tensor where edge indexes of edges startin from each node (let s say w) start\n# 00001112 -&gt; 0,4,7  (related to first order edge indices)\n\n# node 0 needs from 0 to 4, 1 from 4 to 7, and 2... (the rest?)\n\nptrs\n\n\n# ptrs[edge_index[1]]\n# then we index by the target indexes in fo-nodes: edge_index[1]. \n# this will tell us the starting position of the target node as source node in the sorted fo-edge indices\n# i.e., Target node w if taken as source will have positions starting from ptrs[w] in edge index\n# e.g., edge_index[1] -&gt; [4,4,7] means that the continueation (source) indexes for the the nodes in edge_index[1] start at [4,4,7]\n# notice that this would be impossible if the edge_index weren't sorted\n\n\n# torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n# Then, we repeat that starting index (of the target node w as source) a number of time equal to the nodes' outdegree\n# This will give us the starting index (of the target node w as source) repeated the number of times w is actually used as source in the line-graph\n# Givers the starting index (of w as source) for all edges w-&gt;y \n# e.g., [[4,4],[4,4],[7,7,7]] means that a-w_0 and b-w_0 can be continued twice, and c-w_1 three times (using fo-edge-indices starting at 4,4,and 7 ,repsectively)\n# the above gives an initial 'ho_edge_dsts' (pointers to the w_i-k that are ho_edge_dsts)\n\n# ---Index correction ---\n# Until this point we only have the starting (nod) index of the fo-edges that can (transitively) propagate an edge with  w as target.\n# we need to move to specific --not starting-- (ho-node) indexes of ho-edges.\n# \n# first, we generated a tensor with valeus from 0 to num_new_edges ()\n# then, we compute 'cumsum(outdegree_per_dst, dim=0)' which gives where the indexes of each w_i-k start in 'ho_edge_dsts' \n# e.g., [[4,4],[4,4],[7,7,7]] -&gt; [0,2,5] (dim again equal to number of fo-edges) (WRONG HERE)\n# this says \n# \n# then, we select them based on the ho_edge_srsc.\n# so if ho_edge_srcs = [0,1,1,1,2,2], we ll select [0,2,2,2,5,5] \n# what is this???\n# if we substrat this from the tensor with valeus from 0 to num_new_edges\n</pre>   ptrs = cumsum(outdegree, dim=0)[:-1] # position in the first order tensor where edge indexes of edges startin from each node (let s say w) start # 00001112 -&gt; 0,4,7  (related to first order edge indices)  # node 0 needs from 0 to 4, 1 from 4 to 7, and 2... (the rest?)  ptrs   # ptrs[edge_index[1]] # then we index by the target indexes in fo-nodes: edge_index[1].  # this will tell us the starting position of the target node as source node in the sorted fo-edge indices # i.e., Target node w if taken as source will have positions starting from ptrs[w] in edge index # e.g., edge_index[1] -&gt; [4,4,7] means that the continueation (source) indexes for the the nodes in edge_index[1] start at [4,4,7] # notice that this would be impossible if the edge_index weren't sorted   # torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst) # Then, we repeat that starting index (of the target node w as source) a number of time equal to the nodes' outdegree # This will give us the starting index (of the target node w as source) repeated the number of times w is actually used as source in the line-graph # Givers the starting index (of w as source) for all edges w-&gt;y  # e.g., [[4,4],[4,4],[7,7,7]] means that a-w_0 and b-w_0 can be continued twice, and c-w_1 three times (using fo-edge-indices starting at 4,4,and 7 ,repsectively) # the above gives an initial 'ho_edge_dsts' (pointers to the w_i-k that are ho_edge_dsts)  # ---Index correction --- # Until this point we only have the starting (nod) index of the fo-edges that can (transitively) propagate an edge with  w as target. # we need to move to specific --not starting-- (ho-node) indexes of ho-edges. #  # first, we generated a tensor with valeus from 0 to num_new_edges () # then, we compute 'cumsum(outdegree_per_dst, dim=0)' which gives where the indexes of each w_i-k start in 'ho_edge_dsts'  # e.g., [[4,4],[4,4],[7,7,7]] -&gt; [0,2,5] (dim again equal to number of fo-edges) (WRONG HERE) # this says  #  # then, we select them based on the ho_edge_srsc. # so if ho_edge_srcs = [0,1,1,1,2,2], we ll select [0,2,2,2,5,5]  # what is this??? # if we substrat this from the tensor with valeus from 0 to num_new_edges Out[112]: <pre>tensor([0, 1, 2, 4, 5, 6])</pre> <p>Select the number of indexes (repetitions) needed by each ho-target index. From which entry to which entry we ll have teh index of a (ho?) node</p> <p>since the edge indices have been ordered by source index, now ptrs has the</p> In\u00a0[113]: Copied! <pre>torch.repeat_interleave(torch.tensor([5,6,7]),torch.tensor([1,2,3]))\n</pre> torch.repeat_interleave(torch.tensor([5,6,7]),torch.tensor([1,2,3])) Out[113]: <pre>tensor([5, 6, 6, 7, 7, 7])</pre> In\u00a0[114]: Copied! <pre>edge_index[1]\n</pre> edge_index[1] Out[114]: <pre>tensor([2, 2, 3, 4, 5, 5, 0])</pre> In\u00a0[115]: Copied! <pre># this gives the number\nptrs[edge_index[1]]\n</pre> # this gives the number ptrs[edge_index[1]] Out[115]: <pre>tensor([2, 2, 4, 5, 6, 6, 0])</pre> In\u00a0[116]: Copied! <pre>outdegree_per_dst\n</pre> outdegree_per_dst Out[116]: <pre>tensor([2, 2, 1, 1, 1, 1, 1])</pre> <p>ptrs[edge_index[1]]: we use 'edge_index[1]' to couple each target node to the its starting-index-pointer (as obtained in ptrs)</p> <p>Then, use 'repeat_interleave' to repeat the pointer (containing the starting index) a number of time given by 'outdegree_per_dst'. Remember that ' outdegree_per_dst' maps each (target) node v, to its outdegree as a source. Therfore, at this point, ho_edge_dsts maps each node v to its starting-index-pointer. Succesively, the pointer will be corrected so that they contain the index and not the starting-index-pointer.</p> In\u00a0[117]: Copied! <pre># if I focus on the target indices, I have the number of time we need to repear the index of outstub.\n\n\n# Building new edge_index\n# node in ho is edge\n# degree of fo-ones tells how many new outgoing edges we need to allocate for the ho-node\n# diff from before... (where using outdegree...)\n# ...cause \n\n# the pointers gives where edges start for each node in fo. Indexing by destination, I get \n\n\nho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\nho_edge_dsts\n</pre> # if I focus on the target indices, I have the number of time we need to repear the index of outstub.   # Building new edge_index # node in ho is edge # degree of fo-ones tells how many new outgoing edges we need to allocate for the ho-node # diff from before... (where using outdegree...) # ...cause   # the pointers gives where edges start for each node in fo. Indexing by destination, I get    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst) ho_edge_dsts Out[117]: <pre>tensor([2, 2, 2, 2, 4, 5, 6, 6, 0])</pre> <p>The cell above give each (target) node v a list of pointers. Here we computer an index correction to adjust the indices (go beyond the starting-index-pointer)</p> <p>(outdegree-per_dst was giving the out degree of each target node v in 'edge_index[1]') 'cumsum(outdegree_per_dst, dim=0)' stores a starting index for the edges incoming into a node v (in this case). Notice that the dimensionality of this tensor is equal to the number of edges (one entry for each time we take outdegree of a target node in 'edges_index[1]')</p> <p>Then we select</p> In\u00a0[118]: Copied! <pre># num_new_edges = outdegree_per_dst.sum()\nidx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\nidx_correction\n</pre> # num_new_edges = outdegree_per_dst.sum() idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device) idx_correction Out[118]: <pre>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])</pre> In\u00a0[119]: Copied! <pre>edge_index\n</pre> edge_index Out[119]: <pre>tensor([[0, 1, 2, 2, 3, 4, 5],\n        [2, 2, 3, 4, 5, 5, 0]])</pre> In\u00a0[120]: Copied! <pre>outdegree_per_dst\n</pre> outdegree_per_dst Out[120]: <pre>tensor([2, 2, 1, 1, 1, 1, 1])</pre> In\u00a0[121]: Copied! <pre>cumsum(outdegree_per_dst, dim=0)\n</pre> cumsum(outdegree_per_dst, dim=0) Out[121]: <pre>tensor([0, 2, 4, 5, 6, 7, 8, 9])</pre> In\u00a0[122]: Copied! <pre>idx_correction - cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n</pre> idx_correction - cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs] Out[122]: <pre>tensor([0, 1, 0, 1, 0, 0, 0, 0, 0])</pre> In\u00a0[123]: Copied! <pre>ho_edge_srcs\n</pre> ho_edge_srcs Out[123]: <pre>tensor([0, 0, 1, 1, 2, 3, 4, 5, 6])</pre> In\u00a0[124]: Copied! <pre>ho_edge_dsts\n</pre> ho_edge_dsts Out[124]: <pre>tensor([2, 2, 2, 2, 4, 5, 6, 6, 0])</pre> In\u00a0[125]: Copied! <pre># cumsum(outdegree_per_dst, dim=0) gives the number of entries required by each target of each source\n# here, selecting with ho_edge_srcs \ncumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n</pre> # cumsum(outdegree_per_dst, dim=0) gives the number of entries required by each target of each source # here, selecting with ho_edge_srcs  cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs] Out[125]: <pre>tensor([0, 0, 2, 2, 4, 5, 6, 7, 8])</pre> In\u00a0[126]: Copied! <pre>idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\nidx_correction\n</pre> idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs] idx_correction Out[126]: <pre>tensor([0, 1, 0, 1, 0, 0, 0, 0, 0])</pre> In\u00a0[127]: Copied! <pre>ho_edge_dsts += idx_correction\nho_edge_dsts\n</pre> ho_edge_dsts += idx_correction ho_edge_dsts Out[127]: <pre>tensor([2, 3, 2, 3, 4, 5, 6, 6, 0])</pre> <p>All in all, we initialize 'ho_edge_dsts' entries with the minumum index the target ho-node v-t can get (???)(considering that also these indices are sorted by the source indices).</p> <p>Then, we build upon this. We initialize the correction as a tensor 'idx_correction' with the index of each position ('torch.arange(num_new_edges)') Then we compute a starting index for the edges incoming into v (or t?); we subtract this from 'idx_correction'. This gives the index correction. Thus, the index correction ... gives something that ????</p> In\u00a0[130]: Copied! <pre>ho_edge_dsts\n</pre> ho_edge_dsts Out[130]: <pre>tensor([2, 3, 2, 3, 4, 5, 6, 6, 0])</pre> In\u00a0[137]: Copied! <pre>data_ho = Data(edge_index=torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0))\nho_graph = pp.Graph(data_ho)\n</pre> data_ho = Data(edge_index=torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)) ho_graph = pp.Graph(data_ho) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_multi_order_concepts/","title":"multi order concepts","text":"In\u00a0[\u00a0]: Copied! <pre>def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int, edge_weights: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Do a line graph transformation on the edge index to lift the order of the graph by one.\n\n        Args:\n            edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n            num_nodes: The number of nodes in the graph.\n        \"\"\"\n\n        # Since this is a complicated function, we will use the following example to explain the steps:\n        # Example:\n        #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],\n        #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]\n\n        # Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge\n        # Example:\n        #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]\n        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n\n        # For each center node, we need to combine each outgoing edge with each incoming edge\n        # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index\n        # Example:\n        #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]\n        #   num_new_edges = 9\n        outdegree_per_dst = outdegree[edge_index[1]]\n        num_new_edges = outdegree_per_dst.sum()\n\n        # Use each edge from the edge index as node and assign the new indices in the order of the original edge index\n        # Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n        # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor\n        # Example:\n        #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]\n        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n        # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges\n        # (new higher-order nodes) that have the node as source node\n        # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and\n        # we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])\n        # Example:\n        #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]\n        ptrs = cumsum(outdegree, dim=0)[:-1]\n\n        # Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times\n        # Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively\n        # Example:\n        #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n\n        # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...)\n        # for all `outdegree` number of edges consecutively to get the correct destination nodes\n        # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\n        # Example:\n        #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n        # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.\n        # Example:\n        #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]\n        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n        # Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge\n        # Example:\n        #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts += idx_correction\n        # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n        #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</pre> def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int, edge_weights: torch.Tensor) -&gt; torch.Tensor:         \"\"\"         Do a line graph transformation on the edge index to lift the order of the graph by one.          Args:             edge_index: A **sorted** edge index tensor of shape (2, num_edges).             num_nodes: The number of nodes in the graph.         \"\"\"          # Since this is a complicated function, we will use the following example to explain the steps:         # Example:         #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],         #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]          # Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge         # Example:         #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]         outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)          # For each center node, we need to combine each outgoing edge with each incoming edge         # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index         # Example:         #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]         #   num_new_edges = 9         outdegree_per_dst = outdegree[edge_index[1]]         num_new_edges = outdegree_per_dst.sum()          # Use each edge from the edge index as node and assign the new indices in the order of the original edge index         # Each higher order node has one outgoing edge for each outgoing edge of the original destination node         # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor         # Example:         #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]         ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)          # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges         # (new higher-order nodes) that have the node as source node         # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and         # we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])         # Example:         #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]         ptrs = cumsum(outdegree, dim=0)[:-1]          # Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times         # Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively         # Example:         #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]         ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)          # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...)         # for all `outdegree` number of edges consecutively to get the correct destination nodes         # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)         # Example:         #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]         idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)         # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.         # Example:         #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]         idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]         # Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge         # Example:         #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]         ho_edge_dsts += idx_correction         # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],         #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])         return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)"},{"location":"tutorial/_multi_order_concepts/#todo-create-a-notebook-that-explains-the-new-concepts-for-order-lifting-for-dags-and-temporal-graphs","title":"TODO: Create a Notebook that explains the new concepts for order lifting for DAGs and temporal graphs.\u00b6","text":""},{"location":"tutorial/_new_pathData_test/","title":"new pathData test","text":"In\u00a0[39]: Copied! <pre>from typing import Optional\n\nfrom tqdm import trange\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.experimental import disable_dynamic_shapes\nfrom torch_geometric.nn.aggr import Aggregation\nfrom torch_geometric.utils import coalesce, degree, cumsum\nfrom torch_geometric import EdgeIndex\n\nimport pathpyG as pp\n</pre> from typing import Optional  from tqdm import trange import torch from torch import Tensor from torch_geometric.data import Data from torch_geometric.loader import DataLoader from torch_geometric.nn import MessagePassing from torch_geometric.experimental import disable_dynamic_shapes from torch_geometric.nn.aggr import Aggregation from torch_geometric.utils import coalesce, degree, cumsum from torch_geometric import EdgeIndex  import pathpyG as pp In\u00a0[40]: Copied! <pre>dags = pp.DAGData()\ndags.append(torch.tensor([[3,0,1],[0,1,2]]))\ndags.append(torch.tensor([[1,0,2],[0,2,0]]))\ndags.append(torch.tensor([[0,1],[1,2]]))\n</pre> dags = pp.DAGData() dags.append(torch.tensor([[3,0,1],[0,1,2]])) dags.append(torch.tensor([[1,0,2],[0,2,0]])) dags.append(torch.tensor([[0,1],[1,2]])) In\u00a0[41]: Copied! <pre>print(dags)\n</pre> print(dags) <pre>DAGData with 3 dags and total weight 3\n</pre> In\u00a0[50]: Copied! <pre>def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor, num_nodes: int | None = None) -&gt; torch.Tensor:\n        # Since this is a complicated function, we will use the following example to explain the steps:\n        # Example:\n        #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],\n        #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]\n\n        # Compute the outdegree of each node which we will use to get all the edge combinations that lead to a higher order edge\n        # Example:\n        #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]\n        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n\n        # For each center node, we need to combine each outgoing edge with each incoming edge\n        # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index\n        # Example:\n        #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]\n        #   num_new_edges = 9\n        outdegree_per_dst = outdegree[edge_index[1]]\n        num_new_edges = outdegree_per_dst.sum()\n\n        # We use each edge from the edge index as new node and assign the new indices in the order of the original edge index\n        # Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n        # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor\n        # Example:\n        #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]\n        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n        # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges (new higher order nodes) that have the node as source node\n        # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])\n        # Example:\n        #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]\n        ptrs = cumsum(outdegree, dim=0)[:-1]\n\n        # Use these pointers to get the start of the edges for each higher order source node and repeat it `outdegree` times\n        # Since we keep the ordering, all new higher order edges that have the same source node are indexed consecutively\n        # Example:\n        #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n\n        # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) for all `outdegree` number of edges consecutively to get the correct destination nodes\n        # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\n        # Example: \n        #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n        # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.\n        # Example:\n        #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]\n        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n        # Finally, we add this tensor to the destination nodes to get the correct destination nodes for each higher order edge\n        # Example:\n        #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts += idx_correction\n    # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n    #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</pre> def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor, num_nodes: int | None = None) -&gt; torch.Tensor:         # Since this is a complicated function, we will use the following example to explain the steps:         # Example:         #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],         #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]          # Compute the outdegree of each node which we will use to get all the edge combinations that lead to a higher order edge         # Example:         #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]         outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)          # For each center node, we need to combine each outgoing edge with each incoming edge         # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index         # Example:         #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]         #   num_new_edges = 9         outdegree_per_dst = outdegree[edge_index[1]]         num_new_edges = outdegree_per_dst.sum()          # We use each edge from the edge index as new node and assign the new indices in the order of the original edge index         # Each higher order node has one outgoing edge for each outgoing edge of the original destination node         # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor         # Example:         #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]         ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)          # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges (new higher order nodes) that have the node as source node         # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])         # Example:         #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]         ptrs = cumsum(outdegree, dim=0)[:-1]          # Use these pointers to get the start of the edges for each higher order source node and repeat it `outdegree` times         # Since we keep the ordering, all new higher order edges that have the same source node are indexed consecutively         # Example:         #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]         ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)          # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) for all `outdegree` number of edges consecutively to get the correct destination nodes         # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)         # Example:          #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]         idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)         # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.         # Example:         #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]         idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]         # Finally, we add this tensor to the destination nodes to get the correct destination nodes for each higher order edge         # Example:         #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]         ho_edge_dsts += idx_correction     # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],     #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])         return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0) In\u00a0[77]: Copied! <pre>def map_higher_order_index(edge_indices, k):\n    \"\"\"map node indices in k-th order edge index\n    to corresponding tensor of k first-order nodes\n    \"\"\" \n\n    # we need to reverse the node indices\n    # to construct an edge_index with k-th order nodes\n    \n    ei = edge_indices[k].reshape(2,-1,1)\n    \n    j = 0\n    for i in range(k-1, 0, -1):\n        src_edge, tgt_edge = ei\n        src = edge_indices[i][:,src_edge]\n        tgt = edge_indices[i][:,tgt_edge]\n        if j == 0:\n            ei = torch.cat([src, tgt], dim=2)\n        else:\n            ei = torch.cat([src[:,:,:j], tgt], dim=2)\n        j -= 1\n    return ei\n</pre> def map_higher_order_index(edge_indices, k):     \"\"\"map node indices in k-th order edge index     to corresponding tensor of k first-order nodes     \"\"\"       # we need to reverse the node indices     # to construct an edge_index with k-th order nodes          ei = edge_indices[k].reshape(2,-1,1)          j = 0     for i in range(k-1, 0, -1):         src_edge, tgt_edge = ei         src = edge_indices[i][:,src_edge]         tgt = edge_indices[i][:,tgt_edge]         if j == 0:             ei = torch.cat([src, tgt], dim=2)         else:             ei = torch.cat([src[:,:,:j], tgt], dim=2)         j -= 1     return ei In\u00a0[81]: Copied! <pre>def from_DAGs(data: pp.DAGData, max_order: int = 1) -&gt; pp.MultiOrderModel:\n    \"\"\"Creates multiple higher-order De Bruijn graphs for paths in DAGData.\"\"\"\n    m = pp.MultiOrderModel()\n\n    data_list = [Data(edge_index=dag.long()) for dag in data.dags]\n    # We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs\n    # If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards\n    # Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once\n    dag_graph = next(iter(DataLoader(data_list, batch_size=len(data.dags))))\n    dag_edge_index = dag_graph.edge_index\n    dag_edge_index = coalesce(dag_edge_index)\n\n    print(dag_edge_index)\n    print(dag_graph.ptr)\n    print(dag_graph.batch)\n\n    edge_index = pp.MultiOrderModel.map_batch_indices(dag_edge_index, dag_graph.batch, dag_graph.ptr)\n    unique_nodes = torch.unique(edge_index)\n    m.layers[1] = pp.Graph(Data(edge_index=edge_index, num_nodes=unique_nodes.size(), fo_nodes=unique_nodes.reshape(-1, 1)))\n    print(m.layers[1].data.edge_index)\n    print(m.layers[1].data.fo_nodes)\n\n    edge_indices = {}\n    edge_indices[1] = edge_index\n\n    for k in range(2, max_order+1):\n        print('=== k={0} ==='.format(k))\n        num_nodes = torch.unique(dag_edge_index).size(0)\n        print('num nodes = ', num_nodes)\n        ho_index = lift_order_edge_index(dag_edge_index, num_nodes = num_nodes)\n        edge_indices[k] = ho_index\n        print(ho_index)\n\n        # Map k-th-order edge index to nodes in (k-1)-th order edge index\n        # src_edge, tgt_edge = ho_index\n        # src = dag_edge_index[:,src_edge]\n        # tgt = dag_edge_index[:,tgt_edge]\n        # print(src)\n        # print(tgt)\n\n        #ho_edge_index, inverse = x.unique(dim=0, return_inverse=True)\n\n        # weights of the two unique higher-order edges should be N and 3*N\n        # weights of k-th element in output = sum of all w at indices where inverse is k\n        #weights = torch.zeros(ho_edge_index.size()[0], device=config['torch']['device'], dtype=torch.long).index_add(0, inverse, w)\n \n\n        #m.layers[k] = pp.Graph(data=Data(edge_index=dag_edge_index))\n\n        dag_edge_index = coalesce(ho_index)\n\n    return m, edge_indices\n</pre> def from_DAGs(data: pp.DAGData, max_order: int = 1) -&gt; pp.MultiOrderModel:     \"\"\"Creates multiple higher-order De Bruijn graphs for paths in DAGData.\"\"\"     m = pp.MultiOrderModel()      data_list = [Data(edge_index=dag.long()) for dag in data.dags]     # We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs     # If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards     # Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once     dag_graph = next(iter(DataLoader(data_list, batch_size=len(data.dags))))     dag_edge_index = dag_graph.edge_index     dag_edge_index = coalesce(dag_edge_index)      print(dag_edge_index)     print(dag_graph.ptr)     print(dag_graph.batch)      edge_index = pp.MultiOrderModel.map_batch_indices(dag_edge_index, dag_graph.batch, dag_graph.ptr)     unique_nodes = torch.unique(edge_index)     m.layers[1] = pp.Graph(Data(edge_index=edge_index, num_nodes=unique_nodes.size(), fo_nodes=unique_nodes.reshape(-1, 1)))     print(m.layers[1].data.edge_index)     print(m.layers[1].data.fo_nodes)      edge_indices = {}     edge_indices[1] = edge_index      for k in range(2, max_order+1):         print('=== k={0} ==='.format(k))         num_nodes = torch.unique(dag_edge_index).size(0)         print('num nodes = ', num_nodes)         ho_index = lift_order_edge_index(dag_edge_index, num_nodes = num_nodes)         edge_indices[k] = ho_index         print(ho_index)          # Map k-th-order edge index to nodes in (k-1)-th order edge index         # src_edge, tgt_edge = ho_index         # src = dag_edge_index[:,src_edge]         # tgt = dag_edge_index[:,tgt_edge]         # print(src)         # print(tgt)          #ho_edge_index, inverse = x.unique(dim=0, return_inverse=True)          # weights of the two unique higher-order edges should be N and 3*N         # weights of k-th element in output = sum of all w at indices where inverse is k         #weights = torch.zeros(ho_edge_index.size()[0], device=config['torch']['device'], dtype=torch.long).index_add(0, inverse, w)            #m.layers[k] = pp.Graph(data=Data(edge_index=dag_edge_index))          dag_edge_index = coalesce(ho_index)      return m, edge_indices In\u00a0[82]: Copied! <pre>m, edge_indices = from_DAGs(dags, max_order=3)\n</pre> m, edge_indices = from_DAGs(dags, max_order=3) <pre>tensor([[0, 1, 3, 4, 5, 6, 7, 8],\n        [1, 2, 0, 6, 4, 4, 8, 9]])\ntensor([ 0,  4,  7, 10])\ntensor([0, 0, 0, 0, 1, 1, 1, 2, 2, 2])\nEdgeIndex([[0, 0, 0, 1, 1, 1, 2, 3],\n           [1, 2, 1, 2, 0, 2, 0, 0]], sparse_size=(4, 4), nnz=8,\n          sort_order=row)\ntensor([[0],\n        [1],\n        [2],\n        [3]])\n=== k=2 ===\nnum nodes =  10\ntensor([[0, 2, 3, 4, 5, 6],\n        [1, 0, 5, 3, 3, 7]])\n=== k=3 ===\nnum nodes =  8\ntensor([[1, 2, 3, 4],\n        [0, 4, 2, 2]])\n</pre> In\u00a0[89]: Copied! <pre>map_higher_order_index(edge_indices, k=3)\n</pre> map_higher_order_index(edge_indices, k=3) Out[89]: <pre>tensor([[[3, 0, 1],\n         [0, 2, 0],\n         [1, 0, 2],\n         [2, 0, 2]],\n\n        [[0, 1, 2],\n         [2, 0, 2],\n         [0, 2, 0],\n         [0, 2, 0]]])</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_new_pathData_working/","title":"new pathData working","text":"In\u00a0[1]: Copied! <pre>from typing import Optional\n\nfrom tqdm import trange\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.experimental import disable_dynamic_shapes\nfrom torch_geometric.nn.aggr import Aggregation\nfrom torch_geometric.utils import coalesce, degree, cumsum\nfrom torch_geometric import EdgeIndex\n\nimport pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n</pre> from typing import Optional  from tqdm import trange import torch from torch import Tensor from torch_geometric.data import Data from torch_geometric.loader import DataLoader from torch_geometric.nn import MessagePassing from torch_geometric.experimental import disable_dynamic_shapes from torch_geometric.nn.aggr import Aggregation from torch_geometric.utils import coalesce, degree, cumsum from torch_geometric import EdgeIndex  import pathpyG as pp pp.config['torch']['device'] = 'cuda' In\u00a0[2]: Copied! <pre># Example with walks as node sequences\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c')])\ndags = pp.DAGData(mapping = g.mapping)\n\ndags.append_walk(('a', 'b', 'c', 'b'), weight=1.0)\ndags.append_walk(('a', 'c'), weight = 2.0)\nprint(dags)\n</pre> # Example with walks as node sequences g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c')]) dags = pp.DAGData(mapping = g.mapping)  dags.append_walk(('a', 'b', 'c', 'b'), weight=1.0) dags.append_walk(('a', 'c'), weight = 2.0) print(dags) <pre>DAGData with 2 dags with total weight 3.0\n</pre> In\u00a0[5]: Copied! <pre># Example with walks as edge indices (with no mapping)\ndags = pp.DAGData()\ndags.append_dag(torch.tensor([[3,0,1],[0,1,2]]))\ndags.append_dag(torch.tensor([[1,0,2],[0,2,0]]))\ndags.append_dag(torch.tensor([[0,1],[1,2]]))\nprint(dags)\n</pre> # Example with walks as edge indices (with no mapping) dags = pp.DAGData() dags.append_dag(torch.tensor([[3,0,1],[0,1,2]])) dags.append_dag(torch.tensor([[1,0,2],[0,2,0]])) dags.append_dag(torch.tensor([[0,1],[1,2]])) print(dags) <pre>DAGData with 3 dags with total weight 3.0\n</pre> In\u00a0[\u00a0]: Copied! <pre># Example with mix of walks or dags\ndags = pp.DAGData(mapping = g.mapping)\n\ndags.append_dag(torch.tensor([[0,0,1],[1,2,2]]))\ndags.append_walk(('a', 'b', 'c'))\nprint(dags)\n</pre> # Example with mix of walks or dags dags = pp.DAGData(mapping = g.mapping)  dags.append_dag(torch.tensor([[0,0,1],[1,2,2]])) dags.append_walk(('a', 'b', 'c')) print(dags) In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(dags, max_order=2)\n</pre> m = pp.MultiOrderModel.from_DAGs(dags, max_order=2) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[1].data.edge_index)\nprint(m.layers[1].data.node_sequences)\nprint(m.layers[1].mapping)\n</pre> print(m.layers[1].data.edge_index) print(m.layers[1].data.node_sequences) print(m.layers[1].mapping) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.edge_index)\nprint(m.layers[2].data.node_sequences)\nprint(m.layers[2].mapping)\n</pre> print(m.layers[2].data.edge_index) print(m.layers[2].data.node_sequences) print(m.layers[2].mapping) In\u00a0[\u00a0]: Copied! <pre># Real-world example\ndags = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nprint(dags)\n</pre> # Real-world example dags = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') print(dags) In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(dags, max_order=10)\n</pre> m = pp.MultiOrderModel.from_DAGs(dags, max_order=10) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[3].mapping)\n</pre> print(m.layers[3].mapping) In\u00a0[\u00a0]: Copied! <pre>pp.plot(m.layers[10], node_label=list(map(str, m.layers[1].data.node_sequences.tolist())))\n</pre> pp.plot(m.layers[10], node_label=list(map(str, m.layers[1].data.node_sequences.tolist()))) In\u00a0[\u00a0]: Copied! <pre>dags.map_node_seq(m.layers[10].data.node_sequences[5].tolist())\n</pre> dags.map_node_seq(m.layers[10].data.node_sequences[5].tolist()) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.edge_index)\n</pre> print(m.layers[2].data.edge_index) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.edge_weights)\n</pre> print(m.layers[2].data.edge_weights) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.node_sequences)\n</pre> print(m.layers[2].data.node_sequences) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_new_paths/","title":"new paths","text":"In\u00a0[3]: Copied! <pre>from pathpyG import PathData\n\nfrom torch import IntTensor\n\nimport pathpyG as pp\n\npp.config['torch']['device'] = 'cpu'\n</pre> from pathpyG import PathData  from torch import IntTensor  import pathpyG as pp  pp.config['torch']['device'] = 'cpu' In\u00a0[5]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c','e')])\npp.plot(g, node_label=g.mapping.node_ids.tolist(), edge_color='gray')\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c','e')]) pp.plot(g, node_label=g.mapping.node_ids.tolist(), edge_color='gray') Out[5]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f253220a0b0&gt;</pre> In\u00a0[3]: Copied! <pre>path = IntTensor([[0,1],\n                  [1,3]])\n</pre> path = IntTensor([[0,1],                   [1,3]]) Out[3]: <pre>tensor([[[0],\n         [1]],\n\n        [[1],\n         [3]]], dtype=torch.int32)</pre> In\u00a0[4]: Copied! <pre>WalkData.edge_index_kth_order(path, k=2)\n</pre> WalkData.edge_index_kth_order(path, k=2) Out[4]: <pre>tensor([[[0, 1]],\n\n        [[1, 3]]], dtype=torch.int32)</pre> In\u00a0[5]: Copied! <pre>paths_1 = WalkData(g.mapping)\npaths_1.add_walk_seq(('a', 'c', 'd'), freq=2)\npaths_1.add_walk_seq(('b', 'c', 'e'), freq=2)\nprint(paths_1.paths)\nprint(paths_1.path_freq)\n</pre> paths_1 = WalkData(g.mapping) paths_1.add_walk_seq(('a', 'c', 'd'), freq=2) paths_1.add_walk_seq(('b', 'c', 'e'), freq=2) print(paths_1.paths) print(paths_1.path_freq) <pre>{0: tensor([[0, 1],\n        [1, 3]], dtype=torch.int32), 1: tensor([[2, 1],\n        [1, 4]], dtype=torch.int32)}\n{0: 2, 1: 2}\n</pre> In\u00a0[6]: Copied! <pre>paths_1.edge_index\n</pre> paths_1.edge_index Out[6]: <pre>tensor([[0, 1, 1, 2],\n        [1, 3, 4, 1]], dtype=torch.int32)</pre> In\u00a0[7]: Copied! <pre>paths_1.edge_index_weighted\n</pre> paths_1.edge_index_weighted Out[7]: <pre>(tensor([[0, 1, 1, 2],\n         [1, 3, 4, 1]], dtype=torch.int32),\n tensor([2., 2., 2., 2.]))</pre> In\u00a0[8]: Copied! <pre>paths_1.edge_index_k_weighted(k=2)\n</pre> paths_1.edge_index_k_weighted(k=2) Out[8]: <pre>(tensor([[[0, 1],\n          [2, 1]],\n \n         [[1, 3],\n          [1, 4]]], dtype=torch.int32),\n tensor([2., 2.]))</pre> In\u00a0[9]: Copied! <pre>paths_2 = WalkData(g.mapping)\npaths_2.add_walk_seq(('a', 'c', 'd'), freq=1)\npaths_2.add_walk_seq(('a', 'c', 'e'), freq=1)\npaths_2.add_walk_seq(('b', 'c', 'd'), freq=1)\npaths_2.add_walk_seq(('b', 'c', 'e'), freq=1)\nprint(paths_2.paths)\nprint(paths_2.path_freq)\n</pre> paths_2 = WalkData(g.mapping) paths_2.add_walk_seq(('a', 'c', 'd'), freq=1) paths_2.add_walk_seq(('a', 'c', 'e'), freq=1) paths_2.add_walk_seq(('b', 'c', 'd'), freq=1) paths_2.add_walk_seq(('b', 'c', 'e'), freq=1) print(paths_2.paths) print(paths_2.path_freq) <pre>{0: tensor([[0, 1],\n        [1, 3]], dtype=torch.int32), 1: tensor([[0, 1],\n        [1, 4]], dtype=torch.int32), 2: tensor([[2, 1],\n        [1, 3]], dtype=torch.int32), 3: tensor([[2, 1],\n        [1, 4]], dtype=torch.int32)}\n{0: 1, 1: 1, 2: 1, 3: 1}\n</pre> In\u00a0[10]: Copied! <pre>paths_2.edge_index_weighted\n</pre> paths_2.edge_index_weighted Out[10]: <pre>(tensor([[0, 1, 1, 2],\n         [1, 3, 4, 1]], dtype=torch.int32),\n tensor([2., 2., 2., 2.]))</pre> In\u00a0[11]: Copied! <pre>paths_2.edge_index_k_weighted(k=2)\n</pre> paths_2.edge_index_k_weighted(k=2) Out[11]: <pre>(tensor([[[0, 1],\n          [0, 1],\n          [2, 1],\n          [2, 1]],\n \n         [[1, 3],\n          [1, 4],\n          [1, 3],\n          [1, 4]]], dtype=torch.int32),\n tensor([1., 1., 1., 1.]))</pre> In\u00a0[12]: Copied! <pre>path = IntTensor([[0,2,2],\n                  [2,3,4]])\nDAGData.edge_index_kth_order(path, k=2)\n</pre> path = IntTensor([[0,2,2],                   [2,3,4]]) DAGData.edge_index_kth_order(path, k=2) Out[12]: <pre>tensor([[[0, 2],\n         [0, 2]],\n\n        [[2, 3],\n         [2, 4]]], dtype=torch.int32)</pre> In\u00a0[13]: Copied! <pre>paths_1 = DAGData(g.mapping)\ndag = IntTensor([[0,2,2],\n                  [2,3,4]])\npaths_1.add(dag, freq=1)\ndag = IntTensor([[1,2,2],\n                  [2,3,4]])\npaths_1.add(dag, freq=1)\n</pre> paths_1 = DAGData(g.mapping) dag = IntTensor([[0,2,2],                   [2,3,4]]) paths_1.add(dag, freq=1) dag = IntTensor([[1,2,2],                   [2,3,4]]) paths_1.add(dag, freq=1) In\u00a0[14]: Copied! <pre>paths_1.edge_index_weighted\n</pre> paths_1.edge_index_weighted Out[14]: <pre>(tensor([[0, 1, 2, 2],\n         [2, 2, 3, 4]], dtype=torch.int32),\n tensor([1., 1., 2., 2.]))</pre> In\u00a0[15]: Copied! <pre>paths_1.edge_index_k_weighted(k=2)\n</pre> paths_1.edge_index_k_weighted(k=2) Out[15]: <pre>(tensor([[[0, 2],\n          [0, 2],\n          [1, 2],\n          [1, 2]],\n \n         [[2, 3],\n          [2, 4],\n          [2, 3],\n          [2, 4]]], dtype=torch.int32),\n tensor([1., 1., 1., 1.]))</pre>"},{"location":"tutorial/_new_paths/#data-on-walks","title":"Data on Walks\u00b6","text":""},{"location":"tutorial/_new_paths/#data-on-directed-acyclic-graphs","title":"Data on directed acyclic graphs\u00b6","text":""},{"location":"tutorial/_scalability_analysis/","title":"scalability analysis","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nimport torch\nimport copy\nimport time\nimport numpy as np\nfrom collections import defaultdict\nimport json\n\nimport pprint \nprinter = pprint.PrettyPrinter(indent=4)\npp.config['device'] = 'cpu'\nimport seaborn as sns\n</pre> import pathpyG as pp import torch import copy import time import numpy as np from collections import defaultdict import json  import pprint  printer = pprint.PrettyPrinter(indent=4) pp.config['device'] = 'cpu' import seaborn as sns In\u00a0[2]: Copied! <pre>def test_mo_scalability(g, exp):\n    res = copy.deepcopy(exp)\n    pp.config['device'] = exp['device']\n    g.data.to(exp['device'])\n    res['temp_net_nodes'] = g.n\n    res['temp_net_edges'] = g.m\n    res['temp_net_events'] = g.data.edge_index.size(1)\n\n    start_time = time.time()\n    eg = pp.algorithms.lift_order_temporal(g, delta=exp['delta'])\n    eg.to(exp['device'])\n    res['lift_event_graph_time'] = time.time() - start_time\n    res['event_graph_edges'] = eg.size(1)\n\n    start_time = time.time()\n    m = pp.MultiOrderModel.from_temporal_graph(g, delta=exp['delta'], max_order=exp['max_order'])\n    res['mo_time'] = time.time() - start_time\n    res['max_order_nodes'] = m.layers[exp['max_order']].n\n    res['max_order_edges'] = m.layers[exp['max_order']].m\n    return res\n</pre> def test_mo_scalability(g, exp):     res = copy.deepcopy(exp)     pp.config['device'] = exp['device']     g.data.to(exp['device'])     res['temp_net_nodes'] = g.n     res['temp_net_edges'] = g.m     res['temp_net_events'] = g.data.edge_index.size(1)      start_time = time.time()     eg = pp.algorithms.lift_order_temporal(g, delta=exp['delta'])     eg.to(exp['device'])     res['lift_event_graph_time'] = time.time() - start_time     res['event_graph_edges'] = eg.size(1)      start_time = time.time()     m = pp.MultiOrderModel.from_temporal_graph(g, delta=exp['delta'], max_order=exp['max_order'])     res['mo_time'] = time.time() - start_time     res['max_order_nodes'] = m.layers[exp['max_order']].n     res['max_order_edges'] = m.layers[exp['max_order']].m     return res  In\u00a0[3]: Copied! <pre>results = defaultdict(lambda: defaultdict())\nexp = {}\n\ng = pp.io.read_netzschleuder_graph('copenhagen', 'sms', time_attr='timestamp')\nprint(g)\nfor d in ['cuda', 'cpu']:\n    exp['device'] = d\n    for delta in np.linspace(30, 3600, 5):\n        exp['delta'] = delta\n        for k in range(2, 6):\n            exp['max_order'] = k\n            try:\n                res = test_mo_scalability(g, exp)\n                printer.pprint(res)\n                results[delta][k] = res\n            except Exception as e:\n                print(e)\n\nwith open('results_copenhagen.json', 'w') as f:\n    json.dump(results, f)\n</pre> results = defaultdict(lambda: defaultdict()) exp = {}  g = pp.io.read_netzschleuder_graph('copenhagen', 'sms', time_attr='timestamp') print(g) for d in ['cuda', 'cpu']:     exp['device'] = d     for delta in np.linspace(30, 3600, 5):         exp['delta'] = delta         for k in range(2, 6):             exp['max_order'] = k             try:                 res = test_mo_scalability(g, exp)                 printer.pprint(res)                 results[delta][k] = res             except Exception as e:                 print(e)  with open('results_copenhagen.json', 'w') as f:     json.dump(results, f) <pre>Mapping node attributes based on node indices in column `index`\nTemporal Graph with 568 nodes, 1303 unique edges and 24333 events in [18.0, 2418982.0]\n\nNode attributes\n\tnode_female\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([568])\n\tnode_id\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([568])\n\tnode__pos\t\t&lt;class 'numpy.ndarray'&gt;\n\nEdge attributes\n\ttime\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([24333])\n\tedge_index\t\t&lt;class 'torch_geometric.edge_index.EdgeIndex'&gt;\n\nGraph attributes\n\tanalyses_edge_properties\t\t&lt;class 'list'&gt;\n\tanalyses_num_edges\t\t&lt;class 'int'&gt;\n\tanalyses_degree_assortativity\t\t&lt;class 'float'&gt;\n\tanalyses_mixing_time\t\t&lt;class 'float'&gt;\n\tanalyses_diameter\t\t&lt;class 'int'&gt;\n\tanalyses_largest_component_fraction\t\t&lt;class 'float'&gt;\n\tanalyses_is_directed\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_2\t\t&lt;class 'float'&gt;\n\tanalyses_num_vertices\t\t&lt;class 'int'&gt;\n\tanalyses_vertex_properties\t\t&lt;class 'list'&gt;\n\tanalyses_edge_reciprocity\t\t&lt;class 'float'&gt;\n\tanalyses_is_bipartite\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_1\t\t&lt;class 'float'&gt;\n\tanalyses_transition_gap\t\t&lt;class 'float'&gt;\n\tanalyses_average_degree\t\t&lt;class 'float'&gt;\n\tanalyses_hashimoto_radius\t\t&lt;class 'float'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tanalyses_degree_std_dev\t\t&lt;class 'float'&gt;\n\tanalyses_global_clustering\t\t&lt;class 'float'&gt;\n\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2167.73it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2088.86it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.122706413269043,\n    'max_order': 2,\n    'max_order_edges': 557,\n    'max_order_nodes': 1303,\n    'mo_time': 12.025795459747314,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2038.99it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2069.14it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.795116186141968,\n    'max_order': 3,\n    'max_order_edges': 229,\n    'max_order_nodes': 557,\n    'mo_time': 11.878443956375122,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2042.28it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2011.84it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.777009963989258,\n    'max_order': 4,\n    'max_order_edges': 110,\n    'max_order_nodes': 229,\n    'mo_time': 12.220279693603516,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2074.25it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2061.54it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.595112562179565,\n    'max_order': 5,\n    'max_order_edges': 61,\n    'max_order_nodes': 110,\n    'mo_time': 12.093271017074585,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1082.67it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1130.39it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 22.232107639312744,\n    'max_order': 2,\n    'max_order_edges': 1236,\n    'max_order_nodes': 1303,\n    'mo_time': 21.630196571350098,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1095.26it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1120.23it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 21.974792957305908,\n    'max_order': 3,\n    'max_order_edges': 1122,\n    'max_order_nodes': 1236,\n    'mo_time': 22.22197437286377,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1107.00it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1109.25it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 21.74143648147583,\n    'max_order': 4,\n    'max_order_edges': 1008,\n    'max_order_nodes': 1122,\n    'mo_time': 22.65464735031128,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1091.36it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1142.30it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 22.076518774032593,\n    'max_order': 5,\n    'max_order_edges': 878,\n    'max_order_nodes': 1008,\n    'mo_time': 22.64402413368225,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1059.94it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:26&lt;00:00, 896.10it/s] \n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 22.712382793426514,\n    'max_order': 2,\n    'max_order_edges': 1344,\n    'max_order_nodes': 1303,\n    'mo_time': 27.22113013267517,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:28&lt;00:00, 844.85it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:27&lt;00:00, 889.93it/s] \n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 28.49084734916687,\n    'max_order': 3,\n    'max_order_edges': 1306,\n    'max_order_nodes': 1344,\n    'mo_time': 27.783222198486328,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:23&lt;00:00, 1003.20it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:24&lt;00:00, 966.13it/s] \n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 24.00903582572937,\n    'max_order': 4,\n    'max_order_edges': 1279,\n    'max_order_nodes': 1306,\n    'mo_time': 26.02214217185974,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:23&lt;00:00, 1032.85it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1111.71it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 23.30103063583374,\n    'max_order': 5,\n    'max_order_edges': 1232,\n    'max_order_nodes': 1279,\n    'mo_time': 32.56914210319519,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1102.31it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:18&lt;00:00, 1283.34it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 21.834106922149658,\n    'max_order': 2,\n    'max_order_edges': 1408,\n    'max_order_nodes': 1303,\n    'mo_time': 19.122129917144775,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:17&lt;00:00, 1371.76it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:23&lt;00:00, 1042.82it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 17.55621361732483,\n    'max_order': 3,\n    'max_order_edges': 1420,\n    'max_order_nodes': 1408,\n    'mo_time': 23.811742305755615,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1078.05it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1062.19it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 22.32985234260559,\n    'max_order': 4,\n    'max_order_edges': 1448,\n    'max_order_nodes': 1420,\n    'mo_time': 23.88112759590149,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:25&lt;00:00, 950.98it/s] \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:24&lt;00:00, 976.45it/s] \n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 25.302610397338867,\n    'max_order': 5,\n    'max_order_edges': 1452,\n    'max_order_nodes': 1448,\n    'mo_time': 58.79792809486389,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1140.34it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1482.82it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 21.1067316532135,\n    'max_order': 2,\n    'max_order_edges': 1453,\n    'max_order_nodes': 1303,\n    'mo_time': 16.5167076587677,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:15&lt;00:00, 1506.81it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:18&lt;00:00, 1323.43it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 15.98039698600769,\n    'max_order': 3,\n    'max_order_edges': 1506,\n    'max_order_nodes': 1453,\n    'mo_time': 18.9002103805542,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1448.36it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1452.72it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 16.622321605682373,\n    'max_order': 4,\n    'max_order_edges': 1594,\n    'max_order_nodes': 1506,\n    'mo_time': 17.679415464401245,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1473.71it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:15&lt;00:00, 1547.80it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 16.335521936416626,\n    'max_order': 5,\n    'max_order_edges': 1674,\n    'max_order_nodes': 1594,\n    'mo_time': 126.71205115318298,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2870.65it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2878.70it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.384625434875488,\n    'max_order': 2,\n    'max_order_edges': 557,\n    'max_order_nodes': 1303,\n    'mo_time': 8.44395112991333,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2934.42it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2889.33it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.201921463012695,\n    'max_order': 3,\n    'max_order_edges': 229,\n    'max_order_nodes': 557,\n    'mo_time': 8.436858654022217,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2906.52it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2908.75it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.282766819000244,\n    'max_order': 4,\n    'max_order_edges': 110,\n    'max_order_nodes': 229,\n    'mo_time': 8.383979320526123,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2896.13it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2940.09it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.31244707107544,\n    'max_order': 5,\n    'max_order_edges': 61,\n    'max_order_nodes': 110,\n    'mo_time': 8.297135353088379,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:09&lt;00:00, 2424.21it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2379.18it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 9.95227837562561,\n    'max_order': 2,\n    'max_order_edges': 1236,\n    'max_order_nodes': 1303,\n    'mo_time': 10.21712613105774,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2373.41it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2403.32it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 10.163817644119263,\n    'max_order': 3,\n    'max_order_edges': 1122,\n    'max_order_nodes': 1236,\n    'mo_time': 10.227073669433594,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:09&lt;00:00, 2415.48it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2388.56it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 9.988727569580078,\n    'max_order': 4,\n    'max_order_edges': 1008,\n    'max_order_nodes': 1122,\n    'mo_time': 10.93671178817749,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:09&lt;00:00, 2404.24it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2394.89it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 10.032788515090942,\n    'max_order': 5,\n    'max_order_edges': 878,\n    'max_order_nodes': 1008,\n    'mo_time': 16.719266414642334,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2240.81it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2338.14it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.765197515487671,\n    'max_order': 2,\n    'max_order_edges': 1344,\n    'max_order_nodes': 1303,\n    'mo_time': 10.433187007904053,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2329.00it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2352.14it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.362721920013428,\n    'max_order': 3,\n    'max_order_edges': 1306,\n    'max_order_nodes': 1344,\n    'mo_time': 10.513421058654785,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2353.53it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2286.25it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.253392696380615,\n    'max_order': 4,\n    'max_order_edges': 1279,\n    'max_order_nodes': 1306,\n    'mo_time': 12.241335153579712,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2351.43it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2389.42it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.25893259048462,\n    'max_order': 5,\n    'max_order_edges': 1232,\n    'max_order_nodes': 1279,\n    'mo_time': 24.42807126045227,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2166.44it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2259.16it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 11.133711338043213,\n    'max_order': 2,\n    'max_order_edges': 1408,\n    'max_order_nodes': 1303,\n    'mo_time': 10.760009765625,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2304.09it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2265.84it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 10.470611095428467,\n    'max_order': 3,\n    'max_order_edges': 1420,\n    'max_order_nodes': 1408,\n    'mo_time': 10.977295637130737,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2313.20it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2345.28it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 10.43064832687378,\n    'max_order': 4,\n    'max_order_edges': 1448,\n    'max_order_nodes': 1420,\n    'mo_time': 12.300642490386963,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2258.72it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2333.72it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 10.682463884353638,\n    'max_order': 5,\n    'max_order_edges': 1452,\n    'max_order_nodes': 1448,\n    'mo_time': 36.225979804992676,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:12&lt;00:00, 1882.08it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2125.78it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 12.819502115249634,\n    'max_order': 2,\n    'max_order_edges': 1453,\n    'max_order_nodes': 1303,\n    'mo_time': 11.431120872497559,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2244.69it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2262.04it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 10.74588942527771,\n    'max_order': 3,\n    'max_order_edges': 1506,\n    'max_order_nodes': 1453,\n    'mo_time': 10.993196725845337,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2252.99it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2266.47it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 10.709041357040405,\n    'max_order': 4,\n    'max_order_edges': 1594,\n    'max_order_nodes': 1506,\n    'mo_time': 13.24429202079773,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2223.72it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2248.93it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 10.85075306892395,\n    'max_order': 5,\n    'max_order_edges': 1674,\n    'max_order_nodes': 1594,\n    'mo_time': 63.68161463737488,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> In\u00a0[4]: Copied! <pre>results_rm = defaultdict(lambda: defaultdict())\nexp = {}\n\ng = pp.io.read_netzschleuder_graph('reality_mining', time_attr='time')\nprint(g)\nfor d in ['cuda', 'cpu']:\n    exp['device'] = d\n    for delta in np.linspace(300, 3600, 5):\n        exp['delta'] = delta\n        for k in range(2, 6):\n            exp['max_order'] = k\n            try:\n                res = test_mo_scalability(g, exp)\n                printer.pprint(res)\n                results_rm[delta][k] = res\n            except Exception as e:\n                print(e)\n\n            with open('results_rm_realitymining.json', 'w') as f:\n                json.dump(results_rm, f)\n</pre> results_rm = defaultdict(lambda: defaultdict()) exp = {}  g = pp.io.read_netzschleuder_graph('reality_mining', time_attr='time') print(g) for d in ['cuda', 'cpu']:     exp['device'] = d     for delta in np.linspace(300, 3600, 5):         exp['delta'] = delta         for k in range(2, 6):             exp['max_order'] = k             try:                 res = test_mo_scalability(g, exp)                 printer.pprint(res)                 results_rm[delta][k] = res             except Exception as e:                 print(e)              with open('results_rm_realitymining.json', 'w') as f:                 json.dump(results_rm, f) <pre>Mapping node attributes based on node indices in column `index`\nTemporal Graph with 96 nodes, 5078 unique edges and 2172808 events in [1095183104.0, 1115253760.0]\n\nNode attributes\n\tnode__pos\t\t&lt;class 'numpy.ndarray'&gt;\n\nEdge attributes\n\ttime\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2172808])\n\tedge_index\t\t&lt;class 'torch_geometric.edge_index.EdgeIndex'&gt;\n\nGraph attributes\n\tanalyses_edge_properties\t\t&lt;class 'list'&gt;\n\tanalyses_num_edges\t\t&lt;class 'int'&gt;\n\tanalyses_degree_assortativity\t\t&lt;class 'float'&gt;\n\tanalyses_mixing_time\t\t&lt;class 'float'&gt;\n\tanalyses_diameter\t\t&lt;class 'int'&gt;\n\tanalyses_largest_component_fraction\t\t&lt;class 'float'&gt;\n\tanalyses_is_directed\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_2\t\t&lt;class 'float'&gt;\n\tanalyses_num_vertices\t\t&lt;class 'int'&gt;\n\tanalyses_vertex_properties\t\t&lt;class 'list'&gt;\n\tanalyses_edge_reciprocity\t\t&lt;class 'float'&gt;\n\tanalyses_is_bipartite\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_1\t\t&lt;class 'float'&gt;\n\tanalyses_transition_gap\t\t&lt;class 'float'&gt;\n\tanalyses_average_degree\t\t&lt;class 'float'&gt;\n\tanalyses_hashimoto_radius\t\t&lt;class 'float'&gt;\n\tanalyses_degree_std_dev\t\t&lt;class 'float'&gt;\n\tanalyses_global_clustering\t\t&lt;class 'float'&gt;\n\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:05&lt;00:00, 267.26it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:04&lt;00:00, 268.49it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:04&lt;00:00, 268.28it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:03&lt;00:00, 270.22it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:37&lt;00:00, 153.98it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:35&lt;00:00, 155.29it/s]\n</pre> <pre>{   'delta': 1125.0,\n    'device': 'cuda',\n    'event_graph_edges': 55088257,\n    'lift_event_graph_time': 217.30356216430664,\n    'max_order': 2,\n    'max_order_edges': 68938,\n    'max_order_nodes': 5078,\n    'mo_time': 243.20855259895325,\n    'temp_net_edges': 2172808,\n    'temp_net_events': 2172808,\n    'temp_net_nodes': 96}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:36&lt;00:00, 154.75it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:34&lt;00:00, 155.62it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 13.03 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 16.23 GiB is allocated by PyTorch, and 576.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:02&lt;00:00, 138.14it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:04&lt;00:00, 137.04it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 13.03 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 16.23 GiB is allocated by PyTorch, and 576.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:01&lt;00:00, 138.29it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:04&lt;00:00, 136.87it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 13.03 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 16.23 GiB is allocated by PyTorch, and 576.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:10&lt;00:00, 133.29it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:10&lt;00:00, 133.48it/s]\n</pre> <pre>{   'delta': 1950.0,\n    'device': 'cuda',\n    'event_graph_edges': 96946987,\n    'lift_event_graph_time': 251.03341007232666,\n    'max_order': 2,\n    'max_order_edges': 74773,\n    'max_order_nodes': 5078,\n    'mo_time': 281.3313329219818,\n    'temp_net_edges': 2172808,\n    'temp_net_events': 2172808,\n    'temp_net_nodes': 96}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:10&lt;00:00, 133.66it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:11&lt;00:00, 133.02it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 41.73 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.80 GiB is allocated by PyTorch, and 11.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [40:51&lt;00:00, 13.65it/s]  \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [49:33&lt;00:00, 11.25it/s]  \n</pre> <pre>CUDA out of memory. Tried to allocate 41.73 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.80 GiB is allocated by PyTorch, and 11.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [40:54&lt;00:00, 13.63it/s]  \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [49:35&lt;00:00, 11.24it/s]  \n</pre> <pre>CUDA out of memory. Tried to allocate 41.73 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.80 GiB is allocated by PyTorch, and 11.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [51:22&lt;00:00, 10.85it/s]  \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [53:05&lt;00:00, 10.50it/s]  \n</pre> <pre>{   'delta': 2775.0,\n    'device': 'cuda',\n    'event_graph_edges': 124683153,\n    'lift_event_graph_time': 3082.5759828090668,\n    'max_order': 2,\n    'max_order_edges': 77875,\n    'max_order_nodes': 5078,\n    'mo_time': 3224.959701538086,\n    'temp_net_edges': 2172808,\n    'temp_net_events': 2172808,\n    'temp_net_nodes': 96}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [50:31&lt;00:00, 11.03it/s]  \n 44%|\u2588\u2588\u2588\u2588\u258e     | 14586/33452 [22:45&lt;29:25, 10.68it/s]  \n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[4], line 13\n     11 exp['max_order'] = k\n     12 try:\n---&gt; 13     res = test_mo_scalability(g, exp)\n     14     printer.pprint(res)\n     15     results_rm[delta][k] = res\n\nCell In[2], line 16, in test_mo_scalability(g, exp)\n     13 res['event_graph_edges'] = eg.size(1)\n     15 start_time = time.time()\n---&gt; 16 m = pp.MultiOrderModel.from_temporal_graph(g, delta=exp['delta'], max_order=exp['max_order'])\n     17 res['mo_time'] = time.time() - start_time\n     18 res['max_order_nodes'] = m.layers[exp['max_order']].N\n\nFile /workspaces/pathpyG/src/pathpyG/core/multi_order_model.py:108, in MultiOrderModel.from_temporal_graph(g, delta, max_order, weight, cached)\n    106 if max_order &gt; 1:\n    107     node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n--&gt; 108     edge_index = lift_order_temporal(g, delta)\n    109     edge_weight = aggregate_node_attributes(edge_index, edge_weight, \"src\")\n    111     # Aggregate\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/temporal.py:39, in lift_order_temporal(g, delta)\n     36 dst_node_mask = torch.isin(edge_index[0], edge_index[1, src_edge_idx])\n     37 dst_edge_idx = indices[dst_time_mask &amp; dst_node_mask]\n---&gt; 39 if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n     40 \n     41     # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges\n     42     x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n     43     # print(x.size(1))\n\nKeyboardInterrupt: </pre> In\u00a0[\u00a0]: Copied! <pre>order = [] \neg_time = []\nmo_time = []\ndelta = 3600.\n\nfor k in results[delta]:\n    order.append(k)\n    eg_time.append(results[delta][k]['lift_event_graph_time'])\n    mo_time.append(results[delta][k]['mo_time']-results[delta][k]['lift_event_graph_time'])\nsns.lineplot(x=order, y=eg_time, label='event graph')\nsns.lineplot(x=order, y=mo_time, label='order lifting')\n</pre> order = []  eg_time = [] mo_time = [] delta = 3600.  for k in results[delta]:     order.append(k)     eg_time.append(results[delta][k]['lift_event_graph_time'])     mo_time.append(results[delta][k]['mo_time']-results[delta][k]['lift_event_graph_time']) sns.lineplot(x=order, y=eg_time, label='event graph') sns.lineplot(x=order, y=mo_time, label='order lifting') Out[\u00a0]: <pre>&lt;Axes: &gt;</pre>"},{"location":"tutorial/_time_respecting_paths_gpu/","title":"time respecting paths gpu","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nimport torch\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\n\nfrom tqdm import tqdm\n</pre> import pathpyG as pp import torch from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index  from tqdm import tqdm In\u00a0[2]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected()\nprint(t_sp)\nprint(torch.unique(t_sp.data.t).size(0))\n</pre> t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected() print(t_sp) print(torch.unique(t_sp.data.t).size(0)) <pre>Temporal Graph with 327 nodes, 11636 unique edges and 377016 events in [1385982080.0, 1386345600.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\n1157\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 'src', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[4]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2)])\nprint(t)\n</pre> t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2)]) print(t) <pre>Temporal Graph with 5 nodes, 5 unique edges and 5 events in [0.0, 2.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\n</pre> In\u00a0[5]: Copied! <pre># new memory-efficient code copied from `temporal_shortest_paths.ipynb`\ndef lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):\n\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.t\n\n    #print(edge_index)\n    #print(timestamps)\n\n    indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)\n\n    unique_t, reverse_idx = torch.unique(timestamps, sorted=True, return_inverse=True)\n    second_order = []\n    count = 0\n\n    # lift order: find possible continuations for edges in each time stamp\n    for i in tqdm(range(unique_t.size(0))):\n        t = unique_t[i]\n        #print('timestamp index ', i)\n        #print('timestamp ', t)\n        \n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = (timestamps == t)\n        src_edges = edge_index[:,src_time_mask]\n        src_edge_idx = indices[src_time_mask]\n        #print(src_edges)\n        #print(src_edge_idx)\n\n        # find indices of all edges that can continue edges at tine t for given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)\n        dst_edges = edge_index[:,dst_time_mask]        \n        dst_edge_idx = indices[dst_time_mask]\n        #print(dst_edges)\n        #print(dst_edge_idx)\n\n        if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:\n\n            # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges        \n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n            src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n            dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n            #print(src_edges)\n            #print(dst_edges)\n            ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n            second_order.append(ho_edge_index)\n            #print(ho_edge_index) \n            \n            # #print('dst', dst)\n            # src_mask = (edge_index[:,mask][0]==dst)\n            # ctd = edge_index[:,mask][:,src_mask]\n            # #print('continuations', ctd)\n            # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]        \n            # #print('ctd indx', ctd_indices)\n            # count += ctd_indices.size(0)\n    ho_index = torch.cat(second_order, dim=1)    \n    return ho_index.size(1), ho_index\n</pre> # new memory-efficient code copied from `temporal_shortest_paths.ipynb` def lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):      # first-order edge index     edge_index, timestamps = g.data.edge_index, g.data.t      #print(edge_index)     #print(timestamps)      indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)      unique_t, reverse_idx = torch.unique(timestamps, sorted=True, return_inverse=True)     second_order = []     count = 0      # lift order: find possible continuations for edges in each time stamp     for i in tqdm(range(unique_t.size(0))):         t = unique_t[i]         #print('timestamp index ', i)         #print('timestamp ', t)                  # find indices of all source edges that occur at unique timestamp t         src_time_mask = (timestamps == t)         src_edges = edge_index[:,src_time_mask]         src_edge_idx = indices[src_time_mask]         #print(src_edges)         #print(src_edge_idx)          # find indices of all edges that can continue edges at tine t for given delta         dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)         dst_edges = edge_index[:,dst_time_mask]                 dst_edge_idx = indices[dst_time_mask]         #print(dst_edges)         #print(dst_edge_idx)          if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:              # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges                     x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()             src_edges = torch.index_select(edge_index, dim=1, index=x[0])             dst_edges = torch.index_select(edge_index, dim=1, index=x[1])             #print(src_edges)             #print(dst_edges)             ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]             second_order.append(ho_edge_index)             #print(ho_edge_index)                           # #print('dst', dst)             # src_mask = (edge_index[:,mask][0]==dst)             # ctd = edge_index[:,mask][:,src_mask]             # #print('continuations', ctd)             # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]                     # #print('ctd indx', ctd_indices)             # count += ctd_indices.size(0)     ho_index = torch.cat(second_order, dim=1)         return ho_index.size(1), ho_index In\u00a0[4]: Copied! <pre>def time_respecting_paths(g: pp.TemporalGraph, delta: int) -&gt; dict:\n    \"\"\"\n    Calculate all longest time-respecting paths in a temporal graph.\n    \"\"\"\n    paths_of_length = {}\n\n    node_sequence = torch.arange(g.data.num_nodes, device=g.data.edge_index.device).unsqueeze(1)\n    node_sequence = torch.cat([node_sequence[g.data.edge_index[0]], node_sequence[g.data.edge_index[1]][:, -1:]], dim=1)\n    edge_index = lift_order_efficient(g, delta)[1]\n    \n    # calculate degrees\n    out_degree = degree(edge_index[0], num_nodes=g.m, dtype=torch.long)\n    in_degree = degree(edge_index[1], num_nodes=g.m, dtype=torch.long)\n    # identify root nodes with in-degree zero\n    roots = torch.where(in_degree == 0)[0]\n    leafs = (out_degree == 0)\n    # print(\"Roots:\", roots)\n    # print(\"Leafs:\", leafs)\n    paths = node_sequence[roots]\n    paths_of_length[1] = paths[leafs[roots]].cpu()\n\n    paths = paths[~leafs[roots]]\n    nodes = roots[~leafs[roots]]\n\n    ptrs = cumsum(out_degree, dim=0)\n\n\n    # count all longest time-respecting paths in the temporal graph\n    step = 1\n    while nodes.size(0) &gt; 0:\n        # print(\"step\", step)\n        # print(\"Paths: \", paths)\n        # print(\"Nodes: \", nodes)\n        idx_repeat = torch.repeat_interleave(out_degree[nodes])\n        next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])\n        idx_correction = torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]\n        next_idx += idx_correction\n        next_nodes = edge_index[1][next_idx]\n        paths = torch.cat([paths[idx_repeat], node_sequence[next_nodes, 1:]], dim=1)\n        paths_of_length[step] = paths[leafs[next_nodes]].tolist()\n        paths = paths[~leafs[next_nodes]]\n        nodes = next_nodes[~leafs[next_nodes]]\n        step += 1\n\n    return paths_of_length\n</pre> def time_respecting_paths(g: pp.TemporalGraph, delta: int) -&gt; dict:     \"\"\"     Calculate all longest time-respecting paths in a temporal graph.     \"\"\"     paths_of_length = {}      node_sequence = torch.arange(g.data.num_nodes, device=g.data.edge_index.device).unsqueeze(1)     node_sequence = torch.cat([node_sequence[g.data.edge_index[0]], node_sequence[g.data.edge_index[1]][:, -1:]], dim=1)     edge_index = lift_order_efficient(g, delta)[1]          # calculate degrees     out_degree = degree(edge_index[0], num_nodes=g.m, dtype=torch.long)     in_degree = degree(edge_index[1], num_nodes=g.m, dtype=torch.long)     # identify root nodes with in-degree zero     roots = torch.where(in_degree == 0)[0]     leafs = (out_degree == 0)     # print(\"Roots:\", roots)     # print(\"Leafs:\", leafs)     paths = node_sequence[roots]     paths_of_length[1] = paths[leafs[roots]].cpu()      paths = paths[~leafs[roots]]     nodes = roots[~leafs[roots]]      ptrs = cumsum(out_degree, dim=0)       # count all longest time-respecting paths in the temporal graph     step = 1     while nodes.size(0) &gt; 0:         # print(\"step\", step)         # print(\"Paths: \", paths)         # print(\"Nodes: \", nodes)         idx_repeat = torch.repeat_interleave(out_degree[nodes])         next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])         idx_correction = torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]         next_idx += idx_correction         next_nodes = edge_index[1][next_idx]         paths = torch.cat([paths[idx_repeat], node_sequence[next_nodes, 1:]], dim=1)         paths_of_length[step] = paths[leafs[next_nodes]].tolist()         paths = paths[~leafs[next_nodes]]         nodes = next_nodes[~leafs[next_nodes]]         step += 1      return paths_of_length  In\u00a0[6]: Copied! <pre>lift_order_efficient(t_sp, delta=300)\n</pre> lift_order_efficient(t_sp, delta=300) <pre>  0%|          | 0/1157 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1157/1157 [00:08&lt;00:00, 134.85it/s]\n</pre> Out[6]: <pre>(3693050,\n tensor([[     0,      0,      0,  ..., 376991, 376991, 376991],\n         [   835,    885,    933,  ..., 376995, 377000, 377004]]))</pre> In\u00a0[7]: Copied! <pre># lift_order_efficient(t_sp, delta=300)\n</pre> # lift_order_efficient(t_sp, delta=300) In\u00a0[11]: Copied! <pre>t.data.edge_index, t.data.t\n</pre> t.data.edge_index, t.data.t Out[11]: <pre>(tensor([[0, 0, 1, 1, 3],\n         [1, 2, 2, 3, 4]]),\n tensor([0., 0., 1., 1., 2.]))</pre> In\u00a0[5]: Copied! <pre>time_respecting_paths(t_sp, delta=300)\n</pre> time_respecting_paths(t_sp, delta=300) <pre>  0%|          | 0/1157 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1157/1157 [00:07&lt;00:00, 150.48it/s]\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_xx_test/","title":"xx test","text":"In\u00a0[1]: Copied! <pre>import torch\nfrom torch_geometric.data import TemporalData\nfrom torch_geometric.utils import degree\nimport numpy as np\nimport pathpyG as pp\n\nprint('Running on', pp.config['torch']['device'])\n</pre> import torch from torch_geometric.data import TemporalData from torch_geometric.utils import degree import numpy as np import pathpyG as pp  print('Running on', pp.config['torch']['device']) <pre>Running on cpu\n</pre> In\u00a0[2]: Copied! <pre>g = pp.TemporalGraph.from_edge_list([['a', 'b', 1], ['b', 'c', 3]])\nprint(g)\n</pre> g = pp.TemporalGraph.from_edge_list([['a', 'b', 1], ['b', 'c', 3]]) print(g) <pre>Temporal Graph with 3 nodes, 2 unique edges and 2 events in [1.0, 3.0]\n\nGraph attributes\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[3]: Copied! <pre>dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=2)\npp.plot(dag)\nprint(dag.data.node_id)\nprint(dag.data.edge_index)\n</pre> dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=2) pp.plot(dag) print(dag.data.node_id) print(dag.data.edge_index) <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=2)\n      2 pp.plot(dag)\n      3 print(dag.data.node_id)\n\nAttributeError: module 'pathpyG.algorithms' has no attribute 'temporal_graph_to_event_dag'</pre> In\u00a0[30]: Copied! <pre>g = pp.TemporalGraph.from_csv('../data/ants_1_2_val_small.csv')\nprint(g)\n</pre> g = pp.TemporalGraph.from_csv('../data/ants_1_2_val_small.csv') print(g) <pre>tensor([1697, 1697, 1698, 1698, 1698, 1698, 1699, 1699, 1701, 1702, 1702, 1702,\n        1702, 1702, 1702, 1702, 1703, 1703, 1703, 1704, 1704, 1704, 1704, 1704,\n        1704, 1705, 1705, 1705, 1706, 1706, 1706, 1707, 1707, 1707, 1707, 1707,\n        1708, 1708, 1709, 1709, 1709, 1710, 1710, 1710, 1711, 1711, 1711, 1712,\n        1713, 1714, 1715, 1715, 1717, 1718, 1719, 1719, 1719, 1720, 1720, 1720,\n        1720, 1721, 1721, 1723, 1724, 1724, 1726, 1726, 1727, 1728, 1728, 1728,\n        1728, 1729, 1729, 1730, 1731, 1731, 1732, 1733, 1734, 1735, 1735, 1735,\n        1736, 1736, 1737, 1737, 1737, 1738, 1738, 1739, 1742, 1742, 1743, 1743,\n        1743, 1743, 1744, 1744, 1745, 1745, 1746, 1746, 1747, 1748, 1749],\n       device='cuda:0')\nTemporal Graph with 50 nodes 93 edges and 107 time-stamped events in [1697, 1749]\n\nNode attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([107])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([107])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([107])\n\n</pre> In\u00a0[31]: Copied! <pre>dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=30, sparsify=True)\nprint(dag)\n</pre> dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=30, sparsify=True) print(dag) <pre>Graph with 147 nodes and 159 edges\n\nNode attributes\n\tnode_idx\t\t&lt;class 'list'&gt;\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnode_name\t\t&lt;class 'list'&gt;\n\nEdge attributes\n\tedge_ts\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([159])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[32]: Copied! <pre>paths = pp.DAGData.from_temporal_dag(dag, detect_walks=False)\nprint(paths)\n</pre> paths = pp.DAGData.from_temporal_dag(dag, detect_walks=False) print(paths) <pre>PathData with 0 walks and 39 dags\n</pre> In\u00a0[35]: Copied! <pre>index, weights = paths.edge_index_k_weighted(k=2)\nprint(index)\nprint(index.size(dim=1))\nprint(weights)\n</pre> index, weights = paths.edge_index_k_weighted(k=2) print(index) print(index.size(dim=1)) print(weights) <pre>tensor([[[ 0,  1],\n         [ 0,  1],\n         [ 0,  1],\n         [ 0,  1],\n         [ 0,  1],\n         [ 0,  2],\n         [ 0,  2],\n         [ 0, 21],\n         [ 0, 21],\n         [ 0, 21],\n         [ 0, 32],\n         [ 1,  0],\n         [ 1,  0],\n         [ 1,  0],\n         [ 1,  0],\n         [ 1, 13],\n         [ 1, 13],\n         [ 1, 30],\n         [ 4,  5],\n         [ 5, 20],\n         [ 6,  7],\n         [ 6,  7],\n         [ 6,  9],\n         [ 6,  9],\n         [ 7, 39],\n         [ 7, 39],\n         [ 7, 39],\n         [ 8,  0],\n         [ 8,  0],\n         [ 8,  0],\n         [ 8,  0],\n         [ 9,  7],\n         [ 9, 24],\n         [10, 11],\n         [10, 11],\n         [10, 11],\n         [10, 11],\n         [10, 29],\n         [11,  0],\n         [11,  0],\n         [11,  0],\n         [11, 16],\n         [11, 21],\n         [11, 21],\n         [11, 22],\n         [11, 22],\n         [11, 29],\n         [11, 29],\n         [12,  1],\n         [12,  1],\n         [12, 13],\n         [12, 13],\n         [12, 30],\n         [12, 33],\n         [13,  8],\n         [20, 14],\n         [21, 11],\n         [21, 11],\n         [21, 11],\n         [22, 16],\n         [23, 24],\n         [23, 24],\n         [24,  9],\n         [25,  7],\n         [25, 26],\n         [26,  6],\n         [26,  9],\n         [26,  9],\n         [27,  8],\n         [28, 24],\n         [28, 29],\n         [28, 29],\n         [28, 29],\n         [28, 29],\n         [29, 21],\n         [29, 21],\n         [29, 21],\n         [30,  1],\n         [30, 33],\n         [31, 22],\n         [31, 22],\n         [32,  0],\n         [34, 35],\n         [34, 44],\n         [35, 34],\n         [37, 38],\n         [39,  6],\n         [39,  6],\n         [39, 45],\n         [43, 20],\n         [44, 18],\n         [45,  6],\n         [47,  9]],\n\n        [[ 1,  0],\n         [ 1, 12],\n         [ 1, 13],\n         [ 1, 30],\n         [ 1, 33],\n         [ 2,  0],\n         [ 2,  3],\n         [21, 11],\n         [21, 40],\n         [21, 42],\n         [32,  0],\n         [ 0,  2],\n         [ 0,  3],\n         [ 0, 21],\n         [ 0, 32],\n         [13,  1],\n         [13,  8],\n         [30, 33],\n         [ 5, 20],\n         [20, 43],\n         [ 7, 39],\n         [ 7, 43],\n         [ 9, 24],\n         [ 9, 36],\n         [39,  6],\n         [39, 25],\n         [39, 45],\n         [ 0,  2],\n         [ 0,  3],\n         [ 0, 21],\n         [ 0, 32],\n         [ 7, 39],\n         [24,  9],\n         [11,  0],\n         [11, 21],\n         [11, 22],\n         [11, 29],\n         [29, 42],\n         [ 0,  2],\n         [ 0,  3],\n         [ 0, 32],\n         [16, 17],\n         [21, 40],\n         [21, 42],\n         [22, 11],\n         [22, 16],\n         [29, 33],\n         [29, 42],\n         [ 1, 12],\n         [ 1, 30],\n         [13,  1],\n         [13,  8],\n         [30,  1],\n         [33, 12],\n         [ 8, 27],\n         [14, 20],\n         [11, 16],\n         [11, 22],\n         [11, 29],\n         [16, 17],\n         [24,  9],\n         [24, 28],\n         [ 9, 49],\n         [ 7, 39],\n         [26,  6],\n         [ 6, 45],\n         [ 9, 24],\n         [ 9, 36],\n         [ 8, 27],\n         [24,  9],\n         [29, 21],\n         [29, 23],\n         [29, 33],\n         [29, 42],\n         [21, 11],\n         [21, 40],\n         [21, 42],\n         [ 1, 30],\n         [33, 12],\n         [22, 11],\n         [22, 16],\n         [ 0, 46],\n         [35, 34],\n         [44, 18],\n         [34, 44],\n         [38, 37],\n         [ 6,  7],\n         [ 6, 45],\n         [45,  6],\n         [20, 14],\n         [18, 44],\n         [ 6, 45],\n         [ 9, 49]]], device='cuda:0')\n93\ntensor([ 4.,  1.,  2.,  1.,  1.,  3.,  6., 10.,  2.,  2.,  6.,  3.,  1.,  4.,\n         1.,  1.,  1.,  3.,  1.,  1.,  6.,  1.,  1.,  1.,  4.,  4.,  8.,  3.,\n         1.,  4.,  1.,  3.,  2.,  3.,  4.,  2.,  2.,  1.,  3.,  1.,  1.,  3.,\n         1.,  1.,  1.,  1.,  3.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,\n         3.,  6.,  4.,  3.,  1.,  1.,  4.,  3.,  1.,  1.,  1.,  2.,  1.,  1.,\n         3.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  3.,  1.,  1.,  6.,  1.,  1.,\n         1.,  1.,  2.,  1.,  3.,  1.,  1.,  3.,  1.], device='cuda:0')\n</pre> In\u00a0[36]: Copied! <pre>def map_edge_index(edge_index, weights, map):\n    paths = []\n    for i in range(edge_index.size(dim=1)):\n        paths.append((map[edge_index[0][i][0].item()], map[edge_index[0][i][1].item()], map[edge_index[1][i][1].item()], weights[i].item()))\n    return paths\n</pre> def map_edge_index(edge_index, weights, map):     paths = []     for i in range(edge_index.size(dim=1)):         paths.append((map[edge_index[0][i][0].item()], map[edge_index[0][i][1].item()], map[edge_index[1][i][1].item()], weights[i].item()))     return paths  In\u00a0[37]: Copied! <pre>paths = map_edge_index(index, weights, g.mapping.idx_to_id)\nwith open('ants_1_2_paths.csv', 'w') as f:\n    for p in paths:\n        f.write('{0};{1}\\n'.format(','.join(p[:-1]), p[-1]))\n</pre> paths = map_edge_index(index, weights, g.mapping.idx_to_id) with open('ants_1_2_paths.csv', 'w') as f:     for p in paths:         f.write('{0};{1}\\n'.format(','.join(p[:-1]), p[-1])) In\u00a0[5]: Copied! <pre>g1 = pp.HigherOrderGraph(paths, order=1)\nprint(g1)\n</pre> g1 = pp.HigherOrderGraph(paths, order=1) print(g1) <pre>HigherOrderGraph (k=1) with 71 nodes and 591 edges\n\tTotal edge weight = 3230.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([591])\n\nGraph attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[34]: Copied! <pre>g2 = pp.HigherOrderGraph(paths, order=2)\nprint(g2)\n</pre> g2 = pp.HigherOrderGraph(paths, order=2) print(g2) <pre>HigherOrderGraph (k=2) with 80 nodes and 93 edges\n\tTotal edge weight = 202.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([93])\n\nGraph attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[38]: Copied! <pre>g = pp.TemporalGraph.from_edge_list([['a', 'b', 1], ['b', 'c',2], ['c', 'd',3], ['c', 'e', 3]])\nprint(g)\n</pre> g = pp.TemporalGraph.from_edge_list([['a', 'b', 1], ['b', 'c',2], ['c', 'd',3], ['c', 'e', 3]]) print(g) <pre>tensor([1, 2, 3, 3], device='cuda:0')\nTemporal Graph with 5 nodes 4 edges and 4 time-stamped events in [1, 3]\n\nNode attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\n</pre> In\u00a0[39]: Copied! <pre>dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=5, sparsify=True)\nprint(dag)\nprint(dag.data['node_name'])\nprint(dag.node_index_to_id)\npp.plot(dag, edge_color='lightgray')\n</pre> dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=5, sparsify=True) print(dag) print(dag.data['node_name']) print(dag.node_index_to_id) pp.plot(dag, edge_color='lightgray') <pre>Graph with 5 nodes and 4 edges\n\nNode attributes\n\tnode_idx\t\t&lt;class 'list'&gt;\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnode_name\t\t&lt;class 'list'&gt;\n\nEdge attributes\n\tedge_ts\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n['a', 'b', 'c', 'd', 'e']\n{0: 'a-1', 1: 'b-2', 2: 'c-3', 3: 'd-4', 4: 'e-4'}\n</pre> In\u00a0[40]: Copied! <pre>x = pp.algorithms.extract_causal_trees(dag)\nprint(x)\n</pre> x = pp.algorithms.extract_causal_trees(dag) print(x) <pre>{'a-1': tensor([[0, 1, 2, 2],\n        [1, 2, 3, 4]], device='cuda:0', dtype=torch.int32)}\n</pre> In\u00a0[41]: Copied! <pre>paths = pp.DAGData.from_temporal_dag(dag)\nprint(paths)\nprint(paths.mapping)\n</pre> paths = pp.DAGData.from_temporal_dag(dag) print(paths) print(paths.mapping) <pre>PathData with 0 walks and 1 dags\n{0: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n</pre> In\u00a0[42]: Copied! <pre>paths.edge_index_k_weighted(k=1)\n</pre> paths.edge_index_k_weighted(k=1) Out[42]: <pre>(tensor([[0, 1, 2, 2],\n         [1, 2, 3, 4]], device='cuda:0'),\n tensor([1., 1., 1., 1.], device='cuda:0'))</pre> In\u00a0[43]: Copied! <pre>g1 = pp.HigherOrderGraph(paths, order=1)\nprint(g1)\npp.plot(g1)\n</pre> g1 = pp.HigherOrderGraph(paths, order=1) print(g1) pp.plot(g1) <pre>HigherOrderGraph (k=1) with 5 nodes and 4 edges\n\tTotal edge weight = 4.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[44]: Copied! <pre>paths.edge_index_k_weighted(k=2)\n</pre> paths.edge_index_k_weighted(k=2) Out[44]: <pre>(tensor([[[0, 1],\n          [1, 2],\n          [1, 2]],\n \n         [[1, 2],\n          [2, 3],\n          [2, 4]]], device='cuda:0'),\n tensor([1., 1., 1.], device='cuda:0'))</pre> In\u00a0[45]: Copied! <pre>g2 = pp.HigherOrderGraph(paths, order=2)\nprint(g2)\n</pre> g2 = pp.HigherOrderGraph(paths, order=2) print(g2) <pre>HigherOrderGraph (k=2) with 4 nodes and 3 edges\n\tTotal edge weight = 3.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\n\nGraph attributes\n\tnode_id\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[27]: Copied! <pre>pp.plot(g2)\n</pre> pp.plot(g2) In\u00a0[41]: Copied! <pre># edge_index =torch.IntTensor([[0,1,2],[1,2,3]])\n# edge_index = edge_index.reshape(edge_index.size()+(1,))\n# print(edge_index)\n\na = edge_index[0].unique(dim=0)\nb = edge_index[1].unique(dim=0)\n# intersection of a and b corresponds to all center nodes, which have at least one incoming and one outgoing edge\ncombined = torch.cat((a, b))\nuniques, counts = combined.unique(dim=0, return_counts=True)\ncenter_nodes = uniques[counts &gt; 1]\nprint(center_nodes)\nsrc = []\ndst = []\nfor v in center_nodes:\n    src_index = torch.all(edge_index[1]==v, axis=1).nonzero().flatten() # type: ignore\n    srcs = edge_index[0][src_index]\n    # get all successors of v, i.e. elements in edge_index[1] where edge_index[0] == v\n    dst_index = torch.all(edge_index[0]==v, axis=1).nonzero().flatten() # type: ignore\n    dsts = edge_index[1][dst_index]\n    for s in srcs:\n        for d in dsts:\n            src.append(torch.cat((torch.gather(s, 0, torch.tensor([0])), v)))\n            dst.append(torch.cat((v, torch.gather(d, 0, torch.tensor([d.size()[0]-1])))))\nedge_index = torch.stack((torch.stack(src), torch.stack(dst)))\nprint(edge_index)\n</pre> # edge_index =torch.IntTensor([[0,1,2],[1,2,3]]) # edge_index = edge_index.reshape(edge_index.size()+(1,)) # print(edge_index)  a = edge_index[0].unique(dim=0) b = edge_index[1].unique(dim=0) # intersection of a and b corresponds to all center nodes, which have at least one incoming and one outgoing edge combined = torch.cat((a, b)) uniques, counts = combined.unique(dim=0, return_counts=True) center_nodes = uniques[counts &gt; 1] print(center_nodes) src = [] dst = [] for v in center_nodes:     src_index = torch.all(edge_index[1]==v, axis=1).nonzero().flatten() # type: ignore     srcs = edge_index[0][src_index]     # get all successors of v, i.e. elements in edge_index[1] where edge_index[0] == v     dst_index = torch.all(edge_index[0]==v, axis=1).nonzero().flatten() # type: ignore     dsts = edge_index[1][dst_index]     for s in srcs:         for d in dsts:             src.append(torch.cat((torch.gather(s, 0, torch.tensor([0])), v)))             dst.append(torch.cat((v, torch.gather(d, 0, torch.tensor([d.size()[0]-1]))))) edge_index = torch.stack((torch.stack(src), torch.stack(dst))) print(edge_index) <pre>tensor([[1, 2]], dtype=torch.int32)\ntensor([[[0, 1, 2]],\n\n        [[1, 2, 3]]], dtype=torch.int32)\n</pre> In\u00a0[12]: Copied! <pre>g2 = pp.HigherOrderGraph(paths, order=3)\nprint(g2)\n</pre> g2 = pp.HigherOrderGraph(paths, order=3) print(g2) <pre>HigherOrderGraph (k=3) with 2 nodes and 1 edges\n\tTotal edge weight = 1.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tnode_id\t\t&lt;class 'list'&gt;\n\n</pre> In\u00a0[\u00a0]: Copied! <pre>print(g2)\n</pre> print(g2) In\u00a0[\u00a0]: Copied! <pre>pp.plot(g2)\n</pre> pp.plot(g2) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/_xx_test/#toy-example","title":"Toy Example\u00b6","text":""},{"location":"tutorial/basic_concepts/","title":"Basic Concepts","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nimport torch_geometric as pyG\nfrom torch_geometric.data import Data\nimport pandas as pd\n\nimport pathpyG as pp\npp.config['torch']['device'] = 'cpu'\n</pre> import torch import torch_geometric as pyG from torch_geometric.data import Data import pandas as pd  import pathpyG as pp pp.config['torch']['device'] = 'cpu' In\u00a0[2]: Copied! <pre>d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]]))\ng = pp.Graph(d)\nprint(g)\n</pre> d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]])) g = pp.Graph(d) print(g) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>If we do not need additional node or edge attributes, we can use the class function <code>Graph.from_edge_index</code> to directly create a graph based on an edge index:</p> In\u00a0[4]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]))\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]])) print(g) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>We may want to inlude isolated nodes that do not have an edge. We can do so by passing a <code>num_nodes</code> parameter. The following graph thus contains a fourth node (which we could name as <code>d</code>) that is not connected to any of the other nodes.</p> In\u00a0[5]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes=4)\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes=4) print(g) <pre>Directed graph with 4 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>In both cases, the <code>Graph</code> instance has a property <code>g.data</code> that stores a <code>pyG</code> <code>Data</code> object that includes the edge index as well as any further node-, edge- or graph-level attributes.</p> In\u00a0[6]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 3], num_nodes=4, node_sequence=[4, 1])\n</pre> <p>Note that the <code>edge_index</code> is actually of type <code>pyG.EdgeIndex</code>, which is a subclass of <code>torch.Tensor</code>. Any tensor passed as an edge index in the constructor of <code>Graph</code> will automatically be converted to an <code>EdgeIndex</code> instance, as this internally allows us to provide efficient edge traveral routines based on sparse matrix operations. To support this, the edge index will be automatically sorted by row when the <code>Graph</code> object is created. To avoid this additional sort operation, you can pass an already sorted <code>EdgeIndex</code> object in the <code>Data</code> object in the constructor or using the <code>from_edge_index</code> class function.</p> In\u00a0[7]: Copied! <pre>print(g.data.edge_index)\n</pre> print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1],\n           [2, 1, 2]], sparse_size=(4, 4), nnz=3, sort_order=row)\n</pre> <p>We can use the generators <code>nodes</code> and <code>edges</code> to iterate through the nodes and edges of a graph as follows:</p> In\u00a0[8]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>0\n1\n2\n3\n(0, 2)\n(0, 1)\n(1, 2)\n</pre> <p>While the index-based representation of nodes allows for efficient tensor-based operations, it is often more convenient to use string identifiers to refer to nodes. To simplify the handling of graphs with such string node identifiers, <code>pathpyG</code> provides a class <code>IndexMap</code> that transparently maps string identifiers to integer indices. For our small example graph, we can create an <code>IndexMap</code> that associates node indices with string IDs. For our example, we can create a mapping as follows:</p> In\u00a0[9]: Copied! <pre>m = pp.IndexMap(['a', 'b', 'c', 'd'])\nprint(m)\n</pre> m = pp.IndexMap(['a', 'b', 'c', 'd']) print(m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n</pre> <p>We can use the functions <code>IndexMap.to_id</code> or <code>IndexMap.to_idx</code> to map a node to an index or an ID:</p> In\u00a0[10]: Copied! <pre>m.to_id(0)\n</pre> m.to_id(0) Out[10]: <pre>'a'</pre> In\u00a0[11]: Copied! <pre>m.to_idx('b')\n</pre> m.to_idx('b') Out[11]: <pre>1</pre> <p><code>pathpyG</code> actually makes this mapping transparent for the user. For this, we can add our mapping to the <code>Graph</code> object, either by passing it in the constructor or by setting the <code>mapping</code> attribute of an existing <code>Graph</code> instance.</p> In\u00a0[12]: Copied! <pre>g.mapping = m\n</pre> g.mapping = m <p>If we now iterate through the nodes and edges of the graph, we get:</p> In\u00a0[13]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>a\nb\nc\nd\n('a', 'c')\n('a', 'b')\n('b', 'c')\n</pre> <p>We can achieve the same result if we pass the <code>IndexMap</code> object in the constructor of a graph. This transparently applies the mapping in all future function calls.</p> In\u00a0[14]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes = 4, mapping=m)\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes = 4, mapping=m) print(g) <pre>Directed graph with 4 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>Above, we have created a graph based on an edge index tensor and we then additionally applied a mapping that we manually defined. We often have data in the form on an edge list, where edges are given as tuples of non-numeric node identifiers. The class function <code>Graph.from_edge_list</code> simplifies the construction of a <code>Graph</code> from such edge lists. This will automatically generate an internal integer-based representation of the edge index, as well as the associated <code>IndexMap</code>, where the integer node indices are based on the lexicographic order of node IDs.</p> In\u00a0[15]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')])\nprint(g)\nprint(g.data.edge_index)\nprint(g.mapping)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')]) print(g) print(g.data.edge_index) print(g.mapping) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 0, 1],\n           [1, 2, 2]], sparse_size=(3, 3), nnz=3, sort_order=row)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n</pre> <p>We could alternatively pass a custom index mapping, e.g. mapping node <code>c</code> to idex 1 and node <code>b</code> to index 2 (thus deviating from a lexicographic order):</p> In\u00a0[16]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('a','c'), ('b','c')], mapping = pp.IndexMap(['a', 'c', 'b']))\nprint(g.data.edge_index)\nprint(g.mapping)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('a','c'), ('b','c')], mapping = pp.IndexMap(['a', 'c', 'b'])) print(g.data.edge_index) print(g.mapping) <pre>EdgeIndex([[0, 0, 2],\n           [2, 1, 1]], sparse_size=(3, 3), nnz=3, sort_order=row)\na -&gt; 0\nc -&gt; 1\nb -&gt; 2\n\n</pre> In\u00a0[17]: Copied! <pre>g.get_successors(0)\n</pre> g.get_successors(0) Out[17]: <pre>tensor([2, 1])</pre> In\u00a0[18]: Copied! <pre>g.get_predecessors(0)\n</pre> g.get_predecessors(0) Out[18]: <pre>tensor([], dtype=torch.int64)</pre> <p>Note that, even if a mapping is defined, the <code>get_successors</code> and <code>get_predecessors</code> functions always return a tensor with node indices, rather than node IDs. This is useful to support fast tensor-based operations on the list of successors and predecessors. We could always manually map the node indices using the <code>IndexMap</code> object defined in the <code>mapping</code> attribute.</p> <p>If we want to traverse graphs based on string node IDs, we can use the <code>successors</code> and <code>predecessors</code> generators of the <code>Graph</code> object, which -- if an ID-Index mapping is defined - yield the string labels of successor or predecessor nodes for a given node (also identified by its string label).</p> In\u00a0[19]: Copied! <pre>for v in g.successors('a'):\n    print(v)\n</pre> for v in g.successors('a'):     print(v) <pre>b\nc\n</pre> In\u00a0[20]: Copied! <pre>for v in g.predecessors('c'):\n    print(v)\n</pre> for v in g.predecessors('c'):     print(v) <pre>a\nb\n</pre> <p>To check (again in constant time) whether an edge exists in the graph, we can call the <code>is_edge</code> function:</p> In\u00a0[21]: Copied! <pre>g.is_edge('a', 'b')\n</pre> g.is_edge('a', 'b') Out[21]: <pre>True</pre> <p>Alternatively, we can use the following function to check (in constant time) whether node <code>b</code> is a successor of <code>a</code></p> In\u00a0[22]: Copied! <pre>'b' in g.successors('a')\n</pre> 'b' in g.successors('a') Out[22]: <pre>True</pre> <p>By default, graph objects in <code>pathpyG</code> are directed, i.e. for the graph above, the edge <code>(b,a)</code> does not exist, which we can verify as follows:</p> In\u00a0[23]: Copied! <pre>print('a' in g.successors('b'))\nprint(g.is_edge('b', 'a'))\n</pre> print('a' in g.successors('b')) print(g.is_edge('b', 'a')) <pre>False\nFalse\n</pre> <p>To calculate (directed) in- and out-degrees of nodes, we can use the properties <code>in_degrees</code> and <code>out_degrees</code>, which return a dictionary that maps node IDs to their degrees:</p> In\u00a0[24]: Copied! <pre>g.in_degrees\n</pre> g.in_degrees Out[24]: <pre>{'a': 0, 'c': 2, 'b': 1}</pre> In\u00a0[25]: Copied! <pre>g.in_degrees['b']\n</pre> g.in_degrees['b'] Out[25]: <pre>1</pre> In\u00a0[26]: Copied! <pre>g.in_degrees['a']\n</pre> g.in_degrees['a'] Out[26]: <pre>0</pre> In\u00a0[27]: Copied! <pre>g.in_degrees['c']\n</pre> g.in_degrees['c'] Out[27]: <pre>2</pre> <p>Importantly, irrespective of how we have generated the graph object, the actual node and edge data are always stored as a <code>pyG</code> data object. This allows us to use the full power of <code>torch</code> and <code>pyG</code>, including the application of transforms, splits, or any easy migration between CPU and GPU-based computation.</p> In\u00a0[28]: Copied! <pre>g.data\n</pre> g.data Out[28]: <pre>Data(edge_index=[2, 3], num_nodes=3, node_sequence=[3, 1])</pre> <p>In general, <code>pathpyG</code> will use the device specified in the <code>torch.device</code> configuration (see above) whenver it internally creates a torch tensor. Since above, we have specified the <code>cpu</code> device, the data object of the graph generated above will reside in main memory:</p> In\u00a0[29]: Copied! <pre>g.data.is_cuda\n</pre> g.data.is_cuda Out[29]: <pre>False</pre> <p>If we instead set the device to <code>cuda</code>, the <code>Data</code> object will internally be created in main memory instead.</p> In\u00a0[30]: Copied! <pre>pp.config['torch']['device'] = 'cuda'\n\ng = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')])\ng.data.is_cuda\n</pre> pp.config['torch']['device'] = 'cuda'  g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')]) g.data.is_cuda Out[30]: <pre>False</pre> In\u00a0[31]: Copied! <pre>pp.config['torch']['device'] = 'cpu'\ng.data = g.data.to('cpu')\n</pre> pp.config['torch']['device'] = 'cpu' g.data = g.data.to('cpu') In\u00a0[32]: Copied! <pre>g.data['node_class'] = torch.tensor([[0], [0], [1]], device=pp.config['torch']['device'])\ng.data['edge_weight'] = torch.tensor([[1], [2], [3]], device=pp.config['torch']['device'])\ng.data['feature'] = torch.tensor([3, 2], device=pp.config['torch']['device'])\n</pre> g.data['node_class'] = torch.tensor([[0], [0], [1]], device=pp.config['torch']['device']) g.data['edge_weight'] = torch.tensor([[1], [2], [3]], device=pp.config['torch']['device']) g.data['feature'] = torch.tensor([3, 2], device=pp.config['torch']['device']) <p>Once we have added attributes to nodes, edges, or the graph, those attributes, along with their type and shape will be shown when you print a string representation of the graph object:</p> In\u00a0[33]: Copied! <pre>print(g)\n</pre> print(g) <pre>Directed graph with 3 nodes and 3 edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\"},\n    'Graph Attributes': {'feature': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {'node_class': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\"}}\n</pre> <p>To simplify access to attribute values, the <code>Graph</code> class provides getter and setter functions that allow to access attribute values based on node identifiers. To access the feature <code>node_feature</code> of node <code>a</code>, we can write:</p> In\u00a0[34]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[34]: <pre>tensor([0])</pre> <p>To access the weight of edge <code>(a, b)</code> we can write:</p> In\u00a0[35]: Copied! <pre>g['edge_weight', 'a', 'b']\n</pre> g['edge_weight', 'a', 'b'] Out[35]: <pre>tensor([1])</pre> <p>And finally, graph-based attributes can accessed as follows:</p> In\u00a0[36]: Copied! <pre>g['feature']\n</pre> g['feature'] Out[36]: <pre>tensor([3, 2])</pre> <p>We can also use the setter functions to change attributes:</p> In\u00a0[37]: Copied! <pre>g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda')\n</pre> g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda') In\u00a0[38]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[38]: <pre>tensor([7], device='cuda:0')</pre> <p>To create sparse adjacency matrix representations of graphs, we can use the following function:</p> In\u00a0[39]: Copied! <pre>print(g.sparse_adj_matrix())\n</pre> print(g.sparse_adj_matrix()) <pre>  (0, 1)\t1.0\n  (0, 2)\t1.0\n  (1, 2)\t1.0\n</pre> <p>This returns a <code>scipy.sparse.coo_matrix</code> object, which can be turned into a dense <code>numpy</code> matrix as follows:</p> In\u00a0[40]: Copied! <pre>print(g.sparse_adj_matrix().todense())\n</pre> print(g.sparse_adj_matrix().todense()) <pre>[[0. 1. 1.]\n [0. 0. 1.]\n [0. 0. 0.]]\n</pre> <p>By passing the name of the attribute, we can use edge attributes in the creation of the adjacency matrix. To create a sparse, weighted adjacency matrix that uses the <code>edge_weight</code> attribute of our graph object we can simply write:</p> In\u00a0[41]: Copied! <pre>print(g.sparse_adj_matrix(edge_attr='edge_weight').todense())\n</pre> print(g.sparse_adj_matrix(edge_attr='edge_weight').todense()) <pre>[[0 1 2]\n [0 0 3]\n [0 0 0]]\n</pre> <p>By default, graphs in <code>pathpyG</code> are directed. To represent undirected edges, we must add edges in both directions. We can use the <code>to_undirected()</code> function to make a directed graph undirected, which adds all (missing) edges that point in the opposite direction. This will also automatically duplicate and assign the corresponding edge attributes to the newly formed (directed) edges, i.e. edges are assumed to have the same attributes in both directions.</p> In\u00a0[42]: Copied! <pre>g_u = g.to_undirected()\nprint(g_u)\n</pre> g_u = g.to_undirected() print(g_u) <pre>Undirected graph with 3 nodes and 6 (directed) edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 1])\"},\n    'Graph Attributes': {'feature': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {'node_class': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\"}}\n</pre> <p>By default, the <code>Graph</code> object can contain multiple identical edges, so the following is possible:</p> In\u00a0[43]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')])\nprint(g.data.edge_index)\n</pre> g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')]) print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1, 2],\n           [1, 1, 2, 0]], sparse_size=(3, 3), nnz=4, sort_order=row)\n</pre> <p>It is often convenient, to coalesce multi-edges into weighted single-edges, i.e. in the example above we may prefer a graph where each edge occurs once in the edge index, but the edge <code>a-&gt;b</code> has a weight attribute of two, while the two other edges have one.</p> <p>In <code>pathpyG</code> we can do this by turning a graph into a weighted graph, which will coalesce edges and add an edge weight attribute that counts multi-edges in the original istance.</p> In\u00a0[44]: Copied! <pre>g_w = g.to_weighted_graph()\nprint(g_w.data.edge_index)\nprint(g_w['edge_weight', 'a', 'b'])\nprint(g_w['edge_weight', 'b', 'c'])\nprint(g_w['edge_weight', 'c', 'a'])\n</pre> g_w = g.to_weighted_graph() print(g_w.data.edge_index) print(g_w['edge_weight', 'a', 'b']) print(g_w['edge_weight', 'b', 'c']) print(g_w['edge_weight', 'c', 'a']) <pre>EdgeIndex([[0, 1, 2],\n           [1, 2, 0]], sparse_size=(3, 3), nnz=3, sort_order=row)\ntensor(2.)\ntensor(1.)\ntensor(1.)\n</pre> <p>As we will see in a separate notebook focusing on the advanced (temporal) graph visualization features of <code>pathpyG</code>, it is easy to generate (interactive) HTML plots of graphs, that are embedded into jupyter notebooks. You can simply call the <code>pp.plot</code> function on the Graph object:</p> In\u00a0[45]: Copied! <pre>pp.plot(g, edge_color='gray', node_label=g.mapping.node_ids.tolist());\n</pre> pp.plot(g, edge_color='gray', node_label=g.mapping.node_ids.tolist()); In\u00a0[46]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('c','a')])\nprint(g)\n\ndf = pp.io.graph_to_df(g)\nprint(df)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('c','a')]) print(g)  df = pp.io.graph_to_df(g) print(df) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n   v  w\n0  a  b\n1  b  c\n2  c  a\n</pre> In\u00a0[47]: Copied! <pre>g.data.edge_weight = [1.0, 2.0, 3.0]\nprint(g)\n\ndf = pp.io.graph_to_df(g)\nprint(df)\n</pre> g.data.edge_weight = [1.0, 2.0, 3.0] print(g)  df = pp.io.graph_to_df(g) print(df) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'list'&gt;\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n   v  w  edge_weight\n0  a  b          1.0\n1  b  c          2.0\n2  c  a          3.0\n</pre> In\u00a0[48]: Copied! <pre>node_attr = pd.DataFrame({'v': ['b', 'a', 'c'], 'node_size': [5.0, 2.0, 1.0]})\nprint(node_attr)\n</pre> node_attr = pd.DataFrame({'v': ['b', 'a', 'c'], 'node_size': [5.0, 2.0, 1.0]}) print(node_attr) <pre>   v  node_size\n0  b        5.0\n1  a        2.0\n2  c        1.0\n</pre> In\u00a0[49]: Copied! <pre>pp.io.add_node_attributes(node_attr, g)\nprint(g.data.node_size)\n</pre> pp.io.add_node_attributes(node_attr, g) print(g.data.node_size) <pre>Mapping node attributes based on node names in column `v`\ntensor([2., 5., 1.], dtype=torch.float64)\n</pre> In\u00a0[50]: Copied! <pre>edge_attr = pd.DataFrame({'v': ['c', 'a', 'b'], 'w': ['a', 'b', 'c'], 'edge_weight': [42.0, 43.0, 45.0]})\nprint(edge_attr)\n</pre> edge_attr = pd.DataFrame({'v': ['c', 'a', 'b'], 'w': ['a', 'b', 'c'], 'edge_weight': [42.0, 43.0, 45.0]}) print(edge_attr) <pre>   v  w  edge_weight\n0  c  a         42.0\n1  a  b         43.0\n2  b  c         45.0\n</pre> In\u00a0[51]: Copied! <pre>pp.io.add_edge_attributes(edge_attr, g)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> pp.io.add_edge_attributes(edge_attr, g) print(g.data.edge_index) print(g.data.edge_weight) <pre>EdgeIndex([[0, 1, 2],\n           [1, 2, 0]], sparse_size=(3, 3), nnz=3, sort_order=row)\ntensor([45., 42., 43.], dtype=torch.float64)\n</pre> In\u00a0[52]: Copied! <pre>df = pp.io.graph_to_df(g, node_indices=True)\nprint(df)\n</pre> df = pp.io.graph_to_df(g, node_indices=True) print(df) <pre>   v  w  edge_weight\n0  0  1         45.0\n1  1  2         42.0\n2  2  0         43.0\n</pre> In\u00a0[53]: Copied! <pre>edge_attr = pd.DataFrame([['c', 'a', 'b'], ['a', 'b', 'c'], [42.0, 43.0, 45.0]])\nprint(edge_attr)\n</pre> edge_attr = pd.DataFrame([['c', 'a', 'b'], ['a', 'b', 'c'], [42.0, 43.0, 45.0]]) print(edge_attr) <pre>      0     1     2\n0     c     a     b\n1     a     b     c\n2  42.0  43.0  45.0\n</pre> In\u00a0[54]: Copied! <pre>pp.io.write_csv(g, '../data/test_graph.csv')\n</pre> pp.io.write_csv(g, '../data/test_graph.csv') In\u00a0[55]: Copied! <pre>g = pp.io.read_csv_graph('../data/test_graph.csv')\nprint(g)\nprint(g.data)\nprint(g.mapping)\n</pre> g = pp.io.read_csv_graph('../data/test_graph.csv') print(g) print(g.data) print(g.mapping) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nData(edge_index=[2, 3], num_nodes=3, node_sequence=[3, 1], edge_weight=[3])\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n</pre> In\u00a0[56]: Copied! <pre>g.edge_attrs()\n</pre> g.edge_attrs() Out[56]: <pre>['edge_weight']</pre> In\u00a0[57]: Copied! <pre>g.data\n</pre> g.data Out[57]: <pre>Data(edge_index=[2, 3], num_nodes=3, node_sequence=[3, 1], edge_weight=[3])</pre> In\u00a0[58]: Copied! <pre>pp.algorithms.centrality.closeness_centrality(g)\n</pre> pp.algorithms.centrality.closeness_centrality(g) Out[58]: <pre>{'a': 0.6666666666666666, 'b': 0.6666666666666666, 'c': 0.6666666666666666}</pre> In\u00a0[59]: Copied! <pre>pp.algorithms.centrality.eigenvector_centrality(g)\n</pre> pp.algorithms.centrality.eigenvector_centrality(g) Out[59]: <pre>{'a': 0.5773502691896258, 'b': 0.5773502691896258, 'c': 0.5773502691896258}</pre> In\u00a0[60]: Copied! <pre>pp.algorithms.centrality.katz_centrality(g)\n</pre> pp.algorithms.centrality.katz_centrality(g) Out[60]: <pre>{'a': 0.5773502691896258, 'b': 0.5773502691896258, 'c': 0.5773502691896258}</pre> In\u00a0[61]: Copied! <pre>import numpy as np\nimport seaborn as sns\n\nx = np.linspace(0, 1, 100)\ny = pp.statistics.degree_generating_function(g.to_undirected(), x)\nax = sns.lineplot(x=x, y=y)\nax.set_xlabel('$x$', fontsize=16)\nax.set_ylabel('$G_0(x)$', fontsize=16);\n</pre> import numpy as np import seaborn as sns  x = np.linspace(0, 1, 100) y = pp.statistics.degree_generating_function(g.to_undirected(), x) ax = sns.lineplot(x=x, y=y) ax.set_xlabel('$x$', fontsize=16) ax.set_ylabel('$G_0(x)$', fontsize=16); In\u00a0[62]: Copied! <pre>k_2 = pp.statistics.degree_raw_moment(g.to_undirected(), k=2)\nprint(k_2)\nk_1 = pp.statistics.degree_raw_moment(g.to_undirected(), k=1)\nprint(k_1)\nprint('Molloy-Reed Fraction &lt;k^2&gt;/&lt;k&gt;: ', k_2/k_1)\n</pre> k_2 = pp.statistics.degree_raw_moment(g.to_undirected(), k=2) print(k_2) k_1 = pp.statistics.degree_raw_moment(g.to_undirected(), k=1) print(k_1) print('Molloy-Reed Fraction /: ', k_2/k_1) <pre>4.0\n2.0\nMolloy-Reed Fraction &lt;k^2&gt;/&lt;k&gt;:  2.0\n</pre>"},{"location":"tutorial/basic_concepts/#basic-pathpyg-concepts","title":"Basic pathpyG Concepts\u00b6","text":""},{"location":"tutorial/basic_concepts/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/basic_concepts/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>This first step of our multi-stage introductory tutorial introduces key concepts of <code>pathpyG</code>. While <code>pathpyG</code> targets GPU-accelerated analysis and learning using higher-order graph models for time series data on graphs, it can also be used to represent, analyze and interactively visualize static graphs. For this, it provides a <code>Graph</code> class that is build around the <code>torch_geometric.data.Data</code> object, which has the advantage that we can directly apply <code>pyG</code> transforms and use the <code>Graph</code> object for deep graph learning.</p> <p>In this tutorial you will learn how we can use <code>pathpyG</code> to represent static graphs. We start with basic features to create directed and undirected graphs with node-, edge-, and graph-level attributes. We also show how we can read and write graph data and how we can implement graph algorithms that are based on a traversal of nodes and edges.</p> <p>We first import the modules <code>torch</code>, <code>torch_geometric</code> and <code>pathpyG</code>. By setting the device used by <code>torch</code>, we specify whether we want to run our code on the CPU or on the GPU. For a CPU-based execution, set the <code>torch.device</code> configuration to <code>cpu</code>. Set the device to <code>cuda</code> if you want to run it on the GPU instead.</p>"},{"location":"tutorial/basic_concepts/#creating-graph-objects","title":"Creating Graph objects\u00b6","text":"<p>Let's start by generating a simple, directed graph with three nodes <code>a</code>, <code>b</code>, <code>c</code> and three edges <code>(a,b)</code>, <code>(b,c)</code> and <code>(a,b)</code>. The three nodes <code>a</code>, <code>b</code>, and <code>c</code> can be represented by integer indices $0, 1$ and $2$ respectively. Following the tensor-based representation in <code>pyG</code>, we use an <code>edge_index</code> tensor with shape <code>(2,m)</code> to represent the <code>m</code> edges of a graph. We can then add this to a <code>Data</code> object that can hold additional node and edge attributes. We finally pass the <code>Data</code> object to the constructor of the <code>Graph</code> class.</p> <p>Using the mapping of node names to indices specified above, the following code generates a directed <code>Graph</code> with three edges <code>(a,c)</code>, <code>(b,c)</code> and <code>(a,b)</code>.</p>"},{"location":"tutorial/basic_concepts/#traversing-graphs","title":"Traversing Graphs\u00b6","text":"<p>The <code>Graph</code> object provides <code>get_successors</code> and <code>get_predecessors</code> functions, which return the indices of nodes that are connected to a node with a given index. Based on cached CSR (compressed sparse row) and CSC (compressed sparse column) representations cached for the sorted <code>EdgeIndex</code>, access to the successors and predecessors of a node works in constant time, i.e. it does not require to enumerate the <code>edge_index</code> tensor.</p> <p>For node <code>a</code> with index $0$ in our directed network we obtain:</p>"},{"location":"tutorial/basic_concepts/#node-edge-or-graph-level-attributes","title":"Node-, Edge- or Graph-Level Attributes\u00b6","text":"<p>Real-world graphs often have node-, edge-, or graph-level attributes. In <code>pathpyG</code>, we can add attributes as tensors, either by directly assigning them to the <code>pyG</code> data object of an existing graph (or by adding them to the <code>Data</code> object passed to the constructor). Following the <code>pyG</code> semantics of attribute names, we use the prefixes <code>node_</code> and <code>edge_</code> to refer to node- and edge-level attributes. Attributes without those prefixes are assumed to refer to graph-level attributes.</p>"},{"location":"tutorial/basic_concepts/#reading-and-writing-graph-data","title":"Reading and writing graph data\u00b6","text":""},{"location":"tutorial/basic_concepts/#networkx-delegate-mechanism","title":"<code>networkx</code> Delegate Mechanism\u00b6","text":"<p>To calculate node centralities, we can use a <code>networkx</code> delegate mechanism implemented in the module <code>pathpyG.algorithms.centrality</code>. Simply speaking, you can call any function implented in the <code>networkx.centrality</code> module whose name ends with <code>_centrality</code>. The <code>pathpyG</code> graph object will be internally converted to a <code>networkx.DiGraph</code> object, the corresponding centrality function (with all of its parameters) will be called, and the result will be mapped back to nodes based on node IDs.</p> <p>In order to calculate the closeness centralities of all nodes for the graph above, we can call:</p>"},{"location":"tutorial/basic_concepts/#probability-generating-functions-for-degree-distributions","title":"Probability Generating functions for degree distributions\u00b6","text":""},{"location":"tutorial/dbgnn/","title":"Causality-Aware GNNs","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n!pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy as sp\n\nimport torch\nfrom torch_geometric.transforms import RandomNodeSplit\n\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.manifold import TSNE\n\nimport pathpyG as pp\nfrom pathpyG.nn.dbgnn import DBGNN\n\npp.config['torch']['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice = pp.config['torch']['device']\n</pre> import numpy as np import matplotlib.pyplot as plt import scipy as sp  import torch from torch_geometric.transforms import RandomNodeSplit  from sklearn.metrics import balanced_accuracy_score from sklearn.manifold import TSNE  import pathpyG as pp from pathpyG.nn.dbgnn import DBGNN  pp.config['torch']['device'] = 'cuda' if torch.cuda.is_available() else 'cpu' device = pp.config['torch']['device'] In\u00a0[2]: Copied! <pre>t = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False)\n</pre> t = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False) <p>This example has created in such a way that the nodes naturally form three clusters, which are highlighted in the interactive visualization below:</p> In\u00a0[3]: Copied! <pre>style = {}\nstyle['node_color'] = ['green']*10+['red']*10+['blue']*10\npp.plot(t, **style, edge_size=4, edge_color='gray');\n</pre> style = {} style['node_color'] = ['green']*10+['red']*10+['blue']*10 pp.plot(t, **style, edge_size=4, edge_color='gray'); In\u00a0[4]: Copied! <pre>pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray');\n</pre> pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray'); <p>In fact, the topology of this graph corresponds to that of a random graph, i.e. there are not patterns whatsoever in the topology of links. Nevertheless, the temporal graph contains a cluster pattern in the topology of causal or time-respecting paths. In particular, the temporal ordering of time-stamped edges is such that nodes with the same cluster label are more frequently connected by time-respecting paths than nodes with different cluster labels. Hence, nodes within the same clusters can more strongly influence each other in a causal way, i.e. via multiple interactions that follow the arrow of time.</p> <p>Traditional (temporal) graph neural networks will not be able to learn from this pattern, as it is due to the specific microscopic temporal ordering of edges. Using higher-order De Bruijn graph models implemented in pathpyG, we can learn from temporal graph data that contains such patterns. Let us explain this step by step.</p> <p>Referring to the previous tutorial on causal paths in temporal graphs, we first create a node-time directed acyclic graph that captures the causal structure of the temporal graph. In this small example, we will only consider two time-stamped edges $(u,v;t)$ and $(v,w;t')$ to contribute to a causal path iff $0 &lt; t'-t \\leq 1$, i.e. we use a delta for the maximum time difference of one time step.</p> In\u00a0[6]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2)\nprint(m)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2) print(m) <pre>  0%|          | 0/60000 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [00:54&lt;00:00, 1094.30it/s]\n</pre> <pre>MultiOrderModel with max. order 2\n</pre> <p>We can get the first and second order networks from the Multi Order Network object. The first order network is the network of nodes and edges, while the second order network is the network of first order edges as second order nodes and second order edges. The second order network is a De Bruijn graph that captures the temporal-topological patterns in the data.</p> In\u00a0[7]: Copied! <pre>g = m.layers[1]\ng2 = m.layers[2]\n</pre> g = m.layers[1] g2 = m.layers[2] In\u00a0[8]: Copied! <pre>pp.plot(g, edge_size=2);\n</pre> pp.plot(g, edge_size=2); <p>Since it does not consider patterns in the causal topology of the temporal graph, this is not a meaningful model. We can instead use a second-order De Bruijn graph model, which we can easily fit to the paths:</p> In\u00a0[9]: Copied! <pre>layout_style = {}\nlayout_style['layout'] = 'Fruchterman-Reingold'\nlayout_style['seed'] = 1\nlayout_style['force'] = 0.5\nlayout_style['iterations'] = 300\nlayout = pp.layout(g2, **layout_style)\npp.plot(g2, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib',layout=layout);\n</pre> layout_style = {} layout_style['layout'] = 'Fruchterman-Reingold' layout_style['seed'] = 1 layout_style['force'] = 0.5 layout_style['iterations'] = 300 layout = pp.layout(g2, **layout_style) pp.plot(g2, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib',layout=layout); <p>In this graph, every node is a link and links correspond to causal paths of length two, i.e. temporally ordered sequences consisting of two edges that overlap in the center node. In this graph, we clearly see a cluster pattern that is due to the way in which temporal edges are ordered in time. In particular, we see three clusters, where the edges in three of the clusters correspond to causal paths of length two that connect nodes within each of the three clusters. The edges in the fourth cluster (in the center of the visualization) represent causal paths that connect nodes in different clusters.</p> In\u00a0[10]: Copied! <pre>t_shuffled = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False)\nt_shuffled.shuffle_time()\n</pre> t_shuffled = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False) t_shuffled.shuffle_time() In\u00a0[11]: Copied! <pre>g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2]\nprint(g2_shuffled)\n</pre> g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2] print(g2_shuffled) <pre>  0%|          | 47/60000 [00:00&lt;04:48, 207.71it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [00:48&lt;00:00, 1247.58it/s]\n</pre> <pre>Directed graph with 557 nodes and 7863 edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7863])\"},\n    'Graph Attributes': {'inverse_idx': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([120000])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {}}\n</pre> In\u00a0[12]: Copied! <pre>layout = pp.layout(g2_shuffled,**layout_style)\npp.plot(g2_shuffled, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib', layout=layout);\n</pre> layout = pp.layout(g2_shuffled,**layout_style) pp.plot(g2_shuffled, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib', layout=layout); <p>We now find that the cluster pattern in the second-order graph has vanished. In fact, there is no pattern whatsoever since the underlying (static) graph topology is random and the random shuffling of time stamps leads to random causal paths.</p> In\u00a0[13]: Copied! <pre>L = g2.laplacian(normalization='rw', edge_attr='edge_weight')\nL_shuffled= g2_shuffled.laplacian(normalization='rw',edge_attr='edge_weight')\n</pre> L = g2.laplacian(normalization='rw', edge_attr='edge_weight') L_shuffled= g2_shuffled.laplacian(normalization='rw',edge_attr='edge_weight') <p>We then calculate the eigenvalues and eigenvectors of the Laplacians, and compute the Fiedler vector, i.e. the eigenvector that corresponds to the second-smallest eigenvalue of the Laplacian.</p> In\u00a0[14]: Copied! <pre>w,v = sp.linalg.eig(L.todense(),left= False, right = True)\nw_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense())\n</pre> w,v = sp.linalg.eig(L.todense(),left= False, right = True) w_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense()) In\u00a0[15]: Copied! <pre>fiedler = v[:,np.argsort(w)[1]]\nfiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]]\n</pre> fiedler = v[:,np.argsort(w)[1]] fiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]] <p>Below, we show that the clusters in the causal topology of the temporal graph correspond to clusters in the distribution of entries in the Fiedler vector, while there is no such pattern for the Fiedler vector of the second-order graph constructed from the shuffled temporal graph:</p> In\u00a0[16]: Copied! <pre>c = []\na = []\nfor v in g2.nodes:\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c.append('green')\n        a.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c.append('red')\n        a.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c.append('blue')\n        a.append(1)\n    else:\n        c.append('black')\n        a.append(0.1)\n</pre> c = [] a = [] for v in g2.nodes:     if int(v[0])&lt;10 and int(v[1])&lt;10:         c.append('green')         a.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c.append('red')         a.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c.append('blue')         a.append(1)     else:         c.append('black')         a.append(0.1) In\u00a0[17]: Copied! <pre>c_shuffled = []\na_shuffled = []\nfor v in g2_shuffled.nodes: \n\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c_shuffled.append('green')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c_shuffled.append('red')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c_shuffled.append('blue')\n        a_shuffled.append(1)\n    else:\n        c_shuffled.append('black')\n        a_shuffled.append(0.1)\n</pre> c_shuffled = [] a_shuffled = [] for v in g2_shuffled.nodes:       if int(v[0])&lt;10 and int(v[1])&lt;10:         c_shuffled.append('green')         a_shuffled.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c_shuffled.append('red')         a_shuffled.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c_shuffled.append('blue')         a_shuffled.append(1)     else:         c_shuffled.append('black')         a_shuffled.append(0.1) <p>In the plots below, we have colored those entries of the Fiedler vectors that correspond to edges connecting nodes within one of the three clusters shown above. The Fiedler vector shows a clear pattern, which translates to the cluster pattern in the causal topology that we have planted into our synthetic temporal graph.</p> In\u00a0[18]: Copied! <pre>plt.ylim(-.2, .25)\nplt.scatter(range(g2.n), np.real(fiedler),c=c, alpha=a);\n</pre> plt.ylim(-.2, .25) plt.scatter(range(g2.n), np.real(fiedler),c=c, alpha=a); <p>No such pattern exists in the Fiedler vector of the second-order graph corresponding to the shuffled <code>TemporalGraph</code>.</p> In\u00a0[19]: Copied! <pre>plt.ylim(-.1, .1)\nplt.scatter(range(g2_shuffled.n), np.real(fiedler_shuffled), c=c_shuffled, alpha=a_shuffled);\n</pre> plt.ylim(-.1, .1) plt.scatter(range(g2_shuffled.n), np.real(fiedler_shuffled), c=c_shuffled, alpha=a_shuffled); <p>We now set up a <code>pytorch_geometric.Data</code> object that contains all of the information needed to train the DBGNN model. For this, we can use a convenience function of the <code>MultiOrderModel</code> class in <code>pathpyG</code>. Combining a first- and a second-order model, this uses the edge indices and the weight tensors for a message passing scheme. it further constructs an <code>edge_index</code> of a bipartite graph that uses the last node in a second-order node to map messages back to first-order nodes.</p> In\u00a0[20]: Copied! <pre>data = m.to_dbgnn_data(max_order=2, mapping='last')\ndata.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids])\n</pre> data = m.to_dbgnn_data(max_order=2, mapping='last') data.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids]) In\u00a0[21]: Copied! <pre>data = RandomNodeSplit(num_val=0, num_test=0.3)(data)\n\nmodel = DBGNN(\n        num_features =[g.n, g2.n],\n        num_classes = len(data.y.unique()),\n        hidden_dims = [16, 32, 8],\n        p_dropout = 0.4\n        ).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(),  lr=0.005)\nloss_function = torch.nn.CrossEntropyLoss()\n\ndata = data.to(device)\n</pre> data = RandomNodeSplit(num_val=0, num_test=0.3)(data)  model = DBGNN(         num_features =[g.n, g2.n],         num_classes = len(data.y.unique()),         hidden_dims = [16, 32, 8],         p_dropout = 0.4         ).to(device)  optimizer = torch.optim.Adam(model.parameters(),  lr=0.005) loss_function = torch.nn.CrossEntropyLoss()  data = data.to(device) <p>The following function evaluates the prediction of our model based on the balanced accuracy score for categorical predictions.</p> In\u00a0[22]: Copied! <pre>def test(model, data):\n    model.eval()\n\n    _, pred = model(data).max(dim=1)\n\n    metrics_train = balanced_accuracy_score(\n        data.y[data.train_mask].cpu(),\n        pred[data.train_mask].cpu().numpy()\n        )\n\n    metrics_test = balanced_accuracy_score(\n        data.y[data.test_mask].cpu(),\n        pred[data.test_mask].cpu().numpy()\n        )\n\n    return metrics_train, metrics_test\n</pre> def test(model, data):     model.eval()      _, pred = model(data).max(dim=1)      metrics_train = balanced_accuracy_score(         data.y[data.train_mask].cpu(),         pred[data.train_mask].cpu().numpy()         )      metrics_test = balanced_accuracy_score(         data.y[data.test_mask].cpu(),         pred[data.test_mask].cpu().numpy()         )      return metrics_train, metrics_test In\u00a0[23]: Copied! <pre>losses = []\nfor epoch in range(100):\n        output = model(data)\n        loss = loss_function(output[data.train_mask], data.y[data.train_mask])\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        losses.append(loss)\n\n        if epoch % 10 == 0:\n                train_ba, test_ba = test(model, data)\n                print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}')\n</pre> losses = [] for epoch in range(100):         output = model(data)         loss = loss_function(output[data.train_mask], data.y[data.train_mask])         loss.backward()         optimizer.step()         optimizer.zero_grad()         losses.append(loss)          if epoch % 10 == 0:                 train_ba, test_ba = test(model, data)                 print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}') <pre>Epoch: 0, Loss: 1.396331548690796, Train balanced accuracy: 0.3333333333333333, Test balanced accuracy: 0.4444444444444444\nEpoch: 10, Loss: 1.0314276218414307, Train balanced accuracy: 0.625, Test balanced accuracy: 0.6666666666666666\nEpoch: 20, Loss: 0.6930890083312988, Train balanced accuracy: 0.8333333333333334, Test balanced accuracy: 0.8333333333333334\nEpoch: 30, Loss: 0.18330739438533783, Train balanced accuracy: 0.9444444444444445, Test balanced accuracy: 1.0\nEpoch: 40, Loss: 0.012356579303741455, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 50, Loss: 0.0006831764476373792, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 60, Loss: 0.00017408060375601053, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 70, Loss: 0.0001001721466309391, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 80, Loss: 7.844543870305642e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 90, Loss: 7.0568872615695e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\n</pre> In\u00a0[24]: Copied! <pre>model.eval()\nlatent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach()\nlatent = model.higher_order_layers[1].forward(latent, data.edge_index_higher_order).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())\n\ncolors = []\nfor v, w in g2.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g2.edges:\n    src = g2.mapping.to_idx(e[0])\n    tgt = g2.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach() latent = model.higher_order_layers[1].forward(latent, data.edge_index_higher_order).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())  colors = [] for v, w in g2.nodes:     if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g2.edges:     src = g2.mapping.to_idx(e[0])     tgt = g2.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show() <p>We can further generate latent space representations of the nodes generated by the last bipartite layer of our architecture:</p> In\u00a0[25]: Copied! <pre>model.eval()\nlatent = model.forward(data).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())\n\ncolors = []\nfor v in g.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g.edges:\n    src = g.mapping.to_idx(e[0])\n    tgt = g.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.forward(data).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())  colors = [] for v in g.nodes:     if data.y[g.mapping.to_idx(v)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g.edges:     src = g.mapping.to_idx(e[0])     tgt = g.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show()"},{"location":"tutorial/dbgnn/#causality-aware-graph-neural-networks","title":"Causality-Aware Graph Neural Networks\u00b6","text":""},{"location":"tutorial/dbgnn/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/dbgnn/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In previous tutorials, we have introduced causal paths in temporal graphs, and how we can use them to generate higher-order De Bruijn graph models that capture temporal-topological patterns in time series data. In this tutorial, we will show how we can use De Bruijn Graph Neural Networks, a causality-aware deep learning architecture for temporal graph data. The details of this approach are introduced in this paper. The architecture is implemented in pathpyG and can be readily applied to temporal graph data.</p> <p>Below we illustrate this mthod in a supervised node classification task, i.e. given a temporal graph we will use the temporal-topological patterns in the graph to classify nodes.</p> <p>We start by importing a few modules:</p>"},{"location":"tutorial/dbgnn/#temporal-topological-clusters-in-temporal-graphs","title":"Temporal-Topological Clusters in Temporal Graphs\u00b6","text":"<p>Let us load a small synthetic toy example for a temporal graph with 60.000 time-stamped interactions between 30 nodes. We use the <code>TemporalGraph</code> class to load this example from a file containing edges with discrete time-stamps.</p>"},{"location":"tutorial/dbgnn/#modelling-causal-structures-with-higher-order-de-bruijn-graphs","title":"Modelling Causal Structures with Higher-Order De Bruijn Graphs\u00b6","text":"<p>But what is the origin for the cluster pattern? In the visualization above, you will notice that the time-stamped edges randomly interconnect nodes within and across clusters, actually there is no correlation whatsoever between the topology of links and the cluster membership of the nodes. Hence, the notion of clusters does not correspond to the common idea of cluster patterns in static graphs, which we can highlight further by plotting the static time-aggregated network:</p>"},{"location":"tutorial/dbgnn/#comparison-to-temporal-graph-with-shuffled-time-stamps","title":"Comparison to Temporal Graph with Shuffled Time Stamps\u00b6","text":"<p>You may wonder whether this pattern is really due to the temporal ordering of time-stamped edges. It is easy to check this. We can simply randomly shuffle the time stamps of all edges, which will break any correlations in the temporal ordering that lead to patterns in the causal topology.</p> <p>We repeat the path calculation for this shuffled temporal graph and construct the second-order De Bruijn Graph model again:</p>"},{"location":"tutorial/dbgnn/#spectral-clustering-with-second-order-graph-laplacian","title":"Spectral clustering with second-order graph Laplacian\u00b6","text":"<p>To take a different perspective on cluster patterns, we can actually use <code>pathpyG</code> to apply a spectral analysis to the higher-order graph. We can simply calculate a generalization of the Laplacian matrix to the second-order graph both for the actual temporal graph and its shuffled counterpart:</p>"},{"location":"tutorial/dbgnn/#node-classification-with-causality-aware-graph-neural-networks","title":"Node Classification with Causality-Aware Graph Neural Networks\u00b6","text":"<p>Let us now explore how we can develop a causality-aware deep graph learning architecture that utilizes this pattern in the causal topology. We will follow the architecture introduced in this work. The architecture actually performs message passing in higher-order models with multiple orders at once. In a final message passing step, a bipartite graph is used to obtain vector-space representations of actual nodes in the temporal graph.</p>"},{"location":"tutorial/dbgnn/#training-the-model","title":"Training the model\u00b6","text":"<p>We are now ready to train and evaluate our causality-aware graph neural network. We will frist create a random split of the nodes, set the optimizer and the hyperparameters of our model.</p>"},{"location":"tutorial/dbgnn/#causality-aware-latent-space-representation-of-nodes","title":"Causality-aware latent space representation of nodes\u00b6","text":"<p>We can inspect the model by plotting a latent space representation of the edges generated by the second-order layer of our architecture.</p>"},{"location":"tutorial/netzschleuder/","title":"Graph Learning in Netzschleuder Data","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.decomposition import TruncatedSVD\n\nimport torch\nfrom torch.nn import Linear, ReLU, Sigmoid, Parameter\n\nimport torch_geometric\nfrom torch_geometric.nn import Sequential, GCNConv, SimpleConv, MessagePassing\n\nimport pathpyG as pp\n\npp.config['torch']['device'] = 'cpu'\n# pp.config['torch']['device'] = 'cuda'\n</pre> import numpy as np from matplotlib import pyplot as plt  from sklearn import metrics from sklearn.decomposition import TruncatedSVD  import torch from torch.nn import Linear, ReLU, Sigmoid, Parameter  import torch_geometric from torch_geometric.nn import Sequential, GCNConv, SimpleConv, MessagePassing  import pathpyG as pp  pp.config['torch']['device'] = 'cpu' # pp.config['torch']['device'] = 'cuda' In\u00a0[4]: Copied! <pre>g = pp.io.read_netzschleuder_graph('polbooks')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_graph('polbooks') print(g) <pre>Mapping node attributes based on node indices in column `index`\nUndirected graph with 105 nodes and 882 (directed) edges\n{   'Edge Attributes': {},\n    'Graph Attributes': {   'analyses_average_degree': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_assortativity': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_std_dev': \"&lt;class 'float'&gt;\",\n                            'analyses_diameter': \"&lt;class 'int'&gt;\",\n                            'analyses_edge_properties': \"&lt;class 'list'&gt;\",\n                            'analyses_edge_reciprocity': \"&lt;class 'float'&gt;\",\n                            'analyses_global_clustering': \"&lt;class 'float'&gt;\",\n                            'analyses_hashimoto_radius': \"&lt;class 'float'&gt;\",\n                            'analyses_is_bipartite': \"&lt;class 'bool'&gt;\",\n                            'analyses_is_directed': \"&lt;class 'bool'&gt;\",\n                            'analyses_knn_proj_1': \"&lt;class 'float'&gt;\",\n                            'analyses_knn_proj_2': \"&lt;class 'float'&gt;\",\n                            'analyses_largest_component_fraction': \"&lt;class 'float'&gt;\",\n                            'analyses_mixing_time': \"&lt;class 'float'&gt;\",\n                            'analyses_num_edges': \"&lt;class 'int'&gt;\",\n                            'analyses_num_vertices': \"&lt;class 'int'&gt;\",\n                            'analyses_transition_gap': \"&lt;class 'float'&gt;\",\n                            'analyses_vertex_properties': \"&lt;class 'list'&gt;\",\n                            'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {'node__pos': \"&lt;class 'numpy.ndarray'&gt;\", 'node_label': \"&lt;class 'numpy.ndarray'&gt;\", 'node_value': \"&lt;class 'numpy.ndarray'&gt;\"}}\n</pre> <p>We can plot this temporal graph in an interactive way:</p> In\u00a0[5]: Copied! <pre>pp.plot(g, edge_color='lightgray', edge_size=5);\n</pre> pp.plot(g, edge_color='lightgray', edge_size=5); <p>To see how we can apply GNNs to attributed graphs, let us read the famous karate club network. The record <code>karate</code> actually contains two networks with labels <code>77</code> and <code>78</code>, which refer to two different versions of the data with different numbers of edges. If multiple graph data sets exist in the same record, we can specify the name of the network as second argument.</p> In\u00a0[6]: Copied! <pre>g = pp.io.read_netzschleuder_graph('karate', '78')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_graph('karate', '78') print(g) <pre>Mapping node attributes based on node indices in column `index`\nUndirected graph with 34 nodes and 156 (directed) edges\n{   'Edge Attributes': {},\n    'Graph Attributes': {   'analyses_average_degree': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_assortativity': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_std_dev': \"&lt;class 'float'&gt;\",\n                            'analyses_diameter': \"&lt;class 'int'&gt;\",\n                            'analyses_edge_properties': \"&lt;class 'list'&gt;\",\n                            'analyses_edge_reciprocity': \"&lt;class 'float'&gt;\",\n                            'analyses_global_clustering': \"&lt;class 'float'&gt;\",\n                            'analyses_hashimoto_radius': \"&lt;class 'float'&gt;\",\n                            'analyses_is_bipartite': \"&lt;class 'bool'&gt;\",\n                            'analyses_is_directed': \"&lt;class 'bool'&gt;\",\n                            'analyses_knn_proj_1': \"&lt;class 'float'&gt;\",\n                            'analyses_knn_proj_2': \"&lt;class 'float'&gt;\",\n                            'analyses_largest_component_fraction': \"&lt;class 'float'&gt;\",\n                            'analyses_mixing_time': \"&lt;class 'float'&gt;\",\n                            'analyses_num_edges': \"&lt;class 'int'&gt;\",\n                            'analyses_num_vertices': \"&lt;class 'int'&gt;\",\n                            'analyses_transition_gap': \"&lt;class 'float'&gt;\",\n                            'analyses_vertex_properties': \"&lt;class 'list'&gt;\",\n                            'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {   'node__pos': \"&lt;class 'numpy.ndarray'&gt;\",\n                           'node_groups': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\",\n                           'node_name': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\"}}\n</pre> In\u00a0[7]: Copied! <pre>pp.plot(g, edge_color='gray');\n</pre> pp.plot(g, edge_color='gray'); <p>We see that the nodes actually have a <code>node_groups</code> property, which maps the nodes to two groups. Those groups are often used as <code>ground truth</code> for communities in this simple illustrative graph. We will instead use it as ground truth categorical node label for a node classification experiment based on a Graph Neural Network.</p> <p>Conveniently, numerical node attributes (either scalar or vector values) are automatically converted to torch tensors, so we can directly use them for a GNN.</p> In\u00a0[8]: Copied! <pre>print(g['node_groups'])\n</pre> print(g['node_groups']) <pre>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n</pre> <p>For convenience, let us shift the group labels to binary values 0 and 1:</p> In\u00a0[9]: Copied! <pre>g['node_groups'] -= 1\nprint(g['node_groups'])\n</pre> g['node_groups'] -= 1 print(g['node_groups']) <pre>tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n</pre> <p>We can plot categorical labels by passing node colors in the plot function.</p> In\u00a0[10]: Copied! <pre>pp.plot(g, node_color = [g['node_groups',v].item() for v in g.nodes])\n</pre> pp.plot(g, node_color = [g['node_groups',v].item() for v in g.nodes]) Out[10]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f8b38110ee0&gt;</pre> <p>For convenience, let us shift the group labels to binary values 0 and 1:</p> In\u00a0[9]: Copied! <pre>color_map = {0: 'red', 1: 'blue'}\ncolors = [ color_map[g['node_groups',v].item()] for v in g.nodes ]\npp.plot(g, node_color = colors);\n</pre> color_map = {0: 'red', 1: 'blue'} colors = [ color_map[g['node_groups',v].item()] for v in g.nodes ] pp.plot(g, node_color = colors); <p>To simplify the application of deep learning models, we can retrieve a data object that contains the graph and its attributes:</p> In\u00a0[11]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 156], num_nodes=34, node_sequence=[34, 1], node_name=[34], node_groups=[34], node__pos=[34], analyses_average_degree=4.588235294117647, analyses_degree_assortativity=-0.47561309768461424, analyses_degree_std_dev=3.820360677912828, analyses_diameter=5, analyses_edge_properties=[0], analyses_edge_reciprocity=1.0, analyses_global_clustering=0.2556818181818182, analyses_hashimoto_radius=5.292780644548693, analyses_is_bipartite=False, analyses_is_directed=False, analyses_knn_proj_1=3.6123615105719784, analyses_knn_proj_2=1.4566019942625823, analyses_largest_component_fraction=1.0, analyses_mixing_time=7.04834107126513, analyses_num_edges=78, analyses_num_vertices=34, analyses_transition_gap=0.8677276709836416, analyses_vertex_properties=[3])\n</pre> <p>Let's use a one-hot encoding of nodes as a simple additional node feature <code>x</code>, and let's use the node groups as target label <code>y</code>.</p> In\u00a0[12]: Copied! <pre>data = g.data\ng[\"node_feature\"] = torch.eye(g.n)\ndata['x'] = data['node_feature']\ndata['y'] = data['node_groups'].reshape(-1, 1).float()\n</pre> data = g.data g[\"node_feature\"] = torch.eye(g.n) data['x'] = data['node_feature'] data['y'] = data['node_groups'].reshape(-1, 1).float() <p>It is easy to define a Graph Convolutional Network that ues the one-hot-encodings of nodes and the topology to predict binary node labels:</p> In\u00a0[13]: Copied! <pre>model = Sequential('node_ohe, edge_index', [\n    (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),\n    ReLU(inplace=True),\n    (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),\n    Sigmoid(),\n])\nmodel.to(pp.config['torch']['device'])\n</pre> model = Sequential('node_ohe, edge_index', [     (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),     ReLU(inplace=True),     (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),     Sigmoid(), ]) model.to(pp.config['torch']['device']) Out[13]: <pre>Sequential(\n  (0) - GCNConv(34, 8): node_ohe, edge_index -&gt; hidden\n  (1) - ReLU(inplace=True): hidden -&gt; hidden\n  (2) - GCNConv(8, 1): hidden, edge_index -&gt; output\n  (3) - Sigmoid(): output -&gt; output\n)</pre> <p>We next apply a <code>RandomNodeSplit</code> transformation to split the nodes in a training and test set.</p> In\u00a0[14]: Copied! <pre>transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0)\ndata = transform(data)\n</pre> transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0) data = transform(data) <p>We then train our model for 1000 epochs on the training set.</p> In\u00a0[15]: Copied! <pre>epochs = 1000\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n    \nlosses = []\n\nmodel.train()\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)\n    loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n\n    losses.append(loss.cpu().detach().numpy())\n\nplt.plot(range(epochs), losses)\nplt.grid()\n</pre> epochs = 1000  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)      losses = []  model.train() for epoch in range(epochs):     optimizer.zero_grad()     out = model(data.x, data.edge_index)     loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])     loss.backward()     optimizer.step()      losses.append(loss.cpu().detach().numpy())  plt.plot(range(epochs), losses) plt.grid() <p>We evaluate the model in the test set and calculate the adjusted mutual information for the ground truth.</p> In\u00a0[16]: Copied! <pre>model.eval()\npredicted_groups = model(data.x, data.edge_index).round().long()\nmetrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy())\n</pre> model.eval() predicted_groups = model(data.x, data.edge_index).round().long() metrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy()) Out[16]: <pre>1.0</pre> <p>We visualize node representations learned by the model. The test nodes are colored, while training nodes are greyed out.</p> In\u00a0[17]: Copied! <pre># get activations in first-layer\nembedding = model[0].forward(data.x, data.edge_index)\n\n# dimensionality reduction\nsvd = TruncatedSVD()\nlow_dim = svd.fit_transform(embedding.cpu().detach().numpy())\n\n# plot with colors corresponding to groups in validation set\ncolors = {}\nfor v in range(g.n):\n    if not data.val_mask[v]:\n        colors[v] = 'grey'\n    else:\n        if data.y[v].item() == 0.0:\n            colors[v] = 'blue'\n        else:\n            colors[v] = 'orange'\n\nplt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values());\n</pre> # get activations in first-layer embedding = model[0].forward(data.x, data.edge_index)  # dimensionality reduction svd = TruncatedSVD() low_dim = svd.fit_transform(embedding.cpu().detach().numpy())  # plot with colors corresponding to groups in validation set colors = {} for v in range(g.n):     if not data.val_mask[v]:         colors[v] = 'grey'     else:         if data.y[v].item() == 0.0:             colors[v] = 'blue'         else:             colors[v] = 'orange'  plt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values()); <p>This simple code gives you thousands of networks with various meta information at your fingertips, to wich you can directly apply graph learning models provided in pyG, or deep graoh learning architectures defined by yourself.</p>"},{"location":"tutorial/netzschleuder/#learning-in-graphs-from-the-netzschleuder-repository","title":"Learning in Graphs from the Netzschleuder Repository\u00b6","text":""},{"location":"tutorial/netzschleuder/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/netzschleuder/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>Access to a large number of graphs with different topological characteristics and from different domains is crucial for the development and evaluation of graph learning methods. Tousands of graph data sets are available scattered throughout the web, possibly using different data formats and with missing information on their actual origin. Addressing this issue the Netschleuder Online Repository by Tiago Peixoto provides a single repository of graphs in a single format, including descriptions, citations, and node-/edge- or graph-level meta-data. To facilitate the development of graph learning techniques, pathpyG provides a feature that allows to directly read networks from the netzschleuder repository via an API.</p> <p>In this brief unit, we will learn how we can retrieve network records and graph data from the netzschleuder repository. We will further demonstrate how we can conveniently apply a Graph Neural Network to predict node-level categories contained in the meta-data.</p> <p>We first need to import a few modules.</p>"},{"location":"tutorial/netzschleuder/#reading-graphs-from-the-netzschleuder-repository","title":"Reading graphs from the netzschleuder repository\u00b6","text":"<p>In the <code>pathpy.io</code> module, there is a function that allows to read graph data from the API.</p> <p>We can read a given networks from the netzschleuder database using its record name. Just browse the Netschleuder Online Repository to find the record names. As an example, we use a graph capturing co-purchase relationships between political books.</p>"},{"location":"tutorial/netzschleuder/#applying-graph-neural-networks-to-netzschleuder-data","title":"Applying Graph Neural Networks to Netzschleuder Data\u00b6","text":""},{"location":"tutorial/paths_higher_order/","title":"Path Data and Higher-Order Models","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nimport pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\npp.config['torch']['device'] = 'cpu'\n</pre> import torch import pathpyG as pp from torch_geometric.data import Data from torch_geometric import EdgeIndex  pp.config['torch']['device'] = 'cpu' <p>For the following examples, we consider a simple directed graph with five nodes <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>, <code>e</code> and four edges:</p> In\u00a0[2]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\npp.plot(g, node_label=g.nodes, edge_color='gray');\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c', 'e')]) pp.plot(g, node_label=g.nodes, edge_color='gray'); In\u00a0[3]: Copied! <pre>paths = pp.PathData(g.mapping)\n\npaths.append_walk(('a', 'c', 'd'), weight=4.0)\npaths.append_walk(('b', 'c', 'e'), weight=4.0)\nprint(paths)\n</pre> paths = pp.PathData(g.mapping)  paths.append_walk(('a', 'c', 'd'), weight=4.0) paths.append_walk(('b', 'c', 'e'), weight=4.0) print(paths) <pre>PathData with 2 paths with total weight 8.0\n</pre> <p>Let us inspect how those walks are internally stored in the <code>PathData</code> object. We find that the class internally stores a <code>pyG.Data</code> object, which contains the properties <code>edge_index</code>, <code>node_sequence</code>, <code>dag_weight</code>, <code>dag_num_edges</code> and <code>dag_num_nodes</code> that can be used to access all of the individual paths.</p> In\u00a0[\u00a0]: Copied! <pre>paths.data\n</pre> paths.data <p>The <code>edge_index</code> tensor represents an ordered sequence of edges traversed by the walk, where the indices of nodes map to the <code>node_sequence</code> tensor. This additional mapping is neccessary since walks can traverse the same edge multiple times. Moreover, it allows to internally concatenate multiple walks into a single <code>Data</code> object, which is needed for fast GPU-based operations on path data. We can access the first path as follows:</p> In\u00a0[4]: Copied! <pre>paths.data.edge_index[:, :paths.data.dag_num_edges[0]]\n</pre> paths.data.edge_index[:, :paths.data.dag_num_edges[0]] Out[4]: <pre>tensor([[0, 1],\n        [1, 2]])</pre> <p>The <code>node_sequence</code> tensor tells us that the node with index <code>1</code> in the <code>edge_index</code> maps to the node in the graph with index <code>2</code>, which is node <code>c</code>.</p> In\u00a0[5]: Copied! <pre>paths.data.node_sequence[:paths.data.dag_num_nodes[0]]\n</pre> paths.data.node_sequence[:paths.data.dag_num_nodes[0]] Out[5]: <pre>tensor([[0],\n        [2],\n        [3]])</pre> <p>We can index the second edge index accordingly and can see that the <code>node_sequence</code> tensor maps to the sequence <code>b -&gt; c -&gt; e</code>:</p> In\u00a0[6]: Copied! <pre>paths.data.node_sequence[paths.data.edge_index[:, paths.data.dag_num_edges[0]:]]\n</pre> paths.data.node_sequence[paths.data.edge_index[:, paths.data.dag_num_edges[0]:]] Out[6]: <pre>tensor([[[1],\n         [2]],\n\n        [[2],\n         [4]]])</pre> <p>We can actually see a collection of walks as a higher-order generalization of the usual way to define graphs as a collection of dyadic edges (which are simply walks of length one). From this point of view, a standard static (weighted) graph is simply a first-order model of node sequences, which only considers the frequency at which edges are traversed.</p> <p>To generate such a first-order model, we can use the class <code>MultiOderModel</code> and use the first-layer of the model, which is simply a weighted static graph where edge weights count the number of times each edge is traversed by a path. We will explain the class <code>MultiOrderModel</code>, which generalizes this concept to higher-order graph models for any order $k$ in a moment. For now, we can just use it to generate a first-order weighted graph as follows.</p> <p>The generated graph is again based on a <code>pyG.Data</code> object that contains an edge_index and edge weights. As we can see, for the example above the edge_index is just a concatenation of the edge indices of individual walks, where the node indices have been mapped to the correct nodes.</p> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths, max_order=1)\ng = m.layers[1]\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\npp.plot(g, node_label=paths.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_PathData(paths, max_order=1) g = m.layers[1] print(g.data.edge_index) print(g.data.edge_weight) pp.plot(g, node_label=paths.mapping.node_ids.tolist()); <pre>EdgeIndex([[0, 1, 2, 2],\n           [2, 2, 3, 4]], sparse_size=(5, 5), nnz=4, sort_order=row)\ntensor([4., 4., 4., 4.])\n</pre> <p>Why are data on paths and walks interesting in the first place. The answer is that they provide information on the causal topology of complex systems, i.e. which nodes can possibly causally influence each other via paths that follow the arrow of time. This information is lost if we were to split paths into an (unordered) collection of dyadyic interactions between pairs of nodes, i.e. if we were to only onsider links.</p> <p>To illustrate this, let us assume that the four walks above tell us which paths information (or whatever you may be interested in) can take in the simple graph above. That is, we observe something moving from <code>a</code> via <code>c</code> to <code>d</code> and from <code>b</code> via <code>c</code> to <code>e</code>, and each of those events occur four times. However, we never observed that something moving from <code>a</code> to <code>c</code> ended up in <code>d</code>. And neither did we observe that something moving from <code>b</code> to <code>c</code> ended up in <code>e</code>. This means that - assuming that we completely observed all walks or paths - there is no way that <code>a</code> can causally influence <code>e</code> or that <code>b</code> could causally influence <code>d</code> via the center node <code>c</code>. Note that this is not what we would assume if we consider possible paths in the topology of the underlying graph, where paths of length two exist between all four pairs of nodes (<code>a</code>, <code>d</code>), (<code>a</code>, <code>e</code>), (<code>b</code>, <code>d</code>), (<code>b</code>, <code>e</code>).</p> <p>Hence, we can use data capturing actually observed paths or walks ion a network in contrast to which paths or walks would theoretically be possible based on the topology.</p> <p>As a contrast, consider the following observations of walks in the same graph.</p> In\u00a0[8]: Copied! <pre>paths_2 = pp.PathData(g.mapping)\n\npaths_2.append_walk(('a', 'c', 'd'), weight=2)\npaths_2.append_walk(('a', 'c', 'e'), weight=2)\npaths_2.append_walk(('b', 'c', 'd'), weight=2)\npaths_2.append_walk(('b', 'c', 'e'), weight=2)\nprint(paths_2)\n</pre> paths_2 = pp.PathData(g.mapping)  paths_2.append_walk(('a', 'c', 'd'), weight=2) paths_2.append_walk(('a', 'c', 'e'), weight=2) paths_2.append_walk(('b', 'c', 'd'), weight=2) paths_2.append_walk(('b', 'c', 'e'), weight=2) print(paths_2) <pre>PathData with 4 paths with total weight 8.0\n</pre> <p>Here we have observed walks along all four possible paths of length two, each walk occurring only two times. Like in the example before, each edge was traversed exactly four times and thus the weighted edge index of a first-order graph model is identical to the one before:</p> In\u00a0[9]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths_2, max_order=1)\ng = m.layers[1]\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_PathData(paths_2, max_order=1) g = m.layers[1] print(g.data.edge_index) print(g.data.edge_weight) pp.plot(g, node_label=g.mapping.node_ids.tolist()); <pre>EdgeIndex([[0, 1, 2, 2],\n           [2, 2, 3, 4]], sparse_size=(5, 5), nnz=4, sort_order=row)\ntensor([4., 4., 4., 4.])\n</pre> <p>This is a first-order graph representation, as it only captures the (weighted) edges in the underlying path data, i.e. we could say that we only count the frequency of paths (or walks) of length one. This naturally gives rise to an <code>edge_index</code> tensor with shape $(2,m)$, where $m$ is the number of unique edges in the graph that are traversed by the paths.</p> In\u00a0[13]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths, max_order=2)\ng = m.layers[2]\npp.plot(g, node_label=g.nodes, edge_size=5);\n</pre> m = pp.MultiOrderModel.from_PathData(paths, max_order=2) g = m.layers[2] pp.plot(g, node_label=g.nodes, edge_size=5); <p>For $k=2$, we obtain a second-order De Bruijn graph where second-order nodes are first-order edges and second-order edges represent walks of length two in the original graph. Edge weights capture observation frequencies of those walks. In our example, we have two different walks of length two ($a$ -&gt; $c$ -&gt; $d$ and $b$ -&gt; $c$ -&gt; $e$), represented by two edges $(a-c, c-d)$ and $(b-c, c-e)$. Each of those walks appears four times so the weights of both edges are four.</p> In\u00a0[14]: Copied! <pre>print(g.mapping)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> print(g.mapping) print(g.data.edge_index) print(g.data.edge_weight) <pre>('a', 'c') -&gt; 0\n('b', 'c') -&gt; 1\n('c', 'd') -&gt; 2\n('c', 'e') -&gt; 3\n\nEdgeIndex([[0, 1],\n           [2, 3]], sparse_size=(4, 4), nnz=2, sort_order=row)\ntensor([4., 4.])\n</pre> <p>While this goes beyond the scope of this tutorial, thanks to the tensor-based representation of paths, the construction ofhigher-order De Bruijn graphs can be done based on efficient GPU operations, i.e. we can scale it up to large graphs.</p> <p>Let us have a closer look at our examples above. While the first-order edge indices of the two path objects <code>paths</code> and <code>paths_2</code> are the same, we find that the second-order edge indices are actually different. For <code>paths_2</code> we have four different paths of length two, each occurring twice. Hence, our second-order De Bruijn graph has four edges, each with weight two. These edges correspond to all possible paths of length two in the underlying graph.</p> In\u00a0[16]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths_2, max_order=2)\ng = m.layers[2]\npp.plot(g, node_label=g.nodes);\n</pre> m = pp.MultiOrderModel.from_PathData(paths_2, max_order=2) g = m.layers[2] pp.plot(g, node_label=g.nodes); In\u00a0[17]: Copied! <pre>print(g.mapping)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> print(g.mapping) print(g.data.edge_index) print(g.data.edge_weight) <pre>('a', 'c') -&gt; 0\n('b', 'c') -&gt; 1\n('c', 'd') -&gt; 2\n('c', 'e') -&gt; 3\n\nEdgeIndex([[0, 0, 1, 1],\n           [2, 3, 2, 3]], sparse_size=(4, 4), nnz=4, sort_order=row)\ntensor([2., 2., 2., 2.])\n</pre> <p>We thus find that the second-order De Bruijn graph representation of paths is sensitive to the differences in the causal topology, while a first-order graph is not. This is the basis to generalize network analysis and graph learning to causality-aware graph models for various kinds of time series data on graphs. In particular, as we shall see in more detail in a later tutorial, we can use paths to generate k-th order graphs that can be used to generalize Graph Neural Networks to higher-order De Bruijn Graphs.</p> <p>Note that all higher-order graphs are simply <code>Graph</code> objects, which means that we can iterate through the nodes of a higher-order graph just like for normal graphs. Node indices are automatically mapped, yielding tuples of first-order node identifiers.</p> In\u00a0[18]: Copied! <pre>for n in g.nodes:\n    print(n)\n</pre> for n in g.nodes:     print(n) <pre>('a', 'c')\n('b', 'c')\n('c', 'd')\n('c', 'e')\n</pre> <p>Edges are tuples with two elements, where each element is a k-th order node, i.e. a tuple of node IDs of length $k$. I.e. for a second-order model the edges are tuples of length two, each entry containing s tuple of length two.</p> In\u00a0[19]: Copied! <pre>for e in g.edges:\n    print(e)\n</pre> for e in g.edges:     print(e) <pre>(('a', 'c'), ('c', 'd'))\n(('a', 'c'), ('c', 'e'))\n(('b', 'c'), ('c', 'd'))\n(('b', 'c'), ('c', 'e'))\n</pre> <p>The weight attribute stores a tensor whose entries capture the frequencies of edges, i.e. the frequencies of paths of length $k$.</p> In\u00a0[20]: Copied! <pre>for e in g.edges:\n    print(e, g['edge_weight', e[0], e[1]].item())\n</pre> for e in g.edges:     print(e, g['edge_weight', e[0], e[1]].item()) <pre>(('a', 'c'), ('c', 'd')) 2.0\n(('a', 'c'), ('c', 'e')) 2.0\n(('b', 'c'), ('c', 'd')) 2.0\n(('b', 'c'), ('c', 'e')) 2.0\n</pre> <p>We can finally plot a higher-order De Bruijn graph in the same way as a first-order graph.</p> In\u00a0[22]: Copied! <pre>pp.plot(g, node_label=g.nodes, edge_color='gray');\n</pre> pp.plot(g, node_label=g.nodes, edge_color='gray'); <p>Let us compare this to a second-order graph model of the second path data set <code>paths_2</code> from above, which corresponds to a network where all possible paths of length two actually occur. Hence, different from the data in <code>paths</code>, all pairs of nodes in this graph can causally influence each other via paths of length two.</p> In\u00a0[23]: Copied! <pre>m1 = pp.MultiOrderModel.from_PathData(paths, max_order=2)\nprint(m1.estimate_order(paths, significance_threshold=0.01))\n</pre> m1 = pp.MultiOrderModel.from_PathData(paths, max_order=2) print(m1.estimate_order(paths, significance_threshold=0.01)) <pre>2\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/edge_index.py:784: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n  return torch.sparse_csr_tensor(\n</pre> <p>For <code>paths_2</code> where the observed paths are in line what we would expect based on the weighted edges in the first-order graph model, we correctly find that we do not need to consider a second-order model</p> In\u00a0[24]: Copied! <pre>m2 = pp.MultiOrderModel.from_PathData(paths_2, max_order=2)\nprint(m2.estimate_order(paths_2, significance_threshold=0.01))\n</pre> m2 = pp.MultiOrderModel.from_PathData(paths_2, max_order=2) print(m2.estimate_order(paths_2, significance_threshold=0.01)) <pre>1\n</pre> <p>Admittedly, the situation in the <code>paths</code> data is extreme insofar as two of the possible paths of lengths two have not been observed at all. We can also have more subtle deviations from the expectation based on the first-order graph model. Consider the following case, where two of the paths are observed more often than two other paths. Note that we have assigned the path frequencies such that again all edges are traversed with exactly the same frequencies, i.e. all edge weights are again equal in the first-order graph.</p> In\u00a0[25]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\npaths_3 = pp.PathData(g.mapping)\n\npaths_3.append_walk(('a', 'c', 'd'), weight=6.0)\npaths_3.append_walk(('a', 'c', 'e'), weight=2.0)\n\npaths_3.append_walk(('b', 'c', 'e'), weight=6.0)\npaths_3.append_walk(('b', 'c', 'd'), weight=2.0)\n\nm3 = pp.MultiOrderModel.from_PathData(paths_3, max_order=2)\nprint(m3.layers[1].data.edge_weight)\nprint(m3.estimate_order(paths_3, significance_threshold=0.01))\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c', 'e')]) paths_3 = pp.PathData(g.mapping)  paths_3.append_walk(('a', 'c', 'd'), weight=6.0) paths_3.append_walk(('a', 'c', 'e'), weight=2.0)  paths_3.append_walk(('b', 'c', 'e'), weight=6.0) paths_3.append_walk(('b', 'c', 'd'), weight=2.0)  m3 = pp.MultiOrderModel.from_PathData(paths_3, max_order=2) print(m3.layers[1].data.edge_weight) print(m3.estimate_order(paths_3, significance_threshold=0.01)) <pre>tensor([8., 8., 8., 8.])\n1\n</pre> <p>In this example, due to the relatively small number of observations, the deviations from the expected baseline are still not strong enough to detect the optimal order of two (at least not for a significance threshold of $0.01$). We would need to raise the signififance threshold to $0.15$ to detect order two:</p> In\u00a0[26]: Copied! <pre>print(m3.estimate_order(paths_3, significance_threshold=0.15))\n</pre> print(m3.estimate_order(paths_3, significance_threshold=0.15)) <pre>2\n</pre> <p>Alternatively, we are able to detect a significant deviation from a first-order model for a significance threshold of $0.01$ if we make the deviations more extreme. If we observe two fo the paths seven times, while the other two are only observed once we find that order two is significant at a sigificance threshold of $0.01$.</p> In\u00a0[27]: Copied! <pre>paths_3 = pp.PathData(g.mapping)\n\npaths_3.append_walk(('a', 'c', 'd'), weight=7.0)\npaths_3.append_walk(('a', 'c', 'e'), weight=1.0)\n\npaths_3.append_walk(('b', 'c', 'e'), weight=7.0)\npaths_3.append_walk(('b', 'c', 'd'), weight=1.0)\n\nm3 = pp.MultiOrderModel.from_PathData(paths_3, max_order=2)\nprint(m3.layers[1].data.edge_weight)\nprint(m3.estimate_order(paths_3, significance_threshold=0.01))\n</pre> paths_3 = pp.PathData(g.mapping)  paths_3.append_walk(('a', 'c', 'd'), weight=7.0) paths_3.append_walk(('a', 'c', 'e'), weight=1.0)  paths_3.append_walk(('b', 'c', 'e'), weight=7.0) paths_3.append_walk(('b', 'c', 'd'), weight=1.0)  m3 = pp.MultiOrderModel.from_PathData(paths_3, max_order=2) print(m3.layers[1].data.edge_weight) print(m3.estimate_order(paths_3, significance_threshold=0.01)) <pre>tensor([8., 8., 8., 8.])\n2\n</pre> <p>The ability to detect the optimal higher-order for a given data set in a statistically principled way is a powerful feature of the modelling framework of higher-order De Bruijn Graphs. Admittedly, the likelihood-based model selection approach has its limitations especially for small data sets or partially observed graphs, where it can both over- or underfit. To address this, we have developed an alternative Bayesian model selection technique that is explained and evaluated in the following paper:</p> <p>L Petrovic, I Scholtes: Learning the Markov order of paths, In Proc. of the ACM Web Conference (WWW'22), April 2022</p> <p>Unfortunately, this method has not yet been implemented in <code>pathpyG</code> but we are planning to add it soon.</p> In\u00a0[28]: Copied! <pre>paths_tube = pp.PathData.from_ngram('../data/tube_paths_train.ngram', sep=',', weight=True)\n</pre> paths_tube = pp.PathData.from_ngram('../data/tube_paths_train.ngram', sep=',', weight=True) <p>To plot a (first-order) graph representation of the London Tube metro network, we can use the following code:</p> In\u00a0[29]: Copied! <pre>m = pp.MultiOrderModel.from_PathData(paths_tube, max_order=1)\ng = m.layers[1]\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_PathData(paths_tube, max_order=1) g = m.layers[1] pp.plot(g, node_label=g.mapping.node_ids.tolist()); <p>In general, the maximum size of a higher-order model could grow exponentially with the number of nodes in the underlying graph. However, for msot empirical data sets, higher-order models are actually sparse, which allows us to efficiently construct them using GPU-based operations. We demonstrate this in the London Tube data sets by constructing all higher-order De Bruijn graph models up to order 20, which takes approx. 25 seconds on a mobile GPU (RTX A2000) and yields reasonably sized higher-order models.</p> In\u00a0[30]: Copied! <pre>pp.config['torch']['device'] = 'cuda'\npaths_tube = pp.PathData.from_ngram('../data/tube_paths_train.ngram', sep=',', weight=True)\nm = pp.MultiOrderModel.from_PathData(paths_tube, max_order=20)\nprint(m.layers[20])\n</pre> pp.config['torch']['device'] = 'cuda' paths_tube = pp.PathData.from_ngram('../data/tube_paths_train.ngram', sep=',', weight=True) m = pp.MultiOrderModel.from_PathData(paths_tube, max_order=20) print(m.layers[20]) <pre>Directed graph with 5634 nodes and 4729 edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4729])\"},\n    'Graph Attributes': {'inverse_idx': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([18950])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {}}\n</pre> <p>As we shall see in the following two units, the <code>MultiOrderGraph</code> class is also the basis for the GPU-based analysis and modelling of causal structures in temporal graphs. In particular, the underlying generalization of first-order static graph models to higher-order De Bruijn graphs allows us to easily build causality-aware graph neural network architectures that consider both the topology and the temoral ordering of time-stamped edges in a temporal graph. We will</p>"},{"location":"tutorial/paths_higher_order/#path-data-and-higher-order-de-bruijn-graphs","title":"Path Data and Higher-Order De Bruijn Graphs\u00b6","text":""},{"location":"tutorial/paths_higher_order/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/paths_higher_order/#motivation-and-learning-objective","title":"Motivation and Learning Objective\u00b6","text":"<p>While <code>pathpyG</code> is useful to handle and visualize static graphs - as the name suggests - its main advantage is that it facilitates the analysis of time series data that can be used to calculate paths in a graph. As we shall see in the following tutorial, there are various situations in which naturally have access to data on paths, including data on (random) walks or trajectories, traces of dynamical processes giving rise to node sequences or directed acyclic graphs, or time-respecting paths in temporal graphs. ``pathpyG` can be used to model patterns in such data based on higher-order De Bruijn graph models.</p> <p>In this first unit, we will show how <code>pathpyG</code> supports to represent data on paths in graphs. Lile graphs, such data are internally stored as tensors, which facilitates GPU-based operations to create higher-order De Bruijn graphs.</p> <p>We first import the modules <code>torch</code> and <code>pathpyG</code>. By setting the device used by <code>torch</code>, we can specify whether we want to run our code on the CPU or on the GPU.</p>"},{"location":"tutorial/paths_higher_order/#using-pathdata-to-store-walks-or-paths-in-a-graph","title":"Using <code>PathData</code> to store walks or paths in a graph\u00b6","text":"<p>Assume that we have time series data that captures observations of trajectories (i.e. walks or paths) in the graph above. For example, we could observe four walks of length two, four each of the following:</p> <ul> <li>4 x <code>a</code> -&gt; <code>c</code> -&gt; <code>d</code></li> <li>4 x <code>b</code> -&gt; <code>c</code> -&gt; <code>e</code></li> </ul> <p>Note that we define the length of a walk or path as the number of edges that are traversed, i.e. a sequence that consists of a single node, e.g. <code>a</code>, is considered a walk of length zero, while every edge in a graph is a walk of length one.</p> <p><code>pp.PathData</code> supports to store and model such sequential data. We first create an instance of the <code>PathData</code> class. To consistently map node IDs to indices across <code>Graph</code> and <code>PathData</code> objects, we can pass the <code>IndexMap</code> object from the <code>Graph</code> above in the constructor. We then use the <code>append_walk</code> function to add observations of our two walks, where the <code>weight</code> argument is used to indicate the number of times each path or walk has been observed.</p>"},{"location":"tutorial/paths_higher_order/#from-graphs-to-higher-order-de-bruijn-graph-models","title":"From Graphs to Higher-Order De Bruijn Graph Models\u00b6","text":"<p>As we have seen above, the use of a first-order graph model discards information in path data, which capture which nodes can possibly causally influence each other via paths. A key feature of <code>pathpyG</code> is it allows to generalize this first-order modelling perspective to $k$-th order De Bruijn graph models for paths, where the nodes in a $k$-th order De Bruijn graph model are sequences of $k$ nodes. Edges connect pairs of nodes that overlap in $k-1$ nodes and capture paths of length $k$.</p> <p>A De Bruijn graph of order $k=1$ is simply a normal (weighted) static graph consisting of nodes and edges. Pairs of nodes connected by edges overlap in $k-1=0$ nodes and capture paths of length $k=1$, i.e. simple dyadic edges in the underlying path data.</p> <p>For a De Bruijn graph with order $k=2$, in our example above, an edge connects a pair of nodes $(a,b)$ and $(b,c)$ that overlaps in the $k-1=1$ node $b$. Such an edge represents the path $a -&gt; b -&gt; c$ of length two. We can use the <code>MultiOderModel</code> class to generate a second-order De Bruijn graph representation of the path data above. We just have to set the <code>max_order</code> parameter to two and use the second layer of the resulting <code>MultiOrderModel</code> instance.</p>"},{"location":"tutorial/paths_higher_order/#detecting-the-optimal-order-of-higher-order-de-bruijn-graph-models","title":"Detecting the Optimal Order of Higher-Order De Bruijn Graph Models\u00b6","text":"<p>The fact that we can model the same set of paths with higher-order De Bruijn graph models with different orders $k$ raises an important question: What is the optimal order to model a given <code>PathData</code> instance. It is actually easy to answer this question in our example above.</p> <p>For the data contained in <code>paths</code>, we observe only two of the four possible paths, which is different from what we would expect based on a first-order graph model. To capture this pattern in the node sequenves, a first-order graph model is not sufficient and we need a second-order De Bruoijn graph model.</p> <p>For <code>paths_2</code> this is different: Here we observe all four paths of length two with the same frequency, which is exactly what we would expect based on the first-order weighted graph, where all edge weights are the same. Hence, for <code>paths_2</code> the second-order De Bruijn graph model contains no additional information compared to a first-order weighted graph, which means a first-order model is sufficient.</p> <p>While it is easy to see this in the toy example, for real data we need a principled method to automatically determine the optimal order of a higher-order De Bruijn graph model. Luckily, this can be achieved based on statistical model selection in a multi-order De Bruijn graph model. Here we cannot explain the details of this method, so we kindly refer you to the following paper:</p> <p>I Scholtes: When is a Network a Network?: Multi-Order Graphical Model Selection in Pathways and Temporal Networks, In Proc. of SIGKDD 2017, August 2017</p> <p>The method introduced in this paper is implemented in <code>pathpyG</code>. To determine the optimal order of a higher-order De Bruijn graph model for the node sequences contained in a given <code>PathData</code> instance, we can use the <code>MultiOderModel.estimate_order</code> method. Since the method is based on statistical hypothesis testing, we can also pass a significance threshold, which - in line with the interpretation of p-values - bounds the type I error rate of our test, i.e. the rate at which we wrongly reject the null hypothesis that the true optimal order of a data set is $k-1$ in favor of the alternative hypothesis that the order is $k$.</p> <p>Let us test this for our toy example. Using a significance threshold of $0.01$, we determine the optimal order for the data set <code>paths</code> that should actually warrant a second-order model:</p>"},{"location":"tutorial/paths_higher_order/#loading-empirical-path-data-from-n-gram-files","title":"Loading empirical path data from N-Gram Files\u00b6","text":"<p>For real data on walks in graphs it is not convenient to manually construct and add walks based on edge tensors. We can instead use the <code>from_ngram</code> function of class <code>PathData</code> to load such data from an n-gram file, i.e. a text file where each line corresponds to one observed walk consisting of comma-separated node IDs. If we set the argument <code>weight=True</code>, the last component of each line is considered to be the observation frequency of that particular walk.</p> <p>As an example, the file <code>data/tube_paths_train.ngram</code> contains observed passenger itineraries between nodes in a graph that representes the network of London Tube stations. Each of those itineraries is associated with an observation frequencies. The following is an excerpt from that file:</p> <pre><code>Southwark,Waterloo,212.0\nLiverpool Street,Bank / Monument,1271.0\nBarking,West Ham,283.0\nTufnell Park,Kentish Town,103.0\n...\n</code></pre> <p>Note that this will automatically create an internal mapping of node IDs to indices.</p>"},{"location":"tutorial/temporal_betweenness/","title":"Temporal betweenness","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\nimport torch\n\nfrom collections import deque\n\nfrom scipy.sparse.csgraph import bellman_ford, dijkstra\nimport numpy as np\nfrom time import time\nfrom collections import defaultdict\n\n\nfrom tqdm import tqdm\n\nfrom pathpyG.utils import to_numpy\n</pre> import pathpyG as pp from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index import torch  from collections import deque  from scipy.sparse.csgraph import bellman_ford, dijkstra import numpy as np from time import time from collections import defaultdict   from tqdm import tqdm  from pathpyG.utils import to_numpy In\u00a0[2]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('../data/sociopatterns_highschool_2013_train.tedges')\nprint(t_sp)\nprint(torch.unique(t_sp.data.t).size(0))\n</pre> t_sp = pp.TemporalGraph.from_csv('../data/sociopatterns_highschool_2013_train.tedges') print(t_sp) print(torch.unique(t_sp.data.t).size(0)) <pre>Temporal Graph with 327 nodes, 8950 unique edges and 220378 events in [1385982080.0, 1386163840.0]\n\nGraph attributes\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\n579\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[3]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=3600, max_order=2)\nprint(m)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=3600, max_order=2) print(m) <pre>MultiOrderModel with max. order 2\n</pre> In\u00a0[4]: Copied! <pre>t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges')\nprint(t_ants)\n</pre> t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges') print(t_ants) <pre>Temporal Graph with 68 nodes, 506 unique edges and 1045 events in [899.0, 1796.0]\n\nGraph attributes\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=10)\nprint(m)\nprint(m.layers[1].data.edge_weight)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=10) print(m) print(m.layers[1].data.edge_weight) <pre>MultiOrderModel with max. order 10\ntensor([ 2.,  1.,  1.,  3.,  3.,  1.,  2.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,\n         1.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,  1.,  5.,  2.,  6.,  6.,  1.,\n         1.,  3.,  3.,  1.,  1.,  3.,  1.,  2.,  9.,  3.,  1.,  1.,  4.,  1.,\n         1.,  1.,  4.,  2.,  3.,  2.,  1.,  4.,  3.,  2.,  4.,  1.,  1.,  3.,\n         1.,  2.,  3.,  1.,  1.,  4.,  2.,  9.,  5.,  1.,  2.,  4.,  1.,  2.,\n         1.,  1.,  1.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  1.,  3.,  4.,  4.,\n         3.,  4.,  3.,  1.,  2.,  3.,  1.,  2.,  4.,  2.,  1.,  1.,  1.,  1.,\n         1.,  1.,  1.,  2.,  1.,  3.,  1.,  4.,  1.,  1.,  1.,  1.,  5.,  2.,\n         1.,  1.,  2.,  1.,  1.,  2.,  1.,  4.,  3.,  4.,  1.,  2.,  1.,  1.,\n         1.,  2.,  3.,  1.,  4.,  1.,  3.,  3.,  1.,  1.,  3.,  1.,  2.,  1.,\n         1.,  4.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  3.,  1.,  1.,\n         1.,  1.,  3.,  2.,  2.,  2.,  2.,  1.,  1.,  2.,  4.,  3.,  1.,  2.,\n         2.,  3.,  5.,  5.,  2.,  1.,  2.,  1.,  1.,  5.,  2.,  3.,  2.,  1.,\n         1.,  2.,  5.,  1.,  1.,  2.,  2.,  6.,  1.,  2.,  4.,  1.,  2.,  5.,\n         4.,  5.,  1.,  1.,  2.,  1.,  3.,  6.,  2.,  1.,  1.,  1.,  2.,  2.,\n        12.,  7.,  4.,  1.,  1.,  1.,  4.,  2.,  1.,  1.,  1.,  3.,  2.,  1.,\n         1.,  1.,  2.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n         1.,  6.,  1.,  4.,  2.,  2.,  1.,  2.,  2.,  3.,  3.,  2.,  4.,  4.,\n         1.,  7.,  5.,  1.,  2.,  2.,  1.,  2.,  4.,  4.,  5.,  6.,  4.,  1.,\n         2.,  2.,  1.,  4.,  3.,  1.,  1.,  1.,  5.,  7.,  1.,  3.,  5.,  1.,\n         1.,  4.,  1.,  1.,  2.,  1.,  6.,  4.,  2.,  2.,  1.,  4.,  1.,  1.,\n         5.,  1.,  2.,  3.,  4.,  1.,  1.,  1.,  2.,  1.,  2.,  2.,  3.,  1.,\n         2.,  7.,  1.,  7.,  1.,  2.,  1.,  2.,  1.,  3.,  1.,  3.,  3.,  1.,\n         3.,  3.,  1.,  4.,  3.,  2.,  2.,  1.,  1.,  1.,  3.,  1.,  1.,  3.,\n         1.,  1.,  3.,  1.,  6.,  1.,  3.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n         1.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  5.,  2.,  4.,  1.,  3.,  4.,\n         3.,  1.,  2.,  2.,  2.,  1.,  2.,  1.,  3.,  2.,  2.,  1.,  5.,  1.,\n         3.,  1.,  2.,  3.,  2.,  2.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  2.,\n         1.,  2.,  3.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  4.,\n         1.,  2.,  1.,  5.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,\n         2.,  1.,  2.,  2.,  2.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,\n         3.,  2.,  1.,  2.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,\n         2.,  1.,  1.,  3.,  5.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,  4.,  5.,\n         1.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  1.,  1.,  1.,  1.,  1.,\n         3.,  2.,  1.,  1.,  3.,  2.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,\n         2.,  1.,  1.,  1.,  2.,  1.,  1.,  4.,  2.,  1.,  3.,  3.,  3.,  3.,\n         1.,  1.])\n</pre> In\u00a0[3]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=3600)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=3600) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 579/579 [00:53&lt;00:00, 10.79it/s]\n 31%|\u2588\u2588\u2588       | 102/327 [26:29&lt;58:26, 15.59s/it]  \n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=3600)\n      2 print(bw)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:255, in temporal_betweenness_centrality(g, delta)\n    253 v = Q.popleft()\n    254 # for all successor events within delta\n--&gt; 255 for w in event_graph.successors(v):\n    256 \n    257     # we dicover w for the first time\n    258     if dist[w] == -1:\n    259         dist[w] = dist[v] + 1\n\nFile /workspaces/pathpyG/src/pathpyG/core/Graph.py:295, in Graph.successors(self, node)\n    283 def successors(self, node: Union[int, str] | tuple) \\\n    284         -&gt; Generator[Union[int, str] | tuple, None, None]:\n    285     \"\"\"Return all successors of a given node.\n    286 \n    287     This method returns a generator object that yields all successors of a\n   (...)\n    292         node:   Index or string ID of node for which successors shall be returned.\n    293     \"\"\" \n--&gt; 295     for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n    296         yield self.mapping.to_id(j.item())\n\nKeyboardInterrupt: </pre> In\u00a0[4]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=30)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=30) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 4581.51it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7f9453f36cb0&gt;, {0: 9.083333333333336, 7: 15.0, 10: 114.12687232787852, 1: 5.0, 6: 9.5, 12: 35.060389610389606, 22: 58.61201533244884, 49: 2.500000000000001, 2: 346.2515994755158, 27: 249.9532851737187, 4: 140.7880952380952, 42: 28.220839755359876, 28: 146.0366185070518, 65: 15.791666666666675, 29: 190.04444444444454, 24: 26.736796536796536, 5: 126.14722222222221, 3: 40.32903828197944, 35: 3.9999999999999996, 9: 7.5, 17: 78.59657287157289, 20: 68.21558441558443, 48: 27.916666666666664, 11: 99.25000000000001, 15: 53.07553688141922, 8: 5.8571428571428585, 26: 118.34098235785545, 37: -0.33333333333333304, 34: 58.120919946926136, 23: 49.347619047619034, 16: -0.1666666666666714, 32: 1.3333333333333286, 46: 2.40126050420168, 19: -1.8611111111111098, 36: 1.0000000000000004, 39: 2.0, 14: 25.33333333333333, 31: 1.5, 21: 0.5555555555555536, 33: 2.1666666666666705, 13: 0.0, 18: -5.19444444444445, 25: -1.9984014443252818e-15, 41: 14.888888888888886, 57: 1.0, 52: 13.833333333333332, 51: 2.916666666666661, 44: 2.999999999999999, 47: 1.5, 38: 0.0, 40: 0.0, 62: -7.444444444444445, 56: 0.0, 61: 0.0, 67: 2.220446049250313e-16})\n</pre> In\u00a0[7]: Copied! <pre>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt_long = pp.TemporalGraph.from_edge_list(tedges)\nc = pp.algorithms.centrality.temporal_closeness_centrality(t_long, 5)\nprint(c)\n</pre> tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),               ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),               ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),               ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),               ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)] t_long = pp.TemporalGraph.from_edge_list(tedges) c = pp.algorithms.centrality.temporal_closeness_centrality(t_long, 5) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 4453.94it/s]</pre> <pre>Created temporal event DAG with 38 nodes and 47 edges\n{'a': 12.0, 'b': 16.0, 'c': 16.0, 'd': 14.666666666666666, 'e': 14.666666666666666, 'f': 24.0, 'g': 14.666666666666666, 'h': 28.0, 'i': 24.0}\n</pre> <pre>\n</pre> In\u00a0[9]: Copied! <pre>c = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, 3600)\n</pre> c = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, 3600) <pre>  0%|          | 0/1157 [00:00&lt;?, ?it/s]</pre> <pre>  4%|\u258e         | 43/1157 [00:05&lt;02:18,  8.05it/s]\n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 c = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, 3600)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:186, in temporal_closeness_centrality(g, delta)\n    172 \"\"\"Calculates the closeness of nodes based on observed shortest paths\n    173 between all nodes. Following the definition by M. A. Beauchamp 1965\n    174 (https://doi.org/10.1002/bs.3830100205).\n   (...)\n    183 dict\n    184 \"\"\"\n    185 centralities = dict()\n--&gt; 186 dist, _ = temporal_shortest_paths(g, delta)\n    187 for x in g.nodes:\n    188     centralities[x] = sum((g.N - 1) / dist[_np.arange(g.N) != g.mapping.to_idx(x), g.mapping.to_idx(x)])\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/temporal.py:59, in temporal_shortest_paths(g, delta)\n     57 def temporal_shortest_paths(g: TemporalGraph, delta: int):\n     58     # generate temporal event DAG\n---&gt; 59     edge_index = lift_order_temporal(g, delta)\n     61     # Add indices of g.n first-order nodes as source nodes of paths in augmented TEG\n     62     src_edges_src = g.data.edge_index[0] + g.M\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/temporal.py:51, in lift_order_temporal(g, delta)\n     49         src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n     50         dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n---&gt; 51         ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n     52         second_order.append(ho_edge_index)\n     54 ho_index = torch.cat(second_order, dim=1)    \n\nKeyboardInterrupt: </pre> In\u00a0[4]: Copied! <pre>print(c)\n</pre> print(c) <pre>{'454': 41671.338095238054, '640': 42220.10476190471, '1': 31384.485714285773, '939': 43385.1666666666, '185': 46485.271428571396, '258': 42662.533333333326, '55': 41131.62698412695, '170': 43822.54999999994, '9': 55537.204761904715, '453': 42306.650000000016, '45': 54390.77142857138, '14': 42915.57142857141, '190': 51695.83809523803, '400': 37502.9365079365, '637': 40505.24126984126, '255': 43516.342857142794, '275': 53779.13333333323, '176': 52638.13333333328, '533': 36436.70952380954, '116': 46335.46666666662, '151': 46517.87142857134, '866': 51019.77619047604, '280': 40957.63095238092, '484': 38709.39523809525, '243': 42567.83809523808, '687': 43355.67142857139, '54': 44738.06666666662, '364': 43477.92142857135, '374': 41239.258730158705, '295': 37942.38968253968, '441': 44693.04761904753, '101': 46261.46984126977, '425': 40808.355411255354, '47': 34439.18333333336, '241': 40734.0880952381, '179': 51910.84285714278, '202': 47549.81666666654, '63': 48038.816666666564, '564': 38769.93809523808, '577': 34370.49047619052, '265': 42888.016666666605, '494': 40898.7698412698, '443': 42818.935714285675, '209': 33025.35238095244, '843': 39757.76984126982, '222': 31847.612698412748, '205': 43918.02142857136, '894': 39705.247619047565, '1359': 54767.9999999999, '1383': 37680.55476190476, '376': 53616.13333333324, '638': 41859.176190476144, '1238': 42806.904761904734, '1260': 38609.26666666665, '487': 46472.59365079362, '984': 45297.69999999997, '226': 42690.47619047611, '353': 46454.99999999993, '1342': 44222.67619047608, '1518': 59688.27142857133, '122': 48889.13333333324, '1067': 42078.83809523807, '1324': 41852.96666666664, '70': 44801.455555555476, '132': 47628.98809523799, '779': 42758.522222222164, '279': 42601.21428571425, '908': 36329.59523809524, '510': 29415.290476190487, '545': 44361.355555555485, '634': 49410.73333333322, '1332': 57435.76666666657, '1401': 48332.21666666656, '582': 44306.50476190468, '605': 55865.5333333332, '252': 45385.02142857135, '3': 50445.78333333325, '884': 48080.34285714278, '339': 41450.89999999998, '691': 48490.171428571346, '869': 47797.033333333246, '72': 48899.99999999993, '954': 46840.76666666663, '160': 47314.2428571428, '117': 46867.93333333327, '346': 41061.76984126978, '111': 45678.421428571404, '124': 43084.39285714283, '276': 42882.58333333332, '621': 39236.16984126983, '39': 41416.11255411249, '871': 44988.38809523805, '694': 49321.4714285713, '778': 49137.51428571418, '513': 39579.116666666654, '236': 35266.21428571434, '883': 40068.50476190471, '1594': 46784.104761904644, '1828': 41670.949999999946, '1214': 48579.43333333323, '196': 47528.471428571334, '201': 44797.83333333326, '245': 53325.838095237974, '390': 44972.08809523807, '938': 44610.77142857142, '923': 37550.54285714288, '106': 58207.29999999987, '272': 55849.23333333323, '753': 43170.54999999998, '486': 35035.81507936507, '531': 41168.10793650794, '254': 48965.199999999975, '382': 44808.699999999975, '119': 45078.038095238015, '240': 46369.36031746025, '447': 45610.11666666662, '649': 42277.54285714276, '1204': 46224.08333333323, '466': 32600.38809523813, '841': 37388.707142857165, '199': 43105.73809523804, '674': 54227.77142857136, '857': 38546.395238095225, '945': 40750.388095238064, '1218': 47321.61666666656, '1512': 51657.80476190465, '653': 49398.44365079353, '502': 44192.40476190468, '587': 29551.511904761897, '626': 41647.27619047614, '420': 45023.704761904715, '504': 40343.27619047614, '311': 46414.63809523806, '267': 44915.038095238066, '177': 48121.22222222215, '480': 40095.671428571455, '771': 23901.880158730197, '312': 46976.59999999993, '612': 43187.238095238026, '450': 36801.13095238098, '89': 47408.54999999997, '322': 49383.56666666663, '520': 33164.678571428616, '15': 45297.70000000002, '211': 47992.633333333324, '366': 37022.86269841269, '227': 45639.99999999996, '440': 48286.033333333275, '41': 47324.33333333326, '388': 47221.100000000006, '219': 42089.70476190474, '658': 48671.79999999991, '220': 42779.73809523808, '576': 39435.90952380952, '642': 46664.57142857137, '391': 37692.58571428572, '777': 35597.647619047646, '20': 39938.88095238094, '958': 50489.638095238006, '103': 29371.176984127007, '61': 47813.333333333234, '274': 36857.53412698415, '147': 51953.53333333325, '277': 32935.18492063496, '702': 30786.81904761907, '242': 44846.73333333334, '38': 52752.233333333206, '438': 37185.73333333332, '387': 46914.11666666656, '1295': 49073.866666666545, '1412': 52219.76666666659, '492': 47707.3833333333, '1345': 46802.733333333235, '1212': 51198.29999999987, '28': 45031.466666666616, '327': 45873.63333333326, '1216': 50562.59999999988, '372': 52590.526984126904, '720': 45705.19999999992, '1784': 41720.23809523804, '27': 46151.50952380945, '171': 34138.926984126985, '1336': 43007.54999999995, '1423': 52198.03333333327, '1366': 37297.11666666668, '407': 48333.3809523809, '1320': 46319.16666666659, '1805': 47327.438095237994, '1237': 41225.8047619047, '974': 29733.65793650794, '464': 45232.49999999995, '477': 42176.24999999997, '763': 36072.546825396836, '1894': 45776.221428571334, '1201': 43844.28333333326, '1228': 50051.86666666656, '786': 37304.61984126989, '886': 43075.46666666661, '797': 47585.13333333329, '959': 34756.25714285715, '1485': 41606.13809523808, '210': 46916.83333333329, '4': 42904.70476190475, '790': 30436.757142857183, '285': 53224.9333333333, '544': 43005.609523809464, '333': 50127.93333333329, '622': 35464.14285714289, '429': 45130.042857142784, '46': 39267.476190476154, '343': 37518.719047619066, '867': 36621.44285714288, '615': 44610.7714285714, '977': 42285.30476190473, '90': 46425.50476190473, '269': 44197.83809523808, '603': 46936.23809523808, '335': 43720.48095238093, '765': 43121.64999999997, '257': 41894.10476190469, '268': 39532.9333333333, '214': 43410.00476190473, '491': 43702.240476190455, '181': 39791.01666666664, '650': 40985.18571428571, '85': 46765.993650793615, '325': 43602.49999999998, '941': 39712.62142857144, '356': 40737.58095238093, '744': 37414.70952380953, '1543': 46257.07142857135, '145': 43442.992857142846, '173': 41173.02380952376, '909': 33217.84761904766, '79': 48995.083333333285, '854': 38707.45476190475, '527': 43498.49047619046, '475': 39621.94826839824, '471': 43425.269841269816, '681': 27453.98650793652, '465': 36373.57936507936, '446': 35151.33809523811, '58': 49894.29999999995, '32': 42986.204761904744, '991': 44181.53809523805, '725': 39806.15238095237, '859': 40474.45238095238, '798': 41875.088095238054, '256': 49459.63333333331, '306': 39031.514285714235, '131': 41163.70952380949, '677': 38990.11746031743, '960': 34713.56666666667, '769': 37148.47619047621, '248': 38814.18095238095, '125': 46992.89999999995, '917': 38007.71904761903, '120': 49546.566666666615, '115': 45982.68809523806, '1519': 34333.75079365083, '970': 40702.264285714264, '213': 46737.6744588744, '424': 48813.06666666662, '428': 42515.5746031746, '488': 47845.93333333331, '498': 44651.5214285714, '809': 40044.96031746028, '92': 42035.37142857144, '845': 43173.26666666668, '655': 34575.92222222225, '156': 47349.171428571295, '413': 44792.400000000016, '21': 38381.0666666667, '1232': 35705.92619047622, '290': 40728.654761904734, '71': 41315.0666666667, '65': 44592.919047619034, '791': 34942.5428571429, '874': 43733.67619047614, '448': 45072.60476190477, '496': 49872.56666666665, '921': 36919.888095238115, '497': 35312.785714285754, '627': 36676.94047619046, '194': 44672.866666666676, '927': 43220.614285714255, '232': 52527.138095238035, '172': 45822.40476190471, '165': 26068.48650793651, '87': 42138.604761904746, '253': 39907.833333333365, '706': 47116.05555555552, '134': 48729.23809523806, '624': 38011.988095238106, '548': 33913.83174603179, '893': 44520.73333333333, '920': 41900.31428571425, '836': 44773.91255411253, '80': 47968.5714285714, '743': 40576.13333333335, '826': 46025.76666666668, '184': 49569.076190476095, '601': 51230.89999999998, '1870': 34552.11904761907, '200': 45851.899999999994, '784': 39126.209523809506, '751': 34508.53477633482, '434': 23954.014285714296, '979': 35987.0365079365, '647': 36782.50238095241, '246': 36560.12380952383, '489': 43239.24285714284, '998': 42595.00476190477, '435': 38087.278571428564, '468': 21858.55058830061, '48': 42347.78809523811, '1339': 44040.27142857138, '159': 40869.921428571426, '149': 25296.729725829755, '1819': 39140.180952380964, '525': 45662.50952380946, '882': 28492.9174603175, '34': 43807.543650793574, '239': 31866.888095238148, '62': 20550.960028860038, '452': 43745.06031746028, '445': 28096.385447885485}\n</pre> In\u00a0[5]: Copied! <pre>def temporal_event_graph(g: pp.TemporalGraph, delta=1): \n\n    print(g.data.edge_index)\n\n    # generate temporal event DAG\n    edge_index = pp.algorithms.lift_order_temporal(g, delta)\n    print(edge_index)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.data.edge_index.size(1)\n    print(src_edges_src)\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.data.edge_index[1] + g.data.edge_index.size(1) + g.n\n    print(dst_edges_dst)\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    event_graph = pp.Graph.from_edge_index(edge_index) \n    return event_graph\n</pre> def temporal_event_graph(g: pp.TemporalGraph, delta=1):       print(g.data.edge_index)      # generate temporal event DAG     edge_index = pp.algorithms.lift_order_temporal(g, delta)     print(edge_index)      # Add indices of first-order nodes as src and dst of paths in augmented     # temporal event DAG     src_edges_src = g.data.edge_index[0] + g.data.edge_index.size(1)     print(src_edges_src)     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.data.edge_index[1] + g.data.edge_index.size(1) + g.n     print(dst_edges_dst)      # add edges from source to edges and from edges to destinations     src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      # create sparse scipy matrix     event_graph = pp.Graph.from_edge_index(edge_index)      return event_graph In\u00a0[10]: Copied! <pre>eg = pp.algorithms.lift_order_temporal(t_long, delta=5)\nprint(eg)\n</pre> eg = pp.algorithms.lift_order_temporal(t_long, delta=5) print(eg) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 3068.65it/s]</pre> <pre>tensor([[ 0,  1,  1,  4,  5,  8, 12],\n        [ 1,  2,  3,  5,  6, 11, 14]])\n</pre> <pre>\n</pre> In\u00a0[11]: Copied! <pre>print(temporal_event_graph(t_long, delta=5))\n</pre> print(temporal_event_graph(t_long, delta=5)) <pre>tensor([[0, 1, 2, 2, 2, 5, 0, 1, 0, 7, 2, 6, 0, 0, 2, 5, 1, 8, 2, 7],\n        [1, 2, 3, 4, 5, 0, 6, 5, 6, 5, 5, 7, 2, 1, 7, 7, 8, 1, 8, 8]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 3405.44it/s]</pre> <pre>tensor([[ 0,  1,  1,  4,  5,  8, 12],\n        [ 1,  2,  3,  5,  6, 11, 14]])\ntensor([20, 21, 22, 22, 22, 25, 20, 21, 20, 27, 22, 26, 20, 20, 22, 25, 21, 28,\n        22, 27])\ntensor([30, 31, 32, 33, 34, 29, 35, 34, 35, 34, 34, 36, 31, 30, 36, 36, 37, 30,\n        37, 37])\nDirected graph with 38 nodes and 47 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <pre>\n</pre> In\u00a0[13]: Copied! <pre>def betweenness_brandes(g: pp.Graph, sources = None):\n    bw = defaultdict(lambda: 0.0)\n\n    if sources == None:\n        sources = [v for v in g.nodes]\n\n    for s in tqdm(sources):\n        S = list()\n        P = defaultdict(list)\n\n        sigma = defaultdict(lambda: 0)  \n        sigma[s] = 1\n\n        d = defaultdict(lambda: -1)        \n        d[s] = 0\n\n        Q = [s]\n        while Q:\n            v = Q.pop(0)\n            S.append(v)\n            for w in g.successors(v):\n                if d[w] &lt; 0:\n                    Q.append(w)\n                    d[w] = d[v] + 1\n                if d[w] == d[v] + 1:\n                    # we found shortest path from s via v to w\n                    sigma[w] = sigma[w] + sigma[v]\n                    P[w].append(v)\n        delta = defaultdict(lambda: 0.0)\n        while S:\n            w = S.pop()\n            for v in P[w]:\n                delta[v] = delta[v] + sigma[v]/sigma[w] * (1 + delta[w])\n                if v != w:\n                    bw[w] = bw[w] + delta[w]\n    return bw\n</pre> def betweenness_brandes(g: pp.Graph, sources = None):     bw = defaultdict(lambda: 0.0)      if sources == None:         sources = [v for v in g.nodes]      for s in tqdm(sources):         S = list()         P = defaultdict(list)          sigma = defaultdict(lambda: 0)           sigma[s] = 1          d = defaultdict(lambda: -1)                 d[s] = 0          Q = [s]         while Q:             v = Q.pop(0)             S.append(v)             for w in g.successors(v):                 if d[w] &lt; 0:                     Q.append(w)                     d[w] = d[v] + 1                 if d[w] == d[v] + 1:                     # we found shortest path from s via v to w                     sigma[w] = sigma[w] + sigma[v]                     P[w].append(v)         delta = defaultdict(lambda: 0.0)         while S:             w = S.pop()             for v in P[w]:                 delta[v] = delta[v] + sigma[v]/sigma[w] * (1 + delta[w])                 if v != w:                     bw[w] = bw[w] + delta[w]     return bw In\u00a0[14]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'), ('b', 'c'), ('c', 'd'), ('c', 'e')])\nbetweenness_brandes(g, g.nodes)\n</pre> g = pp.Graph.from_edge_list([('a', 'c'), ('b', 'c'), ('c', 'd'), ('c', 'e')]) betweenness_brandes(g, g.nodes) <pre>5it [00:00, 3583.04it/s]\n</pre> Out[14]: <pre>defaultdict(&lt;function __main__.betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {'e': 0.0, 'd': 0.0, 'c': 4.0})</pre> In\u00a0[15]: Copied! <pre>def temporal_event_graph(g: pp.TemporalGraph, delta = 1):\n    # generate temporal event DAG\n    edge_index = pp.algorithms.lift_order_temporal(g, delta)    \n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    print(g.data.edge_index)\n    edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges]\n    print(edges)\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    src = [f'{v}-src' for v in g.nodes]\n    tgt = [f'{v}-tgt' for v in g.nodes]\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.data.edge_index[1] + g.m + g.n\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    mapping = pp.IndexMap(edges + src + tgt)\n    event_graph = pp.Graph.from_edge_index(edge_index, mapping) \n    return event_graph\n</pre> def temporal_event_graph(g: pp.TemporalGraph, delta = 1):     # generate temporal event DAG     edge_index = pp.algorithms.lift_order_temporal(g, delta)          # Add indices of first-order nodes as src and dst of paths in augmented     # temporal event DAG     print(g.data.edge_index)     edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges]     print(edges)     src_edges_src = g.data.edge_index[0] + g.m     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      src = [f'{v}-src' for v in g.nodes]     tgt = [f'{v}-tgt' for v in g.nodes]      dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.data.edge_index[1] + g.m + g.n      # add edges from source to edges and from edges to destinations     src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      # create sparse scipy matrix     mapping = pp.IndexMap(edges + src + tgt)     event_graph = pp.Graph.from_edge_index(edge_index, mapping)      return event_graph In\u00a0[25]: Copied! <pre># def fo_node(v, g, src_indices) -&gt; int:\n#     # if v is one of the source nodes, return corresponding first-order node\n\n    \n# def fo_src(v, g, src_indices):\n#     if v in src_indices:\n#         return v - g.m\n#     else:\n#         return g.data.edge_index[0,v].item()\n\ndef temporal_betweenness_brandes(g: pp.TemporalGraph, delta=1):\n\n    print(g.data.edge_index)\n\n    # generate temporal event DAG\n    edge_index = pp.algorithms.lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n #   print(g.data.edge_index)\n    #edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges]\n#    print(edges)\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    #src = [f'{v}-src' for v in g.nodes]\n    #tgt = [f'{v}-tgt' for v in g.nodes]\n\n    # dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    # dst_edges_dst = g.data.edge_index[1] + g.m + g.n\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    # dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges], dim=1)\n\n    # create sparse scipy matrix\n    #mapping = pp.IndexMap(edges + src + tgt)\n    event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.m+g.n)\n    print(event_graph)\n    #pp.plot(event_graph, node_label=[i for i in event_graph.nodes])\n    #print(edge_index)\n\n    # # sources = first-order source nodes in temporal event graph\n    src_indices = set(torch.unique(src_edges_src).tolist())\n    #print(src_edges_src-g.m)\n    # tgt_indices = set(torch.unique(dst_edges_dst).tolist())\n    #print(src_indices)\n    # print(tgt_indices)\n\n    e_i = to_numpy(g.data.edge_index)\n\n    fo_nodes = dict()\n    for v in event_graph.nodes:\n        if v in src_indices:\n            fo_nodes[v] = v - g.m\n        else: # return first-order target node otherwise\n            fo_nodes[v] = e_i[1,v]\n\n    # start from indegree zero nodes\n    #roots = torch.where((degree(g.data.edge_index[1])==0))[0]\n    #dist, _ = pp.algorithms.temporal_shortest_paths(g, delta=delta)\n    #print(dist)\n    bw = defaultdict(lambda: 0.0)\n\n    # for all first-order nodes\n    for s in tqdm(src_indices):\n        t_start = time()\n        print('source', g.mapping.to_id(fo_nodes[s]))\n\n        # for any given s, d[v] is the shortest path distance from s to v\n        # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)\n        delta_ = defaultdict(lambda: 0.0)\n\n        # for any given s, sigma[v] counts shortest paths from s to v\n        sigma = defaultdict(lambda: 0.0)          \n        sigma[s] = 1\n\n        sigma_fo = defaultdict(lambda: 0.0)       \n        sigma_fo[fo_nodes[s]] = 1\n\n        dist = defaultdict(lambda: -1)\n        dist[s] = 0\n\n        dist_fo = defaultdict(lambda: -1)\n        dist_fo[fo_nodes[s]] = 0\n                \n        # for any given s, P[v] is the set of predecessors of v on shortest paths from s\n        P = defaultdict(list)\n\n        # Q is a queue, so we append at the end and pop from the start\n        Q = deque()  \n        Q.append(s)\n\n        # S is a stack, so we append at the end and pop from the end\n        S = list()\n    \n        # dijkstra with path counting\n        while Q:\n            v = Q.popleft()\n            #print('popped ', v)\n            # for all successor events within delta\n            for w in event_graph.successors(v):\n\n                # we dicover w for the first time\n                if dist[w] == -1:\n                    dist[w] = dist[v] + 1\n                    if dist_fo[fo_nodes[w]] == -1:\n                        dist_fo[fo_nodes[w]] = dist[v] + 1\n                    S.append(w)\n                    Q.append(w)\n                # we found a shortest path to event w via event v\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[w] + sigma[v]\n                    P[w].append(v)\n                    # we found a shortest path to first-order node of event w\n                    if dist[w] == dist_fo[fo_nodes[w]]:\n                        sigma_fo[fo_nodes[w]] += sigma[v]\n        #print('S =', S)\n        #print('P', P)\n        #print('d', dist)\n        print('finished BFS ', (time()- t_start))\n        c = 0\n        for i in dist_fo:\n            if dist_fo[i] &gt;=0:\n                c+= 1\n        bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1\n        #print(bw[fo_node(s, g, src_indices)])\n\n        # We computed top. shortest path distances and shortest path counts from (first-order) source nodes to all temporal events\n        # we must now project this to the first-order target nodes of those events\n        while S:\n            w = S.pop()\n            # work backwards through paths to all targets and sum delta and sigma\n\n            # check whether shortest path from s to event w is also shortest path to first-order target of w\n            # if d[w] == d_fo[w_fo]:            \n            if dist[w] == dist_fo[fo_nodes[w]]:\n                # v_fo = fo_tgt(v, g, src_indices, tgt_indices)\n                delta_[w] += (sigma[w]/sigma_fo[fo_nodes[w]])\n            for v in P[w]:\n                delta_[v] += (sigma[v]/sigma[w]) * delta_[w]\n                bw[fo_nodes[v]] += delta_[w] * (sigma[v]/sigma[w])\n    bw_id = defaultdict(lambda: 0.0)\n    for idx in bw:\n        bw_id[g.mapping.to_id(idx)] = bw[idx]\n    return bw_id\n</pre> # def fo_node(v, g, src_indices) -&gt; int: #     # if v is one of the source nodes, return corresponding first-order node       # def fo_src(v, g, src_indices): #     if v in src_indices: #         return v - g.m #     else: #         return g.data.edge_index[0,v].item()  def temporal_betweenness_brandes(g: pp.TemporalGraph, delta=1):      print(g.data.edge_index)      # generate temporal event DAG     edge_index = pp.algorithms.lift_order_temporal(g, delta)      # Add indices of first-order nodes as src and dst of paths in augmented     # temporal event DAG  #   print(g.data.edge_index)     #edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges] #    print(edges)     src_edges_src = g.data.edge_index[0] + g.m     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      #src = [f'{v}-src' for v in g.nodes]     #tgt = [f'{v}-tgt' for v in g.nodes]      # dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     # dst_edges_dst = g.data.edge_index[1] + g.m + g.n      # add edges from source to edges and from edges to destinations     src_edges = torch.stack([src_edges_src, src_edges_dst])     # dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges], dim=1)      # create sparse scipy matrix     #mapping = pp.IndexMap(edges + src + tgt)     event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.m+g.n)     print(event_graph)     #pp.plot(event_graph, node_label=[i for i in event_graph.nodes])     #print(edge_index)      # # sources = first-order source nodes in temporal event graph     src_indices = set(torch.unique(src_edges_src).tolist())     #print(src_edges_src-g.m)     # tgt_indices = set(torch.unique(dst_edges_dst).tolist())     #print(src_indices)     # print(tgt_indices)      e_i = to_numpy(g.data.edge_index)      fo_nodes = dict()     for v in event_graph.nodes:         if v in src_indices:             fo_nodes[v] = v - g.m         else: # return first-order target node otherwise             fo_nodes[v] = e_i[1,v]      # start from indegree zero nodes     #roots = torch.where((degree(g.data.edge_index[1])==0))[0]     #dist, _ = pp.algorithms.temporal_shortest_paths(g, delta=delta)     #print(dist)     bw = defaultdict(lambda: 0.0)      # for all first-order nodes     for s in tqdm(src_indices):         t_start = time()         print('source', g.mapping.to_id(fo_nodes[s]))          # for any given s, d[v] is the shortest path distance from s to v         # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)         delta_ = defaultdict(lambda: 0.0)          # for any given s, sigma[v] counts shortest paths from s to v         sigma = defaultdict(lambda: 0.0)                   sigma[s] = 1          sigma_fo = defaultdict(lambda: 0.0)                sigma_fo[fo_nodes[s]] = 1          dist = defaultdict(lambda: -1)         dist[s] = 0          dist_fo = defaultdict(lambda: -1)         dist_fo[fo_nodes[s]] = 0                          # for any given s, P[v] is the set of predecessors of v on shortest paths from s         P = defaultdict(list)          # Q is a queue, so we append at the end and pop from the start         Q = deque()           Q.append(s)          # S is a stack, so we append at the end and pop from the end         S = list()              # dijkstra with path counting         while Q:             v = Q.popleft()             #print('popped ', v)             # for all successor events within delta             for w in event_graph.successors(v):                  # we dicover w for the first time                 if dist[w] == -1:                     dist[w] = dist[v] + 1                     if dist_fo[fo_nodes[w]] == -1:                         dist_fo[fo_nodes[w]] = dist[v] + 1                     S.append(w)                     Q.append(w)                 # we found a shortest path to event w via event v                 if dist[w] == dist[v] + 1:                     sigma[w] += sigma[w] + sigma[v]                     P[w].append(v)                     # we found a shortest path to first-order node of event w                     if dist[w] == dist_fo[fo_nodes[w]]:                         sigma_fo[fo_nodes[w]] += sigma[v]         #print('S =', S)         #print('P', P)         #print('d', dist)         print('finished BFS ', (time()- t_start))         c = 0         for i in dist_fo:             if dist_fo[i] &gt;=0:                 c+= 1         bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1         #print(bw[fo_node(s, g, src_indices)])          # We computed top. shortest path distances and shortest path counts from (first-order) source nodes to all temporal events         # we must now project this to the first-order target nodes of those events         while S:             w = S.pop()             # work backwards through paths to all targets and sum delta and sigma              # check whether shortest path from s to event w is also shortest path to first-order target of w             # if d[w] == d_fo[w_fo]:                         if dist[w] == dist_fo[fo_nodes[w]]:                 # v_fo = fo_tgt(v, g, src_indices, tgt_indices)                 delta_[w] += (sigma[w]/sigma_fo[fo_nodes[w]])             for v in P[w]:                 delta_[v] += (sigma[v]/sigma[w]) * delta_[w]                 bw[fo_nodes[v]] += delta_[w] * (sigma[v]/sigma[w])     bw_id = defaultdict(lambda: 0.0)     for idx in bw:         bw_id[g.mapping.to_id(idx)] = bw[idx]     return bw_id  In\u00a0[26]: Copied! <pre>temporal_betweenness_brandes(t_sp, delta=3600)\n</pre> temporal_betweenness_brandes(t_sp, delta=3600) <pre>tensor([[ 43,  43,  44,  ..., 202, 162,  76],\n        [ 45,  44,  43,  ..., 262,  76, 162]])\n</pre> <pre>  0%|          | 0/579 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 579/579 [00:39&lt;00:00, 14.52it/s]\n</pre> <pre>Directed graph with 220705 nodes and 18249204 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <pre>  0%|          | 0/327 [00:00&lt;?, ?it/s]</pre> <pre>source 454\nfinished BFS  21.46290111541748\n</pre> <pre>  0%|          | 1/327 [00:23&lt;2:06:37, 23.30s/it]</pre> <pre>source 640\nfinished BFS  20.32966423034668\n</pre> <pre>  1%|          | 2/327 [00:45&lt;2:03:25, 22.79s/it]</pre> <pre>source 1\nfinished BFS  9.732733726501465\n</pre> <pre>  1%|          | 3/327 [00:56&lt;1:32:16, 17.09s/it]</pre> <pre>source 939\n</pre> <pre>  1%|          | 3/327 [01:19&lt;2:22:30, 26.39s/it]\n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[26], line 1\n----&gt; 1 temporal_betweenness_brandes(t_sp, delta=3600)\n\nCell In[25], line 103, in temporal_betweenness_brandes(g, delta)\n    100 v = Q.popleft()\n    101 #print('popped ', v)\n    102 # for all successor events within delta\n--&gt; 103 for w in event_graph.successors(v):\n    104 \n    105     # we dicover w for the first time\n    106     if dist[w] == -1:\n    107         dist[w] = dist[v] + 1\n\nFile /workspaces/pathpyG/src/pathpyG/core/Graph.py:296, in Graph.successors(self, node)\n    285 \"\"\"Return all successors of a given node.\n    286 \n    287 This method returns a generator object that yields all successors of a\n   (...)\n    292     node:   Index or string ID of node for which successors shall be returned.\n    293 \"\"\" \n    295 for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n--&gt; 296     yield self.mapping.to_id(j.item())\n\nKeyboardInterrupt: </pre> In\u00a0[61]: Copied! <pre># Example with two shortest time-respecting paths from a to e via c or d\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\nprint(t.data.edge_index)\nprint(t.mapping)\n\nbw_1 = temporal_betweenness_brandes(t, delta=1)\n\nfor v in t.nodes:\n    print(v, bw_1[t.mapping.to_idx(v)])\n</pre> # Example with two shortest time-respecting paths from a to e via c or d t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)]) print(t.data.edge_index) print(t.mapping)  bw_1 = temporal_betweenness_brandes(t, delta=1)  for v in t.nodes:     print(v, bw_1[t.mapping.to_idx(v)]) <pre>tensor([[0, 1, 1, 2, 3],\n        [1, 2, 3, 4, 4]])\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\ne -&gt; 4\n\ntensor([[0, 1, 1, 2, 3],\n        [1, 2, 3, 4, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2574.77it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 993.62it/s]</pre> <pre>source d\nsource a\nsource b\nsource c\na 0.0\nb 3.0\nc 1.0\nd 1.0\ne 0.0\n</pre> <pre>\n</pre> In\u00a0[62]: Copied! <pre>bw = temporal_betweenness_brandes(t_long, 5)\nfor v in t_long.nodes:\n    print(v, bw[t_long.mapping.to_idx(v)])\n</pre> bw = temporal_betweenness_brandes(t_long, 5) for v in t_long.nodes:     print(v, bw[t_long.mapping.to_idx(v)]) <pre>tensor([[0, 1, 2, 2, 2, 5, 0, 1, 0, 7, 2, 6, 0, 0, 2, 5, 1, 8, 2, 7],\n        [1, 2, 3, 4, 5, 0, 6, 5, 6, 5, 5, 7, 2, 1, 7, 7, 8, 1, 8, 8]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 3854.64it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00&lt;00:00, 1022.18it/s]</pre> <pre>source a\nsource b\nsource c\nsource f\nsource g\nsource h\nsource i\na 2.0\nb 2.0\nc 4.5\nd 0.0\ne 0.0\nf 2.0\ng 0.5\nh 0.0\ni 0.0\n</pre> <pre>\n</pre> In\u00a0[32]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'd', 3), ('b', 'd', 3)])\nprint(t.data.edge_index)\nprint(t.mapping)\n\nbw_1 = temporal_betweenness_brandes(t, delta=1)\nbw_2 = temporal_betweenness_brandes(t, delta=2)\n\nfor v in t.nodes:\n    print(v, bw_1[t.mapping.to_idx(v)], bw_2[t.mapping.to_idx(v)])\n</pre> t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'd', 3), ('b', 'd', 3)]) print(t.data.edge_index) print(t.mapping)  bw_1 = temporal_betweenness_brandes(t, delta=1) bw_2 = temporal_betweenness_brandes(t, delta=2)  for v in t.nodes:     print(v, bw_1[t.mapping.to_idx(v)], bw_2[t.mapping.to_idx(v)]) <pre>tensor([[0, 1, 2, 1],\n        [1, 2, 3, 3]])\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\ntensor([[0, 1, 2, 1],\n        [1, 2, 3, 3]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 3437.95it/s]\n</pre> <pre>{4, 5, 6}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 875.52it/s]\n</pre> <pre>source a\nsource b\nsource c\ntensor([[0, 1, 2, 1],\n        [1, 2, 3, 3]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2423.05it/s]\n</pre> <pre>{4, 5, 6}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 1125.28it/s]</pre> <pre>source a\nsource b\nsource c\na 0.0 -1.0\nb 1.0 1.0\nc 1.0 0.0\nd 0.0 0.0\n</pre> <pre>\n</pre> In\u00a0[93]: Copied! <pre>pp.algorithms.temporal_shortest_paths(t, delta=2)\n</pre> pp.algorithms.temporal_shortest_paths(t, delta=2) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2388.10it/s]</pre> <pre>Created temporal event DAG with 12 nodes and 11 edges\n</pre> <pre>\n</pre> Out[93]: <pre>(array([[ 0.,  1.,  2.,  2.],\n        [inf,  0.,  1.,  1.],\n        [inf, inf,  0.,  1.],\n        [inf, inf, inf,  0.]]),\n array([[-9999,     0,     1,     3],\n        [-9999, -9999,     1,     3],\n        [-9999, -9999, -9999,     2],\n        [-9999, -9999, -9999, -9999]], dtype=int32))</pre> In\u00a0[57]: Copied! <pre>pp.algorithms.temporal_shortest_paths(t, delta=1)\n</pre> pp.algorithms.temporal_shortest_paths(t, delta=1) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 3233.02it/s]</pre> <pre>Created temporal event DAG with 12 nodes and 10 edges\n</pre> <pre>\n</pre> Out[57]: <pre>(array([[ 0.,  1.,  2.,  3.],\n        [inf,  0.,  1.,  1.],\n        [inf, inf,  0.,  1.],\n        [inf, inf, inf,  0.]]),\n array([[-9999,     0,     1,     2],\n        [-9999, -9999,     1,     3],\n        [-9999, -9999, -9999,     2],\n        [-9999, -9999, -9999, -9999]], dtype=int32))</pre> In\u00a0[313]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4)])\nprint(t.mapping)\n\ntemporal_betweenness_brandes(t, delta=1)\n# 4 = a_src\n# 5 = c_src\n# 7 = b_src\n\n# 10 = c_tgt\n# 11 = d_tgt\n# 13 = e_tgt\n</pre> t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4)]) print(t.mapping)  temporal_betweenness_brandes(t, delta=1) # 4 = a_src # 5 = c_src # 7 = b_src  # 10 = c_tgt # 11 = d_tgt # 13 = e_tgt <pre>a -&gt; 0\nc -&gt; 1\nd -&gt; 2\nb -&gt; 3\ne -&gt; 4\n\ntensor([[0, 1, 3, 1],\n        [1, 2, 1, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 3559.77it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2406.37it/s]</pre> <pre>10\n[0]\n11\n[1]\n13\n[]\n10\n[]\n11\n[1]\n13\n[3]\n10\n[2]\n11\n[]\n13\n[3]\n</pre> <pre>\n</pre> Out[313]: <pre>defaultdict(&lt;function __main__.temporal_betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {1: 0.0, 2: 0.0, 4: 0.0})</pre> In\u00a0[253]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4),('a', 'c', 1), ('c', 'e', 2), ('b', 'c', 3), ('c', 'd', 4)])\nprint(t.mapping)\n\ntemporal_betweenness_brandes(t, delta=1)\n# 4 = a_src\n# 5 = c_src\n# 7 = b_src\n\n# 10 = c_tgt\n# 11 = d_tgt\n# 13 = e_tgt\n</pre> t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4),('a', 'c', 1), ('c', 'e', 2), ('b', 'c', 3), ('c', 'd', 4)]) print(t.mapping)  temporal_betweenness_brandes(t, delta=1) # 4 = a_src # 5 = c_src # 7 = b_src  # 10 = c_tgt # 11 = d_tgt # 13 = e_tgt <pre>a -&gt; 0\nc -&gt; 1\nd -&gt; 2\nb -&gt; 3\ne -&gt; 4\n\ntensor([[0, 0, 1, 1, 3, 3, 1, 1],\n        [1, 1, 2, 4, 1, 1, 4, 2]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 2609.21it/s]\n</pre> <pre>tensor([[0, 0, 1, 1, 4, 4, 5, 5],\n        [2, 3, 2, 3, 6, 7, 6, 7]])\n{8, 9, 11}\n{17, 14, 15}\n</pre> <pre>8it [00:00, 3661.15it/s]\n</pre> Out[253]: <pre>defaultdict(&lt;function __main__.temporal_betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {4: 0.0, 2: 0.0})</pre> In\u00a0[138]: Copied! <pre>event_graph = temporal_event_graph(t, delta=1)\npp.plot(event_graph, node_label = [v for v in event_graph.nodes])\n</pre> event_graph = temporal_event_graph(t, delta=1) pp.plot(event_graph, node_label = [v for v in event_graph.nodes]) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 3337.42it/s]</pre> <pre>tensor([[0, 1, 3, 1],\n        [1, 2, 1, 4]])\n['a-c-1.0', 'c-d-2.0', 'b-c-3.0', 'c-e-4.0']\n</pre> <pre>\n</pre> Out[138]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f8a1da53880&gt;</pre> In\u00a0[179]: Copied! <pre>betweenness_brandes(event_graph, sources=['a-src', 'b-src', 'c-src'])\n</pre> betweenness_brandes(event_graph, sources=['a-src', 'b-src', 'c-src']) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2910.69it/s]\n</pre> Out[179]: <pre>defaultdict(&lt;function __main__.betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {'d-tgt': 0.0,\n             'c-tgt': 0.0,\n             'c-d-2.0': 2.0,\n             'a-c-1.0': 3.0,\n             'e-tgt': 0.0,\n             'c-e-4.0': 2.0,\n             'b-c-3.0': 3.0})</pre> In\u00a0[182]: Copied! <pre>\n</pre> <pre>tensor([[0, 1, 3, 1],\n        [1, 2, 1, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 2712.57it/s]\n</pre> <pre>tensor([[ 0,  2,  4,  5,  7,  5,  0,  1,  2,  3],\n        [ 1,  3,  0,  1,  2,  3, 10, 11, 10, 13]])\n{4, 5, 7}\n</pre> <pre>  0%|          | 0/3 [00:00&lt;?, ?it/s]\n</pre> <pre>\n---------------------------------------------------------------------------\nUnboundLocalError                         Traceback (most recent call last)\nCell In[182], line 1\n----&gt; 1 temporal_betweenness_brandes(t, delta=1)\n\nCell In[180], line 56, in temporal_betweenness_brandes(g, delta)\n     53 bw = defaultdict(lambda: 0.0)\n     54 for s in tqdm(src_indices):\n---&gt; 56     fo_src = fo_src(s, g, src_indices, tgt_indices)     \n     57     dist_eg = defaultdict(lambda: -1)\n     58     dist_eg[s] = 0\n\nUnboundLocalError: local variable 'fo_src' referenced before assignment</pre> In\u00a0[75]: Copied! <pre>temporal_betweenness_brandes(t_sp, delta=3600)\n</pre> temporal_betweenness_brandes(t_sp, delta=3600) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1157/1157 [01:15&lt;00:00, 15.43it/s]\n  8%|\u258a         | 25/327 [13:32&lt;2:43:34, 32.50s/it]</pre> <pre>Unexpected exception formatting exception. Falling back to standard exception\n</pre> <pre>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_3320/540718842.py\", line 1, in &lt;module&gt;\n    temporal_betweenness_brandes(t_sp, delta=3600)\n  File \"/tmp/ipykernel_3320/1211725645.py\", line 36, in temporal_betweenness_brandes\n    return betweenness_brandes(event_graph, src_indices)\n  File \"/tmp/ipykernel_3320/2494254184.py\", line -1, in betweenness_brandes\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n    frames.append(self.format_record(record))\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n    frame_info.lines, Colors, self.has_colors, lvals\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n    return self._sd.lines\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n    pieces = self.included_pieces\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n    pos = scope_pieces.index(self.executing_piece)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n    return only(\n  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n    raise NotOneValueFound('Expected one value, found 0')\nexecuting.executing.NotOneValueFound: Expected one value, found 0\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/temporal_graphs/","title":"Temporal Graphs","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nfrom torch_geometric.data import Data\nimport pathpyG as pp\nimport pandas as pd\n\npp.config['torch']['device'] = 'cpu'\n</pre> import torch from torch_geometric.data import Data import pathpyG as pp import pandas as pd  pp.config['torch']['device'] = 'cpu' <p>We can create a temporal graph object from a list of time-stamped edges. Since <code>TemporalGraph</code> is a subclass of the <code>Graph</code> class, the internal structures are very similar:</p> In\u00a0[2]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nprint(t.mapping)\nprint(t.n)\nprint(t.m)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) print(t.mapping) print(t.n) print(t.m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n10\n</pre> <p>By default, all temporal graphs are directed. We can create an undirected version a temporal graph as follows:</p> In\u00a0[3]: Copied! <pre>x = t.to_undirected()\nprint(x.mapping)\nprint(x.n)\nprint(x.m)\n</pre> x = t.to_undirected() print(x.mapping) print(x.n) print(x.m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n20\n</pre> <p>We can also directly create a temporal graph from an instance of <code>pyG.TemporalData</code></p> In\u00a0[4]: Copied! <pre>td = Data(\n    edge_index = torch.Tensor([[0,1,2,0],[1,2,3,1]]).long(),\n    time = torch.Tensor([0,1,2,3])\n)\nprint(td)\nt2 = pp.TemporalGraph(td)\nprint(t2)\n</pre> td = Data(     edge_index = torch.Tensor([[0,1,2,0],[1,2,3,1]]).long(),     time = torch.Tensor([0,1,2,3]) ) print(td) t2 = pp.TemporalGraph(td) print(t2) <pre>Data(edge_index=[2, 4], time=[4])\nTemporal Graph with 4 nodes, 3 unique edges and 4 events in [0.0, 3.0]\n{'Edge Attributes': {}, 'Graph Attributes': {}, 'Node Attributes': {}}\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index', 'time'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> <p>We can restrict a temporal graph to a time window, which returns a temporal graph that only contains time-stamped edges in the given time interval.</p> In\u00a0[12]: Copied! <pre>t1 = t.get_window(0,4)\nprint(t1)\nprint(t1.m)\nprint(t1.start_time)\nprint(t1.end_time)\n</pre> t1 = t.get_window(0,4) print(t1) print(t1.m) print(t1.start_time) print(t1.end_time) <pre>Temporal Graph with 4 nodes, 5 unique edges and 7 events in [1.0, 4.0]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n7\n1.0\n4.0\n</pre> <p>We can also extract a TemporalGraph object for a batch of temporal edges, which is defined by the start and end index of the edges defining the batch.</p> In\u00a0[13]: Copied! <pre>t1 = t.get_batch(1,6)\nprint(t1)\nprint(t1.m)\nprint(t1.start_time)\nprint(t1.end_time)\n</pre> t1 = t.get_batch(1,6) print(t1) print(t1.m) print(t1.start_time) print(t1.end_time) <pre>Temporal Graph with 4 nodes, 4 unique edges and 5 events in [2.0, 4.0]\n{'Edge Attributes': {}, 'Graph Attributes': {}, 'Node Attributes': {}}\n5\n2.0\n4.0\n</pre> <p>We can easily convert a temporal graph into a weighted time-aggregated static graph, where edge weights count the number of occurrences of an edge across all timestamps.</p> In\u00a0[14]: Copied! <pre>g = t.to_static_graph(weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(weighted=True) print(g) <pre>Directed graph with 4 nodes and 6 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>We can also aggregate a temporal graph within a certain time window:</p> In\u00a0[15]: Copied! <pre>g = t.to_static_graph(time_window=(1, 3), weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(time_window=(1, 3), weighted=True) print(g) <pre>Directed graph with 2 nodes and 1 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>Finally, we can use the class <code>RollingTimeWindow</code> to perform a rolling window analysis. The class returns an iterable object, where each iteration yields a time-aggregated weighted graph object as well as the corresponding time window.</p> In\u00a0[16]: Copied! <pre>r = pp.algorithms.RollingTimeWindow(t, window_size=3, step_size=1, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</pre> r = pp.algorithms.RollingTimeWindow(t, window_size=3, step_size=1, return_window=True) for g, w in r:     print('Time window ', w)     print(g)     print(g.data.edge_index)     print('---') <pre>Time window  (1.0, 4.0)\nDirected graph with 3 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 1],\n           [1, 0, 2]], sparse_size=(3, 3), nnz=3, sort_order=row)\n---\nTime window  (2.0, 5.0)\nDirected graph with 4 nodes and 5 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 1, 2, 3],\n           [1, 0, 2, 1, 2]], sparse_size=(4, 4), nnz=5, sort_order=row)\n---\nTime window  (3.0, 6.0)\nDirected graph with 4 nodes and 6 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 1, 2, 2, 3],\n           [1, 0, 2, 1, 3, 2]], sparse_size=(4, 4), nnz=6, sort_order=row)\n---\nTime window  (4.0, 7.0)\nDirected graph with 4 nodes and 5 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 2, 2, 3],\n           [1, 0, 1, 3, 2]], sparse_size=(4, 4), nnz=5, sort_order=row)\n---\nTime window  (5.0, 8.0)\nDirected graph with 4 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[1, 2, 2],\n           [0, 1, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\n---\nTime window  (6.0, 9.0)\nDirected graph with 3 nodes and 1 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[2],\n           [1]], sparse_size=(3, 3), nnz=1, sort_order=row)\n---\n</pre> <p>We can visualize temporal graphs using the plot function just like static graphs:</p> In\u00a0[17]: Copied! <pre>pp.plot(t, node_label=t.nodes, edge_color='lightgray');\n</pre> pp.plot(t, node_label=t.nodes, edge_color='lightgray'); <p>The source nodes, destination nodes and timestamps of time-stamped edges are stored as a <code>pyG TemporalData</code> object, which we can access in the following way.</p> In\u00a0[18]: Copied! <pre>t.data\n</pre> t.data Out[18]: <pre>Data(edge_index=[2, 10], time=[10], num_nodes=4)</pre> In\u00a0[19]: Copied! <pre>print(t.data.edge_index)\n</pre> print(t.data.edge_index) <pre>EdgeIndex([[0, 0, 1, 1, 3, 0, 2, 2, 1, 2],\n           [1, 1, 0, 2, 2, 1, 1, 3, 0, 1]], sparse_size=(4, 4), nnz=10)\n</pre> In\u00a0[20]: Copied! <pre>print(t.data.time)\n</pre> print(t.data.time) <pre>tensor([1., 2., 3., 3., 4., 4., 4., 5., 5., 6.])\n</pre> <p>With the generator functions <code>edges</code> and <code>temporal_edges</code> we can iterate through the time-ordered (temporal) multi-edges of a temporal graph.</p> In\u00a0[21]: Copied! <pre>for v, w in t.edges:\n    print(v, w)\n</pre> for v, w in t.edges:     print(v, w) <pre>a b\na b\nb a\nb c\nd c\na b\nc b\nc d\nb a\nc b\n</pre> In\u00a0[22]: Copied! <pre>for v, w, time in t.temporal_edges:\n    print(v, w, time)\n</pre> for v, w, time in t.temporal_edges:     print(v, w, time) <pre>a b 1.0\na b 2.0\nb a 3.0\nb c 3.0\nd c 4.0\na b 4.0\nc b 4.0\nc d 5.0\nb a 5.0\nc b 6.0\n</pre> <p>We are often interested in time-respecting paths in a temporal graph. A time-respecting path consists of a sequence of nodes $v_0,...,v_l$ where consecutive nodes are connected by time-stamped edges that occur (i) in the right temporal ordering, and (ii) within a maximum time difference of $\\delta\\in \\N$.</p> <p>To calculate time-respecting paths in a temporal graph, we can construct a directed acyclic graph (DAG), where each time-stamped edge $(u,v;t)$ in the temporal graph is represented by a node and two nodes representing time-stamped edges $(u,v;t_1)$ and $(v,w;t_2)$ are connected by an edge iff $0 &lt; t_2-t_1 \\leq \\delta$. This implies that (i) each edge in the resulting DAG represents a time-respecting path of length two, and (ii) time-respecting paths of any lenghts are represented by paths in this DAG.</p> <p>We can construct such a DAG using the function <code>pp.algorithms.lift_order_temporal</code>, which returns an edge_index. We can pass this to the constructor of a <code>Graph</code> object, which we can use to visualize the resulting DAG.</p> In\u00a0[23]: Copied! <pre>e_i = pp.algorithms.lift_order_temporal(t, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\npp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]);\n</pre> e_i = pp.algorithms.lift_order_temporal(t, delta=1) dag = pp.Graph.from_edge_index(e_i) pp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 2649.31it/s]\n</pre> <p>For $\\delta=1$, this DAG with three connected components tells us that the underlying temporal graph has  the following time-respecting paths (of different lengths):</p> <p>Length one: a -&gt; b b -&gt; a b -&gt; c c -&gt; b c -&gt; d d -&gt; c</p> <p>Length two: a -&gt; b -&gt; a (twice, starting at time 2 and time 4) b -&gt; a -&gt; b a -&gt; b -&gt; c b -&gt; c -&gt; b c -&gt; b -&gt; a d -&gt; c -&gt; d</p> <p>Length three: a -&gt; b -&gt; a -&gt; b b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b b -&gt; c -&gt; b -&gt; a</p> <p>Length four: a -&gt; b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b -&gt; a</p> <p>We can can use the function <code>pp.algorithms.temporal.temporal_shortest_paths</code> to calculate shortest time-respecting path distances between any pair of nodes. This also returns a predecessor matrix, which can be used to reconstruct all shortest time-respecting paths (in analogy to the Dijkstra algorithm for static graphs):</p> In\u00a0[24]: Copied! <pre>dist, pred = pp.algorithms.temporal.temporal_shortest_paths(t, delta=1)\nprint(t.mapping)\nprint(dist)\nprint(pred)\n</pre> dist, pred = pp.algorithms.temporal.temporal_shortest_paths(t, delta=1) print(t.mapping) print(dist) print(pred) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 2528.47it/s]</pre> <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n[[ 0.  1.  2. inf]\n [ 1.  0.  1. inf]\n [ 2.  1.  0.  1.]\n [inf inf  1.  0.]]\n[[ 0  0  1 -1]\n [ 1  1  1 -1]\n [ 1  2  2  2]\n [-1 -1  3  3]]\n</pre> <pre>\n</pre> <p>In the example above, the four <code>inf</code> values indicate that there is no time-respecting paths between the four node pairs (a, d), (b, d), (d,a) and (d, b). This is not something we would expect based on the (strongly connected) topology of the time-aggregated graph, which is shown below:</p> In\u00a0[25]: Copied! <pre>g = t.to_static_graph(weighted=True)\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> g = t.to_static_graph(weighted=True) pp.plot(g, node_label=g.mapping.node_ids.tolist()); In\u00a0[26]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\ndf = pp.io.temporal_graph_to_df(t)\nprint(df)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) df = pp.io.temporal_graph_to_df(t) print(df) <pre>   v  w    t\n0  c  b  6.0\n1  b  a  5.0\n2  c  d  5.0\n3  c  b  4.0\n4  a  b  4.0\n5  d  c  4.0\n6  b  c  3.0\n7  b  a  3.0\n8  a  b  2.0\n9  a  b  1.0\n</pre> In\u00a0[27]: Copied! <pre>t = pp.io.df_to_temporal_graph(df)\nprint(t)\n</pre> t = pp.io.df_to_temporal_graph(df) print(t) <pre>Temporal Graph with 4 nodes, 6 unique edges and 10 events in [1.0, 6.0]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> In\u00a0[28]: Copied! <pre>df = pd.DataFrame([['a', 'b', 1], ['b', 'c', 2], ['a', 'c', 3]])\nprint(df)\nt = pp.io.df_to_temporal_graph(df)\nprint(t)\n</pre> df = pd.DataFrame([['a', 'b', 1], ['b', 'c', 2], ['a', 'c', 3]]) print(df) t = pp.io.df_to_temporal_graph(df) print(t) <pre>   0  1  2\n0  a  b  1\n1  b  c  2\n2  a  c  3\nTemporal Graph with 3 nodes, 3 unique edges and 3 events in [1.0, 3.0]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> In\u00a0[29]: Copied! <pre>pp.io.write_csv(t, '../data/test_temporal_graph.csv')\n</pre> pp.io.write_csv(t, '../data/test_temporal_graph.csv') In\u00a0[30]: Copied! <pre>t = pp.io.read_csv_temporal_graph('../data/test_temporal_graph.csv')\nprint(t)\n</pre> t = pp.io.read_csv_temporal_graph('../data/test_temporal_graph.csv') print(t) <pre>Temporal Graph with 3 nodes, 6 unique edges and 6 events in [1.0, 3.0]\n{'Edge Attributes': {}, 'Graph Attributes': {}, 'Node Attributes': {}}\n</pre> In\u00a0[31]: Copied! <pre>t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False)\nprint(t_ants)\n</pre> t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False) print(t_ants) <pre>Temporal Graph with 89 nodes, 1298 unique edges and 3822 events in [0.0, 1438.0]\n{'Edge Attributes': {}, 'Graph Attributes': {}, 'Node Attributes': {}}\n</pre> <p>To calculate the temporal closeness centrality, which is defined based on the length of shortest time-respecting paths of a node to all other nodes, we can write the following:</p> In\u00a0[32]: Copied! <pre>cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60)\nprint(cl)\nmx = max(cl.values())\nmn = min(cl.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60) print(cl) mx = max(cl.values()) mn = min(cl.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3322.84it/s]\n</pre> <pre>{'GBGR': 3024.615873015872, 'GBGW': 2999.502564102565, 'GBG_': 2928.756043956045, 'GGGG': 2859.2000000000007, 'GGGR': 2811.4253968253956, 'GGRR': 4383.866666666668, 'GGRY': 3304.400000000001, 'GGWW': 3418.311111111112, 'GGWY': 5092.2666666666655, 'GGW_': 4230.076190476191, 'GGYW': 2556.571916971917, 'GG_W': 3788.4000000000015, 'GRBR': 2977.3714285714286, 'GRGY': 3039.911111111111, 'GRWG': 4162.714285714285, 'GRYY': 2736.625396825396, 'GR_Y': 3113.7333333333336, 'GR_Y2': 4416.133333333335, 'GR__': 3305.8666666666663, 'GWRG': 3379.2000000000003, 'GYGG': 3321.2977777777783, 'GYYY': 2301.3777777777777, 'GY__': 2260.066666666665, 'G_GW': 3525.866666666667, 'G_R_': 4034.800000000001, 'G_W_': 3010.4380952380957, 'G___': 3100.533333333335, 'G___big': 2068.308913308913, 'G___small': 2351.7999999999993, 'Q': 4177.311111111112, 'RWGY': 3708.5714285714307, 'RWWG': 3030.488888888889, 'WBGG': 3781.0666666666675, 'WBGW': 3166.742857142857, 'WBYG': 2668.5999999999995, 'WGBB': 3440.171428571429, 'WGGB': 3751.1047619047636, 'WGWB': 4185.7619047619055, 'WG_R': 4216.666666666668, 'WRBB': 4256.266666666667, 'WRRY': 3768.600000000001, 'WRR_': 2583.8825396825387, 'WRWR': 3951.200000000001, 'WR__': 3180.7111111111117, 'WWBG': 2788.5206349206346, 'WYGG': 3617.466666666668, 'W___': 3253.0666666666675, 'YGWW': 4867.866666666667, 'YGWY': 2735.542857142857, 'YWGW': 3273.5999999999995, 'YWWW': 2991.999999999999, 'YWW_': 3136.082539682539, 'YW__': 1220.9476986781337, 'YYGG': 4430.8, 'YYGGmid': 4461.6, 'YYGGright': 3284.565079365079, 'YYGW': 3462.844444444446, 'YYRB': 3366.0000000000005, 'YYRG': 2891.30862663906, 'YYWR': 3060.6888888888893, 'YYYY': 2510.339682539682, 'YYY_': 2561.692063492063, 'YY_R': 3472.926984126984, 'YY_W': 3874.9333333333357, 'YY__': 2901.5206349206346, 'Y_WY': 3572.800000000001, 'Y__W': 2301.933333333332, 'Y___': 3097.8444444444453, '_RYG': 1844.680341880342, '_R__': 4439.600000000002, '_WGG': 3781.0666666666684, '_WWW': 2961.6539682539687, '_WWY': 4007.771428571429, '_WYG': 3018.9199999999996, '_WYW': 4252.914285714287, '_W_Y': 3262.742857142857, '_W__': 4009.8666666666677, '_Y__': 2881.7179487179487, '__BB': 3040.9200000000005, '__W_': 3649.4158730158724, '____almost': 3127.809523809524, '____bm': 3655.6, '____bot': 2454.007326007325, '____brood': 3952.0380952380965, '____corner': 3856.638095238096, '____pale': 4692.7047619047635, '____right': 2577.243809523809, '____topleft': 3392.4, '____topright': 2641.047619047619}\n</pre> <p>The definition of time-respecting paths depends on our maximum time difference parameter $\\delta$, which implies that different values of this parameter also yield different centralities. This means that we can calculate temporal node centralities for different \"time scales\" of a temporal graph.</p> In\u00a0[33]: Copied! <pre>cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=20)\nprint(cl)\nmx = max(cl.values())\nmn = min(cl.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=20) print(cl) mx = max(cl.values()) mn = min(cl.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3573.09it/s]\n</pre> <pre>{'GBGR': 2207.0092796092795, 'GBGW': 1574.1780861656403, 'GBG_': 2245.6238095238077, 'GGGG': 2065.6316957552262, 'GGGR': 2052.219608851188, 'GGRR': 3774.042140822139, 'GGRY': 2541.641269841269, 'GGWW': 2203.5236655224166, 'GGWY': 4598.104761904761, 'GGW_': 3827.514285714286, 'GGYW': 1998.2796889101228, 'GG_W': 3159.310780722547, 'GRBR': 2252.3125606823146, 'GRGY': 1961.2073260073257, 'GRWG': 3434.115731505299, 'GRYY': 1769.6720992921016, 'GR_Y': 2458.6663362781, 'GR_Y2': 3750.974603174604, 'GR__': 2287.758730158729, 'GWRG': 2460.425432737198, 'GYGG': 2512.0908424908425, 'GYYY': 1082.0915750915751, 'GY__': 1348.5477329496612, 'G_GW': 2936.1425267542913, 'G_R_': 3429.2739926739923, 'G_W_': 2107.469050754098, 'G___': 2127.2349206349195, 'G___big': 440.0, 'G___small': 1357.2765347758534, 'Q': 3506.6336134453786, 'RWGY': 2859.332112332112, 'RWWG': 2268.550438842203, 'WBGG': 2896.1205924510273, 'WBGW': 2433.333613445378, 'WBYG': 1977.0355670473316, 'WGBB': 2559.064886091109, 'WGGB': 2960.0190476190473, 'WGWB': 3741.2707061969318, 'WG_R': 3544.1333333333337, 'WRBB': 3554.813675213675, 'WRRY': 3153.2702075702073, 'WRR_': 1459.0539682539682, 'WRWR': 3188.4784241901884, 'WR__': 2500.955555555555, 'WWBG': 2036.6218377769462, 'WYGG': 2725.1190476190477, 'W___': 2336.6073260073267, 'YGWW': 4164.021611721611, 'YGWY': 2041.505738705739, 'YWGW': 2504.1366234788234, 'YWWW': 2304.5686202686197, 'YWW_': 2371.849188204297, 'YW__': 176.0, 'YYGG': 3941.017740429505, 'YYGGmid': 3978.1587301587306, 'YYGGright': 2585.841391941392, 'YYGW': 2942.4609600925396, 'YYRB': 2324.445981469511, 'YYRG': 2314.7781799899453, 'YYWR': 2196.252000287295, 'YYYY': 1173.542857142857, 'YYY_': 1451.0821205745692, 'YY_R': 2608.8452541610436, 'YY_W': 3165.41684981685, 'YY__': 2165.776312576312, 'Y_WY': 3077.7333333333327, 'Y__W': 1355.0833598705335, 'Y___': 2157.622222222223, '_RYG': 885.6630036630038, '_R__': 3843.0485958485956, '_WGG': 3243.3761904761905, '_WWW': 1688.0676434676436, '_WWY': 3225.482539682539, '_WYG': 2279.3990591108236, '_WYW': 3684.37142857143, '_W_Y': 2395.1028197945843, '_W__': 3375.862184873949, '_Y__': 2151.667587957515, '__BB': 1831.7949074070343, '__W_': 2927.860263403607, '____almost': 2504.1190835308475, '____bm': 2888.322842445042, '____bot': 1918.2603174603173, '____brood': 3139.037484737485, '____corner': 3197.7706444286337, '____pale': 4135.756532356533, '____right': 1686.4830900989923, '____topleft': 2661.486524002313, '____topright': 1843.6328641362072}\n</pre> <p>We can also calculate the temporal betweenness centrality, which is based on the number of shortest time-respecting paths between pairs of nodes that pass through a given node. Again, this centrality score is sensitive to the time scale parameter $\\delta$.</p> In\u00a0[34]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=60)\nprint(bw)\nmx = max(bw.values())\nmn = min(bw.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=60) print(bw) mx = max(bw.values()) mn = min(bw.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3475.66it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 89/89 [00:03&lt;00:00, 27.00it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7fdf20a03640&gt;, {'GBGR': 20.192212842427075, 'WGBB': 194.79309833949083, 'WRBB': 365.05013895123216, 'G___': 57.80632230642795, '_WYW': 427.3675796732633, '____topright': 10.760025336141013, 'YYGGmid': 663.4450747248108, '__W_': 46.375038482274306, 'GG_W': 292.080282213412, '_W__': 428.33207844162627, 'WBGW': 71.89857589572318, 'GR__': 64.19763457586924, 'RWWG': 83.25286865190012, '____almost': 134.89554914241063, 'GGGG': 78.97281365765863, 'YYGW': 319.0275353843234, 'YWGW': 84.52883527311734, 'YYWR': 139.62781952597214, 'YYRG': 30.06998326775235, 'WRWR': 130.49639766193505, 'WYGG': 274.1787721126864, 'GGYW': 9.54474098670821, 'GYGG': 206.18561458924665, 'GGWY': 1080.0676471347801, 'G_W_': 30.258200815352502, '_W_Y': 88.46660448533098, '_R__': 724.7535183751095, 'WBGG': 184.56469995815524, 'Y___': 124.00746952439442, '____brood': 261.05135853722055, 'WRRY': 227.56794665132307, '_WWY': 258.17798469631225, 'Y_WY': 168.0214751986637, 'GGWW': 127.47912860736434, 'YYGG': 452.6097076570282, 'YY_W': 372.5488526120025, '____topleft': 72.04751294375436, 'GBG_': 156.55265249530558, 'G_GW': 322.43708957585955, 'YGWY': 17.697241798229907, 'GRBR': 71.17718734804407, 'GGGR': 106.77684001312716, 'GGW_': 756.8587346464093, '____bm': 155.14819522566728, 'WGWB': 353.62165711237867, 'WWBG': 210.3370212595935, 'GRYY': 63.34672574396869, '_WWW': 59.796937914791975, '____right': 6.536713311055403, '_WYG': 159.5168700848977, 'YY__': 48.63844749559088, 'GRGY': 45.365480292377676, 'G_R_': 90.00180925262697, 'Q': 554.8667166042984, 'YYGGright': 329.28472257372005, 'WR__': 38.99166576434191, '____corner': 502.8870906126399, 'WG_R': 269.7153804058385, 'GR_Y2': 337.26045226613337, 'GWRG': 218.44745266674752, 'G___small': 20.205088001429456, 'YGWW': 535.3204311320455, 'YY_R': 143.38496654670294, 'RWGY': 235.07340157680488, 'WGGB': 131.96062903943462, '_WGG': 318.5137155129991, '__BB': 79.02021455742683, 'WBYG': 26.79640022964187, 'GRWG': 385.8105700686363, 'W___': 115.05159194927882, 'GGRR': 487.43937337734934, 'Y__W': 1.0294117647058814, 'GY__': 35.364487473310994, 'GR_Y': 23.23800388929457, 'YWW_': 116.98999358694506, 'YYRB': 32.66941405832229, '_Y__': 25.129282093002608, 'GBGW': 49.133677074004986, 'YYY_': 86.25984566814704, 'GGRY': 269.8419665751779, 'YWWW': 39.83384050331751, '____pale': 591.7102550688354, '____bot': 7.010335960335962, 'GYYY': 9.375127968877965, '_RYG': 5.108461302211301, 'WRR_': 74.76533132490208, 'YYYY': 1.000000000000001, 'G___big': -1.7708057242771247e-14, 'YW__': 0.0})\n</pre> In\u00a0[35]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=20)\nprint(bw)\nmx = max(bw.values())\nmn = min(bw.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=20) print(bw) mx = max(bw.values()) mn = min(bw.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3813.91it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 89/89 [00:01&lt;00:00, 69.84it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7fdf20ed9b40&gt;, {'GBGR': 271.0549203258132, 'YY__': 260.787489965592, '_WYG': 394.1302318596431, '____right': 28.503246753246753, 'Q': 1457.263110413932, 'GGRR': 393.6459799032444, 'GGGR': 201.48208556149757, 'YYGGright': 534.66060053214, 'YY_R': 266.91765439796467, 'Y___': 172.67107899804276, '____corner': 551.646068862101, 'YGWW': 1201.1725191494913, 'WG_R': 512.4899073911774, '_WGG': 662.2060823813118, 'YWGW': 71.94722222222224, '____bm': 520.5037887625123, '__BB': 146.4024424420817, '_Y__': 116.65703669247497, 'WBYG': 337.50697274935305, 'YYWR': 346.0394146748694, '_W_Y': 126.7397860593513, 'WBGG': 100.16123039327377, 'Y_WY': 709.6990969778257, '_W__': 888.9702395101842, 'GGWW': 252.45108178976466, 'RWGY': 400.3435250525273, 'WR__': 324.7003673342413, 'G_R_': 74.0687563696638, '____bot': 18.876190476190477, '____pale': 1160.042127920021, '____almost': 586.5742800306991, '____topright': 6.242857142857144, 'YYGG': 900.9820998851815, '_WYW': 910.3151884148607, 'GGW_': 1229.7209102391769, 'G_GW': 411.33446741036244, 'YYGGmid': 941.7798494844893, 'GG_W': 893.2237821543014, 'WWBG': 82.09047619047621, 'GRWG': 765.7519205139172, 'WGGB': 562.7259479161665, 'WRWR': 79.9309806206866, '____topleft': 31.47539682539684, 'GGRY': 1009.5761263646133, 'GGWY': 2510.3962123782903, 'RWWG': 238.21048955595802, 'GBG_': 219.31044140486634, 'WGWB': 651.4299970278146, '_R__': 1516.87808629868, 'GGYW': 96.16713560885782, 'WGBB': 458.9464625746425, 'GRBR': 229.0634357985618, '____brood': 241.461111111111, 'G___small': 2.0000000000000027, 'GR_Y2': 782.0649724285778, 'W___': 307.82509532385853, 'YYGW': 851.6365545426578, 'GY__': 74.0, 'GBGW': 47.5015406162465, 'YYY_': 148.44444444444446, '__W_': 184.20506454409792, 'YYRB': 213.21211161607084, 'WYGG': 427.62927891499254, 'WRBB': 343.03298248682995, 'WRRY': 409.20603349701526, 'YWWW': 8.403968253968255, 'WBGW': 28.814786967418545, 'GR_Y': 24.047859363598853, 'YWW_': 32.92341269841275, '_WWY': 660.9893002248847, 'YGWY': 172.38878675703566, 'GWRG': 172.5340550134477, 'GYGG': 596.7332954372962, 'GRYY': 221.22555230251604, '_RYG': 16.17857142857143, 'YY_W': 444.00904725283243, 'GRGY': 140.32892318821007, 'G___': 111.45865644159763, 'GR__': 91.98653846153846, 'GGGG': 148.8203370642651, 'G_W_': 13.97619047619047, '_WWW': 49.37142857142858, 'YYRG': 13.01755106156194, 'WRR_': 67.70574974670724, 'Y__W': 0.9999999999999983, 'YYYY': 2.0, 'GYYY': 0.0, 'G___big': 1.5154544286133387e-14, 'YW__': -1.4210854715202004e-14})\n</pre>"},{"location":"tutorial/temporal_graphs/#temporal-graph-analysis","title":"Temporal Graph Analysis\u00b6","text":""},{"location":"tutorial/temporal_graphs/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/temporal_graphs/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In this tutorial we will introduce the representation of temporal graph data using the <code>TemporalGraph</code> class and how such data can be used to calculate shortest time respecting paths between nodes as well temporal node cemtralities.</p>"},{"location":"tutorial/temporal_graphs/#extracting-time-respecting-paths-in-temporal-networks","title":"Extracting Time-Respecting Paths in Temporal Networks\u00b6","text":""},{"location":"tutorial/temporal_graphs/#reading-and-writing-temporal-graph-data","title":"Reading and writing temporal graph data\u00b6","text":""},{"location":"tutorial/temporal_graphs/#temporal-centralities-in-empirical-temporal-networks","title":"Temporal Centralities in Empirical Temporal Networks\u00b6","text":"<p><code>pathpyG</code>'s ability to calculate (shortest) time-respecting paths enables us to calulate different notions of temporal centralities for nodes in empirial temporal networks. We can read an empirical temporal graph based on CSV data, where each line contains the source, target, and timestamp of an edge as comma-separated value:</p>"},{"location":"tutorial/temporal_shortest_paths/","title":"Temporal shortest paths","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\nimport torch\n\nfrom scipy.sparse.csgraph import bellman_ford, dijkstra\nimport numpy as np\n\nfrom collections import defaultdict\n\n\nfrom tqdm import tqdm\n</pre> import pathpyG as pp from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index import torch  from scipy.sparse.csgraph import bellman_ford, dijkstra import numpy as np  from collections import defaultdict   from tqdm import tqdm In\u00a0[4]: Copied! <pre>t_sp = pp.io.read_csv_temporal_graph('sociopatterns_highschool_2013.tedges', header=False).to_undirected()\nprint(t_sp)\nprint(torch.unique(t_sp.data.t).size(0))\n</pre> t_sp = pp.io.read_csv_temporal_graph('sociopatterns_highschool_2013.tedges', header=False).to_undirected() print(t_sp) print(torch.unique(t_sp.data.t).size(0)) <pre>Temporal Graph with 327 nodes, 11636 unique edges and 754032 events in [1385982080.0, 1386345600.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([754032])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([754032])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([754032])\n\n1157\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 'src', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[5]: Copied! <pre>t_ants = pp.io.read_csv_temporal_graph('../data/ants_2_2_val.tedges', header=False)\nprint(t_ants)\n</pre> t_ants = pp.io.read_csv_temporal_graph('../data/ants_2_2_val.tedges', header=False) print(t_ants) <pre>Temporal Graph with 68 nodes, 752 unique edges and 2090 events in [899.0, 1796.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2090])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2090])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2090])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 'src', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[3]: Copied! <pre>c = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60)\nprint(c)\n</pre> c = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 5479.47it/s]</pre> <pre>Created temporal event DAG with 1181 nodes and 4023 edges\n[[ 0.  1. inf ... inf inf inf]\n [ 1.  0. inf ... inf inf inf]\n [ 5.  3.  0. ...  2. inf inf]\n ...\n [inf inf inf ...  0. inf inf]\n [inf inf inf ... inf  0. inf]\n [inf inf inf ...  1. inf  0.]]\n{'JJJJ': 1399.0180458430464, 'WGG_': 1491.1753968253968, '_Y_B': 1461.7166666666667, 'HHHH': 996.0666666666666, 'WGRB': 1834.2047619047619, 'WYWY': 1540.441666666667, 'WY_G': 761.1371794871794, 'XXXX': 1670.8789682539682, 'LLLL': 1182.7095238095237, 'FFFF': 1062.2448773448773, 'WYG_': 1978.7333333333331, 'WW__': 1790.2027777777776, 'WRWB': 1743.196428571429, 'AAAA': 581.3047619047619, 'WGYW': 1155.8297619047619, 'WBYY': 968.8944444444444, '_R__': 880.7575396825396, 'WYBG': 1448.1039682539683, 'W__W': 1546.319877344877, 'RRRR': 924.1214285714285, 'WYRW': 1601.938095238095, 'WYYB': 865.6825396825396, 'WG_W': 1494.8178571428573, 'WRR_': 1195.2853174603176, 'W__G': 867.9182900432901, '_WRR': 622.8873015873016, 'WY_R': 1549.3750000000002, '_YYY': 1706.9047619047617, 'WRGG': 1571.4158730158733, 'WWGY': 1374.6964285714284, 'WW_W': 1325.6428571428573, 'W_W_': 842.7908730158728, 'WYYR': 798.6825396825395, 'ZZZZ': 662.777922077922, 'W_RG': 1339.8936507936507, 'WBGW': 512.55, 'WBGG': 1543.3130952380955, 'WWRY': 965.0658730158731, 'W___': 518.640909090909, 'VVVV': 394.82142857142856, 'WGGY': 402.0, 'WG__': 402.0, 'WY__': 1094.4130952380951, 'W_GY': 847.5990842490843, 'WYWW': 383.8191197691197, 'OOOO': 866.3738095238094, 'W_BG': 1306.0214285714287, 'TTTT': 549.4, 'WBWY': 1183.2944444444443, 'WWY_': 1060.354761904762, 'WBGR': 67.0, 'WGWY': 597.4166666666666, 'PPPP': 1146.8166666666664, 'WGGW': 917.4214285714285, 'EEEE': 617.1976190476189, '__YR': 134.0, 'WYYG': 548.8972582972583, 'WGGG': 207.70000000000002, 'IIII': 409.81666666666666, 'MMMM': 201.0, 'UUUU': 67.0, 'W_WG': 67.0, 'WYY_': 134.0, 'WWR_': 134.0, 'QQQQ': 415.4, 'WR__': 1117.5440476190474, 'W_GW': 167.5, 'AAAB': 0.0}\n</pre> <pre>\n</pre> In\u00a0[47]: Copied! <pre>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nc = pp.algorithms.centrality.temporal_closeness_centrality(t, 5)\nprint(c)\n</pre> tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),               ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),               ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),               ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),               ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)] t = pp.TemporalGraph.from_edge_list(tedges) c = pp.algorithms.centrality.temporal_closeness_centrality(t, 5) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 5773.07it/s]</pre> <pre>Created temporal event DAG with 38 nodes and 47 edges\n(9, 38)\n(9, 9)\n[[ 0.  1.  1.  3.  3. inf  1.  2. inf]\n [inf  0.  1.  2.  2.  1. inf inf  1.]\n [ 2. inf  0.  1.  1.  1.  3.  1.  1.]\n [inf inf inf  0. inf inf inf inf inf]\n [inf inf inf inf  0. inf inf inf inf]\n [ 1. inf inf inf inf  0.  2.  1. inf]\n [inf inf inf inf inf inf  0.  1. inf]\n [inf inf inf inf inf  1. inf  0.  1.]\n [inf  1. inf inf inf inf inf inf  0.]]\n{'a': 12.0, 'b': 16.0, 'c': 16.0, 'd': 14.666666666666666, 'e': 14.666666666666666, 'f': 24.0, 'g': 14.666666666666666, 'h': 28.0, 'i': 24.0}\n</pre> <pre>\n</pre> In\u00a0[49]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2), (1,4,3)])\nprint(t)\n</pre> t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2), (1,4,3)]) print(t) <pre>Temporal Graph with 5 nodes, 6 unique edges and 6 events in [0.0, 3.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 't', 'src'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[5]: Copied! <pre>c = pp.algorithms.centrality.temporal_closeness_centrality(t, delta=1)\nprint(c)\n</pre> c = pp.algorithms.centrality.temporal_closeness_centrality(t, delta=1) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 262.99it/s]</pre> <pre>Created temporal event DAG with 17 nodes and 15 edges\n{0.0: 0.0, 1.0: 4.0, 2.0: 8.0, 3.0: 6.0, 4.0: 9.333333333333332}\n</pre> <pre>\n</pre> In\u00a0[2]: Copied! <pre># old code with explosive memory usage due to computation of all second-order edges irrespective of time stamps\ndef lift_order_not_efficient(g: pp.TemporalGraph, delta=1):\n    # first-order edge index\n    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n    print(edge_index)\n    # second-order edge index with time-respective filtering\n    null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))    \n    # Update node sequences\n    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n    # Remove non-time-respecting higher-order edges\n    time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n    non_negative_mask = time_diff &gt; 0\n    delta_mask = time_diff &lt;= delta\n    time_respecting_mask = non_negative_mask &amp; delta_mask\n    edge_index = null_model_edge_index[:, time_respecting_mask]\n    return edge_index\n</pre> # old code with explosive memory usage due to computation of all second-order edges irrespective of time stamps def lift_order_not_efficient(g: pp.TemporalGraph, delta=1):     # first-order edge index     edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)     node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)     print(edge_index)     # second-order edge index with time-respective filtering     null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))         # Update node sequences     node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)     # Remove non-time-respecting higher-order edges     time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]     non_negative_mask = time_diff &gt; 0     delta_mask = time_diff &lt;= delta     time_respecting_mask = non_negative_mask &amp; delta_mask     edge_index = null_model_edge_index[:, time_respecting_mask]     return edge_index In\u00a0[3]: Copied! <pre># new memory-efficient code\ndef lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):\n\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.t\n    # print(edge_index)\n\n    indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)\n\n    unique_t = torch.unique(timestamps, sorted=True)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for i in tqdm(range(unique_t.size(0))):\n        t = unique_t[i]\n        #print('timestamp index ', i)\n        #print('timestamp ', t)\n        \n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = (timestamps == t)\n        src_edges = edge_index[:,src_time_mask]\n        src_edge_idx = indices[src_time_mask]\n        #print(src_edges)\n        #print(src_edge_idx)\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)\n        dst_edges = edge_index[:,dst_time_mask]        \n        dst_edge_idx = indices[dst_time_mask]\n        #print(dst_edges)\n        #print(dst_edge_idx)\n\n        if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:\n\n            # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges        \n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n            src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n            dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n            #print(src_edges)\n            #print(dst_edges)\n            ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n            second_order.append(ho_edge_index)\n            #print(ho_edge_index) \n            \n            # #print('dst', dst)\n            # src_mask = (edge_index[:,mask][0]==dst)\n            # ctd = edge_index[:,mask][:,src_mask]\n            # #print('continuations', ctd)\n            # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]        \n            # #print('ctd indx', ctd_indices)\n            # count += ctd_indices.size(0)\n    ho_index = torch.cat(second_order, dim=1)    \n    return ho_index\n</pre> # new memory-efficient code def lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):      # first-order edge index     edge_index, timestamps = g.data.edge_index, g.data.t     # print(edge_index)      indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)      unique_t = torch.unique(timestamps, sorted=True)     second_order = []      # lift order: find possible continuations for edges in each time stamp     for i in tqdm(range(unique_t.size(0))):         t = unique_t[i]         #print('timestamp index ', i)         #print('timestamp ', t)                  # find indices of all source edges that occur at unique timestamp t         src_time_mask = (timestamps == t)         src_edges = edge_index[:,src_time_mask]         src_edge_idx = indices[src_time_mask]         #print(src_edges)         #print(src_edge_idx)          # find indices of all edges that can possibly continue edges occurring at time t for the given delta         dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)         dst_edges = edge_index[:,dst_time_mask]                 dst_edge_idx = indices[dst_time_mask]         #print(dst_edges)         #print(dst_edge_idx)          if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:              # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges                     x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()             src_edges = torch.index_select(edge_index, dim=1, index=x[0])             dst_edges = torch.index_select(edge_index, dim=1, index=x[1])             #print(src_edges)             #print(dst_edges)             ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]             second_order.append(ho_edge_index)             #print(ho_edge_index)                           # #print('dst', dst)             # src_mask = (edge_index[:,mask][0]==dst)             # ctd = edge_index[:,mask][:,src_mask]             # #print('continuations', ctd)             # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]                     # #print('ctd indx', ctd_indices)             # count += ctd_indices.size(0)     ho_index = torch.cat(second_order, dim=1)         return ho_index In\u00a0[5]: Copied! <pre>def fo_nodes(ho_edge, g):\n    src_edge = ho_edge[0]\n    dst_edge = ho_edge[1]\n    return g.data.edge_index[:,src_edge][0], g.data.edge_index[:,dst_edge][0], g.data.edge_index[:,dst_edge][1]\n\n\ndef temporal_shortest_paths_all(g: pp.TemporalGraph, delta: int):\n    # generate temporal event DAG\n    edge_index = lift_order_efficient(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in TEG\n    src_edges_src = g.data.edge_index[0,:] + g.data.edge_index.size(1)\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))    \n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.data.edge_index[1,:] + 2*g.data.edge_index.size(1)\n\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    event_graph = pp.Graph.from_edge_index(edge_index)\n    \n    # initialize distance matrix \n    dist = torch.full((g.n, event_graph.n), float(\"inf\"), device=g.data.edge_index.device)\n\n    # predecessor lists\n    pred = defaultdict(lambda: defaultdict(list))\n\n    # Fastest known single source SP in DAG (Cormen, Leiserson): single scan of edges in DAG\n    # trick: index of second-order nodes = topological sorting of event DAG assuming that edges are given in chronological order    \n    # scan second-order nodes in topological order and relax distances between first-order nodes\n\n    # TODO: correct algorithm\n    for src in tqdm(g.nodes):\n        dist[g.mapping.to_idx(src), g.mapping.to_idx(src) + g.data.edge_index.size(1)] = 0\n        for v in event_graph.nodes:\n            for w in event_graph.successors(v):\n                dist[g.mapping.to_idx(src), w] = min(dist[g.mapping.to_idx(src), w], dist[g.mapping.to_idx(src), v]+1)\n    \n    dist_fo = dist[:,2*g.m:] - 1\n    dist_fo.fill_diagonal_(0)\n    return dist_fo, pred\n\n\ndef temporal_shortest_paths(g: pp.TemporalGraph, delta: int):\n    # generate temporal event DAG\n    edge_index = lift_order_efficient(g, delta)    \n\n    # Add indices of g.n first-order nodes as source nodes of paths in augmented TEG\n    src_edges_src = g.m + g.data.edge_index[0,:]\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    # Add indices of g.n first-order nodes as target nodes of paths in augmented TEG\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.m + g.n + g.data.edge_index[1,:]\n\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.m + 2 * g.n)\n    m = event_graph.sparse_adj_matrix()\n    print(m.shape)\n    # compute shortest paths from all source nodes to all nodes \n    dist, pred = dijkstra(m, directed=True, indices = np.arange(g.m, g.m+g.n),  return_predecessors=True, unweighted=True)\n    print(dist.shape)\n    print(g.n + g.m)\n    # we are only interested in target nodes, whose indices start at G.m + G.n\n    dist_fo = dist[:,g.m+g.n:] - 1\n    np.fill_diagonal(dist_fo, 0)\n    pred_fo = pred[:,g.n+g.m:]\n    return dist_fo, pred_fo\n\n\n    \ndef temporal_closeness_centrality(g: pp.TemporalGraph, delta: int) -&gt; dict:\n\n    centralities = dict()\n    dist, _ = temporal_shortest_paths(g, delta)\n    for x in g.nodes:\n        centralities[x] = sum((g.n - 1) / dist[np.arange(g.n)!=x, g.mapping.to_idx(x)])\n\n    return centralities\n</pre> def fo_nodes(ho_edge, g):     src_edge = ho_edge[0]     dst_edge = ho_edge[1]     return g.data.edge_index[:,src_edge][0], g.data.edge_index[:,dst_edge][0], g.data.edge_index[:,dst_edge][1]   def temporal_shortest_paths_all(g: pp.TemporalGraph, delta: int):     # generate temporal event DAG     edge_index = lift_order_efficient(g, delta)      # Add indices of first-order nodes as src and dst of paths in TEG     src_edges_src = g.data.edge_index[0,:] + g.data.edge_index.size(1)     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))         dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.data.edge_index[1,:] + 2*g.data.edge_index.size(1)      src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      event_graph = pp.Graph.from_edge_index(edge_index)          # initialize distance matrix      dist = torch.full((g.n, event_graph.n), float(\"inf\"), device=g.data.edge_index.device)      # predecessor lists     pred = defaultdict(lambda: defaultdict(list))      # Fastest known single source SP in DAG (Cormen, Leiserson): single scan of edges in DAG     # trick: index of second-order nodes = topological sorting of event DAG assuming that edges are given in chronological order         # scan second-order nodes in topological order and relax distances between first-order nodes      # TODO: correct algorithm     for src in tqdm(g.nodes):         dist[g.mapping.to_idx(src), g.mapping.to_idx(src) + g.data.edge_index.size(1)] = 0         for v in event_graph.nodes:             for w in event_graph.successors(v):                 dist[g.mapping.to_idx(src), w] = min(dist[g.mapping.to_idx(src), w], dist[g.mapping.to_idx(src), v]+1)          dist_fo = dist[:,2*g.m:] - 1     dist_fo.fill_diagonal_(0)     return dist_fo, pred   def temporal_shortest_paths(g: pp.TemporalGraph, delta: int):     # generate temporal event DAG     edge_index = lift_order_efficient(g, delta)          # Add indices of g.n first-order nodes as source nodes of paths in augmented TEG     src_edges_src = g.m + g.data.edge_index[0,:]     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      # Add indices of g.n first-order nodes as target nodes of paths in augmented TEG     dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.m + g.n + g.data.edge_index[1,:]      src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.m + 2 * g.n)     m = event_graph.sparse_adj_matrix()     print(m.shape)     # compute shortest paths from all source nodes to all nodes      dist, pred = dijkstra(m, directed=True, indices = np.arange(g.m, g.m+g.n),  return_predecessors=True, unweighted=True)     print(dist.shape)     print(g.n + g.m)     # we are only interested in target nodes, whose indices start at G.m + G.n     dist_fo = dist[:,g.m+g.n:] - 1     np.fill_diagonal(dist_fo, 0)     pred_fo = pred[:,g.n+g.m:]     return dist_fo, pred_fo        def temporal_closeness_centrality(g: pp.TemporalGraph, delta: int) -&gt; dict:      centralities = dict()     dist, _ = temporal_shortest_paths(g, delta)     for x in g.nodes:         centralities[x] = sum((g.n - 1) / dist[np.arange(g.n)!=x, g.mapping.to_idx(x)])      return centralities In\u00a0[6]: Copied! <pre>dist, pred = temporal_shortest_paths(t_ants, delta=30)\nprint(dist.shape)\nprint(t_ants.n)\nprint(t_ants.m)\n</pre> dist, pred = temporal_shortest_paths(t_ants, delta=30) print(dist.shape) print(t_ants.n) print(t_ants.m) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 6304.91it/s]</pre> <pre>(1181, 1181)\n(68, 1181)\n1113\n(68, 68)\n68\n1045\n</pre> <pre>\n</pre> In\u00a0[11]: Copied! <pre>idx[:,1]\n</pre> idx[:,1] <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 idx[:,1]\n\nNameError: name 'idx' is not defined</pre> In\u00a0[\u00a0]: Copied! <pre>edge_index = lift_order_efficient(t)\nprint(edge_index)\n</pre> edge_index = lift_order_efficient(t) print(edge_index) In\u00a0[50]: Copied! <pre>print(t.data.edge_index)\ndist, pred = temporal_shortest_paths(t, delta=1)\n\nprint(dist)\nprint(pred)\n</pre> print(t.data.edge_index) dist, pred = temporal_shortest_paths(t, delta=1)  print(dist) print(pred) <pre>tensor([[0, 0, 1, 1, 3, 1],\n        [1, 2, 2, 3, 4, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 2955.30it/s]</pre> <pre>(16, 16)\n(5, 16)\n11\n[[ 0.  1.  1.  2.  3.]\n [inf  0.  1.  1.  1.]\n [inf inf  0. inf inf]\n [inf inf inf  0.  1.]\n [inf inf inf inf  0.]]\n[[-9999     0     1     3     4]\n [-9999 -9999     2     3     5]\n [-9999 -9999 -9999 -9999 -9999]\n [-9999 -9999 -9999 -9999     4]\n [-9999 -9999 -9999 -9999 -9999]]\n</pre> <pre>\n</pre> In\u00a0[51]: Copied! <pre>dist[:,4]\n</pre> dist[:,4] Out[51]: <pre>array([ 3.,  1., inf,  1.,  0.])</pre> In\u00a0[\u00a0]: Copied! <pre>t.mapping.node_ids\n</pre> t.mapping.node_ids In\u00a0[\u00a0]: Copied! <pre>print(temporal_closeness_centrality(t, delta=1))\nprint(t.n)\n</pre> print(temporal_closeness_centrality(t, delta=1)) print(t.n) In\u00a0[\u00a0]: Copied! <pre>temporal_shortest_paths(t_sp, delta=3600)\n</pre> temporal_shortest_paths(t_sp, delta=3600) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>edge_index[0,:]\n</pre> edge_index[0,:] In\u00a0[\u00a0]: Copied! <pre>t.data.edge_index[:,edge_index[0,:]][0]\n</pre> t.data.edge_index[:,edge_index[0,:]][0] In\u00a0[\u00a0]: Copied! <pre>t.data.edge_index[:,edge_index[1,:]][1]\n</pre> t.data.edge_index[:,edge_index[1,:]][1] In\u00a0[\u00a0]: Copied! <pre>#print(t.data.edge_index)\nprint(t_sp)\ng = temporal_shortest_paths(t_sp, delta=300)\n</pre> #print(t.data.edge_index) print(t_sp) g = temporal_shortest_paths(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>indeg = degree(g.data.edge_index[1])\nroots = torch.where(indeg==0)[0]\nprint(roots)\n</pre> indeg = degree(g.data.edge_index[1]) roots = torch.where(indeg==0)[0] print(roots) In\u00a0[\u00a0]: Copied! <pre>def traverse(g, path):\n    if g.get_successors(path[-1]).size(0) == 0:\n        pass\n    else:\n        for w in g.successors(path[-1]):\n            traverse(g, path + (w,))\n</pre> def traverse(g, path):     if g.get_successors(path[-1]).size(0) == 0:         pass     else:         for w in g.successors(path[-1]):             traverse(g, path + (w,)) In\u00a0[\u00a0]: Copied! <pre>i = 0\nfor x in roots:\n    print(x)\n    traverse(g, (x,))\n</pre> i = 0 for x in roots:     print(x)     traverse(g, (x,)) In\u00a0[\u00a0]: Copied! <pre>ho_index = lift_order_not_efficient(t, delta=1)\nprint(ho_index)\n</pre> ho_index = lift_order_not_efficient(t, delta=1) print(ho_index) In\u00a0[\u00a0]: Copied! <pre>ho_index = lift_order_efficient(t, delta=1)\nprint(ho_index)\n</pre> ho_index = lift_order_efficient(t, delta=1) print(ho_index) In\u00a0[\u00a0]: Copied! <pre>print(t.data.edge_index)\n</pre> print(t.data.edge_index) In\u00a0[\u00a0]: Copied! <pre>node_sequence = torch.arange(t.data.num_nodes, device=t.data.edge_index.device).unsqueeze(1)\nprint(node_sequence)\nnode_sequence = torch.cat([node_sequence[t.data.edge_index[0]], node_sequence[t.data.edge_index[1]][:, -1:]], dim=1)\nprint(node_sequence)\n</pre> node_sequence = torch.arange(t.data.num_nodes, device=t.data.edge_index.device).unsqueeze(1) print(node_sequence) node_sequence = torch.cat([node_sequence[t.data.edge_index[0]], node_sequence[t.data.edge_index[1]][:, -1:]], dim=1) print(node_sequence) In\u00a0[\u00a0]: Copied! <pre>lift_order_not_efficient(t_sp, delta=300)\n</pre> lift_order_not_efficient(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>lift_order_efficient(t_sp, delta=300)\n</pre> lift_order_efficient(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>lift_order_not_efficient(t_sp, delta=300)\n</pre> lift_order_not_efficient(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>x = torch.cartesian_prod(torch.tensor([0,1]), torch.tensor([1,3])).t()\n# edge 0 = 0-&gt;1\n# edge 1 = 1-&gt;2\n# edge 2 = 0-&gt;1\n\n# combination 0,1:     0-&gt;1, 1-&gt;2\n# combination 0,2:     0-&gt;1, 0-&gt;1\nprint(x)\n</pre> x = torch.cartesian_prod(torch.tensor([0,1]), torch.tensor([1,3])).t() # edge 0 = 0-&gt;1 # edge 1 = 1-&gt;2 # edge 2 = 0-&gt;1  # combination 0,1:     0-&gt;1, 1-&gt;2 # combination 0,2:     0-&gt;1, 0-&gt;1 print(x) In\u00a0[\u00a0]: Copied! <pre>src_edges = torch.index_select(t.data.edge_index, dim=1, index=x[0])\nprint(src_edges)\n</pre> src_edges = torch.index_select(t.data.edge_index, dim=1, index=x[0]) print(src_edges) In\u00a0[\u00a0]: Copied! <pre>dst_edges = torch.index_select(t.data.edge_index, dim=1, index=x[1])\nprint(dst_edges)\n</pre> dst_edges = torch.index_select(t.data.edge_index, dim=1, index=x[1]) print(dst_edges) In\u00a0[\u00a0]: Copied! <pre>#select all indices where \ntorch.where(src_edges[1,:] == dst_edges[0,:])[0]\nx[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n</pre>  #select all indices where  torch.where(src_edges[1,:] == dst_edges[0,:])[0] x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]] In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/trp_higher_order/","title":"Higher-Order Models for Time-Respecting Paths","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import pathpyG as pp\n\npp.config['torch']['device'] = 'cpu'\n</pre> import pathpyG as pp  pp.config['torch']['device'] = 'cpu' In\u00a0[2]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nprint(t)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) print(t) <pre>Temporal Graph with 4 nodes, 6 unique edges and 10 events in [1.0, 6.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> <p>To better understand this temporal graph, we can again create a directed acyclic graph that represents the topology of time-respecting paths:</p> In\u00a0[3]: Copied! <pre>e_i = pp.algorithms.lift_order_temporal(t, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\npp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]);\n</pre> e_i = pp.algorithms.lift_order_temporal(t, delta=1) dag = pp.Graph.from_edge_index(e_i) pp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 930.41it/s]\n</pre> <p>For $\\delta=1$, we again have the following time-respecting paths:</p> <p>Length one: a -&gt; b b -&gt; a b -&gt; c c -&gt; b c -&gt; d d -&gt; c Length two: a -&gt; b -&gt; a (twice) b -&gt; a -&gt; b a -&gt; b -&gt; c b -&gt; c -&gt; b c -&gt; b -&gt; a d -&gt; c -&gt; d Length three: a -&gt; b -&gt; a -&gt; b b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b b -&gt; c -&gt; b -&gt; a Length four: a -&gt; b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b -&gt; a</p> <p>As you can see, these time-respecting paths are actually very similar to the paths data that we have previously represented using the <code>PathData</code> object. In fact, we could - in theory - first extract all time-respecting paths of all lengths, add them to a <code>PathData</code> object and then use the <code>MultiOderModel</code> class to generate higher-order De Bruijn graph models of all orders. In the example above, since we have paths of length one to four, we could create higher-order models with orders from one to four.</p> <p>However, this approach would not be efficient for large temporal graphs, as it is computationally expensive to calculate all possible time-respecting paths as well as subpaths of length $k$, especially for larger values of $\\delta$. To avoid this bottleneck, <code>pathpyG</code> uses a smarter, GPU-based algorithm to calculate time-respecting paths of length $k$ that are needed for a given order $k$.</p> <p>For the example above, we can generate all higher-order models up to order four as follows:</p> In\u00a0[4]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=4)\n\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=4)  print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 6 nodes and 4 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Remember that in a $k$-th order model nodes capture paths of length $k-1$, while edges capture paths of length $k$.</p> <p>This implies that the first-order model has four nodes and six edges, which simply corresponds to the time-aggregated weighted graph for our example temporal network.</p> In\u00a0[5]: Copied! <pre>print(m.layers[1])\npp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes]);\n</pre> print(m.layers[1]) pp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes]); <pre>Undirected graph with 4 nodes and 6 (directed) edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 1])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>For the second-order model, we have six nodes, which map to the six different edges (each edge trivially being a time-respecting path of length one) of the temporal graph. The six edges in the second-order model represent the six different time-respecting paths of length two (see above). Since the time-respecting path $a \\rightarrow b \\rightarrow a$  occurs twice at different times, we have one edge with weight two.</p> In\u00a0[6]: Copied! <pre>print(m.layers[2])\nprint(m.layers[2].data.edge_weight)\npp.plot(m.layers[2], node_label=m.layers[2].mapping.node_ids.tolist());\n</pre> print(m.layers[2]) print(m.layers[2].data.edge_weight) pp.plot(m.layers[2], node_label=m.layers[2].mapping.node_ids.tolist()); <pre>Directed graph with 6 nodes and 6 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\ntensor([2., 1., 1., 1., 1., 1.])\n</pre> <p>For the third-oder mode, we have four edges representing the four diffeerent time-respecting paths of length three in the temporal graph above:</p> In\u00a0[7]: Copied! <pre>print(m.layers[3])\npp.plot(m.layers[3], node_label=m.layers[3].mapping.node_ids.tolist());\n</pre> print(m.layers[3]) pp.plot(m.layers[3], node_label=m.layers[3].mapping.node_ids.tolist()); <pre>Directed graph with 6 nodes and 4 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>And finally, for the model with order $k=4$ we only have two edges, representing the two time-respecting paths $a \\rightarrow b \\rightarrow a \\rightarrow b \\rightarrow a$ and $a \\rightarrow b \\rightarrow c \\rightarrow b \\rightarrow a$:</p> In\u00a0[8]: Copied! <pre>print(m.layers[4])\npp.plot(m.layers[4], node_label=m.layers[4].mapping.node_ids.tolist());\n</pre> print(m.layers[4]) pp.plot(m.layers[4], node_label=m.layers[4].mapping.node_ids.tolist()); <pre>Directed graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Intuitively, since in our example there are no time-respecting paths longer than four, if we were to generate a multi-order model with De Bruijn graphs with orders larger than four, those graphs cannot contain any edges. We see this in the following example. The first-order graph is simply the time-aggregated weighted graph, i.e. the number of nodes is equal to the number of nodes in the temporal graph and the number of edges is equal to the number of different time-stamped edges. In each graph of order $k&gt;1$, the number of nodes corresponds to the number of edges in the graph with order $k-1$, since each of those nodes corresponds to a time-respecting path of length $k-1$, which are represented by edges in a $k-1$-th order gaph. This implies that the graph with order five has two nodes, which are the two time-respecting paths of length four. Those nodes are not connected since there is no time-respecting path with length five.</p> In\u00a0[9]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=5)\n\nprint(m.layers[4])\nprint(m.layers[5])\npp.plot(m.layers[5], node_label=m.layers[5].mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=5)  print(m.layers[4]) print(m.layers[5]) pp.plot(m.layers[5], node_label=m.layers[5].mapping.node_ids.tolist()); <pre>Directed graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nUndirected graph with 2 nodes and 0 (directed) edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2, 5])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([0])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[2]: Copied! <pre># pp.config['torch']['device'] = 'cuda'\n</pre> # pp.config['torch']['device'] = 'cuda' In\u00a0[10]: Copied! <pre>t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False)\nprint(t_ants)\n</pre> t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False) print(t_ants) <pre>Temporal Graph with 89 nodes, 1298 unique edges and 3822 events in [0.0, 1438.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3822])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3822])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3822])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[11]: Copied! <pre>t_email = pp.io.read_csv_temporal_graph('../data/manufacturing_email.tedges', header=False)\nprint(t_email)\n</pre> t_email = pp.io.read_csv_temporal_graph('../data/manufacturing_email.tedges', header=False) print(t_email) <pre>Temporal Graph with 167 nodes, 6501 unique edges and 165854 events in [1262454016.0, 1285884544.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([165854])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([165854])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([165854])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[12]: Copied! <pre>t_sp = pp.io.read_csv_temporal_graph('../data/sociopatterns_highschool_2013.tedges', header=False)\nprint(t_sp)\n</pre> t_sp = pp.io.read_csv_temporal_graph('../data/sociopatterns_highschool_2013.tedges', header=False) print(t_sp) <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 t_sp = pp.io.read_csv_temporal_graph('../data/sociopatterns_highschool_2013.tedges', header=False)\n      2 print(t_sp)\n\nFile /workspaces/pathpyG/src/pathpyG/io/pandas.py:399, in read_csv_temporal_graph(filename, sep, header, is_undirected, timestamp_format, time_rescale, **kwargs)\n    397     df = pd.read_csv(filename, header=0, sep=sep)\n    398 else:\n--&gt; 399     df = pd.read_csv(filename, header=None, sep=sep)\n    400 return df_to_temporal_graph(df, is_undirected=is_undirected, timestamp_fromat=timestamp_format, time_rescale=time_rescale, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211, in deprecate_kwarg.&lt;locals&gt;._deprecate_kwarg.&lt;locals&gt;.wrapper(*args, **kwargs)\n    209     else:\n    210         kwargs[new_arg_name] = new_arg_value\n--&gt; 211 return func(*args, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper(*args, **kwargs)\n    325 if len(args) &gt; num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--&gt; 331 return func(*args, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\n    935 kwds_defaults = _refine_defaults_read(\n    936     dialect,\n    937     delimiter,\n   (...)\n    946     defaults={\"delimiter\": \",\"},\n    947 )\n    948 kwds.update(kwds_defaults)\n--&gt; 950 return _read(filepath_or_buffer, kwds)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605, in _read(filepath_or_buffer, kwds)\n    602 _validate_names(kwds.get(\"names\", None))\n    604 # Create the parser.\n--&gt; 605 parser = TextFileReader(filepath_or_buffer, **kwds)\n    607 if chunksize or iterator:\n    608     return parser\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442, in TextFileReader.__init__(self, f, engine, **kwds)\n   1439     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1441 self.handles: IOHandles | None = None\n-&gt; 1442 self._engine = self._make_engine(f, self.engine)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735, in TextFileReader._make_engine(self, f, engine)\n   1733     if \"b\" not in mode:\n   1734         mode += \"b\"\n-&gt; 1735 self.handles = get_handle(\n   1736     f,\n   1737     mode,\n   1738     encoding=self.options.get(\"encoding\", None),\n   1739     compression=self.options.get(\"compression\", None),\n   1740     memory_map=self.options.get(\"memory_map\", False),\n   1741     is_text=is_text,\n   1742     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1743     storage_options=self.options.get(\"storage_options\", None),\n   1744 )\n   1745 assert self.handles is not None\n   1746 f = self.handles.handle\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    851 elif isinstance(handle, str):\n    852     # Check whether the filename is to be opened in binary mode.\n    853     # Binary mode does not support 'encoding' and 'newline'.\n    854     if ioargs.encoding and \"b\" not in ioargs.mode:\n    855         # Encoding\n--&gt; 856         handle = open(\n    857             handle,\n    858             ioargs.mode,\n    859             encoding=ioargs.encoding,\n    860             errors=errors,\n    861             newline=\"\",\n    862         )\n    863     else:\n    864         # Binary mode\n    865         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '../data/sociopatterns_highschool_2013.tedges'</pre> <p>To generate a <code>MultiOderModel</code> consisting of multiple layers of higher-order De Bruijn graph models, we can use the <code>MultiOderModel.from_temporal_graph</code> method. We can further specify the maximum order of the highest-order layer, as well as the maximum time difference $\\delta$ for time-respecting paths.</p> <p>For the ants, we consider time-respecting paths with a maximum time difference of 30 seconds up to length four:</p> In\u00a0[6]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 89 nodes and 947 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([89, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 947 nodes and 1780 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 1780 nodes and 2410 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 2410 nodes and 3292 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3292])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>For the E-Mail communication network, we use time-respecting paths up to length four with a maximum time difference of one hour.</p> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_email, delta=3600, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_email, delta=3600, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 167 nodes and 5784 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([167, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 5784 nodes and 25596 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([25596])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 25596 nodes and 47326 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([25596, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([47326])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 47326 nodes and 67801 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([47326, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([67801])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>And finally, for the largest data set from the Sociopatterns collaboration, we use a maximum time difference of 15 minutes. As you can see below, we can efficiently generate a 5-th order model despite using a temporal graph with more than 188,000 time-stamped edges and considering all time-respecting paths up to length five with a large maximum time difference. Thanks to the use of GPU-accelerated operations, creating such a model takes less than 12 seconds on an (old) RTX 2090 GPU.</p> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=900, max_order=5)\nprint(m.layers[1])\nprint(m.layers[5])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=900, max_order=5) print(m.layers[1]) print(m.layers[5]) <pre>Directed graph with 327 nodes and 5818 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([327, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5818])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 16307 nodes and 8712 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([16307, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([8712])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>How can we use such higher-order graph models for graph learning tasks? We will demonstrate this in the next unit of our tutorial.</p>"},{"location":"tutorial/trp_higher_order/#higher-order-models-for-time-respecting-paths-in-temporal-graphs","title":"Higher-Order Models for Time-Respecting Paths in Temporal Graphs\u00b6","text":""},{"location":"tutorial/trp_higher_order/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/trp_higher_order/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In the previous tutorial, we have seen how we can use higher-order models to model paths in complex networks. In this example, paths were directly given in terms of sequences of nodes traversed by some process (like a random walk). We have further seen that higher-order De Bruijn graph models can be used to capture patterns that influence the causal topology of a complex network, i.e. which nodes can possibly influence each other via paths. The same is true for time-respecting paths in a temporal graph. Due to the fact that time-stamped edges need to occur in the correct temporal ordering (and within a given time interval based on the maximum time difference $\\delta$), the causal topology given by time-respecting paths can be very different from what we would expect from the (static) topology of links.</p> <p>In the following, we will show how we can easiy and efficiently construct higher-order models for time-respecting paths in a temporal graph. To illustrate this, we use the same toy example as before:</p>"},{"location":"tutorial/trp_higher_order/#constructing-higher-order-de-bruijn-graph-models-for-empirical-temporal-networks","title":"Constructing Higher-Order De Bruijn Graph Models for Empirical Temporal Networks\u00b6","text":"<p>Let us now use <code>pathpyG</code> to construcct higher-order De Bruijn graph models for time-respecting paths in empirical temporal network. For this, we first read a number of temporal graphs using <code>TemporalGraph.from_csv</code>. In the following, we use the following three publicly available data sets:</p> <ul> <li>Antenna interactions between ants in a colony (Blonder and Dornhaus, 2011)</li> <li>E-Mail exchanges in a manufacturing company (Nurek and Michalski, 2020)</li> <li>Face-to-face interactions in a highschool (Mastrandrea, Fournet, Barrat, 2015)</li> </ul>"},{"location":"tutorial/visualisation/","title":"Interactive Graph Visualisation","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import pathpyG as pp\nimport torch\nprint('Running on', pp.config['torch']['device'])\n</pre> import pathpyG as pp import torch print('Running on', pp.config['torch']['device']) <pre>Running on cpu\n</pre> <p>With these preparations complete, we are ready to construct our first graph. This is achieved through the <code>Graph.from_edge_list</code> constructor provided by <code>pathpyG</code>, a method that allows us to transform a list of edges into a basic graphical representation.</p> In\u00a0[\u00a0]: Copied! <pre>g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']])\npp.plot(g, node_label=list(g.mapping.node_ids), edge_color='gray')\n</pre> g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']]) pp.plot(g, node_label=list(g.mapping.node_ids), edge_color='gray') Out[\u00a0]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2c7432ca60&gt;</pre> <p>After successfully creating a simple graph using <code>pathpyG</code>, our next step is to examine its structure. This is a crucial part of the process as it gives us an initial understanding of the complexity and scale of our graph. By printing out the number of nodes and edges, we gain insight into the size and connectivity of the graph.</p> <p>Although it may seem unnecessary for this simple graph, it's good practice to gather information about the number of nodes and edges before attempting to visualize it. This preemptive step is crucial, especially when dealing with larger graphs. Visualizing extensive networks can be a time-consuming or even unfeasible task, depending on the sheer volume of elements that need to be represented. Therefore, understanding the graph's scale upfront helps in efficiently planning the visualization process and avoiding potential complications that could arise with larger datasets.</p> In\u00a0[3]: Copied! <pre>f'Our graph has {g.n} nodes and {g.m} edges.'\n</pre> f'Our graph has {g.n} nodes and {g.m} edges.' Out[3]: <pre>'Our graph has 3 nodes and 2 edges.'</pre> In\u00a0[4]: Copied! <pre>pp.plot(g)\n</pre> pp.plot(g) Out[4]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2c7432c3a0&gt;</pre> In\u00a0[5]: Copied! <pre>pp.plot(g,backend='matplotlib');\n</pre> pp.plot(g,backend='matplotlib'); In\u00a0[6]: Copied! <pre>pp.plot(g,backend='matplotlib',layout='fr')\n</pre> pp.plot(g,backend='matplotlib',layout='fr') Out[6]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b528eb550&gt;</pre> <p>Additionally, <code>pathpyG</code> offers the flexibility to incorporate custom layout algorithms. If you have developed your own method or have specific requirements for node positioning, you can directly provide the node coordinates to the visualization. This capability ensures that <code>pathpyG</code> can cater to a wide range of visualization needs, from simple and automatic layouts to highly customized and complex arrangements, making it a versatile tool in the field of data visualization.</p> In\u00a0[7]: Copied! <pre>layout = {'a':[0,0],'b':[1,1],\"c\":[2,2]}\npp.plot(g,backend='matplotlib',layout=layout)\n</pre> layout = {'a':[0,0],'b':[1,1],\"c\":[2,2]} pp.plot(g,backend='matplotlib',layout=layout) Out[7]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b52743af0&gt;</pre> In\u00a0[8]: Copied! <pre>style = {}\nstyle['node_color'] = (255,1,255) # RGB tuple\nstyle['edge_color'] = 'green'     # Color name as str\npp.plot(g,**style)\n</pre> style = {} style['node_color'] = (255,1,255) # RGB tuple style['edge_color'] = 'green'     # Color name as str pp.plot(g,**style) Out[8]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b52743880&gt;</pre> <p>In <code>pathpyG</code>, there are various methods for assigning styles to objects, each offering a different level of customization and control. A straightforward approach, as previously shown, involves using a single value, such as a color string (e.g., <code>'green'</code>) or an RGB tuple (e.g., <code>(255,1,255)</code>). Applying this single value uniformly alters the appearance of all elements within a specific category, providing a quick and easy way to set a general style. However, for more detailed styling, one can utilize a <code>list</code> of values. In this approach, each value in the <code>list</code> is associated with an element according to its index position. This method is particularly familiar and efficient when working with tensors, where the association of values to elements is often index-based.</p> <p>Additionally, a more tailored approach can be employed through the use of dictionaries. In this case, each element id is paired with a corresponding value in the <code>dict</code>. Elements not included in the dictionary are assigned default values, ensuring that every element is styled, albeit some with custom and others with default styles. The types of values that can be used in these styling methods are diverse, including strings, integers, floats, and tuples, each type depending on the specific styling parameter being adjusted. This flexibility in value types and assignment methods allows for a high degree of customization, enabling the creation of visually distinct and information-rich visualizations.</p> In\u00a0[9]: Copied! <pre>style = {}\nstyle['node_color'] = ['red', 'green','blue'] # list based approach\nstyle['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach\nstyle['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value\nstyle['edge_color'] = ['orange','#00FF00']    # hex based color\npp.plot(g,**style)\n</pre> style = {} style['node_color'] = ['red', 'green','blue'] # list based approach style['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach style['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value style['edge_color'] = ['orange','#00FF00']    # hex based color pp.plot(g,**style) Out[9]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b5279af20&gt;</pre> In\u00a0[10]: Copied! <pre>from matplotlib.pyplot import get_cmap\nmy_map = get_cmap()\nmy_map\n</pre> from matplotlib.pyplot import get_cmap my_map = get_cmap() my_map Out[10]: viridis  underbad over  In\u00a0[11]: Copied! <pre>style = {}\nstyle['edge_color'] = [1, 9]      # int values\n\nstyle['node_color'] = pp.algorithms.centrality.betweenness_centrality(g)\nstyle['node_cmap'] = my_map       # new color map from matplotlib for nodes\npp.plot(g,**style)\n</pre> style = {} style['edge_color'] = [1, 9]      # int values  style['node_color'] = pp.algorithms.centrality.betweenness_centrality(g) style['node_cmap'] = my_map       # new color map from matplotlib for nodes pp.plot(g,**style) Out[11]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b560a20b0&gt;</pre> In\u00a0[12]: Copied! <pre>pp.plot(g,filename='test_plot.html')\n</pre> pp.plot(g,filename='test_plot.html') Out[12]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b52743fa0&gt;</pre> In\u00a0[13]: Copied! <pre>n = pp.io.read_netzschleuder_graph('karate', '77')\n</pre> n = pp.io.read_netzschleuder_graph('karate', '77') <pre>Mapping node attributes based on node indices in column `index`\n</pre> In\u00a0[14]: Copied! <pre>pp.plot(n)\n</pre> pp.plot(n) Out[14]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b5279a5c0&gt;</pre> In\u00a0[15]: Copied! <pre>node_color = [n['node_groups',v].item() for v in n.nodes]\npp.plot(n, edge_color='gray',node_color=node_color)\n</pre> node_color = [n['node_groups',v].item() for v in n.nodes] pp.plot(n, edge_color='gray',node_color=node_color) Out[15]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b52743dc0&gt;</pre> In\u00a0[16]: Copied! <pre>t = pp.TemporalGraph.from_edge_list(\n        [\n            (\"a\", \"b\", 1),\n            (\"b\", \"c\", 5),\n            (\"c\", \"d\", 9),\n            (\"d\", \"a\", 9),\n            (\"a\", \"b\", 10),\n            (\"b\", \"c\", 10),\n        ]\n    )\n</pre> t = pp.TemporalGraph.from_edge_list(         [             (\"a\", \"b\", 1),             (\"b\", \"c\", 5),             (\"c\", \"d\", 9),             (\"d\", \"a\", 9),             (\"a\", \"b\", 10),             (\"b\", \"c\", 10),         ]     ) In\u00a0[17]: Copied! <pre>pp.plot(t)\n</pre> pp.plot(t) Out[17]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f2b5279afb0&gt;</pre> <p>Besides the standard formatting options available in <code>pathpyG</code>, temporal plots come with specific options tailored to their unique nature. These specialized settings allow for precise control over the time dimension of the visualization. With the <code>start</code> and <code>end</code> parameters, you can define the exact start time and end time of the simulation, effectively setting the temporal boundaries of your graph. This feature is crucial for focusing on a particular time frame within your dataset. Additionally, the <code>delta</code> option lets you adjust the progression speed through the time steps of your visualization. Here, a value of 1000 translates to a one-second interval, providing a way to calibrate the pace at which the temporal data unfolds. Moreover, the <code>interval</code> option offers the flexibility to either widen or narrow the time intervals considered in the visualization. This feature is particularly useful for either zooming in on finer time-scaled details or zooming out for a broader, more comprehensive view of the temporal dynamics in your network.</p> In\u00a0[18]: Copied! <pre>color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"}\npp.plot(t,node_color=color,start=-1,end=25,delta=1000)\n</pre> color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"} pp.plot(t,node_color=color,start=-1,end=25,delta=1000) Out[18]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f2b527439d0&gt;</pre>"},{"location":"tutorial/visualisation/#interactive-graph-visualization","title":"Interactive Graph Visualization\u00b6","text":""},{"location":"tutorial/visualisation/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/visualisation/#motivation","title":"Motivation\u00b6","text":"<p>This tutorial is specifically designed to guide you through the process of visualizing your data using <code>pathpyG</code>, an advanced data visualization tool. Data visualization is a crucial aspect of data analysis and interpretation, allowing for the transformation of complex datasets into visually appealing and easy-to-understand formats. pathpyG excels in this area by providing a range of functionalities that cater to both beginners and advanced users. Throughout this tutorial, you will be introduced to the basic and advanced features of pathpyG, empowering you to effectively visualize your data. This will not only enhance your understanding of your data but also enable you to communicate your findings more effectively to others.</p> <p>Visualization is a core concept of <code>pathpyG</code> because it bridges the gap between raw data and meaningful visual representations. We, as humans, are wired to process visual information much more rapidly compared to text or audio. This innate ability enables us to quickly identify patterns, outliers, and trends in visual data. Data visualization leverages this capability by graphically representing data, thereby facilitating the swift interpretation of large and complex datasets. Interactive visualizations further this advantage by allowing users to directly engage with the data, exploring and analyzing it in an intuitive and insightful manner. Whether it's understanding the intricate details of microscopic structures or grasping the dynamics of global phenomena, visualizations are instrumental in helping researchers and analysts gain deeper insights and effectively communicate their findings.</p>"},{"location":"tutorial/visualisation/#learning-objectives","title":"Learning objectives\u00b6","text":"<p>In this tutorial, you will learn to master the art of creating simple yet powerful interactive visualizations using <code>pathpyG</code>. You will learn the nuances of customizing the style of your visualizations, enabling you to tailor them to your specific needs and preferences. This customization extends to the aesthetics, layout, and interactive elements, ensuring that your visualizations are not only informative but also engaging. Additionally, the tutorial covers the essential skills needed to save your visualizations in various formats, making it easier to share your work across different platforms and audiences. Lastly, a significant part of the tutorial is dedicated to creating temporal visualizations. These types of visualizations are particularly useful in understanding and presenting data that changes over time, offering dynamic insights into trends and patterns that static visualizations cannot capture. By the end of this tutorial, you will have a comprehensive understanding of how to effectively use pathpyG to create and customize a wide range of visualizations.</p>"},{"location":"tutorial/visualisation/#lets-get-started","title":"Let's Get Started\u00b6","text":"<p>To embark on our journey of visualizing data with <code>pathpyG</code>, the initial step involves initializing and loading the required modules, a crucial process that sets the foundation for our data visualization work. This preparation ensures that all necessary tools and functionalities from <code>pathpyG</code> are at our disposal.</p> <p>In anticipation of enhancing our graphs with additional attributes, we also include the <code>torch</code> package in our setup. <code>torch</code> is renowned for its robust capabilities in data processing and machine learning, and its inclusion allows us to enrich our graphs with more complex and informative attributes.</p>"},{"location":"tutorial/visualisation/#the-plot-function","title":"The <code>plot</code> Function\u00b6","text":"<p>The <code>plot</code> function in <code>pathpyG</code> stands out as the simplest and most direct method for creating visualizations. Designed to encapsulate all the plotting capabilities of <code>pathpyG</code> in a single command, it streamlines the process of generating quick and efficient plots. This functionality is particularly beneficial for users who seek immediate visual feedback from their data without delving into more complex coding. The only prerequisite for using this function is the <code>Graph</code> object, which serves as the foundation for the visualization. Moreover, when working within an interactive environment, such as a <code>Jupyter notebook</code>, the <code>plot</code> function is particularly powerful. In such settings, invoking the <code>plot</code> command will automatically generate and display an interactive visualization. This feature is particularly beneficial as it allows for immediate visual feedback, making it an ideal tool for exploratory data analysis where quick and efficient visualization is key.</p>"},{"location":"tutorial/visualisation/#kwargs-in-the-plot-function","title":"<code>kwargs</code> in the <code>plot</code> function\u00b6","text":"<p>In <code>pathpyG</code>, the customization of your plot is managed through keyword arguments (kwargs), where each customization is specified as a keyword followed by its corresponding value. This approach is what gives the <code>plot</code> function its remarkable flexibility, allowing it to adapt to a wide variety of plotting requirements. Whether you're aiming for a simple graph or a complex, multi-faceted visualization, the keyword arguments provide the tools to tailor your plot precisely to your needs.</p> <p>However, this wealth of options can be somewhat overwhelming for beginners, given the extensive range of available choices. But worry not, as we will guide you through the most essential and basic options, ensuring you have a solid foundation to start from. By mastering these fundamental aspects, you'll be well on your way to effectively utilizing <code>pathpyG</code>'s plot function, gradually building up to more advanced features as you gain confidence and expertise.</p>"},{"location":"tutorial/visualisation/#plotting-backends","title":"Plotting Backends\u00b6","text":"<p>In the diverse world of data visualization, there is no one-size-fits-all technique, as different scenarios demand different approaches. Recognizing this, <code>pathpyG</code> offers a variety of plotting backends, each tailored for specific use cases, ensuring that users have the right tools for their unique requirements.</p> <ul> <li><p>For instance, <code>pathpyG</code> facilitates interactive visualizations, as previously demonstrated, which are immensely useful for dynamic exploration of data. This feature is particularly beneficial in educational settings, exploratory data analysis, and communication, where interaction with the data can lead to deeper understanding and insights.</p> </li> <li><p>On the other hand, <code>pathpyG</code> also integrates with matplotlib, a widely recognized package for creating static plots. This is especially efficient for visualizing large graphs where interactivity might be less critical.</p> </li> <li><p>Additionally, <code>pathpyG</code> caters to the academic and publication community by offering tikz plots, which are highly valued in formal publications for their precision and quality. (Note that for generating tikz plots, currently, the installation of <code>latexmk</code> is necessary to produce the corresponding <code>.tex</code> and <code>.pdf</code> files.)</p> </li> </ul> <p>Let's generate a static png image using the <code>matplotlib</code> backend:</p>"},{"location":"tutorial/visualisation/#quick-introduction-to-layouts","title":"Quick Introduction to Layouts\u00b6","text":"<p>An important aspect to consider is the layout of your plot. The previous plot we generated is static, meaning the positions of the nodes are fixed and do not change. This fixed arrangement presents a unique challenge, as finding the optimal placement for nodes and edges to convey information effectively is not a straightforward task. To assist with this, <code>pathpyG</code> supports simple layout functions designed to create visually appealing and coherent graphs. By default, nodes are assigned random locations for computational efficiency. However, this arrangement can be significantly improved with the use of the <code>layout</code> keyword in the <code>plot</code> function, allowing for more structured and meaningful representations of your graph.</p> <p>For example, <code>pathpyG</code> includes support for sophisticated layout algorithms, such as the Fruchterman-Reingold algorithm for force-directed layouts. This can be activated using the <code>\"fr\"</code> option, which applies a physics-based approach to arrange nodes and edges in a way that visually represents their relational dynamics. Such force-directed layouts are particularly useful for highlighting the underlying structure and relationships within the data.</p>"},{"location":"tutorial/visualisation/#styling-your-plots","title":"Styling Your Plots\u00b6","text":"<p>To enhance the effectiveness and appeal of our visualizations in <code>pathpyG</code>, styling of our plots becomes a key aspect. The ability to style your plots is not just about aesthetic appeal; it is about effectively conveying more information through visual means. Depending on the type of plot you are working with, there are multiple styling options available to tailor your visualization to your specific needs. The fundamental principle here is that the styles applied to your plot should not be dependent on the data of your model. In other words, you should be able to present the same data in different styles, depending on the context or the information you wish to highlight. To facilitate this, styles are organized in dictionaries, which are then incorporated into the <code>plot</code> function.</p> <p>For network plots, where the focus is on the topology of the data, there are several basic styling options you can adjust, including the <code>size</code>, <code>color</code>, and <code>opacity</code> of each node and edge object. These options provide a foundational level of customization, allowing you to make your graph more readable and visually appealing. However, the styling possibilities extend further, varying according to the specific kind of plot you are creating. To distinguish between the styling of edges and nodes, a prefix corresponding to each element type is added to the keyword, such as <code>node_size</code>. This distinction ensures that your styling choices are accurately applied to the intended elements of the graph, further enhancing the clarity and effectiveness of your visualization.</p>"},{"location":"tutorial/visualisation/#colormaps","title":"Colormaps\u00b6","text":"<p>In many instances, particularly when visualizing numerical data, the use of color gradients to represent values can greatly enhance the clarity and effectiveness of a plot. <code>pathpyG</code> addresses this need through its native support for <code>colormaps</code>. When the colors of node or edge elements are defined using <code>int</code> or <code>float</code> values, <code>pathpyG</code> automatically assigns colors based on these colormaps, effectively interpolating the correct color value for each element. By default, <code>pathpyG</code> offers a simple colormap that transitions from red to green, sufficient for many basic visualization needs. However, for more customized or advanced styling, users have the option to utilize any colormap from the extensive color palettes provided by <code>matplotlib</code> or <code>seaborn</code>. These libraries offer a wide range of color schemes, enabling you to select the perfect palette to convey the nuances of your data.</p>"},{"location":"tutorial/visualisation/#saving-plots","title":"Saving Plots\u00b6","text":"<p>In <code>pathpyG</code>, sharing your plots or incorporating them into various mediums is facilitated by the ability to save them as files. This functionality is conveniently accessed by simply adding the <code>filename</code> keyword within the plot function. When you specify a filename, <code>pathpyG</code> assigns the appropriate backend to use based on the file extension provided. For instance, if you save your file with an <code>.html</code> extension, <code>pathpyG</code> generates a standalone interactive visualization, perfect for web applications or interactive presentations. On the other hand, if you choose to save your plot as a <code>.png</code> file, a static image is created using the <code>matplotlib</code> backend, ideal for including in documents, reports, or presentations where interactivity is not required. Additionally, for those seeking to incorporate plots into academic papers or publications, saving the file with a <code>.tex</code> extension activates the <code>tikz</code> backend. This feature is particularly beneficial for creating high-quality, publication-ready figures.</p>"},{"location":"tutorial/visualisation/#larger-network-visualizations","title":"Larger Network Visualizations\u00b6","text":"<p>Having covered the basics, we are now well-prepared to venture into the realm of larger network visualizations using <code>pathpyG</code>.</p>"},{"location":"tutorial/visualisation/#temporal-network-visualizations","title":"Temporal Network Visualizations\u00b6","text":"<p>In the realm of network analysis, <code>pathpyG</code> particularly excels in handling and visualizing temporal graphs, a domain where both nodes and edges can change their properties over time. This dynamic aspect of temporal graphs adds a layer of complexity and richness to data analysis, capturing the evolution of relationships and properties within the network. <code>pathpyG</code> supports this advanced functionality, allowing users to apply the same versatile <code>plot</code> function used for static graphs to <code>TemporalGraph</code> data structures. This integration means that all the customization options, styling features, and layout choices previously explored for static network visualizations are also applicable to temporal graphs. The ability to utilize these tools in the context of temporal data opens up a world of possibilities for in-depth analysis and insightful visualization of networks where time plays a crucial role. Whether you're tracking changes in social networks, analyzing traffic patterns, or studying dynamic biological systems, <code>pathpyG</code>'s capabilities in temporal network visualization provide a powerful tool to uncover and illustrate the temporal dynamics inherent in these complex systems.</p>"},{"location":"tutorial/wl/","title":"Wl","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nimport torch\nfrom torch_geometric import EdgeIndex\n</pre> import pathpyG as pp import torch from torch_geometric import EdgeIndex In\u00a0[2]: Copied! <pre>g1 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'c', 'd']))\nprint(g1.data.edge_index)\ng2 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'c', 'd']))\nprint(g2.data.edge_index)\ng = g1 + g2\nprint(g.data.edge_index)\nprint(g)\n</pre> g1 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'c', 'd'])) print(g1.data.edge_index) g2 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'c', 'd'])) print(g2.data.edge_index) g = g1 + g2 print(g.data.edge_index) print(g) <pre>EdgeIndex([[0, 1, 1],\n           [1, 2, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\nEdgeIndex([[0, 1, 1],\n           [1, 2, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\nEdgeIndex([[0, 0, 1, 1, 1, 1],\n           [1, 1, 2, 3, 2, 3]], sparse_size=(4, 4), nnz=6, sort_order=row)\nDirected graph with 4 nodes and 6 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[3]: Copied! <pre>g1 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'c', 'd']))\nprint(g1.data.edge_index)\ng2 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['e', 'f', 'g', 'h']))\nprint(g2.data.edge_index)\ng = g1 + g2\nprint(g.data.edge_index)\nprint(g)\n</pre> g1 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'c', 'd'])) print(g1.data.edge_index) g2 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['e', 'f', 'g', 'h'])) print(g2.data.edge_index) g = g1 + g2 print(g.data.edge_index) print(g) <pre>EdgeIndex([[0, 1, 1],\n           [1, 2, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\nEdgeIndex([[0, 1, 1],\n           [1, 2, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\nEdgeIndex([[0, 1, 1, 4, 5, 5],\n           [1, 2, 3, 5, 6, 7]], sparse_size=(8, 8), nnz=6, sort_order=row)\nDirected graph with 8 nodes and 6 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[4]: Copied! <pre>g1 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'c', 'd']))\nprint(g1.data.edge_index)\ng2 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'g', 'h']))\nprint(g2.data.edge_index)\ng = g1 + g2\nprint(g.data.edge_index)\nprint(g)\n</pre> g1 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'c', 'd'])) print(g1.data.edge_index) g2 = pp.Graph.from_edge_index(torch.tensor([[0,1,1],[1,2,3]]), mapping=pp.IndexMap(['a', 'b', 'g', 'h'])) print(g2.data.edge_index) g = g1 + g2 print(g.data.edge_index) print(g) <pre>EdgeIndex([[0, 1, 1],\n           [1, 2, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\nEdgeIndex([[0, 1, 1],\n           [1, 2, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\nEdgeIndex([[0, 0, 1, 1, 1, 1],\n           [1, 1, 2, 3, 4, 5]], sparse_size=(6, 6), nnz=6, sort_order=row)\nDirected graph with 6 nodes and 6 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[7]: Copied! <pre>def num_labels(d):\n    return len(set(d.values()))\n</pre> def num_labels(d):     return len(set(d.values())) In\u00a0[35]: Copied! <pre>from typing import Tuple, List\n</pre> from typing import Tuple, List In\u00a0[45]: Copied! <pre>def WL_test(g1: pp.Graph, g2: pp.Graph) -&gt; Tuple[bool, List[str], List[str]]:\n    \"\"\"Run Weisfeiler-Leman test on two graphs\"\"\"\n    if g1.mapping is None or g2.mapping is None:\n        raise Exception('Graphs must contain IndexMap that assigns node IDs')\n    if len(set(g1.mapping.node_ids).intersection(g2.mapping.node_ids)) &gt; 0:\n        raise Exception('node identifiers of graphs must not overlap')\n    g_combined = g1 + g2\n    # initialize labels of all ndoes to zero\n    fingerprint = { v:'0' for v in g_combined.nodes }\n    labels = {} \n    label_count = 1\n    stop = False\n    while not stop:\n        new_fingerprint = {} \n        for node in g_combined.nodes:\n            # create new label based on own label and sorted labels of all neighbors\n            n_label = [fingerprint[x] for x in g_combined.successors(node)]\n            n_label.sort()\n            label = str(fingerprint[node]) + str(n_label)\n            # previously unknown label\n            if label not in labels:\n                # create a new label based on next consecutive number\n                labels[label] = label_count\n                label_count += 1 \n            new_fingerprint[node] = labels[label]        \n        if len(set(fingerprint.values())) == len(set(new_fingerprint.values())):\n            # we processed all nodes in both graphs without encountering a new label, so we stop\n            stop = True\n        else:\n            # update fingerprint and continue\n            fingerprint = new_fingerprint.copy()\n    fingerprint_1 = [fingerprint[v] for v in g1.nodes]\n    fingerprint_1.sort()\n    fingerprint_2 = [fingerprint[v] for v in g2.nodes]\n    fingerprint_2.sort()\n    if fingerprint_1 == fingerprint_2:\n        return True, fingerprint_1, fingerprint_2\n    return False, fingerprint_1, fingerprint_2\n</pre> def WL_test(g1: pp.Graph, g2: pp.Graph) -&gt; Tuple[bool, List[str], List[str]]:     \"\"\"Run Weisfeiler-Leman test on two graphs\"\"\"     if g1.mapping is None or g2.mapping is None:         raise Exception('Graphs must contain IndexMap that assigns node IDs')     if len(set(g1.mapping.node_ids).intersection(g2.mapping.node_ids)) &gt; 0:         raise Exception('node identifiers of graphs must not overlap')     g_combined = g1 + g2     # initialize labels of all ndoes to zero     fingerprint = { v:'0' for v in g_combined.nodes }     labels = {}      label_count = 1     stop = False     while not stop:         new_fingerprint = {}          for node in g_combined.nodes:             # create new label based on own label and sorted labels of all neighbors             n_label = [fingerprint[x] for x in g_combined.successors(node)]             n_label.sort()             label = str(fingerprint[node]) + str(n_label)             # previously unknown label             if label not in labels:                 # create a new label based on next consecutive number                 labels[label] = label_count                 label_count += 1              new_fingerprint[node] = labels[label]                 if len(set(fingerprint.values())) == len(set(new_fingerprint.values())):             # we processed all nodes in both graphs without encountering a new label, so we stop             stop = True         else:             # update fingerprint and continue             fingerprint = new_fingerprint.copy()     fingerprint_1 = [fingerprint[v] for v in g1.nodes]     fingerprint_1.sort()     fingerprint_2 = [fingerprint[v] for v in g2.nodes]     fingerprint_2.sort()     if fingerprint_1 == fingerprint_2:         return True, fingerprint_1, fingerprint_2     return False, fingerprint_1, fingerprint_2 In\u00a0[46]: Copied! <pre>g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\ng2 = pp.Graph.from_edge_list([('y', 'z'), ('x', 'y')])\nWL_test(g1, g2)\n</pre> g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')]) g2 = pp.Graph.from_edge_list([('y', 'z'), ('x', 'y')]) WL_test(g1, g2) Out[46]: <pre>(True, [3, 4, 5], [3, 4, 5])</pre> In\u00a0[26]: Copied! <pre>d = {'a': 0, 'b': 1, 'c': 0}\nnum_labels(d)\n</pre> d = {'a': 0, 'b': 1, 'c': 0} num_labels(d) Out[26]: <pre>2</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/xx_temporal_centralities/","title":"Xx temporal centralities","text":"In\u00a0[2]: Copied! <pre>import torch\n\nimport pathpyG as pp\n\nprint('Running on', pp.config['torch']['device'])\n</pre> import torch  import pathpyG as pp  print('Running on', pp.config['torch']['device']) <pre>Running on cpu\n</pre> In\u00a0[3]: Copied! <pre># Put this as his in conftest as 'simple_paths_centralities'\npaths = pp.WalkData()\npaths.add(torch.tensor([[2, 1, 3], [1, 3, 5]]))  \npaths.add(torch.tensor([[0, 1], [1, 3]]))  \npaths.add(torch.tensor([[3], [4]]))\n\nsimple_paths_centralities = paths\n</pre> # Put this as his in conftest as 'simple_paths_centralities' paths = pp.WalkData() paths.add(torch.tensor([[2, 1, 3], [1, 3, 5]]))   paths.add(torch.tensor([[0, 1], [1, 3]]))   paths.add(torch.tensor([[3], [4]]))  simple_paths_centralities = paths In\u00a0[4]: Copied! <pre># paths = pp.PathData()\n# paths.add_walk(torch.tensor([[0,2,3],[2,3,4]]),freq=3) # A -&gt; C -&gt; D\n# paths.add_walk(torch.tensor([[0,2],[2,3]])) # A -&gt; C -&gt; D\n# paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E\n# paths.add_walk(torch.tensor([[4],[5]]))\n# paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E\n</pre> # paths = pp.PathData() # paths.add_walk(torch.tensor([[0,2,3],[2,3,4]]),freq=3) # A -&gt; C -&gt; D # paths.add_walk(torch.tensor([[0,2],[2,3]])) # A -&gt; C -&gt; D # paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E # paths.add_walk(torch.tensor([[4],[5]])) # paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E  In\u00a0[5]: Copied! <pre>index, edge_weights = paths.edge_index_k_weighted(k=2)\nindex, edge_weights\n</pre> index, edge_weights = paths.edge_index_k_weighted(k=2) index, edge_weights Out[5]: <pre>(tensor([[[0, 1],\n          [1, 3],\n          [2, 1]],\n \n         [[1, 3],\n          [3, 5],\n          [1, 3]]]),\n tensor([1., 1., 1.]))</pre> In\u00a0[6]: Copied! <pre>index, edge_weights = paths.edge_index_k_weighted(k=1)\n</pre> index, edge_weights = paths.edge_index_k_weighted(k=1) In\u00a0[7]: Copied! <pre>from collections import defaultdict\n\ndef node_traversals(paths):\n    \"\"\"Calculates the number of times any path traverses each of the nodes.\n\n    Parameters\n    ----------\n    paths: Paths\n\n    Returns\n    -------\n    dict\n    \"\"\"\n    traversals = defaultdict(lambda: 0)\n    for path_id, path_edgelist in paths.paths.items():\n        path_seq = paths.walk_to_node_seq(path_edgelist)\n        for node in path_seq:\n            traversals[node.item()] += paths.path_freq[path_id]\n    return traversals\n</pre> from collections import defaultdict  def node_traversals(paths):     \"\"\"Calculates the number of times any path traverses each of the nodes.      Parameters     ----------     paths: Paths      Returns     -------     dict     \"\"\"     traversals = defaultdict(lambda: 0)     for path_id, path_edgelist in paths.paths.items():         path_seq = paths.walk_to_node_seq(path_edgelist)         for node in path_seq:             traversals[node.item()] += paths.path_freq[path_id]     return traversals In\u00a0[10]: Copied! <pre>from pathpyG.algorithms.centrality import node_traversals\n</pre> from pathpyG.algorithms.centrality import node_traversals In\u00a0[11]: Copied! <pre>node_traversals(paths)\n</pre> node_traversals(paths) <pre>\n---------------------------------------------------------------------------\nRecursionError                            Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 node_traversals(paths)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\n    [... skipping similar frames: __getattr__.&lt;locals&gt;.wrapper at line 311 (2968 times)]\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:299, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    298 def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n--&gt; 299     if len(args) == 0:\n    300         raise RuntimeError(f'Did not find method {name} with no arguments')\n    301     if isinstance(args[0], TemporalGraph):\n\nRecursionError: maximum recursion depth exceeded while calling a Python object</pre> In\u00a0[13]: Copied! <pre>from pathpyG.algorithms.centrality import visitation_probabilities\n</pre> from pathpyG.algorithms.centrality import visitation_probabilities In\u00a0[14]: Copied! <pre>def test_visitation_probabilities(simple_paths_centralities):\n    traversals_dict = visitation_probabilities(simple_paths_centralities)\n    assert set(traversals_dict.keys()) == {0,1,2,3,4,5}\n    assert traversals_dict[0] == 1/9\n    assert traversals_dict[1] == 2/9\n    assert traversals_dict[2] == 1/9\n    assert traversals_dict[3] == 3/9\n    assert traversals_dict[4] == 1/9\n    assert traversals_dict[5] == 1/9\n\ntest_visitation_probabilities(simple_paths_centralities)\n</pre> def test_visitation_probabilities(simple_paths_centralities):     traversals_dict = visitation_probabilities(simple_paths_centralities)     assert set(traversals_dict.keys()) == {0,1,2,3,4,5}     assert traversals_dict[0] == 1/9     assert traversals_dict[1] == 2/9     assert traversals_dict[2] == 1/9     assert traversals_dict[3] == 3/9     assert traversals_dict[4] == 1/9     assert traversals_dict[5] == 1/9  test_visitation_probabilities(simple_paths_centralities) <pre>\n---------------------------------------------------------------------------\nRecursionError                            Traceback (most recent call last)\nCell In[14], line 11\n      8     assert traversals_dict[4] == 1/9\n      9     assert traversals_dict[5] == 1/9\n---&gt; 11 test_visitation_probabilities(simple_paths_centralities)\n\nCell In[14], line 2, in test_visitation_probabilities(simple_paths_centralities)\n      1 def test_visitation_probabilities(simple_paths_centralities):\n----&gt; 2     traversals_dict = visitation_probabilities(simple_paths_centralities)\n      3     assert set(traversals_dict.keys()) == {0,1,2,3,4,5}\n      4     assert traversals_dict[0] == 1/9\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\n    [... skipping similar frames: __getattr__.&lt;locals&gt;.wrapper at line 311 (2967 times)]\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:299, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    298 def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n--&gt; 299     if len(args) == 0:\n    300         raise RuntimeError(f'Did not find method {name} with no arguments')\n    301     if isinstance(args[0], TemporalGraph):\n\nRecursionError: maximum recursion depth exceeded while calling a Python object</pre> In\u00a0[339]: Copied! <pre>test_shortest_paths(paths)\n</pre> test_shortest_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> In\u00a0[340]: Copied! <pre># @betweenness.register(Paths)\ndef betweenness(paths, normalized=False):\n    \"\"\"Calculates the betweenness of nodes based on observed shortest paths\n    between all pairs of nodes\n\n    Parameters\n    ----------\n    paths:\n        Paths object\n    normalized: bool\n        normalize such that largest value is 1.0\n\n    Returns\n    -------\n    dict\n    \"\"\"\n    assert isinstance(paths, pp.PathData), \"argument must be an instance of pathpy.Paths\"\n    node_centralities = defaultdict(lambda: 0)\n\n    # Log.add('Calculating betweenness in paths ...', Severity.INFO)\n\n    all_paths = shortest_paths(paths)\n\n    for s in all_paths:\n        for d in all_paths[s]:\n            for p in all_paths[s][d]:\n                for x in p[1:-1]:\n                    if s != d != x:\n                        node_centralities[x.item()] += 1.0 / len(all_paths[s][d])\n    if normalized:\n        max_centr = max(node_centralities.values())\n        for v in node_centralities:\n            node_centralities[v] /= max_centr\n    # assign zero values to nodes not occurring on shortest paths\n    nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)]\n    for v in nodes:\n        node_centralities[v] += 0\n    # Log.add('finished.')\n    return node_centralities\n\nbetweenness(paths,normalized=False)\n</pre> # @betweenness.register(Paths) def betweenness(paths, normalized=False):     \"\"\"Calculates the betweenness of nodes based on observed shortest paths     between all pairs of nodes      Parameters     ----------     paths:         Paths object     normalized: bool         normalize such that largest value is 1.0      Returns     -------     dict     \"\"\"     assert isinstance(paths, pp.PathData), \"argument must be an instance of pathpy.Paths\"     node_centralities = defaultdict(lambda: 0)      # Log.add('Calculating betweenness in paths ...', Severity.INFO)      all_paths = shortest_paths(paths)      for s in all_paths:         for d in all_paths[s]:             for p in all_paths[s][d]:                 for x in p[1:-1]:                     if s != d != x:                         node_centralities[x.item()] += 1.0 / len(all_paths[s][d])     if normalized:         max_centr = max(node_centralities.values())         for v in node_centralities:             node_centralities[v] /= max_centr     # assign zero values to nodes not occurring on shortest paths     nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)]     for v in nodes:         node_centralities[v] += 0     # Log.add('finished.')     return node_centralities  betweenness(paths,normalized=False) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> Out[340]: <pre>defaultdict(&lt;function __main__.betweenness.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {1: 3.0, 3: 2.0, 0: 0, 2: 0, 4: 0, 5: 0})</pre> In\u00a0[346]: Copied! <pre>def test_betweenness_paths(simple_paths_centralities):\n    bw = betweenness(simple_paths_centralities,normalized=False)\n    # 1 is in the shortest path between 0-5,2-3,2-5\n    assert bw[1] == 3.0\n    # 1 is in the shortest path between 2-5,1-5\n    assert bw[3] == 2.0\n\ntest_betweenness_paths(paths)\n</pre> def test_betweenness_paths(simple_paths_centralities):     bw = betweenness(simple_paths_centralities,normalized=False)     # 1 is in the shortest path between 0-5,2-3,2-5     assert bw[1] == 3.0     # 1 is in the shortest path between 2-5,1-5     assert bw[3] == 2.0  test_betweenness_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> In\u00a0[347]: Copied! <pre>def distance_matrix(paths):\n    \"\"\"\n    Calculates shortest path distances between all pairs of\n    nodes based on the observed shortest paths (and subpaths)\n    \"\"\"\n    dist = defaultdict(lambda: defaultdict(lambda: _np.inf))\n    # Log.add('Calculating distance matrix based on empirical paths ...', Severity.INFO)\n    nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject\n    for v in nodes:\n        dist[v][v] = 0\n\n    p_length = 1\n    index, edge_weights = paths.edge_index_k_weighted(k=p_length)\n    sources = index[0]\n    destinations = index[-1]\n    for e, (s, d) in enumerate(zip(sources, destinations)):\n        s = s.item()\n        d = d.item()\n        dist[s][d] = p_length\n        # s_p[s][d] = set({torch.tensor([s,d])})\n    p_length += 1\n    while True: # until max path length\n        try:\n            index, edge_weights = paths.edge_index_k_weighted(k=p_length)\n            sources = index[0, :, 0]\n            destinations = index[1, :, -1]\n            for e, (s, d) in enumerate(zip(sources, destinations)):\n                s = s.item()\n                d = d.item()\n                if p_length &lt; dist[s][d]:\n                    # update shortest path length\n                    dist[s][d] = p_length\n            p_length += 1\n        except IndexError:\n            print(f\"IndexError occurred. Reached maximum path length of {p_length}\")\n            break\n    return dist\ndistance_matrix(paths)\n</pre>  def distance_matrix(paths):     \"\"\"     Calculates shortest path distances between all pairs of     nodes based on the observed shortest paths (and subpaths)     \"\"\"     dist = defaultdict(lambda: defaultdict(lambda: _np.inf))     # Log.add('Calculating distance matrix based on empirical paths ...', Severity.INFO)     nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject     for v in nodes:         dist[v][v] = 0      p_length = 1     index, edge_weights = paths.edge_index_k_weighted(k=p_length)     sources = index[0]     destinations = index[-1]     for e, (s, d) in enumerate(zip(sources, destinations)):         s = s.item()         d = d.item()         dist[s][d] = p_length         # s_p[s][d] = set({torch.tensor([s,d])})     p_length += 1     while True: # until max path length         try:             index, edge_weights = paths.edge_index_k_weighted(k=p_length)             sources = index[0, :, 0]             destinations = index[1, :, -1]             for e, (s, d) in enumerate(zip(sources, destinations)):                 s = s.item()                 d = d.item()                 if p_length &lt; dist[s][d]:                     # update shortest path length                     dist[s][d] = p_length             p_length += 1         except IndexError:             print(f\"IndexError occurred. Reached maximum path length of {p_length}\")             break     return dist distance_matrix(paths)      <pre>IndexError occurred. Reached maximum path length of 4\n</pre> Out[347]: <pre>defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {0: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {0: 0, 1: 1, 3: 2}),\n             1: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {1: 0, 3: 1, 5: 2}),\n             2: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {2: 0, 1: 1, 3: 2, 5: 3}),\n             3: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {3: 0, 4: 1, 5: 1}),\n             4: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {4: 0}),\n             5: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {5: 0})})</pre> In\u00a0[352]: Copied! <pre>def test_distance_matrix_paths(simple_paths_centralities):\n    dm = distance_matrix(simple_paths_centralities)\n    assert dm[0] == {0: 0, 1: 1, 3: 2}\n    assert dm[1] == {1: 0, 3: 1, 5: 2}\n    assert dm[2] == {2: 0, 1: 1, 3: 2, 5: 3}\n    assert dm[3] == {3: 0, 4: 1, 5: 1}\n    assert dm[4] == {4: 0}\n    assert dm[5] == {5: 0}\n\ntest_distance_matrix_paths(paths)\n</pre> def test_distance_matrix_paths(simple_paths_centralities):     dm = distance_matrix(simple_paths_centralities)     assert dm[0] == {0: 0, 1: 1, 3: 2}     assert dm[1] == {1: 0, 3: 1, 5: 2}     assert dm[2] == {2: 0, 1: 1, 3: 2, 5: 3}     assert dm[3] == {3: 0, 4: 1, 5: 1}     assert dm[4] == {4: 0}     assert dm[5] == {5: 0}  test_distance_matrix_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> In\u00a0[355]: Copied! <pre>def closeness(paths, normalized=False):\n    \"\"\"Calculates the closeness of nodes based on observed shortest paths\n    between all nodes\n\n    Parameters\n    ----------\n    paths: Paths\n    normalized: bool\n        normalize such that largest value is 1.0\n\n    Returns\n    -------\n    dict\n    \"\"\"\n    node_centralities = defaultdict(lambda: 0)\n    distances = distance_matrix(paths)\n    nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject\n\n    for x in nodes:\n        # calculate closeness centrality of x\n        for d in nodes:\n            if x != d and distances[d][x] &lt; _np.inf:\n                node_centralities[x] += 1.0 / distances[d][x]\n\n    # assign zero values to nodes not occurring\n    \n    for v in nodes:\n        node_centralities[v] += 0.0\n\n    if normalized:\n        m = max(node_centralities.values())\n        for v in nodes:\n            node_centralities[v] /= m\n\n    return node_centralities\ncloseness(paths, normalized=False)\n</pre> def closeness(paths, normalized=False):     \"\"\"Calculates the closeness of nodes based on observed shortest paths     between all nodes      Parameters     ----------     paths: Paths     normalized: bool         normalize such that largest value is 1.0      Returns     -------     dict     \"\"\"     node_centralities = defaultdict(lambda: 0)     distances = distance_matrix(paths)     nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject      for x in nodes:         # calculate closeness centrality of x         for d in nodes:             if x != d and distances[d][x] &lt; _np.inf:                 node_centralities[x] += 1.0 / distances[d][x]      # assign zero values to nodes not occurring          for v in nodes:         node_centralities[v] += 0.0      if normalized:         m = max(node_centralities.values())         for v in nodes:             node_centralities[v] /= m      return node_centralities closeness(paths, normalized=False) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> Out[355]: <pre>defaultdict(&lt;function __main__.closeness.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {1: 2.0, 3: 2.0, 4: 1.0, 5: 1.8333333333333333, 0: 0.0, 2: 0.0})</pre> In\u00a0[360]: Copied! <pre>def test_closeness_paths(simple_paths_centralities):\n    c = closeness(simple_paths_centralities, normalized=False)\n    assert c[0] == 0.0\n    # 1 reachable from 0 and 2 in one step\n    assert c[1] == 1/1 + 1/1\n    assert c[2] == 0\n    # 3 reachable from 1 in one step, from 0 and 3 in two steps\n    assert c[3] == 1 + 1/2 + 1/2\n    assert c[4] == 1\n    # 5 reachable from 3 in one step, from 1 in two steps, from 2 in three steps\n    assert c[5] == 1 + 1/2 + 1/3\ntest_closeness_paths(paths)\n</pre> def test_closeness_paths(simple_paths_centralities):     c = closeness(simple_paths_centralities, normalized=False)     assert c[0] == 0.0     # 1 reachable from 0 and 2 in one step     assert c[1] == 1/1 + 1/1     assert c[2] == 0     # 3 reachable from 1 in one step, from 0 and 3 in two steps     assert c[3] == 1 + 1/2 + 1/2     assert c[4] == 1     # 5 reachable from 3 in one step, from 1 in two steps, from 2 in three steps     assert c[5] == 1 + 1/2 + 1/3 test_closeness_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre>"},{"location":"tutorial/xx_test_random_walks/","title":"Xx test random walks","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nprint('Running on', pp.config['torch']['device'])\nimport torch\nfrom pathpyG.processes.random_walk import RandomWalk, HigherOrderRandomWalk\n</pre> import pathpyG as pp print('Running on', pp.config['torch']['device']) import torch from pathpyG.processes.random_walk import RandomWalk, HigherOrderRandomWalk  <pre>Running on cpu\n</pre> In\u00a0[2]: Copied! <pre>g = pp.io.read_netzschleuder_network('karate', '77')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_network('karate', '77') print(g) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n\nNode attributes\n\tnode__pos\t\t&lt;class 'list'&gt;\n\tnode_name\t\t&lt;class 'list'&gt;\n\tnode_groups\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\turl\t\t&lt;class 'str'&gt;\n\tcitation\t\t&lt;class 'str'&gt;\n\tdescription\t\t&lt;class 'str'&gt;\n\tname\t\t&lt;class 'str'&gt;\n\ttags\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[3]: Copied! <pre>rw = RandomWalk(g)\n</pre> rw = RandomWalk(g) In\u00a0[4]: Copied! <pre>data = rw.run_experiment(steps=100,runs=range(34))\n</pre> data = rw.run_experiment(steps=100,runs=range(34)) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 34/34 [00:00&lt;00:00, 347.70it/s]\n</pre> In\u00a0[5]: Copied! <pre>data\n</pre> data Out[5]: run_id seed time node state 0 0 0 0 0 True 1 0 0 0 1 False 2 0 0 0 2 False 3 0 0 0 3 False 4 0 0 0 4 False ... ... ... ... ... ... 7951 33 33 98 1 False 7952 33 33 99 0 True 7953 33 33 99 21 False 7954 33 33 100 3 True 7955 33 33 100 0 False <p>7956 rows \u00d7 5 columns</p> In\u00a0[7]: Copied! <pre>paths = rw.get_paths(data)\n</pre> paths = rw.get_paths(data) <pre>[0, 8, 32, 31, 32, 22, 32, 8, 33, 30, 1, 30, 32, 20, 33, 14, 32, 15, 33, 13, 1, 21, 1, 30, 33, 13, 1, 19, 1, 7, 0, 13, 33, 9, 33, 18, 33, 13, 0, 5, 6, 0, 1, 2, 7, 0, 12, 0, 12, 0, 17, 1, 30, 32, 23, 32, 22, 32, 23, 25, 24, 25, 23, 33, 23, 29, 33, 27, 24, 25, 23, 25, 24, 27, 23, 25, 23, 27, 24, 31, 33, 23, 33, 13, 2, 7, 0, 19, 0, 6, 16, 5, 10, 0, 5, 10, 0, 19, 33, 27, 24]\n[1, 0, 31, 0, 5, 6, 4, 6, 16, 6, 16, 6, 0, 1, 30, 32, 31, 32, 30, 1, 30, 33, 20, 32, 2, 8, 2, 28, 2, 0, 10, 4, 6, 4, 10, 0, 8, 32, 20, 32, 18, 32, 31, 24, 25, 31, 25, 31, 32, 2, 27, 2, 3, 1, 3, 13, 33, 29, 23, 29, 32, 29, 33, 30, 33, 23, 29, 32, 20, 33, 29, 26, 33, 28, 31, 25, 23, 29, 32, 14, 32, 14, 33, 32, 2, 28, 2, 3, 2, 32, 8, 32, 18, 33, 9, 2, 28, 33, 27, 33, 29]\n[2, 0, 19, 33, 31, 32, 30, 1, 3, 0, 21, 1, 7, 0, 19, 1, 3, 2, 27, 2, 13, 2, 27, 33, 23, 33, 29, 32, 33, 20, 32, 20, 33, 32, 33, 31, 25, 23, 27, 33, 9, 33, 30, 8, 30, 8, 0, 19, 33, 15, 32, 29, 23, 25, 24, 27, 33, 27, 2, 28, 31, 24, 25, 24, 27, 24, 25, 31, 33, 27, 24, 31, 32, 2, 32, 15, 33, 23, 25, 23, 25, 31, 0, 3, 0, 5, 0, 11, 0, 4, 6, 4, 10, 0, 11, 0, 2, 9, 33, 28, 31]\n[3, 7, 0, 5, 16, 6, 16, 6, 5, 6, 16, 6, 0, 3, 0, 3, 13, 1, 7, 0, 7, 3, 2, 1, 19, 0, 11, 0, 31, 33, 9, 33, 19, 33, 27, 23, 29, 26, 29, 32, 8, 0, 11, 0, 17, 1, 17, 1, 2, 27, 24, 31, 25, 23, 32, 20, 32, 23, 32, 22, 32, 29, 33, 26, 33, 18, 33, 20, 32, 22, 32, 29, 26, 33, 28, 2, 8, 30, 8, 2, 27, 24, 27, 23, 32, 30, 33, 20, 33, 28, 33, 27, 23, 29, 26, 33, 18, 32, 30, 32, 29]\n[4, 10, 0, 12, 3, 1, 0, 2, 0, 7, 1, 0, 19, 33, 26, 33, 13, 3, 0, 7, 0, 3, 2, 28, 31, 0, 11, 0, 6, 4, 6, 4, 10, 0, 12, 0, 11, 0, 3, 0, 31, 33, 28, 2, 8, 2, 28, 33, 8, 30, 32, 18, 32, 33, 23, 27, 33, 14, 32, 29, 23, 25, 23, 29, 33, 15, 32, 14, 33, 32, 30, 32, 8, 0, 2, 27, 23, 27, 24, 25, 23, 27, 23, 29, 26, 33, 13, 2, 32, 31, 32, 2, 28, 33, 13, 3, 0, 10, 0, 2, 9]\n[5, 6, 0, 10, 5, 10, 0, 5, 0, 11, 0, 4, 6, 16, 5, 0, 21, 1, 0, 13, 0, 1, 17, 0, 31, 32, 20, 33, 14, 33, 28, 33, 20, 32, 20, 32, 15, 32, 14, 33, 29, 26, 29, 32, 18, 32, 2, 9, 33, 26, 33, 26, 33, 26, 29, 23, 27, 33, 31, 32, 8, 30, 1, 0, 2, 13, 0, 10, 5, 6, 0, 31, 24, 31, 33, 31, 0, 2, 1, 19, 1, 17, 0, 4, 0, 17, 1, 17, 1, 13, 3, 0, 10, 0, 5, 6, 4, 0, 17, 0, 19]\n[6, 0, 10, 5, 16, 6, 4, 6, 5, 6, 0, 31, 32, 2, 7, 3, 12, 3, 0, 13, 33, 31, 25, 31, 33, 20, 33, 23, 27, 33, 18, 32, 22, 32, 30, 33, 13, 1, 0, 6, 5, 16, 6, 5, 0, 7, 0, 13, 2, 13, 2, 3, 1, 19, 1, 17, 0, 6, 5, 0, 3, 0, 6, 5, 6, 4, 6, 0, 3, 1, 21, 0, 4, 10, 5, 16, 5, 6, 16, 5, 0, 12, 0, 31, 32, 31, 25, 31, 32, 30, 33, 20, 32, 30, 33, 15, 32, 22, 32, 23, 33]\n[7, 0, 8, 2, 7, 2, 9, 33, 15, 32, 29, 23, 29, 32, 23, 25, 24, 25, 23, 27, 23, 32, 15, 32, 30, 8, 0, 7, 1, 19, 0, 17, 0, 21, 0, 4, 6, 16, 6, 0, 10, 4, 10, 5, 10, 5, 10, 0, 6, 0, 11, 0, 5, 10, 4, 6, 16, 5, 10, 5, 0, 17, 1, 30, 8, 2, 32, 33, 29, 33, 13, 3, 2, 0, 10, 0, 1, 19, 33, 27, 23, 32, 15, 32, 33, 30, 8, 0, 21, 1, 21, 1, 13, 33, 26, 33, 19, 0, 8, 2, 9]\n[8, 32, 33, 26, 29, 32, 15, 32, 20, 32, 31, 24, 27, 33, 27, 23, 25, 24, 25, 24, 25, 31, 24, 31, 24, 25, 23, 32, 29, 33, 31, 25, 24, 27, 23, 27, 2, 3, 7, 2, 32, 29, 33, 27, 33, 23, 33, 23, 27, 33, 23, 25, 24, 25, 31, 32, 14, 33, 31, 28, 31, 33, 15, 33, 27, 23, 29, 33, 20, 33, 28, 33, 13, 3, 2, 27, 24, 31, 0, 19, 33, 14, 33, 31, 0, 1, 19, 33, 32, 33, 28, 33, 13, 0, 8, 32, 8, 32, 22, 32, 8]\n[9, 33, 23, 33, 31, 25, 23, 25, 24, 31, 25, 24, 25, 24, 25, 23, 29, 23, 25, 24, 25, 31, 28, 2, 13, 0, 7, 2, 3, 0, 11, 0, 21, 0, 17, 0, 8, 30, 1, 7, 1, 3, 7, 3, 12, 3, 2, 8, 2, 0, 2, 32, 23, 29, 33, 28, 2, 7, 1, 30, 1, 0, 19, 33, 32, 8, 30, 33, 13, 0, 31, 25, 23, 27, 24, 31, 28, 2, 32, 33, 9, 2, 1, 3, 1, 21, 1, 2, 27, 23, 33, 23, 32, 30, 8, 2, 13, 1, 0, 11, 0]\n[10, 4, 10, 4, 10, 4, 10, 4, 10, 4, 0, 13, 33, 28, 31, 24, 31, 25, 24, 27, 23, 32, 15, 32, 23, 27, 24, 25, 23, 29, 23, 27, 23, 32, 22, 32, 2, 7, 0, 5, 0, 4, 6, 5, 16, 5, 16, 6, 0, 19, 33, 26, 29, 32, 8, 30, 8, 32, 14, 33, 18, 32, 20, 32, 31, 28, 31, 25, 31, 0, 5, 16, 5, 10, 4, 0, 31, 0, 10, 5, 6, 5, 16, 6, 4, 6, 16, 5, 6, 5, 6, 0, 11, 0, 4, 10, 5, 16, 5, 16, 5]\n[11, 0, 2, 9, 33, 27, 24, 27, 2, 7, 1, 21, 0, 5, 0, 1, 19, 33, 20, 32, 23, 29, 26, 29, 33, 18, 33, 13, 0, 5, 0, 6, 16, 5, 6, 4, 6, 0, 5, 10, 0, 11, 0, 4, 6, 5, 0, 31, 25, 31, 24, 25, 24, 25, 24, 27, 33, 15, 33, 30, 1, 3, 12, 0, 8, 30, 33, 29, 26, 29, 33, 31, 25, 31, 33, 23, 25, 23, 32, 8, 32, 2, 9, 33, 9, 2, 32, 15, 33, 14, 32, 8, 30, 33, 29, 32, 2, 32, 33, 9, 2]\n[12, 0, 6, 16, 6, 0, 21, 1, 30, 8, 2, 0, 4, 10, 5, 6, 5, 0, 3, 12, 0, 1, 0, 8, 30, 1, 19, 1, 21, 1, 21, 0, 17, 0, 13, 33, 29, 23, 33, 30, 1, 21, 1, 13, 33, 14, 33, 32, 2, 32, 18, 32, 18, 33, 18, 32, 15, 33, 18, 33, 32, 14, 32, 30, 1, 13, 1, 17, 0, 5, 6, 16, 6, 4, 6, 0, 8, 33, 27, 2, 9, 33, 30, 33, 13, 0, 1, 21, 0, 1, 13, 1, 17, 0, 7, 2, 27, 2, 32, 30, 32]\n[13, 3, 2, 3, 12, 3, 0, 11, 0, 1, 2, 27, 2, 1, 2, 28, 33, 29, 33, 18, 33, 31, 28, 2, 0, 17, 1, 3, 1, 21, 1, 17, 1, 17, 0, 1, 7, 1, 13, 1, 2, 8, 32, 14, 33, 31, 28, 31, 28, 2, 7, 2, 28, 2, 27, 33, 15, 32, 14, 33, 23, 33, 32, 20, 32, 8, 33, 8, 30, 1, 2, 1, 13, 0, 6, 0, 13, 1, 2, 27, 23, 29, 23, 27, 2, 27, 2, 8, 0, 13, 1, 3, 0, 5, 16, 5, 16, 5, 10, 0, 13]\n[14, 32, 8, 30, 32, 33, 23, 29, 32, 33, 8, 30, 33, 27, 24, 27, 33, 8, 0, 31, 24, 27, 24, 31, 25, 23, 32, 33, 19, 33, 19, 1, 17, 0, 5, 16, 6, 0, 8, 30, 32, 23, 25, 31, 28, 31, 0, 4, 6, 16, 6, 4, 10, 5, 10, 0, 7, 0, 19, 1, 19, 1, 2, 8, 2, 8, 30, 8, 0, 5, 16, 5, 0, 17, 0, 17, 1, 21, 0, 19, 1, 30, 33, 31, 24, 25, 24, 31, 28, 2, 13, 2, 9, 33, 19, 1, 3, 13, 0, 11, 0]\n[15, 33, 26, 33, 27, 23, 29, 23, 27, 2, 8, 33, 15, 33, 27, 23, 25, 31, 33, 9, 33, 29, 32, 23, 33, 20, 33, 31, 33, 30, 1, 21, 1, 13, 3, 1, 2, 28, 31, 25, 24, 27, 33, 8, 30, 1, 2, 13, 33, 30, 32, 31, 28, 33, 30, 8, 0, 2, 0, 31, 25, 23, 33, 27, 23, 32, 18, 33, 28, 31, 25, 23, 32, 8, 33, 20, 32, 23, 33, 8, 33, 18, 33, 31, 24, 27, 23, 27, 23, 33, 8, 0, 8, 2, 32, 14, 33, 19, 1, 0, 6]\n[16, 5, 16, 6, 5, 6, 4, 10, 0, 2, 28, 33, 19, 1, 19, 0, 7, 2, 7, 2, 7, 0, 7, 1, 2, 7, 0, 19, 1, 13, 0, 5, 10, 0, 13, 3, 13, 2, 27, 24, 27, 24, 25, 31, 0, 8, 33, 8, 32, 2, 9, 33, 18, 32, 29, 23, 25, 31, 33, 29, 33, 30, 8, 2, 13, 2, 3, 13, 33, 19, 33, 29, 32, 2, 1, 21, 0, 2, 27, 23, 32, 14, 33, 20, 32, 31, 32, 18, 33, 9, 2, 27, 24, 31, 32, 15, 33, 13, 2, 3, 1]\n[17, 0, 10, 0, 7, 0, 12, 3, 12, 3, 2, 0, 19, 33, 29, 23, 29, 23, 33, 26, 33, 20, 33, 9, 2, 1, 19, 0, 8, 30, 8, 32, 22, 32, 15, 32, 20, 33, 32, 23, 27, 2, 27, 24, 27, 23, 29, 23, 33, 29, 32, 15, 32, 14, 33, 32, 22, 32, 15, 32, 23, 29, 33, 19, 1, 21, 1, 2, 13, 1, 7, 1, 0, 31, 25, 24, 27, 23, 33, 30, 8, 32, 14, 33, 31, 0, 6, 16, 6, 16, 6, 16, 5, 16, 5, 10, 4, 6, 16, 5, 0]\n[18, 32, 20, 33, 29, 23, 29, 26, 29, 26, 29, 26, 29, 32, 2, 8, 32, 15, 33, 9, 33, 19, 1, 7, 0, 13, 2, 28, 31, 33, 26, 29, 23, 32, 15, 32, 30, 33, 26, 33, 19, 0, 10, 5, 6, 4, 10, 5, 6, 16, 6, 4, 6, 4, 0, 10, 5, 0, 17, 1, 0, 21, 1, 19, 33, 32, 22, 32, 29, 23, 32, 18, 33, 8, 30, 1, 2, 32, 20, 33, 31, 33, 20, 32, 23, 32, 30, 33, 26, 33, 28, 33, 15, 33, 26, 29, 33, 13, 33, 28, 31]\n[19, 0, 12, 0, 19, 0, 17, 0, 13, 1, 3, 12, 3, 2, 0, 2, 8, 32, 2, 27, 23, 33, 32, 31, 25, 31, 28, 33, 28, 33, 19, 0, 31, 24, 27, 24, 25, 24, 31, 33, 23, 27, 23, 33, 28, 31, 25, 31, 33, 32, 15, 33, 18, 33, 29, 33, 32, 20, 32, 15, 32, 30, 1, 30, 32, 33, 23, 27, 2, 13, 1, 21, 1, 30, 32, 2, 9, 33, 18, 33, 19, 1, 13, 2, 9, 33, 32, 29, 33, 8, 33, 32, 14, 32, 20, 32, 8, 0, 3, 1, 30]\n[20, 33, 8, 32, 23, 25, 31, 33, 8, 30, 32, 2, 8, 33, 14, 32, 8, 30, 1, 17, 0, 5, 16, 5, 0, 17, 0, 3, 12, 0, 19, 1, 17, 0, 13, 0, 6, 5, 16, 5, 0, 31, 24, 27, 24, 31, 33, 30, 1, 7, 1, 19, 1, 21, 1, 17, 0, 3, 12, 3, 13, 2, 0, 11, 0, 2, 32, 18, 33, 9, 33, 13, 0, 6, 16, 6, 0, 31, 25, 23, 32, 15, 33, 32, 31, 28, 2, 0, 11, 0, 8, 30, 32, 29, 32, 22, 32, 29, 23, 25, 31]\n[21, 1, 30, 32, 18, 32, 33, 15, 32, 8, 33, 32, 29, 33, 15, 33, 27, 2, 32, 22, 32, 30, 8, 32, 8, 2, 27, 24, 27, 24, 27, 23, 27, 2, 13, 0, 17, 0, 2, 13, 0, 21, 1, 30, 1, 2, 7, 3, 7, 1, 2, 13, 0, 17, 1, 13, 0, 1, 19, 0, 8, 30, 1, 17, 1, 21, 1, 2, 9, 33, 15, 32, 33, 20, 33, 15, 32, 20, 32, 30, 33, 13, 3, 13, 3, 13, 1, 30, 32, 31, 24, 25, 24, 27, 2, 28, 2, 8, 30, 32, 29]\n[22, 32, 8, 32, 33, 29, 32, 22, 32, 18, 32, 29, 32, 31, 24, 25, 23, 29, 33, 28, 33, 28, 2, 3, 13, 0, 7, 2, 28, 33, 14, 32, 14, 33, 15, 32, 31, 28, 31, 28, 33, 26, 33, 8, 30, 1, 30, 33, 20, 33, 32, 20, 32, 2, 27, 2, 9, 33, 26, 33, 18, 32, 20, 33, 29, 23, 29, 26, 29, 33, 27, 2, 32, 30, 8, 30, 33, 27, 23, 29, 32, 20, 32, 18, 32, 33, 26, 29, 32, 14, 32, 15, 32, 31, 33, 20, 32, 23, 33, 15, 32]\n[23, 25, 23, 32, 29, 26, 33, 9, 2, 1, 17, 1, 21, 1, 7, 0, 21, 1, 30, 32, 15, 33, 9, 33, 9, 33, 27, 24, 25, 23, 33, 27, 33, 32, 14, 32, 22, 32, 31, 28, 31, 25, 31, 32, 14, 33, 27, 23, 25, 24, 27, 24, 31, 25, 24, 25, 23, 27, 2, 27, 23, 32, 18, 33, 19, 0, 1, 7, 0, 10, 4, 10, 5, 16, 6, 16, 6, 5, 6, 16, 5, 10, 5, 16, 5, 6, 4, 10, 4, 10, 5, 16, 5, 6, 5, 10, 0, 2, 1, 19, 1]\n[24, 25, 23, 25, 31, 32, 29, 33, 30, 32, 15, 32, 23, 32, 30, 8, 30, 33, 31, 28, 2, 9, 2, 3, 2, 8, 2, 27, 23, 32, 14, 33, 19, 1, 3, 12, 3, 0, 12, 3, 13, 3, 1, 17, 1, 21, 1, 13, 3, 12, 3, 13, 1, 21, 1, 21, 1, 13, 3, 1, 7, 1, 19, 1, 2, 7, 1, 0, 5, 6, 0, 2, 7, 2, 0, 12, 3, 7, 1, 2, 3, 7, 2, 3, 12, 3, 1, 19, 0, 11, 0, 17, 1, 30, 8, 32, 20, 32, 30, 1, 17]\n[25, 31, 0, 11, 0, 31, 24, 25, 24, 31, 24, 27, 33, 19, 33, 20, 32, 14, 32, 2, 8, 2, 3, 12, 3, 1, 2, 0, 13, 2, 7, 1, 30, 32, 2, 0, 10, 0, 6, 0, 8, 32, 31, 28, 2, 13, 0, 1, 17, 0, 10, 4, 0, 2, 7, 0, 17, 0, 21, 1, 13, 2, 1, 7, 2, 1, 30, 33, 23, 29, 23, 32, 2, 7, 3, 1, 21, 0, 12, 0, 13, 1, 3, 7, 3, 0, 4, 10, 5, 10, 0, 3, 12, 3, 12, 0, 5, 6, 5, 0, 8]\n[26, 29, 23, 27, 24, 25, 24, 25, 31, 0, 2, 9, 33, 8, 32, 22, 32, 22, 32, 33, 32, 14, 33, 26, 33, 23, 29, 26, 33, 27, 33, 28, 31, 24, 31, 0, 11, 0, 13, 33, 27, 2, 9, 2, 1, 0, 2, 13, 33, 19, 33, 15, 33, 15, 32, 22, 32, 23, 25, 24, 25, 24, 31, 0, 31, 0, 13, 2, 0, 3, 0, 3, 2, 27, 24, 25, 24, 25, 24, 31, 32, 33, 32, 29, 33, 9, 2, 32, 22, 32, 14, 32, 8, 33, 14, 33, 26, 33, 31, 28, 33]\n[27, 24, 27, 2, 7, 2, 0, 12, 0, 10, 5, 10, 5, 16, 5, 16, 6, 0, 13, 0, 1, 17, 1, 7, 2, 0, 12, 0, 10, 0, 21, 1, 30, 33, 30, 32, 31, 0, 6, 4, 0, 12, 0, 19, 33, 20, 32, 29, 26, 33, 8, 0, 2, 13, 3, 1, 13, 2, 27, 24, 27, 2, 3, 7, 1, 30, 8, 30, 1, 2, 32, 22, 32, 23, 33, 8, 32, 31, 32, 33, 8, 32, 31, 33, 8, 32, 2, 0, 17, 0, 21, 0, 7, 3, 2, 1, 17, 0, 11, 0, 8]\n[28, 31, 24, 31, 33, 30, 1, 3, 2, 7, 2, 3, 2, 8, 2, 9, 33, 23, 29, 26, 33, 27, 33, 18, 33, 29, 33, 13, 0, 10, 0, 11, 0, 4, 0, 4, 10, 0, 31, 24, 27, 33, 15, 32, 22, 32, 30, 32, 29, 26, 29, 23, 33, 14, 32, 14, 32, 22, 32, 14, 32, 23, 29, 23, 29, 32, 22, 32, 14, 32, 8, 30, 8, 32, 23, 25, 31, 28, 2, 0, 7, 0, 17, 0, 7, 3, 0, 17, 0, 31, 33, 29, 23, 29, 32, 30, 32, 8, 2, 27, 33]\n[29, 26, 29, 33, 19, 33, 15, 32, 8, 2, 1, 2, 27, 23, 25, 23, 27, 23, 32, 2, 27, 33, 31, 32, 31, 0, 2, 27, 23, 27, 2, 3, 0, 2, 3, 0, 3, 13, 33, 19, 0, 4, 0, 12, 0, 3, 7, 0, 6, 0, 17, 0, 13, 2, 27, 2, 7, 2, 27, 23, 29, 33, 27, 33, 20, 33, 31, 28, 31, 25, 31, 24, 25, 24, 31, 0, 31, 32, 31, 24, 31, 28, 2, 27, 2, 1, 0, 5, 6, 0, 13, 0, 6, 0, 19, 33, 27, 2, 0, 13, 33]\n[30, 33, 9, 2, 3, 13, 3, 13, 0, 10, 5, 6, 16, 6, 4, 0, 2, 28, 2, 9, 2, 3, 13, 33, 26, 29, 33, 31, 24, 27, 24, 31, 28, 31, 33, 13, 0, 13, 3, 13, 1, 30, 1, 17, 0, 12, 3, 12, 0, 2, 3, 12, 3, 0, 10, 4, 0, 2, 13, 2, 3, 2, 9, 33, 13, 3, 2, 9, 33, 32, 23, 25, 24, 25, 23, 32, 23, 29, 32, 15, 32, 8, 0, 17, 0, 19, 1, 2, 9, 2, 13, 3, 2, 13, 33, 19, 1, 30, 32, 33, 20]\n[31, 0, 3, 2, 0, 4, 6, 0, 13, 1, 19, 33, 13, 0, 8, 33, 23, 29, 26, 29, 26, 29, 33, 27, 24, 25, 31, 0, 13, 1, 30, 1, 7, 0, 7, 2, 28, 31, 25, 23, 32, 14, 33, 28, 2, 3, 0, 7, 2, 13, 3, 1, 0, 5, 16, 5, 0, 21, 1, 0, 21, 0, 21, 1, 13, 1, 21, 0, 2, 32, 18, 33, 30, 32, 8, 2, 27, 24, 31, 33, 19, 1, 0, 17, 0, 12, 0, 4, 10, 5, 10, 4, 10, 4, 6, 0, 6, 5, 6, 16, 6]\n[32, 22, 32, 29, 26, 33, 20, 33, 9, 2, 13, 3, 0, 5, 16, 6, 16, 6, 5, 10, 5, 6, 5, 16, 6, 0, 2, 9, 2, 9, 33, 20, 33, 15, 33, 30, 8, 30, 33, 18, 33, 14, 33, 28, 2, 13, 33, 20, 32, 33, 30, 33, 23, 25, 24, 27, 23, 33, 23, 27, 33, 19, 33, 18, 32, 29, 32, 23, 27, 24, 31, 33, 18, 33, 9, 2, 32, 23, 29, 33, 31, 28, 33, 27, 23, 29, 23, 32, 22, 32, 33, 26, 29, 33, 28, 33, 27, 24, 27, 2, 7]\n[33, 15, 33, 20, 32, 2, 27, 24, 31, 28, 31, 32, 22, 32, 30, 33, 32, 30, 8, 32, 20, 32, 23, 29, 26, 33, 19, 1, 21, 0, 6, 16, 6, 0, 1, 0, 3, 0, 4, 6, 5, 16, 6, 4, 6, 16, 6, 5, 6, 4, 6, 16, 6, 4, 10, 5, 0, 13, 0, 17, 0, 6, 0, 4, 10, 0, 10, 4, 6, 16, 6, 4, 0, 7, 1, 17, 0, 8, 33, 13, 2, 32, 8, 30, 32, 14, 33, 14, 33, 9, 2, 13, 3, 1, 30, 1, 3, 1, 21, 0, 3]\n</pre> In\u00a0[14]: Copied! <pre>paths.dags[0].edge_index\n</pre> paths.dags[0].edge_index Out[14]: <pre>tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n          98,  99],\n        [  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n          99, 100]])</pre> In\u00a0[8]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(paths, max_order=3)\ng2 = m.layers[2]\nprint(g2)\n</pre> m = pp.MultiOrderModel.from_DAGs(paths, max_order=3) g2 = m.layers[2] print(g2) <pre>Directed graph with 154 nodes and 1005 edges\n\nNode attributes\n\tnode_sequences\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([154, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1005])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[9]: Copied! <pre>#print(g_ho)\n</pre> #print(g_ho) In\u00a0[10]: Copied! <pre>#for v in g_ho.nodes:\n#    print(v)\n</pre> #for v in g_ho.nodes: #    print(v) In\u00a0[9]: Copied! <pre>g2= pp.Graph.from_edge_list([\n    ['a', 'b'],\n    ['b', 'c'],\n    ['c', 'd'],\n    ['d', 'e'],\n    ['e', 'f'],\n    ['f', 'g'],\n    ['g', 'h'],\n    ['h', 'i'],\n    ['i', 'j'],\n    ['j', 'k'],\n    ['k', 'l'],\n    ['l', 'm'],\n    ['m', 'n'],\n    ['n', 'o'],\n    ['o', 'a']\n])\n</pre> g2= pp.Graph.from_edge_list([     ['a', 'b'],     ['b', 'c'],     ['c', 'd'],     ['d', 'e'],     ['e', 'f'],     ['f', 'g'],     ['g', 'h'],     ['h', 'i'],     ['i', 'j'],     ['j', 'k'],     ['k', 'l'],     ['l', 'm'],     ['m', 'n'],     ['n', 'o'],     ['o', 'a'] ]) In\u00a0[10]: Copied! <pre>g2.mapping.to_idx('b')\n</pre> g2.mapping.to_idx('b') Out[10]: <pre>1</pre> In\u00a0[11]: Copied! <pre>rw2 = RandomWalk(g2)\n</pre> rw2 = RandomWalk(g2) In\u00a0[13]: Copied! <pre>data2 = rw2.run_experiment(steps=20,runs=['a','b'])\n</pre> data2 = rw2.run_experiment(steps=20,runs=['a','b']) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 1900.02it/s]\n</pre> In\u00a0[15]: Copied! <pre>data2\n</pre> data2 Out[15]: run_id seed time node state 0 0 a 0 a True 1 0 a 0 b False 2 0 a 0 c False 3 0 a 0 d False 4 0 a 0 e False ... ... ... ... ... ... 105 1 b 18 d False 106 1 b 19 f True 107 1 b 19 e False 108 1 b 20 g True 109 1 b 20 f False <p>110 rows \u00d7 5 columns</p> In\u00a0[16]: Copied! <pre>paths2 = rw2.get_paths(data2)\n\npaths2.paths\n</pre> paths2 = rw2.get_paths(data2)  paths2.paths Out[16]: <pre>{0: tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,\n           3,  4],\n         [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,\n           4,  5]], dtype=torch.int32),\n 1: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,\n           4,  5],\n         [ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,\n           5,  6]], dtype=torch.int32)}</pre> In\u00a0[17]: Copied! <pre>pp.plot(g2);\n</pre> pp.plot(g2); In\u00a0[18]: Copied! <pre>g2.mapping.idx_to_id\n</pre> g2.mapping.idx_to_id Out[18]: <pre>{0: 'a',\n 1: 'b',\n 2: 'c',\n 3: 'd',\n 4: 'e',\n 5: 'f',\n 6: 'g',\n 7: 'h',\n 8: 'i',\n 9: 'j',\n 10: 'k',\n 11: 'l',\n 12: 'm',\n 13: 'n',\n 14: 'o'}</pre> In\u00a0[19]: Copied! <pre>g2_ho = pp.HigherOrderGraph(paths2, order = 2)\n</pre> g2_ho = pp.HigherOrderGraph(paths2, order = 2) In\u00a0[20]: Copied! <pre>pp.plot(g2_ho,node_label=[g2_ho.mapping.to_id(x) for x in range(g2_ho.n)]);\n</pre> pp.plot(g2_ho,node_label=[g2_ho.mapping.to_id(x) for x in range(g2_ho.n)]); In\u00a0[14]: Copied! <pre>g3 = pp.Graph.from_edge_list([\n    ['a','b'],\n    ['b','c'],\n    ['c','a'],\n    ['c','d'],\n    ['d','a']\n    ])\n\ng3.data['edge_weight'] = torch.tensor([[1],[1],[2],[1],[1]])\n</pre> g3 = pp.Graph.from_edge_list([     ['a','b'],     ['b','c'],     ['c','a'],     ['c','d'],     ['d','a']     ])  g3.data['edge_weight'] = torch.tensor([[1],[1],[2],[1],[1]]) In\u00a0[15]: Copied! <pre>pp.plot(g3, node_label= [g3.mapping.to_id(x) for x in range(g3.n)]);\n</pre> pp.plot(g3, node_label= [g3.mapping.to_id(x) for x in range(g3.n)]); In\u00a0[23]: Copied! <pre>g3.mapping.id_to_idx\n</pre> g3.mapping.id_to_idx Out[23]: <pre>{'a': 0, 'b': 1, 'c': 2, 'd': 3}</pre> In\u00a0[18]: Copied! <pre>paths = pp.DAGData(g3.mapping)\npaths.append_walk(['a','b','c'],weight=1)\npaths.append_walk(['b','c','a'],weight=1)\npaths.append_walk(['b','c','d'],weight=0.2)\npaths.append_walk(['c','a','b'],weight=1)\npaths.append_walk(['c','d','a'],weight=0.2)\npaths.append_walk(['d','a','b'],weight=1)\n</pre> paths = pp.DAGData(g3.mapping) paths.append_walk(['a','b','c'],weight=1) paths.append_walk(['b','c','a'],weight=1) paths.append_walk(['b','c','d'],weight=0.2) paths.append_walk(['c','a','b'],weight=1) paths.append_walk(['c','d','a'],weight=0.2) paths.append_walk(['d','a','b'],weight=1) In\u00a0[19]: Copied! <pre>paths.dags\n</pre> paths.dags Out[19]: <pre>[Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=0.20000000298023224),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=0.20000000298023224),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1)]</pre> In\u00a0[20]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(paths, max_order=3)\ng3_ho = m.layers[2]\n</pre> m = pp.MultiOrderModel.from_DAGs(paths, max_order=3) g3_ho = m.layers[2] In\u00a0[22]: Copied! <pre>pp.plot(g3_ho, node_label = [g3_ho.mapping.to_id(x) for x in range(g3_ho.n)]);\n</pre> pp.plot(g3_ho, node_label = [g3_ho.mapping.to_id(x) for x in range(g3_ho.n)]); In\u00a0[23]: Copied! <pre>rw = HigherOrderRandomWalk(g3_ho, g3, weight=True)\n</pre> rw = HigherOrderRandomWalk(g3_ho, g3, weight=True) In\u00a0[24]: Copied! <pre>data = rw.run_experiment(steps=100, runs=list(g3_ho.nodes))\n</pre> data = rw.run_experiment(steps=100, runs=list(g3_ho.nodes)) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 511.38it/s]\n</pre> In\u00a0[25]: Copied! <pre>data\n</pre> data Out[25]: run_id seed time node state 0 0 (a, b) 0 (a, b) True 1 0 (a, b) 0 (b, c) False 2 0 (a, b) 0 (c, a) False 3 0 (a, b) 0 (c, d) False 4 0 (a, b) 0 (d, a) False ... ... ... ... ... ... 1020 4 (d, a) 98 (b, c) False 1021 4 (d, a) 99 (d, a) True 1022 4 (d, a) 99 (c, d) False 1023 4 (d, a) 100 (a, b) True 1024 4 (d, a) 100 (d, a) False <p>1025 rows \u00d7 5 columns</p> In\u00a0[29]: Copied! <pre>path = rw.get_paths(data,[0,1])\nprint(path)\n</pre> path = rw.get_paths(data,[0,1]) print(path) <pre>DAGData with 2 dags with total weight 2.0\n</pre> In\u00a0[30]: Copied! <pre>path.get_walk(0)\n</pre> path.get_walk(0) Out[30]: <pre>('a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b')</pre> In\u00a0[51]: Copied! <pre>g3.mapping.idx_to_id\n</pre> g3.mapping.idx_to_id Out[51]: <pre>{0: 'a', 1: 'b', 2: 'c', 3: 'd'}</pre> In\u00a0[56]: Copied! <pre>for time,_ in rw.simulation_run(steps=50, seed=('a','b')):\n    print('Current node = {0}'.format(rw.first_order_node(rw.current_node)))\n    print(rw._first_order_visitations)\n</pre> for time,_ in rw.simulation_run(steps=50, seed=('a','b')):     print('Current node = {0}'.format(rw.first_order_node(rw.current_node)))     print(rw._first_order_visitations)  <pre>Current node = c\n[0. 1. 1. 0.]\nCurrent node = a\n[1. 1. 1. 0.]\nCurrent node = b\n[1. 2. 1. 0.]\nCurrent node = c\n[1. 2. 2. 0.]\nCurrent node = a\n[2. 2. 2. 0.]\nCurrent node = b\n[2. 3. 2. 0.]\nCurrent node = c\n[2. 3. 3. 0.]\nCurrent node = a\n[3. 3. 3. 0.]\nCurrent node = b\n[3. 4. 3. 0.]\nCurrent node = c\n[3. 4. 4. 0.]\nCurrent node = a\n[4. 4. 4. 0.]\nCurrent node = b\n[4. 5. 4. 0.]\nCurrent node = c\n[4. 5. 5. 0.]\nCurrent node = d\n[4. 5. 5. 1.]\nCurrent node = a\n[5. 5. 5. 1.]\nCurrent node = b\n[5. 6. 5. 1.]\nCurrent node = c\n[5. 6. 6. 1.]\nCurrent node = d\n[5. 6. 6. 2.]\nCurrent node = a\n[6. 6. 6. 2.]\nCurrent node = b\n[6. 7. 6. 2.]\nCurrent node = c\n[6. 7. 7. 2.]\nCurrent node = a\n[7. 7. 7. 2.]\nCurrent node = b\n[7. 8. 7. 2.]\nCurrent node = c\n[7. 8. 8. 2.]\nCurrent node = a\n[8. 8. 8. 2.]\nCurrent node = b\n[8. 9. 8. 2.]\nCurrent node = c\n[8. 9. 9. 2.]\nCurrent node = d\n[8. 9. 9. 3.]\nCurrent node = a\n[9. 9. 9. 3.]\nCurrent node = b\n[ 9. 10.  9.  3.]\nCurrent node = c\n[ 9. 10. 10.  3.]\nCurrent node = a\n[10. 10. 10.  3.]\nCurrent node = b\n[10. 11. 10.  3.]\nCurrent node = c\n[10. 11. 11.  3.]\nCurrent node = a\n[11. 11. 11.  3.]\nCurrent node = b\n[11. 12. 11.  3.]\nCurrent node = c\n[11. 12. 12.  3.]\nCurrent node = a\n[12. 12. 12.  3.]\nCurrent node = b\n[12. 13. 12.  3.]\nCurrent node = c\n[12. 13. 13.  3.]\nCurrent node = a\n[13. 13. 13.  3.]\nCurrent node = b\n[13. 14. 13.  3.]\nCurrent node = c\n[13. 14. 14.  3.]\nCurrent node = a\n[14. 14. 14.  3.]\nCurrent node = b\n[14. 15. 14.  3.]\nCurrent node = c\n[14. 15. 15.  3.]\nCurrent node = d\n[14. 15. 15.  4.]\nCurrent node = a\n[15. 15. 15.  4.]\nCurrent node = b\n[15. 16. 15.  4.]\nCurrent node = c\n[15. 16. 16.  4.]\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/xx_test_random_walks/#higher-order-random-walk","title":"Higher Order Random Walk\u00b6","text":""}]}