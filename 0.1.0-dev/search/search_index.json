{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pathpyG","text":"<p>This is the index page of the pathpyG documentation.</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#what-is-pathpyg","title":"What is pathpyG?","text":"<p>pathpyG is an Open Source package facilitating GPU-accelerated next-generation network analytics and graph learning for time series data on graphs.</p> <p>pathpyG is tailored to analyse time-stamped network data as well as sequential data that capture multiple short walks or paths observed in a graph or network. Examples for data that can be analysed with pathpyG include high-resolution time-stamped network data, dynamic social networks, user click streams on the Web, biological pathway data, directed acyclic graphs like citation networks, passenger trajectories in transportation networks, or trajectories of information propagation in social networks.</p> <p>pathpyG is fully integrated with jupyter, providing rich interactive visualisations of networks, temporal networks, and higher-order models. Visualisations can be exported to HTML5 files that can be shared and published on the Web.</p>"},{"location":"about/#what-is-the-science-behind-pathpyg","title":"What is the science behind pathpyG?","text":"<p>The theoretical foundation of this package, higher- and multi-order network models, was developed in the following peer-reviewed research articles:</p> <ol> <li>L Qarkaxhija, V Perri, I Scholtes: De Bruijn goes Neural: Causality-Aware Graph Neural Networks for Time Series Data on Dynamic Graphs, In Proceedings of the First Learning on Graphs Conference, PMLR 198:51:1-51:21, December 2022</li> <li>L Petrovic, I Scholtes: Learning the Markov order of paths in graphs, In Proceedings of WWW '22: The Web Conference 2022, Lyon, France, April 2022</li> <li>V Perri, I Scholtes: HOTVis: Higher-Order Time-Aware Visualisation of Dynamic Graphs, In Proceedings of the 28<sup>th</sup> International Symposium on Graph Drawing and Network Visualization (GD 2020), Vancouver, BC, Canada, September 15-18, 2020</li> <li>I Scholtes: When is a network a network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks, In KDD'17 - Proceedings of the 23<sup>rd</sup> ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, Nova Scotia, Canada, August 13-17, 2017</li> <li>I Scholtes, N Wider, A Garas: Higher-Order Aggregate Networks in the Analysis of Temporal Networks: Path structures and centralities, The European Physical Journal B, 89:61, March 2016</li> <li>I Scholtes, N Wider, R Pfitzner, A Garas, CJ Tessone, F Schweitzer: Causality-driven slow-down and speed-up of diffusion in non-Markovian temporal networks, Nature Communications, 5, September 2014</li> <li>R Pfitzner, I Scholtes, A Garas, CJ Tessone, F Schweitzer: Betweenness preference: Quantifying correlations in the topological dynamics of temporal networks, Phys Rev Lett, 110(19), 198701, May 2013</li> </ol> <p>A broader view on the importance of higher-order graph models for complex systems can be found in this overview article. </p>"},{"location":"contributing/","title":"Contributing","text":"<p>This project is open source and welcomes contributions. In the following sections, you will find information about how to contribute to this project, set up your environment correctly, how to document your code and more.</p>"},{"location":"contributing/#overview","title":"Overview","text":"<ul> <li>Setting up your environment</li> <li>Documentation</li> <li>Code Style</li> <li>Formatting</li> <li>Testing</li> <li>Benchmarking</li> </ul>"},{"location":"contributing/#setting-up-your-environment","title":"Setting up your environment","text":""},{"location":"contributing/#clone-the-repository","title":"Clone the Repository","text":"<p>The first step is to clone the repository. You can do this by running the following command: <pre><code>git clone https://github.com/pathpy/pathpyG\n</code></pre> If you do not have the rights to push to the repository, you can also fork the repository and clone your fork instead. From there you can create a pull request to the original repository.</p>"},{"location":"contributing/#installation","title":"Installation","text":"<p>To ensure version consistency, we use a Development Container for this project.   VSCode provides an easy-to-use extension for this. Check out their official documentation for more information. Once you've installed the extension successfully,   VSCode will recommend reopening the project in the Dev Container. You can also do this manually by clicking on the button in the bottom left corner of   VSCode and then selecting <code>Reopen in Container</code>.</p> Setup without Dev Containers <p>If you do not want to use Dev Containers, you can also install the dependencies into your virtual Python environment manually. We recommend that you follow the instructions provided on our getting started page. As last step, install the package in editable mode and include the dependencies necessary for testing, documentation and general development: <pre><code>pip install -e '.[dev,test,doc]'\n</code></pre></p>"},{"location":"contributing/#git-pre-commit-hooks","title":"Git pre-commit hooks","text":"<p>If you are wondering why every commit you make takes so long, it is because we run a couple of checks on your code before it is committed. These checks are configured as pre-commit hooks and are running automatically when you commit your code. The checks are documented in detail in <code>pre-commit-config.yaml</code>. They are installed by default in the Dev Container setup. If you installed the package manually, you can set up the hooks by running the following command: <pre><code>pre-commit install\n</code></pre></p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>This project uses <code>MkDocs</code> for documentation. It is a static site generator that creates the necessary <code>html</code>-files automatically from the <code>markdown</code>-files and  Group.svg Created using Figma 0.90  Jupyter notebooks in the <code>docs/</code>-directory and the <code>Python</code>-files in <code>src/</code>. The documentation is hosted on GitHub Pages.</p>"},{"location":"contributing/#hosting-the-documentation-locally","title":"Hosting the documentation locally","text":"<p>You can host the documentation locally with the following command: <pre><code>mkdocs serve\n</code></pre> The documentation is then available at <code>http://localhost:8000/</code>.</p> Actual Deployment <p>The development version of the documentation is deployed automatically to GitHub Pages when something is pushed to the <code>main</code>-branch. The workflow for deploying a new stable version needs to be triggered manually. You can find it in the <code>Actions</code>-tab of the repository. Both workflows use <code>mike</code> instead of <code>MkDocs</code> to enable versioning.</p>"},{"location":"contributing/#code-reference","title":"Code Reference","text":"<p>The <code>Code Reference</code> is generated automatically from the   Python source files. The docstrings should be formatted according to the Google Python Style Guide. Be sure to also use the advanced stuff like notes, tips and more. They can e.g. look as follows:</p> DocstringResult <pre><code>\"\"\"\nNote:\n    This is a note.\n\nTip: This is a heading\n    This is a tip.\n\"\"\"\n</code></pre> <p>Note</p> <p>This is a note.</p> <p>This is a heading</p> <p>This is a tip.</p> <p>See the documentation of the underlying griffe package for more details.</p> <p>To get an overview for each module, <code>mkdocstrings</code> automatically uses the docstrings from the <code>__init__.py</code> files in each module as description. Thus, do not forget to add a docstring to each <code>__init__.py</code> file.</p>"},{"location":"contributing/#tutorials","title":"Tutorials","text":"<p>The tutorials are written in  Group.svg Created using Figma 0.90  Jupyter notebooks. They are located in the <code>docs/</code>-directory. You can add new tutorials by adding the notebook to the <code>docs/tutorial/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The tutorials are automatically converted to <code>html</code>-files when the documentation is built.</p>"},{"location":"contributing/#adding-new-pages","title":"Adding new pages","text":"<p>You can add more pages to the documentation by adding a <code>markdown</code>-file to the <code>docs/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The pages are automatically converted to <code>html</code>-files when the documentation is built. We are using Material for MkDocs as a theme. It includes many great features like annotations, code blocks, diagrams, admonitions and more. Check out their documentation for more information.</p>"},{"location":"contributing/#code-style","title":"Code Style","text":"<p>We (soon) enforce code style guidelines with <code>pylint</code>, <code>flake8</code>, <code>mypy</code> and <code>pyright</code>. These packages are configured as defaults in the Dev Container setup via <code>VSCode</code> and the settings are saved in <code>pyproject.toml</code>. You can run them locally with the following commands:</p> <ul> <li><code>pylint</code>: A linter that checks for errors and code style violations.     <pre><code>pylint scr/ # (1)!\n</code></pre><ol> <li>This runs <code>pylint</code> on all files in <code>scr/</code>. You can also run <code>pylint</code> on a single file by specifying the path to the file instead.</li> </ol> </li> <li><code>flake8</code>: Another linter that checks for bad code smells and suspicious constructs.     <pre><code>flake8 . # (1)!\n</code></pre><ol> <li>This runs <code>flake8</code> on all files in the current directory. You can also run <code>flake8</code> on a single file or a subdirectory by specifying the path accordingly.</li> </ol> </li> <li><code>mypy</code>: A static type checker for Python.     <pre><code>mypy src/ # (1)!\n</code></pre><ol> <li>This runs <code>mypy</code> on all files in <code>src/</code>. You can also run <code>mypy</code> on a single file by specifying the path to the file instead.</li> </ol> </li> <li><code>pyright</code>: A second static type checker for Python.     <pre><code>pyright . # (1)!\n</code></pre><ol> <li>This runs <code>pyright</code> on all files in the current directory. You can also run it on a single file or a subdirectory by specifying the path accordingly.</li> </ol> </li> </ul>"},{"location":"contributing/#formatting","title":"Formatting","text":"<p>We use <code>black</code> for formatting. You can run it locally with the following command:</p> <pre><code>black . # (1)!\n</code></pre> <ol> <li>This command will format all files in the current directory. You can also run <code>black</code> on a single file or a subdirectory by specifying the path accordingly.</li> </ol> <p>We further use <code>isort</code> for sorting imports. You can run it locally with the following command: <pre><code>isort .\n</code></pre> The default keyboard shortcut for formatting in <code>VSCode</code> is <code>Alt + Shift + F</code>.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>We are using <code>pytest</code> for testing. You can run the tests locally with the following command: <pre><code>pytest\n</code></pre> The tests are located in the <code>tests/</code>-directory. We use <code>pytest-cov</code> to measure the test coverage and are aiming for 100% coverage with a hard limit of 80%. Tests will fail if the coverage drops below 80%.</p> <p>Add tests</p> <p>We are currently only at 60% coverage. So the lines above are currently pure fiction.</p>"},{"location":"contributing/#benchmarking","title":"Benchmarking","text":"<p>For optimal runtime, we continually measure the execution time of our core functions using pytest benchmarks. These benchmarks are located in <code>tests/benchmarks/</code> and are unit-tests that utilize the <code>benchmark</code> fixture from <code>pytest-benchmark</code>. All of them are marked with the benchmark decorator (<code>@pytest.mark.benchmark</code>) to exclude them from the normal unit-tests. You can run all benchmarks in the command line using <pre><code>pytest -m benchmark\n</code></pre> If you are working on runtime improvements, you can compare the runtime of your changes to the runtime of the main branch by saving the results of each run with <pre><code>pytest -m benchmark --benchmark-autosave\n</code></pre> or with a custom name <code>&lt;custom-name&gt;</code> <pre><code>pytest -m benchmark --benchmark-save=&lt;custom-name&gt;\n</code></pre> After running the benchmarks both in your current branch and in the main branch, you can compare them as follows: <pre><code>pytest-benchmark compare # (1)!\n</code></pre></p> <ol> <li>This will compare all runs that are currently saved in <code>.benchmarks/</code>. If you want to compare specific runs, you can add the number of the runs at the end of the command. The numbering usually starts with <code>0001</code>.</li> </ol> <p>Note</p> <p>Since the runtime is strongly dependent on the underlying machine, we do not keep any up-to-date results on <code>git</code> and recommend to do any comparisons locally.</p>"},{"location":"docker_installation/","title":"Docker Installation","text":"<p>  PyTorch provides a  Docker image with PyTorch preinstalled. Using this image, the Dockerfile below creates a Docker image with PathpyG installed.</p> GPUCPU <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre> <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu # CPU only\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html # CPU only\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate the code reference pages and navigation.\"\"\"\n# See for more detail: https://mkdocstrings.github.io/recipes/\n</pre> \"\"\"Generate the code reference pages and navigation.\"\"\" # See for more detail: https://mkdocstrings.github.io/recipes/ In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n</pre> nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>for path in sorted(Path(\"src\").rglob(\"*.py\")):\n    module_path = path.relative_to(\"src\").with_suffix(\"\")\n    doc_path = path.relative_to(\"src\").with_suffix(\".md\")\n    full_doc_path = Path(\"reference\", doc_path)\n\n    parts = tuple(module_path.parts)\n\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1] == \"__main__\":\n        continue\n\n    nav[parts] = doc_path.as_posix()\n\n    with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n        ident = \".\".join(parts)\n        fd.write(f\"::: {ident}\")\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path)\n</pre> for path in sorted(Path(\"src\").rglob(\"*.py\")):     module_path = path.relative_to(\"src\").with_suffix(\"\")     doc_path = path.relative_to(\"src\").with_suffix(\".md\")     full_doc_path = Path(\"reference\", doc_path)      parts = tuple(module_path.parts)      if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1] == \"__main__\":         continue      nav[parts] = doc_path.as_posix()      with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:         ident = \".\".join(parts)         fd.write(f\"::: {ident}\")      mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path) In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"getting_started/","title":"Getting Started","text":"<p>The following will guide you through the installation of the package and the first steps to use it.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>PathpyG is available for   Python versions 3.10 and above. It is not recommended to install it on your system Python. Instead, we recommend using a virtual environment such as   conda or virtualenv. You can also set up a   Docker image as described in the next section.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<p>Once you have an environment up and running, you can install the package simply via pip. But first make sure that you installed the necessary dependencies.</p>"},{"location":"getting_started/#dependencies","title":"Dependencies","text":"<p>This package is based on   PyTorch and   PyTorch Geometric. Please install both libraries before installing PathpyG. You can follow the installation instructions in their respective documentation (  PyTorch and   PyG).</p> <p>Warning</p> <p>We currently only support PyG version 2.5.0 and above.</p>"},{"location":"getting_started/#install-stable-release","title":"Install Stable Release","text":"<p>You can install the latest stable release of PathpyG via pip:</p> <p>TODO</p> <p>This is not yet available. We will release the first stable version soon.</p> <pre><code>pip install pathpyg\n</code></pre>"},{"location":"getting_started/#install-latest-development-version","title":"Install Latest Development Version","text":"<p>If you want to install the latest development version, you can do so via pip directly from the GitHub repository:</p> <pre><code>pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"plot_tutorial/","title":"Develop Custom Plot Functions","text":"<p>This tutorial guides you through the process of creating your own plotting functions in pathpyG.</p> <p>The visualization framework of pathpyg is designed in such a way that is easy to extend it according your own needs.</p> <p>For this tutorial we want to implement capabilities to plot histograms.</p> <p>You will learn:</p> <ul> <li>How to set up a generic plot function</li> <li>How to convert <code>pathpyG</code> data to plot data</li> <li>How to plot with <code>d3js</code> </li> <li>How to plot with <code>tikz</code></li> <li>How to plot with <code>matplotlib</code></li> </ul>"},{"location":"plot_tutorial/#structure","title":"Structure","text":"<p>Plotting commands and functions are located under <code>/src/pathpyG/visualisation/</code></p> <pre><code>\ud83d\udcc1 visualisation\n\u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u251c\u2500\u2500 \ud83d\udcc1 _d3js\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc1 _matplotlib\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc1 _tikz\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc4 layout.py\n\u251c\u2500\u2500 \ud83d\udcc4 network_plots.py\n\u251c\u2500\u2500 \ud83d\udcc4 plot.py\n\u2514\u2500\u2500 \ud83d\udcc4 utils.py\n</code></pre> <p>Folders with <code>_...</code> indicate the supported backends. We will have a look at them later.</p> <p>The <code>layout.py</code> file includes algorithms to calculate the positions of the nodes.</p> <p>In the <code>utils.py</code> file are useful helper functions collected. E.g. among others a function that converts <code>hex_to_rgb</code>, <code>rgb_to_hex</code>, or a simple <code>Colormap</code> class. If your plot needs generic functions which might be helpful for other plots as well, this would be a good place to store them.</p> <p>The <code>network_plots.py</code> file includes all plots related to network visualization. We will create in this tutorial a similar collection for histograms.</p> <p>Finally, the <code>plot.py</code> file contains our generic <code>PathPyPlot</code> class which we will use to build our own class. </p> <p>This abstract class has a property <code>_kind</code> which will specify the type of plot for the generic plot function. Similar to <code>pandas</code> we should be able to call:</p> <pre><code>pp.plot(graph, kind=\"hist\")\n</code></pre> <p>This abstract class has two dict variables <code>self.data</code> and <code>self.config</code>. The <code>self.data</code> variable is used to store the data needed for the plot, while the <code>self.config</code> stores all the configurations passed to the plot.</p> <p>Furthermore this class has three abstract methods we have to define later for our supported backends: <code>generate</code> to generate the plot, <code>save</code> to save the plot to a file, <code>show</code> to show the current plot.</p>"},{"location":"plot_tutorial/#lets-get-started","title":"Let's get started","text":"<p>In order to get started, we have to create a new python file where we will store our histogram plots. So let's generate a new file <code>hist_plots.py</code></p> <pre><code>touch hist_plots.py\n</code></pre> <p>We start with creating a function which allows us later to plot a histogram.</p> <p>This function will take a <code>Graph</code> object as input and has the parameters <code>key</code> and <code>bins</code> as well as a dict of <code>kwargs</code> for furthermore specifications.</p> <p>We will use the <code>key</code> variable to define the data type of the histogram e.g. <code>by='betweenes'</code> to get the betweenes centrality plotted. With the <code>bins</code> parameters we will change the amount of bins in the histogram. all other options will by passed to the function as keyword arguments and can be backend specific.</p> <pre><code>\"\"\"Histogram plot classes.\"\"\"\nfrom __future__ import annotations\n\nimport logging\n\nfrom typing import TYPE_CHECKING, Any\n\n# pseudo load class for type checking\nif TYPE_CHECKING:\n    from pathpyG.core.Graph import Graph\n\n# create logger\nlogger = logging.getLogger(\"pathpyG\")\n\n\ndef hist(network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre> <p>pathpyG is using logging to print out messages and errors. It's a good habit to use it also for your plotting function.</p> <p>Our <code>hist</code> function will be callable via the package. e.g. <code>pp.hist(...)</code>. Itself it will return a plotting class which we have to create.</p> <pre><code>from pathpyG.visualisations.plot import PathPyPlot\n\nclass HistogramPlot(PathPyPlot):\n    \"\"\"Histogram plot class for a network properties.\"\"\"\n\n    _kind = \"hist\"\n\n    def __init__(self, network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.config['bins'] = bins\n        self.config['key'] = key\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n</code></pre> <p>The <code>HistogramPlot</code> plotting class is a child from our abstract <code>PathPyPlot</code> function. We will overwrite the abstract <code>generate()</code> function in order to get the data needed for our plot.</p> <p>By convention we assume <code>d3js</code> will be the default plot backend, hence the final data generated by this function should provide the necessary data structure for this backend. </p> <p>For other backends, this data might be needed to be converted e.g. keywords might be different. We will address this later in our tutorial.</p>"},{"location":"plot_tutorial/#testing-testing-testing","title":"Testing, Testing, Testing","text":"<p>Before we start developing our histogram plot, we should set up a test environment so that we can directly develop the unit test next to our plot function.</p> <p>Therefore we are going to our testing folder an create a new test file.</p> <pre><code>cd ../../../tests/\ntouch test_hist.py\n</code></pre> <p>Now we can create a simple test environment with a simple graph and call our <code>hist(...)</code> function.</p> <pre><code>from pathpyG.core.Graph import Graph\nfrom pathpyG.visualisations.hist_plots import hist\n\n\ndef test_hist_plot() -&gt; None:\n    \"\"\"Test to plot a histogram.\"\"\"\n    net = Graph.from_edge_list([[\"a\", \"b\"], [\"b\", \"c\"], [\"a\", \"c\"]])\n    hist(net)\n</code></pre> <p>Note: If you only want to run this function and not all other test you can use:</p> <pre><code>pytest -s -k 'test_hist_plot'\n</code></pre>"},{"location":"plot_tutorial/#generating-the-plot-data","title":"Generating the plot data","text":"<p>To plot our histogram we first have to generate the required data from our graph.</p> <p>In the future we might want to add more options for histograms, hence we use the <code>match</code>-<code>case</code> function form python.</p> <pre><code>    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n\n        data: dict = {}\n\n        match self.config[\"key\"]:\n            case \"indegrees\":\n                logger.debug(\"Generate data for in-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n            case \"outdegrees\":\n                logger.debug(\"Generate data for out-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n            case _:\n                logger.error(\n                    f\"The &lt;{self.config['key']}&gt; property\",\n                    \"is currently not supported for hist plots.\",\n                )\n                raise KeyError\n\n        data[\"title\"] = self.config[\"key\"]\n        self.data[\"data\"] = data\n</code></pre> <p>First we initialize a dictionary <code>data</code> to store our values. In this case we are interested in the in and out-degrees of our graph, which are already implemented in <code>pathpyG</code> (state 2023-11-26). </p> <p>If the keyword is not supported the function will raise a <code>KeyError</code>.</p> <p>To provide a default title for our plot we also store the keyword in the data dict. If further data is required for the plot it can be stored here.</p> <p>Finally, we add the data dict to our <code>self.data</code> variable of the plotting class. This variable will be used later in the backend classes.</p> <p>With this our basic histogram plot function is finished. We are now able to call the plot function, get the data from our graph and create a data-set which can be passed down to the backend for visualization.</p>"},{"location":"plot_tutorial/#the-matplotlib-backend","title":"The matplotlib backend","text":"<p>Let's open the <code>_matplotlib</code> folder located under <code>/src/pathpyG/visualisation/_matplotlib</code>, where all matplotlib functions are stored.</p> <pre><code>\ud83d\udcc1 _matplotlib\n\u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u251c\u2500\u2500 \ud83d\udcc4 core.py\n\u2514\u2500\u2500 \ud83d\udcc4 network_plots.py\n</code></pre> <p>The <code>_init_.py</code> holds the configuration for the plot function, which we will modify later. The <code>core.py</code> file contains the generic <code>MatplotlibPlot</code> class, which provides <code>save</code> and <code>show</code> functionalities for our plots. We do not need to modify these functions. Instead, we have to generate a translation function from our generic data dict (see above) to a histogram in matplotlib. To do so, lets create first a new python file named <code>hist_plots.py</code></p> <pre><code>cd _matplotlib\ntouch hist_plots.py\n</code></pre> <p>Here we will add our missing piece for a functional matplotlib plot.</p> <pre><code>\"\"\"Histogram plot classes.\"\"\"\nfrom __future__ import annotations\n\nimport logging\n\nfrom typing import TYPE_CHECKING, Any\n\n# pseudo load class for type checking\nif TYPE_CHECKING:\n    from pathpyG.core.Graph import Graph\n\n# create logger\nlogger = logging.getLogger(\"pathpyG\")\n\n\ndef hist(network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre>"},{"location":"tutorial/","title":"Overview","text":"<p>In this tutorial, we will introduce basic concepts of pathpyG. pathpyG can be used as a wrapper around pytorch-geometric that facilitates network analysis, graph learning, and interactive data visualization. However, its real power comes into play when modelling causal path structures in time series data on networks, such as trajectories on graphs or temporal graphs with time-stamped interactions. pathpyG allows to compute causal paths in temporal graphs and model them based on higher-order De Bruijn graphs, a higher-dimensional generalization of standard graph models for relational data.</p> <p>The following introductory video explains the basic idea of higher-order De Bruijn graph models for causal path structures in time series data:</p> <p>The science behind pathpyG has been published in outlets like SIGKDD, WWW, Learning on Graphs, Nature Communications, Nature Physics, and Physical Review Letters. Please check here for more details on key scientific works that have laid the foundations for this package.</p> <p>Different from previous versions of pathpy, the latest version pathpyG fully utilizes the power of torch and tensor-based representations of sparse graph models to failitate the use of higher-order De Bruijn graph models. pathpyG's data structures naturally generalize the concepts of pytorch-geometric, which makes it easy to apply it in (temnporal) graph learning tasks.</p> <p>Finally, pathpyG comes with an implementation of De Bruijn Graph Neural Networks (DBGNN), a causality-aware deep learning architecture for temporal graph data. In the tutorial, we illustrate this temporal graph learning approach in a simple toy example.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>pathpyG<ul> <li>algorithms<ul> <li>RollingTimeWindow</li> <li>centrality</li> <li>temporal</li> </ul> </li> <li>core<ul> <li>DAGData</li> <li>Graph</li> <li>IndexMap</li> <li>MultiOrderModel</li> <li>TemporalGraph</li> </ul> </li> <li>io<ul> <li>netzschleuder</li> </ul> </li> <li>nn<ul> <li>dbgnn</li> </ul> </li> <li>processes<ul> <li>process</li> <li>random_walk</li> <li>sampling</li> </ul> </li> <li>utils<ul> <li>config</li> <li>dbgnn</li> <li>progress</li> </ul> </li> <li>visualisations<ul> <li>_d3js<ul> <li>core</li> <li>network_plots</li> </ul> </li> <li>_matplotlib<ul> <li>core</li> <li>network_plots</li> </ul> </li> <li>_tikz<ul> <li>core</li> <li>network_plots</li> </ul> </li> <li>hist_plots</li> <li>layout</li> <li>network_plots</li> <li>plot</li> <li>utils</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/pathpyG/","title":"pathpyG","text":"<p>pathpyG is an Open Source package facilitating next-generation network analytics and graph learning for time series data on graphs.</p> <p>Building on the industry-proven data structures and concepts of <code>pytorch</code> and <code>torch_geometric</code>, pathpyG makes it easier than ever to apply machine learning to temporal graph data.</p> <p>pathpyG is jointly developed at University of Wuerzburg, Princeton University, and University of Zurich. The research behind pathpyG has been funded by the Swiss National Science Foundation via  grant 176938.</p>"},{"location":"reference/pathpyG/algorithms/","title":"algorithms","text":"<p>Algorithms for temporal path calculation and graph metrics.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG and configure your torch device if you want to use GPU .\nimport pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n\n# Generate a toy example for a temporal graph.\ng = pp.TemporalGraph.from_edge_list([\n    ['b', 'c', 2],\n    ['a', 'b', 1],\n    ['c', 'd', 3],\n    ['d', 'a', 4],\n    ['b', 'd', 2],\n    ['d', 'a', 6],\n    ['a', 'b', 7]\n])\n\n# Extract DAG capturing causal interaction sequences in temporal graph.\ndag = pp.algorithms.temporal_graph_to_event_dag(g, delta=1)\n\n# Get path object to calculate statistics.\npaths = pp.PathData.from_temporal_dag(dag)\n\n# Generate time-aggregated static representation of temporal graph\ns = g.to_static_graph()\n\n# Calculate centrality on static graph using networkx\nc = pp.algorithms.centrality.closeness_centrality(s)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/RollingTimeWindow/","title":"RollingTimeWindow","text":"<p>Iterator interface for rolling time window analysis in temporal graphs.</p>"},{"location":"reference/pathpyG/algorithms/RollingTimeWindow/#pathpyG.algorithms.RollingTimeWindow.RollingTimeWindow","title":"<code>RollingTimeWindow</code>","text":"<p>An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.</p> Source code in <code>src/pathpyG/algorithms/RollingTimeWindow.py</code> <pre><code>class RollingTimeWindow:\n    \"\"\"An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.\n    \"\"\"\n\n    def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n        \"\"\"Initialize a RollingTimeWindow instance that can be used to\n        iterate through a sequence of time-slice networks for a given\n        TemporalNetwork instance.\n\n        Args:\n            temporal_graph: TemporalGraphinstance that will be used to generate the\n                sequence of time-slice networks.\n            window_size: The width of the rolling time window used to create time-slice networks.\n            step_size: The step size in time units by which the starting \n                time of the rolling window will be incremented on each iteration.\n            return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n            weighted: Whether or not to return a weighted graph\n\n        Example:\n            ```py\n            tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n            t = pp.TemporalGraph.from_edge_list(tedges)\n            r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n            for g, w in r:\n                print('Time window ', w)\n                print(g)\n                print(g.data.edge_index)\n                print('---')\n            ```\n        \"\"\"\n        self.g = temporal_graph\n        self.window_size = window_size\n        self.step_size = step_size\n        self.current_time = self.g.start_time\n        self.return_window = return_window\n        self.weighted = weighted\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.current_time &lt;= self.g.end_time:\n            time_window = (self.current_time, self.current_time+self.window_size)\n            s = self.g.to_static_graph(weighted=self.weighted, time_window=time_window)\n            self.current_time += self.step_size\n            if self.return_window:\n                return s, time_window\n            else:\n                return s\n        else:\n            raise StopIteration()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/RollingTimeWindow/#pathpyG.algorithms.RollingTimeWindow.RollingTimeWindow.__init__","title":"<code>__init__</code>","text":"<p>Initialize a RollingTimeWindow instance that can be used to iterate through a sequence of time-slice networks for a given TemporalNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>temporal_graph</code> <p>TemporalGraphinstance that will be used to generate the sequence of time-slice networks.</p> required <code>window_size</code> <p>The width of the rolling time window used to create time-slice networks.</p> required <code>step_size</code> <p>The step size in time units by which the starting  time of the rolling window will be incremented on each iteration.</p> <code>1</code> <code>return_window</code> <p>Whether or not the iterator shall return the current time window as a second return value. Default is False.</p> <code>False</code> <code>weighted</code> <p>Whether or not to return a weighted graph</p> <code>True</code> Example <pre><code>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n  ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n  ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n  ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n  ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nr = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</code></pre> Source code in <code>src/pathpyG/algorithms/RollingTimeWindow.py</code> <pre><code>def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n    \"\"\"Initialize a RollingTimeWindow instance that can be used to\n    iterate through a sequence of time-slice networks for a given\n    TemporalNetwork instance.\n\n    Args:\n        temporal_graph: TemporalGraphinstance that will be used to generate the\n            sequence of time-slice networks.\n        window_size: The width of the rolling time window used to create time-slice networks.\n        step_size: The step size in time units by which the starting \n            time of the rolling window will be incremented on each iteration.\n        return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n        weighted: Whether or not to return a weighted graph\n\n    Example:\n        ```py\n        tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n          ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n          ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n          ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n          ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n        t = pp.TemporalGraph.from_edge_list(tedges)\n        r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n        for g, w in r:\n            print('Time window ', w)\n            print(g)\n            print(g.data.edge_index)\n            print('---')\n        ```\n    \"\"\"\n    self.g = temporal_graph\n    self.window_size = window_size\n    self.step_size = step_size\n    self.current_time = self.g.start_time\n    self.return_window = return_window\n    self.weighted = weighted\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/","title":"centrality","text":"<p>Algorithms to calculate centralities in (temporal) graphs.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG and configure your torch device if you want to use GPU acceleration.\nimport pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n\n# Generate toy example for temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ['b', 'c', 2],\n    ['a', 'b', 1],\n    ['c', 'd', 3],\n    ['d', 'a', 4],\n    ['b', 'd', 2],\n    ['d', 'a', 6],\n    ['a', 'b', 7]\n])\n\n# Extract DAG capturing causal interaction sequences in temporal graph\ndag = pp.algorithms.temporal_graph_to_event_dag(g, delta=1)\n\n# Get path object to calculate statistics.\npaths = pp.PathData.from_temporal_dag(dag)\n\n# Generate weighted (first-order) time-aggregated graph\ng = pp.HigherOrderGraph(paths, order=1)\n\n# Call networkx function `closeness_centrality` on graph\nc = pp.algorithms.centrality.closeness_centrality(g)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.__getattr__","title":"<code>__getattr__</code>","text":"<p>Map to corresponding functions in centrality module of networkx.</p> <p>Any call to a function that is not implemented in the module centrality and whose first argument is of type Graph will be delegated to the corresponding function in the networkx module <code>centrality</code>. Please refer to the networkx documentation for a reference of available functions.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>the name of the function that shall be called</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def __getattr__(name: str) -&gt; Any:\n    \"\"\"Map to corresponding functions in centrality module of networkx.\n\n    Any call to a function that is not implemented in the module centrality\n    and whose first argument is of type Graph will be delegated to the\n    corresponding function in the networkx module `centrality`. Please\n    refer to the [networkx documentation](https://networkx.org/documentation/stable/reference/algorithms/centrality.html)\n    for a reference of available functions.\n\n    Args:\n        name: the name of the function that shall be called\n    \"\"\"\n\n    def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n        if len(args) == 0:\n            raise RuntimeError(f\"Did not find method {name} with no arguments\")\n        if isinstance(args[0], TemporalGraph):\n            raise NotImplementedError(f\"Missing implementation of {name} for temporal graphs\")\n        # if first argument is of type Graph, delegate to networkx function\n        if isinstance(args[0], Graph):\n            g = to_networkx(args[0].data)\n            r = getattr(centrality, name)(g, *args[1:], **kwargs)\n            if name.index(\"centrality\") &gt; 0 and isinstance(r, dict):\n                return map_to_nodes(args[0], r)\n            return r\n        else:\n            return wrapper(*args, **kwargs)\n            # raise RuntimeError(f'Did not find method {name} that accepts first argument of type {type(args[0])}')\n\n    return wrapper\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.betweenness_centrality","title":"<code>betweenness_centrality</code>","text":"<p>Calculate the betweenness centrality of nodes based on the fast algorithm  proposed by Brandes:</p> <p>U. Brandes: A faster algorithm for betweenness centrality, The Journal of  Mathematical Sociology, 2001</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.Graph.Graph</code> <p><code>Graph</code> object for which betweenness centrality will be computed</p> required <code>sources</code> <p>optional list of source nodes for BFS-based shortest path calculation</p> <code>None</code> Example <pre><code>import pathpyG as pp\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                    ('b', 'd'), ('c', 'e'), ('d', 'e')])\nbw = pp.algorithms.betweenness_centrality(g)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def betweenness_centrality(g: Graph, sources=None) -&gt; dict[str, float]:\n    \"\"\"Calculate the betweenness centrality of nodes based on the fast algorithm \n    proposed by Brandes:\n\n    U. Brandes: A faster algorithm for betweenness centrality, The Journal of \n    Mathematical Sociology, 2001\n\n    Args:\n        g: `Graph` object for which betweenness centrality will be computed\n        sources: optional list of source nodes for BFS-based shortest path calculation\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                            ('b', 'd'), ('c', 'e'), ('d', 'e')])\n        bw = pp.algorithms.betweenness_centrality(g)\n        ```\n    \"\"\"\n    bw = defaultdict(lambda: 0.0)\n\n    if sources == None:\n        sources = [v for v in g.nodes]\n\n    for s in sources:\n        S = list()\n        P = defaultdict(list)\n\n        sigma = defaultdict(lambda: 0)  \n        sigma[s] = 1\n\n        d = defaultdict(lambda: -1)        \n        d[s] = 0\n\n        Q = [s]\n        while Q:\n            v = Q.pop(0)\n            S.append(v)\n            for w in g.successors(v):\n                if d[w] &lt; 0:\n                    Q.append(w)\n                    d[w] = d[v] + 1\n                if d[w] == d[v] + 1:\n                    # we found shortest path from s via v to w\n                    sigma[w] = sigma[w] + sigma[v]\n                    P[w].append(v)\n        delta = defaultdict(lambda: 0.0)\n        while S:\n            w = S.pop()\n            for v in P[w]:\n                delta[v] = delta[v] + sigma[v]/sigma[w] * (1 + delta[w])\n                if v != w:\n                    bw[w] = bw[w] + delta[w]\n    return bw\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.map_to_nodes","title":"<code>map_to_nodes</code>","text":"<p>Map node-level centralities in dictionary to node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.Graph.Graph</code> <p>Graph object</p> required <code>c</code> <code>typing.Dict</code> <p>dictionary mapping node indices to metrics</p> required Example <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n...                               node_id=['a', 'b', 'c'])\n&gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n&gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n&gt;&gt;&gt; print(c_mapped)\n{'a': 0.5, 'b': 2.7, 'c': 0.3}\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def map_to_nodes(g: Graph, c: Dict) -&gt; Dict:\n    \"\"\"Map node-level centralities in dictionary to node IDs.\n\n    Args:\n        g: Graph object\n        c: dictionary mapping node indices to metrics\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        ...                               node_id=['a', 'b', 'c'])\n        &gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n        &gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n        &gt;&gt;&gt; print(c_mapped)\n        {'a': 0.5, 'b': 2.7, 'c': 0.3}\n        ```\n    \"\"\"\n    return {g.mapping.to_id(i): c[i] for i in c}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_node_traversals","title":"<code>path_node_traversals</code>","text":"<p>Calculate the number of times any dag traverses each of the nodes.</p> <p>Parameters:</p> Name Type Description Default <code>dags</code> <code>pathpyG.core.DAGData.DAGData</code> <p><code>DAGData</code> object that contains path data</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_node_traversals(dags: DAGData) -&gt; Counter:\n    \"\"\"Calculate the number of times any dag traverses each of the nodes.\n\n    Args:    \n        dags: `DAGData` object that contains path data\n    \"\"\"\n    traversals = Counter()\n    for dag in dags.dags:\n        t = torch.maximum(\n            degree(dag.edge_index[1], num_nodes=dag.num_nodes), degree(dag.edge_index[0], num_nodes=dag.num_nodes)\n        )\n        for v in range(len(t)):\n            # TODO: Re-evaluate the weight representation\n            traversals[dags.mapping.to_id(v)] += t[v].item() * dag.edge_weight.max().item()\n    return traversals\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_visitation_probabilities","title":"<code>path_visitation_probabilities</code>","text":"<p>Calculate the probabilities that a randomly chosen path passes through each of the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be assigned a visitation probability of 0.05. This measure can be interpreted as ground truth for the notion of importance captured by PageRank applied to a graphical abstraction of the paths.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>pathpyG.core.DAGData.DAGData</code> <p>DAGData object that contains path data</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_visitation_probabilities(paths: DAGData) -&gt; dict:\n    \"\"\"Calculate the probabilities that a randomly chosen path passes through each of\n    the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be\n    assigned a visitation probability of 0.05. This measure can be interpreted as ground\n    truth for the notion of importance captured by PageRank applied to a graphical\n    abstraction of the paths.\n\n    Args:\n        paths: DAGData object that contains path data\n    \"\"\"\n    # if not isinstance(paths, PathData):\n    #    assert False, \"`paths` must be an instance of Paths\"\n    # Log.add('Calculating visitation probabilities...', Severity.INFO)\n\n    # entries capture the probability that a given node is visited on an arbitrary path\n    # Note: this is identical to the subpath count of zero-length paths\n    # (i.e. the relative frequencies of nodes across all pathways)\n    visit_probabilities = path_node_traversals(paths)\n\n    # total number of visits\n    visits = 0.0\n    for v in visit_probabilities:\n        visits += visit_probabilities[v]\n\n    for v in visit_probabilities:\n        visit_probabilities[v] /= visits\n    return visit_probabilities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_betweenness_centrality","title":"<code>temporal_betweenness_centrality</code>","text":"<p>Calculate the temporal betweenness of nodes in a temporal graph.</p> <p>The temporal betweenness centrality definition is based on shortest  time-respecting paths with a given maximum time difference delta, where  the length of a path is given as the number of traversed edges (i.e. not  the temporal duration of a path or the earliest arrival at a node).</p> <p>The algorithm is an adaptation of Brandes' fast algorithm for betweenness  centrality based on the following work:</p> <p>S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal Betweenness, arXiv:2006.08668v2</p> <p>Different from the algorithm proposed above, the temporal betweenness centrality implemented in pathpyG is based on a directed acyclic event graph representation of  a temporal graph and it considers a maximum waiting time of delta. The complexity  is in O(nm) where n is the number of nodes in the temporal graph and m is the number  of time-stamped edges.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.TemporalGraph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> <code>1</code> Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\nbw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_betweenness_centrality(g: TemporalGraph, delta: int = 1) -&gt; dict[str, float]:\n    \"\"\"Calculate the temporal betweenness of nodes in a temporal graph.\n\n    The temporal betweenness centrality definition is based on shortest \n    time-respecting paths with a given maximum time difference delta, where \n    the length of a path is given as the number of traversed edges (i.e. not \n    the temporal duration of a path or the earliest arrival at a node).\n\n    The algorithm is an adaptation of Brandes' fast algorithm for betweenness \n    centrality based on the following work:\n\n    S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal\n    Betweenness, arXiv:2006.08668v2\n\n    Different from the algorithm proposed above, the temporal betweenness centrality\n    implemented in pathpyG is based on a directed acyclic event graph representation of \n    a temporal graph and it considers a maximum waiting time of delta. The complexity \n    is in O(nm) where n is the number of nodes in the temporal graph and m is the number \n    of time-stamped edges.\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        bw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.M\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    # add edges from first-order source nodes to edge events\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges], dim=1)\n    src_indices = torch.unique(src_edges_src).tolist()\n\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.M+g.N)\n\n    e_i = g.data.edge_index.numpy()\n\n    fo_nodes = dict()\n    for v in range(g.M+g.N):\n        if v &lt; g.M:  # return first-order target node otherwise\n            fo_nodes[v] = e_i[1, v]\n        else:\n            fo_nodes[v] = v - g.M\n\n    bw: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n    # for all first-order nodes\n    for s in tqdm(src_indices):\n\n        # for any given s, d[v] is the shortest path distance from s to v\n        # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)\n        delta_: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n        # for any given s, sigma[v] counts shortest paths from s to v\n        sigma: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma[s] = 1\n\n        sigma_fo: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma_fo[fo_nodes[s]] = 1\n\n        dist: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist[s] = 0\n\n        dist_fo: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist_fo[fo_nodes[s]] = 0\n\n        # for any given s, P[v] is the set of predecessors of v on shortest paths from s\n        P = defaultdict(set)\n\n        # Q is a queue, so we append at the end and pop from the start\n        Q: deque = deque()\n        Q.append(s)\n\n        # S is a stack, so we append at the end and pop from the end\n        S = list()\n\n        # dijkstra with path counting\n        while Q:\n            v = Q.popleft()\n            # for all successor events within delta\n            for w in event_graph.successors(v):\n\n                # we dicover w for the first time\n                if dist[w] == -1:\n                    dist[w] = dist[v] + 1\n                    if dist_fo[fo_nodes[w]] == -1:\n                        dist_fo[fo_nodes[w]] = dist[v] + 1\n                    S.append(w)\n                    Q.append(w)\n                # we found a shortest path to event w via event v\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[w] + sigma[v]\n                    P[w].add(v)\n                    # we found a shortest path to first-order node of event w\n                    if dist[w] == dist_fo[fo_nodes[w]]:\n                        sigma_fo[fo_nodes[w]] += sigma[v]\n\n        c = 0\n        for i in dist_fo:\n            if dist_fo[i] &gt;= 0:\n                c += 1\n        bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1\n\n        while S:\n            w = S.pop()\n            # work backwards through paths to all targets and sum delta and sigma   \n            if dist[w] == dist_fo[fo_nodes[w]]:\n                # v_fo = fo_tgt(v, g, src_indices, tgt_indices)\n                delta_[w] += (sigma[w]/sigma_fo[fo_nodes[w]])\n            for v in P[w]:\n                delta_[v] += (sigma[v]/sigma[w]) * delta_[w]\n                bw[fo_nodes[v]] += delta_[w] * (sigma[v]/sigma[w])\n\n    # map index-based centralities to node IDs\n    bw_id = defaultdict(lambda: 0.0)\n    for idx in bw:\n        bw_id[g.mapping.to_id(idx)] = bw[idx]\n    return bw_id\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_closeness_centrality","title":"<code>temporal_closeness_centrality</code>","text":"<p>Calculates the temporal closeness centrality of nodes based on observed shortest time-respecting paths between all nodes.</p> <p>Following the definition by M. A. Beauchamp 1965 (https://doi.org/10.1002/bs.3830100205).</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.TemporalGraph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> required Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\ncl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_closeness_centrality(g: TemporalGraph, delta: int) -&gt; dict[str, float]:\n    \"\"\"Calculates the temporal closeness centrality of nodes based on\n    observed shortest time-respecting paths between all nodes.\n\n    Following the definition by M. A. Beauchamp 1965\n    (https://doi.org/10.1002/bs.3830100205).\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        cl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    centralities = dict()\n    dist, _ = temporal_shortest_paths(g, delta)\n    for x in g.nodes:\n        centralities[x] = sum((g.N - 1) / dist[_np.arange(g.N) != g.mapping.to_idx(x), g.mapping.to_idx(x)])\n\n    return centralities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/temporal/","title":"temporal","text":"<p>Algorithms for the analysis of time-respecting paths in temporal graphs.</p>"},{"location":"reference/pathpyG/core/","title":"core","text":"<p>Core classes for (temporal) graphs, paths, and higher-order De Bruijn graphs.</p> <p>The classes in the <code>core</code> module can be used to implement integrated pipelines to preprocess time-stamped network data, do inference and model selection of higher-order De Bruijn graph models and address temporal graph learning tasks based on time-aware graph neural networks.</p> Example <pre><code>import pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n\n# Generate toy example for temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ['b', 'c', 2],\n    ['a', 'b', 1],\n    ['c', 'd', 3],\n    ['d', 'a', 4],\n    ['b', 'd', 2],\n    ['d', 'a', 6],\n    ['a', 'b', 7]])\n\n# Extract DAG capturing causal interaction sequences in temporal graph\ndag = pp.algorithms.temporal_graph_to_event_dag(g, delta=1)\n\n# Calculate path statistics\npaths = pp.DAGData.from_temporal_dag(dag)\n\n# Compute first- and second-order De Bruijn graph model\ng1 = pp.HigherOrderGraph(paths, order=1, node_id=g.data[\"node_id\"])\ng2 = pp.HigherOrderGraph(paths, order=2, node_id=g.data[\"node_id\"])\n</code></pre>"},{"location":"reference/pathpyG/core/DAGData/","title":"DAGData","text":""},{"location":"reference/pathpyG/core/DAGData/#pathpyG.core.DAGData.DAGData","title":"<code>DAGData</code>","text":"<p>Class that can be used to store multiple observations of directed acyclic graphs (or - as a special case - walks)</p> Example <pre><code>import pathpyG as pp\nimport torch\n\npp.config['torch']['device'] = 'cuda'\n\n# Generate toy example graph\ng = pp.Graph.from_edge_list([('a', 'c'),\n                     ('b', 'c'),\n                     ('c', 'd'),\n                     ('c', 'e')])\n\n# Store observations of walks or dags using the index mapping\n# from the graph above\ndags = pp.DAGData(g.mapping)\n\n# Append one observation of a DAG\nd = torch.tensor([[0,2,2], # a -&gt; c, c -&gt; d, c -&gt; e\n          [2,3,4]])\ndags.append_dag(d, weight=1.0)\n\n# Append observation of a walk\ndags.append_walk(('a', 'c', 'd'), weight=2.0)\nprint(dags)\n</code></pre> Source code in <code>src/pathpyG/core/DAGData.py</code> <pre><code>class DAGData:\n    \"\"\"Class that can be used to store multiple observations of\n    directed acyclic graphs (or - as a special case - walks)\n\n    Example:\n        ```py\n        import pathpyG as pp\n        import torch\n\n        pp.config['torch']['device'] = 'cuda'\n\n        # Generate toy example graph\n        g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\n\n        # Store observations of walks or dags using the index mapping\n        # from the graph above\n        dags = pp.DAGData(g.mapping)\n\n        # Append one observation of a DAG\n        d = torch.tensor([[0,2,2], # a -&gt; c, c -&gt; d, c -&gt; e\n                  [2,3,4]])\n        dags.append_dag(d, weight=1.0)\n\n        # Append observation of a walk\n        dags.append_walk(('a', 'c', 'd'), weight=2.0)\n        print(dags)\n        ```\n    \"\"\"\n\n    def __init__(self, mapping: IndexMap | None = None) -&gt; None:\n        self.dags: list = []\n\n        if mapping:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n        # If the function add_walks is used, all walks are saved in one Data object\n        # walk_index stores a tuple that contains the idx in the dag list, the start and end index of the walk\n        self.walk_index: list[tuple[int, int, int]] = []\n\n    @property\n    def num_dags(self) -&gt; int:\n        \"\"\"Return the number of stored dags.\"\"\"\n        return len(self.dags)\n\n    def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n        \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n        Example:\n                ```py\n                import torch\n                import pathpyG as pp\n\n                g = pp.Graph.from_edge_list([('a', 'c'),\n                        ('b', 'c'),\n                        ('c', 'd'),\n                        ('c', 'e')])\n\n                walks = pp.DAGData(g.mapping)\n                walks.append_walk(('a', 'c', 'd'), weight=2.0)\n                paths.append_walk(('b', 'c', 'e'), weight=1.0)\n                ```\n        \"\"\"\n        idx_seq = self.mapping.to_idxs(node_seq)\n        idx = torch.arange(len(node_seq))\n        edge_index = torch.stack([idx[:-1], idx[1:]])\n\n        self.walk_index.append((len(self.dags), 0, len(node_seq)))\n        self.dags.append(\n            Data(\n                edge_index=edge_index,\n                node_sequence=idx_seq.unsqueeze(1),\n                num_nodes=len(node_seq),\n                edge_weight=torch.full((edge_index.size(1),), weight),\n            )\n        )\n\n    def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n        \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\"\"\"\n        idx_seqs = torch.cat([self.mapping.to_idxs(seq) for seq in node_seqs]).unsqueeze(1)\n        path_lengths = torch.tensor([len(seq) for seq in node_seqs])\n        big_idx = torch.arange(path_lengths.sum())\n        big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n        # remove the edges that connect different walks\n        mask = torch.ones(big_edge_index.size(1), dtype=torch.bool)\n        cum_sum = cumsum(path_lengths, 0)\n        mask[cum_sum[1:-1] - 1] = False\n        big_edge_index = big_edge_index[:, mask]\n\n        self.walk_index += [\n            (len(self.dags), start.item(), end.item()) for start, end in torch.vstack([cum_sum[:-1], cum_sum[1:]]).T\n        ]\n        self.dags.append(\n            Data(\n                edge_index=big_edge_index,\n                node_sequence=idx_seqs,\n                num_nodes=idx_seqs.max().item() + 1,\n                edge_weight=torch.cat([torch.full((length,), w) for length, w in zip(path_lengths, weights)]),\n            )\n        )\n\n    def get_walk(self, i: int) -&gt; tuple:\n        i_dag, start, end = self.walk_index[i]\n        return tuple(self.mapping.to_ids(self.dags[i_dag].node_sequence[start:end].squeeze()))\n\n    def append_dag(self, edge_index: torch.Tensor, weight: float = 1.0) -&gt; None:\n        \"\"\"Add an observation of a DAG based on an edge index\n\n        Example:\n            ```py\n            import torch\n            import pathpyG as pp\n\n            dags = pp.DAGData()\n\n        \"\"\"\n        edge_index = coalesce(edge_index.long())\n        num_nodes = edge_index.max().item() + 1\n        node_idx = torch.arange(num_nodes)\n        self.dags.append(\n            Data(\n                edge_index=edge_index,\n                node_sequence=node_idx.unsqueeze(1),\n                num_nodes=num_nodes,\n                edge_weight=torch.full((edge_index.size(1),), weight),\n                # TODO: Re-evaluate the weight representation\n                # weight=torch.tensor(weight),\n            )\n        )\n\n    def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n        \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n        return self.mapping.to_ids(node_seq)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the DAGData object.\"\"\"\n        num_dags = len(self.dags)\n        weight = sum([d.edge_weight.max().item() for d in self.dags])\n        s = f\"DAGData with {num_dags} dags with total weight {weight}\"\n        return s\n\n    @staticmethod\n    def from_ngram(file: str, sep: str = \",\", weight: bool = True) -&gt; DAGData:\n        with open(file, \"r\", encoding=\"utf-8\") as f:\n            if weight:\n                paths_and_weights = [line.split(sep) for line in f]\n                paths = [path[:-1] for path in paths_and_weights]\n                weights = [float(path[-1]) for path in paths_and_weights]\n            else:\n                paths = [line.split(sep) for line in f]\n                weights = [1.0] * len(paths)\n\n        mapping = IndexMap()\n        mapping.add_ids(np.concatenate([np.array(path) for path in paths]))\n\n        dags = DAGData()\n        dags.mapping = mapping\n        dags.append_walks(node_seqs=paths, weights=weights)\n\n        return dags\n</code></pre>"},{"location":"reference/pathpyG/core/DAGData/#pathpyG.core.DAGData.DAGData.num_dags","title":"<code>num_dags: int</code>  <code>property</code>","text":"<p>Return the number of stored dags.</p>"},{"location":"reference/pathpyG/core/DAGData/#pathpyG.core.DAGData.DAGData.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the DAGData object.</p> Source code in <code>src/pathpyG/core/DAGData.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the DAGData object.\"\"\"\n    num_dags = len(self.dags)\n    weight = sum([d.edge_weight.max().item() for d in self.dags])\n    s = f\"DAGData with {num_dags} dags with total weight {weight}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/DAGData/#pathpyG.core.DAGData.DAGData.append_dag","title":"<code>append_dag</code>","text":"<p>Add an observation of a DAG based on an edge index</p> Example <p>```py import torch import pathpyG as pp</p> <p>dags = pp.DAGData()</p> Source code in <code>src/pathpyG/core/DAGData.py</code> <pre><code>def append_dag(self, edge_index: torch.Tensor, weight: float = 1.0) -&gt; None:\n    \"\"\"Add an observation of a DAG based on an edge index\n\n    Example:\n        ```py\n        import torch\n        import pathpyG as pp\n\n        dags = pp.DAGData()\n\n    \"\"\"\n    edge_index = coalesce(edge_index.long())\n    num_nodes = edge_index.max().item() + 1\n    node_idx = torch.arange(num_nodes)\n    self.dags.append(\n        Data(\n            edge_index=edge_index,\n            node_sequence=node_idx.unsqueeze(1),\n            num_nodes=num_nodes,\n            edge_weight=torch.full((edge_index.size(1),), weight),\n            # TODO: Re-evaluate the weight representation\n            # weight=torch.tensor(weight),\n        )\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/DAGData/#pathpyG.core.DAGData.DAGData.append_walk","title":"<code>append_walk</code>","text":"<p>Add an observation of a walk based on a list or tuple of node IDs or indices</p> Example <pre><code>import torch\nimport pathpyG as pp\n\ng = pp.Graph.from_edge_list([('a', 'c'),\n        ('b', 'c'),\n        ('c', 'd'),\n        ('c', 'e')])\n\nwalks = pp.DAGData(g.mapping)\nwalks.append_walk(('a', 'c', 'd'), weight=2.0)\npaths.append_walk(('b', 'c', 'e'), weight=1.0)\n</code></pre> Source code in <code>src/pathpyG/core/DAGData.py</code> <pre><code>def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n    \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n    Example:\n            ```py\n            import torch\n            import pathpyG as pp\n\n            g = pp.Graph.from_edge_list([('a', 'c'),\n                    ('b', 'c'),\n                    ('c', 'd'),\n                    ('c', 'e')])\n\n            walks = pp.DAGData(g.mapping)\n            walks.append_walk(('a', 'c', 'd'), weight=2.0)\n            paths.append_walk(('b', 'c', 'e'), weight=1.0)\n            ```\n    \"\"\"\n    idx_seq = self.mapping.to_idxs(node_seq)\n    idx = torch.arange(len(node_seq))\n    edge_index = torch.stack([idx[:-1], idx[1:]])\n\n    self.walk_index.append((len(self.dags), 0, len(node_seq)))\n    self.dags.append(\n        Data(\n            edge_index=edge_index,\n            node_sequence=idx_seq.unsqueeze(1),\n            num_nodes=len(node_seq),\n            edge_weight=torch.full((edge_index.size(1),), weight),\n        )\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/DAGData/#pathpyG.core.DAGData.DAGData.append_walks","title":"<code>append_walks</code>","text":"<p>Add multiple observations of walks based on lists or tuples of node IDs or indices</p> Source code in <code>src/pathpyG/core/DAGData.py</code> <pre><code>def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n    \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\"\"\"\n    idx_seqs = torch.cat([self.mapping.to_idxs(seq) for seq in node_seqs]).unsqueeze(1)\n    path_lengths = torch.tensor([len(seq) for seq in node_seqs])\n    big_idx = torch.arange(path_lengths.sum())\n    big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n    # remove the edges that connect different walks\n    mask = torch.ones(big_edge_index.size(1), dtype=torch.bool)\n    cum_sum = cumsum(path_lengths, 0)\n    mask[cum_sum[1:-1] - 1] = False\n    big_edge_index = big_edge_index[:, mask]\n\n    self.walk_index += [\n        (len(self.dags), start.item(), end.item()) for start, end in torch.vstack([cum_sum[:-1], cum_sum[1:]]).T\n    ]\n    self.dags.append(\n        Data(\n            edge_index=big_edge_index,\n            node_sequence=idx_seqs,\n            num_nodes=idx_seqs.max().item() + 1,\n            edge_weight=torch.cat([torch.full((length,), w) for length, w in zip(path_lengths, weights)]),\n        )\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/DAGData/#pathpyG.core.DAGData.DAGData.map_node_seq","title":"<code>map_node_seq</code>","text":"<p>Map a sequence of node indices (e.g. representing a higher-order node) to node IDs</p> Source code in <code>src/pathpyG/core/DAGData.py</code> <pre><code>def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n    \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n    return self.mapping.to_ids(node_seq)\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/","title":"Graph","text":""},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as \n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if 'num_nodes' not in data:\n            data.num_nodes = data.edge_index.max().item()+1\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if data.edge_index.get_sparse_size(dim=0) != data.num_nodes or data.edge_index.get_sparse_size(dim=1) != data.num_nodes:\n            raise Exception('sparse size of EdgeIndex should match number of nodes!')\n\n        # sort EdgeIndex and validate\n        data.edge_index = data.edge_index.sort_by('row').values\n        data.edge_index.validate()\n\n        self.data = data\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i\n            for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes=None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can \n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index\n\n        Example:\n            ```py\n            import pathpyG as pp\n\n            g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            print(g)\n\n            g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                                    mapping=pp.IndexMap(['a', 'b', 'c']))\n            print(g)\n            ```\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else: \n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(\n            d,\n            mapping=mapping\n        )\n\n\n    @staticmethod\n    def from_edge_list(edge_list: Iterable[Tuple[str, str]], is_undirected: bool = False) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list. Edges can be given as string tuples and a mapping\n        between node IDs and indices will be created automatically.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n\n        Example:\n            ```\n            import pathpyG as pp\n\n            l = [('a', 'b'), ('b', 'c'), ('a', 'c')]\n            g = pp.Graph.from_edge_list(l)\n            print(g)\n            print(g.mapping)\n            ```\n        \"\"\"\n        sources = []\n        targets = []\n\n        mapping = IndexMap()\n\n        for v, w in edge_list:\n            mapping.add_id(v)\n            mapping.add_id(w)\n            sources.append(mapping.to_idx(v))\n            targets.append(mapping.to_idx(w))\n\n        edge_index = EdgeIndex([sources, targets], sparse_size=(mapping.num_ids(), mapping.num_ids()), is_undirected=is_undirected, device=config['torch']['device'])\n        return Graph(\n            Data(edge_index=edge_index),\n            mapping=mapping\n        )\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        tf = ToUndirected()\n        d = tf(self.data)\n        # unfortunately, the application of a transform creates a new edge_index of type tensor\n        # so we have to recreate the EdgeIndex tensor and sort it again\n\n        e = EdgeIndex(data=d.edge_index, is_undirected=True)\n        d.edge_index = e\n        return Graph(d, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\"\"\"\n        i, w = torch_geometric.utils.coalesce(self.data.edge_index, torch.ones(self.M).to(config[\"torch\"][\"device\"]))\n        return Graph(Data(edge_index=i, edge_weight=w), mapping=self.mapping)\n\n    @staticmethod\n    def attr_types(attr: Dict) -&gt; Dict:\n        \"\"\"\n        Return name, type, and size of all node, edge, and graph attributes.\n\n        This method returns a dictionary that contains the name (key), as well as\n        the type and size of all attributes.\n        \"\"\"\n        a = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                a[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                a[k] = str(t)\n        return a\n\n    def node_attrs(self) -&gt; List:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_id` attribute.\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_id\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; Generator[Union[int, str], None, None]:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a generator object that yields all nodes.\n        If an IndexMap is used, nodes\n        are returned as str IDs. If no IndexMap is used, nodes\n        are returned as integer indices.\n        \"\"\"\n        for i in range(self.N):\n            yield self.mapping.to_id(i)\n\n    @property\n    def edges(self) -&gt; Generator[Union[Tuple[int, int], Tuple[str, str]], None, None]:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a generator object that yields all edges.\n        If an IndexMap is used to map node indices to string IDs, edges\n        are returned as tuples of str IDs. If no mapping is used, edges\n        are returned as tuples of integer indices.\n        \"\"\"\n        for e in self.data.edge_index.t():\n            yield self.mapping.to_id(e[0].item()), self.mapping.to_id(e[1].item())\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([])\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n        \"\"\"        \n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([])\n\n    def successors(self, node: Union[int, str] | tuple) \\\n            -&gt; Generator[Union[int, str] | tuple, None, None]:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n        \"\"\"\n\n        for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n            yield self.mapping.to_id(j.item())\n\n    def predecessors(self, node: Union[str, int] | tuple) \\\n            -&gt; Generator[Union[int, str] | tuple, None, None]:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n        \"\"\"\n        for i in self.get_predecessors(self.mapping.to_idx(node)):  # type: ignore\n            yield self.mapping.to_id(i.item())\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID \n        \"\"\"\n        row = self.mapping.to_idx(v)\n        ((row_ptr, col), perm) = self.data.edge_index.get_csr()\n        row_start = row_ptr[row]\n        row_end   = row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in col[row_start:row_end]\n\n    def get_sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index, edge_attr=self.data[edge_attr], num_nodes=self.N\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return in-degrees of nodes in directed network.\"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return out-degrees of nodes in directed network.\"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n        \"\"\"\n        Return degrees of nodes.\n\n        Args:\n            mode:   `in` or `out` to calculate the in- or out-degree for\n                directed networks.\n        \"\"\"\n        if mode == \"in\":\n            d = torch_geometric.utils.degree(\n                self.data.edge_index[1], num_nodes=self.N, dtype=torch.int\n            )\n        else:\n            d = torch_geometric.utils.degree(\n                self.data.edge_index[0], num_nodes=self.N, dtype=torch.int\n            )\n        return {self.mapping.to_id(i): d[i].item() for i in range(self.N)}\n\n    def get_laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.get_laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.get_laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization:  normalization parameter passed to pyG `get_laplacian`\n                            function\n            edge_attr:      optinal name of numerical edge attribute that shall\n                            be passed to pyG `get_laplacian` function as edge weight\n        \"\"\"\n        if edge_attr is None:\n            index, weight =torch_geometric.utils.get_laplacian(\n                self.data.edge_index, normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index,\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def add_node_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n        \"\"\"Add one-hot encoding of nodes to node attribute.\n\n        Args:\n            attr_name: attribute name used to store one-hot encoding\n            dim: dimension of one-hot encoding\n        \"\"\"\n        if dim == 0:\n            dim = self.N\n        self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n            config[\"torch\"][\"device\"]\n        )[: self.N]\n\n    def add_edge_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n        \"\"\"Add one-hot encoding of edges to edge attribute.\n\n        Args:\n            attr_name: attribute name used to store one-hot encoding\n            dim: dimension of one-hot encoding\n        \"\"\"\n        if dim == 0:\n            dim = self.M\n        self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n            config[\"torch\"][\"device\"]\n        )[: self.M]\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                print(key, \"is not a graph attribute\")\n                return None\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        elif key in self.data.keys():\n            return self.data[key[0]]\n        else:\n            print(key[0], \"is not a node or edge attribute\")\n            return None\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                self.data[key] = val\n            else:\n                print(key, \"is not a graph attribute\")\n        elif self.key[0].starts_with(\"node_\"):  # type: ignore\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif self.key[0].starts_with(\"edge_\"):  # type: ignore\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            print(key[0], \"is not a node or edge attribute\")\n\n    @property\n    def N(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns the number of nodes in the graph.\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def M(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the numnber of directed edges is returned.\n        \"\"\"\n        return self.data.num_edges  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\"\"\"\n        return not is_undirected(self.data.edge_index)        \n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\"\"\"\n        return is_undirected(self.data.edge_index)\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\"\"\"\n        return self.data.has_self_loops()\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr_types = Graph.attr_types(self.data.to_dict())\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.N, self.M)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.N, self.M)\n        if len(self.data.node_attrs()) &gt; 0:\n            s += \"\\nNode attributes\\n\"\n            for a in self.data.node_attrs():\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.edge_attrs()) &gt; 1:\n            s += \"\\nEdge attributes\\n\"\n            for a in self.data.edge_attrs():\n                if a != \"edge_index\":\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n            self.data.node_attrs()\n        ):\n            s += \"\\nGraph attributes\\n\"\n            for a in self.data.keys():\n                if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.M","title":"<code>M: int</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the numnber of directed edges is returned.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.N","title":"<code>N: int</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns the number of nodes in the graph.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.edges","title":"<code>edges: Generator[Union[Tuple[int, int], Tuple[str, str]], None, None]</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a generator object that yields all edges. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of str IDs. If no mapping is used, edges are returned as tuples of integer indices.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.in_degrees","title":"<code>in_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return in-degrees of nodes in directed network.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.nodes","title":"<code>nodes: Generator[Union[int, str], None, None]</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a generator object that yields all nodes. If an IndexMap is used, nodes are returned as str IDs. If no IndexMap is used, nodes are returned as integer indices.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.out_degrees","title":"<code>out_degrees: Dict[str, float]</code>  <code>property</code>","text":"<p>Return out-degrees of nodes in directed network.</p>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            print(key, \"is not a graph attribute\")\n            return None\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    elif key in self.data.keys():\n        return self.data[key[0]]\n    else:\n        print(key[0], \"is not a node or edge attribute\")\n        return None\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as  optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.IndexMap.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as \n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if 'num_nodes' not in data:\n        data.num_nodes = data.edge_index.max().item()+1\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if data.edge_index.get_sparse_size(dim=0) != data.num_nodes or data.edge_index.get_sparse_size(dim=1) != data.num_nodes:\n        raise Exception('sparse size of EdgeIndex should match number of nodes!')\n\n    # sort EdgeIndex and validate\n    data.edge_index = data.edge_index.sort_by('row').values\n    data.edge_index.validate()\n\n    self.data = data\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i\n        for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            self.data[key] = val\n        else:\n            print(key, \"is not a graph attribute\")\n    elif self.key[0].starts_with(\"node_\"):  # type: ignore\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif self.key[0].starts_with(\"edge_\"):  # type: ignore\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        print(key[0], \"is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr_types = Graph.attr_types(self.data.to_dict())\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} (directed) edges\\n\".format(self.N, self.M)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.N, self.M)\n    if len(self.data.node_attrs()) &gt; 0:\n        s += \"\\nNode attributes\\n\"\n        for a in self.data.node_attrs():\n            s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.edge_attrs()) &gt; 1:\n        s += \"\\nEdge attributes\\n\"\n        for a in self.data.edge_attrs():\n            if a != \"edge_index\":\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n        self.data.node_attrs()\n    ):\n        s += \"\\nGraph attributes\\n\"\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.add_edge_ohe","title":"<code>add_edge_ohe</code>","text":"<p>Add one-hot encoding of edges to edge attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attr_name</code> <code>str</code> <p>attribute name used to store one-hot encoding</p> required <code>dim</code> <code>int</code> <p>dimension of one-hot encoding</p> <code>0</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def add_edge_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n    \"\"\"Add one-hot encoding of edges to edge attribute.\n\n    Args:\n        attr_name: attribute name used to store one-hot encoding\n        dim: dimension of one-hot encoding\n    \"\"\"\n    if dim == 0:\n        dim = self.M\n    self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n        config[\"torch\"][\"device\"]\n    )[: self.M]\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.add_node_ohe","title":"<code>add_node_ohe</code>","text":"<p>Add one-hot encoding of nodes to node attribute.</p> <p>Parameters:</p> Name Type Description Default <code>attr_name</code> <code>str</code> <p>attribute name used to store one-hot encoding</p> required <code>dim</code> <code>int</code> <p>dimension of one-hot encoding</p> <code>0</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def add_node_ohe(self, attr_name: str, dim: int = 0) -&gt; None:\n    \"\"\"Add one-hot encoding of nodes to node attribute.\n\n    Args:\n        attr_name: attribute name used to store one-hot encoding\n        dim: dimension of one-hot encoding\n    \"\"\"\n    if dim == 0:\n        dim = self.N\n    self.data[attr_name] = torch.eye(dim, dtype=torch.float).to(\n        config[\"torch\"][\"device\"]\n    )[: self.N]\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.attr_types","title":"<code>attr_types</code>  <code>staticmethod</code>","text":"<p>Return name, type, and size of all node, edge, and graph attributes.</p> <p>This method returns a dictionary that contains the name (key), as well as the type and size of all attributes.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef attr_types(attr: Dict) -&gt; Dict:\n    \"\"\"\n    Return name, type, and size of all node, edge, and graph attributes.\n\n    This method returns a dictionary that contains the name (key), as well as\n    the type and size of all attributes.\n    \"\"\"\n    a = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            a[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            a[k] = str(t)\n    return a\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate the in- or out-degree for directed networks.</p> <code>'in'</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def degrees(self, mode: str = \"in\") -&gt; Dict[str, float]:\n    \"\"\"\n    Return degrees of nodes.\n\n    Args:\n        mode:   `in` or `out` to calculate the in- or out-degree for\n            directed networks.\n    \"\"\"\n    if mode == \"in\":\n        d = torch_geometric.utils.degree(\n            self.data.edge_index[1], num_nodes=self.N, dtype=torch.int\n        )\n    else:\n        d = torch_geometric.utils.degree(\n            self.data.edge_index[0], num_nodes=self.N, dtype=torch.int\n        )\n    return {self.mapping.to_id(i): d[i].item() for i in range(self.N)}\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def edge_attrs(self) -&gt; List:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can  be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.IndexMap.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index</p> <code>None</code> Example <pre><code>import pathpyG as pp\n\ng = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\nprint(g)\n\ng = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                        mapping=pp.IndexMap(['a', 'b', 'c']))\nprint(g)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes=None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can \n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        print(g)\n\n        g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n                                mapping=pp.IndexMap(['a', 'b', 'c']))\n        print(g)\n        ```\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else: \n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(\n        d,\n        mapping=mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list. Edges can be given as string tuples and a mapping between node IDs and indices will be created automatically.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required Example <pre><code>import pathpyG as pp\n\nl = [('a', 'b'), ('b', 'c'), ('a', 'c')]\ng = pp.Graph.from_edge_list(l)\nprint(g)\nprint(g.mapping)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(edge_list: Iterable[Tuple[str, str]], is_undirected: bool = False) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list. Edges can be given as string tuples and a mapping\n    between node IDs and indices will be created automatically.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n\n    Example:\n        ```\n        import pathpyG as pp\n\n        l = [('a', 'b'), ('b', 'c'), ('a', 'c')]\n        g = pp.Graph.from_edge_list(l)\n        print(g)\n        print(g.mapping)\n        ```\n    \"\"\"\n    sources = []\n    targets = []\n\n    mapping = IndexMap()\n\n    for v, w in edge_list:\n        mapping.add_id(v)\n        mapping.add_id(w)\n        sources.append(mapping.to_idx(v))\n        targets.append(mapping.to_idx(w))\n\n    edge_index = EdgeIndex([sources, targets], sparse_size=(mapping.num_ids(), mapping.num_ids()), is_undirected=is_undirected, device=config['torch']['device'])\n    return Graph(\n        Data(edge_index=edge_index),\n        mapping=mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.get_laplacian","title":"<code>get_laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.get_laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code>             function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall             be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.get_laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.get_laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization:  normalization parameter passed to pyG `get_laplacian`\n                        function\n        edge_attr:      optinal name of numerical edge attribute that shall\n                        be passed to pyG `get_laplacian` function as edge weight\n    \"\"\"\n    if edge_attr is None:\n        index, weight =torch_geometric.utils.get_laplacian(\n            self.data.edge_index, normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index,\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n    \"\"\"        \n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([])\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.get_sparse_adj_matrix","title":"<code>get_sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index, edge_attr=self.data[edge_attr], num_nodes=self.N\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([])\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\"\"\"\n    return not is_undirected(self.data.edge_index)        \n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID \n    \"\"\"\n    row = self.mapping.to_idx(v)\n    ((row_ptr, col), perm) = self.data.edge_index.get_csr()\n    row_start = row_ptr[row]\n    row_end   = row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\"\"\"\n    return is_undirected(self.data.edge_index)\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_id</code> attribute.</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def node_attrs(self) -&gt; List:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_id` attribute.\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_id\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) \\\n        -&gt; Generator[Union[int, str] | tuple, None, None]:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n    \"\"\"\n    for i in self.get_predecessors(self.mapping.to_idx(node)):  # type: ignore\n        yield self.mapping.to_id(i.item())\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) \\\n        -&gt; Generator[Union[int, str] | tuple, None, None]:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n    \"\"\"\n\n    for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n        yield self.mapping.to_id(j.item())\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    tf = ToUndirected()\n    d = tf(self.data)\n    # unfortunately, the application of a transform creates a new edge_index of type tensor\n    # so we have to recreate the EdgeIndex tensor and sort it again\n\n    e = EdgeIndex(data=d.edge_index, is_undirected=True)\n    d.edge_index = e\n    return Graph(d, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/Graph/#pathpyG.core.Graph.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> Source code in <code>src/pathpyG/core/Graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\"\"\"\n    i, w = torch_geometric.utils.coalesce(self.data.edge_index, torch.ones(self.M).to(config[\"torch\"][\"device\"]))\n    return Graph(Data(edge_index=i, edge_weight=w), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/","title":"IndexMap","text":""},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap","title":"<code>IndexMap</code>","text":"<p>Maps node indices to string ids</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>class IndexMap:\n    \"\"\"Maps node indices to string ids\"\"\"\n    def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n        \"\"\"Initialize mapping from indices to node IDs.\"\"\"\n        if node_ids is not None:\n            assert len(node_ids) == len(set(node_ids)), \"node_id entries must be unique\"\n            # first-order: nodes = integer indices\n            self.node_ids: np.ndarray = np.array(node_ids)\n            self.id_to_idx: Dict[str, int] = {v: i for i, v in enumerate(node_ids)}\n            self.has_ids = True\n        else:\n            self.node_ids = np.array([])\n            self.id_to_idx = {}\n            self.has_ids = False\n\n    def num_ids(self) -&gt; int:\n        return len(self.node_ids)\n\n    def add_id(self, node_id: str) -&gt; None:\n        \"\"\"Assigns additional ID to next consecutive index.\"\"\"\n        if node_id not in self.id_to_idx:\n            idx = self.num_ids()\n            self.node_ids = np.append(self.node_ids, node_id)\n            self.id_to_idx[node_id] = idx\n            self.has_ids = True\n\n    def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n        \"\"\"Assigns additional IDs to next consecutive indices.\"\"\"\n        cur_num_ids = self.num_ids()\n        node_ids = np.array(node_ids)\n        mask = np.isin(node_ids, self.node_ids)\n        new_ids = np.unique(node_ids[~mask])\n        self.node_ids = np.append(self.node_ids, new_ids)\n        self.id_to_idx.update({v: i + cur_num_ids for i, v in enumerate(new_ids)})\n        self.has_ids = True\n\n    def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n        \"\"\"Map index to ID if mapping is defined, return index otherwise.\"\"\"\n        if self.has_ids:\n            if self.node_ids.ndim == 1:\n                return self.node_ids[idx]\n            else:\n                return tuple(self.node_ids[idx])\n        else:\n            return idx\n\n    def to_ids(self, idxs: list | tuple) -&gt; list:\n        \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise.\"\"\"\n        if self.has_ids:\n            return self.node_ids[idxs].tolist()\n        else:\n            return idxs\n\n    def to_idx(self, node: Union[str, int]) -&gt; int:\n        \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\"\"\"\n        if self.has_ids:\n            return self.id_to_idx[node]\n        else:\n            return node\n\n    def to_idxs(self, nodes: list | tuple) -&gt; torch.Tensor:\n        \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise.\"\"\"\n        if self.has_ids:\n            return torch.tensor([self.id_to_idx[node] for node in nodes])\n        else:\n            return torch.tensor(nodes)\n\n    def __str__(self) -&gt; str:\n        s = ''\n        for v in self.id_to_idx:\n            s += str(v) + ' -&gt; ' + str(self.to_idx(v)) + '\\n'\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.__init__","title":"<code>__init__</code>","text":"<p>Initialize mapping from indices to node IDs.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n    \"\"\"Initialize mapping from indices to node IDs.\"\"\"\n    if node_ids is not None:\n        assert len(node_ids) == len(set(node_ids)), \"node_id entries must be unique\"\n        # first-order: nodes = integer indices\n        self.node_ids: np.ndarray = np.array(node_ids)\n        self.id_to_idx: Dict[str, int] = {v: i for i, v in enumerate(node_ids)}\n        self.has_ids = True\n    else:\n        self.node_ids = np.array([])\n        self.id_to_idx = {}\n        self.has_ids = False\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.add_id","title":"<code>add_id</code>","text":"<p>Assigns additional ID to next consecutive index.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def add_id(self, node_id: str) -&gt; None:\n    \"\"\"Assigns additional ID to next consecutive index.\"\"\"\n    if node_id not in self.id_to_idx:\n        idx = self.num_ids()\n        self.node_ids = np.append(self.node_ids, node_id)\n        self.id_to_idx[node_id] = idx\n        self.has_ids = True\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.add_ids","title":"<code>add_ids</code>","text":"<p>Assigns additional IDs to next consecutive indices.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n    \"\"\"Assigns additional IDs to next consecutive indices.\"\"\"\n    cur_num_ids = self.num_ids()\n    node_ids = np.array(node_ids)\n    mask = np.isin(node_ids, self.node_ids)\n    new_ids = np.unique(node_ids[~mask])\n    self.node_ids = np.append(self.node_ids, new_ids)\n    self.id_to_idx.update({v: i + cur_num_ids for i, v in enumerate(new_ids)})\n    self.has_ids = True\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.to_id","title":"<code>to_id</code>","text":"<p>Map index to ID if mapping is defined, return index otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n    \"\"\"Map index to ID if mapping is defined, return index otherwise.\"\"\"\n    if self.has_ids:\n        if self.node_ids.ndim == 1:\n            return self.node_ids[idx]\n        else:\n            return tuple(self.node_ids[idx])\n    else:\n        return idx\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.to_ids","title":"<code>to_ids</code>","text":"<p>Map list of indices to IDs if mapping is defined, return indices otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_ids(self, idxs: list | tuple) -&gt; list:\n    \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise.\"\"\"\n    if self.has_ids:\n        return self.node_ids[idxs].tolist()\n    else:\n        return idxs\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.to_idx","title":"<code>to_idx</code>","text":"<p>Map argument (ID or index) to index if mapping is defined, return argument otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_idx(self, node: Union[str, int]) -&gt; int:\n    \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\"\"\"\n    if self.has_ids:\n        return self.id_to_idx[node]\n    else:\n        return node\n</code></pre>"},{"location":"reference/pathpyG/core/IndexMap/#pathpyG.core.IndexMap.IndexMap.to_idxs","title":"<code>to_idxs</code>","text":"<p>Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise.</p> Source code in <code>src/pathpyG/core/IndexMap.py</code> <pre><code>def to_idxs(self, nodes: list | tuple) -&gt; torch.Tensor:\n    \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise.\"\"\"\n    if self.has_ids:\n        return torch.tensor([self.id_to_idx[node] for node in nodes])\n    else:\n        return torch.tensor(nodes)\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/","title":"MultiOrderModel","text":""},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel","title":"<code>MultiOrderModel</code>","text":"<p>MultiOrderModel based on torch_geometric.Data.</p> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>class MultiOrderModel:\n    \"\"\"MultiOrderModel based on torch_geometric.Data.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.layers: dict[int, Graph] = {}\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the higher-order graph.\"\"\"\n        max_order = max(list(self.layers.keys())) if self.layers else 0\n        s = f\"MultiOrderModel with max. order {max_order}\"\n        return s\n\n    @staticmethod\n    def aggregate_edge_weight(ho_index: torch.Tensor, edge_weight: torch.Tensor, aggr: str = \"src\") -&gt; torch.Tensor:\n        \"\"\"\n        Aggregate edge weights of a (k-1)-th order graph for a kth-order graph.\n\n        Args:\n            ho_index: The higher-order edge index of the higher-order graph.\n            edge_weight: The edge weights of the (k-1)th order graph.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        \"\"\"\n        if aggr == \"src\":\n            ho_edge_weight = edge_weight[ho_index[0]]\n        elif aggr == \"dst\":\n            ho_edge_weight = edge_weight[ho_index[1]]\n        elif aggr == \"max\":\n            ho_edge_weight = torch.maximum(edge_weight[ho_index[0]], edge_weight[ho_index[1]])\n        elif aggr == \"mul\":\n            ho_edge_weight = edge_weight[ho_index[0]] * edge_weight[ho_index[1]]\n        else:\n            raise ValueError(f\"Unknown aggregation method {aggr}\")\n        return ho_edge_weight\n\n    @staticmethod\n    def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int) -&gt; torch.Tensor:\n        \"\"\"\n        Do a line graph transformation on the edge index to lift the order of the graph by one.\n        Assumes that the edge index is sorted.\n\n        Args:\n            edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n            num_nodes: The number of nodes in the graph.\n        \"\"\"\n        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n        # Map outdegree to each destination node to create an edge for each combination\n        # of incoming and outgoing edges for each destination node\n        outdegree_per_dst = outdegree[edge_index[1]]\n        num_new_edges = outdegree_per_dst.sum()\n        # Create sources of the new higher-order edges\n        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n        # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n        # of all previous nodes in the ordered sequence of nodes\n        ptrs = cumsum(outdegree, dim=0)[:-1]\n        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n        ho_edge_dsts += idx_correction\n        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n\n    @staticmethod\n    def lift_order_edge_index_weighted(\n        edge_index: torch.Tensor, edge_weight: torch.Tensor, num_nodes: int, aggr: str = \"src\"\n    ) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Do a line graph transformation on the edge index to lift the order of the graph by one.\n        Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph.\n        Assumes that the edge index is sorted.\n\n        Args:\n            edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n            edge_weight: The edge weights of the (k-1)th order graph.\n            num_nodes: The number of nodes in the graph.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        \"\"\"\n        ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes)\n        ho_edge_weight = MultiOrderModel.aggregate_edge_weight(ho_index, edge_weight, aggr)\n\n        return ho_index, ho_edge_weight\n\n    @staticmethod\n    def aggregate_edge_index(\n        edge_index: torch.Tensor, node_sequence: torch.Tensor, edge_weight: torch.Tensor | None = None\n    ) -&gt; Graph:\n        \"\"\"\n        Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object\n        containing the (higher-order) edge index without duplicates and the node sequences.\n        The edge weights of duplicated edges are summed up.\n\n        Args:\n            edge_index: The edge index of a (higher-order) graph where each source and destination node\n                corresponds to a node which is an edge in the (k-1)-th order graph.\n            node_sequence: The node sequences of first order nodes that each node in the edge index corresponds to.\n            edge_weight: The edge weights corresponding to the edge index.\n        \"\"\"\n        if edge_weight is None:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n\n        # If first order, then the indices in the node sequence are the inverse idx we would need already\n        if node_sequence.size(1) == 1:\n            unique_nodes = torch.arange(node_sequence.max().item() + 1, device=node_sequence.device).unsqueeze(1)\n            mapped_edge_index = node_sequence.squeeze()[edge_index]\n        else:\n            unique_nodes, inverse_idx = torch.unique(node_sequence, dim=0, return_inverse=True)\n            mapped_edge_index = inverse_idx[edge_index]\n        aggregated_edge_index, edge_weight = coalesce(\n            mapped_edge_index,\n            edge_attr=edge_weight,\n            num_nodes=unique_nodes.size(0),\n            reduce=\"sum\",\n        )\n        data = Data(\n            edge_index=aggregated_edge_index,\n            num_nodes=unique_nodes.size(0),\n            node_sequence=unique_nodes,\n            edge_weight=edge_weight,\n        )\n        return Graph(data)\n\n    @staticmethod\n    def iterate_lift_order(\n        edge_index: torch.Tensor,\n        node_sequence: torch.Tensor,\n        mapping: IndexMap,\n        edge_weight: torch.Tensor | None = None,\n        aggr: str = \"src\",\n        save: bool = True,\n    ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n        \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n        This is a helper function that should not be called directly.\n        Only use for edge_indices after the special cases have been handled e.g.\n        in the from_temporal_graph (filtering non-time-respecting paths of order 2)\n        or from_DAGs (reindexing with dataloader) functions.\n\n        Args:\n            edge_index: The edge index of the (k-1)-th order graph.\n            node_sequence: The node sequences of the (k-1)-th order graph.\n            edge_weight: The edge weights of the (k-1)-th order graph.\n            k: The order of the graph that should be computed.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n            save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n        \"\"\"\n        # Lift order\n        if edge_weight is None:\n            ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n        else:\n            ho_index, edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n                edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n            )\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n        # Aggregate\n        if save:\n            gk = MultiOrderModel.aggregate_edge_index(ho_index, node_sequence, edge_weight)\n            gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n        else:\n            gk = None\n        return ho_index, node_sequence, edge_weight, gk\n\n    @staticmethod\n    def from_temporal_graph(\n        g: TemporalGraph, delta: float | int = 1, max_order: int = 1, weight: str = \"edge_weight\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\"\"\"\n        m = MultiOrderModel()\n        edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n        node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n        if weight in g.data:\n            edge_weight = g.data[weight]\n        else:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n        if cached or max_order == 1:\n            m.layers[1] = MultiOrderModel.aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[1].mapping = g.mapping\n\n        if max_order &gt; 1:\n            # Compute null model\n            null_model_edge_index, null_model_edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n                edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=\"src\"\n            )\n            # Update node sequences\n            node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n            # Remove non-time-respecting higher-order edges\n            time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n            non_negative_mask = time_diff &gt; 0\n            delta_mask = time_diff &lt;= delta\n            time_respecting_mask = non_negative_mask &amp; delta_mask\n            edge_index = null_model_edge_index[:, time_respecting_mask]\n            edge_weight = null_model_edge_weight[time_respecting_mask]\n            # Aggregate\n            if cached or max_order == 2:\n                m.layers[2] = MultiOrderModel.aggregate_edge_index(\n                    edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n                )\n                m.layers[2].mapping = IndexMap(\n                    [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n                )\n\n            for k in range(3, max_order + 1):\n                edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                    edge_index=edge_index,\n                    node_sequence=node_sequence,\n                    mapping=g.mapping,\n                    edge_weight=edge_weight,\n                    aggr=\"src\",\n                    save=cached or k == max_order,\n                )\n                if cached or k == max_order:\n                    m.layers[k] = gk\n\n        return m\n\n    @staticmethod\n    def from_DAGs(\n        dag_data: DAGData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"\n        Creates multiple higher-order De Bruijn graphs for paths in DAGData.\n\n        Args:\n            dag_data: The DAGData object containing the DAGs as list of PyG Data objects\n                with sorted edge indices, node sequences and num_nodes.\n            max_order: The maximum order of the MultiOrderModel that should be computed\n            mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n            cached: Whether to save the aggregated higher-order graphs smaller than max order\n                in the MultiOrderModel.\n        \"\"\"\n        m = MultiOrderModel()\n\n        # We assume that the DAGs are sorted and that walks are remapped to a DAG\n        dag_graph = next(iter(DataLoader(dag_data.dags, batch_size=len(dag_data.dags)))).to(config[\"torch\"][\"device\"])\n        edge_index = dag_graph.edge_index\n        node_sequence = dag_graph.node_sequence\n        if dag_graph.edge_attr is None:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n        else:\n            edge_weight = dag_graph.edge_attr\n        if mode == \"diffusion\":\n            edge_weight = (\n                edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n            )\n            aggr = \"mul\"\n        elif mode == \"propagation\":\n            aggr = \"src\"\n\n        m.layers[1] = MultiOrderModel.aggregate_edge_index(\n            edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n        )\n        m.layers[1].mapping = dag_data.mapping\n\n        for k in range(2, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=m.layers[1].mapping,\n                edge_weight=edge_weight,\n                aggr=aggr,\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n        return m\n\n    def to_dbgnn_data(self, max_order: int = 2, mapping: str = 'last') -&gt; Data:\n        \"\"\"\n        Convert the MultiOrderModel to a De Bruijn graph for the given maximum order.\n\n        Args:\n            max_order: The maximum order of the De Bruijn graph to be computed.\n            mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n        \"\"\"\n        if max_order not in self.layers:\n            raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n        g = self.layers[1]\n        g_max_order = self.layers[max_order]\n        num_nodes = g.data.num_nodes\n        num_ho_nodes = g_max_order.data.num_nodes\n        if g.data.x is not None:\n            x = g.data.x\n        else:\n            x = torch.eye(num_nodes, num_nodes)\n        x_max_order = torch.eye(num_ho_nodes, num_ho_nodes)\n        edge_index = g.data.edge_index\n        edge_index_max_order = g_max_order.data.edge_index\n        edge_weight = g.data.edge_weight\n        edge_weight_max_order = g_max_order.data.edge_weight\n        bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping)\n\n        if g.data.y is not None:\n            y = g.data.y\n\n        return Data(\n            num_nodes=num_nodes,\n            num_ho_nodes=num_ho_nodes,\n            x=x,\n            x_h=x_max_order,\n            edge_index=edge_index,\n            edge_index_higher_order=edge_index_max_order,\n            edge_weights=edge_weight.float(),\n            edge_weights_higher_order=edge_weight_max_order.float(),\n            bipartite_edge_index=bipartite_edge_index,\n            y=y if 'y' in locals() else None\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the higher-order graph.</p> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the higher-order graph.\"\"\"\n    max_order = max(list(self.layers.keys())) if self.layers else 0\n    s = f\"MultiOrderModel with max. order {max_order}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.aggregate_edge_index","title":"<code>aggregate_edge_index</code>  <code>staticmethod</code>","text":"<p>Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object containing the (higher-order) edge index without duplicates and the node sequences. The edge weights of duplicated edges are summed up.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of a (higher-order) graph where each source and destination node corresponds to a node which is an edge in the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of first order nodes that each node in the edge index corresponds to.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights corresponding to the edge index.</p> <code>None</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef aggregate_edge_index(\n    edge_index: torch.Tensor, node_sequence: torch.Tensor, edge_weight: torch.Tensor | None = None\n) -&gt; Graph:\n    \"\"\"\n    Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object\n    containing the (higher-order) edge index without duplicates and the node sequences.\n    The edge weights of duplicated edges are summed up.\n\n    Args:\n        edge_index: The edge index of a (higher-order) graph where each source and destination node\n            corresponds to a node which is an edge in the (k-1)-th order graph.\n        node_sequence: The node sequences of first order nodes that each node in the edge index corresponds to.\n        edge_weight: The edge weights corresponding to the edge index.\n    \"\"\"\n    if edge_weight is None:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n\n    # If first order, then the indices in the node sequence are the inverse idx we would need already\n    if node_sequence.size(1) == 1:\n        unique_nodes = torch.arange(node_sequence.max().item() + 1, device=node_sequence.device).unsqueeze(1)\n        mapped_edge_index = node_sequence.squeeze()[edge_index]\n    else:\n        unique_nodes, inverse_idx = torch.unique(node_sequence, dim=0, return_inverse=True)\n        mapped_edge_index = inverse_idx[edge_index]\n    aggregated_edge_index, edge_weight = coalesce(\n        mapped_edge_index,\n        edge_attr=edge_weight,\n        num_nodes=unique_nodes.size(0),\n        reduce=\"sum\",\n    )\n    data = Data(\n        edge_index=aggregated_edge_index,\n        num_nodes=unique_nodes.size(0),\n        node_sequence=unique_nodes,\n        edge_weight=edge_weight,\n    )\n    return Graph(data)\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.aggregate_edge_weight","title":"<code>aggregate_edge_weight</code>  <code>staticmethod</code>","text":"<p>Aggregate edge weights of a (k-1)-th order graph for a kth-order graph.</p> <p>Parameters:</p> Name Type Description Default <code>ho_index</code> <code>torch.Tensor</code> <p>The higher-order edge index of the higher-order graph.</p> required <code>edge_weight</code> <code>torch.Tensor</code> <p>The edge weights of the (k-1)th order graph.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef aggregate_edge_weight(ho_index: torch.Tensor, edge_weight: torch.Tensor, aggr: str = \"src\") -&gt; torch.Tensor:\n    \"\"\"\n    Aggregate edge weights of a (k-1)-th order graph for a kth-order graph.\n\n    Args:\n        ho_index: The higher-order edge index of the higher-order graph.\n        edge_weight: The edge weights of the (k-1)th order graph.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n    \"\"\"\n    if aggr == \"src\":\n        ho_edge_weight = edge_weight[ho_index[0]]\n    elif aggr == \"dst\":\n        ho_edge_weight = edge_weight[ho_index[1]]\n    elif aggr == \"max\":\n        ho_edge_weight = torch.maximum(edge_weight[ho_index[0]], edge_weight[ho_index[1]])\n    elif aggr == \"mul\":\n        ho_edge_weight = edge_weight[ho_index[0]] * edge_weight[ho_index[1]]\n    else:\n        raise ValueError(f\"Unknown aggregation method {aggr}\")\n    return ho_edge_weight\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.from_DAGs","title":"<code>from_DAGs</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graphs for paths in DAGData.</p> <p>Parameters:</p> Name Type Description Default <code>dag_data</code> <code>pathpyG.core.DAGData.DAGData</code> <p>The DAGData object containing the DAGs as list of PyG Data objects with sorted edge indices, node sequences and num_nodes.</p> required <code>max_order</code> <code>int</code> <p>The maximum order of the MultiOrderModel that should be computed</p> <code>1</code> <code>mode</code> <code>str</code> <p>The process that we assume. Can be \"diffusion\" or \"propagation\".</p> <code>'propagation'</code> <code>cached</code> <code>bool</code> <p>Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.</p> <code>True</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef from_DAGs(\n    dag_data: DAGData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"\n    Creates multiple higher-order De Bruijn graphs for paths in DAGData.\n\n    Args:\n        dag_data: The DAGData object containing the DAGs as list of PyG Data objects\n            with sorted edge indices, node sequences and num_nodes.\n        max_order: The maximum order of the MultiOrderModel that should be computed\n        mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n        cached: Whether to save the aggregated higher-order graphs smaller than max order\n            in the MultiOrderModel.\n    \"\"\"\n    m = MultiOrderModel()\n\n    # We assume that the DAGs are sorted and that walks are remapped to a DAG\n    dag_graph = next(iter(DataLoader(dag_data.dags, batch_size=len(dag_data.dags)))).to(config[\"torch\"][\"device\"])\n    edge_index = dag_graph.edge_index\n    node_sequence = dag_graph.node_sequence\n    if dag_graph.edge_attr is None:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n    else:\n        edge_weight = dag_graph.edge_attr\n    if mode == \"diffusion\":\n        edge_weight = (\n            edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n        )\n        aggr = \"mul\"\n    elif mode == \"propagation\":\n        aggr = \"src\"\n\n    m.layers[1] = MultiOrderModel.aggregate_edge_index(\n        edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n    )\n    m.layers[1].mapping = dag_data.mapping\n\n    for k in range(2, max_order + 1):\n        edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n            edge_index=edge_index,\n            node_sequence=node_sequence,\n            mapping=m.layers[1].mapping,\n            edge_weight=edge_weight,\n            aggr=aggr,\n            save=cached or k == max_order,\n        )\n        if cached or k == max_order:\n            m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.from_temporal_graph","title":"<code>from_temporal_graph</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.</p> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef from_temporal_graph(\n    g: TemporalGraph, delta: float | int = 1, max_order: int = 1, weight: str = \"edge_weight\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\"\"\"\n    m = MultiOrderModel()\n    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n    if weight in g.data:\n        edge_weight = g.data[weight]\n    else:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n    if cached or max_order == 1:\n        m.layers[1] = MultiOrderModel.aggregate_edge_index(\n            edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n        )\n        m.layers[1].mapping = g.mapping\n\n    if max_order &gt; 1:\n        # Compute null model\n        null_model_edge_index, null_model_edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n            edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=\"src\"\n        )\n        # Update node sequences\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n        # Remove non-time-respecting higher-order edges\n        time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n        non_negative_mask = time_diff &gt; 0\n        delta_mask = time_diff &lt;= delta\n        time_respecting_mask = non_negative_mask &amp; delta_mask\n        edge_index = null_model_edge_index[:, time_respecting_mask]\n        edge_weight = null_model_edge_weight[time_respecting_mask]\n        # Aggregate\n        if cached or max_order == 2:\n            m.layers[2] = MultiOrderModel.aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[2].mapping = IndexMap(\n                [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n            )\n\n        for k in range(3, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=g.mapping,\n                edge_weight=edge_weight,\n                aggr=\"src\",\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.iterate_lift_order","title":"<code>iterate_lift_order</code>  <code>staticmethod</code>","text":"<p>Lift order by one and save the result in the layers dictionary of the object. This is a helper function that should not be called directly. Only use for edge_indices after the special cases have been handled e.g. in the from_temporal_graph (filtering non-time-respecting paths of order 2) or from_DAGs (reindexing with dataloader) functions.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of the (k-1)-th order graph.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights of the (k-1)-th order graph.</p> <code>None</code> <code>k</code> <p>The order of the graph that should be computed.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> <code>save</code> <code>bool</code> <p>Whether to compute the aggregated graph and later save it in the layers dictionary.</p> <code>True</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef iterate_lift_order(\n    edge_index: torch.Tensor,\n    node_sequence: torch.Tensor,\n    mapping: IndexMap,\n    edge_weight: torch.Tensor | None = None,\n    aggr: str = \"src\",\n    save: bool = True,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n    \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n    This is a helper function that should not be called directly.\n    Only use for edge_indices after the special cases have been handled e.g.\n    in the from_temporal_graph (filtering non-time-respecting paths of order 2)\n    or from_DAGs (reindexing with dataloader) functions.\n\n    Args:\n        edge_index: The edge index of the (k-1)-th order graph.\n        node_sequence: The node sequences of the (k-1)-th order graph.\n        edge_weight: The edge weights of the (k-1)-th order graph.\n        k: The order of the graph that should be computed.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n    \"\"\"\n    # Lift order\n    if edge_weight is None:\n        ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n    else:\n        ho_index, edge_weight = MultiOrderModel.lift_order_edge_index_weighted(\n            edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n        )\n    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n    # Aggregate\n    if save:\n        gk = MultiOrderModel.aggregate_edge_index(ho_index, node_sequence, edge_weight)\n        gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n    else:\n        gk = None\n    return ho_index, node_sequence, edge_weight, gk\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.lift_order_edge_index","title":"<code>lift_order_edge_index</code>  <code>staticmethod</code>","text":"<p>Do a line graph transformation on the edge index to lift the order of the graph by one. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>num_nodes</code> <code>int</code> <p>The number of nodes in the graph.</p> required Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int) -&gt; torch.Tensor:\n    \"\"\"\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        num_nodes: The number of nodes in the graph.\n    \"\"\"\n    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n    # Map outdegree to each destination node to create an edge for each combination\n    # of incoming and outgoing edges for each destination node\n    outdegree_per_dst = outdegree[edge_index[1]]\n    num_new_edges = outdegree_per_dst.sum()\n    # Create sources of the new higher-order edges\n    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n    # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n    # of all previous nodes in the ordered sequence of nodes\n    ptrs = cumsum(outdegree, dim=0)[:-1]\n    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n    idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n    ho_edge_dsts += idx_correction\n    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.lift_order_edge_index_weighted","title":"<code>lift_order_edge_index_weighted</code>  <code>staticmethod</code>","text":"<p>Do a line graph transformation on the edge index to lift the order of the graph by one. Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>edge_weight</code> <code>torch.Tensor</code> <p>The edge weights of the (k-1)th order graph.</p> required <code>num_nodes</code> <code>int</code> <p>The number of nodes in the graph.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>@staticmethod\ndef lift_order_edge_index_weighted(\n    edge_index: torch.Tensor, edge_weight: torch.Tensor, num_nodes: int, aggr: str = \"src\"\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        edge_weight: The edge weights of the (k-1)th order graph.\n        num_nodes: The number of nodes in the graph.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n    \"\"\"\n    ho_index = MultiOrderModel.lift_order_edge_index(edge_index, num_nodes)\n    ho_edge_weight = MultiOrderModel.aggregate_edge_weight(ho_index, edge_weight, aggr)\n\n    return ho_index, ho_edge_weight\n</code></pre>"},{"location":"reference/pathpyG/core/MultiOrderModel/#pathpyG.core.MultiOrderModel.MultiOrderModel.to_dbgnn_data","title":"<code>to_dbgnn_data</code>","text":"<p>Convert the MultiOrderModel to a De Bruijn graph for the given maximum order.</p> <p>Parameters:</p> Name Type Description Default <code>max_order</code> <code>int</code> <p>The maximum order of the De Bruijn graph to be computed.</p> <code>2</code> <code>mapping</code> <code>str</code> <p>The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".</p> <code>'last'</code> Source code in <code>src/pathpyG/core/MultiOrderModel.py</code> <pre><code>def to_dbgnn_data(self, max_order: int = 2, mapping: str = 'last') -&gt; Data:\n    \"\"\"\n    Convert the MultiOrderModel to a De Bruijn graph for the given maximum order.\n\n    Args:\n        max_order: The maximum order of the De Bruijn graph to be computed.\n        mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n    \"\"\"\n    if max_order not in self.layers:\n        raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n    g = self.layers[1]\n    g_max_order = self.layers[max_order]\n    num_nodes = g.data.num_nodes\n    num_ho_nodes = g_max_order.data.num_nodes\n    if g.data.x is not None:\n        x = g.data.x\n    else:\n        x = torch.eye(num_nodes, num_nodes)\n    x_max_order = torch.eye(num_ho_nodes, num_ho_nodes)\n    edge_index = g.data.edge_index\n    edge_index_max_order = g_max_order.data.edge_index\n    edge_weight = g.data.edge_weight\n    edge_weight_max_order = g_max_order.data.edge_weight\n    bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping)\n\n    if g.data.y is not None:\n        y = g.data.y\n\n    return Data(\n        num_nodes=num_nodes,\n        num_ho_nodes=num_ho_nodes,\n        x=x,\n        x_h=x_max_order,\n        edge_index=edge_index,\n        edge_index_higher_order=edge_index_max_order,\n        edge_weights=edge_weight.float(),\n        edge_weights_higher_order=edge_weight_max_order.float(),\n        bipartite_edge_index=bipartite_edge_index,\n        y=y if 'y' in locals() else None\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/","title":"TemporalGraph","text":""},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph","title":"<code>TemporalGraph</code>","text":"<p>               Bases: <code>pathpyG.Graph</code></p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>class TemporalGraph(Graph):\n    def __init__(self, data: TemporalData, mapping: IndexMap = None) -&gt; None:\n        \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n\n        Example:\n            ```py\n            from pytorch_geometric.data import TemporalData\n            import pathpyG as pp\n\n            d = TemporalData(src=[0,0,1], dst=[1,2,2], t=[0,1,2])\n            t = pp.TemporalGraph(d, mapping)\n            print(t)\n            ```\n        \"\"\"\n\n        # sort edges by timestamp\n        # Note: function sort_by_time mentioned in pyG documentation does not exist\n        t_sorted, sort_index = torch.sort(data.t)\n\n        # reorder temporal data\n        self.data = TemporalData(\n            src=data.src[sort_index],\n            dst=data.dst[sort_index],\n            t=t_sorted\n        ).to(config['torch']['device'])\n\n        if mapping is not None:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n\n        # create mapping between edge index and edge tuples\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i\n            for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        self.start_time = t_sorted.min().item()\n        self.end_time = t_sorted.max().item()\n\n        # # initialize adjacency matrix\n        # self._sparse_adj_matrix = torch_geometric.utils.to_scipy_sparse_matrix(\n        #     self.data.edge_index\n        # ).tocsr()\n\n    @staticmethod\n    def from_edge_list(edge_list) -&gt; TemporalGraph:\n        sources = []\n        targets = []\n        ts = []\n\n        index_map = IndexMap()\n\n        for v, w, t in edge_list:\n            index_map.add_id(v)\n            index_map.add_id(w)\n            sources.append(index_map.to_idx(v))\n            targets.append(index_map.to_idx(w))\n            ts.append(t)\n\n        return TemporalGraph(\n            data=TemporalData(\n                        src=torch.Tensor(sources).long(),\n                        dst=torch.Tensor(targets).long(),\n                        t=torch.Tensor(ts)),\n            mapping=index_map\n        )\n\n    @staticmethod\n    def from_csv(file, timestamp_format='%Y-%m-%d %H:%M:%S', time_rescale=1) -&gt; TemporalGraph:\n        tedges = []\n        with open(file, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                fields = line.strip().split(\",\")\n                timestamp = fields[2]\n                if timestamp.isdigit():\n                    t = int(timestamp)\n                else:\n                    # if it is a string, we use the timestamp format to convert\n                    # it to a UNIX timestamp\n                    x = datetime.datetime.strptime(timestamp, timestamp_format)\n                    t = int(mktime(x.timetuple()))\n                tedges.append((fields[0], fields[1], int(t/time_rescale)))\n        return TemporalGraph.from_edge_list(tedges)\n\n    @property\n    def temporal_edges(self) -&gt; Generator[Tuple[int, int, int], None, None]:\n        \"\"\"Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.\"\"\"\n        i = 0\n        for e in self.data.edge_index.t():\n            yield self.mapping.to_id(e[0].item()), self.mapping.to_id(e[1].item()), self.data.t[i].item()  # type: ignore\n            i += 1\n\n    def shuffle_time(self) -&gt; None:\n        \"\"\"Randomly shuffles the temporal order of edges by randomly permuting timestamps.\"\"\"\n        self.data['t'] = self.data['t'][torch.randperm(len(self.data['t']))]\n        # t_sorted, indices = torch.sort(torch.tensor(t).to(config[\"torch\"][\"device\"]))\n        # self.data['src'] = self.data['src']\n        # self.data['dst'] = self.data['dst']\n        # self.data['t'] = t_sorted\n\n    def to_static_graph(self, weighted=False, time_window: Optional[Tuple[int,int]]=None) -&gt; Graph:\n        \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n        \"\"\"\n        if time_window is not None:\n            idx = (self.data.t &gt;= time_window[0]).logical_and(self.data.t &lt; time_window[1]).nonzero().ravel()\n            edge_index = torch.stack((self.data.src[idx], self.data.dst[idx]))\n        else:\n            edge_index = torch.stack((self.data.src, self.data.dst))\n\n        n = edge_index.max().item()+1\n\n        if weighted:\n            i, w = torch_geometric.utils.coalesce(edge_index, torch.ones(edge_index.size(1), device=self.data.edge_index.device))\n            return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n,n)), edge_weight=w), self.mapping)\n        else:\n            return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n,n)), self.mapping)\n\n    def to_undirected(self) -&gt; TemporalGraph:\n        \"\"\"\n        Returns an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"        \n        rev_edge_index = self.data.edge_index.flip([0])\n        edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n        times = torch.cat([self.data.t, self.data.t])\n        return TemporalGraph(\n            data=TemporalData(\n                src=edge_index[0],\n                dst=edge_index[1],\n                t=times\n            ),\n            mapping=self.mapping\n        )        \n\n    def get_window(self, start: int, end: int) -&gt; TemporalGraph:\n        \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n        edges in a given window defined by start and (non-inclusive) end, where start\n        and end refer to the number of events\"\"\"\n\n        #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n        #max_idx = torch.max(idx).item()\n\n        # return TemporalGraph(\n        #     edge_index = idx,\n        #     t = self.data.t[start:end],\n        #     node_id = self.data.node_id[:max_idx+1]\n        #     )\n        return TemporalGraph(\n            data=TemporalData(\n                src=self.data.src[start:end],\n                dst=self.data.dst[start:end],\n                t=self.data.t[start:end]\n            ),\n            mapping=self.mapping\n        )\n\n\n    def get_snapshot(self, start: int, end: int) -&gt; TemporalGraph:\n        \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n        edges in a given time window defined by start and (non-inclusive) end, where start\n        and end refer to the time stamps\"\"\"\n\n        #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n        #max_idx = torch.max(idx).item()\n\n        return TemporalGraph(\n            data=TemporalData(\n                src=self.data.src[start:end],\n                dst=self.data.dst[start:end],\n                t=self.data.t[start:end]\n            ),\n            mapping=self.mapping\n        )\n\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Returns a string representation of the graph\n        \"\"\"\n        s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n            self.data.num_nodes,\n            self.data.edge_index.unique(dim=1).size(dim=1),\n            self.data.num_events,\n            self.start_time,\n            self.end_time,\n        )\n\n        attr_types = Graph.attr_types(self.data.to_dict())\n\n        if len(self.data.node_attrs()) &gt; 0:\n            s += \"\\nNode attributes\\n\"\n            for a in self.data.node_attrs():\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.edge_attrs()) &gt; 1:\n            s += \"\\nEdge attributes\\n\"\n            for a in self.data.edge_attrs():\n                if a != \"edge_index\":\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n            self.data.node_attrs()\n        ):\n            s += \"\\nGraph attributes\\n\"\n            for a in self.data.keys():\n                if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                    s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.temporal_edges","title":"<code>temporal_edges: Generator[Tuple[int, int, int], None, None]</code>  <code>property</code>","text":"<p>Iterator that yields each edge as a tuple of source and destination node as well as the corresponding timestamp.</p>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.__init__","title":"<code>__init__</code>","text":"<p>Creates an instance of a temporal graph from a <code>TemporalData</code> object.</p> Example <pre><code>from pytorch_geometric.data import TemporalData\nimport pathpyG as pp\n\nd = TemporalData(src=[0,0,1], dst=[1,2,2], t=[0,1,2])\nt = pp.TemporalGraph(d, mapping)\nprint(t)\n</code></pre> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def __init__(self, data: TemporalData, mapping: IndexMap = None) -&gt; None:\n    \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n\n    Example:\n        ```py\n        from pytorch_geometric.data import TemporalData\n        import pathpyG as pp\n\n        d = TemporalData(src=[0,0,1], dst=[1,2,2], t=[0,1,2])\n        t = pp.TemporalGraph(d, mapping)\n        print(t)\n        ```\n    \"\"\"\n\n    # sort edges by timestamp\n    # Note: function sort_by_time mentioned in pyG documentation does not exist\n    t_sorted, sort_index = torch.sort(data.t)\n\n    # reorder temporal data\n    self.data = TemporalData(\n        src=data.src[sort_index],\n        dst=data.dst[sort_index],\n        t=t_sorted\n    ).to(config['torch']['device'])\n\n    if mapping is not None:\n        self.mapping = mapping\n    else:\n        self.mapping = IndexMap()\n\n    # create mapping between edge index and edge tuples\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i\n        for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    self.start_time = t_sorted.min().item()\n    self.end_time = t_sorted.max().item()\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.__str__","title":"<code>__str__</code>","text":"<p>Returns a string representation of the graph</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Returns a string representation of the graph\n    \"\"\"\n    s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n        self.data.num_nodes,\n        self.data.edge_index.unique(dim=1).size(dim=1),\n        self.data.num_events,\n        self.start_time,\n        self.end_time,\n    )\n\n    attr_types = Graph.attr_types(self.data.to_dict())\n\n    if len(self.data.node_attrs()) &gt; 0:\n        s += \"\\nNode attributes\\n\"\n        for a in self.data.node_attrs():\n            s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.edge_attrs()) &gt; 1:\n        s += \"\\nEdge attributes\\n\"\n        for a in self.data.edge_attrs():\n            if a != \"edge_index\":\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    if len(self.data.keys()) &gt; len(self.data.edge_attrs()) + len(\n        self.data.node_attrs()\n    ):\n        s += \"\\nGraph attributes\\n\"\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                s += \"\\t{0}\\t\\t{1}\\n\".format(a, attr_types[a])\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.get_snapshot","title":"<code>get_snapshot</code>","text":"<p>Returns an instance of the TemporalGraph that captures all time-stamped  edges in a given time window defined by start and (non-inclusive) end, where start and end refer to the time stamps</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def get_snapshot(self, start: int, end: int) -&gt; TemporalGraph:\n    \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n    edges in a given time window defined by start and (non-inclusive) end, where start\n    and end refer to the time stamps\"\"\"\n\n    #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n    #max_idx = torch.max(idx).item()\n\n    return TemporalGraph(\n        data=TemporalData(\n            src=self.data.src[start:end],\n            dst=self.data.dst[start:end],\n            t=self.data.t[start:end]\n        ),\n        mapping=self.mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.get_window","title":"<code>get_window</code>","text":"<p>Returns an instance of the TemporalGraph that captures all time-stamped  edges in a given window defined by start and (non-inclusive) end, where start and end refer to the number of events</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def get_window(self, start: int, end: int) -&gt; TemporalGraph:\n    \"\"\"Returns an instance of the TemporalGraph that captures all time-stamped \n    edges in a given window defined by start and (non-inclusive) end, where start\n    and end refer to the number of events\"\"\"\n\n    #idx = torch.tensor([self.data['src'][start:end].numpy(), self.data['dst'][start:end].numpy()]).to(config[\"torch\"][\"device\"])\n    #max_idx = torch.max(idx).item()\n\n    # return TemporalGraph(\n    #     edge_index = idx,\n    #     t = self.data.t[start:end],\n    #     node_id = self.data.node_id[:max_idx+1]\n    #     )\n    return TemporalGraph(\n        data=TemporalData(\n            src=self.data.src[start:end],\n            dst=self.data.dst[start:end],\n            t=self.data.t[start:end]\n        ),\n        mapping=self.mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.shuffle_time","title":"<code>shuffle_time</code>","text":"<p>Randomly shuffles the temporal order of edges by randomly permuting timestamps.</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def shuffle_time(self) -&gt; None:\n    \"\"\"Randomly shuffles the temporal order of edges by randomly permuting timestamps.\"\"\"\n    self.data['t'] = self.data['t'][torch.randperm(len(self.data['t']))]\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.to_static_graph","title":"<code>to_static_graph</code>","text":"<p>Return weighted time-aggregated instance of <code>Graph</code> graph.</p> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def to_static_graph(self, weighted=False, time_window: Optional[Tuple[int,int]]=None) -&gt; Graph:\n    \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n    \"\"\"\n    if time_window is not None:\n        idx = (self.data.t &gt;= time_window[0]).logical_and(self.data.t &lt; time_window[1]).nonzero().ravel()\n        edge_index = torch.stack((self.data.src[idx], self.data.dst[idx]))\n    else:\n        edge_index = torch.stack((self.data.src, self.data.dst))\n\n    n = edge_index.max().item()+1\n\n    if weighted:\n        i, w = torch_geometric.utils.coalesce(edge_index, torch.ones(edge_index.size(1), device=self.data.edge_index.device))\n        return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n,n)), edge_weight=w), self.mapping)\n    else:\n        return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n,n)), self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/TemporalGraph/#pathpyG.core.TemporalGraph.TemporalGraph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Returns an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/TemporalGraph.py</code> <pre><code>def to_undirected(self) -&gt; TemporalGraph:\n    \"\"\"\n    Returns an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"        \n    rev_edge_index = self.data.edge_index.flip([0])\n    edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n    times = torch.cat([self.data.t, self.data.t])\n    return TemporalGraph(\n        data=TemporalData(\n            src=edge_index[0],\n            dst=edge_index[1],\n            t=times\n        ),\n        mapping=self.mapping\n    )        \n</code></pre>"},{"location":"reference/pathpyG/io/","title":"io","text":""},{"location":"reference/pathpyG/io/netzschleuder/","title":"netzschleuder","text":""},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.list_netzschleuder_records","title":"<code>list_netzschleuder_records</code>","text":"<p>Read a list of data sets available at the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <code>**kwargs</code> <code>typing.Any</code> <p>Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters. For supported parameters see https://networks.skewed.de/api</p> <code>{}</code> <p>Examples:</p> <p>Return a list of all data sets</p> <pre><code>&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records()\n['karate', 'reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a list of all data sets with a given tag</p> <pre><code>&gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records(tags='temporal')\n['reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a dictionary containing all data set names (keys) as well as all network attributes</p> <pre><code>&gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records(full=True)\n{ 'reality_mining': [...], 'karate': [...] }\n</code></pre> <p>Returns:</p> Type Description <code>typing.Union[list, dict]</code> <p>Either a list of data set names or a dictionary containing all data set names and network attributes.</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def list_netzschleuder_records(base_url: str='https://networks.skewed.de', **kwargs: Any) -&gt; Union[list, dict]:\n    \"\"\"\n    Read a list of data sets available at the netzschleuder repository.\n\n    Args:\n        base_url: Base URL of netzschleuder repository\n        **kwargs: Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters.\n            For supported parameters see https://networks.skewed.de/api\n\n\n    Examples:\n        Return a list of all data sets\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records()\n        ['karate', 'reality_mining', 'sp_hypertext', ...]\n\n        Return a list of all data sets with a given tag\n\n        &gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records(tags='temporal')\n        ['reality_mining', 'sp_hypertext', ...]\n\n        Return a dictionary containing all data set names (keys) as well as all network attributes\n\n        &gt;&gt;&gt; pp.io.graphtool.list_netzschleuder_records(full=True)\n        { 'reality_mining': [...], 'karate': [...] }\n\n\n    Returns:\n        Either a list of data set names or a dictionary containing all data set names and network attributes.\n\n    \"\"\"\n    url = '/api/nets'\n    for k, v in kwargs.items():\n        url += '?{0}={1}'.format(k, v)\n    try:\n        f = request.urlopen(base_url + url).read()\n        return json.loads(f)\n    except HTTPError:\n        msg = 'Could not connect to netzschleuder repository at {0}'.format(base_url)\n        # LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.parse_graphtool_format","title":"<code>parse_graphtool_format</code>","text":"<p>Decodes data in graphtool binary format and returns a <code>Graph</code>. For a documentation of hte graphtool binary format, see see doc at https://graph-tool.skewed.de/static/doc/gt_format.html</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>Array of bys to be decoded</p> required <code>ignore_temporal</code> <p>If False, this function will return a static or temporal network depending on whether edges contain a time attribute. If True, pathpy will not interpret time attributes and thus always return a static network.</p> required <p>Returns:</p> Type Description <code>pathpyG.core.Graph.Graph</code> <p>Network or TemporalNetwork: a static or temporal network object</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def parse_graphtool_format(data: bytes, id_node_attr=None) -&gt; Graph:\n    \"\"\"\n    Decodes data in graphtool binary format and returns a [`Graph`][pathpyG.Graph]. For a documentation of\n    hte graphtool binary format, see see doc at https://graph-tool.skewed.de/static/doc/gt_format.html\n\n    Args:\n        data: Array of bys to be decoded\n        ignore_temporal: If False, this function will return a static or temporal network depending\n            on whether edges contain a time attribute. If True, pathpy will not interpret\n            time attributes and thus always return a static network.\n\n    Returns:\n        Network or TemporalNetwork: a static or temporal network object\n    \"\"\"\n\n    # check magic bytes\n    if data[0:6] != b'\\xe2\\x9b\\xbe\\x20\\x67\\x74':\n        print('Invalid graphtool file. Wrong magic bytes.')\n        raise Exception('Invalid graphtool file. Wrong magic bytes.')\n    ptr = 6\n\n    # read graphtool version byte\n    graphtool_version = int(data[ptr])\n    ptr += 1\n\n    # read endianness\n    if bool(data[ptr]):\n        graphtool_endianness = '&gt;'\n    else:\n        graphtool_endianness = '&lt;'\n    ptr += 1\n\n    # read length of comment\n    str_len = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n    ptr += 8\n\n    # read string comment\n    comment = data[ptr:ptr+str_len].decode('ascii')\n    ptr += str_len\n\n    # read network directedness\n    directed = bool(data[ptr])\n    ptr += 1\n\n    # read number of nodes\n    n_nodes = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n    ptr += 8\n\n    # create pandas dataframe\n    network_dict = {}\n    # n = Network(directed = directed, multiedges=True)\n\n    # determine binary representation of neighbour lists\n    if n_nodes&lt;2**8:\n        fmt = 'B'\n        d = 1\n    elif n_nodes&lt;2**16:\n        fmt = 'H'\n        d = 2\n    elif n_nodes&lt;2**32:\n        fmt = 'I'\n        d = 4\n    else:\n        fmt = 'Q'\n        d = 8\n\n    sources = []\n    targets = []\n    # parse lists of out-neighbors for all n nodes\n    n_edges = 0\n    for v in range(n_nodes):\n        # read number of neighbors\n        num_neighbors = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n        ptr += 8\n\n        # add edges to record\n        for j in range(num_neighbors):\n            w = struct.unpack(graphtool_endianness + fmt, data[ptr:ptr+d])[0]\n            ptr += d\n            sources.append(v)\n            targets.append(w)\n            n_edges += 1\n\n    # collect attributes from property maps\n    graph_attr = dict()\n    node_attr = dict()\n    edge_attr = dict()\n\n    # parse property maps\n    property_maps = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n    ptr += 8\n\n    for i in range(property_maps):\n        key_type = struct.unpack(graphtool_endianness + 'B', data[ptr:ptr+1])[0]\n        ptr += 1\n\n        property_len  = struct.unpack(graphtool_endianness + 'Q', data[ptr:ptr+8])[0]\n        ptr += 8\n\n        property_name = data[ptr:ptr+property_len].decode('ascii')\n        ptr += property_len\n\n        property_type = struct.unpack(graphtool_endianness + 'B', data[ptr:ptr+1])[0]\n        ptr += 1\n\n        if key_type == 0: # graph-level property\n            res = _parse_property_value(data, ptr, property_type, graphtool_endianness)\n            graph_attr[property_name] = res[0]\n            ptr += res[1]\n        elif key_type == 1: # node-level property\n            if property_name not in node_attr:\n                node_attr[property_name] = []\n            for v in range(n_nodes):\n                res = _parse_property_value(data, ptr, property_type, graphtool_endianness)\n                node_attr[property_name].append([res[0]])\n                ptr += res[1]\n        elif key_type == 2: # edge-level property\n            if property_name not in edge_attr:\n                edge_attr[property_name] = []\n            for e in range(n_edges):\n                res = _parse_property_value(data, ptr, property_type, graphtool_endianness)\n                edge_attr[property_name].append(res[0])\n                ptr += res[1]\n        else:\n            print('Unknown key type {0}'.format(key_type))\n\n    # LOG.info('Version \\t= {0}'.format(graphtool_version))\n    # LOG.info('Endianness \\t= {0}'.format(graphtool_endianness))\n    # LOG.info('comment size \\t= {0}'.format(str_len))\n    # LOG.info('comment \\t= {0}'.format(comment))\n    # LOG.info('directed \\t= {0}'.format(directed))\n    # LOG.info('nodes \\t\\t= {0}'.format(n_nodes))\n\n    # add edge properties to data frame\n    # for p in edge_attribute_names:\n    #     # due to use of default_dict, this will add NA values to edges which have missing properties\n    #     network_data[p] = [ edge_attributes[e][p] for e in range(n_edges) ]\n\n    # create graph from pandas dataframe\n\n\n    # if 'time' in edge_attribute_names and not ignore_temporal:\n    #     raise Exception('')\n    #     n = to_temporal_network(network_data, directed=directed, **network_attributes)\n    # else:\n\n\n    if id_node_attr:\n        mapping = pp.IndexMap(node_attr[id_node_attr])\n    else:\n        mapping = None\n\n    g = Graph.from_edge_index(torch.LongTensor([sources, targets]).to(config['torch']['device']), mapping=mapping)\n    for a in node_attr:\n        if not a.startswith('node_'):\n            # print(node_attr[a])\n            # g.data['node_{0}'.format(a)] = torch.tensor(node_attr[a], dtype=torch.float).to(config['torch']['device'])\n            g.data['node_{0}'.format(a)] = node_attr[a]\n    for a in edge_attr:\n        if not a.startswith('edge_'):\n            g.data['edge_{0}'.format(a)] = torch.tensor(edge_attr[a], dtype=torch.float).to(config['torch']['device'])\n    for a in graph_attr:\n        g.data[a] = graph_attr[a]\n\n    if not directed:\n        return g.to_undirected()\n    return g\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_graphtool","title":"<code>read_graphtool</code>","text":"<p>Read a file in graphtool binary format.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>Path to graphtool file to be read</p> required Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_graphtool(file: str, ignore_temporal: bool=False, multiedges: bool=False) -&gt; Optional[Union[Graph, TemporalGraph]]:\n    \"\"\"\n    Read a file in graphtool binary format.\n\n    Args:\n        file: Path to graphtool file to be read\n    \"\"\"\n    with open(file, 'rb') as f:\n        if '.zst' in file:\n            try:\n                import zstandard as zstd\n                dctx = zstd.ZstdDecompressor()\n                data = f.read()\n                return parse_graphtool_format(dctx.decompress(data, max_output_size=len(data)))\n            except ModuleNotFoundError:\n                msg = 'Package zstandard is required to decompress graphtool files. Please install module, e.g., using \"pip install zstandard\".'\n                # LOG.error(msg)\n                raise Exception(msg)\n        else:\n            return parse_graphtool_format(f.read(), multiedges)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_network","title":"<code>read_netzschleuder_network</code>","text":"<p>Read a pathpy network record from the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the network data sets to read from</p> required <code>net</code> <code>typing.Optional[str]</code> <p>Identifier of the network within the data set to read. For data sets containing a single network only, this can be set to None.</p> <code>None</code> <code>ignore_temporal</code> <code>bool</code> <p>If False, this function will return a static or temporal network depending on whether edges contain a time attribute. If True, pathpy will not interpret time attributes and thus always return a static network.</p> <code>False</code> <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <p>Examples:</p> <p>Read network '77' from karate club data set</p> <pre><code>&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('karate', '77')\n&gt;&gt;&gt; print(type(n))\n&gt;&gt;&gt; pp.plot(n)\npp.Network\n</code></pre> <p>Read a temporal network from a data set containing a single network only (i.e. net can be omitted):</p> <pre><code>&gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('reality_mining')\n&gt;&gt;&gt; print(type(n))\n&gt;&gt;&gt; pp.plot(n)\npp.TemporalNetwork\n</code></pre> <p>Read temporal network but ignore time attribute of edges:</p> <pre><code>&gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('reality_mining', ignore_temporal=True)\n&gt;&gt;&gt; print(type(n))\n&gt;&gt;&gt; pp.plot(n)\npp.Network\n</code></pre> <p>Returns:</p> Type Description <code>typing.Union[pathpyG.core.Graph.Graph, pathpyG.core.TemporalGraph.TemporalGraph]</code> <p>Depending on whether the network data set contains an edge attribute</p> <code>typing.Union[pathpyG.core.Graph.Graph, pathpyG.core.TemporalGraph.TemporalGraph]</code> <p><code>time</code> (and whether ignore_temporal is set to True), this function</p> <code>typing.Union[pathpyG.core.Graph.Graph, pathpyG.core.TemporalGraph.TemporalGraph]</code> <p>returns an instance of Network or TemporalNetwork</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_network(name: str, net: Optional[str]=None,\n        ignore_temporal: bool=False, multiedges: bool=False,\n        base_url: str='https://networks.skewed.de') -&gt; Union[Graph, TemporalGraph]:\n    \"\"\"Read a pathpy network record from the netzschleuder repository.\n\n    Args:\n        name: Name of the network data sets to read from\n        net: Identifier of the network within the data set to read. For data sets\n            containing a single network only, this can be set to None.\n        ignore_temporal: If False, this function will return a static or temporal network depending\n            on whether edges contain a time attribute. If True, pathpy will not interpret\n            time attributes and thus always return a static network.\n        base_url: Base URL of netzschleuder repository\n\n    Examples:\n        Read network '77' from karate club data set\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('karate', '77')\n        &gt;&gt;&gt; print(type(n))\n        &gt;&gt;&gt; pp.plot(n)\n        pp.Network\n\n        Read a temporal network from a data set containing a single network only\n        (i.e. net can be omitted):\n\n        &gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('reality_mining')\n        &gt;&gt;&gt; print(type(n))\n        &gt;&gt;&gt; pp.plot(n)\n        pp.TemporalNetwork\n\n        Read temporal network but ignore time attribute of edges:\n\n        &gt;&gt;&gt; n = pp.io.graphtool.read_netzschleuder_network('reality_mining', ignore_temporal=True)\n        &gt;&gt;&gt; print(type(n))\n        &gt;&gt;&gt; pp.plot(n)\n        pp.Network\n\n\n    Returns:\n        Depending on whether the network data set contains an edge attribute\n        `time` (and whether ignore_temporal is set to True), this function\n        returns an instance of Network or TemporalNetwork\n\n    \"\"\"\n    try:\n        import zstandard as zstd\n\n        # retrieve network properties\n        url = '/api/net/{0}'.format(name)\n        properties = json.loads(request.urlopen(base_url + url).read())\n\n        # retrieve data\n        if not net:\n            net = name\n        url = '/net/{0}/files/{1}.gt.zst'.format(name, net)\n        try:\n            f = request.urlopen(base_url + url)\n        except HTTPError:\n            msg = 'Could not connect to netzschleuder repository at {0}'.format(base_url)\n            #LOG.error(msg)\n            raise Exception(msg)\n\n        # decompress data\n        dctx = zstd.ZstdDecompressor()\n        reader = dctx.stream_reader(f)\n        decompressed = reader.readall()\n\n        # parse graphtool binary format\n        return parse_graphtool_format(bytes(decompressed))\n\n    except ModuleNotFoundError:\n        msg = 'Package zstandard is required to decompress graphtool files. Please install module, e.g., using \"pip install zstandard.'\n        # LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_record","title":"<code>read_netzschleuder_record</code>","text":"<p>Read metadata of a single data record with given name from the netzschleuder repository</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the data set for which to retrieve the metadata</p> required <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <p>Examples:</p> <p>Retrieve metadata of karate club network</p> <pre><code>&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; metdata = pp.io.graphtool.read_netzschleuder_record('karate')\n&gt;&gt;&gt; print(metadata)\n{\n    'analyses': {'77': {'average_degree': 4.52... } }\n}\n</code></pre> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing key-value pairs of metadata</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_record(name: str, base_url: str='https://networks.skewed.de') -&gt; dict:\n    \"\"\"\n    Read metadata of a single data record with given name from the netzschleuder repository\n\n    Args:\n        name: Name of the data set for which to retrieve the metadata\n        base_url: Base URL of netzschleuder repository\n\n    Examples:\n        Retrieve metadata of karate club network\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; metdata = pp.io.graphtool.read_netzschleuder_record('karate')\n        &gt;&gt;&gt; print(metadata)\n        {\n            'analyses': {'77': {'average_degree': 4.52... } }\n        }\n\n    Returns:\n        Dictionary containing key-value pairs of metadata\n    \"\"\"\n    url = '/api/net/{0}'.format(name)\n    try:\n        return json.loads(request.urlopen(base_url + url).read())\n    except HTTPError:\n        msg = 'Could not connect to netzschleuder repository at {0}'.format(base_url)\n        #LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/nn/","title":"nn","text":""},{"location":"reference/pathpyG/nn/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/nn/dbgnn/#pathpyG.nn.dbgnn.DBGNN","title":"<code>DBGNN</code>","text":"<p>               Bases: <code>torch.nn.Module</code></p> <p>Implementation of time-aware graph neural network DBGNN (Reference paper).</p> <p>Parameters:</p> Name Type Description Default <code>num_classes</code> <code>int</code> <p>number of classes</p> required <code>num_features</code> <code>list[int]</code> <p>number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]</p> required <code>hidden_dims</code> <code>list[int]</code> <p>number of hidden dimensions per each layer in the first/higher order network</p> required <code>p_dropout</code> <code>float</code> <p>drop-out probability</p> <code>0.0</code> Source code in <code>src/pathpyG/nn/dbgnn.py</code> <pre><code>class DBGNN(Module):\n    \"\"\"Implementation of time-aware graph neural network DBGNN ([Reference paper](https://openreview.net/pdf?id=Dbkqs1EhTr)).\n\n    Args:\n        num_classes: number of classes\n        num_features: number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]\n        hidden_dims: number of hidden dimensions per each layer in the first/higher order network\n        p_dropout: drop-out probability\n    \"\"\"\n    def __init__(\n        self,\n        num_classes: int,\n        num_features: list[int],\n        hidden_dims: list[int],\n        p_dropout: float = 0.0\n    ):\n        super().__init__()\n\n        self.num_features = num_features\n        self.num_classes = num_classes\n        self.hidden_dims = hidden_dims\n        self.p_dropout = p_dropout\n\n        # higher-order layers\n        self.higher_order_layers = ModuleList()\n        self.higher_order_layers.append(GCNConv(self.num_features[1], self.hidden_dims[0]))\n\n        # first-order layers\n        self.first_order_layers = ModuleList()\n        self.first_order_layers.append(GCNConv(self.num_features[0], self.hidden_dims[0]))\n\n        for dim in range(1, len(self.hidden_dims)-1):\n            # higher-order layers\n            self.higher_order_layers.append(GCNConv(self.hidden_dims[dim-1], self.hidden_dims[dim]))\n            # first-order layers\n            self.first_order_layers.append(GCNConv(self.hidden_dims[dim-1], self.hidden_dims[dim]))\n\n        self.bipartite_layer = BipartiteGraphOperator(self.hidden_dims[-2], self.hidden_dims[-1])\n\n        # Linear layer\n        self.lin = torch.nn.Linear(self.hidden_dims[-1], num_classes)\n\n\n\n    def forward(self, data):\n\n        x = data.x\n        x_h = data.x_h\n\n        # First-order convolutions\n        for layer in self.first_order_layers:\n            x = F.dropout(x, p=self.p_dropout, training=self.training)\n            x = F.elu(layer(x, data.edge_index, data.edge_weights))\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Second-order convolutions\n        for layer in self.higher_order_layers:\n            x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n            x_h = F.elu(layer(x_h, data.edge_index_higher_order, data.edge_weights_higher_order))\n        x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n\n        # Bipartite message passing\n        x = torch.nn.functional.elu(self.bipartite_layer((x_h, x), data.bipartite_edge_index, N = data.num_ho_nodes, M= data.num_nodes))\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Linear layer\n        x = self.lin(x)\n\n        return x\n</code></pre>"},{"location":"reference/pathpyG/processes/","title":"processes","text":"<p>Module for pathpy processes.</p>"},{"location":"reference/pathpyG/processes/process/","title":"process","text":"<p>Base classes for simulation of dynamical processes</p>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess","title":"<code>BaseProcess</code>","text":"<p>Abstract base class for all implementations of discrete-time dynamical processes.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>class BaseProcess:\n    \"\"\"Abstract base class for all implementations of discrete-time dynamical processes.\n    \"\"\"\n\n    def __init__(self, network: Graph):\n        \"\"\"initialize process.\"\"\"\n        self._network = network\n        self.init(self.random_seed())\n\n    @property\n    def network(self) -&gt; Graph:\n        return self._network\n\n    @abc.abstractmethod\n    def init(self, seed: Any) -&gt; None:\n        \"\"\"Abstract method to initialize the process with a given seed state.\"\"\"\n\n    @abc.abstractmethod\n    def random_seed(self) -&gt; Any:\n        \"\"\"Abstract method to generate a random seed state for the process.\"\"\"\n\n    @abc.abstractmethod\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"Abstract method to simulate a single step of the process. Returns \n        an iterable of node uids whose state has been changed in this step.\"\"\"\n\n    @abc.abstractproperty\n    def time(self) -&gt; int:\n        \"\"\"Abstract property returning the current time.\"\"\"\n\n    @abc.abstractmethod\n    def state_to_color(self, Any) -&gt; Union[Tuple[int, int, int], str]:\n        \"\"\"Abstract method mapping node states to RGB colors or color names.\"\"\"\n\n    @abc.abstractmethod\n    def node_state(self, v: str) -&gt; Any:\n        \"\"\"Abstract method returning the current state of a given node.\"\"\"\n\n    def simulation_run(self, steps: int, seed: Optional[Any] = None) -&gt; Tuple[int, Set[str]]:\n        \"\"\"Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.\"\"\"\n        if seed == None:\n            self.init(self.random_seed())\n        else:\n            self.init(seed)\n        for _ in range(steps):\n            ret = self.step()\n            if ret is not None:\n                yield self.time, ret\n            else:\n                return None\n\n    def run_experiment(self, steps: int, runs: Optional[Union[int, Iterable[Any]]] = 1) -&gt; DataFrame:\n        \"\"\"Perform one or more simulation runs of the process with a given number of steps.\"\"\"\n\n        # Generate initializations for different runs\n        seeds: List = list()\n        if type(runs) == int:\n            for s in range(runs):\n                seeds.append(self.random_seed())\n        else:\n            for s in runs:\n                seeds.append(s)\n\n        results = list()\n        run_id: int = 0\n        for seed in tqdm(seeds):\n\n            # initialize seed state and record initial state\n            self.init(seed)\n            for v in self.network.nodes:\n                results.append({'run_id': run_id, 'seed': seed,\n                               'time': self.time, 'node': v, 'state': self.node_state(v)})\n\n            # simulate the given number of steps\n            for time, updated_nodes in self.simulation_run(steps, seed):\n                # print(updated_nodes)\n                # record the new state of each changed node\n                for v in updated_nodes:\n                    results.append({'run_id': run_id, 'seed': seed,\n                                   'time': time, 'node': v, 'state': self.node_state(v)})\n            run_id += 1\n\n        return DataFrame.from_dict(results)\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.__init__","title":"<code>__init__</code>","text":"<p>initialize process.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def __init__(self, network: Graph):\n    \"\"\"initialize process.\"\"\"\n    self._network = network\n    self.init(self.random_seed())\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.init","title":"<code>init</code>  <code>abstractmethod</code>","text":"<p>Abstract method to initialize the process with a given seed state.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef init(self, seed: Any) -&gt; None:\n    \"\"\"Abstract method to initialize the process with a given seed state.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.node_state","title":"<code>node_state</code>  <code>abstractmethod</code>","text":"<p>Abstract method returning the current state of a given node.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef node_state(self, v: str) -&gt; Any:\n    \"\"\"Abstract method returning the current state of a given node.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.random_seed","title":"<code>random_seed</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate a random seed state for the process.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef random_seed(self) -&gt; Any:\n    \"\"\"Abstract method to generate a random seed state for the process.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.run_experiment","title":"<code>run_experiment</code>","text":"<p>Perform one or more simulation runs of the process with a given number of steps.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def run_experiment(self, steps: int, runs: Optional[Union[int, Iterable[Any]]] = 1) -&gt; DataFrame:\n    \"\"\"Perform one or more simulation runs of the process with a given number of steps.\"\"\"\n\n    # Generate initializations for different runs\n    seeds: List = list()\n    if type(runs) == int:\n        for s in range(runs):\n            seeds.append(self.random_seed())\n    else:\n        for s in runs:\n            seeds.append(s)\n\n    results = list()\n    run_id: int = 0\n    for seed in tqdm(seeds):\n\n        # initialize seed state and record initial state\n        self.init(seed)\n        for v in self.network.nodes:\n            results.append({'run_id': run_id, 'seed': seed,\n                           'time': self.time, 'node': v, 'state': self.node_state(v)})\n\n        # simulate the given number of steps\n        for time, updated_nodes in self.simulation_run(steps, seed):\n            # print(updated_nodes)\n            # record the new state of each changed node\n            for v in updated_nodes:\n                results.append({'run_id': run_id, 'seed': seed,\n                               'time': time, 'node': v, 'state': self.node_state(v)})\n        run_id += 1\n\n    return DataFrame.from_dict(results)\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.simulation_run","title":"<code>simulation_run</code>","text":"<p>Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def simulation_run(self, steps: int, seed: Optional[Any] = None) -&gt; Tuple[int, Set[str]]:\n    \"\"\"Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.\"\"\"\n    if seed == None:\n        self.init(self.random_seed())\n    else:\n        self.init(seed)\n    for _ in range(steps):\n        ret = self.step()\n        if ret is not None:\n            yield self.time, ret\n        else:\n            return None\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.state_to_color","title":"<code>state_to_color</code>  <code>abstractmethod</code>","text":"<p>Abstract method mapping node states to RGB colors or color names.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef state_to_color(self, Any) -&gt; Union[Tuple[int, int, int], str]:\n    \"\"\"Abstract method mapping node states to RGB colors or color names.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.step","title":"<code>step</code>  <code>abstractmethod</code>","text":"<p>Abstract method to simulate a single step of the process. Returns  an iterable of node uids whose state has been changed in this step.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef step(self) -&gt; Iterable[str]:\n    \"\"\"Abstract method to simulate a single step of the process. Returns \n    an iterable of node uids whose state has been changed in this step.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.time","title":"<code>time</code>","text":"<p>Abstract property returning the current time.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractproperty\ndef time(self) -&gt; int:\n    \"\"\"Abstract property returning the current time.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/","title":"random_walk","text":"<p>Classes to simlate random walks on static, temporal, and higher-order networks.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk","title":"<code>HigherOrderRandomWalk</code>","text":"<p>               Bases: <code>pathpyG.processes.random_walk.RandomWalk</code></p> <p>Class that implements a biased random walk process in a higher-order network.</p> <p>Instances of this class can be used to simulate random walk processes in higher-order networks for arbitrary orders k. The random walk process can include weighted edges as well as a  restart probability, i.e. a per-step probability to teleport to a randomly chosen higher-order node.</p> <p>Different from the class RandomWalk, instances of class HigherOrderRandomWalk automatically project states to the corresponding first-order network, i.e. paths and visualisations are given  in terms of the nodes in the first-order network, while the dynamics of the random walk is governed by the underlying higher-order network.</p> <p>The implementation follows the general concept to simulate discrete-time (stochastic) processes as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface to iterate through the steps of a single random walk process, or use the <code>run_experiment</code> function to simulate multiple runs of a random walk with different start nodes (i.e. seeds).</p> <p>The <code>run_experiment</code> function returns a pandas DataFrame object that contains all node state changes  during the process' evolution. This data frame can be converted to Path and PathCollection objects  and it can be visualized using the plot function.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk--examples","title":"Examples","text":"<p>Generate and visualize a single random walk with 10 steps on a higher-order network</p> <p>import pathpy as pp g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']]) paths = pp.WalkData(g3.mapping) paths.add_walk_seq(['a','b','c'],freq=1) paths.add_walk_seq(['b','c','a'],freq=1) paths.add_walk_seq(['b','c','d'],freq=0.2) paths.add_walk_seq(['c','a','b'],freq=1) paths.add_walk_seq(['c','d','a'],freq=0.2) paths.add_walk_seq(['d','a','b'],freq=1) g_ho = pp.HigherOrderGraph(paths, order =2)</p> <p>rw = pp.processes.HigherOrderRandomWalk(g_ho, weight=True) data = rw.run_experiment(steps=10, runs=[('b','c')]) rw.plot(data) [interactive visualization in first-order network]</p> <p>Use <code>plot</code> function of base class to visualize random walk in second-order network</p> <p>pp.processes.RandomWalk.plot(rw, data) [interactive visualization in second-order network]</p> <p>Generate a single random walk with 10 steps starting from node 'b-c' and  return a first-order path</p> <p>p = rw.get_path(rw.run_experiment(steps=10, runs=['b-c'])) pprint([v.uid for v in p.nodes ])  [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']</p> <p>Use <code>get_path</code> function of base class to return path with second-order nodes</p> <p>p = pp.processes.RandomWalk.get_path(rw2, data) print([ v.uid for v in p.nodes ])</p> <p>Generate one random walk with 10 steps starting from each node and  return a WalkData instance with first-order paths</p> <p>paths = rw.get_paths(rw.run_experiment(steps=10, runs=g_ho.nodes)) pprint([v.uid for v in p.nodes ])  [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']  [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ] [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ] [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]</p> <p>Simulate a random walk using the iterator interface, which provides full access  to the state after each simulation step</p> <p>for time, _ in rw2.simulation_run(steps=50, seed='b-c'):     print('Current node = {0}'.format(rw2.first_order_node(rw2.current_node)))     print(rw2._first_order_visitation_frequencies) Current node = b [0.33333333 0.33333333 0.33333333 0.        ] Current node = c [0.32142857 0.32142857 0.35714286 0.        ] Current node = a [0.34482759 0.31034483 0.34482759 0.        ] Current node = b [0.33333333 0.33333333 0.33333333 0.        ] Current node = c [0.32258065 0.32258065 0.35483871 0.        ] Current node = a</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk--see-also","title":"See Also","text":"<p>VoseAliasSampling, RandomWalk, BaseProcess</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>class HigherOrderRandomWalk(RandomWalk):\n    \"\"\"Class that implements a biased random walk process in a higher-order network.\n\n        Instances of this class can be used to simulate random walk processes in higher-order networks for\n        arbitrary orders k. The random walk process can include weighted edges as well as a \n        restart probability, i.e. a per-step probability to teleport to a\n        randomly chosen higher-order node.\n\n        Different from the class RandomWalk, instances of class HigherOrderRandomWalk automatically project states to the corresponding first-order network, i.e. paths and visualisations are given \n        in terms of the nodes in the first-order network, while the dynamics of the random walk is governed by the underlying higher-order network.\n\n        The implementation follows the general concept to simulate discrete-time (stochastic) processes\n        as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface\n        to iterate through the steps of a single random walk process, or use the `run_experiment` function\n        to simulate multiple runs of a random walk with different start nodes (i.e. seeds).\n\n        The `run_experiment` function returns a pandas DataFrame object that contains all node state changes \n        during the process' evolution. This data frame can be converted to Path and PathCollection objects \n        and it can be visualized using the plot function.\n\n        Examples\n        --------\n        Generate and visualize a single random walk with 10 steps on a higher-order network\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n        &gt;&gt;&gt; paths = pp.WalkData(g3.mapping)\n        &gt;&gt;&gt; paths.add_walk_seq(['a','b','c'],freq=1)\n        &gt;&gt;&gt; paths.add_walk_seq(['b','c','a'],freq=1)\n        &gt;&gt;&gt; paths.add_walk_seq(['b','c','d'],freq=0.2)\n        &gt;&gt;&gt; paths.add_walk_seq(['c','a','b'],freq=1)\n        &gt;&gt;&gt; paths.add_walk_seq(['c','d','a'],freq=0.2)\n        &gt;&gt;&gt; paths.add_walk_seq(['d','a','b'],freq=1)\n        &gt;&gt;&gt; g_ho = pp.HigherOrderGraph(paths, order =2)\n\n        &gt;&gt;&gt; rw = pp.processes.HigherOrderRandomWalk(g_ho, weight=True)\n        &gt;&gt;&gt; data = rw.run_experiment(steps=10, runs=[('b','c')])\n        &gt;&gt;&gt; rw.plot(data)\n        [interactive visualization in first-order network]\n\n        Use `plot` function of base class to visualize random walk in second-order network\n\n        &gt;&gt;&gt; pp.processes.RandomWalk.plot(rw, data)\n        [interactive visualization in second-order network]\n\n        Generate a single random walk with 10 steps starting from node 'b-c' and \n        return a first-order path\n\n        &gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['b-c']))\n        &gt;&gt;&gt; pprint([v.uid for v in p.nodes ]) \n        [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n\n        Use `get_path` function of base class to return path with second-order nodes\n\n        &gt;&gt;&gt; p = pp.processes.RandomWalk.get_path(rw2, data)\n        &gt;&gt;&gt; print([ v.uid for v in p.nodes ])\n\n        Generate one random walk with 10 steps starting from each node and \n        return a WalkData instance with first-order paths\n\n        &gt;&gt;&gt; paths = rw.get_paths(rw.run_experiment(steps=10, runs=g_ho.nodes))\n        &gt;&gt;&gt; pprint([v.uid for v in p.nodes ]) \n        [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b'] \n        [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n        [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n        [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n\n        Simulate a random walk using the iterator interface, which provides full access \n        to the state after each simulation step\n\n        &gt;&gt;&gt; for time, _ in rw2.simulation_run(steps=50, seed='b-c'):\n        &gt;&gt;&gt;     print('Current node = {0}'.format(rw2.first_order_node(rw2.current_node)))\n        &gt;&gt;&gt;     print(rw2._first_order_visitation_frequencies)\n        Current node = b\n        [0.33333333 0.33333333 0.33333333 0.        ]\n        Current node = c\n        [0.32142857 0.32142857 0.35714286 0.        ]\n        Current node = a\n        [0.34482759 0.31034483 0.34482759 0.        ]\n        Current node = b\n        [0.33333333 0.33333333 0.33333333 0.        ]\n        Current node = c\n        [0.32258065 0.32258065 0.35483871 0.        ]\n        Current node = a\n\n        See Also\n        --------\n        VoseAliasSampling, RandomWalk, BaseProcess\n    \"\"\"\n\n    def __init__(self, higher_order_network: Graph, first_order_network, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n        \"\"\"Creates a biased random walk process in a network.\n\n            Parameters\n            ----------\n            higher_order_network: HigherOrderGraph\n                The higher-order network instance on which to perform the random walk process.\n\n            first_order_network: Network\n                The first-order network instance to be used for mapping the process to first-order nodes\n\n            weight: Weight = None\n                If specified, the given numerical edge attribute will be used to bias\n                the random walk transition probabilities.\n\n            restart_probability: float = 0\n                The per-step probability that a random walker restarts in a random (higher-order) node\n\n            See Also\n            --------\n            RandomWalk, BaseProcess\n        \"\"\"\n        self._first_order_network = first_order_network\n        RandomWalk.__init__(self, higher_order_network, weight, restart_prob)\n\n    def init(self, seed) -&gt; None:\n\n        # set number of times each first-order node has been visited\n        self._first_order_visitations = np.ravel(\n            np.zeros(shape=(1, self._first_order_network.N)))\n        self._first_order_visitations[self._first_order_network.mapping.to_idx(seed[-1])] = 1\n        RandomWalk.init(self, seed)\n\n    @property\n    def first_order_visitation_frequencies(self) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n        the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n        \"\"\"\n        return np.nan_to_num(self._first_order_visitations/(self._t+1))\n\n    def first_order_stationary_state(self, **kwargs) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n        the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n        \"\"\"\n        first_order_stationary_state = np.ravel(\n            np.zeros(shape=(1, self._first_order_network.N)))\n        higher_order_stationary_dist = RandomWalk.stationary_state(\n            self, **kwargs)\n        for v in self._network.nodes:\n            # newly visited node in first_order network\n            v1 = v.relations[-1]\n            first_order_stationary_state[self._first_order_network.mapping.to_idx[v1]\n                                         ] += higher_order_stationary_dist[self._network.mapping.to_idx[v]]\n        return first_order_stationary_state\n\n    @property\n    def first_order_total_variation_distance(self) -&gt; float:\n        \"\"\"Returns the total variation distance between stationary \n        visitation probabilities and the current visitation frequencies, projected\n        to nodes in the first_order_network.\n\n        Computes the total variation distance between the current (first-order) node visitation\n        probabilities and the (first-order) stationary node visitation probabilities. This quantity converges to zero for HigherOrderRandomWalk.time -&gt; np.infty and its magnitude indicates the\n        current relaxation of the higher-order random walk process.\n        \"\"\"\n        return self.TVD(self.first_order_stationary_state(), self.first_order_visitation_frequencies)\n\n    def first_order_node(self, higher_order_node: tuple) -&gt; str:\n        \"\"\"\n        Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.\n\n        Parameters\n        ----------\n        higher_order_node: tuple\n            Tuple that represents the higher-order node \n\n        Returns\n        -------\n        str\n            String of the corresponding first-order node\n        \"\"\"\n        return higher_order_node[-1]\n\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"\n        Function that will be called for each step of the random walk. This function \n        returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.\n\n        Use the `first_order_node` function to map those nodes to nodes in the first-order network\n        \"\"\"\n        (current_node, previous_node) = RandomWalk.step(self)\n\n        self._first_order_visitations[self._first_order_network.mapping.to_idx(current_node[-1])] += 1\n\n        return (current_node, previous_node)\n\n\n    def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = 0) -&gt; DAGData:\n        \"\"\"Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.\n\n        Parameters\n        ----------\n\n        data: DataFrame\n            Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n\n        run_uid: Optional[int]=0\n               Uid of the random walk simulations to be returned as WalkData (default: 0).\n\n        Returns\n        -------\n\n        Path\n            WalkData object containing the sequences of nodes traversed by the random walks\n\n        \"\"\"\n        # list of traversed nodes starting with seed node\n\n        if not run_ids:  # generate paths for all run_ids in the data frame\n            runs = data['run_id'].unique()\n        else:\n            runs = run_ids\n\n        paths = DAGData(mapping = self._first_order_network.mapping)\n        for run in runs:\n            walk_steps = list(data.loc[(data['run_id'] == run) &amp; (\n                data['state'] == True)]['node'].values)\n\n            # for higher-order random walk, seed node is a higher-order node\n            # consisting of one or more edges\n            seed = walk_steps[0]\n            walk = [v for v in seed]\n\n            # map higher-order nodes to first-order nodes\n            for i in range(1, len(walk_steps)):\n                walk.append(walk_steps[i][-1])\n            paths.append_walk(walk)\n        return paths\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_total_variation_distance","title":"<code>first_order_total_variation_distance: float</code>  <code>property</code>","text":"<p>Returns the total variation distance between stationary  visitation probabilities and the current visitation frequencies, projected to nodes in the first_order_network.</p> <p>Computes the total variation distance between the current (first-order) node visitation probabilities and the (first-order) stationary node visitation probabilities. This quantity converges to zero for HigherOrderRandomWalk.time -&gt; np.infty and its magnitude indicates the current relaxation of the higher-order random walk process.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_visitation_frequencies","title":"<code>first_order_visitation_frequencies: np.array</code>  <code>property</code>","text":"<p>Returns current normalized visitation frequencies of first-order nodes based on the history of the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.__init__","title":"<code>__init__</code>","text":"<p>Creates a biased random walk process in a network.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.__init__--parameters","title":"Parameters","text":"<p>higher_order_network: HigherOrderGraph     The higher-order network instance on which to perform the random walk process.</p> Network <p>The first-order network instance to be used for mapping the process to first-order nodes</p> Weight = None <p>If specified, the given numerical edge attribute will be used to bias the random walk transition probabilities.</p> float = 0 <p>The per-step probability that a random walker restarts in a random (higher-order) node</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.__init__--see-also","title":"See Also","text":"<p>RandomWalk, BaseProcess</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def __init__(self, higher_order_network: Graph, first_order_network, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n    \"\"\"Creates a biased random walk process in a network.\n\n        Parameters\n        ----------\n        higher_order_network: HigherOrderGraph\n            The higher-order network instance on which to perform the random walk process.\n\n        first_order_network: Network\n            The first-order network instance to be used for mapping the process to first-order nodes\n\n        weight: Weight = None\n            If specified, the given numerical edge attribute will be used to bias\n            the random walk transition probabilities.\n\n        restart_probability: float = 0\n            The per-step probability that a random walker restarts in a random (higher-order) node\n\n        See Also\n        --------\n        RandomWalk, BaseProcess\n    \"\"\"\n    self._first_order_network = first_order_network\n    RandomWalk.__init__(self, higher_order_network, weight, restart_prob)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_node","title":"<code>first_order_node</code>","text":"<p>Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_node--parameters","title":"Parameters","text":"<p>higher_order_node: tuple     Tuple that represents the higher-order node </p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_node--returns","title":"Returns","text":"<p>str     String of the corresponding first-order node</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def first_order_node(self, higher_order_node: tuple) -&gt; str:\n    \"\"\"\n    Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.\n\n    Parameters\n    ----------\n    higher_order_node: tuple\n        Tuple that represents the higher-order node \n\n    Returns\n    -------\n    str\n        String of the corresponding first-order node\n    \"\"\"\n    return higher_order_node[-1]\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_stationary_state","title":"<code>first_order_stationary_state</code>","text":"<p>Returns current normalized visitation frequencies of first-order nodes based on the history of the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def first_order_stationary_state(self, **kwargs) -&gt; np.array:\n    \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n    the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n    \"\"\"\n    first_order_stationary_state = np.ravel(\n        np.zeros(shape=(1, self._first_order_network.N)))\n    higher_order_stationary_dist = RandomWalk.stationary_state(\n        self, **kwargs)\n    for v in self._network.nodes:\n        # newly visited node in first_order network\n        v1 = v.relations[-1]\n        first_order_stationary_state[self._first_order_network.mapping.to_idx[v1]\n                                     ] += higher_order_stationary_dist[self._network.mapping.to_idx[v]]\n    return first_order_stationary_state\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.get_paths","title":"<code>get_paths</code>","text":"<p>Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.get_paths--parameters","title":"Parameters","text":"DataFrame <p>Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of <code>run_experiment</code></p> Optional[int]=0 <p>Uid of the random walk simulations to be returned as WalkData (default: 0).</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.get_paths--returns","title":"Returns","text":"<p>Path     WalkData object containing the sequences of nodes traversed by the random walks</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = 0) -&gt; DAGData:\n    \"\"\"Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.\n\n    Parameters\n    ----------\n\n    data: DataFrame\n        Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n\n    run_uid: Optional[int]=0\n           Uid of the random walk simulations to be returned as WalkData (default: 0).\n\n    Returns\n    -------\n\n    Path\n        WalkData object containing the sequences of nodes traversed by the random walks\n\n    \"\"\"\n    # list of traversed nodes starting with seed node\n\n    if not run_ids:  # generate paths for all run_ids in the data frame\n        runs = data['run_id'].unique()\n    else:\n        runs = run_ids\n\n    paths = DAGData(mapping = self._first_order_network.mapping)\n    for run in runs:\n        walk_steps = list(data.loc[(data['run_id'] == run) &amp; (\n            data['state'] == True)]['node'].values)\n\n        # for higher-order random walk, seed node is a higher-order node\n        # consisting of one or more edges\n        seed = walk_steps[0]\n        walk = [v for v in seed]\n\n        # map higher-order nodes to first-order nodes\n        for i in range(1, len(walk_steps)):\n            walk.append(walk_steps[i][-1])\n        paths.append_walk(walk)\n    return paths\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.step","title":"<code>step</code>","text":"<p>Function that will be called for each step of the random walk. This function  returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.</p> <p>Use the <code>first_order_node</code> function to map those nodes to nodes in the first-order network</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def step(self) -&gt; Iterable[str]:\n    \"\"\"\n    Function that will be called for each step of the random walk. This function \n    returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.\n\n    Use the `first_order_node` function to map those nodes to nodes in the first-order network\n    \"\"\"\n    (current_node, previous_node) = RandomWalk.step(self)\n\n    self._first_order_visitations[self._first_order_network.mapping.to_idx(current_node[-1])] += 1\n\n    return (current_node, previous_node)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk","title":"<code>RandomWalk</code>","text":"<p>               Bases: <code>pathpyG.processes.process.BaseProcess</code></p> <p>Class that implements a biased random walk process in a network.</p> <p>Instances of this class can be used to simulate random walk processes in any instance of the class Graph. The random walk process can include weighted edges as well as a  restart probability, i.e. a per-step probability to teleport to a randomly chosen node.</p> <p>Since any instance of HigherOrderGraph is also an instance of Graph, this class can be directly be applied to simulate random walks in higher-order networks. However,  the state space of such a random walk is given by the higher-order nodes. If you wish to simulate a higher-order random walk while projecting states to the corresponding first-order  network, you should use the class HigherOrderRandomWalk instead.</p> <p>The implementation follows the general concept to simulate discrete-time (stochastic) processes as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface to iterate through the steps of a single random walk process, or use the <code>run_experiment</code> function to simulate multiple runs of a random walk with different start nodes (i.e. seeds).</p> <p>The <code>run_experiment</code> function returns a pandas DataFrame object that contains all node state changes  during the process' evolution. This data frame can be converted to Path and PathCollection objects  and it can be visualized using the plot function.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk--examples","title":"Examples","text":"<p>Generate and visualize a single biased random walk with 10 steps on a network</p> <p>import pathpyG as pp g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']]) rw = pp.processes.RandomWalk(g, weight='edge_weight') data = rw.run_experiment(steps=10, seed='a') rw.plot(data) [interactive visualization]</p> <p>Generate a single random walk with 10 steps starting from node 'a' and  return a WalkData instance</p> <p>p = rw.get_path(rw.run_experiment(steps=10, runs=['a']))</p> <p>Generate one random walk with 10 steps starting from each node and  return a PathCollection instance</p> <p>pc = rw.get_paths(rw.run_experiment(steps=10, runs=g.nodes)) [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']  [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ] [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ] [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]</p> <p>Simulate a random walk using the iterator interface, which provides full access  to the state after each simulation step</p> <p>for time, _ in rw.simulation_run(steps=5, seed='a'):     print('Current node = {0}'.format(rw.current_node))     print(rw.visitation_frequencies) Current node = b [0.5 0.5 0.  0. ] Current node = c [0.33333333 0.33333333 0.33333333 0. ] Current node = d [0.25 0.25 0.25 0.25] Current node = a [0.4 0.2 0.2 0.2] Current node = b [0.33333333 0.33333333 0.16666667 0.16666667] Current node = a [0.42857143 0.28571429 0.14285714 0.14285714] Current node = c [0.375 0.25  0.25  0.125] Current node = a [0.44444444 0.22222222 0.22222222 0.11111111] Current node = b [0.4 0.3 0.2 0.1] Current node = a [0.45454545 0.27272727 0.18181818 0.09090909]</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>class RandomWalk(BaseProcess):\n    \"\"\"Class that implements a biased random walk process in a network.\n\n    Instances of this class can be used to simulate random walk processes in any instance\n    of the class Graph. The random walk process can include weighted edges as well as a \n    restart probability, i.e. a per-step probability to teleport to a\n    randomly chosen node.\n\n    Since any instance of HigherOrderGraph is also an instance of Graph, this class\n    can be directly be applied to simulate random walks in higher-order networks. However, \n    the state space of such a random walk is given by the higher-order nodes. If you wish to\n    simulate a higher-order random walk while projecting states to the corresponding first-order \n    network, you should use the class HigherOrderRandomWalk instead.\n\n    The implementation follows the general concept to simulate discrete-time (stochastic) processes\n    as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface\n    to iterate through the steps of a single random walk process, or use the `run_experiment` function\n    to simulate multiple runs of a random walk with different start nodes (i.e. seeds).\n\n    The `run_experiment` function returns a pandas DataFrame object that contains all node state changes \n    during the process' evolution. This data frame can be converted to Path and PathCollection objects \n    and it can be visualized using the plot function.\n\n    Examples\n    --------\n    Generate and visualize a single biased random walk with 10 steps on a network\n\n    &gt;&gt;&gt; import pathpyG as pp\n    &gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n    &gt;&gt;&gt; rw = pp.processes.RandomWalk(g, weight='edge_weight')\n    &gt;&gt;&gt; data = rw.run_experiment(steps=10, seed='a')\n    &gt;&gt;&gt; rw.plot(data)\n    [interactive visualization]\n\n    Generate a single random walk with 10 steps starting from node 'a' and \n    return a WalkData instance\n\n    &gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['a']))\n\n    Generate one random walk with 10 steps starting from each node and \n    return a PathCollection instance\n\n    &gt;&gt;&gt; pc = rw.get_paths(rw.run_experiment(steps=10, runs=g.nodes))\n    [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b'] \n    [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n    [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n    [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n\n    Simulate a random walk using the iterator interface, which provides full access \n    to the state after each simulation step\n\n    &gt;&gt;&gt; for time, _ in rw.simulation_run(steps=5, seed='a'):\n    &gt;&gt;&gt;     print('Current node = {0}'.format(rw.current_node))\n    &gt;&gt;&gt;     print(rw.visitation_frequencies)\n    Current node = b\n    [0.5 0.5 0.  0. ]\n    Current node = c\n    [0.33333333 0.33333333 0.33333333 0. ]\n    Current node = d\n    [0.25 0.25 0.25 0.25]\n    Current node = a\n    [0.4 0.2 0.2 0.2]\n    Current node = b\n    [0.33333333 0.33333333 0.16666667 0.16666667]\n    Current node = a\n    [0.42857143 0.28571429 0.14285714 0.14285714]\n    Current node = c\n    [0.375 0.25  0.25  0.125]\n    Current node = a\n    [0.44444444 0.22222222 0.22222222 0.11111111]\n    Current node = b\n    [0.4 0.3 0.2 0.1]\n    Current node = a\n    [0.45454545 0.27272727 0.18181818 0.09090909]\n    \"\"\"\n\n    def __init__(self, network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n        \"\"\"Creates a biased random walk process in a network.\n\n        Parameters\n        ----------\n        network: Network\n            The network instance on which to perform the random walk process. Can also \n            be an instance of HigherOrderNetwork.\n\n        weight: Weight = None\n            If specified, the given numerical edge attribute will be used to bias\n            the random walk transition probabilities.\n\n        restart_probability: float = 0\n            The per-step probability that a random walker restarts in a random node\n\n        See Also\n        --------\n        VoseAliasSampling, HigherOrderRandomWalk, BaseProcess\n        \"\"\"\n\n        # transition matrix of random walk\n        self._transition_matrix = RandomWalk.compute_transition_matrix(\n            network, weight, restart_prob)\n\n        # initialize Vose Alias Samplers\n\n        self.samplers = {v: VoseAliasSampling(np.nan_to_num(np.ravel(\n            self._transition_matrix[\n                network.mapping.to_idx(v), :].todense()))) for v in network.nodes}\n\n        # compute eigenvectors and eigenvalues of transition matrix\n        if network.N &gt; 2:\n            _, eigenvectors = spl.eigs(\n                self._transition_matrix.transpose(), k=1, which='LM')\n            pi = eigenvectors.reshape(eigenvectors.size, )\n        else:\n            eigenvals, eigenvectors = spla.eig(\n                self._transition_matrix.transpose().toarray())\n            x = np.argsort(-eigenvals)\n            pi = eigenvectors[x][:, 0]\n\n        # calculate stationary visitation probabilities\n        self._stationary_probabilities = np.real(pi/np.sum(pi))\n\n        self._network = network\n        self.init(self.random_seed())\n\n    def init(self, seed: str) -&gt; None:\n        \"\"\"\n        Initializes the random walk state with a given seed/source node\n\n        Parameters\n        ----------\n\n        seed: Union[int, str]\n\n            Id of node in which the random walk will start\n        \"\"\"\n        # reset currently visited node (or higher-order node)\n        self._current_node = seed\n\n        # set time\n        self._t = 0\n\n        # set number of times each node has been visited\n        self._visitations = np.ravel(\n            np.zeros(shape=(1, self._network.N)))\n        self._visitations[self._network.mapping.to_idx(seed)] = 1\n\n    def random_seed(self) -&gt; Any:\n        \"\"\"\n        Returns a random node from the network, chosen uniformly at random\n        \"\"\"\n        x = np.random.choice(range(self._network.N))\n        return self._network.mapping.to_id(x)\n\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"\n        Function that will be called for each step of the random walk. This function \n        returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.\n        \"\"\"\n\n        # determine next node\n        next_node = self.network.mapping.to_id(self.samplers[self._current_node].sample(\n        ))\n        # TODO: assertion will not hold if restart_prob &gt; 0\n        # assert (self._current_node, next_node) in self._network.edges, 'Assertion Error: {0} not in edge list'.format(\n        #     (self._current_node, next_node))\n\n        previous_node = self._current_node\n        self._current_node = next_node\n\n        # increment visitations and current time\n        self._visitations[self._network.mapping.to_idx(self._current_node)] += 1\n        self._t += 1\n\n        # return tuple of changed nodes, where the first node is the currently visited node\n        return (self._current_node, previous_node)\n\n    def node_state(self, v) -&gt; bool:\n        \"\"\"\n        Returns a boolean variable indicating whether the walker is currently \n        visiting (first-order) node v\n        \"\"\"\n        if v in self._network.nodes:\n            return v == self._current_node\n        elif type(self._network) == HigherOrderGraph:\n            return v == self._network.mapping.to_id(self._current_node)[-1]\n        else:\n            raise NotImplementedError(\n                'Random walk not implemented for network of type {0}'.format(type(self._network)))\n\n    @property\n    def time(self) -&gt; int:\n        \"\"\"\n        The current time of the random walk process, i.e. the number of steps taken since the start node.\n        \"\"\"\n        return self._t\n\n    def state_to_color(self, state: bool) -&gt; str:\n        \"\"\"\n        Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.\n\n        Parameters\n        ----------\n\n        state: bool\n        \"\"\"\n        if state:\n            return 'red'\n        else:\n            return 'blue'\n\n    @staticmethod\n    def compute_transition_matrix(network: Graph,\n                                  weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; sp.sparse.csr_matrix:\n        \"\"\"Returns the transition matrix of a (biased) random walk in the given network.\n\n        Returns a transition matrix that describes a random walk process in the\n        given network.\n\n        Parameters\n        ----------\n        network: Network\n\n            The network for which the transition matrix will be created.\n\n        weight: Weight\n\n            If specified, the numerical edge attribute that shall be used in the biased\n            transition probabilities of the random walk.\n\n        \"\"\"\n        if weight is None or weight is False:\n            A = network.get_sparse_adj_matrix().todense()\n        elif weight is True:\n            A = network.get_sparse_adj_matrix(edge_attr='edge_weight').todense()\n        else:\n            A = network.get_sparse_adj_matrix(edge_attr=weight).todense()\n        D = A.sum(axis=1)\n        n = network.N\n        T = sp.sparse.lil_matrix((n, n))\n        zero_deg = 0\n        for i in range(n):\n            if D[i] == 0:\n                zero_deg += 1\n            for j in range(n):\n                if D[i] &gt; 0:\n                    T[i, j] = restart_prob * \\\n                        (1./n) + (1-restart_prob)*A[i, j]/D[i]\n                else:\n                    if restart_prob &gt; 0:\n                        T[i, j] = 1./n\n                    else:\n                        T[i, j] = 0.0\n        # if zero_deg &gt; 0:\n        #     LOG.warning(\n        #         'Network contains {0} nodes with zero out-degree'.format(zero_deg))\n        return T.tocsr()\n\n    @property\n    def transition_matrix(self) -&gt; sp.sparse.csr_matrix:\n        \"\"\"Returns the transition matrix of the random walk\n        \"\"\"\n        return self._transition_matrix\n\n    def transition_probabilities(self, node: str) -&gt; np.array:\n        \"\"\"Returns a vector that contains transition probabilities.\n\n        Returns a vector that contains transition probabilities from a given\n        node to all other nodes in the network.\n\n        \"\"\"\n        return np.nan_to_num(np.ravel(\n            self._transition_matrix[\n                self._network.nodes.to_idx(node), :].todense()))\n\n    def visitation_probabilities(self, t, seed: str) -&gt; np.ndarray:\n        \"\"\"Calculates visitation probabilities of nodes after t steps for a given start node\n\n        Initially, all visitation probabilities are zero except for the start node.\n        \"\"\"\n        assert seed in self._network.nodes\n\n        initial_dist = np.zeros(self._network.N)\n        initial_dist[self._network.mapping.to_idx(seed)] = 1.0\n        return np.dot(initial_dist, (self._transition_matrix**t).todense())\n\n    def transition_matrix_pd(self) -&gt; DataFrame:\n        \"\"\"\n        Returns the transition matrix as pandas DataFrame with proper row/column labels.\n        \"\"\"\n        return DataFrame(self.transition_matrix.todense(), columns=[v for v in self._network.nodes], index=[v for v in self._network.nodes])\n\n    @property\n    def current_node(self) -&gt; str:\n        return self._current_node\n\n    def get_path(self, data: DataFrame, run_id: Optional[int] = 0, first_order: Optional[bool] = True) -&gt; DAGData:\n        \"\"\"Returns a path that represents the sequence of (first-order) nodes traversed\n        by a single random walk.\n\n        Parameters\n        ----------\n\n        data: DataFrame\n            Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n\n        run_uid: Optional[int]=0\n               Uid of the random walk simulation to be returns as Path (default: 0).\n\n        Returns\n        -------\n\n        Path\n            Path object containing the sequence of nodes traversed by the random walk\n\n        See Also\n        --------\n\n        Path\n        \"\"\"\n        # list of traversed nodes starting with seed node\n        walk_steps = list(data.loc[(data['run_id'] == run_id) &amp; (\n            data['state'] == True)]['node'].values)\n\n        # generate Path\n        path = DAGData(self._network.mapping)\n        path.append_walk([walk_steps[i] for i in range(len(walk_steps))])\n        return path\n\n    def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = None) -&gt; DAGData:\n        \"\"\"Returns a DAGData object where each DAG is one walk\n\n        Parameters\n        ----------\n\n        data: DataFrame\n            Pandas data frame containing the trajectory of one or more random walks, generated by \n            `run_experiment`\n\n        run_ids: Optional[Iterable]=None\n            Uids of the random walk simulations to be included in the PathCollection instance. If None (default), all random walk simulations will be included.\n\n        Returns\n        -------\n\n        DAGData\n            DAGData object where each random walk is represented by one dag.\n\n        See Also\n        --------\n\n        DAGData\n        \"\"\"\n\n        if not run_ids:  # generate paths for all run_ids in the data frame\n            runs = data['run_id'].unique()\n        else:\n            runs = run_ids\n\n        walks = DAGData(self._network.mapping)\n        for id in runs:\n            walk_steps = list(data.loc[(data['run_id'] == id) &amp; (\n            data['state'] == True)]['node'].values)\n\n            # add walk to DAGData\n            walks.append_walk(walk_steps)\n\n        return walks\n\n    def stationary_state(self, **kwargs: Any) -&gt; np.array:\n        \"\"\"Computes stationary visitation probabilities.\n\n        Computes stationary visitation probabilities of nodes based on the\n        leading eigenvector of the transition matrix.\n\n        Parameters\n        ----------\n\n        **kwargs: Any\n\n            Arbitrary key-value pairs to bee passed to the\n            scipy.sparse.linalg.eigs function.\n        \"\"\"\n        _p = self._stationary_probabilities\n        if kwargs:\n            _, eigenvectors = sp.sparse.linalg.eigs(\n                self._transition_matrix.transpose(), k=1, which='LM', **kwargs)\n            pi = eigenvectors.reshape(eigenvectors.size, )\n            _p = np.real(pi/np.sum(pi))\n        return _p\n\n    @property\n    def visitation_frequencies(self) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of nodes based on the history of\n        the random walk. Initially, all visitation probabilities are zero except for the start node.\n        \"\"\"\n        return np.nan_to_num(self._visitations/(self._t+1))\n\n    @property\n    def total_variation_distance(self) -&gt; float:\n        \"\"\"Returns the total variation distance between stationary \n        visitation probabilities and the current visitation frequencies\n\n        Computes the total variation distance between the current visitation\n        probabilities and the stationary probabilities. This quantity converges\n        to zero for RandomWalk.t -&gt; np.infty and its magnitude indicates the\n        current relaxation of the random walk process.\n\n        \"\"\"\n        return self.TVD(self.stationary_state(), self.visitation_frequencies)\n\n    @staticmethod\n    def TVD(a: np.array, b: np.array) -&gt; float:\n        \"\"\"Calculates the total variation distance between two probability vectors\n        \"\"\"\n        return np.abs(a - b).sum()/2.0\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.time","title":"<code>time: int</code>  <code>property</code>","text":"<p>The current time of the random walk process, i.e. the number of steps taken since the start node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.total_variation_distance","title":"<code>total_variation_distance: float</code>  <code>property</code>","text":"<p>Returns the total variation distance between stationary  visitation probabilities and the current visitation frequencies</p> <p>Computes the total variation distance between the current visitation probabilities and the stationary probabilities. This quantity converges to zero for RandomWalk.t -&gt; np.infty and its magnitude indicates the current relaxation of the random walk process.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_matrix","title":"<code>transition_matrix: sp.sparse.csr_matrix</code>  <code>property</code>","text":"<p>Returns the transition matrix of the random walk</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.visitation_frequencies","title":"<code>visitation_frequencies: np.array</code>  <code>property</code>","text":"<p>Returns current normalized visitation frequencies of nodes based on the history of the random walk. Initially, all visitation probabilities are zero except for the start node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.TVD","title":"<code>TVD</code>  <code>staticmethod</code>","text":"<p>Calculates the total variation distance between two probability vectors</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>@staticmethod\ndef TVD(a: np.array, b: np.array) -&gt; float:\n    \"\"\"Calculates the total variation distance between two probability vectors\n    \"\"\"\n    return np.abs(a - b).sum()/2.0\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.__init__","title":"<code>__init__</code>","text":"<p>Creates a biased random walk process in a network.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.__init__--parameters","title":"Parameters","text":"<p>network: Network     The network instance on which to perform the random walk process. Can also      be an instance of HigherOrderNetwork.</p> Weight = None <p>If specified, the given numerical edge attribute will be used to bias the random walk transition probabilities.</p> float = 0 <p>The per-step probability that a random walker restarts in a random node</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.__init__--see-also","title":"See Also","text":"<p>VoseAliasSampling, HigherOrderRandomWalk, BaseProcess</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def __init__(self, network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n    \"\"\"Creates a biased random walk process in a network.\n\n    Parameters\n    ----------\n    network: Network\n        The network instance on which to perform the random walk process. Can also \n        be an instance of HigherOrderNetwork.\n\n    weight: Weight = None\n        If specified, the given numerical edge attribute will be used to bias\n        the random walk transition probabilities.\n\n    restart_probability: float = 0\n        The per-step probability that a random walker restarts in a random node\n\n    See Also\n    --------\n    VoseAliasSampling, HigherOrderRandomWalk, BaseProcess\n    \"\"\"\n\n    # transition matrix of random walk\n    self._transition_matrix = RandomWalk.compute_transition_matrix(\n        network, weight, restart_prob)\n\n    # initialize Vose Alias Samplers\n\n    self.samplers = {v: VoseAliasSampling(np.nan_to_num(np.ravel(\n        self._transition_matrix[\n            network.mapping.to_idx(v), :].todense()))) for v in network.nodes}\n\n    # compute eigenvectors and eigenvalues of transition matrix\n    if network.N &gt; 2:\n        _, eigenvectors = spl.eigs(\n            self._transition_matrix.transpose(), k=1, which='LM')\n        pi = eigenvectors.reshape(eigenvectors.size, )\n    else:\n        eigenvals, eigenvectors = spla.eig(\n            self._transition_matrix.transpose().toarray())\n        x = np.argsort(-eigenvals)\n        pi = eigenvectors[x][:, 0]\n\n    # calculate stationary visitation probabilities\n    self._stationary_probabilities = np.real(pi/np.sum(pi))\n\n    self._network = network\n    self.init(self.random_seed())\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.compute_transition_matrix","title":"<code>compute_transition_matrix</code>  <code>staticmethod</code>","text":"<p>Returns the transition matrix of a (biased) random walk in the given network.</p> <p>Returns a transition matrix that describes a random walk process in the given network.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.compute_transition_matrix--parameters","title":"Parameters","text":"<p>network: Network</p> <pre><code>The network for which the transition matrix will be created.\n</code></pre> <p>weight: Weight</p> <pre><code>If specified, the numerical edge attribute that shall be used in the biased\ntransition probabilities of the random walk.\n</code></pre> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>@staticmethod\ndef compute_transition_matrix(network: Graph,\n                              weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; sp.sparse.csr_matrix:\n    \"\"\"Returns the transition matrix of a (biased) random walk in the given network.\n\n    Returns a transition matrix that describes a random walk process in the\n    given network.\n\n    Parameters\n    ----------\n    network: Network\n\n        The network for which the transition matrix will be created.\n\n    weight: Weight\n\n        If specified, the numerical edge attribute that shall be used in the biased\n        transition probabilities of the random walk.\n\n    \"\"\"\n    if weight is None or weight is False:\n        A = network.get_sparse_adj_matrix().todense()\n    elif weight is True:\n        A = network.get_sparse_adj_matrix(edge_attr='edge_weight').todense()\n    else:\n        A = network.get_sparse_adj_matrix(edge_attr=weight).todense()\n    D = A.sum(axis=1)\n    n = network.N\n    T = sp.sparse.lil_matrix((n, n))\n    zero_deg = 0\n    for i in range(n):\n        if D[i] == 0:\n            zero_deg += 1\n        for j in range(n):\n            if D[i] &gt; 0:\n                T[i, j] = restart_prob * \\\n                    (1./n) + (1-restart_prob)*A[i, j]/D[i]\n            else:\n                if restart_prob &gt; 0:\n                    T[i, j] = 1./n\n                else:\n                    T[i, j] = 0.0\n    # if zero_deg &gt; 0:\n    #     LOG.warning(\n    #         'Network contains {0} nodes with zero out-degree'.format(zero_deg))\n    return T.tocsr()\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_path","title":"<code>get_path</code>","text":"<p>Returns a path that represents the sequence of (first-order) nodes traversed by a single random walk.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_path--parameters","title":"Parameters","text":"DataFrame <p>Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of <code>run_experiment</code></p> Optional[int]=0 <p>Uid of the random walk simulation to be returns as Path (default: 0).</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_path--returns","title":"Returns","text":"<p>Path     Path object containing the sequence of nodes traversed by the random walk</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_path--see-also","title":"See Also","text":"<p>Path</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_path(self, data: DataFrame, run_id: Optional[int] = 0, first_order: Optional[bool] = True) -&gt; DAGData:\n    \"\"\"Returns a path that represents the sequence of (first-order) nodes traversed\n    by a single random walk.\n\n    Parameters\n    ----------\n\n    data: DataFrame\n        Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n\n    run_uid: Optional[int]=0\n           Uid of the random walk simulation to be returns as Path (default: 0).\n\n    Returns\n    -------\n\n    Path\n        Path object containing the sequence of nodes traversed by the random walk\n\n    See Also\n    --------\n\n    Path\n    \"\"\"\n    # list of traversed nodes starting with seed node\n    walk_steps = list(data.loc[(data['run_id'] == run_id) &amp; (\n        data['state'] == True)]['node'].values)\n\n    # generate Path\n    path = DAGData(self._network.mapping)\n    path.append_walk([walk_steps[i] for i in range(len(walk_steps))])\n    return path\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_paths","title":"<code>get_paths</code>","text":"<p>Returns a DAGData object where each DAG is one walk</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_paths--parameters","title":"Parameters","text":"DataFrame <p>Pandas data frame containing the trajectory of one or more random walks, generated by  <code>run_experiment</code></p> Optional[Iterable]=None <p>Uids of the random walk simulations to be included in the PathCollection instance. If None (default), all random walk simulations will be included.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_paths--returns","title":"Returns","text":"<p>DAGData     DAGData object where each random walk is represented by one dag.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_paths--see-also","title":"See Also","text":"<p>DAGData</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = None) -&gt; DAGData:\n    \"\"\"Returns a DAGData object where each DAG is one walk\n\n    Parameters\n    ----------\n\n    data: DataFrame\n        Pandas data frame containing the trajectory of one or more random walks, generated by \n        `run_experiment`\n\n    run_ids: Optional[Iterable]=None\n        Uids of the random walk simulations to be included in the PathCollection instance. If None (default), all random walk simulations will be included.\n\n    Returns\n    -------\n\n    DAGData\n        DAGData object where each random walk is represented by one dag.\n\n    See Also\n    --------\n\n    DAGData\n    \"\"\"\n\n    if not run_ids:  # generate paths for all run_ids in the data frame\n        runs = data['run_id'].unique()\n    else:\n        runs = run_ids\n\n    walks = DAGData(self._network.mapping)\n    for id in runs:\n        walk_steps = list(data.loc[(data['run_id'] == id) &amp; (\n        data['state'] == True)]['node'].values)\n\n        # add walk to DAGData\n        walks.append_walk(walk_steps)\n\n    return walks\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.init","title":"<code>init</code>","text":"<p>Initializes the random walk state with a given seed/source node</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.init--parameters","title":"Parameters","text":"<p>seed: Union[int, str]</p> <pre><code>Id of node in which the random walk will start\n</code></pre> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def init(self, seed: str) -&gt; None:\n    \"\"\"\n    Initializes the random walk state with a given seed/source node\n\n    Parameters\n    ----------\n\n    seed: Union[int, str]\n\n        Id of node in which the random walk will start\n    \"\"\"\n    # reset currently visited node (or higher-order node)\n    self._current_node = seed\n\n    # set time\n    self._t = 0\n\n    # set number of times each node has been visited\n    self._visitations = np.ravel(\n        np.zeros(shape=(1, self._network.N)))\n    self._visitations[self._network.mapping.to_idx(seed)] = 1\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.node_state","title":"<code>node_state</code>","text":"<p>Returns a boolean variable indicating whether the walker is currently  visiting (first-order) node v</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def node_state(self, v) -&gt; bool:\n    \"\"\"\n    Returns a boolean variable indicating whether the walker is currently \n    visiting (first-order) node v\n    \"\"\"\n    if v in self._network.nodes:\n        return v == self._current_node\n    elif type(self._network) == HigherOrderGraph:\n        return v == self._network.mapping.to_id(self._current_node)[-1]\n    else:\n        raise NotImplementedError(\n            'Random walk not implemented for network of type {0}'.format(type(self._network)))\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.random_seed","title":"<code>random_seed</code>","text":"<p>Returns a random node from the network, chosen uniformly at random</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def random_seed(self) -&gt; Any:\n    \"\"\"\n    Returns a random node from the network, chosen uniformly at random\n    \"\"\"\n    x = np.random.choice(range(self._network.N))\n    return self._network.mapping.to_id(x)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.state_to_color","title":"<code>state_to_color</code>","text":"<p>Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.state_to_color--parameters","title":"Parameters","text":"<p>state: bool</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def state_to_color(self, state: bool) -&gt; str:\n    \"\"\"\n    Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.\n\n    Parameters\n    ----------\n\n    state: bool\n    \"\"\"\n    if state:\n        return 'red'\n    else:\n        return 'blue'\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.stationary_state","title":"<code>stationary_state</code>","text":"<p>Computes stationary visitation probabilities.</p> <p>Computes stationary visitation probabilities of nodes based on the leading eigenvector of the transition matrix.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.stationary_state--parameters","title":"Parameters","text":"<p>**kwargs: Any</p> <pre><code>Arbitrary key-value pairs to bee passed to the\nscipy.sparse.linalg.eigs function.\n</code></pre> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def stationary_state(self, **kwargs: Any) -&gt; np.array:\n    \"\"\"Computes stationary visitation probabilities.\n\n    Computes stationary visitation probabilities of nodes based on the\n    leading eigenvector of the transition matrix.\n\n    Parameters\n    ----------\n\n    **kwargs: Any\n\n        Arbitrary key-value pairs to bee passed to the\n        scipy.sparse.linalg.eigs function.\n    \"\"\"\n    _p = self._stationary_probabilities\n    if kwargs:\n        _, eigenvectors = sp.sparse.linalg.eigs(\n            self._transition_matrix.transpose(), k=1, which='LM', **kwargs)\n        pi = eigenvectors.reshape(eigenvectors.size, )\n        _p = np.real(pi/np.sum(pi))\n    return _p\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.step","title":"<code>step</code>","text":"<p>Function that will be called for each step of the random walk. This function  returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def step(self) -&gt; Iterable[str]:\n    \"\"\"\n    Function that will be called for each step of the random walk. This function \n    returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.\n    \"\"\"\n\n    # determine next node\n    next_node = self.network.mapping.to_id(self.samplers[self._current_node].sample(\n    ))\n    # TODO: assertion will not hold if restart_prob &gt; 0\n    # assert (self._current_node, next_node) in self._network.edges, 'Assertion Error: {0} not in edge list'.format(\n    #     (self._current_node, next_node))\n\n    previous_node = self._current_node\n    self._current_node = next_node\n\n    # increment visitations and current time\n    self._visitations[self._network.mapping.to_idx(self._current_node)] += 1\n    self._t += 1\n\n    # return tuple of changed nodes, where the first node is the currently visited node\n    return (self._current_node, previous_node)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_matrix_pd","title":"<code>transition_matrix_pd</code>","text":"<p>Returns the transition matrix as pandas DataFrame with proper row/column labels.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def transition_matrix_pd(self) -&gt; DataFrame:\n    \"\"\"\n    Returns the transition matrix as pandas DataFrame with proper row/column labels.\n    \"\"\"\n    return DataFrame(self.transition_matrix.todense(), columns=[v for v in self._network.nodes], index=[v for v in self._network.nodes])\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Returns a vector that contains transition probabilities.</p> <p>Returns a vector that contains transition probabilities from a given node to all other nodes in the network.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def transition_probabilities(self, node: str) -&gt; np.array:\n    \"\"\"Returns a vector that contains transition probabilities.\n\n    Returns a vector that contains transition probabilities from a given\n    node to all other nodes in the network.\n\n    \"\"\"\n    return np.nan_to_num(np.ravel(\n        self._transition_matrix[\n            self._network.nodes.to_idx(node), :].todense()))\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.visitation_probabilities","title":"<code>visitation_probabilities</code>","text":"<p>Calculates visitation probabilities of nodes after t steps for a given start node</p> <p>Initially, all visitation probabilities are zero except for the start node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def visitation_probabilities(self, t, seed: str) -&gt; np.ndarray:\n    \"\"\"Calculates visitation probabilities of nodes after t steps for a given start node\n\n    Initially, all visitation probabilities are zero except for the start node.\n    \"\"\"\n    assert seed in self._network.nodes\n\n    initial_dist = np.zeros(self._network.N)\n    initial_dist[self._network.mapping.to_idx(seed)] = 1.0\n    return np.dot(initial_dist, (self._transition_matrix**t).todense())\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/","title":"sampling","text":"<p>Classes for efficient random sampling from discrete distributions</p>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling","title":"<code>VoseAliasSampling</code>","text":"<p>Implementation of fast biased sampling of discrete values [0, ..., n]</p> <p>For a concise explanation see https://www.keithschwarz.com/darts-dice-coins/</p>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling--parameters","title":"Parameters","text":"<p>weights: Union[np.array, list]</p> <pre><code>relative weights of the n events, where weights[i] is the relative \nstatistical weight of event i. The weights do not need to be \nnormalized.\n\nFor an array with length n, generated random values \nwill be from range(n).\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling--see-also","title":"See Also","text":"<p>RandomWalk</p>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling--examples","title":"Examples","text":"<p>Create a VoseAliasSampling instance</p> <p>from pathpy.processes import VoseAliasSampling sampler = VoseAliasSampling([1,1,2])</p> <p>Fast biased sampling in O(1)</p> <p>[ sampler.sample() for i in range(10) ] [ 0 2 0 1 2 1 2 1 2 0 2 2 ]</p> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>class VoseAliasSampling:\n    \"\"\"\n    Implementation of fast biased sampling of discrete values [0, ..., n]\n\n    For a concise explanation see https://www.keithschwarz.com/darts-dice-coins/\n\n    Parameters\n    ----------\n\n    weights: Union[np.array, list]\n\n        relative weights of the n events, where weights[i] is the relative \n        statistical weight of event i. The weights do not need to be \n        normalized. \n\n        For an array with length n, generated random values \n        will be from range(n).\n\n    See Also\n    --------\n    RandomWalk\n\n    Examples\n    --------\n\n    Create a VoseAliasSampling instance\n\n    &gt;&gt;&gt; from pathpy.processes import VoseAliasSampling\n    &gt;&gt;&gt; sampler = VoseAliasSampling([1,1,2])\n\n    Fast biased sampling in O(1)\n\n    &gt;&gt;&gt; [ sampler.sample() for i in range(10) ]\n    [ 0 2 0 1 2 1 2 1 2 0 2 2 ] \n\n    \"\"\"\n\n    def __init__(self, weights: Union[np.array, list]) -&gt; None:\n        \"\"\"\n        Initializes probability and alias tables\n        \"\"\"\n        self.n = len(weights)\n        self.probs = dict()\n        self.scaled_probs = dict()\n        self.aliases = dict()\n\n        small = list()\n        large = list()\n\n        for i in range(1, self.n+1):\n            self.probs[i] = weights[i-1]\n            self.scaled_probs[i] = self.n*weights[i-1]\n            if self.scaled_probs[i]&gt;1:\n                large.append(i)\n            elif self.scaled_probs[i]&lt;=1:\n                small.append(i)\n\n        while small and large:\n            l = small.pop()\n            g = large.pop()\n\n            self.probs[l] = self.scaled_probs[l]\n            self.aliases[l] = g\n            self.scaled_probs[g] = self.scaled_probs[l] + self.scaled_probs[g] -1\n\n            if self.scaled_probs[g] &lt; 1:\n                small.append(g)\n            else:\n                large.append(g)\n        while large:\n            g = large.pop()\n            self.probs[g] = 1\n        while small:\n            l = small.pop()\n            self.probs[l] = 1\n\n    def sample(self) -&gt; int:\n        \"\"\"\n        Biased sampling of discrete value in O(1)\n\n        Returns\n        -------\n            integer value from range(n), where n is the length \n            of the weight array used to create the instance.\n\n        \"\"\"\n        i = np.random.randint(1, self.n+1)\n        x = np.random.rand()\n        if x &lt; self.probs[i]:\n            return i-1\n        else:\n            return self.aliases[i]-1\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling.__init__","title":"<code>__init__</code>","text":"<p>Initializes probability and alias tables</p> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>def __init__(self, weights: Union[np.array, list]) -&gt; None:\n    \"\"\"\n    Initializes probability and alias tables\n    \"\"\"\n    self.n = len(weights)\n    self.probs = dict()\n    self.scaled_probs = dict()\n    self.aliases = dict()\n\n    small = list()\n    large = list()\n\n    for i in range(1, self.n+1):\n        self.probs[i] = weights[i-1]\n        self.scaled_probs[i] = self.n*weights[i-1]\n        if self.scaled_probs[i]&gt;1:\n            large.append(i)\n        elif self.scaled_probs[i]&lt;=1:\n            small.append(i)\n\n    while small and large:\n        l = small.pop()\n        g = large.pop()\n\n        self.probs[l] = self.scaled_probs[l]\n        self.aliases[l] = g\n        self.scaled_probs[g] = self.scaled_probs[l] + self.scaled_probs[g] -1\n\n        if self.scaled_probs[g] &lt; 1:\n            small.append(g)\n        else:\n            large.append(g)\n    while large:\n        g = large.pop()\n        self.probs[g] = 1\n    while small:\n        l = small.pop()\n        self.probs[l] = 1\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling.sample","title":"<code>sample</code>","text":"<p>Biased sampling of discrete value in O(1)</p>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling.sample--returns","title":"Returns","text":"<pre><code>integer value from range(n), where n is the length \nof the weight array used to create the instance.\n</code></pre> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>def sample(self) -&gt; int:\n    \"\"\"\n    Biased sampling of discrete value in O(1)\n\n    Returns\n    -------\n        integer value from range(n), where n is the length \n        of the weight array used to create the instance.\n\n    \"\"\"\n    i = np.random.randint(1, self.n+1)\n    x = np.random.rand()\n    if x &lt; self.probs[i]:\n        return i-1\n    else:\n        return self.aliases[i]-1\n</code></pre>"},{"location":"reference/pathpyG/utils/","title":"utils","text":""},{"location":"reference/pathpyG/utils/config/","title":"config","text":""},{"location":"reference/pathpyG/utils/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/utils/dbgnn/#pathpyG.utils.dbgnn.generate_bipartite_edge_index","title":"<code>generate_bipartite_edge_index</code>","text":"<p>Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.</p> Source code in <code>src/pathpyG/utils/dbgnn.py</code> <pre><code>def generate_bipartite_edge_index(g: Graph, g2: Graph, mapping: str = 'last') -&gt; torch.Tensor:\n    \"\"\"Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.\"\"\"\n\n    if mapping == 'last':\n        bipartide_edge_index = torch.tensor(\n            [list(range(g2.N)), [v[1] for v in g2.data.node_sequence]]\n            )\n\n    elif mapping == 'first':\n        bipartide_edge_index = torch.tensor(\n            [list(range(g2.N)), [v[0] for v in g2.data.node_sequence]]\n        )\n    else:\n        bipartide_edge_index = torch.tensor(\n            [list(range(g2.N)) + list(range(g2.N)),\n            [v[0] for v in g2.data.node_sequence] + [v[1] for v in g2.data.node_sequence]]\n        )\n\n    return bipartide_edge_index\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/","title":"progress","text":"<p>Progressbar for pathpy.</p>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_console","title":"<code>tqdm_console</code>","text":"<p>Progressbar for a console environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_console(*args, **kwargs):\n    \"\"\"Progressbar for a console environment.\"\"\"\n    if len(args[0]) &gt; config['progress']['min_iter']:\n        return tq(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_disabled","title":"<code>tqdm_disabled</code>","text":"<p>Disable the progress bar and return initial iterator.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_disabled(it, *args, **kwargs):\n    \"\"\"Disable the progress bar and return initial iterator.\"\"\"\n    return it\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_notebook","title":"<code>tqdm_notebook</code>","text":"<p>Progressbar for a notebook environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_notebook(*args, **kwargs):\n    \"\"\"Progressbar for a notebook environment.\"\"\"\n    if len(args[0]) &gt; config['progress']['min_iter']:\n        return tqn(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/visualisations/","title":"visualisations","text":"<p>PathpyG visualizations.</p>"},{"location":"reference/pathpyG/visualisations/hist_plots/","title":"hist_plots","text":"<p>Histogram plot classes.</p>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.HistogramPlot","title":"<code>HistogramPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Histogram plot class for a network property.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>class HistogramPlot(PathPyPlot):\n    \"\"\"Histogram plot class for a network property.\"\"\"\n\n    _kind = \"hist\"\n\n    def __init__(\n        self, network: Graph, key: str = \"indegrees\", bins: int = 10, **kwargs: Any\n    ) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.config[\"bins\"] = bins\n        self.config[\"key\"] = key\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n\n        data: dict = {}\n\n        match self.config[\"key\"]:\n            case \"indegrees\":\n                logger.debug(\"Generate data for in-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n            case \"outdegrees\":\n                logger.debug(\"Generate data for out-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n            case _:\n                logger.error(\n                    f\"The &lt;{self.config['key']}&gt; property\",\n                    \"is currently not supported for hist plots.\",\n                )\n                raise KeyError\n\n        data[\"title\"] = self.config[\"key\"]\n        self.data[\"data\"] = data\n</code></pre>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.HistogramPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>def __init__(\n    self, network: Graph, key: str = \"indegrees\", bins: int = 10, **kwargs: Any\n) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.network = network\n    self.config = kwargs\n    self.config[\"bins\"] = bins\n    self.config[\"key\"] = key\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.HistogramPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    logger.debug(\"Generate histogram.\")\n\n    data: dict = {}\n\n    match self.config[\"key\"]:\n        case \"indegrees\":\n            logger.debug(\"Generate data for in-degrees\")\n            data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n        case \"outdegrees\":\n            logger.debug(\"Generate data for out-degrees\")\n            data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n        case _:\n            logger.error(\n                f\"The &lt;{self.config['key']}&gt; property\",\n                \"is currently not supported for hist plots.\",\n            )\n            raise KeyError\n\n    data[\"title\"] = self.config[\"key\"]\n    self.data[\"data\"] = data\n</code></pre>"},{"location":"reference/pathpyG/visualisations/hist_plots/#pathpyG.visualisations.hist_plots.hist","title":"<code>hist</code>","text":"<p>Plot a histogram.</p> Source code in <code>src/pathpyG/visualisations/hist_plots.py</code> <pre><code>def hist(\n    network: Graph, key: str = \"indegrees\", bins: int = 10, **kwargs: Any\n) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/","title":"layout","text":""},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout","title":"<code>Layout</code>","text":"<p>               Bases: <code>object</code></p> <p>Default class to create layouts</p> <p>The <code>Layout</code> class is used to generate node a layout drawer and return the calculated node positions as a dictionary, where the keywords represents the node ids and the values represents a two dimensional tuple with the x and y coordinates for the associated nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>list with node ids. The list contain a list of unique node ids.</p> required <code>**attr</code> <code>dict</code> <p>Attributes to add to node as key=value pairs. See also <code>layout</code></p> <code>{}</code> See also <p><code>layout</code></p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>class Layout(object):\n    \"\"\"Default class to create layouts\n\n    The [`Layout`][pathpyG.visualisations.layout.Layout] class is used to generate node a layout drawer and\n    return the calculated node positions as a dictionary, where the keywords\n    represents the node ids and the values represents a two dimensional tuple\n    with the x and y coordinates for the associated nodes.\n\n    Args:\n        nodes (list): list with node ids.\n            The list contain a list of unique node ids.\n        **attr (dict): Attributes to add to node as key=value pairs.\n            See also [`layout`][pathpyG.visualisations.layout.layout]\n\n    Note: See also\n        [`layout`][pathpyG.visualisations.layout.layout]\n    \"\"\"\n\n    def __init__(self, nodes, adjacency_matrix, **attr):\n        \"\"\"Initialize the Layout class\n\n        The [`Layout`][pathpyG.visualisations.layout.Layout] class is used to generate node a layout drawer and\n        return the calculated node positions as a dictionary, where the keywords\n        represents the node ids and the values represents a two dimensional tuple\n        with the x and y coordinates for the associated nodes.\n\n        Args:\n            nodes (list): list with node ids.\n                The list contain a list of unique node ids.\n            **attr (dict): Attributes to add to node as key=value pairs.\n                See also [`layout`][pathpyG.visualisations.layout.layout]\n        \"\"\"\n\n        # initialize variables\n        self.nodes = nodes\n        self.adjacency_matrix = adjacency_matrix\n\n        # rename the attributes\n        attr = self.rename_attributes(**attr)\n\n        # options for the layouts\n        self.layout_type = attr.get('layout', None)\n        self.k = attr.get('force', None,)\n        self.fixed = attr.get('fixed', None)\n        self.iterations = attr.get('iterations', 50)\n        self.threshold = attr.get('threshold', 1e-4)\n        self.weight = attr.get('weight', None)\n        self.dimension = attr.get('dimension', 2)\n        self.seed = attr.get('seed', None)\n        self.positions = attr.get('positions', None)\n        self.radius = attr.get('radius', 1.0)\n        self.direction = attr.get('direction', 1.0)\n        self.start_angle = attr.get('start_angle', 0.0)\n\n        # TODO: allow also higher dimensional layouts\n        if self.dimension &gt; 2:\n            print('Currently only plots with maximum dimension 2 are supported!')\n            self.dimension = 2\n\n    @staticmethod\n    def rename_attributes(**kwds):\n        \"\"\"Rename layout attributes.\n\n        In the style dictionary multiple keywords can be used to address\n        attributes. These keywords will be converted to an unique key word,\n        used in the remaining code.\n\n        | keys | other valid keys |\n        | ---- | ---------------- |\n        | fixed | `fixed_nodes`, `fixed_vertices`, `fixed_n`, `fixed_v` |\n        | positions | `initial_positions`, `node_positions` `vertex_positions`, `n_positions`, `v_positions` |\n        \"\"\"\n        names = {'fixed': ['fixed_nodes', 'fixed_vertices',\n                           'fixed_v', 'fixed_n'],\n                 'positions': ['initial_positions', 'node_positions',\n                               'vertex_positions', 'n_positions',\n                               'v_positions'],\n                 'layout_': ['layout_'],\n                 }\n\n        _kwds = {}\n        del_keys = []\n        for key, value in kwds.items():\n            for attr, name_list in names.items():\n                for name in name_list:\n                    if name in key and name[0] == key[0]:\n                        _kwds[key.replace(name, attr).replace(\n                            'layout_', '')] = value\n                        del_keys.append(key)\n                        break\n        # remove the replaced keys from the dict\n        for key in del_keys:\n            del kwds[key]\n\n        return {**_kwds, **kwds}\n\n    def generate_layout(self):\n        \"\"\"Function to pick and generate the right layout.\"\"\"\n        # method names\n        names_rand = ['Random', 'random', 'rand', None]\n        names_fr = ['Fruchterman-Reingold', 'fruchterman_reingold', 'fr',\n                    'spring_layout', 'spring layout', 'FR']\n        names_circular = ['circular', 'circle', 'ring', '1d-lattice', 'lattice-1d']\n        names_grid = ['grid', '2d-lattice', 'lattice-2d']\n        # check which layout should be plotted\n        if self.layout_type in names_rand:\n            self.layout = self.random()\n        elif self.layout_type in names_circular or (self.layout_type == 'lattice' and self.dimension == 1):\n            self.layout = self.circular()\n        elif self.layout_type in names_grid or (self.layout_type == 'lattice' and self.dimension == 2):\n            self.layout = self.grid()\n        elif self.layout_type in names_fr:\n            self.layout = self.fruchterman_reingold()\n\n        # print(self.layout)\n        return self.layout\n\n    def random(self):\n        \"\"\"Position nodes uniformly at random in the unit square.\n\n        For every node, a position is generated by choosing each of dimension\n        coordinates uniformly at random on the interval $[0.0, 1.0)$.\n\n        This algorithm can be enabled with the keywords: `Random`,\n        `random`, `rand`, or `None`\n\n        Keyword Args:\n            dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n            seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n                the seed used by the random number generator, if None, the a random\n                seed by created by the numpy random number generator is used.\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n        np.random.seed(self.seed)\n        layout = np.random.rand(len(self.nodes), self.dimension)\n        return dict(zip(self.nodes, layout))\n\n    def fruchterman_reingold(self):\n        \"\"\"Position nodes using Fruchterman-Reingold force-directed algorithm.\n\n        In this algorithm, the nodes are represented by steel rings and the\n        edges are springs between them. The attractive force is analogous to the\n        spring force and the repulsive force is analogous to the electrical\n        force. The basic idea is to minimize the energy of the system by moving\n        the nodes and changing the forces between them.\n\n        This algorithm can be enabled with the keywords: `Fruchterman-Reingold`,\n        `fruchterman_reingold`, `fr`, `spring_layout`, `spring layout`, `FR`\n\n        Keyword Args:\n            force (float): Optimal distance between nodes. If None the distance is set to\n                1/sqrt(n) where n is the number of nodes.  Increase this value to move\n                nodes farther apart.\n            positions (dict): Initial positions for nodes as a dictionary with node as keys and values\n                as a coordinate list or tuple.  If None, then use random initial\n                positions.\n            fixed (list): Nodes to keep fixed at initial position.\n            iterations (int): Maximum number of iterations taken. Defaults to 50.\n            threshold (float): Threshold for relative error in node position changes.  The iteration\n                stops if the error is below this threshold. Defaults to 1e-4.\n            weight (string): The edge attribute that holds the numerical value used for the edge\n                weight.  If None, then all edge weights are 1.\n            dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n            seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n                the seed used by the random number generator, if None, the a random seed\n                by created by the numpy random number generator is used.\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n\n        # convert adjacency matrix\n        self.adjacency_matrix = self.adjacency_matrix.astype(float)\n\n        if self.fixed is not None:\n            self.fixed = np.asarray([self.nodes.index(v) for v in self.fixed])\n\n        if self.positions is not None:\n            # Determine size of existing domain to adjust initial positions\n            _size = max(coord for t in layout.values() for coord in t) # type: ignore\n            if _size == 0:\n                _size = 1\n            np.random.seed(self.seed)\n            self.layout = np.random.rand(\n                len(self.nodes), self.dimension) * _size # type: ignore\n\n            for i, n in enumerate(self.nodes):\n                if n in self.positions:\n                    self.layout[i] = np.asarray(self.positions[n])\n        else:\n            self.layout = None\n            _size = 0\n\n        if self.k is None and self.fixed is not None:\n            # We must adjust k by domain size for layouts not near 1x1\n            self.k = _size / np.sqrt(len(self.nodes))\n\n        try:\n            # Sparse matrix\n            if len(self.nodes) &lt; 500:  # sparse solver for large graphs\n                raise ValueError\n            layout = self._sparse_fruchterman_reingold()\n        except:\n            layout = self._fruchterman_reingold()\n\n        layout = dict(zip(self.nodes, layout))\n\n        return layout\n\n    def _fruchterman_reingold(self):\n        \"\"\"Fruchterman-Reingold algorithm for dense matrices.\n\n        This algorithm is based on the Fruchterman-Reingold algorithm provided\n        by `networkx`. (Copyright (C) 2004-2018 by Aric Hagberg &lt;hagberg@lanl.gov&gt;\n        Dan Schult &lt;dschult@colgate.edu&gt; Pieter Swart &lt;swart@lanl.gov&gt; Richard\n        Penney &lt;rwpenney@users.sourceforge.net&gt; All rights reserved. BSD\n        license.)\n\n        \"\"\"\n        A = self.adjacency_matrix.todense()\n        k = self.k\n        try:\n            _n, _ = A.shape\n        except AttributeError:\n            print('Fruchterman-Reingold algorithm needs an adjacency matrix as input')\n            raise AttributeError\n\n        # make sure we have an array instead of a matrix\n        A = np.asarray(A)\n\n        if self.layout is None:\n            # random initial positions\n            np.random.seed(self.seed)\n            layout = np.asarray(np.random.rand(\n                _n, self.dimension), dtype=A.dtype)\n        else:\n            # make sure positions are of same type as matrix\n            layout = self.layout.astype(A.dtype) # type: ignore\n\n        # optimal distance between nodes\n        if k is None:\n            k = np.sqrt(1.0 / _n)\n        # the initial \"temperature\"  is about .1 of domain area (=1x1)\n        # this is the largest step allowed in the dynamics.\n        # We need to calculate this in case our fixed positions force our domain\n        # to be much bigger than 1x1\n        t = max(max(layout.T[0]) - min(layout.T[0]),\n                max(layout.T[1]) - min(layout.T[1])) * 0.1\n        # simple cooling scheme.\n        # linearly step down by dt on each iteration so last iteration is size dt.\n        dt = t / float(self.iterations + 1)\n        delta = np.zeros(\n            (layout.shape[0], layout.shape[0], layout.shape[1]), dtype=A.dtype)\n        # the inscrutable (but fast) version\n        # this is still O(V^2)\n        # could use multilevel methods to speed this up significantly\n        for iteration in tqdm(range(self.iterations), desc='Calculating Fruchterman-Reingold layout'):\n            # matrix of difference between points\n            delta = layout[:, np.newaxis, :] - layout[np.newaxis, :, :] # type: ignore\n            # distance between points\n            distance = np.linalg.norm(delta, axis=-1)\n            # enforce minimum distance of 0.01\n            np.clip(distance, 0.01, None, out=distance)\n            # displacement \"force\"\n            displacement = np.einsum('ijk,ij-&gt;ik',\n                                     delta,\n                                     (k * k / distance**2 - A * distance / k))\n            # update layoutitions\n            length = np.linalg.norm(displacement, axis=-1)\n            length = np.where(length &lt; 0.01, 0.1, length)\n            delta_layout = np.einsum('ij,i-&gt;ij', displacement, t / length)\n            if self.fixed is not None:\n                # don't change positions of fixed nodes\n                delta_layout[self.fixed] = 0.0\n            layout += delta_layout\n            # cool temperature\n            t -= dt\n            error = np.linalg.norm(delta_layout) / _n\n            if error &lt; self.threshold:\n                break\n        return layout\n\n    def _sparse_fruchterman_reingold(self):\n        \"\"\"Fruchterman-Reingold algorithm for sparse matrices.\n\n        This algorithm is based on the Fruchterman-Reingold algorithm provided\n        by networkx. (Copyright (C) 2004-2018 by Aric Hagberg &lt;hagberg@lanl.gov&gt;\n        Dan Schult &lt;dschult@colgate.edu&gt; Pieter Swart &lt;swart@lanl.gov&gt; Richard\n        Penney &lt;rwpenney@users.sourceforge.net&gt; All rights reserved. BSD\n        license.)\n\n        \"\"\"\n        A = self.adjacency_matrix\n        k = self.k\n        try:\n            _n, _ = A.shape\n        except AttributeError:\n            print('Fruchterman-Reingold algorithm needs an adjacency '\n                      'matrix as input')\n            raise AttributeError\n        try:\n            from scipy.sparse import spdiags, coo_matrix\n        except ImportError:\n            print('The sparse Fruchterman-Reingold algorithm needs the '\n                      'scipy package: http://scipy.org/')\n            raise ImportError\n        # make sure we have a LIst of Lists representation\n        try:\n            A = A.tolil()\n        except:\n            A = (coo_matrix(A)).tolil()\n\n        if self.layout is None:\n            # random initial positions\n            np.random.seed(self.seed)\n            layout = np.asarray(np.random.rand(\n                _n, self.dimension), dtype=A.dtype)\n        else:\n            # make sure positions are of same type as matrix\n            layout = layout.astype(A.dtype) # type: ignore\n\n        # no fixed nodes\n        if self.fixed is None:\n            self.fixed = []\n\n        # optimal distance between nodes\n        if k is None:\n            k = np.sqrt(1.0 / _n)\n        # the initial \"temperature\"  is about .1 of domain area (=1x1)\n        # this is the largest step allowed in the dynamics.\n        t = max(max(layout.T[0]) - min(layout.T[0]),\n                max(layout.T[1]) - min(layout.T[1])) * 0.1\n        # simple cooling scheme.\n        # linearly step down by dt on each iteration so last iteration is size dt.\n        dt = t / float(self.iterations + 1)\n\n        displacement = np.zeros((self.dimension, _n))\n        for iteration in range(self.iterations):\n            displacement *= 0\n            # loop over rows\n            for i in range(A.shape[0]):\n                if i in self.fixed:\n                    continue\n                # difference between this row's node position and all others\n                delta = (layout[i] - layout).T\n                # distance between points\n                distance = np.sqrt((delta**2).sum(axis=0))\n                # enforce minimum distance of 0.01\n                distance = np.where(distance &lt; 0.01, 0.01, distance)\n                # the adjacency matrix row\n                Ai = np.asarray(A.getrowview(i).toarray())\n                # displacement \"force\"\n                displacement[:, i] +=\\\n                    (delta * (k * k / distance**2 - Ai * distance / k)).sum(axis=1)\n            # update positions\n            length = np.sqrt((displacement**2).sum(axis=0))\n            length = np.where(length &lt; 0.01, 0.1, length)\n            delta_layout = (displacement * t / length).T\n            layout += delta_layout\n            # cool temperature\n            t -= dt\n            err = np.linalg.norm(delta_layout) / _n\n            if err &lt; self.threshold:\n                break\n        return layout\n\n\n    def circular(self):\n        \"\"\"Position nodes on a circle with given radius.\n\n        This algorithm can be enabled with the keywords: `circular`, `circle`, `ring`, `lattice-1d`, `1d-lattice`, `lattice`\n\n        Keyword Args:\n            radius (float): Sets the radius of the circle on which nodes\n                are positioned. Defaults to 1.0.\n            direction (float): Sets the direction in which nodes are placed on the circle. 1.0 for clockwise (default)\n                and -1.0 for counter-clockwise direction. Defaults to 1.0.\n            start_angle (float): Sets the angle of the first node relative to the 3pm position on a clock.\n                and -1.0 for counter-clockwise direction. Defaults to 90.0.\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n\n        n = len(self.nodes)\n        rad = 2.0 * np.pi / n\n        rotation = (90.0 - self.start_angle*self.direction) * np.pi / 180.0\n        layout = {}\n\n        for i in range(n):\n            x = self.radius * np.cos(rotation - i*rad*self.direction)\n            y = self.radius * np.sin(rotation - i*rad*self.direction)\n            layout[self.nodes[i]] = (x,y)\n\n        return layout\n\n\n    def grid(self):\n        \"\"\"Position nodes on a two-dimensional grid\n\n        This algorithm can be enabled with the keywords: `grid`, `lattice-2d`, `2d-lattice`, `lattice`\n\n        Returns:\n            layout (dict): A dictionary of positions keyed by node\n        \"\"\"\n\n        n = len(self.nodes)\n        width = 1.0\n\n        # number of nodes in horizontal/vertical direction\n        k = np.floor(np.sqrt(n))\n        dist = width / k\n        layout = {}\n\n        i = 0\n        for i in range(n):\n            layout[self.nodes[i]] = ((i%k) *dist, -(np.floor(i/k))*dist)\n            i += 1\n\n        return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.__init__","title":"<code>__init__</code>","text":"<p>Initialize the Layout class</p> <p>The <code>Layout</code> class is used to generate node a layout drawer and return the calculated node positions as a dictionary, where the keywords represents the node ids and the values represents a two dimensional tuple with the x and y coordinates for the associated nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>list with node ids. The list contain a list of unique node ids.</p> required <code>**attr</code> <code>dict</code> <p>Attributes to add to node as key=value pairs. See also <code>layout</code></p> <code>{}</code> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def __init__(self, nodes, adjacency_matrix, **attr):\n    \"\"\"Initialize the Layout class\n\n    The [`Layout`][pathpyG.visualisations.layout.Layout] class is used to generate node a layout drawer and\n    return the calculated node positions as a dictionary, where the keywords\n    represents the node ids and the values represents a two dimensional tuple\n    with the x and y coordinates for the associated nodes.\n\n    Args:\n        nodes (list): list with node ids.\n            The list contain a list of unique node ids.\n        **attr (dict): Attributes to add to node as key=value pairs.\n            See also [`layout`][pathpyG.visualisations.layout.layout]\n    \"\"\"\n\n    # initialize variables\n    self.nodes = nodes\n    self.adjacency_matrix = adjacency_matrix\n\n    # rename the attributes\n    attr = self.rename_attributes(**attr)\n\n    # options for the layouts\n    self.layout_type = attr.get('layout', None)\n    self.k = attr.get('force', None,)\n    self.fixed = attr.get('fixed', None)\n    self.iterations = attr.get('iterations', 50)\n    self.threshold = attr.get('threshold', 1e-4)\n    self.weight = attr.get('weight', None)\n    self.dimension = attr.get('dimension', 2)\n    self.seed = attr.get('seed', None)\n    self.positions = attr.get('positions', None)\n    self.radius = attr.get('radius', 1.0)\n    self.direction = attr.get('direction', 1.0)\n    self.start_angle = attr.get('start_angle', 0.0)\n\n    # TODO: allow also higher dimensional layouts\n    if self.dimension &gt; 2:\n        print('Currently only plots with maximum dimension 2 are supported!')\n        self.dimension = 2\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.circular","title":"<code>circular</code>","text":"<p>Position nodes on a circle with given radius.</p> <p>This algorithm can be enabled with the keywords: <code>circular</code>, <code>circle</code>, <code>ring</code>, <code>lattice-1d</code>, <code>1d-lattice</code>, <code>lattice</code></p> <p>Other Parameters:</p> Name Type Description <code>radius</code> <code>float</code> <p>Sets the radius of the circle on which nodes are positioned. Defaults to 1.0.</p> <code>direction</code> <code>float</code> <p>Sets the direction in which nodes are placed on the circle. 1.0 for clockwise (default) and -1.0 for counter-clockwise direction. Defaults to 1.0.</p> <code>start_angle</code> <code>float</code> <p>Sets the angle of the first node relative to the 3pm position on a clock. and -1.0 for counter-clockwise direction. Defaults to 90.0.</p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def circular(self):\n    \"\"\"Position nodes on a circle with given radius.\n\n    This algorithm can be enabled with the keywords: `circular`, `circle`, `ring`, `lattice-1d`, `1d-lattice`, `lattice`\n\n    Keyword Args:\n        radius (float): Sets the radius of the circle on which nodes\n            are positioned. Defaults to 1.0.\n        direction (float): Sets the direction in which nodes are placed on the circle. 1.0 for clockwise (default)\n            and -1.0 for counter-clockwise direction. Defaults to 1.0.\n        start_angle (float): Sets the angle of the first node relative to the 3pm position on a clock.\n            and -1.0 for counter-clockwise direction. Defaults to 90.0.\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n\n    n = len(self.nodes)\n    rad = 2.0 * np.pi / n\n    rotation = (90.0 - self.start_angle*self.direction) * np.pi / 180.0\n    layout = {}\n\n    for i in range(n):\n        x = self.radius * np.cos(rotation - i*rad*self.direction)\n        y = self.radius * np.sin(rotation - i*rad*self.direction)\n        layout[self.nodes[i]] = (x,y)\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.fruchterman_reingold","title":"<code>fruchterman_reingold</code>","text":"<p>Position nodes using Fruchterman-Reingold force-directed algorithm.</p> <p>In this algorithm, the nodes are represented by steel rings and the edges are springs between them. The attractive force is analogous to the spring force and the repulsive force is analogous to the electrical force. The basic idea is to minimize the energy of the system by moving the nodes and changing the forces between them.</p> <p>This algorithm can be enabled with the keywords: <code>Fruchterman-Reingold</code>, <code>fruchterman_reingold</code>, <code>fr</code>, <code>spring_layout</code>, <code>spring layout</code>, <code>FR</code></p> <p>Other Parameters:</p> Name Type Description <code>force</code> <code>float</code> <p>Optimal distance between nodes. If None the distance is set to 1/sqrt(n) where n is the number of nodes.  Increase this value to move nodes farther apart.</p> <code>positions</code> <code>dict</code> <p>Initial positions for nodes as a dictionary with node as keys and values as a coordinate list or tuple.  If None, then use random initial positions.</p> <code>fixed</code> <code>list</code> <p>Nodes to keep fixed at initial position.</p> <code>iterations</code> <code>int</code> <p>Maximum number of iterations taken. Defaults to 50.</p> <code>threshold</code> <code>float</code> <p>Threshold for relative error in node position changes.  The iteration stops if the error is below this threshold. Defaults to 1e-4.</p> <code>weight</code> <code>string</code> <p>The edge attribute that holds the numerical value used for the edge weight.  If None, then all edge weights are 1.</p> <code>dimension</code> <code>int</code> <p>Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.</p> <code>seed</code> <code>int</code> <p>Set the random state for deterministic node layouts. If int, <code>seed</code> is the seed used by the random number generator, if None, the a random seed by created by the numpy random number generator is used.</p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def fruchterman_reingold(self):\n    \"\"\"Position nodes using Fruchterman-Reingold force-directed algorithm.\n\n    In this algorithm, the nodes are represented by steel rings and the\n    edges are springs between them. The attractive force is analogous to the\n    spring force and the repulsive force is analogous to the electrical\n    force. The basic idea is to minimize the energy of the system by moving\n    the nodes and changing the forces between them.\n\n    This algorithm can be enabled with the keywords: `Fruchterman-Reingold`,\n    `fruchterman_reingold`, `fr`, `spring_layout`, `spring layout`, `FR`\n\n    Keyword Args:\n        force (float): Optimal distance between nodes. If None the distance is set to\n            1/sqrt(n) where n is the number of nodes.  Increase this value to move\n            nodes farther apart.\n        positions (dict): Initial positions for nodes as a dictionary with node as keys and values\n            as a coordinate list or tuple.  If None, then use random initial\n            positions.\n        fixed (list): Nodes to keep fixed at initial position.\n        iterations (int): Maximum number of iterations taken. Defaults to 50.\n        threshold (float): Threshold for relative error in node position changes.  The iteration\n            stops if the error is below this threshold. Defaults to 1e-4.\n        weight (string): The edge attribute that holds the numerical value used for the edge\n            weight.  If None, then all edge weights are 1.\n        dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n        seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n            the seed used by the random number generator, if None, the a random seed\n            by created by the numpy random number generator is used.\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n\n    # convert adjacency matrix\n    self.adjacency_matrix = self.adjacency_matrix.astype(float)\n\n    if self.fixed is not None:\n        self.fixed = np.asarray([self.nodes.index(v) for v in self.fixed])\n\n    if self.positions is not None:\n        # Determine size of existing domain to adjust initial positions\n        _size = max(coord for t in layout.values() for coord in t) # type: ignore\n        if _size == 0:\n            _size = 1\n        np.random.seed(self.seed)\n        self.layout = np.random.rand(\n            len(self.nodes), self.dimension) * _size # type: ignore\n\n        for i, n in enumerate(self.nodes):\n            if n in self.positions:\n                self.layout[i] = np.asarray(self.positions[n])\n    else:\n        self.layout = None\n        _size = 0\n\n    if self.k is None and self.fixed is not None:\n        # We must adjust k by domain size for layouts not near 1x1\n        self.k = _size / np.sqrt(len(self.nodes))\n\n    try:\n        # Sparse matrix\n        if len(self.nodes) &lt; 500:  # sparse solver for large graphs\n            raise ValueError\n        layout = self._sparse_fruchterman_reingold()\n    except:\n        layout = self._fruchterman_reingold()\n\n    layout = dict(zip(self.nodes, layout))\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.generate_layout","title":"<code>generate_layout</code>","text":"<p>Function to pick and generate the right layout.</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def generate_layout(self):\n    \"\"\"Function to pick and generate the right layout.\"\"\"\n    # method names\n    names_rand = ['Random', 'random', 'rand', None]\n    names_fr = ['Fruchterman-Reingold', 'fruchterman_reingold', 'fr',\n                'spring_layout', 'spring layout', 'FR']\n    names_circular = ['circular', 'circle', 'ring', '1d-lattice', 'lattice-1d']\n    names_grid = ['grid', '2d-lattice', 'lattice-2d']\n    # check which layout should be plotted\n    if self.layout_type in names_rand:\n        self.layout = self.random()\n    elif self.layout_type in names_circular or (self.layout_type == 'lattice' and self.dimension == 1):\n        self.layout = self.circular()\n    elif self.layout_type in names_grid or (self.layout_type == 'lattice' and self.dimension == 2):\n        self.layout = self.grid()\n    elif self.layout_type in names_fr:\n        self.layout = self.fruchterman_reingold()\n\n    # print(self.layout)\n    return self.layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.grid","title":"<code>grid</code>","text":"<p>Position nodes on a two-dimensional grid</p> <p>This algorithm can be enabled with the keywords: <code>grid</code>, <code>lattice-2d</code>, <code>2d-lattice</code>, <code>lattice</code></p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def grid(self):\n    \"\"\"Position nodes on a two-dimensional grid\n\n    This algorithm can be enabled with the keywords: `grid`, `lattice-2d`, `2d-lattice`, `lattice`\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n\n    n = len(self.nodes)\n    width = 1.0\n\n    # number of nodes in horizontal/vertical direction\n    k = np.floor(np.sqrt(n))\n    dist = width / k\n    layout = {}\n\n    i = 0\n    for i in range(n):\n        layout[self.nodes[i]] = ((i%k) *dist, -(np.floor(i/k))*dist)\n        i += 1\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.random","title":"<code>random</code>","text":"<p>Position nodes uniformly at random in the unit square.</p> <p>For every node, a position is generated by choosing each of dimension coordinates uniformly at random on the interval \\([0.0, 1.0)\\).</p> <p>This algorithm can be enabled with the keywords: <code>Random</code>, <code>random</code>, <code>rand</code>, or <code>None</code></p> <p>Other Parameters:</p> Name Type Description <code>dimension</code> <code>int</code> <p>Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.</p> <code>seed</code> <code>int</code> <p>Set the random state for deterministic node layouts. If int, <code>seed</code> is the seed used by the random number generator, if None, the a random seed by created by the numpy random number generator is used.</p> <p>Returns:</p> Name Type Description <code>layout</code> <code>dict</code> <p>A dictionary of positions keyed by node</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def random(self):\n    \"\"\"Position nodes uniformly at random in the unit square.\n\n    For every node, a position is generated by choosing each of dimension\n    coordinates uniformly at random on the interval $[0.0, 1.0)$.\n\n    This algorithm can be enabled with the keywords: `Random`,\n    `random`, `rand`, or `None`\n\n    Keyword Args:\n        dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n        seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n            the seed used by the random number generator, if None, the a random\n            seed by created by the numpy random number generator is used.\n\n    Returns:\n        layout (dict): A dictionary of positions keyed by node\n    \"\"\"\n    np.random.seed(self.seed)\n    layout = np.random.rand(len(self.nodes), self.dimension)\n    return dict(zip(self.nodes, layout))\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.rename_attributes","title":"<code>rename_attributes</code>  <code>staticmethod</code>","text":"<p>Rename layout attributes.</p> <p>In the style dictionary multiple keywords can be used to address attributes. These keywords will be converted to an unique key word, used in the remaining code.</p> keys other valid keys fixed <code>fixed_nodes</code>, <code>fixed_vertices</code>, <code>fixed_n</code>, <code>fixed_v</code> positions <code>initial_positions</code>, <code>node_positions</code> <code>vertex_positions</code>, <code>n_positions</code>, <code>v_positions</code> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>@staticmethod\ndef rename_attributes(**kwds):\n    \"\"\"Rename layout attributes.\n\n    In the style dictionary multiple keywords can be used to address\n    attributes. These keywords will be converted to an unique key word,\n    used in the remaining code.\n\n    | keys | other valid keys |\n    | ---- | ---------------- |\n    | fixed | `fixed_nodes`, `fixed_vertices`, `fixed_n`, `fixed_v` |\n    | positions | `initial_positions`, `node_positions` `vertex_positions`, `n_positions`, `v_positions` |\n    \"\"\"\n    names = {'fixed': ['fixed_nodes', 'fixed_vertices',\n                       'fixed_v', 'fixed_n'],\n             'positions': ['initial_positions', 'node_positions',\n                           'vertex_positions', 'n_positions',\n                           'v_positions'],\n             'layout_': ['layout_'],\n             }\n\n    _kwds = {}\n    del_keys = []\n    for key, value in kwds.items():\n        for attr, name_list in names.items():\n            for name in name_list:\n                if name in key and name[0] == key[0]:\n                    _kwds[key.replace(name, attr).replace(\n                        'layout_', '')] = value\n                    del_keys.append(key)\n                    break\n    # remove the replaced keys from the dict\n    for key in del_keys:\n        del kwds[key]\n\n    return {**_kwds, **kwds}\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.layout","title":"<code>layout</code>","text":"<p>Function to generate a layout for the network.</p> <p>This function generates a layout configuration for the nodes in the network. Thereby, different layouts and options can be chosen. The layout function is directly included in the plot function or can be separately called.</p> <p>The layout function supports different network types and layout algorithm. Currently supported networks are:</p> <ul> <li><code>cnet</code>,</li> <li><code>networkx</code>,</li> <li><code>igraph</code>,</li> <li><code>pathpyG</code></li> <li>node/edge list</li> </ul> <p>Currently supported algorithms are:</p> <ul> <li>Fruchterman-Reingold force-directed algorithm</li> <li>Uniformly at random node positions</li> </ul> <p>The appearance of the layout can be modified by keyword arguments which will be explained in more detail below.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>network object</code> <p>Network to be drawn. The network can be a <code>cnet</code>, <code>networkx</code>, <code>igraph</code>, <code>pathpy</code> object, or a tuple of a node list and edge list.</p> required <code>**kwds</code> <code>Optional dict</code> <p>Attributes used to modify the appearance of the layout. For details see below.</p> <code>{}</code>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.layout--layout","title":"Layout:","text":"<p>The layout can be modified by the following keyword arguments: Note:      All layout arguments can be entered with or without <code>layout_</code> at the beginning, e.g. <code>layout_iterations</code> is equal to <code>iterations</code></p> <p>Other Parameters:</p> Name Type Description <code>layout</code> <code>Optional dict or string</code> <p>A dictionary with the node positions on a 2-dimensional plane. The key value of the dict represents the node id while the value represents a tuple of coordinates (e.g. \\(n = (x,y)\\)). The initial layout can be placed anywhere on the 2-dimensional plane.</p> <p>Instead of a dictionary, the algorithm used for the layout can be defined via a string value. Currently, supported are:</p> <ul> <li>Random layout, where the nodes are uniformly at random placed in the     unit square. </li> <li>Fruchterman-Reingold force-directed algorithm. In this algorithm, the     nodes are represented by steel rings and the edges are springs between     them. The attractive force is analogous to the spring force and the     repulsive force is analogous to the electrical force. The basic idea is     to minimize the energy of the system by moving the nodes and changing     the forces between them. </li> </ul> <p>The algorithm can be enabled with the keywords: | Algorithms | Keywords | | ---------- | -------- | | Random | <code>Random</code>, <code>random</code>, <code>rand</code>, <code>None</code> | |Fruchterman-Reingold | <code>Fruchterman-Reingold</code>, <code>fruchterman_reingold</code>, <code>fr spring_layout</code>, <code>spring layout</code>, <code>FR</code> |</p> <code>force</code> <code>float</code> <p>Optimal distance between nodes.  If None the distance is set to 1/sqrt(n) where n is the number of nodes.  Increase this value to move nodes farther apart.</p> <code>positions</code> <code>dict</code> <p>Initial positions for nodes as a dictionary with node as keys and values as a coordinate list or tuple.  If None, then use random initial positions.</p> <code>fixed</code> <code>list</code> <p>Nodes to keep fixed at initial position.</p> <code>iterations</code> <code>int</code> <p>Maximum number of iterations taken. Defaults to 50.</p> <code>threshold</code> <code>float</code> <p>Threshold for relative error in node position changes.  The iteration stops if the error is below this threshold. Defaults to 1e-4.</p> <code>weight</code> <code>string</code> <p>or None, optional (default = None) The edge attribute that holds the numerical value used for the edge weight. If None, then all edge weights are 1.</p> <code>dimension</code> <code>int</code> <p>Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.</p> <code>seed</code> <code>int</code> <p>Set the random state for deterministic node layouts. If int, <code>seed</code> is the seed used by the random number generator, if None, the a random seed by created by the numpy random number generator is used.</p> <p>In the layout style dictionary multiple keywords can be used to address attributes. These keywords will be converted to an unique key word, used in the remaining code.</p> keys other valid keys fixed <code>fixed_nodes</code>, <code>fixed_vertices</code>, <code>fixed_n</code>, <code>fixed_v</code> positions <code>initial_positions</code>, <code>node_positions</code>, <code>vertex_positions</code>, <code>n_positions</code>, <code>v_positions</code> <p>Examples:</p> <p>For illustration purpose a similar network as in the <code>python-igraph</code> tutorial is used. Instead of <code>igraph</code>, the <code>cnet</code> module is used for creating the network.</p> <p>Create an empty network object, and add some edges.</p> <pre><code>&gt;&gt;&gt; net = Network(name = 'my tikz test network',directed=True)\n&gt;&gt;&gt; net.add_edges_from([('ab','a','b'), ('ac','a','c'), ('cd','c','d'),\n...                     ('de','d','e'), ('ec','e','c'), ('cf','c','f'),\n...                     ('fa','f','a'), ('fg','f','g'),('gg','g','g'),\n...                     ('gd','g','d')])\n</code></pre> <p>Now a layout can be generated:</p> <pre><code>&gt;&gt;&gt; layout(net)\n{'b': array([0.88878309, 0.15685131]), 'd': array([0.4659341 , 0.79839535]),\n'c': array([0.60386662, 0.40727962]), 'e': array([0.71073353, 0.65608203]),\n'g': array([0.42663927, 0.47412449]), 'f': array([0.48759769, 0.86787594]),\n'a': array([0.84154488, 0.1633732 ])}\n</code></pre> <p>Per default, the node positions are assigned uniform random. In order to create a layout, the layout methods of the packages can be used, or the position of the nodes can be directly assigned, in form of a dictionary, where the key is the <code>node_id</code> and the value is a tuple of the node position in \\(x\\) and \\(y\\).</p> <p>Let us generate a force directed layout (e.g. Fruchterman-Reingold):</p> <pre><code>&gt;&gt;&gt; layout(net, layout='fr')\n{'g': array([-0.77646408,  1.71291126]), 'c': array([-0.18639655,0.96232326]),\n'f': array([0.33394308, 0.93778681]), 'e': array([0.09740098, 1.28511973]),\n'a': array([1.37933158, 0.23171857]), 'b': array([ 2.93561876,-0.46183461]),\n'd': array([-0.29329793,  1.48971303])}\n</code></pre> <p>Note, instead of the command <code>fr</code> also the command <code>Fruchterman-Reingold</code> or any other command mentioned above can be used. For more information see table above.</p> <p>In order to keep the properties of the layout for your network separate from the network itself, you can simply set up a Python dictionary containing the keyword arguments you would pass to <code>layout</code> and then use the double asterisk (**) operator to pass your specific layout attributes to <code>layout</code>:</p> <pre><code>&gt;&gt;&gt; layout_style = {}\n&gt;&gt;&gt; layout_style['layout'] = 'Fruchterman-Reingold'\n&gt;&gt;&gt; layout_style['seed'] = 1\n&gt;&gt;&gt; layout_style['iterations'] = 100\n&gt;&gt;&gt; layout(net,**layout_style)\n{'d': array([-0.31778276, 1.78246882]), 'f': array([-0.8603259, 0.82328291]),\n'c': array([-0.4423771 , 1.21203895]), 'e': array([-0.79934355, 1.49000119]),\n'g': array([0.43694799, 1.51428788]), 'a': array([-2.15517293, 0.23948823]),\n'b': array([-3.84803812, -0.71628417])}\n</code></pre> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def layout(network, **kwds):\n    \"\"\"Function to generate a layout for the network.\n\n    This function generates a layout configuration for the nodes in the\n    network. Thereby, different layouts and options can be chosen. The layout\n    function is directly included in the plot function or can be separately\n    called.\n\n    The layout function supports different network types and layout algorithm.\n    Currently supported networks are:\n\n    - `cnet`,\n    - `networkx`,\n    - `igraph`,\n    - `pathpyG`\n    - node/edge list\n\n    Currently supported algorithms are:\n\n    - Fruchterman-Reingold force-directed algorithm\n    - Uniformly at random node positions\n\n    The appearance of the layout can be modified by keyword arguments which will\n    be explained in more detail below.\n\n    Args:\n        network (network object): Network to be drawn. The network can be a `cnet`, `networkx`, `igraph`, `pathpy` object, or a tuple of a node list and edge list.\n        **kwds (Optional dict): Attributes used to modify the appearance of the layout. For details see below.\n\n    # Layout:\n\n    The layout can be modified by the following keyword arguments:\n    Note: \n        All layout arguments can be entered with or without `layout_` at the beginning, e.g. `layout_iterations` is equal to `iterations`\n\n    Keyword Args:\n        layout (Optional dict or string): A dictionary with the node positions on a 2-dimensional plane. The\n            key value of the dict represents the node id while the value\n            represents a tuple of coordinates (e.g. $n = (x,y)$). The initial\n            layout can be placed anywhere on the 2-dimensional plane.\n\n            Instead of a dictionary, the algorithm used for the layout can be defined\n            via a string value. Currently, supported are:\n\n            - **Random layout**, where the nodes are uniformly at random placed in the\n                unit square. \n            - **Fruchterman-Reingold force-directed algorithm**. In this algorithm, the\n                nodes are represented by steel rings and the edges are springs between\n                them. The attractive force is analogous to the spring force and the\n                repulsive force is analogous to the electrical force. The basic idea is\n                to minimize the energy of the system by moving the nodes and changing\n                the forces between them. \n\n            The algorithm can be enabled with the keywords:\n            | Algorithms | Keywords |\n            | ---------- | -------- |\n            | Random | `Random`, `random`, `rand`, `None` |\n            |Fruchterman-Reingold | `Fruchterman-Reingold`, `fruchterman_reingold`, `fr spring_layout`, `spring layout`, `FR` |\n\n        force (float): Optimal distance between nodes.  If None the distance is set to\n            1/sqrt(n) where n is the number of nodes.  Increase this value to move\n            nodes farther apart.\n        positions (dict): Initial positions for nodes as a dictionary with node as keys and values\n            as a coordinate list or tuple.  If None, then use random initial\n            positions.\n        fixed (list): Nodes to keep fixed at initial position.\n        iterations (int): Maximum number of iterations taken. Defaults to 50.\n        threshold (float): Threshold for relative error in node position changes.  The iteration\n            stops if the error is below this threshold. Defaults to 1e-4.\n        weight (string):  or None, optional (default = None)\n            The edge attribute that holds the numerical value used for the edge\n            weight. If None, then all edge weights are 1.\n        dimension (int): Dimension of layout. Currently, only plots in 2 dimension are supported. Defaults to 2.\n        seed (int): Set the random state for deterministic node layouts. If int, `seed` is\n            the seed used by the random number generator, if None, the a random seed\n            by created by the numpy random number generator is used.\n\n    In the layout style dictionary multiple keywords can be used to address\n    attributes. These keywords will be converted to an unique key word,\n    used in the remaining code.\n\n    | keys | other valid keys |\n    | ---- | ---------------- |\n    | fixed | `fixed_nodes`, `fixed_vertices`, `fixed_n`, `fixed_v` |\n    | positions| `initial_positions`, `node_positions`, `vertex_positions`, `n_positions`, `v_positions` |\n\n    Examples:\n        For illustration purpose a similar network as in the `python-igraph` tutorial\n        is used. Instead of `igraph`, the `cnet` module is used for creating the\n        network.\n\n        Create an empty network object, and add some edges.\n\n        &gt;&gt;&gt; net = Network(name = 'my tikz test network',directed=True)\n        &gt;&gt;&gt; net.add_edges_from([('ab','a','b'), ('ac','a','c'), ('cd','c','d'),\n        ...                     ('de','d','e'), ('ec','e','c'), ('cf','c','f'),\n        ...                     ('fa','f','a'), ('fg','f','g'),('gg','g','g'),\n        ...                     ('gd','g','d')])\n\n        Now a layout can be generated:\n\n        &gt;&gt;&gt; layout(net)\n        {'b': array([0.88878309, 0.15685131]), 'd': array([0.4659341 , 0.79839535]),\n        'c': array([0.60386662, 0.40727962]), 'e': array([0.71073353, 0.65608203]),\n        'g': array([0.42663927, 0.47412449]), 'f': array([0.48759769, 0.86787594]),\n        'a': array([0.84154488, 0.1633732 ])}\n\n        Per default, the node positions are assigned uniform random. In order to\n        create a layout, the layout methods of the packages can be used, or the\n        position of the nodes can be directly assigned, in form of a dictionary,\n        where the key is the `node_id` and the value is a tuple of the node position\n        in $x$ and $y$.\n\n        Let us generate a force directed layout (e.g. Fruchterman-Reingold):\n\n        &gt;&gt;&gt; layout(net, layout='fr')\n        {'g': array([-0.77646408,  1.71291126]), 'c': array([-0.18639655,0.96232326]),\n        'f': array([0.33394308, 0.93778681]), 'e': array([0.09740098, 1.28511973]),\n        'a': array([1.37933158, 0.23171857]), 'b': array([ 2.93561876,-0.46183461]),\n        'd': array([-0.29329793,  1.48971303])}\n\n        Note, instead of the command `fr` also the command\n        `Fruchterman-Reingold` or any other command mentioned above can be\n        used. For more information see table above.\n\n        In order to keep the properties of the layout for your network separate from\n        the network itself, you can simply set up a Python dictionary containing the\n        keyword arguments you would pass to [`layout`][pathpyG.visualisations.layout.layout] and then use the\n        double asterisk (**) operator to pass your specific layout attributes to\n        [`layout`][pathpyG.visualisations.layout.layout]:\n\n        &gt;&gt;&gt; layout_style = {}\n        &gt;&gt;&gt; layout_style['layout'] = 'Fruchterman-Reingold'\n        &gt;&gt;&gt; layout_style['seed'] = 1\n        &gt;&gt;&gt; layout_style['iterations'] = 100\n        &gt;&gt;&gt; layout(net,**layout_style)\n        {'d': array([-0.31778276, 1.78246882]), 'f': array([-0.8603259, 0.82328291]),\n        'c': array([-0.4423771 , 1.21203895]), 'e': array([-0.79934355, 1.49000119]),\n        'g': array([0.43694799, 1.51428788]), 'a': array([-2.15517293, 0.23948823]),\n        'b': array([-3.84803812, -0.71628417])}\n    \"\"\"\n    # initialize variables\n    _weight = kwds.get('weight', None)\n    if _weight is None:\n        _weight = kwds.get('layout_weight', None)\n\n    # check type of network\n    if 'cnet' in str(type(network)):\n        # log.debug('The network is of type \"cnet\".')\n        nodes = list(network.nodes)\n        adjacency_matrix = network.adjacency_matrix(weight=_weight)\n\n    elif 'networkx' in str(type(network)):\n        # log.debug('The network is of type \"networkx\".')\n        nodes = list(network.nodes())\n        import networkx as nx\n        adjacency_matrix = nx.adjacency_matrix(network, weight=_weight) # type: ignore\n    elif 'igraph' in str(type(network)):\n        # log.debug('The network is of type \"igraph\".')\n        nodes = list(range(len(network.vs)))\n        from scipy.sparse import coo_matrix\n        A = np.array(network.get_adjacency(attribute=_weight).data)\n        adjacency_matrix = coo_matrix(A)\n    elif 'pathpyG' in str(type(network)):\n        # log.debug('The network is of type \"pathpy\".')\n        nodes = list(network.nodes)\n        if _weight is not None:\n            _w = True\n        else:\n            _w = False\n        adjacency_matrix = network.get_sparse_adj_matrix()\n    # elif isinstance(network, tuple):\n    #     # log.debug('The network is of type \"list\".')\n    #     nodes = network[0]\n    #     from collections import OrderedDict\n    #     edges = OrderedDict()\n    #     for e in network[1]:\n    #         edges[e] = e\n\n    else:\n        print('Type of the network could not be determined.'\n                  ' Currently only \"cnet\", \"networkx\",\"igraph\", \"pathpy\"'\n                  ' and \"node/edge list\" is supported!')\n        raise NotImplementedError\n\n    # create layout class\n    layout = Layout(nodes, adjacency_matrix, **kwds)\n    # return the layout\n    return layout.generate_layout()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/","title":"network_plots","text":"<p>Network plot classes.</p>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>class NetworkPlot(PathPyPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, network: Graph, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        self._compute_edge_data()\n        self._compute_node_data()\n        self._compute_layout()\n        self._cleanup_config()\n        self._cleanup_data()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the nodes.\"\"\"\n        # initialize values\n        nodes: dict = {}\n        attributes: set = {\"color\", \"size\", \"opacity\", \"label\"}\n        attr: defaultdict = defaultdict(dict)\n\n        # get attributes categories from pathpyg\n        categories = {a.replace(\"node_\", \"\") for a in self.network.node_attrs()}.intersection(attributes)\n\n        # add node data to data dict\n        self._get_node_data(nodes, attributes, attr, categories)\n\n        # convert needed attributes to useful values\n        attr[\"color\"] = self._convert_color(attr[\"color\"], mode=\"node\")\n        attr[\"opacity\"] = self._convert_opacity(attr[\"opacity\"], mode=\"node\")\n        attr[\"size\"] = self._convert_size(attr[\"size\"], mode=\"node\")\n        attr[\"label\"] = self._convert_label(attr[\"label\"], mode=\"node\")\n\n        # update data dict with converted attributes\n        for attribute in attr:\n            for key, value in attr[attribute].items():\n                nodes[key][attribute] = value\n\n        # save node data\n        self.data[\"nodes\"] = nodes\n\n    def _get_node_data(\n        self,\n        nodes: dict,\n        attributes: set,\n        attr: defaultdict,\n        categories: set,\n    ) -&gt; None:\n        \"\"\"Extract node data from network.\"\"\"\n        for uid in self.network.nodes:\n            nodes[uid] = {\"uid\": str(uid)}\n\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"node_{attribute}\", uid].item() if attribute in categories else None\n                )\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the edges.\"\"\"\n        # initialize values\n        edges: dict = {}\n        attributes: set = {\"weight\", \"color\", \"size\", \"opacity\"}\n        attr: defaultdict = defaultdict(dict)\n\n        # get attributes categories from pathpyg\n        categories: set = {a.replace(\"edge_\", \"\") for a in self.network.edge_attrs()}.intersection(attributes)\n\n        # add edge data to data dict\n        self._get_edge_data(edges, attributes, attr, categories)\n\n        # convert needed attributes to useful values\n        attr[\"weight\"] = self._convert_weight(attr[\"weight\"], mode=\"edge\")\n        attr[\"color\"] = self._convert_color(attr[\"color\"], mode=\"edge\")\n        attr[\"opacity\"] = self._convert_opacity(attr[\"opacity\"], mode=\"edge\")\n        attr[\"size\"] = self._convert_size(attr[\"size\"], mode=\"edge\")\n\n        # update data dict with converted attributes\n        for attribute in attr:\n            for key, value in attr[attribute].items():\n                edges[key][attribute] = value\n\n        # save edge data\n        self.data[\"edges\"] = edges\n\n    def _get_edge_data(\n        self,\n        edges: dict,\n        attributes: set,\n        attr: defaultdict,\n        categories: set,\n    ) -&gt; None:\n        \"\"\"Extract edge data from network.\"\"\"\n        for u, v in self.network.edges:\n            uid = f\"{u}-{v}\"\n            edges[uid] = {\n                \"uid\": uid,\n                \"source\": str(u),\n                \"target\": str(v),\n            }\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"edge_{attribute}\", u, v].item() if attribute in categories else None\n                )\n\n    def _convert_weight(self, weight: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert weight to float.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_weight\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (int, float)):\n            weight = {k: style for k in weight}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            weight.update(**{k: v for k, v in style.items() if k in weight})\n\n        # return all weights which are not None\n        return {k: v if v is not None else 1 for k, v in weight.items()}\n\n    def _convert_color(self, color: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert colors to hex if rgb.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_color\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (str, int, float, tuple)):\n            color = {k: style for k in color}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            color.update(**{k: v for k, v in style.items() if k in color})\n\n        # check if new attribute is a list\n        elif isinstance(style, list):\n            for i, k in enumerate(color):\n                try:\n                    color[k] = style[i]\n                except IndexError:\n                    pass\n\n        # check if numerical values are given\n        values = [v for v in color.values() if isinstance(v, (int, float))]\n\n        if values:\n            # load colormap to map numerical values to color\n            cmap = self.config.get(f\"{mode}_cmap\", Colormap())\n            cdict = {values[i]: tuple(c[:3]) for i, c in enumerate(cmap(values, bytes=True))}\n\n        # convert colors to hex if not already string\n        for key, value in color.items():\n            if isinstance(value, tuple):\n                color[key] = rgb_to_hex(value)\n            elif isinstance(value, (int, float)):\n                color[key] = rgb_to_hex(cdict[value])\n\n        # return all colors wich are not None\n        return {k: v for k, v in color.items() if v is not None}\n\n    def _convert_opacity(self, opacity: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert opacity to float.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_opacity\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (int, float)):\n            opacity = {k: style for k in opacity}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            opacity.update(**{k: v for k, v in style.items() if k in opacity})\n\n        # return all colors wich are not None\n        return {k: v for k, v in opacity.items() if v is not None}\n\n    def _convert_size(self, size: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert size to float.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_size\")\n\n        # check if new attribute is a single object\n        if isinstance(style, (int, float)):\n            size = {k: style for k in size}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            size.update(**{k: v for k, v in style.items() if k in size})\n\n        # return all colors wich are not None\n        return {k: v for k, v in size.items() if v is not None}\n\n    def _convert_label(self, label: dict, mode: str = \"node\") -&gt; dict:\n        \"\"\"Convert label to string.\"\"\"\n        # get style from the config\n        style = self.config.get(f\"{mode}_label\")\n\n        # check if new attribute is a single object\n        if isinstance(style, str):\n            label = {k: style for k in label}\n\n        # check if new attribute is a dict\n        elif isinstance(style, dict):\n            label.update(**{k: v for k, v in style.items() if k in label})\n\n        # check if new attribute is a list\n        elif isinstance(style, list):\n            for i, k in enumerate(label):\n                try:\n                    label[k] = style[i]\n                except IndexError:\n                    pass\n\n        # return all labels wich are not None\n        return {k: v for k, v in label.items() if v is not None}\n\n    def _compute_layout(self) -&gt; None:\n        \"\"\"Create layout.\"\"\"\n        # get layout form the config\n        layout = self.config.get(\"layout\", \"rand\")\n\n        # if no layout is considered stop this process\n        if layout is None:\n            return\n\n        # get layout dict for each node\n        if isinstance(layout, str):\n            layout = network_layout(self.network, layout=layout)\n        elif not isinstance(layout, dict):\n            logger.error(\"The provided layout is not valid!\")\n            raise AttributeError\n\n        # update x,y position of the nodes\n        for uid, (_x, _y) in layout.items():\n            self.data[\"nodes\"][uid][\"x\"] = _x\n            self.data[\"nodes\"][uid][\"y\"] = _y\n\n    def _cleanup_config(self) -&gt; None:\n        \"\"\"Clean up final config file.\"\"\"\n        try:\n            directed = self.network.is_directed()\n        except NotImplementedError:\n            directed = False\n\n        if not self.config.get(\"directed\", None):\n            self.config[\"directed\"] = directed\n\n        if not self.config.get(\"curved\", None):\n            self.config[\"curved\"] = directed\n\n    def _cleanup_data(self) -&gt; None:\n        \"\"\"Clean up final data structure.\"\"\"\n        self.data[\"nodes\"] = list(self.data[\"nodes\"].values())\n        self.data[\"edges\"] = list(self.data[\"edges\"].values())\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def __init__(self, network: Graph, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.network = network\n    self.config = kwargs\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    self._compute_edge_data()\n    self._compute_node_data()\n    self._compute_layout()\n    self._cleanup_config()\n    self._cleanup_data()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.network_plots.NetworkPlot</code></p> <p>Network plot class for a temporal network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a temporal network.\"\"\"\n\n    _kind = \"temporal\"\n\n    def __init__(self, network: TemporalGraph, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__(network, **kwargs)\n\n    def _get_edge_data(self, edges: dict, attributes: set, attr: defaultdict, categories: set) -&gt; None:\n        \"\"\"Extract edge data from temporal network.\"\"\"\n        # TODO: Fix typing issue with temporal graphs\n        for u, v, t in self.network.temporal_edges:  # type: ignore\n            uid = f\"{u}-{v}-{t}\"\n            edges[uid] = {\n                \"uid\": uid,\n                \"source\": str(u),\n                \"target\": str(v),\n                \"start\": int(t),\n                \"end\": int(t) + 1,\n            }\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"edge_{attribute}\", u, v].item() if attribute in categories else None\n                )\n\n    def _get_node_data(self, nodes: dict, attributes: set, attr: defaultdict, categories: set) -&gt; None:\n        \"\"\"Extract node data from temporal network.\"\"\"\n\n        time = {e[2] for e in self.network.temporal_edges}\n\n        if self.config.get(\"end\", None) is None:\n            self.config[\"end\"] = int(max(time) + 1)\n\n        if self.config.get(\"start\", None) is None:\n            self.config[\"start\"] = int(min(time) - 1)\n\n        for uid in self.network.nodes:\n            nodes[uid] = {\n                \"uid\": uid,\n                \"start\": int(min(time) - 1),\n                \"end\": int(max(time) + 1),\n            }\n\n            # add edge attributes if needed\n            for attribute in attributes:\n                attr[attribute][uid] = (\n                    self.network[f\"node_{attribute}\", uid].item() if attribute in categories else None\n                )\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def __init__(self, network: TemporalGraph, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.network_plot","title":"<code>network_plot</code>","text":"<p>Plot a static network.</p> <p>This function generates a static plot of the network with various output formats including interactive HTML with d3js, tex file with tikz code, PDF from the tex source, and PNG based on matplotlib. The appearance of the plot can be modified using keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.core.Graph.Graph</code> <p>A <code>Graph</code> object to be plotted.</p> required <code>**kwargs</code> <code>typing.Any</code> <p>Keyword arguments to modify the appearance of the plot. Defaults to no attributes. For details see below.</p> <code>{}</code> <p>Returns:</p> Type Description <code>pathpyG.visualisations.network_plots.NetworkPlot</code> <p>A plot object, the type of which depends on the output format chosen.</p>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.network_plot--keyword-arguments-to-modify-the-appearance-of-the-plot","title":"Keyword Arguments to modify the appearance of the plot","text":"<p>Nodes:</p> <ul> <li> <p><code>node_size</code> : diameter of the node</p> </li> <li> <p><code>node_color</code> : The fill color of the node. Possible values are:</p> <ul> <li> <p>A single color string referred to by name, RGB or RGBA code, for   instance <code>red</code> or <code>#a98d19</code> or <code>(12,34,102)</code>.</p> </li> <li> <p>A sequence of color strings referred to by name, RGB or RGBA code,   which will be used for each point's color recursively. For   instance <code>['green', 'yellow']</code> all points will be filled in green or   yellow, alternatively.</p> </li> <li> <p>A column name or position whose values will be used to color the   marker points according to a colormap.</p> </li> </ul> </li> <li> <p><code>node_cmap</code> : Colormap for node colors. If node colors are given as int   or float values the color will be assigned based on a colormap. Per   default the color map goes from red to green. Matplotlib colormaps or   seaborn color palettes can be used to style the node colors.</p> </li> <li> <p><code>node_opacity</code> : fill opacity of the node. The default is 1. The range   of the number lies between 0 and 1. Where 0 represents a fully   transparent fill and 1 a solid fill.</p> </li> </ul> <p>Edges</p> <ul> <li> <p><code>edge_size</code> : width of the edge</p> </li> <li> <p><code>edge_color</code> : The line color of the edge. Possible values are:</p> <ul> <li> <p>A single color string referred to by name, RGB or RGBA code, for   instance <code>red</code> or <code>#a98d19</code> or <code>(12,34,102)</code>.</p> </li> <li> <p>A sequence of color strings referred to by name, RGB or RGBA   code, which will be used for each point's color recursively. For   instance <code>['green','yellow']</code> all points will be filled in green or   yellow, alternatively.</p> </li> <li> <p>A column name or position whose values will be used to color the   marker points according to a colormap.</p> </li> </ul> </li> <li> <p><code>edge_cmap</code> : Colormap for edge colors. If node colors are given as int   or float values the color will be assigned based on a colormap. Per   default the color map goes from red to green. Matplotlib colormaps or   seaborn color palettes can be used to style the edge colors.</p> </li> <li> <p><code>edge_opacity</code> : line opacity of the edge. The default is 1. The range   of the number lies between 0 and 1. Where 0 represents a fully   transparent fill and 1 a solid fill.</p> </li> </ul> <p>General</p> <ul> <li> <p><code>keep_aspect_ratio</code></p> </li> <li> <p><code>margin</code></p> </li> <li> <p><code>layout</code></p> </li> </ul> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def network_plot(network: Graph, **kwargs: Any) -&gt; NetworkPlot:\n    \"\"\"Plot a static network.\n\n    This function generates a static plot of the network with various output\n    formats including interactive HTML with d3js, tex file with tikz code, PDF\n    from the tex source, and PNG based on matplotlib. The appearance of the\n    plot can be modified using keyword arguments.\n\n    Args:\n        network (Graph): A `Graph` object to be plotted.\n        **kwargs (Any): Keyword arguments to modify the appearance of the\n            plot. Defaults to no attributes. For details see below.\n\n    Returns:\n        A plot object, the type of which depends on the output format chosen.\n\n\n    # Keyword Arguments to modify the appearance of the plot\n    **Nodes:**\n\n    - `node_size` : diameter of the node\n\n    - `node_color` : The fill color of the node. Possible values are:\n\n        - A single color string referred to by name, RGB or RGBA code, for\n          instance `red` or `#a98d19` or `(12,34,102)`.\n\n        - A sequence of color strings referred to by name, RGB or RGBA code,\n          which will be used for each point's color recursively. For\n          instance `['green', 'yellow']` all points will be filled in green or\n          yellow, alternatively.\n\n        - A column name or position whose values will be used to color the\n          marker points according to a colormap.\n\n    - `node_cmap` : Colormap for node colors. If node colors are given as int\n      or float values the color will be assigned based on a colormap. Per\n      default the color map goes from red to green. Matplotlib colormaps or\n      seaborn color palettes can be used to style the node colors.\n\n    - `node_opacity` : fill opacity of the node. The default is 1. The range\n      of the number lies between 0 and 1. Where 0 represents a fully\n      transparent fill and 1 a solid fill.\n\n\n    **Edges**\n\n    - `edge_size` : width of the edge\n\n    - `edge_color` : The line color of the edge. Possible values are:\n\n        - A single color string referred to by name, RGB or RGBA code, for\n          instance `red` or `#a98d19` or `(12,34,102)`.\n\n        - A sequence of color strings referred to by name, RGB or RGBA\n          code, which will be used for each point's color recursively. For\n          instance `['green','yellow']` all points will be filled in green or\n          yellow, alternatively.\n\n        - A column name or position whose values will be used to color the\n          marker points according to a colormap.\n\n    - `edge_cmap` : Colormap for edge colors. If node colors are given as int\n      or float values the color will be assigned based on a colormap. Per\n      default the color map goes from red to green. Matplotlib colormaps or\n      seaborn color palettes can be used to style the edge colors.\n\n    - `edge_opacity` : line opacity of the edge. The default is 1. The range\n      of the number lies between 0 and 1. Where 0 represents a fully\n      transparent fill and 1 a solid fill.\n\n\n    **General**\n\n    - `keep_aspect_ratio`\n\n    - `margin`\n\n    - `layout`\n\n    \"\"\"\n    return NetworkPlot(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.static_plot","title":"<code>static_plot</code>","text":"<p>Plot a static network.</p> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def static_plot(network: Graph, **kwargs: Any) -&gt; NetworkPlot:\n    \"\"\"Plot a static network.\"\"\"\n    return StaticNetworkPlot(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plots/#pathpyG.visualisations.network_plots.temporal_plot","title":"<code>temporal_plot</code>","text":"<p>Plot a temporal network.</p> <p>Temporal properties:</p> <ul> <li> <p><code>start</code> : start time of the simulation</p> </li> <li> <p><code>end</code> : end time of the simulation</p> </li> <li> <p><code>delta</code> : time needed for progressing one time step</p> </li> <li> <p><code>intervals</code> : number of numeric intervals</p> </li> </ul> Source code in <code>src/pathpyG/visualisations/network_plots.py</code> <pre><code>def temporal_plot(network: TemporalGraph, **kwargs: Any) -&gt; NetworkPlot:\n    \"\"\"Plot a temporal network.\n\n    **Temporal properties:**\n\n    - ``start`` : start time of the simulation\n\n    - ``end`` : end time of the simulation\n\n    - ``delta`` : time needed for progressing one time step\n\n    - ``intervals`` : number of numeric intervals\n\n    \"\"\"\n    return TemporalNetworkPlot(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/","title":"plot","text":"<p>Class to plot pathpy networks.</p>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot","title":"<code>PathPyPlot</code>","text":"<p>Abstract class for assemblig plots.</p>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot--attributes","title":"Attributes","text":"<p>data : dict     data of the plot object config : dict     configuration for the plot</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>class PathPyPlot:\n    \"\"\"Abstract class for assemblig plots.\n\n    Attributes\n    ----------\n    data : dict\n        data of the plot object\n    config : dict\n        configuration for the plot\n\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize plot class.\"\"\"\n        logger.debug(\"Initalize PathPyPlot class\")\n        self.data: dict = {}\n        self.config: dict = {}\n\n    @property\n    def _kind(self) -&gt; str:\n        \"\"\"Specify kind str. Must be overridden in child class.\"\"\"\n        raise NotImplementedError\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n        plot_backend = _get_plot_backend(_backend, filename)\n        plot_backend.plot(\n            deepcopy(self.data), self._kind, **deepcopy(self.config)\n        ).save(filename, **kwargs)\n\n    def show(self, **kwargs: Any) -&gt; None:\n        \"\"\"Show the plot on the device.\"\"\"\n        _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n        plot_backend = _get_plot_backend(_backend, None)\n        plot_backend.plot(\n            deepcopy(self.data), self._kind, **deepcopy(self.config)\n        ).show(**kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize plot class.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize plot class.\"\"\"\n    logger.debug(\"Initalize PathPyPlot class\")\n    self.data: dict = {}\n    self.config: dict = {}\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n    plot_backend = _get_plot_backend(_backend, filename)\n    plot_backend.plot(\n        deepcopy(self.data), self._kind, **deepcopy(self.config)\n    ).save(filename, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/#pathpyG.visualisations.plot.PathPyPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/plot.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:\n    \"\"\"Show the plot on the device.\"\"\"\n    _backend: str = kwargs.pop(\"backend\", self.config.get(\"backend\", None))\n\n    plot_backend = _get_plot_backend(_backend, None)\n    plot_backend.plot(\n        deepcopy(self.data), self._kind, **deepcopy(self.config)\n    ).show(**kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/","title":"utils","text":"<p>Helper functions for plotting.</p>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.Colormap","title":"<code>Colormap</code>","text":"<p>Very simple colormap class.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>class Colormap:\n    \"\"\"Very simple colormap class.\"\"\"\n\n    def __call__(\n        self,\n        values: list,\n        alpha: Optional[float] = None,\n        bytes: bool = False,\n    ) -&gt; list:\n        \"\"\"Return color value.\"\"\"\n        vmin, vmax = min(values), max(values)\n        if vmin == vmax:\n            vmin -= 1\n            vmax += 1\n        return [\n            self.color_tuple(v)\n            for v in ((x - vmin) / (vmax - vmin) * 100 for x in values)\n        ]\n\n    @staticmethod\n    def color_tuple(n: float) -&gt; tuple:\n        \"\"\"Return color ramp from green to red.\"\"\"\n        return (int((255 * n) * 0.01), int((255 * (100 - n)) * 0.01), 0, 255)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.Colormap.__call__","title":"<code>__call__</code>","text":"<p>Return color value.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def __call__(\n    self,\n    values: list,\n    alpha: Optional[float] = None,\n    bytes: bool = False,\n) -&gt; list:\n    \"\"\"Return color value.\"\"\"\n    vmin, vmax = min(values), max(values)\n    if vmin == vmax:\n        vmin -= 1\n        vmax += 1\n    return [\n        self.color_tuple(v)\n        for v in ((x - vmin) / (vmax - vmin) * 100 for x in values)\n    ]\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.Colormap.color_tuple","title":"<code>color_tuple</code>  <code>staticmethod</code>","text":"<p>Return color ramp from green to red.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>@staticmethod\ndef color_tuple(n: float) -&gt; tuple:\n    \"\"\"Return color ramp from green to red.\"\"\"\n    return (int((255 * n) * 0.01), int((255 * (100 - n)) * 0.01), 0, 255)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.hex_to_rgb","title":"<code>hex_to_rgb</code>","text":"<p>Convert hex string to rgb color tuple.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def hex_to_rgb(value: str) -&gt; tuple:\n    \"\"\"Convert hex string to rgb color tuple.\"\"\"\n    value = value.lstrip(\"#\")\n    _l = len(value)\n    return tuple(int(value[i : i + _l // 3], 16) for i in range(0, _l, _l // 3))\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.rgb_to_hex","title":"<code>rgb_to_hex</code>","text":"<p>Convert rgb color tuple to hex string.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def rgb_to_hex(rgb: tuple) -&gt; str:\n    \"\"\"Convert rgb color tuple to hex string.\"\"\"\n    return \"#%02x%02x%02x\" % rgb\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/","title":"_d3js","text":"<p>Initialize d3js plotting functions.</p>"},{"location":"reference/pathpyG/visualisations/_d3js/#pathpyG.visualisations._d3js.plot","title":"<code>plot</code>","text":"<p>Plot function.</p> Source code in <code>src/pathpyG/visualisations/_d3js/__init__.py</code> <pre><code>def plot(data: dict, kind: str = \"network\", **kwargs: Any) -&gt; Any:\n    \"\"\"Plot function.\"\"\"\n    return PLOT_CLASSES[kind](data, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/","title":"core","text":""},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot","title":"<code>D3jsPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Base class for plotting d3js objects.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>class D3jsPlot(PathPyPlot):\n    \"\"\"Base class for plotting d3js objects.\"\"\"\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        with open(filename, \"w+\") as new:\n            new.write(self.to_html())\n\n    def show(self, **kwargs: Any) -&gt; None:\n        \"\"\"Show the plot on the device.\"\"\"\n        if config[\"environment\"][\"interactive\"]:\n            from IPython.display import display_html, HTML\n\n            display_html(HTML(self.to_html()))\n        else:\n            # create temporal file\n            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n                # save html\n                self.save(temp_file.name)\n                # open the file\n                webbrowser.open(r\"file:///\" + temp_file.name)\n\n    def to_json(self) -&gt; str:\n        \"\"\"Convert data to json.\"\"\"\n        raise NotImplementedError\n\n    def to_html(self) -&gt; str:\n        \"\"\"Convert data to html.\"\"\"\n        # generate unique dom uids\n        dom_id = \"#x\" + uuid.uuid4().hex\n\n        # get path to the pathpy templates\n        template_dir = os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"_d3js/templates\"),\n        )\n\n        # get d3js version\n        local = self.config.get(\"d3js_local\", False)\n        if local:\n            d3js = os.path.join(template_dir, \"d3.v5.min.js\")\n        else:\n            d3js = \"https://d3js.org/d3.v5.min.js\"\n\n        # get template files\n        with open(os.path.join(template_dir, f\"{self._kind}.js\")) as template:\n            js_template = template.read()\n\n        with open(os.path.join(template_dir, \"setup.js\")) as template:\n            setup_template = template.read()\n\n        with open(os.path.join(template_dir, \"styles.css\")) as template:\n            css_template = template.read()\n\n        # load custom template\n        _template = self.config.get(\"template\", None)\n        if _template and os.path.isfile(_template):\n            with open(_template) as template:\n                js_template = template.read()\n\n        # load custom css template\n        _template = self.config.get(\"css\", None)\n        if _template and os.path.isfile(_template):\n            with open(_template) as template:\n                css_template += template.read()\n\n        # update config\n        self.config[\"selector\"] = dom_id\n        data = self.to_json()\n\n        # generate html file\n        html = \"&lt;style&gt;\\n\" + css_template + \"\\n&lt;/style&gt;\\n\"\n\n        # div environment for the plot object\n        html += f'\\n&lt;div id = \"{dom_id[1:]}\"&gt; &lt;/div&gt;\\n'\n\n        # add d3js library\n        html += f'&lt;script charset=\"utf-8\" src=\"{d3js}\"&gt;&lt;/script&gt;\\n'\n\n        # start JavaScript\n        html += '&lt;script charset=\"utf-8\"&gt;\\n'\n\n        # add setup code to run d3js in multiple environments\n        html += Template(setup_template).substitute(d3js=d3js)\n\n        # start d3 environment\n        html += \"require(['d3'], function(d3){ //START\\n\"\n\n        # add data and config\n        html += f\"const data = {data}\\n\"\n        html += f\"const config = {json.dumps(self.config)}\\n\"\n\n        # add JavaScript\n        html += js_template\n\n        # end d3 environment\n        html += \"\\n}); //END\\n\"\n\n        # end JavaScript\n        html += \"\\n&lt;/script&gt;\"\n\n        return html\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    with open(filename, \"w+\") as new:\n        new.write(self.to_html())\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:\n    \"\"\"Show the plot on the device.\"\"\"\n    if config[\"environment\"][\"interactive\"]:\n        from IPython.display import display_html, HTML\n\n        display_html(HTML(self.to_html()))\n    else:\n        # create temporal file\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            # save html\n            self.save(temp_file.name)\n            # open the file\n            webbrowser.open(r\"file:///\" + temp_file.name)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.to_html","title":"<code>to_html</code>","text":"<p>Convert data to html.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def to_html(self) -&gt; str:\n    \"\"\"Convert data to html.\"\"\"\n    # generate unique dom uids\n    dom_id = \"#x\" + uuid.uuid4().hex\n\n    # get path to the pathpy templates\n    template_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)),\n        os.path.normpath(\"_d3js/templates\"),\n    )\n\n    # get d3js version\n    local = self.config.get(\"d3js_local\", False)\n    if local:\n        d3js = os.path.join(template_dir, \"d3.v5.min.js\")\n    else:\n        d3js = \"https://d3js.org/d3.v5.min.js\"\n\n    # get template files\n    with open(os.path.join(template_dir, f\"{self._kind}.js\")) as template:\n        js_template = template.read()\n\n    with open(os.path.join(template_dir, \"setup.js\")) as template:\n        setup_template = template.read()\n\n    with open(os.path.join(template_dir, \"styles.css\")) as template:\n        css_template = template.read()\n\n    # load custom template\n    _template = self.config.get(\"template\", None)\n    if _template and os.path.isfile(_template):\n        with open(_template) as template:\n            js_template = template.read()\n\n    # load custom css template\n    _template = self.config.get(\"css\", None)\n    if _template and os.path.isfile(_template):\n        with open(_template) as template:\n            css_template += template.read()\n\n    # update config\n    self.config[\"selector\"] = dom_id\n    data = self.to_json()\n\n    # generate html file\n    html = \"&lt;style&gt;\\n\" + css_template + \"\\n&lt;/style&gt;\\n\"\n\n    # div environment for the plot object\n    html += f'\\n&lt;div id = \"{dom_id[1:]}\"&gt; &lt;/div&gt;\\n'\n\n    # add d3js library\n    html += f'&lt;script charset=\"utf-8\" src=\"{d3js}\"&gt;&lt;/script&gt;\\n'\n\n    # start JavaScript\n    html += '&lt;script charset=\"utf-8\"&gt;\\n'\n\n    # add setup code to run d3js in multiple environments\n    html += Template(setup_template).substitute(d3js=d3js)\n\n    # start d3 environment\n    html += \"require(['d3'], function(d3){ //START\\n\"\n\n    # add data and config\n    html += f\"const data = {data}\\n\"\n    html += f\"const config = {json.dumps(self.config)}\\n\"\n\n    # add JavaScript\n    html += js_template\n\n    # end d3 environment\n    html += \"\\n}); //END\\n\"\n\n    # end JavaScript\n    html += \"\\n&lt;/script&gt;\"\n\n    return html\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/core/#pathpyG.visualisations._d3js.core.D3jsPlot.to_json","title":"<code>to_json</code>","text":"<p>Convert data to json.</p> Source code in <code>src/pathpyG/visualisations/_d3js/core.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Convert data to json.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/","title":"network_plots","text":"<p>Network plots with d3js.</p>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._d3js.core.D3jsPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>class NetworkPlot(D3jsPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.data = data\n        self.config = kwargs\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Clen up data.\"\"\"\n        self.config.pop(\"node_cmap\", None)\n        self.config.pop(\"edge_cmap\", None)\n        for node in self.data[\"nodes\"]:\n            node.pop(\"x\", None)\n            node.pop(\"y\", None)\n\n    def to_json(self) -&gt; Any:\n        \"\"\"Convert data to json.\"\"\"\n        return json.dumps(self.data)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.data = data\n    self.config = kwargs\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Clen up data.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Clen up data.\"\"\"\n    self.config.pop(\"node_cmap\", None)\n    self.config.pop(\"edge_cmap\", None)\n    for node in self.data[\"nodes\"]:\n        node.pop(\"x\", None)\n        node.pop(\"y\", None)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.NetworkPlot.to_json","title":"<code>to_json</code>","text":"<p>Convert data to json.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>def to_json(self) -&gt; Any:\n    \"\"\"Convert data to json.\"\"\"\n    return json.dumps(self.data)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._d3js.network_plots.NetworkPlot</code></p> <p>Network plot class for a temporal network.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a temporal network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/network_plots/#pathpyG.visualisations._d3js.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._d3js.network_plots.NetworkPlot</code></p> <p>Network plot class for a temporal network.</p> Source code in <code>src/pathpyG/visualisations/_d3js/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a temporal network.\"\"\"\n\n    _kind = \"temporal\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/","title":"_matplotlib","text":"<p>Initialize matplotlib plotting functions.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/#pathpyG.visualisations._matplotlib.plot","title":"<code>plot</code>","text":"<p>Plot function.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/__init__.py</code> <pre><code>def plot(data: dict, kind: str = \"network\", **kwargs: Any) -&gt; Any:\n    \"\"\"Plot function.\"\"\"\n    return PLOT_CLASSES[kind](data, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/","title":"core","text":"<p>Generic matplotlib plot class.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot","title":"<code>MatplotlibPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Base class for plotting matplotlib objects.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>class MatplotlibPlot(PathPyPlot):\n    \"\"\"Base class for plotting matplotlib objects.\"\"\"\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:  # type: ignore\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        self.to_fig().savefig(filename)\n\n    def show(self, **kwargs: Any) -&gt; None:  # type: ignore\n        \"\"\"Show the plot on the device.\"\"\"\n        self.to_fig().show()\n\n    def to_fig(self) -&gt; Any:  # type: ignore\n        \"\"\"Convert to matplotlib figure.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:  # type: ignore\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    self.to_fig().savefig(filename)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:  # type: ignore\n    \"\"\"Show the plot on the device.\"\"\"\n    self.to_fig().show()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/core/#pathpyG.visualisations._matplotlib.core.MatplotlibPlot.to_fig","title":"<code>to_fig</code>","text":"<p>Convert to matplotlib figure.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/core.py</code> <pre><code>def to_fig(self) -&gt; Any:  # type: ignore\n    \"\"\"Convert to matplotlib figure.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/","title":"network_plots","text":"<p>Network plots with matplotlib.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._matplotlib.core.MatplotlibPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>class NetworkPlot(MatplotlibPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.data = data\n        self.config = kwargs\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Clen up data.\"\"\"\n        self._compute_node_data()\n        self._compute_edge_data()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the nodes.\"\"\"\n        default = {\n            \"uid\": None,\n            \"x\": 0,\n            \"y\": 0,\n            \"size\": 30,\n            \"color\": \"blue\",\n            \"opacity\": 1.0,\n        }\n\n        nodes: dict = {key: [] for key in default}\n\n        for node in self.data[\"nodes\"]:\n            for key, value in default.items():\n                nodes[key].append(node.get(key, value))\n\n        self.data[\"nodes\"] = nodes\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the edges.\"\"\"\n        default = {\n            \"uid\": None,\n            \"size\": 5,\n            \"color\": \"red\",\n            \"opacity\": 1.0,\n        }\n\n        edges: dict = {**{key: [] for key in default}, **{\"line\": []}}\n\n        for edge in self.data[\"edges\"]:\n            source = self.data[\"nodes\"][\"uid\"].index(edge.get(\"source\"))\n            target = self.data[\"nodes\"][\"uid\"].index(edge.get(\"target\"))\n            edges[\"line\"].append(\n                [\n                    (self.data[\"nodes\"][\"x\"][source], self.data[\"nodes\"][\"x\"][target]),\n                    (self.data[\"nodes\"][\"y\"][source], self.data[\"nodes\"][\"y\"][target]),\n                ]\n            )\n\n            for key, value in default.items():\n                edges[key].append(edge.get(key, value))\n\n        self.data[\"edges\"] = edges\n\n    def to_fig(self) -&gt; Any:\n        \"\"\"Convert data to figure.\"\"\"\n        import matplotlib.pyplot as plt\n\n        fig, ax = plt.subplots()\n        ax.set_axis_off()\n\n        # plot edges\n        for i in range(len(self.data[\"edges\"][\"uid\"])):\n            ax.plot(\n                *self.data[\"edges\"][\"line\"][i],\n                color=self.data[\"edges\"][\"color\"][i],\n                alpha=self.data[\"edges\"][\"opacity\"][i],\n                zorder=1,\n            )\n\n        # plot nodes\n        ax.scatter(\n            self.data[\"nodes\"][\"x\"],\n            self.data[\"nodes\"][\"y\"],\n            s=self.data[\"nodes\"][\"size\"],\n            c=self.data[\"nodes\"][\"color\"],\n            alpha=self.data[\"nodes\"][\"opacity\"],\n            zorder=2,\n        )\n        return plt\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.data = data\n    self.config = kwargs\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Clen up data.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Clen up data.\"\"\"\n    self._compute_node_data()\n    self._compute_edge_data()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.NetworkPlot.to_fig","title":"<code>to_fig</code>","text":"<p>Convert data to figure.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def to_fig(self) -&gt; Any:\n    \"\"\"Convert data to figure.\"\"\"\n    import matplotlib.pyplot as plt\n\n    fig, ax = plt.subplots()\n    ax.set_axis_off()\n\n    # plot edges\n    for i in range(len(self.data[\"edges\"][\"uid\"])):\n        ax.plot(\n            *self.data[\"edges\"][\"line\"][i],\n            color=self.data[\"edges\"][\"color\"][i],\n            alpha=self.data[\"edges\"][\"opacity\"][i],\n            zorder=1,\n        )\n\n    # plot nodes\n    ax.scatter(\n        self.data[\"nodes\"][\"x\"],\n        self.data[\"nodes\"][\"y\"],\n        s=self.data[\"nodes\"][\"size\"],\n        c=self.data[\"nodes\"][\"color\"],\n        alpha=self.data[\"nodes\"][\"opacity\"],\n        zorder=2,\n    )\n    return plt\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._matplotlib.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._matplotlib.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"temporal\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/network_plots/#pathpyG.visualisations._matplotlib.network_plots.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/","title":"_tikz","text":"<p>Initialize tikz plotting functions.</p>"},{"location":"reference/pathpyG/visualisations/_tikz/#pathpyG.visualisations._tikz.plot","title":"<code>plot</code>","text":"<p>Plot function.</p> Source code in <code>src/pathpyG/visualisations/_tikz/__init__.py</code> <pre><code>def plot(data: dict, kind: str = \"network\", **kwargs: Any) -&gt; Any:\n    \"\"\"Plot function.\"\"\"\n    return PLOT_CLASSES[kind](data, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/","title":"core","text":""},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot","title":"<code>TikzPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot.PathPyPlot</code></p> <p>Base class for plotting d3js objects.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>class TikzPlot(PathPyPlot):\n    \"\"\"Base class for plotting d3js objects.\"\"\"\n\n    def __init__(self, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize plot class.\"\"\"\n        super().__init__()\n        if kwargs:\n            self.config = kwargs\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        raise NotImplementedError\n\n    def save(self, filename: str, **kwargs: Any) -&gt; None:\n        \"\"\"Save the plot to the hard drive.\"\"\"\n        if filename.endswith(\"tex\"):\n            with open(filename, \"w+\") as new:\n                new.write(self.to_tex())\n        elif filename.endswith(\"pdf\"):\n            # compile temporary pdf\n            temp_file, temp_dir = self.compile_pdf()\n            # Copy a file with new name\n            shutil.copy(temp_file, filename)\n            # remove the temporal directory\n            shutil.rmtree(temp_dir)\n\n        else:\n            raise NotImplementedError\n\n    def show(self, **kwargs: Any) -&gt; None:\n        \"\"\"Show the plot on the device.\"\"\"\n        # compile temporary pdf\n        temp_file, temp_dir = self.compile_pdf()\n\n        if config[\"environment\"][\"interactive\"]:\n            from IPython.display import IFrame, display\n\n            # open the file in the notebook\n            display(IFrame(temp_file, width=600, height=300))\n        else:\n            # open the file in the webbrowser\n            webbrowser.open(r\"file:///\" + temp_file)\n\n        # Wait for .1 second before temp file is deleted\n        time.sleep(0.1)\n\n        # remove the temporal directory\n        shutil.rmtree(temp_dir)\n\n    def compile_pdf(self) -&gt; tuple:\n        \"\"\"Compile pdf from tex.\"\"\"\n        # basename\n        basename = \"default\"\n        # get current directory\n        current_dir = os.getcwd()\n\n        # template directory\n        tikz_dir = str(\n            os.path.join(\n                os.path.dirname(os.path.dirname(__file__)),\n                os.path.normpath(\"templates\"),\n                \"tikz-network.sty\",\n            )\n        )\n\n        # get temporal directory\n        temp_dir = tempfile.mkdtemp()\n\n        # copy tikz-network to temporal directory\n        shutil.copy(tikz_dir, temp_dir)\n\n        # change to output dir\n        os.chdir(temp_dir)\n\n        # save the tex file\n        self.save(basename + \".tex\")\n\n        # latex compiler\n        command = [\n            \"latexmk\",\n            \"--pdf\",\n            \"-shell-escape\",\n            \"--interaction=nonstopmode\",\n            basename + \".tex\",\n        ]\n\n        try:\n            subprocess.check_output(command, stderr=subprocess.STDOUT)\n        except Exception:\n            # If compiler does not exist, try next in the list\n            logger.error(\"No latexmk compiler found\")\n            raise AttributeError\n        finally:\n            # change back to the current directory\n            os.chdir(current_dir)\n\n        # return the name of the folder and temp pdf file\n        return (os.path.join(temp_dir, basename + \".pdf\"), temp_dir)\n\n    def to_tex(self) -&gt; str:\n        \"\"\"Convert data to tex.\"\"\"\n        # get path to the pathpy templates\n        template_dir = os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"_tikz/templates\"),\n        )\n\n        # get template files\n        with open(os.path.join(template_dir, f\"{self._kind}.tex\")) as template:\n            tex_template = template.read()\n\n        # generate data\n        data = self.to_tikz()\n\n        # fill template with data\n        tex = Template(tex_template).substitute(\n            classoptions=self.config.get(\"latex_class_options\", \"\"),\n            width=self.config.get(\"width\", \"6cm\"),\n            height=self.config.get(\"height\", \"6cm\"),\n            tikz=data,\n        )\n\n        return tex\n\n    def to_tikz(self) -&gt; str:\n        \"\"\"Convert data to tikz.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize plot class.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def __init__(self, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize plot class.\"\"\"\n    super().__init__()\n    if kwargs:\n        self.config = kwargs\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.compile_pdf","title":"<code>compile_pdf</code>","text":"<p>Compile pdf from tex.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def compile_pdf(self) -&gt; tuple:\n    \"\"\"Compile pdf from tex.\"\"\"\n    # basename\n    basename = \"default\"\n    # get current directory\n    current_dir = os.getcwd()\n\n    # template directory\n    tikz_dir = str(\n        os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"templates\"),\n            \"tikz-network.sty\",\n        )\n    )\n\n    # get temporal directory\n    temp_dir = tempfile.mkdtemp()\n\n    # copy tikz-network to temporal directory\n    shutil.copy(tikz_dir, temp_dir)\n\n    # change to output dir\n    os.chdir(temp_dir)\n\n    # save the tex file\n    self.save(basename + \".tex\")\n\n    # latex compiler\n    command = [\n        \"latexmk\",\n        \"--pdf\",\n        \"-shell-escape\",\n        \"--interaction=nonstopmode\",\n        basename + \".tex\",\n    ]\n\n    try:\n        subprocess.check_output(command, stderr=subprocess.STDOUT)\n    except Exception:\n        # If compiler does not exist, try next in the list\n        logger.error(\"No latexmk compiler found\")\n        raise AttributeError\n    finally:\n        # change back to the current directory\n        os.chdir(current_dir)\n\n    # return the name of the folder and temp pdf file\n    return (os.path.join(temp_dir, basename + \".pdf\"), temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.generate","title":"<code>generate</code>","text":"<p>Generate the plot.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate the plot.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.save","title":"<code>save</code>","text":"<p>Save the plot to the hard drive.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def save(self, filename: str, **kwargs: Any) -&gt; None:\n    \"\"\"Save the plot to the hard drive.\"\"\"\n    if filename.endswith(\"tex\"):\n        with open(filename, \"w+\") as new:\n            new.write(self.to_tex())\n    elif filename.endswith(\"pdf\"):\n        # compile temporary pdf\n        temp_file, temp_dir = self.compile_pdf()\n        # Copy a file with new name\n        shutil.copy(temp_file, filename)\n        # remove the temporal directory\n        shutil.rmtree(temp_dir)\n\n    else:\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.show","title":"<code>show</code>","text":"<p>Show the plot on the device.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def show(self, **kwargs: Any) -&gt; None:\n    \"\"\"Show the plot on the device.\"\"\"\n    # compile temporary pdf\n    temp_file, temp_dir = self.compile_pdf()\n\n    if config[\"environment\"][\"interactive\"]:\n        from IPython.display import IFrame, display\n\n        # open the file in the notebook\n        display(IFrame(temp_file, width=600, height=300))\n    else:\n        # open the file in the webbrowser\n        webbrowser.open(r\"file:///\" + temp_file)\n\n    # Wait for .1 second before temp file is deleted\n    time.sleep(0.1)\n\n    # remove the temporal directory\n    shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.to_tex","title":"<code>to_tex</code>","text":"<p>Convert data to tex.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def to_tex(self) -&gt; str:\n    \"\"\"Convert data to tex.\"\"\"\n    # get path to the pathpy templates\n    template_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)),\n        os.path.normpath(\"_tikz/templates\"),\n    )\n\n    # get template files\n    with open(os.path.join(template_dir, f\"{self._kind}.tex\")) as template:\n        tex_template = template.read()\n\n    # generate data\n    data = self.to_tikz()\n\n    # fill template with data\n    tex = Template(tex_template).substitute(\n        classoptions=self.config.get(\"latex_class_options\", \"\"),\n        width=self.config.get(\"width\", \"6cm\"),\n        height=self.config.get(\"height\", \"6cm\"),\n        tikz=data,\n    )\n\n    return tex\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/core/#pathpyG.visualisations._tikz.core.TikzPlot.to_tikz","title":"<code>to_tikz</code>","text":"<p>Convert data to tikz.</p> Source code in <code>src/pathpyG/visualisations/_tikz/core.py</code> <pre><code>def to_tikz(self) -&gt; str:\n    \"\"\"Convert data to tikz.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/","title":"network_plots","text":"<p>Network plots with tikz.</p>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._tikz.core.TikzPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>class NetworkPlot(TikzPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.data = data\n        self.config = kwargs\n        self.config[\"width\"] = self.config.pop(\"width\", 6)\n        self.config[\"height\"] = self.config.pop(\"height\", 6)\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Clen up data.\"\"\"\n        self._compute_node_data()\n        self._compute_edge_data()\n        self._update_layout()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the nodes.\"\"\"\n        default: set = {\"uid\", \"x\", \"y\", \"size\", \"color\", \"opacity\"}\n        mapping: dict = {}\n\n        for node in self.data[\"nodes\"]:\n            for key in list(node):\n                if key in mapping:\n                    node[mapping[key]] = node.pop(key)\n                if key not in default:\n                    node.pop(key, None)\n\n            color = node.get(\"color\", None)\n            if isinstance(color, str) and \"#\" in color:\n                color = hex_to_rgb(color)\n                node[\"color\"] = f\"{{{color[0]},{color[1]},{color[2]}}}\"\n                node[\"RGB\"] = True\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate the data structure for the edges.\"\"\"\n        default: set = {\"uid\", \"source\", \"target\", \"lw\", \"color\", \"opacity\"}\n        mapping: dict = {\"size\": \"lw\"}\n\n        for edge in self.data[\"edges\"]:\n            for key in list(edge):\n                if key in mapping:\n                    edge[mapping[key]] = edge.pop(key)\n                if key not in default:\n                    edge.pop(key, None)\n\n            color = edge.get(\"color\", None)\n            if isinstance(color, str) and \"#\" in color:\n                color = hex_to_rgb(color)\n                edge[\"color\"] = f\"{{{color[0]},{color[1]},{color[2]}}}\"\n                edge[\"RGB\"] = True\n\n    def _update_layout(self, default_size: float = 0.6) -&gt; None:\n        \"\"\"Update the layout.\"\"\"\n        layout = self.config.get(\"layout\")\n\n        if layout is None:\n            return\n\n        # get data\n        layout = {n[\"uid\"]: (n[\"x\"], n[\"y\"]) for n in self.data[\"nodes\"]}\n        sizes = {n[\"uid\"]: n.get(\"size\", default_size) for n in self.data[\"nodes\"]}\n\n        # get config values\n        width = self.config[\"width\"]\n        height = self.config[\"height\"]\n        keep_aspect_ratio = self.config.get(\"keep_aspect_ratio\", True)\n        margin = self.config.get(\"margin\", 0.0)\n        margins = {\"top\": margin, \"left\": margin, \"bottom\": margin, \"right\": margin}\n\n        # calculate the scaling ratio\n        x_ratio = float(\"inf\")\n        y_ratio = float(\"inf\")\n\n        # calculate absolute min and max coordinates\n        x_absolute = []\n        y_absolute = []\n        for uid, (_x, _y) in layout.items():\n            _s = sizes[uid] / 2\n            x_absolute.extend([_x - _s, _x + _s])\n            y_absolute.extend([_y - _s, _y + _s])\n\n        # calculate min and max center coordinates\n        x_values, y_values = zip(*layout.values())\n        x_min, x_max = min(x_values), max(x_values)\n        y_min, y_max = min(y_values), max(y_values)\n\n        # change margins\n        margins[\"left\"] += abs(x_min - min(x_absolute))\n        margins[\"bottom\"] += abs(y_min - min(y_absolute))\n        margins[\"top\"] += abs(y_max - max(y_absolute))\n        margins[\"right\"] += abs(x_max - max(x_absolute))\n\n        if x_max - x_min &gt; 0:\n            x_ratio = (width - margins[\"left\"] - margins[\"right\"]) / (x_max - x_min)\n        if y_max - y_min &gt; 0:\n            y_ratio = (height - margins[\"top\"] - margins[\"bottom\"]) / (y_max - y_min)\n\n        if keep_aspect_ratio:\n            scaling = (min(x_ratio, y_ratio), min(x_ratio, y_ratio))\n        else:\n            scaling = (x_ratio, y_ratio)\n\n        if scaling[0] == float(\"inf\"):\n            scaling = (1, scaling[1])\n        if scaling[1] == float(\"inf\"):\n            scaling = (scaling[0], 1)\n\n        x_values = []\n        y_values = []\n\n        # apply scaling to the points\n        _layout = {n: (x * scaling[0], y * scaling[1]) for n, (x, y) in layout.items()}\n\n        # find min and max values of the points\n        x_values, y_values = zip(*_layout.values())\n        x_min, x_max = min(x_values), max(x_values)\n        y_min, y_max = min(y_values), max(y_values)\n\n        # calculate the translation\n        translation = (\n            ((width - margins[\"left\"] - margins[\"right\"]) / 2 + margins[\"left\"])\n            - ((x_max - x_min) / 2 + x_min),\n            ((height - margins[\"top\"] - margins[\"bottom\"]) / 2 + margins[\"bottom\"])\n            - ((y_max - y_min) / 2 + y_min),\n        )\n\n        # apply translation to the points\n        _layout = {\n            n: (x + translation[0], y + translation[1]) for n, (x, y) in _layout.items()\n        }\n\n        # update node position for the plot\n        for node in self.data[\"nodes\"]:\n            node[\"x\"], node[\"y\"] = _layout[node[\"uid\"]]\n\n    def to_tikz(self) -&gt; str:\n        \"\"\"Convert to Tex.\"\"\"\n\n        def _add_args(args: dict):\n            string = \"\"\n            for key, value in args.items():\n                string += f\",{key}\" if value is True else f\",{key}={value}\"\n            return string\n\n        tikz = \"\"\n        for node in self.data[\"nodes\"]:\n            uid = node.pop(\"uid\")\n            string = \"\\\\Vertex[\"\n            string += _add_args(node)\n            string += \"]{{{}}}\\n\".format(uid)\n            tikz += string\n\n        for edge in self.data[\"edges\"]:\n            uid = edge.pop(\"uid\")\n            source = edge.pop(\"source\")\n            target = edge.pop(\"target\")\n            string = \"\\\\Edge[\"\n            string += _add_args(edge)\n            string += \"]({})({})\\n\".format(source, target)\n            tikz += string\n        return tikz\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    super().__init__()\n    self.data = data\n    self.config = kwargs\n    self.config[\"width\"] = self.config.pop(\"width\", 6)\n    self.config[\"height\"] = self.config.pop(\"height\", 6)\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Clen up data.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Clen up data.\"\"\"\n    self._compute_node_data()\n    self._compute_edge_data()\n    self._update_layout()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.NetworkPlot.to_tikz","title":"<code>to_tikz</code>","text":"<p>Convert to Tex.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def to_tikz(self) -&gt; str:\n    \"\"\"Convert to Tex.\"\"\"\n\n    def _add_args(args: dict):\n        string = \"\"\n        for key, value in args.items():\n            string += f\",{key}\" if value is True else f\",{key}={value}\"\n        return string\n\n    tikz = \"\"\n    for node in self.data[\"nodes\"]:\n        uid = node.pop(\"uid\")\n        string = \"\\\\Vertex[\"\n        string += _add_args(node)\n        string += \"]{{{}}}\\n\".format(uid)\n        tikz += string\n\n    for edge in self.data[\"edges\"]:\n        uid = edge.pop(\"uid\")\n        source = edge.pop(\"source\")\n        target = edge.pop(\"target\")\n        string = \"\\\\Edge[\"\n        string += _add_args(edge)\n        string += \"]({})({})\\n\".format(source, target)\n        tikz += string\n    return tikz\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.StaticNetworkPlot","title":"<code>StaticNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._tikz.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>class StaticNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"static\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations._tikz.network_plots.NetworkPlot</code></p> <p>Network plot class for a static network.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Network plot class for a static network.\"\"\"\n\n    _kind = \"temporal\"\n\n    def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/network_plots/#pathpyG.visualisations._tikz.network_plots.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot class.</p> Source code in <code>src/pathpyG/visualisations/_tikz/network_plots.py</code> <pre><code>def __init__(self, data: dict, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot class.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"tutorial/basic_concepts/","title":"Basic Concepts","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[2]: Copied! <pre>import torch\nimport torch_geometric as pyG\nfrom torch_geometric.data import Data\n\nimport pathpyG as pp\npp.config['torch']['device'] = 'cpu'\n</pre> import torch import torch_geometric as pyG from torch_geometric.data import Data  import pathpyG as pp pp.config['torch']['device'] = 'cpu' In\u00a0[2]: Copied! <pre>d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]]))\ng = pp.Graph(d)\nprint(g)\n</pre> d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]])) g = pp.Graph(d) print(g) <pre>Directed graph with 3 nodes and 3 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>If we do not need additional node or edge attributes, we can use the class function <code>Graph.from_edge_index</code> to directly create a graph based on an edge index:</p> In\u00a0[3]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]))\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]])) print(g) <pre>Directed graph with 3 nodes and 3 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>In both cases, the <code>Graph</code> instance has a property <code>g.data</code> that stores a <code>pyG</code> <code>Data</code> object that includes the edge index as well as any further node-, edge- or graph-level attributes.</p> In\u00a0[4]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 3], num_nodes=3)\n</pre> <p>Note that the <code>edge_index</code> is actually of type <code>pyG.EdgeIndex</code>, which is a subclass of <code>torch.Tensor</code>. Any tensor passed as an edge index in the constructor of <code>Graph</code> will automatically be converted to an <code>EdgeIndex</code> instance, as this allows us to provide efficient edge traveral routines. To support this, the edge index will be automatically sorted by row when the <code>Graph</code> object is created. If you want to avoid this, you can directly pass an already sorted <code>EdgeIndex</code> object in the <code>Data</code> object in the constructor or in the <code>from_edge_index</code> class function.</p> In\u00a0[5]: Copied! <pre>print(g.data.edge_index)\n</pre> print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1],\n           [2, 1, 2]], sparse_size=(2, 3), nnz=3, sort_order=row)\n</pre> <p>We can use the generators <code>nodes</code> and <code>edges</code> to iterate through the nodes and edges of a graph as follows:</p> In\u00a0[6]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>0\n1\n2\n(0, 2)\n(0, 1)\n(1, 2)\n</pre> <p>While the index-based representation of nodes allows for efficient tensor-based operations, it is often convenient to use string identifiers for nodes. To simplify the handling of graphs with node labels, <code>pathpyG</code> provides a class <code>IndexMap</code> that transparently maps string identifiers to indices. For our small example graph, we can create an <code>IndexMap</code> that associates node indices with string IDs. For our example, we can create a mapping as follows:</p> In\u00a0[7]: Copied! <pre>m = pp.IndexMap(['a', 'b', 'c'])\nprint(m)\n</pre> m = pp.IndexMap(['a', 'b', 'c']) print(m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n</pre> <p>We could now use the functions <code>IndexMap.to_id</code> or <code>IndexMap.to_idx</code> to map a node to an index or an ID:</p> In\u00a0[9]: Copied! <pre>m.to_id(0)\n</pre> m.to_id(0) Out[9]: <pre>'a'</pre> In\u00a0[10]: Copied! <pre>m.to_idx('b')\n</pre> m.to_idx('b') Out[10]: <pre>1</pre> <p>To make this mapping transparent for the user, we can add the mapping to <code>Graph</code> object, either by passing it in the constructor or by setting the <code>mapping</code> attribute of an existing instance.</p> In\u00a0[11]: Copied! <pre>g.mapping = m\n</pre> g.mapping = m <p>If we now iterate through the nodes and edges of the graph, we get:</p> In\u00a0[12]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>a\nb\nc\n('a', 'c')\n('a', 'b')\n('b', 'c')\n</pre> <p>We can achieve the same result if we pass the <code>IndexMap</code> object in the constructor of a graph. This transparently applies the mapping in all future function calls.</p> In\u00a0[14]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), mapping=m)\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), mapping=m) print(g) <pre>Directed graph with 3 nodes and 3 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Above, we have created a graph based on an edge index tensor and we then additionally applied a mapping that we manually defined. However, we often have data in the form on an edge list, where edges are given as tuples of non-numeric node identifiers. The class function <code>Graph.from_edge_list</code> simplifies the construction of a <code>Graph</code> from such edge lists. This will automatically generate an internal integer-based representation of the edge index, as well as the associated <code>IndexMap</code>:</p> In\u00a0[15]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')])\nprint(g)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')]) print(g) <pre>Directed graph with 3 nodes and 3 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[16]: Copied! <pre>print(g.mapping)\n</pre> print(g.mapping) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n</pre> In\u00a0[18]: Copied! <pre>g.get_successors(0)\n</pre> g.get_successors(0) Out[18]: <pre>tensor([1, 2])</pre> In\u00a0[19]: Copied! <pre>g.get_predecessors(0)\n</pre> g.get_predecessors(0) Out[19]: <pre>tensor([], dtype=torch.int64)</pre> <p>Note that, even if a mapping is defined, the <code>get_successors</code> and <code>get_predecessors</code> functions always return a tensor with node indices, rather than node IDs. This is useful to support fast tensor-based operations on the list of successors and predecessors. We could always manually map the node indices using the <code>IndexMap</code> object defined in the <code>mapping</code> attribute.</p> <p>We can also use the <code>successors</code> and <code>predecessors</code> generators of the <code>Graph</code> object, which -- if an ID-Index mapping is defined - yield the string labels of successor or predecessor nodes for a given node (also identified by its string label).</p> In\u00a0[20]: Copied! <pre>for v in g.successors('a'):\n    print(v)\n</pre> for v in g.successors('a'):     print(v) <pre>b\nc\n</pre> In\u00a0[21]: Copied! <pre>for v in g.predecessors('c'):\n    print(v)\n</pre> for v in g.predecessors('c'):     print(v) <pre>a\nb\n</pre> <p>We can easily check, whether an edge exists in the graph:</p> In\u00a0[22]: Copied! <pre>g.is_edge('a', 'b')\n</pre> g.is_edge('a', 'b') Out[22]: <pre>True</pre> <p>Alternatively, we can use the following code to check whether node <code>b</code> is a successor of <code>a</code></p> In\u00a0[23]: Copied! <pre>'b' in g.successors('a')\n</pre> 'b' in g.successors('a') Out[23]: <pre>True</pre> <p>By default, a graph object in <code>pathpyG</code> is directed, i.e. for the graph above, the edge <code>(b,a)</code> does not exist, which we can verify as follows:</p> In\u00a0[24]: Copied! <pre>'a' in g.successors('b')\n</pre> 'a' in g.successors('b') Out[24]: <pre>False</pre> <p>To check the (directed) in- and out-degrees of nodes, we can use the properties <code>in_degrees</code> and <code>out_degrees</code>, which return a dictionary that maps node IDs to their degrees:</p> In\u00a0[25]: Copied! <pre>g.in_degrees\n</pre> g.in_degrees Out[25]: <pre>{'a': 0, 'b': 1, 'c': 2}</pre> In\u00a0[26]: Copied! <pre>g.in_degrees['b']\n</pre> g.in_degrees['b'] Out[26]: <pre>1</pre> In\u00a0[27]: Copied! <pre>g.in_degrees['c']\n</pre> g.in_degrees['c'] Out[27]: <pre>2</pre> In\u00a0[18]: Copied! <pre>g.data\n</pre> g.data Out[18]: <pre>Data(edge_index=[2, 3], num_nodes=3)</pre> <p>Importantly, irrespective of how we have generated the graph object, the actual node and edge data are always stored as a <code>pyG</code> data object. This allows us to use the full power of <code>torch</code> and <code>pyG</code>, including the application of transforms, splits, or any easy migration between CPU and GPU-based computation. In general, <code>pathpyG</code> will use the device specified in the <code>torch.device</code> configuration (see above) whenver it internally creates a torch tensor. Since above, we have specified the <code>cpu</code> device, the data object of the graph generated above will reside in main memory:</p> In\u00a0[28]: Copied! <pre>g.data.is_cuda\n</pre> g.data.is_cuda Out[28]: <pre>False</pre> <p>If we instead set the device to <code>cuda</code>, the <code>Data</code> object will internally be created in main memory instead.</p> In\u00a0[49]: Copied! <pre>pp.config['torch']['device'] = 'cuda'\n\ng = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['a','c']])\ng.data.is_cuda\n</pre> pp.config['torch']['device'] = 'cuda'  g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['a','c']]) g.data.is_cuda Out[49]: <pre>True</pre> In\u00a0[50]: Copied! <pre>g.data['node_class'] = torch.tensor([[0], [0], [1]], device=pp.config['torch']['device'])\ng.data['edge_weight'] = torch.tensor([[1], [2], [3]], device=pp.config['torch']['device'])\ng.data['feature'] = torch.tensor([3, 2], device=pp.config['torch']['device'])\n</pre> g.data['node_class'] = torch.tensor([[0], [0], [1]], device=pp.config['torch']['device']) g.data['edge_weight'] = torch.tensor([[1], [2], [3]], device=pp.config['torch']['device']) g.data['feature'] = torch.tensor([3, 2], device=pp.config['torch']['device']) <p>Once we have added attributes to nodes, edges, or the graph, those attributes, along with their type and shape will be shown when you print a string representation of the graph object:</p> In\u00a0[51]: Copied! <pre>print(g)\n</pre> print(g) <pre>Directed graph with 3 nodes and 3 edges\n\nNode attributes\n\tnode_class\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tfeature\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\n</pre> <p>To simplify the access to attribute values, the <code>Graph</code> class provides getter and setter functions that allow an indexed access based on node identifiers. To access the feature <code>node_feature</code> of node <code>a</code>, we can write:</p> In\u00a0[52]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[52]: <pre>tensor([0], device='cuda:0')</pre> <p>To access the weight of edge <code>(a, b)</code> we can write:</p> In\u00a0[53]: Copied! <pre>g['edge_weight', 'a', 'b']\n</pre> g['edge_weight', 'a', 'b'] Out[53]: <pre>tensor([1], device='cuda:0')</pre> <p>And finally, graph-based attributes can accessed as follows:</p> In\u00a0[54]: Copied! <pre>g['feature']\n</pre> g['feature'] Out[54]: <pre>tensor([3, 2], device='cuda:0')</pre> <p>We can also use the setter functions to change attributes:</p> In\u00a0[55]: Copied! <pre>g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda')\n</pre> g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda') In\u00a0[56]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[56]: <pre>tensor([7], device='cuda:0')</pre> <p>To create a sparse adjacency matrix representations of the topology of a graph, we can use the following function:</p> In\u00a0[57]: Copied! <pre>print(g.get_sparse_adj_matrix())\n</pre> print(g.get_sparse_adj_matrix()) <pre>  (0, 1)\t1.0\n  (0, 2)\t1.0\n  (1, 2)\t1.0\n</pre> <p>This returns a <code>scipy.sparse.coo_matrix</code> object, which can be turned into a dense <code>numpy</code> matrix as follows:</p> In\u00a0[58]: Copied! <pre>print(g.get_sparse_adj_matrix().todense())\n</pre> print(g.get_sparse_adj_matrix().todense()) <pre>[[0. 1. 1.]\n [0. 0. 1.]\n [0. 0. 0.]]\n</pre> <p>By passing the name of the attribute, we can also use edge attributes in the creation of the adjacency matrix. To create a sparse, weighted adjacency matrix that uses the <code>edge_weight</code> attribute of our graph object we can simply write:</p> In\u00a0[59]: Copied! <pre>print(g.get_sparse_adj_matrix(edge_attr='edge_weight').todense())\n</pre> print(g.get_sparse_adj_matrix(edge_attr='edge_weight').todense()) <pre>[[0 1 2]\n [0 0 3]\n [0 0 0]]\n</pre> <p>It is easy to apply GNN models to a graph object. We can add attributes based on one-hot-encodings of nodes and edges as follows:</p> In\u00a0[60]: Copied! <pre>g.add_node_ohe(attr_name='node_ohe_feature_1')\ng.add_node_ohe(attr_name='node_ohe_feature_2', dim=4)\ng.add_edge_ohe(attr_name='edge_ohe_feature_1', dim=5)\nprint(g)\n\nprint(g.data['node_ohe_feature_1'])\nprint(g.data['node_ohe_feature_2'])\nprint(g.data['edge_ohe_feature_1'])\n</pre> g.add_node_ohe(attr_name='node_ohe_feature_1') g.add_node_ohe(attr_name='node_ohe_feature_2', dim=4) g.add_edge_ohe(attr_name='edge_ohe_feature_1', dim=5) print(g)  print(g.data['node_ohe_feature_1']) print(g.data['node_ohe_feature_2']) print(g.data['edge_ohe_feature_1']) <pre>Directed graph with 3 nodes and 3 edges\n\nNode attributes\n\tnode_class\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\tnode_ohe_feature_2\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 4])\n\tnode_ohe_feature_1\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 3])\n\nEdge attributes\n\tedge_ohe_feature_1\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 5])\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tfeature\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\ntensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]], device='cuda:0')\ntensor([[1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 1., 0.]], device='cuda:0')\ntensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.]], device='cuda:0')\n</pre> <p>By default, all graphs in <code>pathpyG</code> are directed. To represent undirected graphs, we must add all edges in both directions. We can use the <code>to_undirected()</code> function to make a directed graph undirected, i.e. to add all (missing) edges that point in the opposite direction. This will automatically duplicate and assign the corresponding edge attributes to the newly formed (directed) edges, i.e. edges are assumed to have the same attributes in both directions.</p> In\u00a0[61]: Copied! <pre>g_u = g.to_undirected()\nprint(g_u)\n</pre> g_u = g.to_undirected() print(g_u) <pre>Undirected graph with 3 nodes and 6 edges\n\nNode attributes\n\tnode_class\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\n\tnode_ohe_feature_2\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 4])\n\tnode_ohe_feature_1\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 3])\n\nEdge attributes\n\tedge_ohe_feature_1\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 5])\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tfeature\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\n</pre> <p>By default, the <code>Graph</code> object can contain multiple identical edges, so the following is possible:</p> In\u00a0[62]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')])\nprint(g.data.edge_index)\n</pre> g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')]) print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1, 2],\n           [1, 1, 2, 0]], device='cuda:0', sparse_size=(3, ?), nnz=4,\n          sort_order=row)\n</pre> <p>It is often convenient, to coalesce multi-edges into weighted single-edges, i.e. in the example above we may prefer a graph where each edge occurs once in the edge index, but the edge <code>a-&gt;b</code> has a weight attribute of two, while the two other edges have one.</p> <p>In <code>pathpyG</code> we can do this as follows:</p> In\u00a0[63]: Copied! <pre>g_w = g.to_weighted_graph()\nprint(g_w.data.edge_index)\nprint(g_w['edge_weight', 'b', 'c'])\nprint(g_w['edge_weight', 'a', 'b'])\nprint(g_w['edge_weight', 'c', 'a'])\n</pre> g_w = g.to_weighted_graph() print(g_w.data.edge_index) print(g_w['edge_weight', 'b', 'c']) print(g_w['edge_weight', 'a', 'b']) print(g_w['edge_weight', 'c', 'a']) <pre>EdgeIndex([[0, 1, 2],\n           [1, 2, 0]], device='cuda:0', sparse_size=(3, 3), nnz=3,\n          sort_order=row)\ntensor(1., device='cuda:0')\ntensor(2., device='cuda:0')\ntensor(1., device='cuda:0')\n</pre> <p>As we will see in a separate notebook focussing on the advanced (temporal) graph visualization features of <code>pathpyG</code>, it is easy to generate (interactive) HTML plots of graphs, that are embedded into jupyter notebooks. You can simply call the <code>pp.plot</code> function on the Graph object:</p> In\u00a0[68]: Copied! <pre>pp.plot(g, edge_color='gray');\n</pre> pp.plot(g, edge_color='gray'); In\u00a0[69]: Copied! <pre>pp.algorithms.centrality.closeness_centrality(g)\n</pre> pp.algorithms.centrality.closeness_centrality(g) Out[69]: <pre>{'a': 0.6666666666666666, 'b': 0.6666666666666666, 'c': 0.6666666666666666}</pre>"},{"location":"tutorial/basic_concepts/#basic-pathpyg-concepts","title":"Basic pathpyG Concepts\u00b6","text":""},{"location":"tutorial/basic_concepts/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/basic_concepts/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>This first step of our multi-stage introductory tutorial introduces the key concepts of <code>pathpyG</code>. While <code>pathpyG</code> targets GPU-accelerated analysis and learning in time series data on temporal graphs, it is also a great tool to represent, analyze and visualize static graphs. For this, it provides a <code>Graph</code> class that is implemented based on the <code>torch_geometric.data.Data</code> object, which has the advantage that we can directly apply <code>pyG</code> transforms and use the underlying data for graph learning tasks.</p> <p>In this basic tutorial you will learn how we can use <code>pathpyG</code> to represent static graphs. We start with basic features to create directed and undirected graphs with node-, edge-, and graph-level attributes. We further discuss how we can calculate node centralities, and how we can read graph data from the <code>netzschleuder</code> database. We finally show how we can implement graph algorithms that are based on a traversal of edges.</p> <p>We first import the modules <code>torch</code>, <code>torch_geometric</code> and <code>pathpyG</code>. By setting the device used by <code>torch</code>, we specify whether we want to run our code on the CPU or on the GPU. For a CPU-based execution, set the <code>torch.device</code> configuration to <code>cpu</code>. Set the device to <code>cuda</code> if you want to run it on the GPU instead.</p>"},{"location":"tutorial/basic_concepts/#creating-graphs","title":"Creating Graphs\u00b6","text":"<p>Let's start by generating a simple, directed graph with three nodes <code>a</code>, <code>b</code>, <code>c</code> and three edges <code>(a,b)</code>, <code>(b,c)</code> and <code>(a,b)</code>. The three nodes <code>a</code>, <code>b</code>, and <code>c</code> can be represented by integer indices $0, 1$ and $2$ respectively. Following the tensor-based representation in <code>pyG</code>, we use an <code>edge_index</code> tensor with shape <code>(2,m)</code> to represent the <code>m</code> edges of a graph. We can then add this to a <code>Data</code> object that can possibly hold additional node and edge attributes, and pass the <code>Data</code> object to the constructor of the <code>Graph</code> class.</p> <p>Using the mapping of node names to indices specified above, the following code generates a directed <code>Graph</code> with three edges <code>(a,c)</code>, <code>(b,c)</code> and <code>(a,b)</code>.</p>"},{"location":"tutorial/basic_concepts/#traversing-graphs","title":"Traversing Graphs\u00b6","text":"<p>The <code>Graph</code> object provides <code>get_successors</code> and <code>get_predecessors</code> functions, which return the indices of nodes that are connected to a node with a given index. Based on the CSR and CSC representations cached for the sorted <code>EdgeIndex</code>, the access of the successors and predecessors is done in constant time, i.e. it does not require us to enumerate the <code>edge_index</code> tensor.</p> <p>For node <code>a</code> with index $0$ in our directed network we obtain:</p>"},{"location":"tutorial/basic_concepts/#node-edge-or-graph-level-attributes","title":"Node-, Edge- or Graph-Level Attributes\u00b6","text":"<p>Real-world graphs often have node-, edge-, or graph-level attributes. In <code>pathpyG</code>, we can simply add attributes as tensors, either by directly assigning them to the <code>pyG</code> data object of an existing graph (or by adding them to the <code>Data</code> object that we pass in the constructor). Following the <code>pyG</code> semantics of attribute names, we must use the prefixes <code>node_</code> and <code>edge_</code> to refer to node- and edge-level attributes. Attributes with other names will be assumed to refer to graph-level attributes.</p>"},{"location":"tutorial/basic_concepts/#node-centralities","title":"Node Centralities\u00b6","text":"<p>To calculate node centralities, we can use a <code>networkx</code> delegate mechanism implemented in the module <code>pathpyG.algorithms.centrality</code>. Simply speaking, you can call any function implented in the networkx centrality module that starts with the string <code>centrality_</code>. The <code>pathpyG</code> will be internally converted to a <code>networkx.DiGraph</code> object, the corresponding centrality function (with all of its parameters) will be called, and the result will be mapped to the nodes based on their IDs.</p> <p>In order to calculate the closeness centralities of all nodes for the graph above, we can call:</p>"},{"location":"tutorial/dbgnn/","title":"Causality-Aware GNNs","text":"In\u00a0[1]: Copied! <pre>%%capture\n!pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[2]: Copied! <pre>import pathpyG as pp\n\nimport torch\nfrom pathpyG.nn.dbgnn import DBGNN\nfrom pathpyG.utils.dbgnn import generate_bipartite_edge_index\nfrom torch_geometric.transforms import RandomNodeSplit\nfrom sklearn.metrics import balanced_accuracy_score\nimport torch_geometric\nfrom torch_geometric.data import Data\nfrom sklearn.manifold import TSNE\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy as sp\n\npp.config['torch']['device'] = 'cpu'\ndevice = pp.config['torch']['device']\n</pre> import pathpyG as pp  import torch from pathpyG.nn.dbgnn import DBGNN from pathpyG.utils.dbgnn import generate_bipartite_edge_index from torch_geometric.transforms import RandomNodeSplit from sklearn.metrics import balanced_accuracy_score import torch_geometric from torch_geometric.data import Data from sklearn.manifold import TSNE import numpy as np import matplotlib.pyplot as plt import scipy as sp  pp.config['torch']['device'] = 'cpu' device = pp.config['torch']['device'] <pre>\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[2], line 5\n      3 import torch\n      4 from pathpyG.nn.dbgnn import DBGNN\n----&gt; 5 from pathpyG.utils.dbgnn import generate_bipartite_edge_index\n      6 from torch_geometric.transforms import RandomNodeSplit\n      7 from sklearn.metrics import balanced_accuracy_score\n\nModuleNotFoundError: No module named 'pathpyG.utils.dbgnn'</pre> In\u00a0[\u00a0]: Copied! <pre>t = pp.TemporalGraph.from_csv('../data/temporal_clusters.tedges')\n</pre> t = pp.TemporalGraph.from_csv('../data/temporal_clusters.tedges') <p>This example has created in such a way that the nodes naturally form three clusters, which are highlighted in the interactive visualization below:</p> In\u00a0[\u00a0]: Copied! <pre>style = {}\nstyle['node_color'] = ['green']*10+['red']*10+['blue']*10\npp.plot(t, **style, edge_size=10);\n</pre> style = {} style['node_color'] = ['green']*10+['red']*10+['blue']*10 pp.plot(t, **style, edge_size=10); In\u00a0[\u00a0]: Copied! <pre>pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray');\n</pre> pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray'); <p>In fact, the topology of this graph corresponds to that of a random graph, i.e. there are not patterns whatsoever in the topology of links. Nevertheless, the temporal graph contains a cluster pattern in the topology of causal or time-respecting paths. In particular, the temporal ordering of time-stamped edges is such that nodes with the same cluster label are more frequently connected by time-respecting paths than nodes with different cluster labels. Hence, nodes within the same clusters can more strongly influence each other in a causal way, i.e. via multiple interactions that follow the arrow of time.</p> <p>Traditional (temporal) graph neural networks will not be able to learn from this pattern, as it is due to the specific microscopic temporal ordering of edges. Using higher-order De Bruijn graph models implemented in pathpyG, we can learn from temporal graph data that contains such patterns. Let us explain this step by step.</p> <p>Referring to the previous tutorial on causal paths in temporal graphs, we first create a node-time directed acyclic graph that captures the causal structure of the temporal graph. In this small example, we will only consider two time-stamped edges $(u,v;t)$ and $(v,w;t')$ to contribute to a causal path iff $0 &lt; t'-t \\leq 1$, i.e. we use a delta for the maximum time difference of one time step.</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2)\nprint(m)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2) print(m) <pre>MultiOrderModel with max. order 2\n</pre> <p>We can get the first and second order networks from the Multi Order Network object. The first order network is the network of nodes and edges, while the second order network is the network of first order edges as second order nodes and second order edges. The second order network is a De Bruijn graph that captures the temporal-topological patterns in the data.</p> In\u00a0[\u00a0]: Copied! <pre>g = m.layers[1]\ng2 = m.layers[2]\n</pre> g = m.layers[1] g2 = m.layers[2] In\u00a0[\u00a0]: Copied! <pre>pp.plot(g, edge_size=2);\n</pre> pp.plot(g, edge_size=2); <p>Since it does not consider patterns in the causal topology of the temporal graph, this is not a meaningful model. We can instead use a second-order De Bruijn graph model, which we can easily fit to the paths:</p> In\u00a0[\u00a0]: Copied! <pre>pp.plot(g2, edge_size=1);\n</pre> pp.plot(g2, edge_size=1); <p>In this graph, every node is a link and links correspond to causal paths of length two, i.e. temporally ordered sequences consisting of two edges that overlap in the center node. In this graph, we clearly see a cluster pattern that is due to the way in which temporal edges are ordered in time. In particular, we see three clusters, where the edges in three of the clusters correspond to causal paths of length two that connect nodes within each of the three clusters. The edges in the fourth cluster (in the center of the visualization) represent causal paths that connect nodes in different clusters.</p> In\u00a0[\u00a0]: Copied! <pre>t_shuffled = pp.TemporalGraph.from_csv('../data/temporal_clusters.tedges')\nt_shuffled.shuffle_time()\n</pre> t_shuffled = pp.TemporalGraph.from_csv('../data/temporal_clusters.tedges') t_shuffled.shuffle_time() In\u00a0[\u00a0]: Copied! <pre>g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2]\n</pre> g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2] In\u00a0[\u00a0]: Copied! <pre>pp.plot(g2_shuffled);\n</pre> pp.plot(g2_shuffled); <p>We now find that the cluster pattern in the second-order graph has vanished. In fact, there is no pattern whatsoever since the underlying (static) graph topology is random and the random shuffling of time stamps leads to random causal paths.</p> In\u00a0[\u00a0]: Copied! <pre>L = g2.get_laplacian(normalization='rw', edge_attr='edge_weight')\nL_shuffled= g2_shuffled.get_laplacian(normalization='rw',edge_attr='edge_weight')\n</pre> L = g2.get_laplacian(normalization='rw', edge_attr='edge_weight') L_shuffled= g2_shuffled.get_laplacian(normalization='rw',edge_attr='edge_weight') <p>We then calculate the eigenvalues and eigenvectors of the Laplacians, and compute the Fiedler vector, i.e. the eigenvector that corresponds to the second-smallest eigenvalue of the Laplacian.</p> In\u00a0[\u00a0]: Copied! <pre>w,v = sp.linalg.eig(L.todense(),left= False, right = True)\nw_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense())\n</pre> w,v = sp.linalg.eig(L.todense(),left= False, right = True) w_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense()) In\u00a0[\u00a0]: Copied! <pre>fiedler = v[:,np.argsort(w)[1]]\nfiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]]\n</pre> fiedler = v[:,np.argsort(w)[1]] fiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]] <p>Below, we show that the clusters in the causal topology of the temporal graph correspond to clusters in the distribution of entries in the Fiedler vector, while there is no such pattern for the Fiedler vector of the second-order graph constructed from the shuffled temporal graph:</p> In\u00a0[\u00a0]: Copied! <pre>c = []\na = []\nfor v in g2.nodes:\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c.append('green')\n        a.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c.append('red')\n        a.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c.append('blue')\n        a.append(1)\n    else:\n        c.append('black')\n        a.append(0.1)\n</pre> c = [] a = [] for v in g2.nodes:     if int(v[0])&lt;10 and int(v[1])&lt;10:         c.append('green')         a.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c.append('red')         a.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c.append('blue')         a.append(1)     else:         c.append('black')         a.append(0.1) In\u00a0[\u00a0]: Copied! <pre>c_shuffled = []\na_shuffled = []\nfor v in g2_shuffled.nodes: \n\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c_shuffled.append('green')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c_shuffled.append('red')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c_shuffled.append('blue')\n        a_shuffled.append(1)\n    else:\n        c_shuffled.append('black')\n        a_shuffled.append(0.1)\n</pre> c_shuffled = [] a_shuffled = [] for v in g2_shuffled.nodes:       if int(v[0])&lt;10 and int(v[1])&lt;10:         c_shuffled.append('green')         a_shuffled.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c_shuffled.append('red')         a_shuffled.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c_shuffled.append('blue')         a_shuffled.append(1)     else:         c_shuffled.append('black')         a_shuffled.append(0.1) <p>In the plots below, we have colored those entries of the Fiedler vectors that correspond to edges connecting nodes within one of the three clusters shown above. The Fiedler vector shows a clear pattern, which translates to the cluster pattern in the causal topology that we have planted into our synthetic temporal graph.</p> In\u00a0[\u00a0]: Copied! <pre>plt.ylim(-.2, .25)\nplt.scatter(range(g2.N), np.real(fiedler),c=c, alpha=a);\n</pre> plt.ylim(-.2, .25) plt.scatter(range(g2.N), np.real(fiedler),c=c, alpha=a); <p>No such pattern exists in the Fiedler vector of the second-order graph corresponding to the shuffled <code>TemporalGraph</code>.</p> In\u00a0[\u00a0]: Copied! <pre>plt.ylim(-.1, .1)\nplt.scatter(range(g2_shuffled.N), fiedler_shuffled, c=c_shuffled, alpha=a_shuffled);\n</pre> plt.ylim(-.1, .1) plt.scatter(range(g2_shuffled.N), fiedler_shuffled, c=c_shuffled, alpha=a_shuffled); <pre>/Users/lisi/miniconda3/envs/ppG_dev/lib/python3.11/site-packages/matplotlib/cbook.py:1699: ComplexWarning: Casting complex values to real discards the imaginary part\n  return math.isfinite(val)\n/Users/lisi/miniconda3/envs/ppG_dev/lib/python3.11/site-packages/matplotlib/collections.py:194: ComplexWarning: Casting complex values to real discards the imaginary part\n  offsets = np.asanyarray(offsets, float)\n</pre> <p>We now set up a <code>pytorch_geometric.Data</code> object that contains all of the information needed to train the DBGNN model.</p> <p>We can use a convenience function of the <code>DBGNN</code> class in <code>pathpyG</code> to simplify this step. Combining a first- and a second-order model, we use the edge indices and the weight tensors for our message passing scheme. We further construct an edge_index of a bipartite graph that uses the last node in a second-order node to map messages back to first-order nodes.</p> In\u00a0[\u00a0]: Copied! <pre>data = m.to_dbgnn_data(max_order=2, mapping='last')\ndata.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids])\n</pre> data = m.to_dbgnn_data(max_order=2, mapping='last') data.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids]) In\u00a0[\u00a0]: Copied! <pre>data = RandomNodeSplit(num_val=0, num_test=0.3)(data)\n\nmodel = DBGNN(\n        num_features =[g.N, g2.N],\n        num_classes = len(data.y.unique()),\n        hidden_dims = [16, 32, 8],\n        p_dropout = 0.4\n        ).to(device)\n\noptimizer = torch.optim.Adam(model.parameters(),  lr=0.005)\nloss_function = torch.nn.CrossEntropyLoss()\n\ndata = data.to(device)\n</pre> data = RandomNodeSplit(num_val=0, num_test=0.3)(data)  model = DBGNN(         num_features =[g.N, g2.N],         num_classes = len(data.y.unique()),         hidden_dims = [16, 32, 8],         p_dropout = 0.4         ).to(device)  optimizer = torch.optim.Adam(model.parameters(),  lr=0.005) loss_function = torch.nn.CrossEntropyLoss()  data = data.to(device) <p>The following function evaluates the prediction of our model based on the balanced accuracy score for categorical predictions.</p> In\u00a0[\u00a0]: Copied! <pre>def test(model, data):\n    model.eval()\n\n    _, pred = model(data).max(dim=1)\n\n    metrics_train = balanced_accuracy_score(\n        data.y[data.train_mask].cpu(),\n        pred[data.train_mask].cpu().numpy()\n        )\n\n    metrics_test = balanced_accuracy_score(\n        data.y[data.test_mask].cpu(),\n        pred[data.test_mask].cpu().numpy()\n        )\n\n    return metrics_train, metrics_test\n</pre> def test(model, data):     model.eval()      _, pred = model(data).max(dim=1)      metrics_train = balanced_accuracy_score(         data.y[data.train_mask].cpu(),         pred[data.train_mask].cpu().numpy()         )      metrics_test = balanced_accuracy_score(         data.y[data.test_mask].cpu(),         pred[data.test_mask].cpu().numpy()         )      return metrics_train, metrics_test In\u00a0[\u00a0]: Copied! <pre>losses = []\nfor epoch in range(100):\n        output = model(data)\n        loss = loss_function(output[data.train_mask], data.y[data.train_mask])\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        losses.append(loss)\n\n        if epoch % 10 == 0:\n                train_ba, test_ba = test(model, data)\n                print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}')\n</pre> losses = [] for epoch in range(100):         output = model(data)         loss = loss_function(output[data.train_mask], data.y[data.train_mask])         loss.backward()         optimizer.step()         optimizer.zero_grad()         losses.append(loss)          if epoch % 10 == 0:                 train_ba, test_ba = test(model, data)                 print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}') <pre>Epoch: 0, Loss: 1.333080530166626, Train balanced accuracy: 0.3333333333333333, Test balanced accuracy: 0.3333333333333333\nEpoch: 10, Loss: 0.9498822093009949, Train balanced accuracy: 0.7222222222222222, Test balanced accuracy: 0.6666666666666666\nEpoch: 20, Loss: 0.3054783046245575, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 30, Loss: 0.008039548061788082, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 40, Loss: 0.00031461837352253497, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 50, Loss: 9.158226748695597e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 60, Loss: 3.9874685171525925e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 70, Loss: 2.476602458045818e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 80, Loss: 1.9464583601802588e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 90, Loss: 1.717707527859602e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\n</pre> In\u00a0[\u00a0]: Copied! <pre>model.eval()\nlatent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach()\nlatent = model.higher_order_layers[1].forward(latent.cpu(), data.edge_index_higher_order).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())\n\ncolors = []\nfor v, w in g2.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g2.edges:\n    src = g2.mapping.to_idx(e[0])\n    tgt = g2.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach() latent = model.higher_order_layers[1].forward(latent.cpu(), data.edge_index_higher_order).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())  colors = [] for v, w in g2.nodes:     if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g2.edges:     src = g2.mapping.to_idx(e[0])     tgt = g2.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show() In\u00a0[\u00a0]: Copied! <pre>model.eval()\nlatent = model.forward(data).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())\n\ncolors = []\nfor v in g.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g.edges:\n    src = g.mapping.to_idx(e[0])\n    tgt = g.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.forward(data).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())  colors = [] for v in g.nodes:     if data.y[g.mapping.to_idx(v)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g.edges:     src = g.mapping.to_idx(e[0])     tgt = g.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show()"},{"location":"tutorial/dbgnn/#causality-aware-graph-neural-networks","title":"Causality-Aware Graph Neural Networks\u00b6","text":""},{"location":"tutorial/dbgnn/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/dbgnn/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In previous tutorials, we have introduced causal paths in temporal graphs, and how we can use them to generate higher-order De Bruijn graph models that capture temporal-topological patterns in time series data. In this tutorial, we will show how we can use De Bruijn Graph Neural Networks, a causality-aware deep learning architecture for temporal graph data. The details of this approach are introduced in this paper. The architecture is implemented in pathpyG and can be readily applied to temporal graph data.</p> <p>Below we illustrate this mthod in a supervised node classification task, i.e. given a temporal graph we will use the temporal-topological patterns in the graph to classify nodes.</p> <p>We start by importing a few modules:</p>"},{"location":"tutorial/dbgnn/#temporal-topological-clusters-in-temporal-graphs","title":"Temporal-Topological Clusters in Temporal Graphs\u00b6","text":"<p>Let us load a small synthetic toy example for a temporal graph with 60.000 time-stamped interactions between 30 nodes. We use the <code>TemporalGraph</code> class to load this example from a file containing edges with discrete time-stamps.</p>"},{"location":"tutorial/dbgnn/#modelling-causal-structures-with-higher-order-de-bruijn-graphs","title":"Modelling Causal Structures with Higher-Order De Bruijn Graphs\u00b6","text":"<p>But what is the origin for the cluster pattern? In the visualization above, you will notice that the time-stamped edges randomly interconnect nodes within and across clusters, actually there is no correlation whatsoever between the topology of links and the cluster membership of the nodes. Hence, the notion of clusters does not correspond to the common idea of cluster patterns in static graphs, which we can highlight further by plotting the static time-aggregated network:</p>"},{"location":"tutorial/dbgnn/#comparison-to-temporal-graph-with-shuffled-time-stamps","title":"Comparison to Temporal Graph with Shuffled Time Stamps\u00b6","text":"<p>You may wonder whether this pattern is really due to the temporal ordering of time-stamped edges. It is easy to check this. We can simply randomly shuffle the time stamps of all edges, which will break any correlations in the temporal ordering that lead to patterns in the causal topology.</p> <p>We repeat the path calculation for this shuffled temporal graph and construct the second-order De Bruijn Graph model again:</p>"},{"location":"tutorial/dbgnn/#spectral-clustering-with-second-order-graph-laplacian","title":"Spectral clustering with second-order graph Laplacian\u00b6","text":"<p>To take a different perspective on cluster patterns, we can actually use <code>pathpyG</code> to apply a spectral analysis to the higher-order graph. We can simply calculate a generalization of the Laplacian matrix to the second-order graph both for the actual temporal graph and its shuffled counterpart:</p>"},{"location":"tutorial/dbgnn/#node-classification-with-causality-aware-graph-neural-networks","title":"Node Classification with Causality-Aware Graph Neural Networks\u00b6","text":"<p>Let us now explore how we can develop a causality-aware deep graph learning architecture that utilizes this pattern in the causal topology. We will follow the architecture introduced in this work. The architecture actually performs message passing in higher-order models with multiple orders at once. In a final message passing step, a bipartite graph is used to obtain vector-space representations of actual nodes in the temporal graph.</p>"},{"location":"tutorial/dbgnn/#training-the-model","title":"Training the model\u00b6","text":"<p>We are now ready to train and evaluate our causality-aware graph neural network. We will frist create a random split of the nodes, set the optimizer and the hyperparameters of our model.</p>"},{"location":"tutorial/dbgnn/#latent-space-representation-of-edges","title":"Latent space representation of edges\u00b6","text":"<p>We can inspect the model by plotting a latent space representation of the edges generated by the second-order layer of our architecture.</p>"},{"location":"tutorial/dbgnn/#causality-aware-latent-space-representation-of-nodes","title":"Causality-aware latent space representation of nodes\u00b6","text":"<p>We can further generate latent space representations of the nodes generated by the last bipartite layer of our architecture:</p>"},{"location":"tutorial/higher_order_scalability/","title":"Higher order scalability","text":"In\u00a0[1]: Copied! <pre>import time\nimport torch\n\nimport pathpy as pp2\nimport pathpyG as pp\nfrom matplotlib import pyplot as plt\npp.config['torch']['device'] = 'cuda'\nprint('Running on', pp.config['torch']['device'])\n</pre> import time import torch  import pathpy as pp2 import pathpyG as pp from matplotlib import pyplot as plt pp.config['torch']['device'] = 'cuda' print('Running on', pp.config['torch']['device']) <pre>Running on cuda\n</pre> In\u00a0[2]: Copied! <pre>p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\n</pre> p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') In\u00a0[3]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(p, max_order=2)\ng2 = m.layers[2]\nprint(g2.N)\nprint(g2.M)\nprint(g2['edge_weight'].sum().item())\n</pre> m = pp.MultiOrderModel.from_DAGs(p, max_order=2) g2 = m.layers[2] print(g2.N) print(g2.M) print(g2['edge_weight'].sum().item()) <pre>646\n1139\n634916.0\n</pre> In\u00a0[4]: Copied! <pre>for e in g2.edges:\n    print(e, g2['edge_weight', e[0], e[1]])\n</pre> for e in g2.edges:     print(e, g2['edge_weight', e[0], e[1]]) <pre>(('Acton Town', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(2399., device='cuda:0')\n(('Acton Town', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(155., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(398., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(96., device='cuda:0')\n(('Acton Town', 'South Ealing'), ('South Ealing', 'Northfields')) tensor(1149., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(481., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(113., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(8., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(117., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(9., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(173., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(24., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(112., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(5., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2121., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1453., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(135., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(2147., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(234., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(5062., device='cuda:0')\n(('Alperton', 'Park Royal'), ('Park Royal', 'North Ealing')) tensor(232., device='cuda:0')\n(('Alperton', 'Sudbury Town'), ('Sudbury Town', 'Sudbury Hill')) tensor(117., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(1., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(180., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(46., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(665., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1404., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(3., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(33., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(56., device='cuda:0')\n(('Angel', 'Old Street'), ('Old Street', 'Moorgate')) tensor(2150., device='cuda:0')\n(('Archway', 'Highgate'), ('Highgate', 'East Finchley')) tensor(818., device='cuda:0')\n(('Archway', 'Tufnell Park'), ('Tufnell Park', 'Kentish Town')) tensor(1248., device='cuda:0')\n(('Arnos Grove', 'Bounds Green'), ('Bounds Green', 'Wood Green')) tensor(503., device='cuda:0')\n(('Arnos Grove', 'Southgate'), ('Southgate', 'Oakwood')) tensor(207., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(71., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(20., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(78., device='cuda:0')\n(('Arsenal', 'Holloway Road'), ('Holloway Road', 'Caledonian Road')) tensor(87., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(2561., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(104., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(669., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(2627., device='cuda:0')\n(('Baker Street', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Paddington')) tensor(5427., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(1379., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(157., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(639., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(290., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(463., device='cuda:0')\n(('Baker Street', 'Great Portland Street'), ('Great Portland Street', 'Euston Square')) tensor(4311., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(126., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(1391., device='cuda:0')\n(('Baker Street', \"Regent's Park\"), (\"Regent's Park\", 'Oxford Circus')) tensor(662., device='cuda:0')\n(('Baker Street', \"St. John's Wood\"), (\"St. John's Wood\", 'Swiss Cottage')) tensor(159., device='cuda:0')\n(('Balham', 'Clapham South'), ('Clapham South', 'Clapham Common')) tensor(1132., device='cuda:0')\n(('Balham', 'Tooting Bec'), ('Tooting Bec', 'Tooting Broadway')) tensor(637., device='cuda:0')\n(('Bank / Monument', 'Cannon Street'), ('Cannon Street', 'Mansion House')) tensor(274., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(110., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(2194., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(2353., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(522., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(264., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Borough')) tensor(805., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(3545., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(279., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(301., device='cuda:0')\n(('Bank / Monument', \"St. Paul's\"), (\"St. Paul's\", 'Chancery Lane')) tensor(3344., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(116., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(2188., device='cuda:0')\n(('Barbican', 'Farringdon'), ('Farringdon', \"King's Cross St. Pancras\")) tensor(2027., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1800., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(2., device='cuda:0')\n(('Barking', 'East Ham'), ('East Ham', 'Upton Park')) tensor(9., device='cuda:0')\n(('Barking', 'Upminster'), ('Upminster', 'Upminster Bridge')) tensor(561., device='cuda:0')\n(('Barking', 'Upney'), ('Upney', 'Becontree')) tensor(684., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(20., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Canning Town')) tensor(288., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Plaistow')) tensor(7., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Stratford')) tensor(2122., device='cuda:0')\n(('Barkingside', 'Fairlop'), ('Fairlop', 'Hainault')) tensor(201., device='cuda:0')\n(('Barkingside', 'Newbury Park'), ('Newbury Park', 'Gants Hill')) tensor(448., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1088., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(94., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(6., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(150., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(340., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(182., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(316., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(634., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(114., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(23., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(101., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(113., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(414., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(40., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(82., device='cuda:0')\n(('Becontree', 'Dagenham Heathway'), ('Dagenham Heathway', 'Dagenham East')) tensor(169., device='cuda:0')\n(('Becontree', 'Upney'), ('Upney', 'Barking')) tensor(623., device='cuda:0')\n(('Belsize Park', 'Chalk Farm'), ('Chalk Farm', 'Camden Town')) tensor(1156., device='cuda:0')\n(('Belsize Park', 'Hampstead'), ('Hampstead', 'Golders Green')) tensor(771., device='cuda:0')\n(('Bermondsey', 'Canada Water'), ('Canada Water', 'Canary Wharf')) tensor(1026., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(320., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Borough')) tensor(110., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(1094., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(11., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2252., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1505., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(119., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(253., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(144., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(3210., device='cuda:0')\n(('Blackfriars', 'Mansion House'), ('Mansion House', 'Cannon Street')) tensor(255., device='cuda:0')\n(('Blackfriars', 'Temple'), ('Temple', 'Embankment')) tensor(384., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(224., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(152., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2570., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(1699., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(92., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(999., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(174., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(282., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(225., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Victoria')) tensor(858., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Westminster')) tensor(1524., device='cuda:0')\n(('Bond Street', 'Marble Arch'), ('Marble Arch', 'Lancaster Gate')) tensor(835., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(226., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(519., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(93., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(3138., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(283., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(679., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(86., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(845., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(103., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(38., device='cuda:0')\n(('Boston Manor', 'Northfields'), ('Northfields', 'South Ealing')) tensor(1179., device='cuda:0')\n(('Boston Manor', 'Osterley'), ('Osterley', 'Hounslow East')) tensor(819., device='cuda:0')\n(('Bounds Green', 'Arnos Grove'), ('Arnos Grove', 'Southgate')) tensor(350., device='cuda:0')\n(('Bounds Green', 'Wood Green'), ('Wood Green', 'Turnpike Lane')) tensor(630., device='cuda:0')\n(('Bow Road', 'BromleyByBow'), ('BromleyByBow', 'West Ham')) tensor(13., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(225., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(5., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stratford')) tensor(10., device='cuda:0')\n(('Brent Cross', 'Golders Green'), ('Golders Green', 'Hampstead')) tensor(680., device='cuda:0')\n(('Brent Cross', 'Hendon Central'), ('Hendon Central', 'Colindale')) tensor(382., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(9., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Oval')) tensor(167., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(147., device='cuda:0')\n(('BromleyByBow', 'Bow Road'), ('Bow Road', 'Mile End')) tensor(87., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Barking')) tensor(16., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(3., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Plaistow')) tensor(4., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Stratford')) tensor(9., device='cuda:0')\n(('Buckhurst Hill', 'Loughton'), ('Loughton', 'Debden')) tensor(468., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(6., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'South Woodford')) tensor(934., device='cuda:0')\n(('Burnt Oak', 'Colindale'), ('Colindale', 'Hendon Central')) tensor(218., device='cuda:0')\n(('Caledonian Road', 'Holloway Road'), ('Holloway Road', 'Arsenal')) tensor(93., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(36., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(139., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(155., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(34., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(14., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(39., device='cuda:0')\n(('Camden Town', 'Chalk Farm'), ('Chalk Farm', 'Belsize Park')) tensor(1083., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(1459., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', 'Warren Street')) tensor(1639., device='cuda:0')\n(('Camden Town', 'Kentish Town'), ('Kentish Town', 'Tufnell Park')) tensor(1335., device='cuda:0')\n(('Canada Water', 'Bermondsey'), ('Bermondsey', 'London Bridge')) tensor(1333., device='cuda:0')\n(('Canada Water', 'Canary Wharf'), ('Canary Wharf', 'North Greenwich')) tensor(765., device='cuda:0')\n(('Canary Wharf', 'Canada Water'), ('Canada Water', 'Bermondsey')) tensor(1104., device='cuda:0')\n(('Canary Wharf', 'North Greenwich'), ('North Greenwich', 'Canning Town')) tensor(600., device='cuda:0')\n(('Canning Town', 'North Greenwich'), ('North Greenwich', 'Canary Wharf')) tensor(598., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Barking')) tensor(304., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(5., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Plaistow')) tensor(79., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Stratford')) tensor(222., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(198., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(78., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(42., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(59., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(96., device='cuda:0')\n(('Cannon Street', 'Mansion House'), ('Mansion House', 'Blackfriars')) tensor(268., device='cuda:0')\n(('Canons Park', 'Queensbury'), ('Queensbury', 'Kingsbury')) tensor(218., device='cuda:0')\n(('Chalfont &amp; Latimer', 'Chorleywood'), ('Chorleywood', 'Rickmansworth')) tensor(395., device='cuda:0')\n(('Chalk Farm', 'Belsize Park'), ('Belsize Park', 'Hampstead')) tensor(910., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1248., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(43., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(9., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(220., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Russell Square')) tensor(115., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(3066., device='cuda:0')\n(('Chancery Lane', \"St. Paul's\"), (\"St. Paul's\", 'Bank / Monument')) tensor(3482., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Temple')) tensor(61., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Waterloo')) tensor(231., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Westminster')) tensor(5., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(59., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(159., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(122., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(304., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(1., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(85., device='cuda:0')\n(('Chigwell', 'Grange Hill'), ('Grange Hill', 'Hainault')) tensor(204., device='cuda:0')\n(('Chigwell', 'Roding Valley'), ('Roding Valley', 'Woodford')) tensor(320., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(90., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(6., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(1., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(146., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(62., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'HarrowOnTheHill')) tensor(496., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'Moor Park')) tensor(10., device='cuda:0')\n(('Clapham Common', 'Clapham North'), ('Clapham North', 'Stockwell')) tensor(1504., device='cuda:0')\n(('Clapham Common', 'Clapham South'), ('Clapham South', 'Balham')) tensor(969., device='cuda:0')\n(('Clapham North', 'Clapham Common'), ('Clapham Common', 'Clapham South')) tensor(1148., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(8., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Oval')) tensor(964., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(686., device='cuda:0')\n(('Clapham South', 'Balham'), ('Balham', 'Tooting Bec')) tensor(782., device='cuda:0')\n(('Clapham South', 'Clapham Common'), ('Clapham Common', 'Clapham North')) tensor(1297., device='cuda:0')\n(('Cockfosters', 'Oakwood'), ('Oakwood', 'Southgate')) tensor(120., device='cuda:0')\n(('Colindale', 'Burnt Oak'), ('Burnt Oak', 'Edgware')) tensor(139., device='cuda:0')\n(('Colindale', 'Hendon Central'), ('Hendon Central', 'Brent Cross')) tensor(370., device='cuda:0')\n(('Colliers Wood', 'South Wimbledon'), ('South Wimbledon', 'Morden')) tensor(152., device='cuda:0')\n(('Colliers Wood', 'Tooting Broadway'), ('Tooting Broadway', 'Tooting Bec')) tensor(477., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(239., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Russell Square')) tensor(90., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(52., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(129., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(238., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(6., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Dagenham East', 'Dagenham Heathway'), ('Dagenham Heathway', 'Becontree')) tensor(161., device='cuda:0')\n(('Dagenham East', 'Elm Park'), ('Elm Park', 'Hornchurch')) tensor(5., device='cuda:0')\n(('Dagenham Heathway', 'Becontree'), ('Becontree', 'Upney')) tensor(418., device='cuda:0')\n(('Dagenham Heathway', 'Dagenham East'), ('Dagenham East', 'Elm Park')) tensor(5., device='cuda:0')\n(('Debden', 'Loughton'), ('Loughton', 'Buckhurst Hill')) tensor(577., device='cuda:0')\n(('Debden', 'Theydon Bois'), ('Theydon Bois', 'Epping')) tensor(217., device='cuda:0')\n(('Dollis Hill', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(118., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(2., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(2315., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(113., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Bayswater')) tensor(117., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(132., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(3451., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(94., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(60., device='cuda:0')\n(('Ealing Broadway', 'West Acton'), ('West Acton', 'North Acton')) tensor(875., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(105., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(508., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(1068., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(699., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(2570., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(49., device='cuda:0')\n(('Ealing Common', 'North Ealing'), ('North Ealing', 'Park Royal')) tensor(232., device='cuda:0')\n((\"Earl's Court\", 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(1065., device='cuda:0')\n((\"Earl's Court\", 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(3117., device='cuda:0')\n((\"Earl's Court\", 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(504., device='cuda:0')\n((\"Earl's Court\", 'West Brompton'), ('West Brompton', 'Fulham Broadway')) tensor(1757., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(70., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'West Acton')) tensor(168., device='cuda:0')\n(('East Acton', 'White City'), ('White City', \"Shepherd's Bush (Cen)\")) tensor(103., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(69., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(427., device='cuda:0')\n(('East Finchley', 'Highgate'), ('Highgate', 'Archway')) tensor(844., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upminster')) tensor(8., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upney')) tensor(7., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'West Ham')) tensor(426., device='cuda:0')\n(('East Ham', 'Upton Park'), ('Upton Park', 'Plaistow')) tensor(1., device='cuda:0')\n(('East Putney', 'Putney Bridge'), ('Putney Bridge', 'Parsons Green')) tensor(969., device='cuda:0')\n(('East Putney', 'Southfields'), ('Southfields', 'Wimbledon Park')) tensor(375., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(66., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(918., device='cuda:0')\n(('Eastcote', 'Ruislip Manor'), ('Ruislip Manor', 'Ruislip')) tensor(619., device='cuda:0')\n(('Edgware', 'Burnt Oak'), ('Burnt Oak', 'Colindale')) tensor(118., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(122., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(326., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(153., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(135., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(50., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(44., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(2860., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(253., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(2439., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(13., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(425., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(57., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(475., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(3182., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(590., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(924., device='cuda:0')\n(('Elephant &amp; Castle', 'Borough'), ('Borough', 'London Bridge')) tensor(867., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Oval')) tensor(627., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Waterloo')) tensor(217., device='cuda:0')\n(('Elephant &amp; Castle', 'Lambeth North'), ('Lambeth North', 'Waterloo')) tensor(211., device='cuda:0')\n(('Elm Park', 'Dagenham East'), ('Dagenham East', 'Dagenham Heathway')) tensor(5., device='cuda:0')\n(('Elm Park', 'Hornchurch'), ('Hornchurch', 'Upminster Bridge')) tensor(238., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Leicester Square')) tensor(114., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Piccadilly Circus')) tensor(175., device='cuda:0')\n(('Embankment', 'Temple'), ('Temple', 'Blackfriars')) tensor(412., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(105., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(23., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(276., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', 'Green Park')) tensor(549., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(132., device='cuda:0')\n(('Epping', 'Theydon Bois'), ('Theydon Bois', 'Debden')) tensor(306., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(1176., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(1482., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(703., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(131., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(326., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(683., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(576., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(100., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(88., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(2579., device='cuda:0')\n(('Euston Square', 'Great Portland Street'), ('Great Portland Street', 'Baker Street')) tensor(4039., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(1503., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(154., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(315., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(1522., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(739., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(87., device='cuda:0')\n(('Fairlop', 'Barkingside'), ('Barkingside', 'Newbury Park')) tensor(301., device='cuda:0')\n(('Fairlop', 'Hainault'), ('Hainault', 'Grange Hill')) tensor(3., device='cuda:0')\n(('Farringdon', 'Barbican'), ('Barbican', 'Moorgate')) tensor(2110., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(3., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(45., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(626., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1384., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(32., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(45., device='cuda:0')\n(('Finchley Central', 'East Finchley'), ('East Finchley', 'Highgate')) tensor(687., device='cuda:0')\n(('Finchley Central', 'West Finchley'), ('West Finchley', 'Woodside Park')) tensor(345., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1763., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(214., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(1034., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(145., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(245., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(172., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(95., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(235., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(603., device='cuda:0')\n(('Finchley Road', 'Swiss Cottage'), ('Swiss Cottage', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(338., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(96., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(85., device='cuda:0')\n(('Finchley Road', 'West Hampstead'), ('West Hampstead', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(110., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(98., device='cuda:0')\n(('Finsbury Park', 'Arsenal'), ('Arsenal', 'Holloway Road')) tensor(65., device='cuda:0')\n(('Finsbury Park', 'Highbury &amp; Islington'), ('Highbury &amp; Islington', \"King's Cross St. Pancras\")) tensor(1377., device='cuda:0')\n(('Finsbury Park', 'Manor House'), ('Manor House', 'Turnpike Lane')) tensor(960., device='cuda:0')\n(('Finsbury Park', 'Seven Sisters'), ('Seven Sisters', 'Tottenham Hale')) tensor(708., device='cuda:0')\n(('Fulham Broadway', 'Parsons Green'), ('Parsons Green', 'Putney Bridge')) tensor(1095., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', \"Earl's Court\")) tensor(1813., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', 'Kensington (Olympia)')) tensor(4., device='cuda:0')\n(('Gants Hill', 'Newbury Park'), ('Newbury Park', 'Barkingside')) tensor(471., device='cuda:0')\n(('Gants Hill', 'Redbridge'), ('Redbridge', 'Wanstead')) tensor(1094., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(1135., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(98., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(1410., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(192., device='cuda:0')\n(('Gloucester Road', 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(158., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(1378., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(2449., device='cuda:0')\n(('Golders Green', 'Brent Cross'), ('Brent Cross', 'Hendon Central')) tensor(542., device='cuda:0')\n(('Golders Green', 'Hampstead'), ('Hampstead', 'Belsize Park')) tensor(846., device='cuda:0')\n(('Goldhawk Road', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Wood Lane')) tensor(201., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(73., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(59., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(38., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(41., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Euston')) tensor(79., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(42., device='cuda:0')\n(('Grange Hill', 'Chigwell'), ('Chigwell', 'Roding Valley')) tensor(256., device='cuda:0')\n(('Grange Hill', 'Hainault'), ('Hainault', 'Fairlop')) tensor(3., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(93., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2262., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(946., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(582., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(14., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(115., device='cuda:0')\n(('Great Portland Street', 'Euston Square'), ('Euston Square', \"King's Cross St. Pancras\")) tensor(4322., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2417., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(156., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(245., device='cuda:0')\n(('Green Park', 'Hyde Park Corner'), ('Hyde Park Corner', 'Knightsbridge')) tensor(1812., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(41., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(250., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(1507., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(131., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(101., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Pimlico')) tensor(1017., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1741., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(140., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Embankment')) tensor(595., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(136., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Waterloo')) tensor(3391., device='cuda:0')\n(('Greenford', 'Northolt'), ('Northolt', 'South Ruislip')) tensor(194., device='cuda:0')\n(('Greenford', 'Perivale'), ('Perivale', 'Hanger Lane')) tensor(544., device='cuda:0')\n(('Gunnersbury', 'Kew Gardens'), ('Kew Gardens', 'Richmond')) tensor(293., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(557., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(217., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(6., device='cuda:0')\n(('Hainault', 'Fairlop'), ('Fairlop', 'Barkingside')) tensor(189., device='cuda:0')\n(('Hainault', 'Grange Hill'), ('Grange Hill', 'Chigwell')) tensor(187., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(437., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(191., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', \"Earl's Court\")) tensor(1123., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', 'West Kensington')) tensor(25., device='cuda:0')\n(('Hammersmith (Dis)', 'Ravenscourt Park'), ('Ravenscourt Park', 'Stamford Brook')) tensor(54., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(177., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(58., device='cuda:0')\n(('Hammersmith (H&amp;C)', 'Goldhawk Road'), ('Goldhawk Road', \"Shepherd's Bush Market\")) tensor(108., device='cuda:0')\n(('Hampstead', 'Belsize Park'), ('Belsize Park', 'Chalk Farm')) tensor(982., device='cuda:0')\n(('Hampstead', 'Golders Green'), ('Golders Green', 'Brent Cross')) tensor(610., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'East Acton')) tensor(80., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'West Acton')) tensor(688., device='cuda:0')\n(('Hanger Lane', 'Perivale'), ('Perivale', 'Greenford')) tensor(454., device='cuda:0')\n(('Harlesden', 'Stonebridge Park'), ('Stonebridge Park', 'Wembley Central')) tensor(333., device='cuda:0')\n(('Harlesden', 'Willesden Junction'), ('Willesden Junction', 'Kensal Green')) tensor(545., device='cuda:0')\n(('Harrow &amp; Wealdstone', 'Kenton'), ('Kenton', 'South Kenton')) tensor(118., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(1461., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(29., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(33., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(36., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(1479., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(383., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(222., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'North Harrow'), ('North Harrow', 'Pinner')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'Northwick Park'), ('Northwick Park', 'Preston Road')) tensor(21., device='cuda:0')\n(('HarrowOnTheHill', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(389., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(59., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'West Harrow'), ('West Harrow', 'Rayners Lane')) tensor(1303., device='cuda:0')\n(('Hatton Cross', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Heathrow Terminal 5')) tensor(75., device='cuda:0')\n(('Hatton Cross', 'Hounslow West'), ('Hounslow West', 'Hounslow Central')) tensor(571., device='cuda:0')\n(('Heathrow Terminal 4', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(123., device='cuda:0')\n(('Heathrow Terminal 5', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Hatton Cross')) tensor(92., device='cuda:0')\n(('Heathrow Terminals 123', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(332., device='cuda:0')\n(('Hendon Central', 'Brent Cross'), ('Brent Cross', 'Golders Green')) tensor(568., device='cuda:0')\n(('Hendon Central', 'Colindale'), ('Colindale', 'Burnt Oak')) tensor(251., device='cuda:0')\n(('High Barnet', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'Woodside Park')) tensor(159., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(97., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(15., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(379., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(34., device='cuda:0')\n(('High Street Kensington', 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(452., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(518., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(110., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(172., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(80., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(768., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(392., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(32., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(13., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(617., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(725., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(33., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(144., device='cuda:0')\n(('Highgate', 'Archway'), ('Archway', 'Tufnell Park')) tensor(1030., device='cuda:0')\n(('Highgate', 'East Finchley'), ('East Finchley', 'Finchley Central')) tensor(639., device='cuda:0')\n(('Hillingdon', 'Ickenham'), ('Ickenham', 'Ruislip')) tensor(424., device='cuda:0')\n(('Holborn', 'Chancery Lane'), ('Chancery Lane', \"St. Paul's\")) tensor(3506., device='cuda:0')\n(('Holborn', 'Covent Garden'), ('Covent Garden', 'Leicester Square')) tensor(203., device='cuda:0')\n(('Holborn', 'Russell Square'), ('Russell Square', \"King's Cross St. Pancras\")) tensor(302., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(2909., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(63., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(215., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(404., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(96., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(127., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(328., device='cuda:0')\n(('Holland Park', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'White City')) tensor(277., device='cuda:0')\n(('Holloway Road', 'Arsenal'), ('Arsenal', 'Finsbury Park')) tensor(69., device='cuda:0')\n(('Holloway Road', 'Caledonian Road'), ('Caledonian Road', \"King's Cross St. Pancras\")) tensor(243., device='cuda:0')\n(('Hornchurch', 'Elm Park'), ('Elm Park', 'Dagenham East')) tensor(4., device='cuda:0')\n(('Hornchurch', 'Upminster Bridge'), ('Upminster Bridge', 'Upminster')) tensor(437., device='cuda:0')\n(('Hounslow Central', 'Hounslow East'), ('Hounslow East', 'Osterley')) tensor(828., device='cuda:0')\n(('Hounslow Central', 'Hounslow West'), ('Hounslow West', 'Hatton Cross')) tensor(433., device='cuda:0')\n(('Hounslow East', 'Hounslow Central'), ('Hounslow Central', 'Hounslow West')) tensor(554., device='cuda:0')\n(('Hounslow East', 'Osterley'), ('Osterley', 'Boston Manor')) tensor(959., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminal 4')) tensor(69., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminals 123')) tensor(277., device='cuda:0')\n(('Hounslow West', 'Hounslow Central'), ('Hounslow Central', 'Hounslow East')) tensor(667., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Bond Street')) tensor(234., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(492., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(73., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Victoria')) tensor(20., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Westminster')) tensor(1029., device='cuda:0')\n(('Hyde Park Corner', 'Knightsbridge'), ('Knightsbridge', 'South Kensington')) tensor(1581., device='cuda:0')\n(('Ickenham', 'Hillingdon'), ('Hillingdon', 'Uxbridge')) tensor(257., device='cuda:0')\n(('Ickenham', 'Ruislip'), ('Ruislip', 'Ruislip Manor')) tensor(541., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(774., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Oval'), ('Oval', 'Stockwell')) tensor(1245., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(113., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(715., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(378., device='cuda:0')\n(('Kensal Green', \"Queen's Park\"), (\"Queen's Park\", 'Kilburn Park')) tensor(754., device='cuda:0')\n(('Kensal Green', 'Willesden Junction'), ('Willesden Junction', 'Harlesden')) tensor(470., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(47., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1547., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(11., device='cuda:0')\n(('Kentish Town', 'Tufnell Park'), ('Tufnell Park', 'Archway')) tensor(1191., device='cuda:0')\n(('Kenton', 'South Kenton'), ('South Kenton', 'North Wembley')) tensor(150., device='cuda:0')\n(('Kew Gardens', 'Gunnersbury'), ('Gunnersbury', 'Turnham Green')) tensor(510., device='cuda:0')\n(('Kilburn', 'West Hampstead'), ('West Hampstead', 'Finchley Road')) tensor(140., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(1., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(145., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(8., device='cuda:0')\n(('Kilburn Park', 'Maida Vale'), ('Maida Vale', 'Warwick Avenue')) tensor(1048., device='cuda:0')\n(('Kilburn Park', \"Queen's Park\"), (\"Queen's Park\", 'Kensal Green')) tensor(622., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Angel'), ('Angel', 'Old Street')) tensor(2221., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Caledonian Road'), ('Caledonian Road', 'Holloway Road')) tensor(246., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Camden Town')) tensor(1406., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Mornington Crescent')) tensor(85., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Warren Street')) tensor(881., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston Square'), ('Euston Square', 'Great Portland Street')) tensor(4062., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Farringdon'), ('Farringdon', 'Barbican')) tensor(2195., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Highbury &amp; Islington'), ('Highbury &amp; Islington', 'Finsbury Park')) tensor(1352., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Russell Square'), ('Russell Square', 'Holborn')) tensor(299., device='cuda:0')\n(('Kingsbury', 'Queensbury'), ('Queensbury', 'Canons Park')) tensor(189., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(334., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(66., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(16., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(1., device='cuda:0')\n(('Knightsbridge', 'Hyde Park Corner'), ('Hyde Park Corner', 'Green Park')) tensor(1733., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(1409., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(14., device='cuda:0')\n(('Ladbroke Grove', 'Latimer Road'), ('Latimer Road', 'Wood Lane')) tensor(299., device='cuda:0')\n(('Ladbroke Grove', 'Westbourne Park'), ('Westbourne Park', 'Royal Oak')) tensor(607., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(83., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(19., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(45., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(287., device='cuda:0')\n(('Lancaster Gate', 'Marble Arch'), ('Marble Arch', 'Bond Street')) tensor(839., device='cuda:0')\n(('Lancaster Gate', 'Queensway'), ('Queensway', 'Notting Hill Gate')) tensor(616., device='cuda:0')\n(('Latimer Road', 'Ladbroke Grove'), ('Ladbroke Grove', 'Westbourne Park')) tensor(446., device='cuda:0')\n(('Latimer Road', 'Wood Lane'), ('Wood Lane', \"Shepherd's Bush Market\")) tensor(240., device='cuda:0')\n(('Leicester Square', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(103., device='cuda:0')\n(('Leicester Square', 'Covent Garden'), ('Covent Garden', 'Holborn')) tensor(222., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(101., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(277., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(39., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(212., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(1851., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(1449., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Mile End')) tensor(1671., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'West Ham')) tensor(95., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2639., device='cuda:0')\n(('Leytonstone', 'Leyton'), ('Leyton', 'Stratford')) tensor(3987., device='cuda:0')\n(('Leytonstone', 'Snaresbrook'), ('Snaresbrook', 'South Woodford')) tensor(1706., device='cuda:0')\n(('Leytonstone', 'Wanstead'), ('Wanstead', 'Redbridge')) tensor(1245., device='cuda:0')\n(('Liverpool Street', 'Aldgate'), ('Aldgate', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(3609., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(2842., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(2155., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Bethnal Green'), ('Bethnal Green', 'Mile End')) tensor(3900., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(1688., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(1701., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(546., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(73., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2915., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(495., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(107., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1264., device='cuda:0')\n(('London Bridge', 'Bermondsey'), ('Bermondsey', 'Canada Water')) tensor(1250., device='cuda:0')\n(('London Bridge', 'Borough'), ('Borough', 'Elephant &amp; Castle')) tensor(795., device='cuda:0')\n(('London Bridge', 'Southwark'), ('Southwark', 'Waterloo')) tensor(4797., device='cuda:0')\n(('Loughton', 'Buckhurst Hill'), ('Buckhurst Hill', 'Woodford')) tensor(773., device='cuda:0')\n(('Loughton', 'Debden'), ('Debden', 'Theydon Bois')) tensor(301., device='cuda:0')\n(('Maida Vale', 'Kilburn Park'), ('Kilburn Park', \"Queen's Park\")) tensor(736., device='cuda:0')\n(('Maida Vale', 'Warwick Avenue'), ('Warwick Avenue', 'Paddington')) tensor(1186., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(21., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(806., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(328., device='cuda:0')\n(('Manor House', 'Turnpike Lane'), ('Turnpike Lane', 'Wood Green')) tensor(794., device='cuda:0')\n(('Mansion House', 'Blackfriars'), ('Blackfriars', 'Temple')) tensor(286., device='cuda:0')\n(('Mansion House', 'Cannon Street'), ('Cannon Street', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(104., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(145., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(161., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(658., device='cuda:0')\n(('Marble Arch', 'Lancaster Gate'), ('Lancaster Gate', 'Queensway')) tensor(725., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1060., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(1., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(4., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(601., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(104., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(15., device='cuda:0')\n(('Marylebone', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Paddington')) tensor(393., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(5., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(262., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(185., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(115., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(265., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(69., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(699., device='cuda:0')\n(('Mile End', 'Bethnal Green'), ('Bethnal Green', 'Liverpool Street')) tensor(3726., device='cuda:0')\n(('Mile End', 'Bow Road'), ('Bow Road', 'BromleyByBow')) tensor(112., device='cuda:0')\n(('Mile End', 'Stepney Green'), ('Stepney Green', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Leyton')) tensor(1541., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'West Ham')) tensor(1383., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(94., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(3., device='cuda:0')\n(('Moor Park', 'Croxley'), ('Croxley', 'Watford')) tensor(124., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(255., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(284., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(9., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(13., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(20., device='cuda:0')\n(('Moor Park', 'Northwood'), ('Northwood', 'Northwood Hills')) tensor(113., device='cuda:0')\n(('Moor Park', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(9., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(55., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(455., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(15., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(54., device='cuda:0')\n(('Moorgate', 'Barbican'), ('Barbican', 'Farringdon')) tensor(1978., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(187., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(1525., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(1624., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(26., device='cuda:0')\n(('Moorgate', 'Old Street'), ('Old Street', 'Angel')) tensor(2014., device='cuda:0')\n(('Morden', 'South Wimbledon'), ('South Wimbledon', 'Colliers Wood')) tensor(199., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(9., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(10., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(82., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', 'Warren Street')) tensor(88., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(114., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(14., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(5., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(108., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(8., device='cuda:0')\n(('Newbury Park', 'Barkingside'), ('Barkingside', 'Fairlop')) tensor(335., device='cuda:0')\n(('Newbury Park', 'Gants Hill'), ('Gants Hill', 'Redbridge')) tensor(742., device='cuda:0')\n(('North Acton', 'East Acton'), ('East Acton', 'White City')) tensor(131., device='cuda:0')\n(('North Acton', 'Hanger Lane'), ('Hanger Lane', 'Perivale')) tensor(534., device='cuda:0')\n(('North Acton', 'West Acton'), ('West Acton', 'Ealing Broadway')) tensor(1035., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(189., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(152., device='cuda:0')\n(('North Ealing', 'Park Royal'), ('Park Royal', 'Alperton')) tensor(180., device='cuda:0')\n(('North Greenwich', 'Canary Wharf'), ('Canary Wharf', 'Canada Water')) tensor(806., device='cuda:0')\n(('North Greenwich', 'Canning Town'), ('Canning Town', 'West Ham')) tensor(513., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(190., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(196., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(3., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(7., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(10., device='cuda:0')\n(('North Harrow', 'Pinner'), ('Pinner', 'Northwood Hills')) tensor(104., device='cuda:0')\n(('North Wembley', 'South Kenton'), ('South Kenton', 'Kenton')) tensor(163., device='cuda:0')\n(('North Wembley', 'Wembley Central'), ('Wembley Central', 'Stonebridge Park')) tensor(272., device='cuda:0')\n(('Northfields', 'Boston Manor'), ('Boston Manor', 'Osterley')) tensor(924., device='cuda:0')\n(('Northfields', 'South Ealing'), ('South Ealing', 'Acton Town')) tensor(1308., device='cuda:0')\n(('Northolt', 'Greenford'), ('Greenford', 'Perivale')) tensor(382., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'Ruislip Gardens')) tensor(51., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'West Ruislip')) tensor(73., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(92., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(110., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(7., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(2., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(13., device='cuda:0')\n(('Northwick Park', 'Preston Road'), ('Preston Road', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(257., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Northwood', 'Northwood Hills'), ('Northwood Hills', 'Pinner')) tensor(5., device='cuda:0')\n(('Northwood Hills', 'Northwood'), ('Northwood', 'Moor Park')) tensor(124., device='cuda:0')\n(('Northwood Hills', 'Pinner'), ('Pinner', 'North Harrow')) tensor(107., device='cuda:0')\n(('Notting Hill Gate', 'Bayswater'), ('Bayswater', 'Paddington')) tensor(656., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', \"Earl's Court\")) tensor(581., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', 'Gloucester Road')) tensor(194., device='cuda:0')\n(('Notting Hill Gate', 'Holland Park'), ('Holland Park', \"Shepherd's Bush (Cen)\")) tensor(462., device='cuda:0')\n(('Notting Hill Gate', 'Queensway'), ('Queensway', 'Lancaster Gate')) tensor(611., device='cuda:0')\n(('Oakwood', 'Southgate'), ('Southgate', 'Arnos Grove')) tensor(229., device='cuda:0')\n(('Old Street', 'Angel'), ('Angel', \"King's Cross St. Pancras\")) tensor(2078., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(296., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(3., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1828., device='cuda:0')\n(('Osterley', 'Boston Manor'), ('Boston Manor', 'Northfields')) tensor(1091., device='cuda:0')\n(('Osterley', 'Hounslow East'), ('Hounslow East', 'Hounslow Central')) tensor(679., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(691., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Waterloo')) tensor(837., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(155., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(859., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(169., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(672., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(178., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(519., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(999., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(361., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(304., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', \"Regent's Park\"), (\"Regent's Park\", 'Baker Street')) tensor(674., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(47., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(376., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Euston')) tensor(2437., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(48., device='cuda:0')\n(('Paddington', 'Bayswater'), ('Bayswater', 'Notting Hill Gate')) tensor(811., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(2429., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(891., device='cuda:0')\n(('Paddington', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Marylebone')) tensor(353., device='cuda:0')\n(('Paddington', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Baker Street')) tensor(5928., device='cuda:0')\n(('Paddington', 'Royal Oak'), ('Royal Oak', 'Westbourne Park')) tensor(686., device='cuda:0')\n(('Paddington', 'Warwick Avenue'), ('Warwick Avenue', 'Maida Vale')) tensor(976., device='cuda:0')\n(('Park Royal', 'Alperton'), ('Alperton', 'Sudbury Town')) tensor(128., device='cuda:0')\n(('Park Royal', 'North Ealing'), ('North Ealing', 'Ealing Common')) tensor(305., device='cuda:0')\n(('Parsons Green', 'Fulham Broadway'), ('Fulham Broadway', 'West Brompton')) tensor(1506., device='cuda:0')\n(('Parsons Green', 'Putney Bridge'), ('Putney Bridge', 'East Putney')) tensor(828., device='cuda:0')\n(('Perivale', 'Greenford'), ('Greenford', 'Northolt')) tensor(321., device='cuda:0')\n(('Perivale', 'Hanger Lane'), ('Hanger Lane', 'North Acton')) tensor(621., device='cuda:0')\n(('Piccadilly Circus', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(180., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Bond Street')) tensor(220., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(74., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(109., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(106., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(138., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(82., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(218., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(215., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(80., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(174., device='cuda:0')\n(('Pimlico', 'Vauxhall'), ('Vauxhall', 'Stockwell')) tensor(940., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Green Park')) tensor(1025., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(258., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(89., device='cuda:0')\n(('Pinner', 'North Harrow'), ('North Harrow', 'HarrowOnTheHill')) tensor(261., device='cuda:0')\n(('Pinner', 'Northwood Hills'), ('Northwood Hills', 'Northwood')) tensor(5., device='cuda:0')\n(('Plaistow', 'Upton Park'), ('Upton Park', 'East Ham')) tensor(1., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Barking')) tensor(9., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(4., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(97., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Stratford')) tensor(770., device='cuda:0')\n(('Preston Road', 'Northwick Park'), ('Northwick Park', 'HarrowOnTheHill')) tensor(23., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(84., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(22., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(2., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(5., device='cuda:0')\n(('Putney Bridge', 'East Putney'), ('East Putney', 'Southfields')) tensor(577., device='cuda:0')\n(('Putney Bridge', 'Parsons Green'), ('Parsons Green', 'Fulham Broadway')) tensor(1250., device='cuda:0')\n((\"Queen's Park\", 'Kensal Green'), ('Kensal Green', 'Willesden Junction')) tensor(551., device='cuda:0')\n((\"Queen's Park\", 'Kilburn Park'), ('Kilburn Park', 'Maida Vale')) tensor(903., device='cuda:0')\n(('Queensbury', 'Canons Park'), ('Canons Park', 'Stanmore')) tensor(99., device='cuda:0')\n(('Queensbury', 'Kingsbury'), ('Kingsbury', 'Wembley Park')) tensor(312., device='cuda:0')\n(('Queensway', 'Lancaster Gate'), ('Lancaster Gate', 'Marble Arch')) tensor(723., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(18., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(165., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(333., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(76., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(173., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Ravenscourt Park', 'Stamford Brook'), ('Stamford Brook', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Rayners Lane', 'Eastcote'), ('Eastcote', 'Ruislip Manor')) tensor(743., device='cuda:0')\n(('Rayners Lane', 'South Harrow'), ('South Harrow', 'Sudbury Hill')) tensor(253., device='cuda:0')\n(('Rayners Lane', 'West Harrow'), ('West Harrow', 'HarrowOnTheHill')) tensor(1408., device='cuda:0')\n(('Redbridge', 'Gants Hill'), ('Gants Hill', 'Newbury Park')) tensor(701., device='cuda:0')\n(('Redbridge', 'Wanstead'), ('Wanstead', 'Leytonstone')) tensor(1302., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(426., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(150., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(6., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(106., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(12., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(40., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(211., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(26., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(347., device='cuda:0')\n(('Richmond', 'Kew Gardens'), ('Kew Gardens', 'Gunnersbury')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'Chorleywood'), ('Chorleywood', 'Chalfont &amp; Latimer')) tensor(312., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(276., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(9., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(11., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(7., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(3., device='cuda:0')\n(('Roding Valley', 'Chigwell'), ('Chigwell', 'Grange Hill')) tensor(261., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(8., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'South Woodford')) tensor(372., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Bayswater')) tensor(47., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(92., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(54., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(684., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(8., device='cuda:0')\n(('Royal Oak', 'Westbourne Park'), ('Westbourne Park', 'Ladbroke Grove')) tensor(569., device='cuda:0')\n(('Ruislip', 'Ickenham'), ('Ickenham', 'Hillingdon')) tensor(398., device='cuda:0')\n(('Ruislip', 'Ruislip Manor'), ('Ruislip Manor', 'Eastcote')) tensor(712., device='cuda:0')\n(('Ruislip Gardens', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(78., device='cuda:0')\n(('Ruislip Manor', 'Eastcote'), ('Eastcote', 'Rayners Lane')) tensor(825., device='cuda:0')\n(('Ruislip Manor', 'Ruislip'), ('Ruislip', 'Ickenham')) tensor(496., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(119., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(90., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(327., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(59., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(40., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(91., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(86., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(53., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(151., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(66., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(387., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(335., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(153., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(561., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'Holland Park'), ('Holland Park', 'Notting Hill Gate')) tensor(468., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'White City'), ('White City', 'East Acton')) tensor(93., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Goldhawk Road'), ('Goldhawk Road', 'Hammersmith (H&amp;C)')) tensor(77., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Wood Lane'), ('Wood Lane', 'Latimer Road')) tensor(279., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(2467., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(15., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Green Park')) tensor(1713., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Pimlico')) tensor(260., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(1042., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(2080., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(7., device='cuda:0')\n(('Snaresbrook', 'South Woodford'), ('South Woodford', 'Woodford')) tensor(1415., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(8., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(1168., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(212., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(25., device='cuda:0')\n(('South Ealing', 'Northfields'), ('Northfields', 'Boston Manor')) tensor(1019., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(62., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(316., device='cuda:0')\n(('South Harrow', 'Sudbury Hill'), ('Sudbury Hill', 'Sudbury Town')) tensor(183., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', \"Earl's Court\")) tensor(3171., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', 'High Street Kensington')) tensor(414., device='cuda:0')\n(('South Kensington', 'Knightsbridge'), ('Knightsbridge', 'Hyde Park Corner')) tensor(1538., device='cuda:0')\n(('South Kensington', 'Sloane Square'), ('Sloane Square', 'Victoria')) tensor(2746., device='cuda:0')\n(('South Kenton', 'Kenton'), ('Kenton', 'Harrow &amp; Wealdstone')) tensor(119., device='cuda:0')\n(('South Kenton', 'North Wembley'), ('North Wembley', 'Wembley Central')) tensor(207., device='cuda:0')\n(('South Ruislip', 'Northolt'), ('Northolt', 'Greenford')) tensor(252., device='cuda:0')\n(('South Wimbledon', 'Colliers Wood'), ('Colliers Wood', 'Tooting Broadway')) tensor(328., device='cuda:0')\n(('South Woodford', 'Snaresbrook'), ('Snaresbrook', 'Leytonstone')) tensor(1888., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(830., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(309., device='cuda:0')\n(('Southfields', 'East Putney'), ('East Putney', 'Putney Bridge')) tensor(677., device='cuda:0')\n(('Southfields', 'Wimbledon Park'), ('Wimbledon Park', 'Wimbledon')) tensor(255., device='cuda:0')\n(('Southgate', 'Arnos Grove'), ('Arnos Grove', 'Bounds Green')) tensor(390., device='cuda:0')\n(('Southgate', 'Oakwood'), ('Oakwood', 'Cockfosters')) tensor(101., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(3604., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(1002., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Borough')) tensor(52., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(279., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(640., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(45., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(3875., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Green Park')) tensor(132., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Pimlico')) tensor(84., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1027., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Embankment')) tensor(128., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Green Park')) tensor(135., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Waterloo')) tensor(1190., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(168., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(54., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(119., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(16., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(11., device='cuda:0')\n((\"St. John's Wood\", 'Swiss Cottage'), ('Swiss Cottage', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(49., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2220., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(86., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(13., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1106., device='cuda:0')\n((\"St. Paul's\", 'Chancery Lane'), ('Chancery Lane', 'Holborn')) tensor(3317., device='cuda:0')\n(('Stamford Brook', 'Ravenscourt Park'), ('Ravenscourt Park', 'Hammersmith (Dis)')) tensor(63., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(89., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(6., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(67., device='cuda:0')\n(('Stanmore', 'Canons Park'), ('Canons Park', 'Queensbury')) tensor(110., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(132., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(5., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(24., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(214., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(25., device='cuda:0')\n(('Stockwell', 'Clapham North'), ('Clapham North', 'Clapham Common')) tensor(1366., device='cuda:0')\n(('Stockwell', 'Oval'), ('Oval', 'Kennington')) tensor(1370., device='cuda:0')\n(('Stockwell', 'Vauxhall'), ('Vauxhall', 'Pimlico')) tensor(928., device='cuda:0')\n(('Stonebridge Park', 'Harlesden'), ('Harlesden', 'Willesden Junction')) tensor(443., device='cuda:0')\n(('Stonebridge Park', 'Wembley Central'), ('Wembley Central', 'North Wembley')) tensor(257., device='cuda:0')\n(('Stratford', 'Leyton'), ('Leyton', 'Leytonstone')) tensor(3711., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(3185., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bow Road')) tensor(8., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(27., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Barking')) tensor(2374., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(7., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Canning Town')) tensor(170., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Plaistow')) tensor(707., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(5039., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(26., device='cuda:0')\n(('Sudbury Hill', 'South Harrow'), ('South Harrow', 'Rayners Lane')) tensor(290., device='cuda:0')\n(('Sudbury Hill', 'Sudbury Town'), ('Sudbury Town', 'Alperton')) tensor(143., device='cuda:0')\n(('Sudbury Town', 'Alperton'), ('Alperton', 'Park Royal')) tensor(166., device='cuda:0')\n(('Sudbury Town', 'Sudbury Hill'), ('Sudbury Hill', 'South Harrow')) tensor(190., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(180., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(4., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(8., device='cuda:0')\n(('Swiss Cottage', \"St. John's Wood\"), (\"St. John's Wood\", 'Baker Street')) tensor(175., device='cuda:0')\n(('Temple', 'Blackfriars'), ('Blackfriars', 'Mansion House')) tensor(291., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(57., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Waterloo')) tensor(44., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Westminster')) tensor(487., device='cuda:0')\n(('Theydon Bois', 'Debden'), ('Debden', 'Loughton')) tensor(447., device='cuda:0')\n(('Tooting Bec', 'Balham'), ('Balham', 'Clapham South')) tensor(939., device='cuda:0')\n(('Tooting Bec', 'Tooting Broadway'), ('Tooting Broadway', 'Colliers Wood')) tensor(404., device='cuda:0')\n(('Tooting Broadway', 'Colliers Wood'), ('Colliers Wood', 'South Wimbledon')) tensor(264., device='cuda:0')\n(('Tooting Broadway', 'Tooting Bec'), ('Tooting Bec', 'Balham')) tensor(763., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2377., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(244., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(630., device='cuda:0')\n(('Tottenham Court Road', 'Goodge Street'), ('Goodge Street', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(3254., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(104., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Russell Square')) tensor(322., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(154., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(101., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(86., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(245., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(80., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(40., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Hale', 'Blackhorse Road'), ('Blackhorse Road', 'Walthamstow Central')) tensor(197., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(24., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(138., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(566., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(133., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(26., device='cuda:0')\n(('Tottenham Hale', 'Seven Sisters'), ('Seven Sisters', 'Finsbury Park')) tensor(690., device='cuda:0')\n(('Totteridge &amp; Whetstone', 'Woodside Park'), ('Woodside Park', 'West Finchley')) tensor(259., device='cuda:0')\n(('Tower Hill', 'Aldgate'), ('Aldgate', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(2085., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(96., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(17., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(1239., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(59., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(1078., device='cuda:0')\n(('Tufnell Park', 'Archway'), ('Archway', 'Highgate')) tensor(965., device='cuda:0')\n(('Tufnell Park', 'Kentish Town'), ('Kentish Town', 'Camden Town')) tensor(1387., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(769., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(21., device='cuda:0')\n(('Turnham Green', 'Gunnersbury'), ('Gunnersbury', 'Kew Gardens')) tensor(470., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(367., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnham Green', 'Stamford Brook'), ('Stamford Brook', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnpike Lane', 'Manor House'), ('Manor House', 'Finsbury Park')) tensor(1014., device='cuda:0')\n(('Turnpike Lane', 'Wood Green'), ('Wood Green', 'Bounds Green')) tensor(618., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'Upney')) tensor(5., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'West Ham')) tensor(735., device='cuda:0')\n(('Upminster', 'Upminster Bridge'), ('Upminster Bridge', 'Hornchurch')) tensor(468., device='cuda:0')\n(('Upminster Bridge', 'Hornchurch'), ('Hornchurch', 'Elm Park')) tensor(269., device='cuda:0')\n(('Upminster Bridge', 'Upminster'), ('Upminster', 'Barking')) tensor(571., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'Upminster')) tensor(4., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'West Ham')) tensor(779., device='cuda:0')\n(('Upney', 'Becontree'), ('Becontree', 'Dagenham Heathway')) tensor(478., device='cuda:0')\n(('Upton Park', 'East Ham'), ('East Ham', 'Barking')) tensor(8., device='cuda:0')\n(('Upton Park', 'Plaistow'), ('Plaistow', 'West Ham')) tensor(464., device='cuda:0')\n(('Uxbridge', 'Hillingdon'), ('Hillingdon', 'Ickenham')) tensor(256., device='cuda:0')\n(('Vauxhall', 'Pimlico'), ('Pimlico', 'Victoria')) tensor(1094., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(152., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(680., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Oval')) tensor(173., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Bond Street')) tensor(835., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(23., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(974., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(116., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Westminster')) tensor(1201., device='cuda:0')\n(('Victoria', 'Pimlico'), ('Pimlico', 'Vauxhall')) tensor(1093., device='cuda:0')\n(('Victoria', 'Sloane Square'), ('Sloane Square', 'South Kensington')) tensor(2745., device='cuda:0')\n(('Victoria', \"St. James's Park\"), (\"St. James's Park\", 'Westminster')) tensor(1214., device='cuda:0')\n(('Walthamstow Central', 'Blackhorse Road'), ('Blackhorse Road', 'Tottenham Hale')) tensor(221., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(1544., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(15., device='cuda:0')\n(('Wanstead', 'Redbridge'), ('Redbridge', 'Gants Hill')) tensor(1049., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Camden Town')) tensor(1550., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(881., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Mornington Crescent')) tensor(73., device='cuda:0')\n(('Warren Street', 'Goodge Street'), ('Goodge Street', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(553., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(1574., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(182., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(369., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warwick Avenue', 'Maida Vale'), ('Maida Vale', 'Kilburn Park')) tensor(836., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Bayswater')) tensor(103., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(58., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(43., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(1143., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(8., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(229., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Temple')) tensor(53., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(231., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Oval')) tensor(779., device='cuda:0')\n(('Waterloo', 'Lambeth North'), ('Lambeth North', 'Elephant &amp; Castle')) tensor(226., device='cuda:0')\n(('Waterloo', 'Southwark'), ('Southwark', 'London Bridge')) tensor(4777., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', 'Green Park')) tensor(3439., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(1183., device='cuda:0')\n(('Watford', 'Croxley'), ('Croxley', 'Moor Park')) tensor(122., device='cuda:0')\n(('Wembley Central', 'North Wembley'), ('North Wembley', 'South Kenton')) tensor(199., device='cuda:0')\n(('Wembley Central', 'Stonebridge Park'), ('Stonebridge Park', 'Harlesden')) tensor(356., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(657., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(13., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(68., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(14., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(4., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(7., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(36., device='cuda:0')\n(('Wembley Park', 'Kingsbury'), ('Kingsbury', 'Queensbury')) tensor(311., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Dollis Hill')) tensor(14., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Preston Road'), ('Preston Road', 'Northwick Park')) tensor(4., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(61., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(1040., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'East Acton')) tensor(149., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(600., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(144., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1519., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(344., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(7., device='cuda:0')\n(('West Brompton', 'Fulham Broadway'), ('Fulham Broadway', 'Parsons Green')) tensor(1357., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(468., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(2., device='cuda:0')\n(('West Finchley', 'Woodside Park'), ('Woodside Park', 'Totteridge &amp; Whetstone')) tensor(221., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'East Ham')) tensor(588., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upminster')) tensor(788., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upney')) tensor(857., device='cuda:0')\n(('West Ham', 'BromleyByBow'), ('BromleyByBow', 'Bow Road')) tensor(16., device='cuda:0')\n(('West Ham', 'Canning Town'), ('Canning Town', 'North Greenwich')) tensor(490., device='cuda:0')\n(('West Ham', 'Plaistow'), ('Plaistow', 'Upton Park')) tensor(482., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Leyton')) tensor(122., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Mile End')) tensor(1283., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2023., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(267., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(19., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(4., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(13., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Hampstead', 'Kilburn'), ('Kilburn', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(660., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(779., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(13., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(31., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(853., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(270., device='cuda:0')\n(('West Kensington', 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(205., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(40., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(5., device='cuda:0')\n(('West Ruislip', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(64., device='cuda:0')\n(('Westbourne Park', 'Ladbroke Grove'), ('Ladbroke Grove', 'Latimer Road')) tensor(405., device='cuda:0')\n(('Westbourne Park', 'Royal Oak'), ('Royal Oak', 'Paddington')) tensor(780., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(5., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Temple')) tensor(525., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Bond Street')) tensor(1478., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(1051., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(353., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(101., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Victoria')) tensor(1205., device='cuda:0')\n(('Westminster', \"St. James's Park\"), (\"St. James's Park\", 'Victoria')) tensor(1204., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(372., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(319., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(3784., device='cuda:0')\n(('White City', 'East Acton'), ('East Acton', 'North Acton')) tensor(127., device='cuda:0')\n(('White City', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'Holland Park')) tensor(279., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(3522., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(2077., device='cuda:0')\n(('Whitechapel', 'Stepney Green'), ('Stepney Green', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Leyton')) tensor(2499., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'West Ham')) tensor(2098., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(512., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(27., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(8., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Kilburn'), ('Kilburn', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Junction', 'Harlesden'), ('Harlesden', 'Stonebridge Park')) tensor(405., device='cuda:0')\n(('Willesden Junction', 'Kensal Green'), ('Kensal Green', \"Queen's Park\")) tensor(678., device='cuda:0')\n(('Wimbledon', 'Wimbledon Park'), ('Wimbledon Park', 'Southfields')) tensor(299., device='cuda:0')\n(('Wimbledon Park', 'Southfields'), ('Southfields', 'East Putney')) tensor(456., device='cuda:0')\n(('Wood Green', 'Bounds Green'), ('Bounds Green', 'Arnos Grove')) tensor(479., device='cuda:0')\n(('Wood Green', 'Turnpike Lane'), ('Turnpike Lane', 'Manor House')) tensor(831., device='cuda:0')\n(('Wood Lane', 'Latimer Road'), ('Latimer Road', 'Ladbroke Grove')) tensor(346., device='cuda:0')\n(('Wood Lane', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Goldhawk Road')) tensor(133., device='cuda:0')\n(('Woodford', 'Buckhurst Hill'), ('Buckhurst Hill', 'Loughton')) tensor(683., device='cuda:0')\n(('Woodford', 'Roding Valley'), ('Roding Valley', 'Chigwell')) tensor(294., device='cuda:0')\n(('Woodford', 'South Woodford'), ('South Woodford', 'Snaresbrook')) tensor(1601., device='cuda:0')\n(('Woodside Park', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'High Barnet')) tensor(132., device='cuda:0')\n(('Woodside Park', 'West Finchley'), ('West Finchley', 'Finchley Central')) tensor(384., device='cuda:0')\n</pre> In\u00a0[5]: Copied! <pre>g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')]\n</pre> g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')] Out[5]: <pre>tensor(279., device='cuda:0')</pre> In\u00a0[6]: Copied! <pre>paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2)\ng2 = pp2.HigherOrderNetwork(paths, k=2)\nprint(g2)\n</pre> paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2) g2 = pp2.HigherOrderNetwork(paths, k=2) print(g2) <pre>2024-03-27 11:21:58 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:58 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:58 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n</pre> In\u00a0[7]: Copied! <pre>ks = range(1,10)\ntimes = []\nfor k in ks:\n    start = time.time() \n    paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)\n    g2 = pp2.HigherOrderNetwork(paths, k=k)\n    print(g2)\n    elapsed_pp = time.time()-start\n    times.append(elapsed_pp)\nplt.plot(ks, times)\n</pre> ks = range(1,10) times = [] for k in ks:     start = time.time()      paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)     g2 = pp2.HigherOrderNetwork(paths, k=k)     print(g2)     elapsed_pp = time.time()-start     times.append(elapsed_pp) plt.plot(ks, times) <pre>2024-03-27 11:21:59 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:59 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished.\nHigher-order network of order k = 1\n\nNodes:\t\t\t\t268\nLinks:\t\t\t\t646\nTotal weight (subpaths/longest paths):\t14404381.0/99956.0\n\n2024-03-27 11:22:00 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:00 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n2024-03-27 11:22:01 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:01 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished.\nHigher-order network of order k = 3\n\nNodes:\t\t\t\t1889\nLinks:\t\t\t\t1869\nTotal weight (subpaths/longest paths):\t10078001.0/230562.0\n\n2024-03-27 11:22:02 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:02 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:03 [Severity.INFO]\tfinished.\nHigher-order network of order k = 4\n\nNodes:\t\t\t\t5770\nLinks:\t\t\t\t2730\nTotal weight (subpaths/longest paths):\t8198110.0/236412.0\n\n2024-03-27 11:22:04 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:04 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:04 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:05 [Severity.INFO]\tfinished.\nHigher-order network of order k = 5\n\nNodes:\t\t\t\t19424\nLinks:\t\t\t\t3683\nTotal weight (subpaths/longest paths):\t6547275.0/243768.0\n\n2024-03-27 11:22:06 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:06 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:06 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:08 [Severity.INFO]\tfinished.\nHigher-order network of order k = 6\n\nNodes:\t\t\t\t66882\nLinks:\t\t\t\t4748\nTotal weight (subpaths/longest paths):\t5174028.0/209948.0\n\n2024-03-27 11:22:09 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:09 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:09 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:11 [Severity.INFO]\tfinished.\nHigher-order network of order k = 7\n\nNodes:\t\t\t\t242779\nLinks:\t\t\t\t5745\nTotal weight (subpaths/longest paths):\t4044268.0/176409.0\n\n2024-03-27 11:22:14 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:15 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:15 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:17 [Severity.INFO]\tfinished.\nHigher-order network of order k = 8\n\nNodes:\t\t\t\t888479\nLinks:\t\t\t\t6463\nTotal weight (subpaths/longest paths):\t3116104.0/151222.0\n\n2024-03-27 11:22:29 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:29 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:29 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:31 [Severity.INFO]\tfinished.\nHigher-order network of order k = 9\n\nNodes:\t\t\t\t3348421\nLinks:\t\t\t\t7053\nTotal weight (subpaths/longest paths):\t2349934.0/140450.0\n\n</pre> Out[7]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f081d30d9c0&gt;]</pre> In\u00a0[15]: Copied! <pre>pp.config['torch']['device'] = 'cuda:0'\n</pre> pp.config['torch']['device'] = 'cuda:0' In\u00a0[16]: Copied! <pre>ks = range(1,10)\ntimes_new_gpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_gpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_gpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_gpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[17]: Copied! <pre>pp.config['torch']['device'] = 'cpu'\n</pre> pp.config['torch']['device'] = 'cpu' In\u00a0[18]: Copied! <pre>ks = range(1,10)\ntimes_new_cpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_cpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_cpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_cpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[19]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.grid()\nplt.ylabel('time [s]')\nplt.legend()\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.grid() plt.ylabel('time [s]') plt.legend() Out[19]: <pre>&lt;matplotlib.legend.Legend at 0x7f082668d9f0&gt;</pre> In\u00a0[20]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.ylabel('time [s]')\nplt.legend()\nplt.grid()\nplt.yscale('log')\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.ylabel('time [s]') plt.legend() plt.grid() plt.yscale('log') In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/higher_order_scalability/#pathpy-20","title":"Pathpy 2.0\u00b6","text":""},{"location":"tutorial/higher_order_scalability/#pathpyg-gpu","title":"pathpyG (GPU)\u00b6","text":""},{"location":"tutorial/higher_order_scalability/#pathpyg-cpu","title":"pathpyG (CPU)\u00b6","text":""},{"location":"tutorial/multi_order_concepts/","title":"Multi order concepts","text":"In\u00a0[\u00a0]: Copied! <pre>def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int, edge_weights: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Do a line graph transformation on the edge index to lift the order of the graph by one.\n\n        Args:\n            edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n            num_nodes: The number of nodes in the graph.\n        \"\"\"\n\n        # Since this is a complicated function, we will use the following example to explain the steps:\n        # Example:\n        #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],\n        #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]\n\n        # Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge\n        # Example:\n        #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]\n        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n\n        # For each center node, we need to combine each outgoing edge with each incoming edge\n        # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index\n        # Example:\n        #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]\n        #   num_new_edges = 9\n        outdegree_per_dst = outdegree[edge_index[1]]\n        num_new_edges = outdegree_per_dst.sum()\n\n        # Use each edge from the edge index as node and assign the new indices in the order of the original edge index\n        # Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n        # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor\n        # Example:\n        #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]\n        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n        # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges\n        # (new higher-order nodes) that have the node as source node\n        # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and\n        # we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])\n        # Example:\n        #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]\n        ptrs = cumsum(outdegree, dim=0)[:-1]\n\n        # Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times\n        # Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively\n        # Example:\n        #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n\n        # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...)\n        # for all `outdegree` number of edges consecutively to get the correct destination nodes\n        # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\n        # Example:\n        #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n        # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.\n        # Example:\n        #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]\n        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n        # Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge\n        # Example:\n        #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts += idx_correction\n        # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n        #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</pre> def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int, edge_weights: torch.Tensor) -&gt; torch.Tensor:         \"\"\"         Do a line graph transformation on the edge index to lift the order of the graph by one.          Args:             edge_index: A **sorted** edge index tensor of shape (2, num_edges).             num_nodes: The number of nodes in the graph.         \"\"\"          # Since this is a complicated function, we will use the following example to explain the steps:         # Example:         #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],         #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]          # Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge         # Example:         #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]         outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)          # For each center node, we need to combine each outgoing edge with each incoming edge         # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index         # Example:         #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]         #   num_new_edges = 9         outdegree_per_dst = outdegree[edge_index[1]]         num_new_edges = outdegree_per_dst.sum()          # Use each edge from the edge index as node and assign the new indices in the order of the original edge index         # Each higher order node has one outgoing edge for each outgoing edge of the original destination node         # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor         # Example:         #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]         ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)          # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges         # (new higher-order nodes) that have the node as source node         # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and         # we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])         # Example:         #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]         ptrs = cumsum(outdegree, dim=0)[:-1]          # Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times         # Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively         # Example:         #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]         ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)          # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...)         # for all `outdegree` number of edges consecutively to get the correct destination nodes         # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)         # Example:         #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]         idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)         # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.         # Example:         #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]         idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]         # Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge         # Example:         #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]         ho_edge_dsts += idx_correction         # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],         #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])         return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)"},{"location":"tutorial/multi_order_concepts/#todo-create-a-notebook-that-explains-the-new-concepts-for-order-lifting-for-dags-and-temporal-graphs","title":"TODO: Create a Notebook that explains the new concepts for order lifting for DAGs and temporal graphs.\u00b6","text":""},{"location":"tutorial/netzschleuder/","title":"Accessing Netzschleuder","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[2]: Copied! <pre>import numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.decomposition import TruncatedSVD\n\nimport torch\nfrom torch.nn import Linear, ReLU, Sigmoid, Parameter\n\nimport torch_geometric\nfrom torch_geometric.nn import Sequential, GCNConv, SimpleConv, MessagePassing\n\nimport pathpyG as pp\n\npp.config['torch']['device'] = 'cpu'\n</pre> import numpy as np from matplotlib import pyplot as plt  from sklearn import metrics from sklearn.decomposition import TruncatedSVD  import torch from torch.nn import Linear, ReLU, Sigmoid, Parameter  import torch_geometric from torch_geometric.nn import Sequential, GCNConv, SimpleConv, MessagePassing  import pathpyG as pp  pp.config['torch']['device'] = 'cpu' In\u00a0[3]: Copied! <pre>g = pp.io.read_netzschleuder_network('polbooks')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_network('polbooks') print(g) <pre>Undirected graph with 105 nodes and 882 edges\n\nNode attributes\n\tnode_label\t\t&lt;class 'list'&gt;\n\tnode__pos\t\t&lt;class 'list'&gt;\n\tnode_value\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\ttags\t\t&lt;class 'list'&gt;\n\tcitation\t\t&lt;class 'str'&gt;\n\tdirected\t\t&lt;class 'float'&gt;\n\tname\t\t&lt;class 'str'&gt;\n\turl\t\t&lt;class 'str'&gt;\n\tdescription\t\t&lt;class 'str'&gt;\n\n</pre> <p>If we print the resulting <code>Graph</code> instance, we find that the meta information at the node- and grah-level are automatically retrieved and added to the graph.</p> <p>Let us read the famous karate club network. The record <code>karate club</code> actually contains two networks with labels <code>77</code> and <code>78</code>, which refer to two different versions of the graph data. If multiple graph data sets exist in the same record, we need to specify the name of the graph as second argument.</p> In\u00a0[4]: Copied! <pre>g = pp.io.read_netzschleuder_network('karate', '77')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_network('karate', '77') print(g) <pre>Undirected graph with 34 nodes and 154 edges\n\nNode attributes\n\tnode_name\t\t&lt;class 'list'&gt;\n\tnode__pos\t\t&lt;class 'list'&gt;\n\tnode_groups\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\ttags\t\t&lt;class 'list'&gt;\n\turl\t\t&lt;class 'str'&gt;\n\tname\t\t&lt;class 'str'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tcitation\t\t&lt;class 'str'&gt;\n\tname\t\t&lt;class 'str'&gt;\n\turl\t\t&lt;class 'str'&gt;\n\tdescription\t\t&lt;class 'str'&gt;\n\n</pre> In\u00a0[5]: Copied! <pre>pp.plot(g, edge_color='gray');\n</pre> pp.plot(g, edge_color='gray'); <p>We see that the nodes actually contain a <code>node_group</code> property, which maps the nodes to two groups. Those groups are often used as <code>ground truth</code> for communities in this simple illustrative graph. We will instead use it as ground truth categorical node label for a node classification experiment based on a Graph Neural Network.</p> In\u00a0[6]: Copied! <pre>print(g['node_groups'])\n</pre> print(g['node_groups']) <pre>[[1], [1], [1], [1], [1], [1], [1], [1], [1], [2], [1], [1], [1], [1], [2], [2], [1], [1], [2], [1], [2], [1], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2], [2]]\n</pre> <p>We can plot categorical labels by passing them as node colors in the pathpy plot function.</p> In\u00a0[7]: Copied! <pre>pp.plot(g, node_color = [g['node_groups',v][0] for v in g.nodes])\n</pre> pp.plot(g, node_color = [g['node_groups',v][0] for v in g.nodes]) Out[7]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fab2bf61720&gt;</pre> <p>For convenience, let us shift the group labels to binary values 0 and 1:</p> In\u00a0[8]: Copied! <pre>g['node_groups'] = torch.tensor(g['node_groups']).float()\ng['node_groups'] -= 1\nprint(g['node_groups'])\n</pre> g['node_groups'] = torch.tensor(g['node_groups']).float() g['node_groups'] -= 1 print(g['node_groups']) <pre>tensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])\n</pre> <p>We can retrieve a data object that contains the graph and its attributes:</p> In\u00a0[16]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 154], num_nodes=34, node_name=[34], node_groups=[34, 1], node__pos=[34], name='karate (77)', description='Network of friendships among members of a university karate club. Includes metadata for faction membership after a social partition. Note: there are two versions of this network, one with 77 edges and one with 78, due to an ambiguous typo in the original study. (The most commonly used is the one with 78 edges.)[^icon]\n[^icon]: Description obtained from the [ICON](https://icon.colorado.edu) project.', citation='['W. W. Zachary, \"An information flow model for conflict and fission in small groups.\" Journal of Anthropological Research 33, 452-473 (1977)., https://doi.org/10.1086/jar.33.4.3629752']', url='https://aaronclauset.github.io/datacode.htm', tags=[3], node_feature=[34, 34], x=[34, 34], y=[34, 1])\n</pre> <p>Let's use a one-hot encoding of nodes as a simple feature <code>x</code>, and let's use the node groups as target label <code>y</code>.</p> In\u00a0[10]: Copied! <pre>data = g.data\ng.add_node_ohe('node_feature')\ndata['x'] = data['node_feature']\ndata['y'] = data['node_groups']\n</pre> data = g.data g.add_node_ohe('node_feature') data['x'] = data['node_feature'] data['y'] = data['node_groups'] <p>It is easy to define a Graph Convolutional Network that ues the one-hot-encodings of nodes and the topology to predict binary node labels:</p> In\u00a0[23]: Copied! <pre>model = Sequential('node_ohe, edge_index', [\n    (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),\n    ReLU(inplace=True),\n    (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),\n    Sigmoid(),\n])\nmodel.to(pp.config['torch']['device'])\n</pre> model = Sequential('node_ohe, edge_index', [     (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),     ReLU(inplace=True),     (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),     Sigmoid(), ]) model.to(pp.config['torch']['device']) Out[23]: <pre>Sequential(\n  (0) - GCNConv(34, 8): node_ohe, edge_index -&gt; hidden\n  (1) - ReLU(inplace=True): hidden -&gt; hidden\n  (2) - GCNConv(8, 1): hidden, edge_index -&gt; output\n  (3) - Sigmoid(): output -&gt; output\n)</pre> <p>We next apply a <code>RandomNodeSplit</code> transformation to split the nodes in a training and test set.</p> In\u00a0[24]: Copied! <pre>transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0)\ndata = transform(data)\n</pre> transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0) data = transform(data) <p>We then train our model for 1000 epochs on the training set.</p> In\u00a0[25]: Copied! <pre>epochs = 1000\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n    \nlosses = []\n\nmodel.train()\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)\n    loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n\n    losses.append(loss.cpu().detach().numpy())\n\nplt.plot(range(epochs), losses)\nplt.grid()\n</pre> epochs = 1000  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)      losses = []  model.train() for epoch in range(epochs):     optimizer.zero_grad()     out = model(data.x, data.edge_index)     loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])     loss.backward()     optimizer.step()      losses.append(loss.cpu().detach().numpy())  plt.plot(range(epochs), losses) plt.grid() <p>We evaluate the model in the test set and calculate the adjusted mutual information for the ground truth.</p> In\u00a0[26]: Copied! <pre>model.eval()\npredicted_groups = model(data.x, data.edge_index).round().long()\nmetrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy())\n</pre> model.eval() predicted_groups = model(data.x, data.edge_index).round().long() metrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy()) Out[26]: <pre>1.0</pre> <p>We visualize node representations learned by the model. The training nodes are colored, while test nodes are greyed out.</p> In\u00a0[27]: Copied! <pre># get activations in first-layer\nembedding = model[0].forward(data.x, data.edge_index)\n\n# dimensionality reduction\nsvd = TruncatedSVD()\nlow_dim = svd.fit_transform(embedding.cpu().detach().numpy())\n\n# plot with colors corresponding to groups in validation set\ncolors = {}\nfor v in range(g.N):\n    if data.val_mask[v]:\n        colors[v] = 'grey'\n    else:\n        if data.y[v].item() == 0.0:\n            colors[v] = 'blue'\n        else:\n            colors[v] = 'orange'\n\nplt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values());\n</pre> # get activations in first-layer embedding = model[0].forward(data.x, data.edge_index)  # dimensionality reduction svd = TruncatedSVD() low_dim = svd.fit_transform(embedding.cpu().detach().numpy())  # plot with colors corresponding to groups in validation set colors = {} for v in range(g.N):     if data.val_mask[v]:         colors[v] = 'grey'     else:         if data.y[v].item() == 0.0:             colors[v] = 'blue'         else:             colors[v] = 'orange'  plt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values()); <p>This simple code gives you thousands of networks with various meta information at your fingertips, to wich you can directly apply graph learning models provided in pyG, or deep graoh learning architectures defined by yourself.</p>"},{"location":"tutorial/netzschleuder/#accessing-the-netzschleuder-repository","title":"Accessing the Netzschleuder Repository\u00b6","text":""},{"location":"tutorial/netzschleuder/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/netzschleuder/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>Access to a large number of graphs with different topological characteristics and from different domains is crucial for the development and evaluation of graph learning methods. Tousands of graph data sets are available scattered throughout the web, possibly using different data formats and with missing information on their actual origin. Addressing this issue the Netschleuder Online Repository by Tiago Peixoto provides a single repository of graphs in a single format, including descriptions, citations, and node-/edge- or graph-level meta-data. To facilitate the development of graph learning techniques, pathpyG provides a feature that allows to directly read networks from the netzschleuder repository via an API.</p> <p>In this brief unit, we will learn how we can retrieve network records and graph data from the netzschleuder repository. We will further demonstrate how we can conveniently apply a Graph Neural Network to predict node-level categories contained in the meta-data.</p> <p>We first need to import a few modules.</p>"},{"location":"tutorial/netzschleuder/#reading-graphs-from-the-netzschleuder-repository","title":"Reading graphs from the netzschleuder repository\u00b6","text":"<p>In the <code>pathpy.io</code> module, there is a function that allows to read graph data from the API.</p> <p>We can read a given networks from the netzschleuder database using its record name. Just browse the Netschleuder Online Repository to find the record names. In the following, we use a graph capturing co-purchase relationships between political books.</p>"},{"location":"tutorial/netzschleuder/#applying-graph-neural-networks-to-netzschleuder-data","title":"Applying Graph Neural Networks to Netzschleuder Data\u00b6","text":""},{"location":"tutorial/new_pathData_test/","title":"new pathData test","text":"In\u00a0[39]: Copied! <pre>from typing import Optional\n\nfrom tqdm import trange\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.experimental import disable_dynamic_shapes\nfrom torch_geometric.nn.aggr import Aggregation\nfrom torch_geometric.utils import coalesce, degree, cumsum\nfrom torch_geometric import EdgeIndex\n\nimport pathpyG as pp\n</pre> from typing import Optional  from tqdm import trange import torch from torch import Tensor from torch_geometric.data import Data from torch_geometric.loader import DataLoader from torch_geometric.nn import MessagePassing from torch_geometric.experimental import disable_dynamic_shapes from torch_geometric.nn.aggr import Aggregation from torch_geometric.utils import coalesce, degree, cumsum from torch_geometric import EdgeIndex  import pathpyG as pp In\u00a0[40]: Copied! <pre>dags = pp.DAGData()\ndags.append(torch.tensor([[3,0,1],[0,1,2]]))\ndags.append(torch.tensor([[1,0,2],[0,2,0]]))\ndags.append(torch.tensor([[0,1],[1,2]]))\n</pre> dags = pp.DAGData() dags.append(torch.tensor([[3,0,1],[0,1,2]])) dags.append(torch.tensor([[1,0,2],[0,2,0]])) dags.append(torch.tensor([[0,1],[1,2]])) In\u00a0[41]: Copied! <pre>print(dags)\n</pre> print(dags) <pre>DAGData with 3 dags and total weight 3\n</pre> In\u00a0[50]: Copied! <pre>def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor, num_nodes: int | None = None) -&gt; torch.Tensor:\n        # Since this is a complicated function, we will use the following example to explain the steps:\n        # Example:\n        #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],\n        #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]\n\n        # Compute the outdegree of each node which we will use to get all the edge combinations that lead to a higher order edge\n        # Example:\n        #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]\n        outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n\n        # For each center node, we need to combine each outgoing edge with each incoming edge\n        # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index\n        # Example:\n        #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]\n        #   num_new_edges = 9\n        outdegree_per_dst = outdegree[edge_index[1]]\n        num_new_edges = outdegree_per_dst.sum()\n\n        # We use each edge from the edge index as new node and assign the new indices in the order of the original edge index\n        # Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n        # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor\n        # Example:\n        #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]\n        ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n        # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges (new higher order nodes) that have the node as source node\n        # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])\n        # Example:\n        #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]\n        ptrs = cumsum(outdegree, dim=0)[:-1]\n\n        # Use these pointers to get the start of the edges for each higher order source node and repeat it `outdegree` times\n        # Since we keep the ordering, all new higher order edges that have the same source node are indexed consecutively\n        # Example:\n        #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n\n        # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) for all `outdegree` number of edges consecutively to get the correct destination nodes\n        # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\n        # Example: \n        #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n        idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n        # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.\n        # Example:\n        #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]\n        idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n        # Finally, we add this tensor to the destination nodes to get the correct destination nodes for each higher order edge\n        # Example:\n        #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]\n        ho_edge_dsts += idx_correction\n    # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n    #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n        return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</pre> def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor, num_nodes: int | None = None) -&gt; torch.Tensor:         # Since this is a complicated function, we will use the following example to explain the steps:         # Example:         #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],         #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]          # Compute the outdegree of each node which we will use to get all the edge combinations that lead to a higher order edge         # Example:         #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]         outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)          # For each center node, we need to combine each outgoing edge with each incoming edge         # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index         # Example:         #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]         #   num_new_edges = 9         outdegree_per_dst = outdegree[edge_index[1]]         num_new_edges = outdegree_per_dst.sum()          # We use each edge from the edge index as new node and assign the new indices in the order of the original edge index         # Each higher order node has one outgoing edge for each outgoing edge of the original destination node         # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor         # Example:         #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]         ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)          # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges (new higher order nodes) that have the node as source node         # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])         # Example:         #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]         ptrs = cumsum(outdegree, dim=0)[:-1]          # Use these pointers to get the start of the edges for each higher order source node and repeat it `outdegree` times         # Since we keep the ordering, all new higher order edges that have the same source node are indexed consecutively         # Example:         #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]         ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)          # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) for all `outdegree` number of edges consecutively to get the correct destination nodes         # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)         # Example:          #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]         idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)         # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.         # Example:         #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]         idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]         # Finally, we add this tensor to the destination nodes to get the correct destination nodes for each higher order edge         # Example:         #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]         ho_edge_dsts += idx_correction     # tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],     #         [2, 3, 4, 5, 5, 8, 6, 7, 7]])         return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0) In\u00a0[77]: Copied! <pre>def map_higher_order_index(edge_indices, k):\n    \"\"\"map node indices in k-th order edge index\n    to corresponding tensor of k first-order nodes\n    \"\"\" \n\n    # we need to reverse the node indices\n    # to construct an edge_index with k-th order nodes\n    \n    ei = edge_indices[k].reshape(2,-1,1)\n    \n    j = 0\n    for i in range(k-1, 0, -1):\n        src_edge, tgt_edge = ei\n        src = edge_indices[i][:,src_edge]\n        tgt = edge_indices[i][:,tgt_edge]\n        if j == 0:\n            ei = torch.cat([src, tgt], dim=2)\n        else:\n            ei = torch.cat([src[:,:,:j], tgt], dim=2)\n        j -= 1\n    return ei\n</pre> def map_higher_order_index(edge_indices, k):     \"\"\"map node indices in k-th order edge index     to corresponding tensor of k first-order nodes     \"\"\"       # we need to reverse the node indices     # to construct an edge_index with k-th order nodes          ei = edge_indices[k].reshape(2,-1,1)          j = 0     for i in range(k-1, 0, -1):         src_edge, tgt_edge = ei         src = edge_indices[i][:,src_edge]         tgt = edge_indices[i][:,tgt_edge]         if j == 0:             ei = torch.cat([src, tgt], dim=2)         else:             ei = torch.cat([src[:,:,:j], tgt], dim=2)         j -= 1     return ei In\u00a0[81]: Copied! <pre>def from_DAGs(data: pp.DAGData, max_order: int = 1) -&gt; pp.MultiOrderModel:\n    \"\"\"Creates multiple higher-order De Bruijn graphs for paths in DAGData.\"\"\"\n    m = pp.MultiOrderModel()\n\n    data_list = [Data(edge_index=dag.long()) for dag in data.dags]\n    # We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs\n    # If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards\n    # Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once\n    dag_graph = next(iter(DataLoader(data_list, batch_size=len(data.dags))))\n    dag_edge_index = dag_graph.edge_index\n    dag_edge_index = coalesce(dag_edge_index)\n\n    print(dag_edge_index)\n    print(dag_graph.ptr)\n    print(dag_graph.batch)\n\n    edge_index = pp.MultiOrderModel.map_batch_indices(dag_edge_index, dag_graph.batch, dag_graph.ptr)\n    unique_nodes = torch.unique(edge_index)\n    m.layers[1] = pp.Graph(Data(edge_index=edge_index, num_nodes=unique_nodes.size(), fo_nodes=unique_nodes.reshape(-1, 1)))\n    print(m.layers[1].data.edge_index)\n    print(m.layers[1].data.fo_nodes)\n\n    edge_indices = {}\n    edge_indices[1] = edge_index\n\n    for k in range(2, max_order+1):\n        print('=== k={0} ==='.format(k))\n        num_nodes = torch.unique(dag_edge_index).size(0)\n        print('num nodes = ', num_nodes)\n        ho_index = lift_order_edge_index(dag_edge_index, num_nodes = num_nodes)\n        edge_indices[k] = ho_index\n        print(ho_index)\n\n        # Map k-th-order edge index to nodes in (k-1)-th order edge index\n        # src_edge, tgt_edge = ho_index\n        # src = dag_edge_index[:,src_edge]\n        # tgt = dag_edge_index[:,tgt_edge]\n        # print(src)\n        # print(tgt)\n\n        #ho_edge_index, inverse = x.unique(dim=0, return_inverse=True)\n\n        # weights of the two unique higher-order edges should be N and 3*N\n        # weights of k-th element in output = sum of all w at indices where inverse is k\n        #weights = torch.zeros(ho_edge_index.size()[0], device=config['torch']['device'], dtype=torch.long).index_add(0, inverse, w)\n \n\n        #m.layers[k] = pp.Graph(data=Data(edge_index=dag_edge_index))\n\n        dag_edge_index = coalesce(ho_index)\n\n    return m, edge_indices\n</pre> def from_DAGs(data: pp.DAGData, max_order: int = 1) -&gt; pp.MultiOrderModel:     \"\"\"Creates multiple higher-order De Bruijn graphs for paths in DAGData.\"\"\"     m = pp.MultiOrderModel()      data_list = [Data(edge_index=dag.long()) for dag in data.dags]     # We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs     # If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards     # Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once     dag_graph = next(iter(DataLoader(data_list, batch_size=len(data.dags))))     dag_edge_index = dag_graph.edge_index     dag_edge_index = coalesce(dag_edge_index)      print(dag_edge_index)     print(dag_graph.ptr)     print(dag_graph.batch)      edge_index = pp.MultiOrderModel.map_batch_indices(dag_edge_index, dag_graph.batch, dag_graph.ptr)     unique_nodes = torch.unique(edge_index)     m.layers[1] = pp.Graph(Data(edge_index=edge_index, num_nodes=unique_nodes.size(), fo_nodes=unique_nodes.reshape(-1, 1)))     print(m.layers[1].data.edge_index)     print(m.layers[1].data.fo_nodes)      edge_indices = {}     edge_indices[1] = edge_index      for k in range(2, max_order+1):         print('=== k={0} ==='.format(k))         num_nodes = torch.unique(dag_edge_index).size(0)         print('num nodes = ', num_nodes)         ho_index = lift_order_edge_index(dag_edge_index, num_nodes = num_nodes)         edge_indices[k] = ho_index         print(ho_index)          # Map k-th-order edge index to nodes in (k-1)-th order edge index         # src_edge, tgt_edge = ho_index         # src = dag_edge_index[:,src_edge]         # tgt = dag_edge_index[:,tgt_edge]         # print(src)         # print(tgt)          #ho_edge_index, inverse = x.unique(dim=0, return_inverse=True)          # weights of the two unique higher-order edges should be N and 3*N         # weights of k-th element in output = sum of all w at indices where inverse is k         #weights = torch.zeros(ho_edge_index.size()[0], device=config['torch']['device'], dtype=torch.long).index_add(0, inverse, w)            #m.layers[k] = pp.Graph(data=Data(edge_index=dag_edge_index))          dag_edge_index = coalesce(ho_index)      return m, edge_indices In\u00a0[82]: Copied! <pre>m, edge_indices = from_DAGs(dags, max_order=3)\n</pre> m, edge_indices = from_DAGs(dags, max_order=3) <pre>tensor([[0, 1, 3, 4, 5, 6, 7, 8],\n        [1, 2, 0, 6, 4, 4, 8, 9]])\ntensor([ 0,  4,  7, 10])\ntensor([0, 0, 0, 0, 1, 1, 1, 2, 2, 2])\nEdgeIndex([[0, 0, 0, 1, 1, 1, 2, 3],\n           [1, 2, 1, 2, 0, 2, 0, 0]], sparse_size=(4, 4), nnz=8,\n          sort_order=row)\ntensor([[0],\n        [1],\n        [2],\n        [3]])\n=== k=2 ===\nnum nodes =  10\ntensor([[0, 2, 3, 4, 5, 6],\n        [1, 0, 5, 3, 3, 7]])\n=== k=3 ===\nnum nodes =  8\ntensor([[1, 2, 3, 4],\n        [0, 4, 2, 2]])\n</pre> In\u00a0[89]: Copied! <pre>map_higher_order_index(edge_indices, k=3)\n</pre> map_higher_order_index(edge_indices, k=3) Out[89]: <pre>tensor([[[3, 0, 1],\n         [0, 2, 0],\n         [1, 0, 2],\n         [2, 0, 2]],\n\n        [[0, 1, 2],\n         [2, 0, 2],\n         [0, 2, 0],\n         [0, 2, 0]]])</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/new_pathData_working/","title":"new pathData working","text":"In\u00a0[1]: Copied! <pre>from typing import Optional\n\nfrom tqdm import trange\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.experimental import disable_dynamic_shapes\nfrom torch_geometric.nn.aggr import Aggregation\nfrom torch_geometric.utils import coalesce, degree, cumsum\nfrom torch_geometric import EdgeIndex\n\nimport pathpyG as pp\npp.config['torch']['device'] = 'cuda'\n</pre> from typing import Optional  from tqdm import trange import torch from torch import Tensor from torch_geometric.data import Data from torch_geometric.loader import DataLoader from torch_geometric.nn import MessagePassing from torch_geometric.experimental import disable_dynamic_shapes from torch_geometric.nn.aggr import Aggregation from torch_geometric.utils import coalesce, degree, cumsum from torch_geometric import EdgeIndex  import pathpyG as pp pp.config['torch']['device'] = 'cuda' In\u00a0[2]: Copied! <pre># Example with walks as node sequences\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c')])\ndags = pp.DAGData(mapping = g.mapping)\n\ndags.append_walk(('a', 'b', 'c', 'b'), weight=1.0)\ndags.append_walk(('a', 'c'), weight = 2.0)\nprint(dags)\n</pre> # Example with walks as node sequences g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c')]) dags = pp.DAGData(mapping = g.mapping)  dags.append_walk(('a', 'b', 'c', 'b'), weight=1.0) dags.append_walk(('a', 'c'), weight = 2.0) print(dags) <pre>DAGData with 2 dags with total weight 3.0\n</pre> In\u00a0[5]: Copied! <pre># Example with walks as edge indices (with no mapping)\ndags = pp.DAGData()\ndags.append_dag(torch.tensor([[3,0,1],[0,1,2]]))\ndags.append_dag(torch.tensor([[1,0,2],[0,2,0]]))\ndags.append_dag(torch.tensor([[0,1],[1,2]]))\nprint(dags)\n</pre> # Example with walks as edge indices (with no mapping) dags = pp.DAGData() dags.append_dag(torch.tensor([[3,0,1],[0,1,2]])) dags.append_dag(torch.tensor([[1,0,2],[0,2,0]])) dags.append_dag(torch.tensor([[0,1],[1,2]])) print(dags) <pre>DAGData with 3 dags with total weight 3.0\n</pre> In\u00a0[\u00a0]: Copied! <pre># Example with mix of walks or dags\ndags = pp.DAGData(mapping = g.mapping)\n\ndags.append_dag(torch.tensor([[0,0,1],[1,2,2]]))\ndags.append_walk(('a', 'b', 'c'))\nprint(dags)\n</pre> # Example with mix of walks or dags dags = pp.DAGData(mapping = g.mapping)  dags.append_dag(torch.tensor([[0,0,1],[1,2,2]])) dags.append_walk(('a', 'b', 'c')) print(dags) In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(dags, max_order=2)\n</pre> m = pp.MultiOrderModel.from_DAGs(dags, max_order=2) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[1].data.edge_index)\nprint(m.layers[1].data.node_sequences)\nprint(m.layers[1].mapping)\n</pre> print(m.layers[1].data.edge_index) print(m.layers[1].data.node_sequences) print(m.layers[1].mapping) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.edge_index)\nprint(m.layers[2].data.node_sequences)\nprint(m.layers[2].mapping)\n</pre> print(m.layers[2].data.edge_index) print(m.layers[2].data.node_sequences) print(m.layers[2].mapping) In\u00a0[\u00a0]: Copied! <pre># Real-world example\ndags = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nprint(dags)\n</pre> # Real-world example dags = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') print(dags) In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(dags, max_order=10)\n</pre> m = pp.MultiOrderModel.from_DAGs(dags, max_order=10) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[3].mapping)\n</pre> print(m.layers[3].mapping) In\u00a0[\u00a0]: Copied! <pre>pp.plot(m.layers[10], node_label=list(map(str, m.layers[1].data.node_sequences.tolist())))\n</pre> pp.plot(m.layers[10], node_label=list(map(str, m.layers[1].data.node_sequences.tolist()))) In\u00a0[\u00a0]: Copied! <pre>dags.map_node_seq(m.layers[10].data.node_sequences[5].tolist())\n</pre> dags.map_node_seq(m.layers[10].data.node_sequences[5].tolist()) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.edge_index)\n</pre> print(m.layers[2].data.edge_index) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.edge_weights)\n</pre> print(m.layers[2].data.edge_weights) In\u00a0[\u00a0]: Copied! <pre>print(m.layers[2].data.node_sequences)\n</pre> print(m.layers[2].data.node_sequences) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/paths_higher_order/","title":"Paths and Higher-Order Models","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[2]: Copied! <pre>import torch\nimport pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\npp.config['torch']['device'] = 'cpu'\n</pre> import torch import pathpyG as pp from torch_geometric.data import Data from torch_geometric import EdgeIndex  pp.config['torch']['device'] = 'cpu' <p>For the following examples, we consider a simple directed graph with five nodes <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>, <code>e</code> and four edges:</p> In\u00a0[2]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\npp.plot(g, node_label=g.mapping.node_ids, edge_color='gray');\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c', 'e')]) pp.plot(g, node_label=g.mapping.node_ids, edge_color='gray'); In\u00a0[3]: Copied! <pre>print(g.mapping)\n</pre> print(g.mapping) <pre>a -&gt; 0\nc -&gt; 1\nb -&gt; 2\nd -&gt; 3\ne -&gt; 4\n\n</pre> <p>With this mapping, we can use the following ordered <code>edge_index</code> with source and target node indices to represent the walk <code>a</code> -&gt; <code>c</code> -&gt; <code>d</code>:</p> <pre><code>torch.tensor([ [0,2], # node indices of `a` and `c`  \n               [2,3]  # node indices of `c` and `d`\n             ])   \n</code></pre> <p>Note that this representation naturally extends the <code>edge_index</code> semantics of <code>pyG</code>. This allows us to efficiently generate higher-order De Bruijn graph models for path data based on a convolution operation that can be executed on the GPU.</p> <p>Let us now use this representation to generate a Walk data set that can be used in <code>pathpyG</code>. We first create an instance of the <code>WalkData</code> class, which is a subclass of <code>PathData</code>. To consistently map node IDs to indices across <code>Graph</code> and <code>PathData</code> objects, we can pass the <code>IndexMap</code> object from the <code>Graph</code> above in the constructor. We then use the <code>add</code> function to add observations of our two walks, where the <code>freq</code> argument is used to indicate the number of times each path has been observed.</p> In\u00a0[28]: Copied! <pre>paths = pp.WalkData(g.mapping)\npaths.add(torch.tensor([[0,1],[1,3]]), freq=2) # a -&gt; c -&gt; d\npaths.add(torch.tensor([[2,1],[1,4]]), freq=2) # b -&gt; c -&gt; e\nprint(paths)\n</pre> paths = pp.WalkData(g.mapping) paths.add(torch.tensor([[0,1],[1,3]]), freq=2) # a -&gt; c -&gt; d paths.add(torch.tensor([[2,1],[1,4]]), freq=2) # b -&gt; c -&gt; e print(paths) <pre>PathData with 2 walks and total weight 4\n</pre> <p>Let us inspect how the walks are internally stored in the <code>WalkData</code> object. Each observation is internally assigned an integer identifier and there are two dictionaries that store the tensors capturing the observed path as well as their frequencies.</p> In\u00a0[29]: Copied! <pre>paths.paths\n</pre> paths.paths Out[29]: <pre>{0: tensor([[0, 1],\n         [1, 3]]),\n 1: tensor([[2, 1],\n         [1, 4]])}</pre> In\u00a0[30]: Copied! <pre>paths.path_freq\n</pre> paths.path_freq Out[30]: <pre>{0: 2, 1: 2}</pre> <p>For convenience, there is a helper function that can be used to transform the tensor-based <code>edge_index</code> representation of a given walk into a simple sequence of traversed nodes, i.e. for the walk with index 0 above we get the node index sequence <code>[0,2,3]</code>:</p> In\u00a0[31]: Copied! <pre>pp.WalkData.walk_to_node_seq(paths.paths[0])\n</pre> pp.WalkData.walk_to_node_seq(paths.paths[0]) Out[31]: <pre>tensor([0, 1, 3])</pre> <p>Each <code>PathData</code> object has an <code>edge_index</code> property, which yields an edge index tensor of the aggregated graph representation of all paths. We can further get the number of nodes and the number of edges that are traversed by the paths.</p> In\u00a0[5]: Copied! <pre>print(f'Paths traverse {paths.num_nodes} nodes via {paths.num_edges} edges')\nprint(paths.edge_index)\n</pre> print(f'Paths traverse {paths.num_nodes} nodes via {paths.num_edges} edges') print(paths.edge_index) <pre>Paths traverse 5 nodes via 4 edges\ntensor([[0, 1, 1, 2],\n        [1, 3, 4, 1]])\n</pre> <p>We could use the <code>Graph.from_edge_index</code> function to generate a (first-order) aggregate graph representation that can be visualized:</p> In\u00a0[7]: Copied! <pre>pp.plot(pp.Graph.from_edge_index(paths.edge_index.contiguous(), paths.mapping), edge_color='gray', node_label=paths.mapping.node_ids);\n</pre> pp.plot(pp.Graph.from_edge_index(paths.edge_index.contiguous(), paths.mapping), edge_color='gray', node_label=paths.mapping.node_ids); <p>We can also create a weighted <code>edge_index</code> where the edge weights capture the number of times each edge is traversed. This function returnes two tensors, the first being the edge index and the second being the edge weights. In our example, each edge is observed two times.</p> In\u00a0[8]: Copied! <pre>print(paths.edge_index_weighted)\n</pre> print(paths.edge_index_weighted) <pre>(tensor([[0, 1, 1, 2],\n        [1, 3, 4, 1]]), tensor([2., 2., 2., 2.]))\n</pre> <p>The internal tensor-based representation of walks directly corresponds to the <code>pyG</code> representation of edges, which provides several advantages. However, it is often cumbersome to manually create those tensors for walks that can easily be represented as a sequence of nodes. The <code>WalkData</code> class thus provides methods to add walks based on a sequencde of node IDs, i.e. we can write the following more readable code to obtain the same <code>WalkData</code> instance as above:</p> In\u00a0[9]: Copied! <pre>paths_1 = pp.WalkData(g.mapping)\n\npaths_1.add_walk_seq(('a', 'c', 'd'), freq=2)\npaths_1.add_walk_seq(('b', 'c', 'e'), freq=2)\nprint(paths_1)\nprint(paths_1.edge_index_weighted)\n</pre> paths_1 = pp.WalkData(g.mapping)  paths_1.add_walk_seq(('a', 'c', 'd'), freq=2) paths_1.add_walk_seq(('b', 'c', 'e'), freq=2) print(paths_1) print(paths_1.edge_index_weighted) <pre>PathData with 2 walks and total weight 4\n(tensor([[0, 1, 1, 2],\n        [1, 3, 4, 1]], dtype=torch.int32), tensor([2., 2., 2., 2.]))\n</pre> <p>At this point, you may ask why data on paths and walks are interesting in the first place. The answer is that they provide a lot of information on the causal topology of networked systems, i.e. which nodes can causally influence each other.</p> <p>For this, let us assume that the four walks above tell us which paths information (or whatever you may be interested in) have taken in graph above. That is, we observe something moving from <code>a</code> via <code>c</code> to <code>d</code> and from <code>b</code> via <code>c</code> to <code>e</code>, and each of those events occur twice. However, we never observed that something moving from <code>a</code> to <code>c</code> ended up in <code>d</code>. Neither did we observe that something moving from <code>b</code> to <code>c</code> ended up in <code>e</code>. This means that - assuming that we have completely observed all walks or paths - there is no way how <code>a</code> can causally influence <code>e</code> or how <code>b</code> could causally influence <code>d</code>. Note that this is not what we would assume based on the topology of the underlying graph, where paths of length two exist between all fair pairs of nodes (<code>a</code>, <code>d</code>), (<code>a</code>, <code>e</code>), (<code>b</code>, <code>d</code>), (<code>b</code>, <code>e</code>).</p> <p>As a contrast, consider the following four observations of walks in the same graph.</p> In\u00a0[10]: Copied! <pre>paths_2 = pp.WalkData(g.mapping)\n\npaths_2.add_walk_seq(('a', 'c', 'd'), freq=1)\npaths_2.add_walk_seq(('a', 'c', 'e'), freq=1)\npaths_2.add_walk_seq(('b', 'c', 'd'), freq=1)\npaths_2.add_walk_seq(('b', 'c', 'e'), freq=1)\nprint(paths_2)\n</pre> paths_2 = pp.WalkData(g.mapping)  paths_2.add_walk_seq(('a', 'c', 'd'), freq=1) paths_2.add_walk_seq(('a', 'c', 'e'), freq=1) paths_2.add_walk_seq(('b', 'c', 'd'), freq=1) paths_2.add_walk_seq(('b', 'c', 'e'), freq=1) print(paths_2) <pre>PathData with 4 walks and total weight 4\n</pre> <p>Here we have observed walks along all four possible paths of length two. It is easy to see that the weighted edge index of this <code>WalkData</code> instance is identical to the one before:</p> In\u00a0[11]: Copied! <pre>print(paths_2.edge_index_weighted)\n</pre> print(paths_2.edge_index_weighted) <pre>(tensor([[0, 1, 1, 2],\n        [1, 3, 4, 1]], dtype=torch.int32), tensor([2., 2., 2., 2.]))\n</pre> <p>This is a first-order graph representation, as it only captures the (weighted) edges in the underlying path data, i.e. we could say that we only count the frequency of paths (or walks) of length one. This naturally gives rise to an <code>edge_index</code> tensor with shape $(2,m)$, where $m$ is the number of unique edges in the graph that are traversed by the paths.</p> In\u00a0[12]: Copied! <pre>edge_index, weights = paths_1.edge_index_k_weighted(k=1)\nprint('first-order edges =', edge_index)\nprint('weights =', weights)\n</pre> edge_index, weights = paths_1.edge_index_k_weighted(k=1) print('first-order edges =', edge_index) print('weights =', weights) <pre>first-order edges = tensor([[0, 1, 1, 2],\n        [1, 3, 4, 1]], dtype=torch.int32)\nweights = tensor([2., 2., 2., 2.])\n</pre> <p>For $k=2$, we get the edge index of a second-order De Bruijn graph where the second-order nodes are first-order edges and second-order edges represent walks of length two in the original graph. The edge weights capture the observation frequencies of those walks.</p> In\u00a0[13]: Copied! <pre>edge_index, weights = paths_1.edge_index_k_weighted(k=2)\nprint('second-order edges =', edge_index)\nprint('weights =', weights)\n</pre> edge_index, weights = paths_1.edge_index_k_weighted(k=2) print('second-order edges =', edge_index) print('weights =', weights) <pre>second-order edges = tensor([[[0, 1],\n         [2, 1]],\n\n        [[1, 3],\n         [1, 4]]], dtype=torch.int32)\nweights = tensor([2., 2.])\n</pre> <p>Naturally extending the <code>pyG</code>-style <code>edge_index</code> to a higher-dimensional representation, the edge_index of a k-th De Bruijn graph model with m edges has the shape [2,m,k], i.e. it consists of a src and dst tensor with $m$ entries, where each entry is a k-dimensional tensor that contains the $k$ nodes in the graph that constitute the higher-order node. For the example above, each node in this second-order model is actually represented by a tensor with two elements.</p> <p>While this goes way beyond the scope of this tutorial, thanks to the tensor-based representation of paths, the construction of a higher-order De Bruijn graph model can actually be done based on efficient GPU operations, i.e. we can scale up the models for large graphs.</p> <p>Let us have a closer look at our examples above. While the first-order edge indices of the two path objects <code>paths_1</code> and <code>paths_2</code> are the same, we find that the second-order edge indices are actually different:</p> In\u00a0[14]: Copied! <pre>edge_index, weights = paths_2.edge_index_k_weighted(k=2)\nprint('second-order edges =', edge_index)\nprint('weights =', weights)\n</pre> edge_index, weights = paths_2.edge_index_k_weighted(k=2) print('second-order edges =', edge_index) print('weights =', weights) <pre>second-order edges = tensor([[[0, 1],\n         [0, 1],\n         [2, 1],\n         [2, 1]],\n\n        [[1, 3],\n         [1, 4],\n         [1, 3],\n         [1, 4]]], dtype=torch.int32)\nweights = tensor([1., 1., 1., 1.])\n</pre> <p>We thus find that the second-order De Bruijn graph representation of paths is sensitive to the differences in the causal topology, while a first-order graph is not. This is the basis to generalize network analysis and graph learning to causality-aware graph models for various kinds of time series data on graphs.</p> <p>In particular, as we shall see in more detail in a later tutorial, we can use paths to generate k-th order graphs that can be used to generalize Graph Neural Networks. <code>pathpyG</code> provides the class <code>HigherOrderGraph</code>, which is a subclass of <code>Graph</code> and provides additional functionality that simplifies the analysis of higher-order De Bruijn graphs. For convenience, we can directly create a $k$-th order De Bruijn graph from any instance of <code>PathData</code>. For the two examples above, we can create and plot the associated second-order De Bruijn graph models as follows:</p> In\u00a0[15]: Copied! <pre>g2 = pp.HigherOrderGraph(paths_1, order=2)\nprint(g2)\n</pre> g2 = pp.HigherOrderGraph(paths_1, order=2) print(g2) <pre>HigherOrderGraph (k=2) with 4 nodes and 2 edges\n\tTotal edge weight = 4.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Just like for a \"normal\" first-order graph, we can iterate through the nodes of a higher-order graph, which are tuples with k elements. Just as for a normal <code>Graph</code> object, the node indices are automatically mapped, yielding tuples of first-order node identifiers.</p> In\u00a0[17]: Copied! <pre>for n in g2.nodes:\n    print(n)\n</pre> for n in g2.nodes:     print(n) <pre>('a', 'c')\n('c', 'd')\n('c', 'e')\n('b', 'c')\n</pre> <p>Edges are tuples with two elements, where each element is a k-th order node, i.e. a tuple of node IDs of length $k$.</p> In\u00a0[20]: Copied! <pre>for e in g2.edges:\n    print(e)\n</pre> for e in g2.edges:     print(e) <pre>(('a', 'c'), ('c', 'd'))\n(('b', 'c'), ('c', 'e'))\n</pre> <p>The weight attribute stores a tensor whose entries capture the frequencies of edges, i.e. the frequencies of paths of length $k$.</p> In\u00a0[21]: Copied! <pre>for e in g2.edges:\n    print(e, g2['edge_weight', e[0], e[1]].item())\n</pre> for e in g2.edges:     print(e, g2['edge_weight', e[0], e[1]].item()) <pre>(('a', 'c'), ('c', 'd')) 2.0\n(('b', 'c'), ('c', 'e')) 2.0\n</pre> <p>We can finally plot a higher-order De Bruijn graph in the same way as a first-order graph.</p> In\u00a0[24]: Copied! <pre>pp.plot(g2, node_label=[g2.mapping.to_id(x) for x in range(g2.N)], edge_color='gray');\n</pre> pp.plot(g2, node_label=[g2.mapping.to_id(x) for x in range(g2.N)], edge_color='gray'); <p>Let us compare this to a second-order graph model of the second path data set from above, which corresponds to a system where all paths of length two are actually realized in terms of walks.</p> In\u00a0[\u00a0]: Copied! <pre>g2 = pp.HigherOrderGraph(paths_2, order=2)\nprint(g2)\npp.plot(g2, node_label=[g2.mapping.to_id(x) for x in range(g2.N)], edge_color='gray');\n</pre> g2 = pp.HigherOrderGraph(paths_2, order=2) print(g2) pp.plot(g2, node_label=[g2.mapping.to_id(x) for x in range(g2.N)], edge_color='gray'); <pre>HigherOrderGraph (k=2) with 4 nodes and 4 edges\n\tTotal edge weight = 4.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[26]: Copied! <pre>paths_tube = pp.WalkData.from_csv('../data/tube_paths_train.ngram', sep=',', freq=True)\nprint(paths_tube)\nprint(f'London Tube network has {paths_tube.num_nodes} nodes and {paths_tube.num_edges} edges.')\n</pre> paths_tube = pp.WalkData.from_csv('../data/tube_paths_train.ngram', sep=',', freq=True) print(paths_tube) print(f'London Tube network has {paths_tube.num_nodes} nodes and {paths_tube.num_edges} edges.') <pre>PathData with 61748 walks and total weight 2147865\nLondon Tube network has 268 nodes and 646 edges.\n</pre> <p>Note that this will automatically create an internal mapping of node IDs to indices.</p> In\u00a0[32]: Copied! <pre>paths = pp.DAGData(mapping = pp.IndexMap(['a', 'b', 'c', 'd']))\npaths.add(torch.tensor([[0, 1, 1],\n                        [1, 2, 3]]),\n                        freq=2)\n</pre> paths = pp.DAGData(mapping = pp.IndexMap(['a', 'b', 'c', 'd'])) paths.add(torch.tensor([[0, 1, 1],                         [1, 2, 3]]),                         freq=2) <p>We can now again inspect the internal dictionaries holding our data:</p> In\u00a0[33]: Copied! <pre>print(paths.paths)\nprint(paths.path_freq)\n</pre> print(paths.paths) print(paths.path_freq) <pre>{0: tensor([[0, 1, 1],\n        [1, 2, 3]])}\n{0: 2}\n</pre> <p>At first glance, it may seem unnecessary to distinguish between walks and DAGs, as a walk is simply a special type of a DAG, where all nodes have in- and out-degrees smaller or equal than one. And indeed, you could simply ignore this distinction and store both walks and DAGs as a DAG. Nevertheless, <code>pathpyG</code> explicitly distinguishes between the two types of path data, since some downstream operations - specifically the creation of higher-order De Bruijn graph models - are much more straight-forward and thus faster for walks (which are essentially just sequences of nodes) than for DAGs (which can have arbitrarily complex branching structures).</p> <p>As shown before, we can use the <code>PathData</code> class to easily generate an <code>edge_index</code> tensor of a weighted graph representation, which essentially aggregates all of the observed walks or DAGs into a weighted static graph. For the DAG above, this graph has four nodes connected by three edges that have weights two (because we have observed the DAG twice).</p> In\u00a0[34]: Copied! <pre>edge_index, edge_weight = paths.edge_index_weighted\nprint(edge_index)\nprint(edge_weight)\n</pre> edge_index, edge_weight = paths.edge_index_weighted print(edge_index) print(edge_weight) <pre>tensor([[0, 1, 1],\n        [1, 2, 3]])\ntensor([2., 2., 2.])\n</pre> <p>Let's have a look at a visualization of this graph:</p> In\u00a0[37]: Copied! <pre>g = pp.Graph.from_edge_index(edge_index.contiguous(), mapping=paths.mapping)\npp.plot(g, edge_color='gray', node_label=paths.mapping.node_ids);\n</pre> g = pp.Graph.from_edge_index(edge_index.contiguous(), mapping=paths.mapping) pp.plot(g, edge_color='gray', node_label=paths.mapping.node_ids); In\u00a0[38]: Copied! <pre>for e in g.edges:\n    print(e)\n</pre> for e in g.edges:     print(e) <pre>('a', 'b')\n('b', 'c')\n('b', 'd')\n</pre> In\u00a0[42]: Copied! <pre>g2 = pp.HigherOrderGraph(paths, order=2)\nprint(g2)\npp.plot(g2, edge_color='gray', node_label=[g2.mapping.to_id(x) for x in range(g2.N)]);\n</pre> g2 = pp.HigherOrderGraph(paths, order=2) print(g2) pp.plot(g2, edge_color='gray', node_label=[g2.mapping.to_id(x) for x in range(g2.N)]); <pre>HigherOrderGraph (k=2) with 3 nodes and 2 edges\n\tTotal edge weight = 4.0\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>As we shall see in the following tutorial, the <code>PathData</code> and the <code>HigherOrderGraph</code> classes are the basis for the GPU-based analysis and modelling of causal structures in temporal graphs. In particular, the underlying generalization of first-order static graph models to higher-order De Bruijn graphs allows us to easily build causality-aware graph neural network architectures that consider both the topology and the temoral ordering of time-stamped edges in a temporal graph.</p>"},{"location":"tutorial/paths_higher_order/#paths-and-higher-order-de-bruijn-graph-models","title":"Paths and Higher-Order De Bruijn Graph Models\u00b6","text":""},{"location":"tutorial/paths_higher_order/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/paths_higher_order/#motivation-and-learning-objective","title":"Motivation and Learning Objective\u00b6","text":"<p>While <code>pathpyG</code> is useful to handle and visualize static graphs - as the name suggests - its main advantage is that it facilitates the analysis of time series data that can be used to calculate paths in a graph. As we shall see in the following tutorial, there are various situations in which naturally have access to data on paths, including data on (random) walks or trajectories, traces of dynamical processes giving rise to node sequences or directed acyclic graphs, or temporal graph data with time-stamped edges. ``pathpyG` ca nbe used to model patterns in such data based on higher-order De Bruijn graph models, a modelling framework that captures patterns in time series data on graphs.</p> <p>In this first unit, we will introduce classes to store data on walks and directed acyclic graphs. We will show how such data are internally stored as tensors, and how this approach facilitates a GPU-based generation of higher-order De Bruijn graph models.</p> <p>We first import the modules <code>torch</code> and <code>pathpyG</code>. By setting the device used by <code>torch</code>, we can specify whether we want to run our code on the CPU or on the GPU.</p>"},{"location":"tutorial/paths_higher_order/#using-walkdata-to-store-walks-in-a-graph","title":"Using <code>WalkData</code> to store walks in a graph\u00b6","text":"<p>Assume that we have time series data that captures observations of walks in the graph above. For example, we could observe four walks of length two, two each of the following:</p> <ul> <li>2 x <code>a</code> -&gt; <code>c</code> -&gt; <code>d</code></li> <li>2 x <code>b</code> -&gt; <code>c</code> -&gt; <code>e</code></li> </ul> <p>Note that we define the length of a walk as the number of edges that are traversed, i.e. a sequence that consists of a single node, e.g. <code>a</code>, is considered a walk of length zero, while every edge in a graph is a walk of length one.</p> <p><code>pathpyG</code> supports to store and model such data based on subclasses of the abstract class <code>pp.PathData</code>. Generally, this class provides functions to store different types of pathway data of length $l$ in the form of tensor with shape $(2,l), which is essentially an ordered version of an <code>pyG</code> edge index. To better understand this, let us consider the mapping of node IDs to node indices that is given by the graph above:</p>"},{"location":"tutorial/paths_higher_order/#from-graphs-to-higher-order-de-bruijn-graph-models","title":"From Graphs to Higher-Order De Bruijn Graph Models\u00b6","text":"<p>A key feature of <code>pathpyG</code> is it allows to generalize this first-order modelling perspective to $k$-th order De Bruijn graph models for paths, where the nodes in a $k$-th order De Bruijn graph model are sequences of $k$ nodes. Edges connect pairs of nodes that overlap in $k-1$ nodes and capture paths of length $k$.</p> <p>A De Bruijn graph of order $k=1$ is simply a normal (weighted) graph consisting of nodes and edges. Pairs of nodes connected by edges overlap in $k-1=0$ nodes and capture paths of length $k=1$, i.e. simple edges in the underlying path data.</p> <p>For a De Bruijn graph with order $k=2$, in our example above, an edge could connect a pair of nodes $(a,b)$ and $(b,c)$ that overlaps in the $k-1=1$ node $b$ and such an edge would represent the walk $a -&gt; b -&gt; c$ of length two.</p> <p>All instances of <code>PathData</code> provide methods to calculate an edge index of such a k-th order De Bruijn graph. We can pass the order of the model that we seek to create as the argument $k$. For $k=1$ we obtain the same edge index and weights as before.</p>"},{"location":"tutorial/paths_higher_order/#loading-empirical-walks-from-n-gram-files","title":"Loading empirical walks from N-Gram Files\u00b6","text":"<p>For real data on walks in graphs it is not convenient to manually construct and add walks based on edge tensors. We can instead use the <code>from_csv</code> function of class <code>WalkData</code> to load such data from an n-gram file, i.e. a text file where each line corresponds to one observed walk consisting of comma-separated node IDs. If we set the argument <code>freq=True</code>, the last component of each line is considered to be the observation frequency of that particular walk.</p> <p>As an example, the file <code>data/tube_paths_train.ngram</code> contains observed passenger itineraries between nodes in a graph that representes the network of London Tube stations. Each of those itineraries is associated with an observation frequencies. The following is an excerpt from that file:</p> <pre><code>Southwark,Waterloo,212.0\nLiverpool Street,Bank / Monument,1271.0\nBarking,West Ham,283.0\nTufnell Park,Kentish Town,103.0\n...\n</code></pre> <p>Let us now read this file:</p>"},{"location":"tutorial/paths_higher_order/#from-walks-to-directed-acyclic-graphs","title":"From Walks to Directed Acyclic Graphs\u00b6","text":"<p>An important feature of <code>pathpyG</code> is that it allows us to model the causal topology of temporal graphs, i.e. the topology of time-stamped edges by which nodes can causally influence each other via time-respecting paths, i.e. paths that must (minimally) follow the arrow of time.</p> <p>As we shall see in the following detailed tutorial, time-respecting paths in temporal graphs naturally give rise to directed acyclic graphs (DAGs), where the directionality of edges is due to the directionality of the arrow of time. Thus, the analysis of time-respecting paths in temporal graphs naturally gives rise to a (possibly large) collection of DAGs, which can be stored using the class <code>DAGData</code>, another subclass of the base class <code>PathData</code>.</p> <p>A very simple example for a DAG is one that consists of the following edges:</p> <p><code>a</code> -&gt; <code>b</code> <code>b</code> -&gt; <code>c</code> <code>b</code> -&gt; <code>d</code></p> <p>This DAG captures that node <code>a</code> causally influences node <code>b</code>, which in turn causally influences the two nodes <code>c</code> and <code>d</code> (potentially at a later point in time). In <code>pathpyG</code>, such a DAG can be represented by a topologically ordered edge index, where the order of edges corresponds to the topological ordering. For the example above, and assuming the same node ID mapping as in the example before, we can add two observations of this DAG to a <code>DAGData</code> object as follows:</p>"},{"location":"tutorial/temporal_betweenness/","title":"Temporal betweenness","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\nimport torch\n\nfrom collections import deque\n\nfrom scipy.sparse.csgraph import bellman_ford, dijkstra\nimport numpy as np\nfrom time import time\nfrom collections import defaultdict\n\n\nfrom tqdm import tqdm\n</pre> import pathpyG as pp from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index import torch  from collections import deque  from scipy.sparse.csgraph import bellman_ford, dijkstra import numpy as np from time import time from collections import defaultdict   from tqdm import tqdm In\u00a0[2]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('../data/sociopatterns_highschool_2013_train.tedges')\nprint(t_sp)\nprint(torch.unique(t_sp.data.t).size(0))\n</pre> t_sp = pp.TemporalGraph.from_csv('../data/sociopatterns_highschool_2013_train.tedges') print(t_sp) print(torch.unique(t_sp.data.t).size(0)) <pre>Temporal Graph with 327 nodes, 8950 unique edges and 220378 events in [1385982080.0, 1386163840.0]\n\nGraph attributes\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([220378])\n\n579\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[3]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=3600, max_order=2)\nprint(m)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=3600, max_order=2) print(m) <pre>MultiOrderModel with max. order 2\n</pre> In\u00a0[4]: Copied! <pre>t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges')\nprint(t_ants)\n</pre> t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges') print(t_ants) <pre>Temporal Graph with 68 nodes, 506 unique edges and 1045 events in [899.0, 1796.0]\n\nGraph attributes\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'t', 'src', 'dst'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=10)\nprint(m)\nprint(m.layers[1].data.edge_weight)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=10) print(m) print(m.layers[1].data.edge_weight) <pre>MultiOrderModel with max. order 10\ntensor([ 2.,  1.,  1.,  3.,  3.,  1.,  2.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,\n         1.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,  1.,  5.,  2.,  6.,  6.,  1.,\n         1.,  3.,  3.,  1.,  1.,  3.,  1.,  2.,  9.,  3.,  1.,  1.,  4.,  1.,\n         1.,  1.,  4.,  2.,  3.,  2.,  1.,  4.,  3.,  2.,  4.,  1.,  1.,  3.,\n         1.,  2.,  3.,  1.,  1.,  4.,  2.,  9.,  5.,  1.,  2.,  4.,  1.,  2.,\n         1.,  1.,  1.,  3.,  4.,  1.,  2.,  3.,  4.,  1.,  1.,  3.,  4.,  4.,\n         3.,  4.,  3.,  1.,  2.,  3.,  1.,  2.,  4.,  2.,  1.,  1.,  1.,  1.,\n         1.,  1.,  1.,  2.,  1.,  3.,  1.,  4.,  1.,  1.,  1.,  1.,  5.,  2.,\n         1.,  1.,  2.,  1.,  1.,  2.,  1.,  4.,  3.,  4.,  1.,  2.,  1.,  1.,\n         1.,  2.,  3.,  1.,  4.,  1.,  3.,  3.,  1.,  1.,  3.,  1.,  2.,  1.,\n         1.,  4.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  3.,  1.,  3.,  1.,  1.,\n         1.,  1.,  3.,  2.,  2.,  2.,  2.,  1.,  1.,  2.,  4.,  3.,  1.,  2.,\n         2.,  3.,  5.,  5.,  2.,  1.,  2.,  1.,  1.,  5.,  2.,  3.,  2.,  1.,\n         1.,  2.,  5.,  1.,  1.,  2.,  2.,  6.,  1.,  2.,  4.,  1.,  2.,  5.,\n         4.,  5.,  1.,  1.,  2.,  1.,  3.,  6.,  2.,  1.,  1.,  1.,  2.,  2.,\n        12.,  7.,  4.,  1.,  1.,  1.,  4.,  2.,  1.,  1.,  1.,  3.,  2.,  1.,\n         1.,  1.,  2.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n         1.,  6.,  1.,  4.,  2.,  2.,  1.,  2.,  2.,  3.,  3.,  2.,  4.,  4.,\n         1.,  7.,  5.,  1.,  2.,  2.,  1.,  2.,  4.,  4.,  5.,  6.,  4.,  1.,\n         2.,  2.,  1.,  4.,  3.,  1.,  1.,  1.,  5.,  7.,  1.,  3.,  5.,  1.,\n         1.,  4.,  1.,  1.,  2.,  1.,  6.,  4.,  2.,  2.,  1.,  4.,  1.,  1.,\n         5.,  1.,  2.,  3.,  4.,  1.,  1.,  1.,  2.,  1.,  2.,  2.,  3.,  1.,\n         2.,  7.,  1.,  7.,  1.,  2.,  1.,  2.,  1.,  3.,  1.,  3.,  3.,  1.,\n         3.,  3.,  1.,  4.,  3.,  2.,  2.,  1.,  1.,  1.,  3.,  1.,  1.,  3.,\n         1.,  1.,  3.,  1.,  6.,  1.,  3.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,\n         1.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  5.,  2.,  4.,  1.,  3.,  4.,\n         3.,  1.,  2.,  2.,  2.,  1.,  2.,  1.,  3.,  2.,  2.,  1.,  5.,  1.,\n         3.,  1.,  2.,  3.,  2.,  2.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,  2.,\n         1.,  2.,  3.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  4.,\n         1.,  2.,  1.,  5.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,\n         2.,  1.,  2.,  2.,  2.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,\n         3.,  2.,  1.,  2.,  1.,  1.,  3.,  1.,  1.,  1.,  3.,  1.,  1.,  1.,\n         2.,  1.,  1.,  3.,  5.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,  4.,  5.,\n         1.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  3.,  1.,  1.,  1.,  1.,  1.,\n         3.,  2.,  1.,  1.,  3.,  2.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,\n         2.,  1.,  1.,  1.,  2.,  1.,  1.,  4.,  2.,  1.,  3.,  3.,  3.,  3.,\n         1.,  1.])\n</pre> In\u00a0[3]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=3600)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=3600) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 579/579 [00:53&lt;00:00, 10.79it/s]\n 31%|\u2588\u2588\u2588       | 102/327 [26:29&lt;58:26, 15.59s/it]  \n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_sp, delta=3600)\n      2 print(bw)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:255, in temporal_betweenness_centrality(g, delta)\n    253 v = Q.popleft()\n    254 # for all successor events within delta\n--&gt; 255 for w in event_graph.successors(v):\n    256 \n    257     # we dicover w for the first time\n    258     if dist[w] == -1:\n    259         dist[w] = dist[v] + 1\n\nFile /workspaces/pathpyG/src/pathpyG/core/Graph.py:295, in Graph.successors(self, node)\n    283 def successors(self, node: Union[int, str] | tuple) \\\n    284         -&gt; Generator[Union[int, str] | tuple, None, None]:\n    285     \"\"\"Return all successors of a given node.\n    286 \n    287     This method returns a generator object that yields all successors of a\n   (...)\n    292         node:   Index or string ID of node for which successors shall be returned.\n    293     \"\"\" \n--&gt; 295     for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n    296         yield self.mapping.to_id(j.item())\n\nKeyboardInterrupt: </pre> In\u00a0[4]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=30)\nprint(bw)\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=30) print(bw) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 4581.51it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7f9453f36cb0&gt;, {0: 9.083333333333336, 7: 15.0, 10: 114.12687232787852, 1: 5.0, 6: 9.5, 12: 35.060389610389606, 22: 58.61201533244884, 49: 2.500000000000001, 2: 346.2515994755158, 27: 249.9532851737187, 4: 140.7880952380952, 42: 28.220839755359876, 28: 146.0366185070518, 65: 15.791666666666675, 29: 190.04444444444454, 24: 26.736796536796536, 5: 126.14722222222221, 3: 40.32903828197944, 35: 3.9999999999999996, 9: 7.5, 17: 78.59657287157289, 20: 68.21558441558443, 48: 27.916666666666664, 11: 99.25000000000001, 15: 53.07553688141922, 8: 5.8571428571428585, 26: 118.34098235785545, 37: -0.33333333333333304, 34: 58.120919946926136, 23: 49.347619047619034, 16: -0.1666666666666714, 32: 1.3333333333333286, 46: 2.40126050420168, 19: -1.8611111111111098, 36: 1.0000000000000004, 39: 2.0, 14: 25.33333333333333, 31: 1.5, 21: 0.5555555555555536, 33: 2.1666666666666705, 13: 0.0, 18: -5.19444444444445, 25: -1.9984014443252818e-15, 41: 14.888888888888886, 57: 1.0, 52: 13.833333333333332, 51: 2.916666666666661, 44: 2.999999999999999, 47: 1.5, 38: 0.0, 40: 0.0, 62: -7.444444444444445, 56: 0.0, 61: 0.0, 67: 2.220446049250313e-16})\n</pre> In\u00a0[7]: Copied! <pre>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt_long = pp.TemporalGraph.from_edge_list(tedges)\nc = pp.algorithms.centrality.temporal_closeness_centrality(t_long, 5)\nprint(c)\n</pre> tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),               ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),               ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),               ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),               ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)] t_long = pp.TemporalGraph.from_edge_list(tedges) c = pp.algorithms.centrality.temporal_closeness_centrality(t_long, 5) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 4453.94it/s]</pre> <pre>Created temporal event DAG with 38 nodes and 47 edges\n{'a': 12.0, 'b': 16.0, 'c': 16.0, 'd': 14.666666666666666, 'e': 14.666666666666666, 'f': 24.0, 'g': 14.666666666666666, 'h': 28.0, 'i': 24.0}\n</pre> <pre>\n</pre> In\u00a0[9]: Copied! <pre>c = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, 3600)\n</pre> c = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, 3600) <pre>  0%|          | 0/1157 [00:00&lt;?, ?it/s]</pre> <pre>  4%|\u258e         | 43/1157 [00:05&lt;02:18,  8.05it/s]\n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 c = pp.algorithms.centrality.temporal_closeness_centrality(t_sp, 3600)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:186, in temporal_closeness_centrality(g, delta)\n    172 \"\"\"Calculates the closeness of nodes based on observed shortest paths\n    173 between all nodes. Following the definition by M. A. Beauchamp 1965\n    174 (https://doi.org/10.1002/bs.3830100205).\n   (...)\n    183 dict\n    184 \"\"\"\n    185 centralities = dict()\n--&gt; 186 dist, _ = temporal_shortest_paths(g, delta)\n    187 for x in g.nodes:\n    188     centralities[x] = sum((g.N - 1) / dist[_np.arange(g.N) != g.mapping.to_idx(x), g.mapping.to_idx(x)])\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/temporal.py:59, in temporal_shortest_paths(g, delta)\n     57 def temporal_shortest_paths(g: TemporalGraph, delta: int):\n     58     # generate temporal event DAG\n---&gt; 59     edge_index = lift_order_temporal(g, delta)\n     61     # Add indices of g.N first-order nodes as source nodes of paths in augmented TEG\n     62     src_edges_src = g.data.edge_index[0] + g.M\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/temporal.py:51, in lift_order_temporal(g, delta)\n     49         src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n     50         dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n---&gt; 51         ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n     52         second_order.append(ho_edge_index)\n     54 ho_index = torch.cat(second_order, dim=1)    \n\nKeyboardInterrupt: </pre> In\u00a0[4]: Copied! <pre>print(c)\n</pre> print(c) <pre>{'454': 41671.338095238054, '640': 42220.10476190471, '1': 31384.485714285773, '939': 43385.1666666666, '185': 46485.271428571396, '258': 42662.533333333326, '55': 41131.62698412695, '170': 43822.54999999994, '9': 55537.204761904715, '453': 42306.650000000016, '45': 54390.77142857138, '14': 42915.57142857141, '190': 51695.83809523803, '400': 37502.9365079365, '637': 40505.24126984126, '255': 43516.342857142794, '275': 53779.13333333323, '176': 52638.13333333328, '533': 36436.70952380954, '116': 46335.46666666662, '151': 46517.87142857134, '866': 51019.77619047604, '280': 40957.63095238092, '484': 38709.39523809525, '243': 42567.83809523808, '687': 43355.67142857139, '54': 44738.06666666662, '364': 43477.92142857135, '374': 41239.258730158705, '295': 37942.38968253968, '441': 44693.04761904753, '101': 46261.46984126977, '425': 40808.355411255354, '47': 34439.18333333336, '241': 40734.0880952381, '179': 51910.84285714278, '202': 47549.81666666654, '63': 48038.816666666564, '564': 38769.93809523808, '577': 34370.49047619052, '265': 42888.016666666605, '494': 40898.7698412698, '443': 42818.935714285675, '209': 33025.35238095244, '843': 39757.76984126982, '222': 31847.612698412748, '205': 43918.02142857136, '894': 39705.247619047565, '1359': 54767.9999999999, '1383': 37680.55476190476, '376': 53616.13333333324, '638': 41859.176190476144, '1238': 42806.904761904734, '1260': 38609.26666666665, '487': 46472.59365079362, '984': 45297.69999999997, '226': 42690.47619047611, '353': 46454.99999999993, '1342': 44222.67619047608, '1518': 59688.27142857133, '122': 48889.13333333324, '1067': 42078.83809523807, '1324': 41852.96666666664, '70': 44801.455555555476, '132': 47628.98809523799, '779': 42758.522222222164, '279': 42601.21428571425, '908': 36329.59523809524, '510': 29415.290476190487, '545': 44361.355555555485, '634': 49410.73333333322, '1332': 57435.76666666657, '1401': 48332.21666666656, '582': 44306.50476190468, '605': 55865.5333333332, '252': 45385.02142857135, '3': 50445.78333333325, '884': 48080.34285714278, '339': 41450.89999999998, '691': 48490.171428571346, '869': 47797.033333333246, '72': 48899.99999999993, '954': 46840.76666666663, '160': 47314.2428571428, '117': 46867.93333333327, '346': 41061.76984126978, '111': 45678.421428571404, '124': 43084.39285714283, '276': 42882.58333333332, '621': 39236.16984126983, '39': 41416.11255411249, '871': 44988.38809523805, '694': 49321.4714285713, '778': 49137.51428571418, '513': 39579.116666666654, '236': 35266.21428571434, '883': 40068.50476190471, '1594': 46784.104761904644, '1828': 41670.949999999946, '1214': 48579.43333333323, '196': 47528.471428571334, '201': 44797.83333333326, '245': 53325.838095237974, '390': 44972.08809523807, '938': 44610.77142857142, '923': 37550.54285714288, '106': 58207.29999999987, '272': 55849.23333333323, '753': 43170.54999999998, '486': 35035.81507936507, '531': 41168.10793650794, '254': 48965.199999999975, '382': 44808.699999999975, '119': 45078.038095238015, '240': 46369.36031746025, '447': 45610.11666666662, '649': 42277.54285714276, '1204': 46224.08333333323, '466': 32600.38809523813, '841': 37388.707142857165, '199': 43105.73809523804, '674': 54227.77142857136, '857': 38546.395238095225, '945': 40750.388095238064, '1218': 47321.61666666656, '1512': 51657.80476190465, '653': 49398.44365079353, '502': 44192.40476190468, '587': 29551.511904761897, '626': 41647.27619047614, '420': 45023.704761904715, '504': 40343.27619047614, '311': 46414.63809523806, '267': 44915.038095238066, '177': 48121.22222222215, '480': 40095.671428571455, '771': 23901.880158730197, '312': 46976.59999999993, '612': 43187.238095238026, '450': 36801.13095238098, '89': 47408.54999999997, '322': 49383.56666666663, '520': 33164.678571428616, '15': 45297.70000000002, '211': 47992.633333333324, '366': 37022.86269841269, '227': 45639.99999999996, '440': 48286.033333333275, '41': 47324.33333333326, '388': 47221.100000000006, '219': 42089.70476190474, '658': 48671.79999999991, '220': 42779.73809523808, '576': 39435.90952380952, '642': 46664.57142857137, '391': 37692.58571428572, '777': 35597.647619047646, '20': 39938.88095238094, '958': 50489.638095238006, '103': 29371.176984127007, '61': 47813.333333333234, '274': 36857.53412698415, '147': 51953.53333333325, '277': 32935.18492063496, '702': 30786.81904761907, '242': 44846.73333333334, '38': 52752.233333333206, '438': 37185.73333333332, '387': 46914.11666666656, '1295': 49073.866666666545, '1412': 52219.76666666659, '492': 47707.3833333333, '1345': 46802.733333333235, '1212': 51198.29999999987, '28': 45031.466666666616, '327': 45873.63333333326, '1216': 50562.59999999988, '372': 52590.526984126904, '720': 45705.19999999992, '1784': 41720.23809523804, '27': 46151.50952380945, '171': 34138.926984126985, '1336': 43007.54999999995, '1423': 52198.03333333327, '1366': 37297.11666666668, '407': 48333.3809523809, '1320': 46319.16666666659, '1805': 47327.438095237994, '1237': 41225.8047619047, '974': 29733.65793650794, '464': 45232.49999999995, '477': 42176.24999999997, '763': 36072.546825396836, '1894': 45776.221428571334, '1201': 43844.28333333326, '1228': 50051.86666666656, '786': 37304.61984126989, '886': 43075.46666666661, '797': 47585.13333333329, '959': 34756.25714285715, '1485': 41606.13809523808, '210': 46916.83333333329, '4': 42904.70476190475, '790': 30436.757142857183, '285': 53224.9333333333, '544': 43005.609523809464, '333': 50127.93333333329, '622': 35464.14285714289, '429': 45130.042857142784, '46': 39267.476190476154, '343': 37518.719047619066, '867': 36621.44285714288, '615': 44610.7714285714, '977': 42285.30476190473, '90': 46425.50476190473, '269': 44197.83809523808, '603': 46936.23809523808, '335': 43720.48095238093, '765': 43121.64999999997, '257': 41894.10476190469, '268': 39532.9333333333, '214': 43410.00476190473, '491': 43702.240476190455, '181': 39791.01666666664, '650': 40985.18571428571, '85': 46765.993650793615, '325': 43602.49999999998, '941': 39712.62142857144, '356': 40737.58095238093, '744': 37414.70952380953, '1543': 46257.07142857135, '145': 43442.992857142846, '173': 41173.02380952376, '909': 33217.84761904766, '79': 48995.083333333285, '854': 38707.45476190475, '527': 43498.49047619046, '475': 39621.94826839824, '471': 43425.269841269816, '681': 27453.98650793652, '465': 36373.57936507936, '446': 35151.33809523811, '58': 49894.29999999995, '32': 42986.204761904744, '991': 44181.53809523805, '725': 39806.15238095237, '859': 40474.45238095238, '798': 41875.088095238054, '256': 49459.63333333331, '306': 39031.514285714235, '131': 41163.70952380949, '677': 38990.11746031743, '960': 34713.56666666667, '769': 37148.47619047621, '248': 38814.18095238095, '125': 46992.89999999995, '917': 38007.71904761903, '120': 49546.566666666615, '115': 45982.68809523806, '1519': 34333.75079365083, '970': 40702.264285714264, '213': 46737.6744588744, '424': 48813.06666666662, '428': 42515.5746031746, '488': 47845.93333333331, '498': 44651.5214285714, '809': 40044.96031746028, '92': 42035.37142857144, '845': 43173.26666666668, '655': 34575.92222222225, '156': 47349.171428571295, '413': 44792.400000000016, '21': 38381.0666666667, '1232': 35705.92619047622, '290': 40728.654761904734, '71': 41315.0666666667, '65': 44592.919047619034, '791': 34942.5428571429, '874': 43733.67619047614, '448': 45072.60476190477, '496': 49872.56666666665, '921': 36919.888095238115, '497': 35312.785714285754, '627': 36676.94047619046, '194': 44672.866666666676, '927': 43220.614285714255, '232': 52527.138095238035, '172': 45822.40476190471, '165': 26068.48650793651, '87': 42138.604761904746, '253': 39907.833333333365, '706': 47116.05555555552, '134': 48729.23809523806, '624': 38011.988095238106, '548': 33913.83174603179, '893': 44520.73333333333, '920': 41900.31428571425, '836': 44773.91255411253, '80': 47968.5714285714, '743': 40576.13333333335, '826': 46025.76666666668, '184': 49569.076190476095, '601': 51230.89999999998, '1870': 34552.11904761907, '200': 45851.899999999994, '784': 39126.209523809506, '751': 34508.53477633482, '434': 23954.014285714296, '979': 35987.0365079365, '647': 36782.50238095241, '246': 36560.12380952383, '489': 43239.24285714284, '998': 42595.00476190477, '435': 38087.278571428564, '468': 21858.55058830061, '48': 42347.78809523811, '1339': 44040.27142857138, '159': 40869.921428571426, '149': 25296.729725829755, '1819': 39140.180952380964, '525': 45662.50952380946, '882': 28492.9174603175, '34': 43807.543650793574, '239': 31866.888095238148, '62': 20550.960028860038, '452': 43745.06031746028, '445': 28096.385447885485}\n</pre> In\u00a0[5]: Copied! <pre>def temporal_event_graph(g: pp.TemporalGraph, delta=1): \n\n    print(g.data.edge_index)\n\n    # generate temporal event DAG\n    edge_index = pp.algorithms.lift_order_temporal(g, delta)\n    print(edge_index)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.data.edge_index.size(1)\n    print(src_edges_src)\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.data.edge_index[1] + g.data.edge_index.size(1) + g.N\n    print(dst_edges_dst)\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    event_graph = pp.Graph.from_edge_index(edge_index) \n    return event_graph\n</pre> def temporal_event_graph(g: pp.TemporalGraph, delta=1):       print(g.data.edge_index)      # generate temporal event DAG     edge_index = pp.algorithms.lift_order_temporal(g, delta)     print(edge_index)      # Add indices of first-order nodes as src and dst of paths in augmented     # temporal event DAG     src_edges_src = g.data.edge_index[0] + g.data.edge_index.size(1)     print(src_edges_src)     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.data.edge_index[1] + g.data.edge_index.size(1) + g.N     print(dst_edges_dst)      # add edges from source to edges and from edges to destinations     src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      # create sparse scipy matrix     event_graph = pp.Graph.from_edge_index(edge_index)      return event_graph In\u00a0[10]: Copied! <pre>eg = pp.algorithms.lift_order_temporal(t_long, delta=5)\nprint(eg)\n</pre> eg = pp.algorithms.lift_order_temporal(t_long, delta=5) print(eg) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 3068.65it/s]</pre> <pre>tensor([[ 0,  1,  1,  4,  5,  8, 12],\n        [ 1,  2,  3,  5,  6, 11, 14]])\n</pre> <pre>\n</pre> In\u00a0[11]: Copied! <pre>print(temporal_event_graph(t_long, delta=5))\n</pre> print(temporal_event_graph(t_long, delta=5)) <pre>tensor([[0, 1, 2, 2, 2, 5, 0, 1, 0, 7, 2, 6, 0, 0, 2, 5, 1, 8, 2, 7],\n        [1, 2, 3, 4, 5, 0, 6, 5, 6, 5, 5, 7, 2, 1, 7, 7, 8, 1, 8, 8]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 3405.44it/s]</pre> <pre>tensor([[ 0,  1,  1,  4,  5,  8, 12],\n        [ 1,  2,  3,  5,  6, 11, 14]])\ntensor([20, 21, 22, 22, 22, 25, 20, 21, 20, 27, 22, 26, 20, 20, 22, 25, 21, 28,\n        22, 27])\ntensor([30, 31, 32, 33, 34, 29, 35, 34, 35, 34, 34, 36, 31, 30, 36, 36, 37, 30,\n        37, 37])\nDirected graph with 38 nodes and 47 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <pre>\n</pre> In\u00a0[13]: Copied! <pre>def betweenness_brandes(g: pp.Graph, sources = None):\n    bw = defaultdict(lambda: 0.0)\n\n    if sources == None:\n        sources = [v for v in g.nodes]\n\n    for s in tqdm(sources):\n        S = list()\n        P = defaultdict(list)\n\n        sigma = defaultdict(lambda: 0)  \n        sigma[s] = 1\n\n        d = defaultdict(lambda: -1)        \n        d[s] = 0\n\n        Q = [s]\n        while Q:\n            v = Q.pop(0)\n            S.append(v)\n            for w in g.successors(v):\n                if d[w] &lt; 0:\n                    Q.append(w)\n                    d[w] = d[v] + 1\n                if d[w] == d[v] + 1:\n                    # we found shortest path from s via v to w\n                    sigma[w] = sigma[w] + sigma[v]\n                    P[w].append(v)\n        delta = defaultdict(lambda: 0.0)\n        while S:\n            w = S.pop()\n            for v in P[w]:\n                delta[v] = delta[v] + sigma[v]/sigma[w] * (1 + delta[w])\n                if v != w:\n                    bw[w] = bw[w] + delta[w]\n    return bw\n</pre> def betweenness_brandes(g: pp.Graph, sources = None):     bw = defaultdict(lambda: 0.0)      if sources == None:         sources = [v for v in g.nodes]      for s in tqdm(sources):         S = list()         P = defaultdict(list)          sigma = defaultdict(lambda: 0)           sigma[s] = 1          d = defaultdict(lambda: -1)                 d[s] = 0          Q = [s]         while Q:             v = Q.pop(0)             S.append(v)             for w in g.successors(v):                 if d[w] &lt; 0:                     Q.append(w)                     d[w] = d[v] + 1                 if d[w] == d[v] + 1:                     # we found shortest path from s via v to w                     sigma[w] = sigma[w] + sigma[v]                     P[w].append(v)         delta = defaultdict(lambda: 0.0)         while S:             w = S.pop()             for v in P[w]:                 delta[v] = delta[v] + sigma[v]/sigma[w] * (1 + delta[w])                 if v != w:                     bw[w] = bw[w] + delta[w]     return bw In\u00a0[14]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'), ('b', 'c'), ('c', 'd'), ('c', 'e')])\nbetweenness_brandes(g, g.nodes)\n</pre> g = pp.Graph.from_edge_list([('a', 'c'), ('b', 'c'), ('c', 'd'), ('c', 'e')]) betweenness_brandes(g, g.nodes) <pre>5it [00:00, 3583.04it/s]\n</pre> Out[14]: <pre>defaultdict(&lt;function __main__.betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {'e': 0.0, 'd': 0.0, 'c': 4.0})</pre> In\u00a0[15]: Copied! <pre>def temporal_event_graph(g: pp.TemporalGraph, delta = 1):\n    # generate temporal event DAG\n    edge_index = pp.algorithms.lift_order_temporal(g, delta)    \n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    print(g.data.edge_index)\n    edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges]\n    print(edges)\n    src_edges_src = g.data.edge_index[0] + g.M\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    src = [f'{v}-src' for v in g.nodes]\n    tgt = [f'{v}-tgt' for v in g.nodes]\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.data.edge_index[1] + g.M + g.N\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    mapping = pp.IndexMap(edges + src + tgt)\n    event_graph = pp.Graph.from_edge_index(edge_index, mapping) \n    return event_graph\n</pre> def temporal_event_graph(g: pp.TemporalGraph, delta = 1):     # generate temporal event DAG     edge_index = pp.algorithms.lift_order_temporal(g, delta)          # Add indices of first-order nodes as src and dst of paths in augmented     # temporal event DAG     print(g.data.edge_index)     edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges]     print(edges)     src_edges_src = g.data.edge_index[0] + g.M     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      src = [f'{v}-src' for v in g.nodes]     tgt = [f'{v}-tgt' for v in g.nodes]      dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.data.edge_index[1] + g.M + g.N      # add edges from source to edges and from edges to destinations     src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      # create sparse scipy matrix     mapping = pp.IndexMap(edges + src + tgt)     event_graph = pp.Graph.from_edge_index(edge_index, mapping)      return event_graph In\u00a0[25]: Copied! <pre># def fo_node(v, g, src_indices) -&gt; int:\n#     # if v is one of the source nodes, return corresponding first-order node\n\n    \n# def fo_src(v, g, src_indices):\n#     if v in src_indices:\n#         return v - g.M\n#     else:\n#         return g.data.edge_index[0,v].item()\n\ndef temporal_betweenness_brandes(g: pp.TemporalGraph, delta=1):\n\n    print(g.data.edge_index)\n\n    # generate temporal event DAG\n    edge_index = pp.algorithms.lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n #   print(g.data.edge_index)\n    #edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges]\n#    print(edges)\n    src_edges_src = g.data.edge_index[0] + g.M\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    #src = [f'{v}-src' for v in g.nodes]\n    #tgt = [f'{v}-tgt' for v in g.nodes]\n\n    # dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    # dst_edges_dst = g.data.edge_index[1] + g.M + g.N\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    # dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges], dim=1)\n\n    # create sparse scipy matrix\n    #mapping = pp.IndexMap(edges + src + tgt)\n    event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.M+g.N)\n    print(event_graph)\n    #pp.plot(event_graph, node_label=[i for i in event_graph.nodes])\n    #print(edge_index)\n\n    # # sources = first-order source nodes in temporal event graph\n    src_indices = set(torch.unique(src_edges_src).tolist())\n    #print(src_edges_src-g.M)\n    # tgt_indices = set(torch.unique(dst_edges_dst).tolist())\n    #print(src_indices)\n    # print(tgt_indices)\n\n    e_i = g.data.edge_index.numpy()\n\n    fo_nodes = dict()\n    for v in event_graph.nodes:\n        if v in src_indices:\n            fo_nodes[v] = v - g.M\n        else: # return first-order target node otherwise\n            fo_nodes[v] = e_i[1,v]\n\n    # start from indegree zero nodes\n    #roots = torch.where((degree(g.data.edge_index[1])==0))[0]\n    #dist, _ = pp.algorithms.temporal_shortest_paths(g, delta=delta)\n    #print(dist)\n    bw = defaultdict(lambda: 0.0)\n\n    # for all first-order nodes\n    for s in tqdm(src_indices):\n        t_start = time()\n        print('source', g.mapping.to_id(fo_nodes[s]))\n\n        # for any given s, d[v] is the shortest path distance from s to v\n        # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)\n        delta_ = defaultdict(lambda: 0.0)\n\n        # for any given s, sigma[v] counts shortest paths from s to v\n        sigma = defaultdict(lambda: 0.0)          \n        sigma[s] = 1\n\n        sigma_fo = defaultdict(lambda: 0.0)       \n        sigma_fo[fo_nodes[s]] = 1\n\n        dist = defaultdict(lambda: -1)\n        dist[s] = 0\n\n        dist_fo = defaultdict(lambda: -1)\n        dist_fo[fo_nodes[s]] = 0\n                \n        # for any given s, P[v] is the set of predecessors of v on shortest paths from s\n        P = defaultdict(list)\n\n        # Q is a queue, so we append at the end and pop from the start\n        Q = deque()  \n        Q.append(s)\n\n        # S is a stack, so we append at the end and pop from the end\n        S = list()\n    \n        # dijkstra with path counting\n        while Q:\n            v = Q.popleft()\n            #print('popped ', v)\n            # for all successor events within delta\n            for w in event_graph.successors(v):\n\n                # we dicover w for the first time\n                if dist[w] == -1:\n                    dist[w] = dist[v] + 1\n                    if dist_fo[fo_nodes[w]] == -1:\n                        dist_fo[fo_nodes[w]] = dist[v] + 1\n                    S.append(w)\n                    Q.append(w)\n                # we found a shortest path to event w via event v\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[w] + sigma[v]\n                    P[w].append(v)\n                    # we found a shortest path to first-order node of event w\n                    if dist[w] == dist_fo[fo_nodes[w]]:\n                        sigma_fo[fo_nodes[w]] += sigma[v]\n        #print('S =', S)\n        #print('P', P)\n        #print('d', dist)\n        print('finished BFS ', (time()- t_start))\n        c = 0\n        for i in dist_fo:\n            if dist_fo[i] &gt;=0:\n                c+= 1\n        bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1\n        #print(bw[fo_node(s, g, src_indices)])\n\n        # We computed top. shortest path distances and shortest path counts from (first-order) source nodes to all temporal events\n        # we must now project this to the first-order target nodes of those events\n        while S:\n            w = S.pop()\n            # work backwards through paths to all targets and sum delta and sigma\n\n            # check whether shortest path from s to event w is also shortest path to first-order target of w\n            # if d[w] == d_fo[w_fo]:            \n            if dist[w] == dist_fo[fo_nodes[w]]:\n                # v_fo = fo_tgt(v, g, src_indices, tgt_indices)\n                delta_[w] += (sigma[w]/sigma_fo[fo_nodes[w]])\n            for v in P[w]:\n                delta_[v] += (sigma[v]/sigma[w]) * delta_[w]\n                bw[fo_nodes[v]] += delta_[w] * (sigma[v]/sigma[w])\n    bw_id = defaultdict(lambda: 0.0)\n    for idx in bw:\n        bw_id[g.mapping.to_id(idx)] = bw[idx]\n    return bw_id\n</pre> # def fo_node(v, g, src_indices) -&gt; int: #     # if v is one of the source nodes, return corresponding first-order node       # def fo_src(v, g, src_indices): #     if v in src_indices: #         return v - g.M #     else: #         return g.data.edge_index[0,v].item()  def temporal_betweenness_brandes(g: pp.TemporalGraph, delta=1):      print(g.data.edge_index)      # generate temporal event DAG     edge_index = pp.algorithms.lift_order_temporal(g, delta)      # Add indices of first-order nodes as src and dst of paths in augmented     # temporal event DAG  #   print(g.data.edge_index)     #edges = [f'{v}-{w}-{t}' for v, w, t in g.temporal_edges] #    print(edges)     src_edges_src = g.data.edge_index[0] + g.M     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      #src = [f'{v}-src' for v in g.nodes]     #tgt = [f'{v}-tgt' for v in g.nodes]      # dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     # dst_edges_dst = g.data.edge_index[1] + g.M + g.N      # add edges from source to edges and from edges to destinations     src_edges = torch.stack([src_edges_src, src_edges_dst])     # dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges], dim=1)      # create sparse scipy matrix     #mapping = pp.IndexMap(edges + src + tgt)     event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.M+g.N)     print(event_graph)     #pp.plot(event_graph, node_label=[i for i in event_graph.nodes])     #print(edge_index)      # # sources = first-order source nodes in temporal event graph     src_indices = set(torch.unique(src_edges_src).tolist())     #print(src_edges_src-g.M)     # tgt_indices = set(torch.unique(dst_edges_dst).tolist())     #print(src_indices)     # print(tgt_indices)      e_i = g.data.edge_index.numpy()      fo_nodes = dict()     for v in event_graph.nodes:         if v in src_indices:             fo_nodes[v] = v - g.M         else: # return first-order target node otherwise             fo_nodes[v] = e_i[1,v]      # start from indegree zero nodes     #roots = torch.where((degree(g.data.edge_index[1])==0))[0]     #dist, _ = pp.algorithms.temporal_shortest_paths(g, delta=delta)     #print(dist)     bw = defaultdict(lambda: 0.0)      # for all first-order nodes     for s in tqdm(src_indices):         t_start = time()         print('source', g.mapping.to_id(fo_nodes[s]))          # for any given s, d[v] is the shortest path distance from s to v         # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)         delta_ = defaultdict(lambda: 0.0)          # for any given s, sigma[v] counts shortest paths from s to v         sigma = defaultdict(lambda: 0.0)                   sigma[s] = 1          sigma_fo = defaultdict(lambda: 0.0)                sigma_fo[fo_nodes[s]] = 1          dist = defaultdict(lambda: -1)         dist[s] = 0          dist_fo = defaultdict(lambda: -1)         dist_fo[fo_nodes[s]] = 0                          # for any given s, P[v] is the set of predecessors of v on shortest paths from s         P = defaultdict(list)          # Q is a queue, so we append at the end and pop from the start         Q = deque()           Q.append(s)          # S is a stack, so we append at the end and pop from the end         S = list()              # dijkstra with path counting         while Q:             v = Q.popleft()             #print('popped ', v)             # for all successor events within delta             for w in event_graph.successors(v):                  # we dicover w for the first time                 if dist[w] == -1:                     dist[w] = dist[v] + 1                     if dist_fo[fo_nodes[w]] == -1:                         dist_fo[fo_nodes[w]] = dist[v] + 1                     S.append(w)                     Q.append(w)                 # we found a shortest path to event w via event v                 if dist[w] == dist[v] + 1:                     sigma[w] += sigma[w] + sigma[v]                     P[w].append(v)                     # we found a shortest path to first-order node of event w                     if dist[w] == dist_fo[fo_nodes[w]]:                         sigma_fo[fo_nodes[w]] += sigma[v]         #print('S =', S)         #print('P', P)         #print('d', dist)         print('finished BFS ', (time()- t_start))         c = 0         for i in dist_fo:             if dist_fo[i] &gt;=0:                 c+= 1         bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1         #print(bw[fo_node(s, g, src_indices)])          # We computed top. shortest path distances and shortest path counts from (first-order) source nodes to all temporal events         # we must now project this to the first-order target nodes of those events         while S:             w = S.pop()             # work backwards through paths to all targets and sum delta and sigma              # check whether shortest path from s to event w is also shortest path to first-order target of w             # if d[w] == d_fo[w_fo]:                         if dist[w] == dist_fo[fo_nodes[w]]:                 # v_fo = fo_tgt(v, g, src_indices, tgt_indices)                 delta_[w] += (sigma[w]/sigma_fo[fo_nodes[w]])             for v in P[w]:                 delta_[v] += (sigma[v]/sigma[w]) * delta_[w]                 bw[fo_nodes[v]] += delta_[w] * (sigma[v]/sigma[w])     bw_id = defaultdict(lambda: 0.0)     for idx in bw:         bw_id[g.mapping.to_id(idx)] = bw[idx]     return bw_id  In\u00a0[26]: Copied! <pre>temporal_betweenness_brandes(t_sp, delta=3600)\n</pre> temporal_betweenness_brandes(t_sp, delta=3600) <pre>tensor([[ 43,  43,  44,  ..., 202, 162,  76],\n        [ 45,  44,  43,  ..., 262,  76, 162]])\n</pre> <pre>  0%|          | 0/579 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 579/579 [00:39&lt;00:00, 14.52it/s]\n</pre> <pre>Directed graph with 220705 nodes and 18249204 edges\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <pre>  0%|          | 0/327 [00:00&lt;?, ?it/s]</pre> <pre>source 454\nfinished BFS  21.46290111541748\n</pre> <pre>  0%|          | 1/327 [00:23&lt;2:06:37, 23.30s/it]</pre> <pre>source 640\nfinished BFS  20.32966423034668\n</pre> <pre>  1%|          | 2/327 [00:45&lt;2:03:25, 22.79s/it]</pre> <pre>source 1\nfinished BFS  9.732733726501465\n</pre> <pre>  1%|          | 3/327 [00:56&lt;1:32:16, 17.09s/it]</pre> <pre>source 939\n</pre> <pre>  1%|          | 3/327 [01:19&lt;2:22:30, 26.39s/it]\n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[26], line 1\n----&gt; 1 temporal_betweenness_brandes(t_sp, delta=3600)\n\nCell In[25], line 103, in temporal_betweenness_brandes(g, delta)\n    100 v = Q.popleft()\n    101 #print('popped ', v)\n    102 # for all successor events within delta\n--&gt; 103 for w in event_graph.successors(v):\n    104 \n    105     # we dicover w for the first time\n    106     if dist[w] == -1:\n    107         dist[w] = dist[v] + 1\n\nFile /workspaces/pathpyG/src/pathpyG/core/Graph.py:296, in Graph.successors(self, node)\n    285 \"\"\"Return all successors of a given node.\n    286 \n    287 This method returns a generator object that yields all successors of a\n   (...)\n    292     node:   Index or string ID of node for which successors shall be returned.\n    293 \"\"\" \n    295 for j in self.get_successors(self.mapping.to_idx(node)):  # type: ignore\n--&gt; 296     yield self.mapping.to_id(j.item())\n\nKeyboardInterrupt: </pre> In\u00a0[61]: Copied! <pre># Example with two shortest time-respecting paths from a to e via c or d\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\nprint(t.data.edge_index)\nprint(t.mapping)\n\nbw_1 = temporal_betweenness_brandes(t, delta=1)\n\nfor v in t.nodes:\n    print(v, bw_1[t.mapping.to_idx(v)])\n</pre> # Example with two shortest time-respecting paths from a to e via c or d t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)]) print(t.data.edge_index) print(t.mapping)  bw_1 = temporal_betweenness_brandes(t, delta=1)  for v in t.nodes:     print(v, bw_1[t.mapping.to_idx(v)]) <pre>tensor([[0, 1, 1, 2, 3],\n        [1, 2, 3, 4, 4]])\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\ne -&gt; 4\n\ntensor([[0, 1, 1, 2, 3],\n        [1, 2, 3, 4, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2574.77it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 993.62it/s]</pre> <pre>source d\nsource a\nsource b\nsource c\na 0.0\nb 3.0\nc 1.0\nd 1.0\ne 0.0\n</pre> <pre>\n</pre> In\u00a0[62]: Copied! <pre>bw = temporal_betweenness_brandes(t_long, 5)\nfor v in t_long.nodes:\n    print(v, bw[t_long.mapping.to_idx(v)])\n</pre> bw = temporal_betweenness_brandes(t_long, 5) for v in t_long.nodes:     print(v, bw[t_long.mapping.to_idx(v)]) <pre>tensor([[0, 1, 2, 2, 2, 5, 0, 1, 0, 7, 2, 6, 0, 0, 2, 5, 1, 8, 2, 7],\n        [1, 2, 3, 4, 5, 0, 6, 5, 6, 5, 5, 7, 2, 1, 7, 7, 8, 1, 8, 8]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 3854.64it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00&lt;00:00, 1022.18it/s]</pre> <pre>source a\nsource b\nsource c\nsource f\nsource g\nsource h\nsource i\na 2.0\nb 2.0\nc 4.5\nd 0.0\ne 0.0\nf 2.0\ng 0.5\nh 0.0\ni 0.0\n</pre> <pre>\n</pre> In\u00a0[32]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'd', 3), ('b', 'd', 3)])\nprint(t.data.edge_index)\nprint(t.mapping)\n\nbw_1 = temporal_betweenness_brandes(t, delta=1)\nbw_2 = temporal_betweenness_brandes(t, delta=2)\n\nfor v in t.nodes:\n    print(v, bw_1[t.mapping.to_idx(v)], bw_2[t.mapping.to_idx(v)])\n</pre> t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'd', 3), ('b', 'd', 3)]) print(t.data.edge_index) print(t.mapping)  bw_1 = temporal_betweenness_brandes(t, delta=1) bw_2 = temporal_betweenness_brandes(t, delta=2)  for v in t.nodes:     print(v, bw_1[t.mapping.to_idx(v)], bw_2[t.mapping.to_idx(v)]) <pre>tensor([[0, 1, 2, 1],\n        [1, 2, 3, 3]])\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\ntensor([[0, 1, 2, 1],\n        [1, 2, 3, 3]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 3437.95it/s]\n</pre> <pre>{4, 5, 6}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 875.52it/s]\n</pre> <pre>source a\nsource b\nsource c\ntensor([[0, 1, 2, 1],\n        [1, 2, 3, 3]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2423.05it/s]\n</pre> <pre>{4, 5, 6}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 1125.28it/s]</pre> <pre>source a\nsource b\nsource c\na 0.0 -1.0\nb 1.0 1.0\nc 1.0 0.0\nd 0.0 0.0\n</pre> <pre>\n</pre> In\u00a0[93]: Copied! <pre>pp.algorithms.temporal_shortest_paths(t, delta=2)\n</pre> pp.algorithms.temporal_shortest_paths(t, delta=2) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2388.10it/s]</pre> <pre>Created temporal event DAG with 12 nodes and 11 edges\n</pre> <pre>\n</pre> Out[93]: <pre>(array([[ 0.,  1.,  2.,  2.],\n        [inf,  0.,  1.,  1.],\n        [inf, inf,  0.,  1.],\n        [inf, inf, inf,  0.]]),\n array([[-9999,     0,     1,     3],\n        [-9999, -9999,     1,     3],\n        [-9999, -9999, -9999,     2],\n        [-9999, -9999, -9999, -9999]], dtype=int32))</pre> In\u00a0[57]: Copied! <pre>pp.algorithms.temporal_shortest_paths(t, delta=1)\n</pre> pp.algorithms.temporal_shortest_paths(t, delta=1) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 3233.02it/s]</pre> <pre>Created temporal event DAG with 12 nodes and 10 edges\n</pre> <pre>\n</pre> Out[57]: <pre>(array([[ 0.,  1.,  2.,  3.],\n        [inf,  0.,  1.,  1.],\n        [inf, inf,  0.,  1.],\n        [inf, inf, inf,  0.]]),\n array([[-9999,     0,     1,     2],\n        [-9999, -9999,     1,     3],\n        [-9999, -9999, -9999,     2],\n        [-9999, -9999, -9999, -9999]], dtype=int32))</pre> In\u00a0[313]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4)])\nprint(t.mapping)\n\ntemporal_betweenness_brandes(t, delta=1)\n# 4 = a_src\n# 5 = c_src\n# 7 = b_src\n\n# 10 = c_tgt\n# 11 = d_tgt\n# 13 = e_tgt\n</pre> t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4)]) print(t.mapping)  temporal_betweenness_brandes(t, delta=1) # 4 = a_src # 5 = c_src # 7 = b_src  # 10 = c_tgt # 11 = d_tgt # 13 = e_tgt <pre>a -&gt; 0\nc -&gt; 1\nd -&gt; 2\nb -&gt; 3\ne -&gt; 4\n\ntensor([[0, 1, 3, 1],\n        [1, 2, 1, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 3559.77it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2406.37it/s]</pre> <pre>10\n[0]\n11\n[1]\n13\n[]\n10\n[]\n11\n[1]\n13\n[3]\n10\n[2]\n11\n[]\n13\n[3]\n</pre> <pre>\n</pre> Out[313]: <pre>defaultdict(&lt;function __main__.temporal_betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {1: 0.0, 2: 0.0, 4: 0.0})</pre> In\u00a0[253]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4),('a', 'c', 1), ('c', 'e', 2), ('b', 'c', 3), ('c', 'd', 4)])\nprint(t.mapping)\n\ntemporal_betweenness_brandes(t, delta=1)\n# 4 = a_src\n# 5 = c_src\n# 7 = b_src\n\n# 10 = c_tgt\n# 11 = d_tgt\n# 13 = e_tgt\n</pre> t = pp.TemporalGraph.from_edge_list([('a', 'c', 1), ('c', 'd', 2), ('b', 'c', 3), ('c', 'e', 4),('a', 'c', 1), ('c', 'e', 2), ('b', 'c', 3), ('c', 'd', 4)]) print(t.mapping)  temporal_betweenness_brandes(t, delta=1) # 4 = a_src # 5 = c_src # 7 = b_src  # 10 = c_tgt # 11 = d_tgt # 13 = e_tgt <pre>a -&gt; 0\nc -&gt; 1\nd -&gt; 2\nb -&gt; 3\ne -&gt; 4\n\ntensor([[0, 0, 1, 1, 3, 3, 1, 1],\n        [1, 1, 2, 4, 1, 1, 4, 2]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 2609.21it/s]\n</pre> <pre>tensor([[0, 0, 1, 1, 4, 4, 5, 5],\n        [2, 3, 2, 3, 6, 7, 6, 7]])\n{8, 9, 11}\n{17, 14, 15}\n</pre> <pre>8it [00:00, 3661.15it/s]\n</pre> Out[253]: <pre>defaultdict(&lt;function __main__.temporal_betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {4: 0.0, 2: 0.0})</pre> In\u00a0[138]: Copied! <pre>event_graph = temporal_event_graph(t, delta=1)\npp.plot(event_graph, node_label = [v for v in event_graph.nodes])\n</pre> event_graph = temporal_event_graph(t, delta=1) pp.plot(event_graph, node_label = [v for v in event_graph.nodes]) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 3337.42it/s]</pre> <pre>tensor([[0, 1, 3, 1],\n        [1, 2, 1, 4]])\n['a-c-1.0', 'c-d-2.0', 'b-c-3.0', 'c-e-4.0']\n</pre> <pre>\n</pre> Out[138]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f8a1da53880&gt;</pre> In\u00a0[179]: Copied! <pre>betweenness_brandes(event_graph, sources=['a-src', 'b-src', 'c-src'])\n</pre> betweenness_brandes(event_graph, sources=['a-src', 'b-src', 'c-src']) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2910.69it/s]\n</pre> Out[179]: <pre>defaultdict(&lt;function __main__.betweenness_brandes.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {'d-tgt': 0.0,\n             'c-tgt': 0.0,\n             'c-d-2.0': 2.0,\n             'a-c-1.0': 3.0,\n             'e-tgt': 0.0,\n             'c-e-4.0': 2.0,\n             'b-c-3.0': 3.0})</pre> In\u00a0[182]: Copied! <pre>\n</pre> <pre>tensor([[0, 1, 3, 1],\n        [1, 2, 1, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 2712.57it/s]\n</pre> <pre>tensor([[ 0,  2,  4,  5,  7,  5,  0,  1,  2,  3],\n        [ 1,  3,  0,  1,  2,  3, 10, 11, 10, 13]])\n{4, 5, 7}\n</pre> <pre>  0%|          | 0/3 [00:00&lt;?, ?it/s]\n</pre> <pre>\n---------------------------------------------------------------------------\nUnboundLocalError                         Traceback (most recent call last)\nCell In[182], line 1\n----&gt; 1 temporal_betweenness_brandes(t, delta=1)\n\nCell In[180], line 56, in temporal_betweenness_brandes(g, delta)\n     53 bw = defaultdict(lambda: 0.0)\n     54 for s in tqdm(src_indices):\n---&gt; 56     fo_src = fo_src(s, g, src_indices, tgt_indices)     \n     57     dist_eg = defaultdict(lambda: -1)\n     58     dist_eg[s] = 0\n\nUnboundLocalError: local variable 'fo_src' referenced before assignment</pre> In\u00a0[75]: Copied! <pre>temporal_betweenness_brandes(t_sp, delta=3600)\n</pre> temporal_betweenness_brandes(t_sp, delta=3600) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1157/1157 [01:15&lt;00:00, 15.43it/s]\n  8%|\u258a         | 25/327 [13:32&lt;2:43:34, 32.50s/it]</pre> <pre>Unexpected exception formatting exception. Falling back to standard exception\n</pre> <pre>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_3320/540718842.py\", line 1, in &lt;module&gt;\n    temporal_betweenness_brandes(t_sp, delta=3600)\n  File \"/tmp/ipykernel_3320/1211725645.py\", line 36, in temporal_betweenness_brandes\n    return betweenness_brandes(event_graph, src_indices)\n  File \"/tmp/ipykernel_3320/2494254184.py\", line -1, in betweenness_brandes\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n    frames.append(self.format_record(record))\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n    frame_info.lines, Colors, self.has_colors, lvals\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n    return self._sd.lines\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n    pieces = self.included_pieces\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n    pos = scope_pieces.index(self.executing_piece)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n    return only(\n  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n    raise NotOneValueFound('Expected one value, found 0')\nexecuting.executing.NotOneValueFound: Expected one value, found 0\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/temporal_graphs/","title":"Temporal Graphs","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nfrom torch_geometric.data import TemporalData\nimport pathpyG as pp\n\npp.config['torch']['device'] = 'cuda'\n</pre> import torch from torch_geometric.data import TemporalData import pathpyG as pp  pp.config['torch']['device'] = 'cuda' <p>We can create a temporal graph object from a list of time-stamped edges. Since TemporalGraph is a subclass of the <code>Graph</code> class, the inernal structures are very similar:</p> In\u00a0[2]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nprint(t.mapping)\nprint(t.N)\nprint(t.M)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) print(t.mapping) print(t.N) print(t.M) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n10\n</pre> <p>By default, all temporal graphs are directed. We can create an undirected version a temporal graph as follows:</p> In\u00a0[5]: Copied! <pre>x = t.to_undirected()\nprint(x.mapping)\nprint(x.N)\nprint(x.M)\n</pre> x = t.to_undirected() print(x.mapping) print(x.N) print(x.M) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n20\n</pre> <p>We can also create a temporal graph from an instance of <code>TemporalData</code></p> In\u00a0[13]: Copied! <pre>td = TemporalData(\n    src = torch.Tensor([0,1,2,0]),\n    dst = torch.Tensor([1,2,3,1]), \n    t = torch.Tensor([0,1,2,3]))\nprint(td)\nt2 = pp.TemporalGraph(td)\nprint(t2)\n</pre> td = TemporalData(     src = torch.Tensor([0,1,2,0]),     dst = torch.Tensor([1,2,3,1]),      t = torch.Tensor([0,1,2,3])) print(td) t2 = pp.TemporalGraph(td) print(t2) <pre>TemporalData(src=[4], dst=[4], t=[4])\nTemporal Graph with 4 nodes, 3 unique edges and 4 events in [0.0, 3.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> <p>We can restrict a temporal graph to a time window:</p> In\u00a0[14]: Copied! <pre>t1 = t.get_window(0,4)\nprint(t1)\nprint(t1.N)\nprint(t1.M)\n</pre> t1 = t.get_window(0,4) print(t1) print(t1.N) print(t1.M) <pre>Temporal Graph with 3 nodes, 3 unique edges and 4 events in [1.0, 3.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\n3\n4\n</pre> <p>We can convert a temporal graph into a weighted time-aggregated static graph:</p> In\u00a0[17]: Copied! <pre>g = t.to_static_graph(weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(weighted=True) print(g) <pre>Undirected graph with 4 nodes and 6 (directed) edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>We can also aggregate the temporal graph in a given time window:</p> In\u00a0[19]: Copied! <pre>g = t.to_static_graph(time_window=(1, 3), weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(time_window=(1, 3), weighted=True) print(g) <pre>Directed graph with 2 nodes and 1 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Finally, we can perform a rolling window analysis:</p> In\u00a0[21]: Copied! <pre>r = pp.algorithms.RollingTimeWindow(t, 3, 1, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</pre> r = pp.algorithms.RollingTimeWindow(t, 3, 1, return_window=True) for g, w in r:     print('Time window ', w)     print(g)     print(g.data.edge_index)     print('---') <pre>Time window  (1.0, 4.0)\nDirected graph with 3 nodes and 3 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[0, 1, 1],\n           [1, 2, 0]], device='cuda:0', sparse_size=(3, 3), nnz=3,\n          sort_order=row)\n---\nTime window  (2.0, 5.0)\nDirected graph with 4 nodes and 5 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[0, 1, 1, 2, 3],\n           [1, 2, 0, 1, 2]], device='cuda:0', sparse_size=(4, 4), nnz=5,\n          sort_order=row)\n---\nTime window  (3.0, 6.0)\nUndirected graph with 4 nodes and 6 (directed) edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[0, 1, 1, 2, 2, 3],\n           [1, 2, 0, 3, 1, 2]], device='cuda:0', sparse_size=(4, 4), nnz=6,\n          sort_order=row)\n---\nTime window  (4.0, 7.0)\nDirected graph with 4 nodes and 5 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[0, 1, 2, 2, 3],\n           [1, 0, 1, 3, 2]], device='cuda:0', sparse_size=(4, 4), nnz=5,\n          sort_order=row)\n---\nTime window  (5.0, 8.0)\nDirected graph with 4 nodes and 3 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[1, 2, 2],\n           [0, 3, 1]], device='cuda:0', sparse_size=(4, 4), nnz=3,\n          sort_order=row)\n---\nTime window  (6.0, 9.0)\nDirected graph with 3 nodes and 1 edges\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nEdgeIndex([[2],\n           [1]], device='cuda:0', sparse_size=(3, 3), nnz=1, sort_order=row)\n---\n</pre> <p>Let's start with a simple temporal graph with four nodes <code>a</code>,<code>b</code>,<code>c</code>,<code>d</code> and seven timestamped edges <code>(b,c;2)</code>,<code>(a,b;1)</code>,<code>(c,d;3)</code>,<code>(d,a;4)</code>,<code>(b,d;2)</code>, <code>(d,a;6)</code>,<code>(a,b;7)</code>.</p> <p>The following code generates this temporal graph from the given edge list.</p> In\u00a0[29]: Copied! <pre>g = pp.TemporalGraph.from_edge_list([['b', 'c', 2],['a', 'b', 1], ['c', 'd', 3], ['d', 'a', 4], ['b', 'd', 2], ['d', 'a', 6], ['a', 'b', 7]])\nprint(g)\n</pre> g = pp.TemporalGraph.from_edge_list([['b', 'c', 2],['a', 'b', 1], ['c', 'd', 3], ['d', 'a', 4], ['b', 'd', 2], ['d', 'a', 6], ['a', 'b', 7]]) print(g) <pre>Temporal Graph with 4 nodes, 5 unique edges and 7 events in [1.0, 7.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7])\n\n</pre> <p>We can visualize a temporal graph by using the pathpyG plot function.</p> In\u00a0[30]: Copied! <pre>pp.plot(g, edge_color='lightgray')\n</pre> pp.plot(g, edge_color='lightgray') Out[30]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f32c6f8f730&gt;</pre> <p>Consistent with <code>pyG</code> the sources, destinations and timestamps are stored as a <code>pyG TemporalData</code> object, which we can access in the following way.</p> In\u00a0[31]: Copied! <pre>g.data\n</pre> g.data Out[31]: <pre>TemporalData(src=[7], dst=[7], t=[7])</pre> In\u00a0[32]: Copied! <pre>print(g.data.t)\n</pre> print(g.data.t) <pre>tensor([1., 2., 2., 3., 4., 6., 7.], device='cuda:0')\n</pre> <p>With the generator functions <code>edges</code> and <code>temporal_edges</code> we can iterate through the (temporal) edges of this graph.</p> In\u00a0[33]: Copied! <pre>for v, w in g.edges:\n    print(v, w)\n</pre> for v, w in g.edges:     print(v, w) <pre>a b\nb c\nb d\nc d\nd a\nd a\na b\n</pre> In\u00a0[34]: Copied! <pre>for v, w, t in g.temporal_edges:\n    print(v, w, t)\n</pre> for v, w, t in g.temporal_edges:     print(v, w, t) <pre>a b 1.0\nb c 2.0\nb d 2.0\nc d 3.0\nd a 4.0\nd a 6.0\na b 7.0\n</pre> <p>We are often interested in the time respecting paths of a temporal graph.</p> <p>A time respecting path is defined as a sequence of nodes $v_0,...,v_l$ where the corresponding edges occur in the right time ordering and with a maximum time difference of $\\delta\\in \\N$.</p> <p>To calculate time-respecting paths in a temporal graph, we can construct a time-unfolded directed acyclic graph (DAG), where each node is a time-stamped edge $(u,v;t)$ and two nodes representing time-stamped edges $(u,v;t_1)$ and $(v,w;t_2)$ are connected by a (second-order) edge iff $0 &lt; t_2-t_1 \\leq \\delta$.</p> <p>For the toy example above, we can construct the time-unfolded DAG as follows:</p> In\u00a0[36]: Copied! <pre>dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=1, create_mapping=True)\npp.plot(dag, node_label = [str(dag.mapping.to_id(i)) for i in range(dag.N)])\n</pre> dag = pp.algorithms.temporal_graph_to_event_dag(g, delta=1, create_mapping=True) pp.plot(dag, node_label = [str(dag.mapping.to_id(i)) for i in range(dag.N)])  Out[36]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f32b00f5540&gt;</pre> <p>For $\\delta=1$, this DAG with two connected components tells us that there are the following three time-respecting paths:</p> <p>a -&gt; b -&gt; c -&gt; d -&gt; a a -&gt; b -&gt; d d -&gt; a -&gt; b</p> <p>We can use the function <code>pp.algorithms.time_respecting_paths</code> to calculate all (longest) time-respecting paths:</p> In\u00a0[39]: Copied! <pre>pp.algorithms.time_respecting_paths(g, delta=1)\n</pre> pp.algorithms.time_respecting_paths(g, delta=1) <pre>Constructed temporal event DAG with 7 nodes and 5 edges\nProcessing root 1/2\n</pre> Out[39]: <pre>defaultdict(&lt;function pathpyG.algorithms.temporal.time_respecting_paths.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {2: [['a', 'b', 'd'], ['d', 'a', 'b']],\n             4: [['a', 'b', 'c', 'd', 'a']]})</pre> <p>The following function computes all shortest time-respecting paths between all pairs of nodes:</p> In\u00a0[47]: Copied! <pre>shortest_paths, distances = pp.algorithms.temporal_shortest_paths(g, delta=1)\nprint(shortest_paths['a'])\nprint(shortest_paths['b'])\nprint(shortest_paths['c'])\nprint(shortest_paths['d'])\n</pre> shortest_paths, distances = pp.algorithms.temporal_shortest_paths(g, delta=1) print(shortest_paths['a']) print(shortest_paths['b']) print(shortest_paths['c']) print(shortest_paths['d']) <pre>Constructed temporal event DAG with 7 nodes and 5 edges\nProcessing root 1/2\ndefaultdict(&lt;class 'set'&gt;, {'d': {('a', 'b', 'd')}, 'a': {('a', 'b', 'c', 'd', 'a')}})\ndefaultdict(&lt;class 'set'&gt;, {})\ndefaultdict(&lt;class 'set'&gt;, {})\ndefaultdict(&lt;class 'set'&gt;, {'b': {('d', 'a', 'b')}})\n</pre> In\u00a0[57]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(g, delta=1, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(g, delta=1, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 4 nodes and 5 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 5 nodes and 5 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 5 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 2 nodes and 1 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[59]: Copied! <pre>pp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes])\n</pre> pp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes]) Out[59]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f3299c34be0&gt;</pre> In\u00a0[60]: Copied! <pre>pp.plot(m.layers[2], node_label=[v for v in m.layers[2].nodes])\n</pre> pp.plot(m.layers[2], node_label=[v for v in m.layers[2].nodes]) Out[60]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f3299c34ca0&gt;</pre> In\u00a0[61]: Copied! <pre>pp.plot(m.layers[3], node_label=[v for v in m.layers[3].nodes])\n</pre> pp.plot(m.layers[3], node_label=[v for v in m.layers[3].nodes]) Out[61]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f3299c33610&gt;</pre> In\u00a0[62]: Copied! <pre>pp.plot(m.layers[4], node_label=[v for v in m.layers[4].nodes])\n</pre> pp.plot(m.layers[4], node_label=[v for v in m.layers[4].nodes]) Out[62]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f3299c33730&gt;</pre> <p>We can read temporal graphs from CSV files that contain the source, target, and time-stamps of edges in each line:</p> In\u00a0[63]: Copied! <pre>t = pp.TemporalGraph.from_csv('../data/ants_1_1.tedges')\nprint(t)\n</pre> t = pp.TemporalGraph.from_csv('../data/ants_1_1.tedges') print(t) <pre>Temporal Graph with 89 nodes, 947 unique edges and 1911 events in [0.0, 1438.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[65]: Copied! <pre>paths = pp.algorithms.time_respecting_paths(t, delta=5)\n</pre> paths = pp.algorithms.time_respecting_paths(t, delta=5) <pre>Constructed temporal event DAG with 1910 nodes and 562 edges\nProcessing root 1/1416\nProcessing root 11/1416\nProcessing root 21/1416\nProcessing root 31/1416\nProcessing root 41/1416\nProcessing root 51/1416\nProcessing root 61/1416\nProcessing root 71/1416\nProcessing root 81/1416\nProcessing root 91/1416\nProcessing root 101/1416\nProcessing root 111/1416\nProcessing root 121/1416\nProcessing root 131/1416\nProcessing root 141/1416\nProcessing root 151/1416\nProcessing root 161/1416\nProcessing root 171/1416\nProcessing root 181/1416\nProcessing root 191/1416\nProcessing root 201/1416\nProcessing root 211/1416\nProcessing root 221/1416\nProcessing root 231/1416\nProcessing root 241/1416\nProcessing root 251/1416\nProcessing root 261/1416\nProcessing root 271/1416\nProcessing root 281/1416\nProcessing root 291/1416\nProcessing root 301/1416\nProcessing root 311/1416\nProcessing root 321/1416\nProcessing root 331/1416\nProcessing root 341/1416\nProcessing root 351/1416\nProcessing root 361/1416\nProcessing root 371/1416\nProcessing root 381/1416\nProcessing root 391/1416\nProcessing root 401/1416\nProcessing root 411/1416\nProcessing root 421/1416\nProcessing root 431/1416\nProcessing root 441/1416\nProcessing root 451/1416\nProcessing root 461/1416\nProcessing root 471/1416\nProcessing root 481/1416\nProcessing root 491/1416\nProcessing root 501/1416\nProcessing root 511/1416\nProcessing root 521/1416\nProcessing root 531/1416\nProcessing root 541/1416\nProcessing root 551/1416\nProcessing root 561/1416\nProcessing root 571/1416\nProcessing root 581/1416\nProcessing root 591/1416\nProcessing root 601/1416\nProcessing root 611/1416\nProcessing root 621/1416\nProcessing root 631/1416\nProcessing root 641/1416\nProcessing root 651/1416\nProcessing root 661/1416\nProcessing root 671/1416\nProcessing root 681/1416\nProcessing root 691/1416\nProcessing root 701/1416\nProcessing root 711/1416\nProcessing root 721/1416\nProcessing root 731/1416\nProcessing root 741/1416\nProcessing root 751/1416\nProcessing root 761/1416\nProcessing root 771/1416\nProcessing root 781/1416\nProcessing root 791/1416\nProcessing root 801/1416\nProcessing root 811/1416\nProcessing root 821/1416\nProcessing root 831/1416\nProcessing root 841/1416\nProcessing root 851/1416\nProcessing root 861/1416\nProcessing root 871/1416\nProcessing root 881/1416\nProcessing root 891/1416\nProcessing root 901/1416\nProcessing root 911/1416\nProcessing root 921/1416\nProcessing root 931/1416\nProcessing root 941/1416\nProcessing root 951/1416\nProcessing root 961/1416\nProcessing root 971/1416\nProcessing root 981/1416\nProcessing root 991/1416\nProcessing root 1001/1416\nProcessing root 1011/1416\nProcessing root 1021/1416\nProcessing root 1031/1416\nProcessing root 1041/1416\nProcessing root 1051/1416\nProcessing root 1061/1416\nProcessing root 1071/1416\nProcessing root 1081/1416\nProcessing root 1091/1416\nProcessing root 1101/1416\nProcessing root 1111/1416\nProcessing root 1121/1416\nProcessing root 1131/1416\nProcessing root 1141/1416\nProcessing root 1151/1416\nProcessing root 1161/1416\nProcessing root 1171/1416\nProcessing root 1181/1416\nProcessing root 1191/1416\nProcessing root 1201/1416\nProcessing root 1211/1416\nProcessing root 1221/1416\nProcessing root 1231/1416\nProcessing root 1241/1416\nProcessing root 1251/1416\nProcessing root 1261/1416\nProcessing root 1271/1416\nProcessing root 1281/1416\nProcessing root 1291/1416\nProcessing root 1301/1416\nProcessing root 1311/1416\nProcessing root 1321/1416\nProcessing root 1331/1416\nProcessing root 1341/1416\nProcessing root 1351/1416\nProcessing root 1361/1416\nProcessing root 1371/1416\nProcessing root 1381/1416\nProcessing root 1391/1416\nProcessing root 1401/1416\nProcessing root 1411/1416\n</pre> In\u00a0[66]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=30, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=30, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 89 nodes and 947 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([89, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 947 nodes and 1780 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 1780 nodes and 2410 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 2410 nodes and 3292 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3292])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[67]: Copied! <pre>t = pp.TemporalGraph.from_csv('../data/manufacturing_email.tedges')\nprint(t)\n</pre> t = pp.TemporalGraph.from_csv('../data/manufacturing_email.tedges') print(t) <pre>Temporal Graph with 167 nodes, 5784 unique edges and 82927 events in [1262454016.0, 1285884544.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([82927])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([82927])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([82927])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[68]: Copied! <pre>paths = pp.algorithms.time_respecting_paths(t, delta=240)\n</pre> paths = pp.algorithms.time_respecting_paths(t, delta=240) <pre>Constructed temporal event DAG with 82887 nodes and 9779 edges\nProcessing root 1/74729\nProcessing root 11/74729\nProcessing root 21/74729\nProcessing root 31/74729\nProcessing root 41/74729\nProcessing root 51/74729\nProcessing root 61/74729\nProcessing root 71/74729\nProcessing root 81/74729\nProcessing root 91/74729\nProcessing root 101/74729\nProcessing root 111/74729\nProcessing root 121/74729\nProcessing root 131/74729\nProcessing root 141/74729\nProcessing root 151/74729\nProcessing root 161/74729\nProcessing root 171/74729\nProcessing root 181/74729\nProcessing root 191/74729\nProcessing root 201/74729\nProcessing root 211/74729\nProcessing root 221/74729\nProcessing root 231/74729\nProcessing root 241/74729\nProcessing root 251/74729\nProcessing root 261/74729\nProcessing root 271/74729\nProcessing root 281/74729\nProcessing root 291/74729\nProcessing root 301/74729\nProcessing root 311/74729\nProcessing root 321/74729\nProcessing root 331/74729\nProcessing root 341/74729\nProcessing root 351/74729\nProcessing root 361/74729\nProcessing root 371/74729\nProcessing root 381/74729\nProcessing root 391/74729\nProcessing root 401/74729\nProcessing root 411/74729\nProcessing root 421/74729\nProcessing root 431/74729\nProcessing root 441/74729\nProcessing root 451/74729\nProcessing root 461/74729\nProcessing root 471/74729\nProcessing root 481/74729\nProcessing root 491/74729\nProcessing root 501/74729\nProcessing root 511/74729\nProcessing root 521/74729\nProcessing root 531/74729\nProcessing root 541/74729\nProcessing root 551/74729\nProcessing root 561/74729\nProcessing root 571/74729\nProcessing root 581/74729\nProcessing root 591/74729\nProcessing root 601/74729\nProcessing root 611/74729\nProcessing root 621/74729\nProcessing root 631/74729\nProcessing root 641/74729\nProcessing root 651/74729\nProcessing root 661/74729\nProcessing root 671/74729\nProcessing root 681/74729\nProcessing root 691/74729\nProcessing root 701/74729\nProcessing root 711/74729\nProcessing root 721/74729\nProcessing root 731/74729\nProcessing root 741/74729\nProcessing root 751/74729\nProcessing root 761/74729\nProcessing root 771/74729\nProcessing root 781/74729\nProcessing root 791/74729\nProcessing root 801/74729\nProcessing root 811/74729\nProcessing root 821/74729\nProcessing root 831/74729\nProcessing root 841/74729\nProcessing root 851/74729\nProcessing root 861/74729\nProcessing root 871/74729\nProcessing root 881/74729\nProcessing root 891/74729\nProcessing root 901/74729\nProcessing root 911/74729\nProcessing root 921/74729\nProcessing root 931/74729\nProcessing root 941/74729\nProcessing root 951/74729\nProcessing root 961/74729\nProcessing root 971/74729\nProcessing root 981/74729\nProcessing root 991/74729\nProcessing root 1001/74729\nProcessing root 1011/74729\nProcessing root 1021/74729\nProcessing root 1031/74729\nProcessing root 1041/74729\nProcessing root 1051/74729\nProcessing root 1061/74729\nProcessing root 1071/74729\nProcessing root 1081/74729\nProcessing root 1091/74729\nProcessing root 1101/74729\nProcessing root 1111/74729\nProcessing root 1121/74729\nProcessing root 1131/74729\nProcessing root 1141/74729\nProcessing root 1151/74729\nProcessing root 1161/74729\nProcessing root 1171/74729\nProcessing root 1181/74729\nProcessing root 1191/74729\nProcessing root 1201/74729\nProcessing root 1211/74729\nProcessing root 1221/74729\nProcessing root 1231/74729\nProcessing root 1241/74729\nProcessing root 1251/74729\nProcessing root 1261/74729\nProcessing root 1271/74729\nProcessing root 1281/74729\nProcessing root 1291/74729\nProcessing root 1301/74729\nProcessing root 1311/74729\nProcessing root 1321/74729\nProcessing root 1331/74729\nProcessing root 1341/74729\nProcessing root 1351/74729\nProcessing root 1361/74729\nProcessing root 1371/74729\nProcessing root 1381/74729\nProcessing root 1391/74729\nProcessing root 1401/74729\nProcessing root 1411/74729\nProcessing root 1421/74729\nProcessing root 1431/74729\nProcessing root 1441/74729\nProcessing root 1451/74729\nProcessing root 1461/74729\nProcessing root 1471/74729\nProcessing root 1481/74729\nProcessing root 1491/74729\nProcessing root 1501/74729\nProcessing root 1511/74729\nProcessing root 1521/74729\nProcessing root 1531/74729\nProcessing root 1541/74729\nProcessing root 1551/74729\nProcessing root 1561/74729\nProcessing root 1571/74729\nProcessing root 1581/74729\nProcessing root 1591/74729\nProcessing root 1601/74729\nProcessing root 1611/74729\nProcessing root 1621/74729\nProcessing root 1631/74729\nProcessing root 1641/74729\nProcessing root 1651/74729\nProcessing root 1661/74729\nProcessing root 1671/74729\nProcessing root 1681/74729\nProcessing root 1691/74729\nProcessing root 1701/74729\nProcessing root 1711/74729\nProcessing root 1721/74729\nProcessing root 1731/74729\nProcessing root 1741/74729\nProcessing root 1751/74729\nProcessing root 1761/74729\nProcessing root 1771/74729\nProcessing root 1781/74729\nProcessing root 1791/74729\nProcessing root 1801/74729\nProcessing root 1811/74729\nProcessing root 1821/74729\nProcessing root 1831/74729\nProcessing root 1841/74729\nProcessing root 1851/74729\nProcessing root 1861/74729\nProcessing root 1871/74729\nProcessing root 1881/74729\nProcessing root 1891/74729\nProcessing root 1901/74729\nProcessing root 1911/74729\nProcessing root 1921/74729\nProcessing root 1931/74729\nProcessing root 1941/74729\nProcessing root 1951/74729\nProcessing root 1961/74729\nProcessing root 1971/74729\nProcessing root 1981/74729\nProcessing root 1991/74729\nProcessing root 2001/74729\nProcessing root 2011/74729\nProcessing root 2021/74729\nProcessing root 2031/74729\nProcessing root 2041/74729\nProcessing root 2051/74729\nProcessing root 2061/74729\nProcessing root 2071/74729\nProcessing root 2081/74729\nProcessing root 2091/74729\nProcessing root 2101/74729\nProcessing root 2111/74729\nProcessing root 2121/74729\nProcessing root 2131/74729\nProcessing root 2141/74729\nProcessing root 2151/74729\nProcessing root 2161/74729\nProcessing root 2171/74729\nProcessing root 2181/74729\nProcessing root 2191/74729\nProcessing root 2201/74729\nProcessing root 2211/74729\nProcessing root 2221/74729\nProcessing root 2231/74729\nProcessing root 2241/74729\nProcessing root 2251/74729\nProcessing root 2261/74729\nProcessing root 2271/74729\nProcessing root 2281/74729\nProcessing root 2291/74729\nProcessing root 2301/74729\nProcessing root 2311/74729\nProcessing root 2321/74729\nProcessing root 2331/74729\nProcessing root 2341/74729\nProcessing root 2351/74729\nProcessing root 2361/74729\nProcessing root 2371/74729\nProcessing root 2381/74729\nProcessing root 2391/74729\nProcessing root 2401/74729\nProcessing root 2411/74729\nProcessing root 2421/74729\nProcessing root 2431/74729\nProcessing root 2441/74729\nProcessing root 2451/74729\nProcessing root 2461/74729\nProcessing root 2471/74729\nProcessing root 2481/74729\nProcessing root 2491/74729\nProcessing root 2501/74729\nProcessing root 2511/74729\nProcessing root 2521/74729\nProcessing root 2531/74729\nProcessing root 2541/74729\nProcessing root 2551/74729\nProcessing root 2561/74729\nProcessing root 2571/74729\nProcessing root 2581/74729\nProcessing root 2591/74729\nProcessing root 2601/74729\nProcessing root 2611/74729\nProcessing root 2621/74729\nProcessing root 2631/74729\nProcessing root 2641/74729\nProcessing root 2651/74729\nProcessing root 2661/74729\nProcessing root 2671/74729\nProcessing root 2681/74729\nProcessing root 2691/74729\nProcessing root 2701/74729\nProcessing root 2711/74729\nProcessing root 2721/74729\nProcessing root 2731/74729\nProcessing root 2741/74729\nProcessing root 2751/74729\nProcessing root 2761/74729\nProcessing root 2771/74729\nProcessing root 2781/74729\nProcessing root 2791/74729\nProcessing root 2801/74729\nProcessing root 2811/74729\nProcessing root 2821/74729\nProcessing root 2831/74729\nProcessing root 2841/74729\nProcessing root 2851/74729\nProcessing root 2861/74729\nProcessing root 2871/74729\nProcessing root 2881/74729\nProcessing root 2891/74729\nProcessing root 2901/74729\nProcessing root 2911/74729\nProcessing root 2921/74729\nProcessing root 2931/74729\nProcessing root 2941/74729\nProcessing root 2951/74729\nProcessing root 2961/74729\nProcessing root 2971/74729\nProcessing root 2981/74729\nProcessing root 2991/74729\nProcessing root 3001/74729\nProcessing root 3011/74729\nProcessing root 3021/74729\nProcessing root 3031/74729\nProcessing root 3041/74729\nProcessing root 3051/74729\nProcessing root 3061/74729\nProcessing root 3071/74729\nProcessing root 3081/74729\nProcessing root 3091/74729\nProcessing root 3101/74729\nProcessing root 3111/74729\nProcessing root 3121/74729\nProcessing root 3131/74729\nProcessing root 3141/74729\nProcessing root 3151/74729\nProcessing root 3161/74729\nProcessing root 3171/74729\nProcessing root 3181/74729\nProcessing root 3191/74729\nProcessing root 3201/74729\nProcessing root 3211/74729\nProcessing root 3221/74729\nProcessing root 3231/74729\nProcessing root 3241/74729\nProcessing root 3251/74729\nProcessing root 3261/74729\nProcessing root 3271/74729\nProcessing root 3281/74729\nProcessing root 3291/74729\nProcessing root 3301/74729\nProcessing root 3311/74729\nProcessing root 3321/74729\nProcessing root 3331/74729\nProcessing root 3341/74729\nProcessing root 3351/74729\nProcessing root 3361/74729\nProcessing root 3371/74729\nProcessing root 3381/74729\nProcessing root 3391/74729\nProcessing root 3401/74729\nProcessing root 3411/74729\nProcessing root 3421/74729\nProcessing root 3431/74729\nProcessing root 3441/74729\nProcessing root 3451/74729\nProcessing root 3461/74729\nProcessing root 3471/74729\nProcessing root 3481/74729\nProcessing root 3491/74729\nProcessing root 3501/74729\nProcessing root 3511/74729\nProcessing root 3521/74729\nProcessing root 3531/74729\nProcessing root 3541/74729\nProcessing root 3551/74729\nProcessing root 3561/74729\nProcessing root 3571/74729\nProcessing root 3581/74729\nProcessing root 3591/74729\nProcessing root 3601/74729\nProcessing root 3611/74729\nProcessing root 3621/74729\nProcessing root 3631/74729\nProcessing root 3641/74729\nProcessing root 3651/74729\nProcessing root 3661/74729\nProcessing root 3671/74729\nProcessing root 3681/74729\nProcessing root 3691/74729\nProcessing root 3701/74729\nProcessing root 3711/74729\nProcessing root 3721/74729\nProcessing root 3731/74729\nProcessing root 3741/74729\nProcessing root 3751/74729\nProcessing root 3761/74729\nProcessing root 3771/74729\nProcessing root 3781/74729\nProcessing root 3791/74729\nProcessing root 3801/74729\nProcessing root 3811/74729\nProcessing root 3821/74729\nProcessing root 3831/74729\nProcessing root 3841/74729\nProcessing root 3851/74729\nProcessing root 3861/74729\nProcessing root 3871/74729\nProcessing root 3881/74729\nProcessing root 3891/74729\nProcessing root 3901/74729\nProcessing root 3911/74729\nProcessing root 3921/74729\nProcessing root 3931/74729\nProcessing root 3941/74729\nProcessing root 3951/74729\nProcessing root 3961/74729\nProcessing root 3971/74729\nProcessing root 3981/74729\nProcessing root 3991/74729\nProcessing root 4001/74729\nProcessing root 4011/74729\nProcessing root 4021/74729\nProcessing root 4031/74729\nProcessing root 4041/74729\nProcessing root 4051/74729\nProcessing root 4061/74729\nProcessing root 4071/74729\nProcessing root 4081/74729\nProcessing root 4091/74729\nProcessing root 4101/74729\nProcessing root 4111/74729\nProcessing root 4121/74729\nProcessing root 4131/74729\nProcessing root 4141/74729\nProcessing root 4151/74729\nProcessing root 4161/74729\nProcessing root 4171/74729\nProcessing root 4181/74729\nProcessing root 4191/74729\nProcessing root 4201/74729\nProcessing root 4211/74729\nProcessing root 4221/74729\nProcessing root 4231/74729\nProcessing root 4241/74729\nProcessing root 4251/74729\nProcessing root 4261/74729\nProcessing root 4271/74729\nProcessing root 4281/74729\nProcessing root 4291/74729\nProcessing root 4301/74729\nProcessing root 4311/74729\nProcessing root 4321/74729\nProcessing root 4331/74729\nProcessing root 4341/74729\nProcessing root 4351/74729\nProcessing root 4361/74729\nProcessing root 4371/74729\nProcessing root 4381/74729\nProcessing root 4391/74729\nProcessing root 4401/74729\nProcessing root 4411/74729\nProcessing root 4421/74729\nProcessing root 4431/74729\nProcessing root 4441/74729\nProcessing root 4451/74729\nProcessing root 4461/74729\nProcessing root 4471/74729\nProcessing root 4481/74729\nProcessing root 4491/74729\nProcessing root 4501/74729\nProcessing root 4511/74729\nProcessing root 4521/74729\nProcessing root 4531/74729\nProcessing root 4541/74729\nProcessing root 4551/74729\nProcessing root 4561/74729\nProcessing root 4571/74729\nProcessing root 4581/74729\nProcessing root 4591/74729\nProcessing root 4601/74729\nProcessing root 4611/74729\nProcessing root 4621/74729\nProcessing root 4631/74729\nProcessing root 4641/74729\nProcessing root 4651/74729\nProcessing root 4661/74729\nProcessing root 4671/74729\nProcessing root 4681/74729\nProcessing root 4691/74729\nProcessing root 4701/74729\nProcessing root 4711/74729\nProcessing root 4721/74729\nProcessing root 4731/74729\nProcessing root 4741/74729\nProcessing root 4751/74729\nProcessing root 4761/74729\nProcessing root 4771/74729\nProcessing root 4781/74729\nProcessing root 4791/74729\nProcessing root 4801/74729\nProcessing root 4811/74729\nProcessing root 4821/74729\nProcessing root 4831/74729\nProcessing root 4841/74729\nProcessing root 4851/74729\nProcessing root 4861/74729\nProcessing root 4871/74729\nProcessing root 4881/74729\nProcessing root 4891/74729\nProcessing root 4901/74729\nProcessing root 4911/74729\nProcessing root 4921/74729\nProcessing root 4931/74729\nProcessing root 4941/74729\nProcessing root 4951/74729\nProcessing root 4961/74729\nProcessing root 4971/74729\nProcessing root 4981/74729\nProcessing root 4991/74729\nProcessing root 5001/74729\nProcessing root 5011/74729\nProcessing root 5021/74729\nProcessing root 5031/74729\nProcessing root 5041/74729\nProcessing root 5051/74729\nProcessing root 5061/74729\nProcessing root 5071/74729\nProcessing root 5081/74729\nProcessing root 5091/74729\nProcessing root 5101/74729\nProcessing root 5111/74729\nProcessing root 5121/74729\nProcessing root 5131/74729\nProcessing root 5141/74729\nProcessing root 5151/74729\nProcessing root 5161/74729\nProcessing root 5171/74729\nProcessing root 5181/74729\nProcessing root 5191/74729\nProcessing root 5201/74729\nProcessing root 5211/74729\nProcessing root 5221/74729\nProcessing root 5231/74729\nProcessing root 5241/74729\nProcessing root 5251/74729\nProcessing root 5261/74729\nProcessing root 5271/74729\nProcessing root 5281/74729\nProcessing root 5291/74729\nProcessing root 5301/74729\nProcessing root 5311/74729\nProcessing root 5321/74729\nProcessing root 5331/74729\nProcessing root 5341/74729\nProcessing root 5351/74729\nProcessing root 5361/74729\nProcessing root 5371/74729\nProcessing root 5381/74729\nProcessing root 5391/74729\nProcessing root 5401/74729\nProcessing root 5411/74729\nProcessing root 5421/74729\nProcessing root 5431/74729\nProcessing root 5441/74729\nProcessing root 5451/74729\nProcessing root 5461/74729\nProcessing root 5471/74729\nProcessing root 5481/74729\nProcessing root 5491/74729\nProcessing root 5501/74729\nProcessing root 5511/74729\nProcessing root 5521/74729\nProcessing root 5531/74729\nProcessing root 5541/74729\nProcessing root 5551/74729\nProcessing root 5561/74729\nProcessing root 5571/74729\nProcessing root 5581/74729\nProcessing root 5591/74729\nProcessing root 5601/74729\nProcessing root 5611/74729\nProcessing root 5621/74729\nProcessing root 5631/74729\nProcessing root 5641/74729\nProcessing root 5651/74729\nProcessing root 5661/74729\nProcessing root 5671/74729\nProcessing root 5681/74729\nProcessing root 5691/74729\nProcessing root 5701/74729\nProcessing root 5711/74729\nProcessing root 5721/74729\nProcessing root 5731/74729\nProcessing root 5741/74729\nProcessing root 5751/74729\nProcessing root 5761/74729\nProcessing root 5771/74729\nProcessing root 5781/74729\nProcessing root 5791/74729\nProcessing root 5801/74729\nProcessing root 5811/74729\nProcessing root 5821/74729\nProcessing root 5831/74729\nProcessing root 5841/74729\nProcessing root 5851/74729\nProcessing root 5861/74729\nProcessing root 5871/74729\nProcessing root 5881/74729\nProcessing root 5891/74729\nProcessing root 5901/74729\nProcessing root 5911/74729\nProcessing root 5921/74729\nProcessing root 5931/74729\nProcessing root 5941/74729\nProcessing root 5951/74729\nProcessing root 5961/74729\nProcessing root 5971/74729\nProcessing root 5981/74729\nProcessing root 5991/74729\nProcessing root 6001/74729\nProcessing root 6011/74729\nProcessing root 6021/74729\nProcessing root 6031/74729\nProcessing root 6041/74729\nProcessing root 6051/74729\nProcessing root 6061/74729\nProcessing root 6071/74729\nProcessing root 6081/74729\nProcessing root 6091/74729\nProcessing root 6101/74729\nProcessing root 6111/74729\nProcessing root 6121/74729\nProcessing root 6131/74729\nProcessing root 6141/74729\nProcessing root 6151/74729\nProcessing root 6161/74729\nProcessing root 6171/74729\nProcessing root 6181/74729\nProcessing root 6191/74729\nProcessing root 6201/74729\nProcessing root 6211/74729\nProcessing root 6221/74729\nProcessing root 6231/74729\nProcessing root 6241/74729\nProcessing root 6251/74729\nProcessing root 6261/74729\nProcessing root 6271/74729\nProcessing root 6281/74729\nProcessing root 6291/74729\nProcessing root 6301/74729\nProcessing root 6311/74729\nProcessing root 6321/74729\nProcessing root 6331/74729\nProcessing root 6341/74729\nProcessing root 6351/74729\nProcessing root 6361/74729\nProcessing root 6371/74729\nProcessing root 6381/74729\nProcessing root 6391/74729\nProcessing root 6401/74729\nProcessing root 6411/74729\nProcessing root 6421/74729\nProcessing root 6431/74729\nProcessing root 6441/74729\nProcessing root 6451/74729\nProcessing root 6461/74729\nProcessing root 6471/74729\nProcessing root 6481/74729\nProcessing root 6491/74729\nProcessing root 6501/74729\nProcessing root 6511/74729\nProcessing root 6521/74729\nProcessing root 6531/74729\nProcessing root 6541/74729\nProcessing root 6551/74729\nProcessing root 6561/74729\nProcessing root 6571/74729\nProcessing root 6581/74729\nProcessing root 6591/74729\nProcessing root 6601/74729\nProcessing root 6611/74729\nProcessing root 6621/74729\nProcessing root 6631/74729\nProcessing root 6641/74729\nProcessing root 6651/74729\nProcessing root 6661/74729\nProcessing root 6671/74729\nProcessing root 6681/74729\nProcessing root 6691/74729\nProcessing root 6701/74729\nProcessing root 6711/74729\nProcessing root 6721/74729\nProcessing root 6731/74729\nProcessing root 6741/74729\nProcessing root 6751/74729\nProcessing root 6761/74729\nProcessing root 6771/74729\nProcessing root 6781/74729\nProcessing root 6791/74729\nProcessing root 6801/74729\nProcessing root 6811/74729\nProcessing root 6821/74729\nProcessing root 6831/74729\nProcessing root 6841/74729\nProcessing root 6851/74729\nProcessing root 6861/74729\nProcessing root 6871/74729\nProcessing root 6881/74729\nProcessing root 6891/74729\nProcessing root 6901/74729\nProcessing root 6911/74729\nProcessing root 6921/74729\nProcessing root 6931/74729\nProcessing root 6941/74729\nProcessing root 6951/74729\nProcessing root 6961/74729\nProcessing root 6971/74729\nProcessing root 6981/74729\nProcessing root 6991/74729\nProcessing root 7001/74729\nProcessing root 7011/74729\nProcessing root 7021/74729\nProcessing root 7031/74729\nProcessing root 7041/74729\nProcessing root 7051/74729\nProcessing root 7061/74729\nProcessing root 7071/74729\nProcessing root 7081/74729\nProcessing root 7091/74729\nProcessing root 7101/74729\nProcessing root 7111/74729\nProcessing root 7121/74729\nProcessing root 7131/74729\nProcessing root 7141/74729\nProcessing root 7151/74729\nProcessing root 7161/74729\nProcessing root 7171/74729\nProcessing root 7181/74729\nProcessing root 7191/74729\nProcessing root 7201/74729\nProcessing root 7211/74729\nProcessing root 7221/74729\nProcessing root 7231/74729\nProcessing root 7241/74729\nProcessing root 7251/74729\nProcessing root 7261/74729\nProcessing root 7271/74729\nProcessing root 7281/74729\nProcessing root 7291/74729\nProcessing root 7301/74729\nProcessing root 7311/74729\nProcessing root 7321/74729\nProcessing root 7331/74729\nProcessing root 7341/74729\nProcessing root 7351/74729\nProcessing root 7361/74729\nProcessing root 7371/74729\nProcessing root 7381/74729\nProcessing root 7391/74729\nProcessing root 7401/74729\nProcessing root 7411/74729\nProcessing root 7421/74729\nProcessing root 7431/74729\nProcessing root 7441/74729\nProcessing root 7451/74729\nProcessing root 7461/74729\nProcessing root 7471/74729\nProcessing root 7481/74729\nProcessing root 7491/74729\nProcessing root 7501/74729\nProcessing root 7511/74729\nProcessing root 7521/74729\nProcessing root 7531/74729\nProcessing root 7541/74729\nProcessing root 7551/74729\nProcessing root 7561/74729\nProcessing root 7571/74729\nProcessing root 7581/74729\nProcessing root 7591/74729\nProcessing root 7601/74729\nProcessing root 7611/74729\nProcessing root 7621/74729\nProcessing root 7631/74729\nProcessing root 7641/74729\nProcessing root 7651/74729\nProcessing root 7661/74729\nProcessing root 7671/74729\nProcessing root 7681/74729\nProcessing root 7691/74729\nProcessing root 7701/74729\nProcessing root 7711/74729\nProcessing root 7721/74729\nProcessing root 7731/74729\nProcessing root 7741/74729\nProcessing root 7751/74729\nProcessing root 7761/74729\nProcessing root 7771/74729\nProcessing root 7781/74729\nProcessing root 7791/74729\nProcessing root 7801/74729\nProcessing root 7811/74729\nProcessing root 7821/74729\nProcessing root 7831/74729\nProcessing root 7841/74729\nProcessing root 7851/74729\nProcessing root 7861/74729\nProcessing root 7871/74729\nProcessing root 7881/74729\nProcessing root 7891/74729\nProcessing root 7901/74729\nProcessing root 7911/74729\nProcessing root 7921/74729\nProcessing root 7931/74729\nProcessing root 7941/74729\nProcessing root 7951/74729\nProcessing root 7961/74729\nProcessing root 7971/74729\nProcessing root 7981/74729\nProcessing root 7991/74729\nProcessing root 8001/74729\nProcessing root 8011/74729\nProcessing root 8021/74729\nProcessing root 8031/74729\nProcessing root 8041/74729\nProcessing root 8051/74729\nProcessing root 8061/74729\nProcessing root 8071/74729\nProcessing root 8081/74729\nProcessing root 8091/74729\nProcessing root 8101/74729\nProcessing root 8111/74729\nProcessing root 8121/74729\nProcessing root 8131/74729\nProcessing root 8141/74729\nProcessing root 8151/74729\nProcessing root 8161/74729\nProcessing root 8171/74729\nProcessing root 8181/74729\nProcessing root 8191/74729\nProcessing root 8201/74729\nProcessing root 8211/74729\nProcessing root 8221/74729\nProcessing root 8231/74729\nProcessing root 8241/74729\nProcessing root 8251/74729\nProcessing root 8261/74729\nProcessing root 8271/74729\nProcessing root 8281/74729\nProcessing root 8291/74729\nProcessing root 8301/74729\nProcessing root 8311/74729\nProcessing root 8321/74729\nProcessing root 8331/74729\nProcessing root 8341/74729\nProcessing root 8351/74729\nProcessing root 8361/74729\nProcessing root 8371/74729\nProcessing root 8381/74729\nProcessing root 8391/74729\nProcessing root 8401/74729\nProcessing root 8411/74729\nProcessing root 8421/74729\nProcessing root 8431/74729\nProcessing root 8441/74729\nProcessing root 8451/74729\nProcessing root 8461/74729\nProcessing root 8471/74729\nProcessing root 8481/74729\nProcessing root 8491/74729\nProcessing root 8501/74729\nProcessing root 8511/74729\nProcessing root 8521/74729\nProcessing root 8531/74729\nProcessing root 8541/74729\nProcessing root 8551/74729\nProcessing root 8561/74729\nProcessing root 8571/74729\nProcessing root 8581/74729\nProcessing root 8591/74729\nProcessing root 8601/74729\nProcessing root 8611/74729\nProcessing root 8621/74729\nProcessing root 8631/74729\nProcessing root 8641/74729\nProcessing root 8651/74729\nProcessing root 8661/74729\nProcessing root 8671/74729\nProcessing root 8681/74729\nProcessing root 8691/74729\nProcessing root 8701/74729\nProcessing root 8711/74729\nProcessing root 8721/74729\nProcessing root 8731/74729\nProcessing root 8741/74729\nProcessing root 8751/74729\nProcessing root 8761/74729\nProcessing root 8771/74729\nProcessing root 8781/74729\nProcessing root 8791/74729\nProcessing root 8801/74729\nProcessing root 8811/74729\nProcessing root 8821/74729\nProcessing root 8831/74729\nProcessing root 8841/74729\nProcessing root 8851/74729\nProcessing root 8861/74729\nProcessing root 8871/74729\nProcessing root 8881/74729\nProcessing root 8891/74729\nProcessing root 8901/74729\nProcessing root 8911/74729\nProcessing root 8921/74729\nProcessing root 8931/74729\nProcessing root 8941/74729\nProcessing root 8951/74729\nProcessing root 8961/74729\nProcessing root 8971/74729\nProcessing root 8981/74729\nProcessing root 8991/74729\nProcessing root 9001/74729\nProcessing root 9011/74729\nProcessing root 9021/74729\nProcessing root 9031/74729\nProcessing root 9041/74729\nProcessing root 9051/74729\nProcessing root 9061/74729\nProcessing root 9071/74729\nProcessing root 9081/74729\nProcessing root 9091/74729\nProcessing root 9101/74729\nProcessing root 9111/74729\nProcessing root 9121/74729\nProcessing root 9131/74729\nProcessing root 9141/74729\nProcessing root 9151/74729\nProcessing root 9161/74729\nProcessing root 9171/74729\nProcessing root 9181/74729\nProcessing root 9191/74729\nProcessing root 9201/74729\nProcessing root 9211/74729\nProcessing root 9221/74729\nProcessing root 9231/74729\nProcessing root 9241/74729\nProcessing root 9251/74729\nProcessing root 9261/74729\nProcessing root 9271/74729\nProcessing root 9281/74729\nProcessing root 9291/74729\nProcessing root 9301/74729\nProcessing root 9311/74729\nProcessing root 9321/74729\nProcessing root 9331/74729\nProcessing root 9341/74729\nProcessing root 9351/74729\nProcessing root 9361/74729\nProcessing root 9371/74729\nProcessing root 9381/74729\nProcessing root 9391/74729\nProcessing root 9401/74729\nProcessing root 9411/74729\nProcessing root 9421/74729\nProcessing root 9431/74729\nProcessing root 9441/74729\nProcessing root 9451/74729\nProcessing root 9461/74729\nProcessing root 9471/74729\nProcessing root 9481/74729\nProcessing root 9491/74729\nProcessing root 9501/74729\nProcessing root 9511/74729\nProcessing root 9521/74729\nProcessing root 9531/74729\nProcessing root 9541/74729\nProcessing root 9551/74729\nProcessing root 9561/74729\nProcessing root 9571/74729\nProcessing root 9581/74729\nProcessing root 9591/74729\nProcessing root 9601/74729\nProcessing root 9611/74729\nProcessing root 9621/74729\nProcessing root 9631/74729\nProcessing root 9641/74729\nProcessing root 9651/74729\nProcessing root 9661/74729\nProcessing root 9671/74729\nProcessing root 9681/74729\nProcessing root 9691/74729\nProcessing root 9701/74729\nProcessing root 9711/74729\nProcessing root 9721/74729\nProcessing root 9731/74729\nProcessing root 9741/74729\nProcessing root 9751/74729\nProcessing root 9761/74729\nProcessing root 9771/74729\nProcessing root 9781/74729\nProcessing root 9791/74729\nProcessing root 9801/74729\nProcessing root 9811/74729\nProcessing root 9821/74729\nProcessing root 9831/74729\nProcessing root 9841/74729\nProcessing root 9851/74729\nProcessing root 9861/74729\nProcessing root 9871/74729\nProcessing root 9881/74729\nProcessing root 9891/74729\nProcessing root 9901/74729\nProcessing root 9911/74729\nProcessing root 9921/74729\nProcessing root 9931/74729\nProcessing root 9941/74729\nProcessing root 9951/74729\nProcessing root 9961/74729\nProcessing root 9971/74729\nProcessing root 9981/74729\nProcessing root 9991/74729\nProcessing root 10001/74729\nProcessing root 10011/74729\nProcessing root 10021/74729\nProcessing root 10031/74729\nProcessing root 10041/74729\nProcessing root 10051/74729\nProcessing root 10061/74729\nProcessing root 10071/74729\nProcessing root 10081/74729\nProcessing root 10091/74729\nProcessing root 10101/74729\nProcessing root 10111/74729\nProcessing root 10121/74729\nProcessing root 10131/74729\nProcessing root 10141/74729\nProcessing root 10151/74729\nProcessing root 10161/74729\nProcessing root 10171/74729\nProcessing root 10181/74729\nProcessing root 10191/74729\nProcessing root 10201/74729\nProcessing root 10211/74729\nProcessing root 10221/74729\nProcessing root 10231/74729\nProcessing root 10241/74729\nProcessing root 10251/74729\nProcessing root 10261/74729\nProcessing root 10271/74729\nProcessing root 10281/74729\nProcessing root 10291/74729\nProcessing root 10301/74729\nProcessing root 10311/74729\nProcessing root 10321/74729\nProcessing root 10331/74729\nProcessing root 10341/74729\nProcessing root 10351/74729\nProcessing root 10361/74729\nProcessing root 10371/74729\nProcessing root 10381/74729\nProcessing root 10391/74729\nProcessing root 10401/74729\nProcessing root 10411/74729\nProcessing root 10421/74729\nProcessing root 10431/74729\nProcessing root 10441/74729\nProcessing root 10451/74729\nProcessing root 10461/74729\nProcessing root 10471/74729\nProcessing root 10481/74729\nProcessing root 10491/74729\nProcessing root 10501/74729\nProcessing root 10511/74729\nProcessing root 10521/74729\nProcessing root 10531/74729\nProcessing root 10541/74729\nProcessing root 10551/74729\nProcessing root 10561/74729\nProcessing root 10571/74729\nProcessing root 10581/74729\nProcessing root 10591/74729\nProcessing root 10601/74729\nProcessing root 10611/74729\nProcessing root 10621/74729\nProcessing root 10631/74729\nProcessing root 10641/74729\nProcessing root 10651/74729\nProcessing root 10661/74729\nProcessing root 10671/74729\nProcessing root 10681/74729\nProcessing root 10691/74729\nProcessing root 10701/74729\nProcessing root 10711/74729\nProcessing root 10721/74729\nProcessing root 10731/74729\nProcessing root 10741/74729\nProcessing root 10751/74729\nProcessing root 10761/74729\nProcessing root 10771/74729\nProcessing root 10781/74729\nProcessing root 10791/74729\nProcessing root 10801/74729\nProcessing root 10811/74729\nProcessing root 10821/74729\nProcessing root 10831/74729\nProcessing root 10841/74729\nProcessing root 10851/74729\nProcessing root 10861/74729\nProcessing root 10871/74729\nProcessing root 10881/74729\nProcessing root 10891/74729\nProcessing root 10901/74729\nProcessing root 10911/74729\nProcessing root 10921/74729\nProcessing root 10931/74729\nProcessing root 10941/74729\nProcessing root 10951/74729\nProcessing root 10961/74729\nProcessing root 10971/74729\nProcessing root 10981/74729\nProcessing root 10991/74729\nProcessing root 11001/74729\nProcessing root 11011/74729\nProcessing root 11021/74729\nProcessing root 11031/74729\nProcessing root 11041/74729\nProcessing root 11051/74729\nProcessing root 11061/74729\nProcessing root 11071/74729\nProcessing root 11081/74729\nProcessing root 11091/74729\nProcessing root 11101/74729\nProcessing root 11111/74729\nProcessing root 11121/74729\nProcessing root 11131/74729\nProcessing root 11141/74729\nProcessing root 11151/74729\nProcessing root 11161/74729\nProcessing root 11171/74729\nProcessing root 11181/74729\nProcessing root 11191/74729\nProcessing root 11201/74729\nProcessing root 11211/74729\nProcessing root 11221/74729\nProcessing root 11231/74729\nProcessing root 11241/74729\nProcessing root 11251/74729\nProcessing root 11261/74729\nProcessing root 11271/74729\nProcessing root 11281/74729\nProcessing root 11291/74729\nProcessing root 11301/74729\nProcessing root 11311/74729\nProcessing root 11321/74729\nProcessing root 11331/74729\nProcessing root 11341/74729\nProcessing root 11351/74729\nProcessing root 11361/74729\nProcessing root 11371/74729\nProcessing root 11381/74729\nProcessing root 11391/74729\nProcessing root 11401/74729\nProcessing root 11411/74729\nProcessing root 11421/74729\nProcessing root 11431/74729\nProcessing root 11441/74729\nProcessing root 11451/74729\nProcessing root 11461/74729\nProcessing root 11471/74729\nProcessing root 11481/74729\nProcessing root 11491/74729\nProcessing root 11501/74729\nProcessing root 11511/74729\nProcessing root 11521/74729\nProcessing root 11531/74729\nProcessing root 11541/74729\nProcessing root 11551/74729\nProcessing root 11561/74729\nProcessing root 11571/74729\nProcessing root 11581/74729\nProcessing root 11591/74729\nProcessing root 11601/74729\nProcessing root 11611/74729\nProcessing root 11621/74729\nProcessing root 11631/74729\nProcessing root 11641/74729\nProcessing root 11651/74729\nProcessing root 11661/74729\nProcessing root 11671/74729\nProcessing root 11681/74729\nProcessing root 11691/74729\nProcessing root 11701/74729\nProcessing root 11711/74729\nProcessing root 11721/74729\nProcessing root 11731/74729\nProcessing root 11741/74729\nProcessing root 11751/74729\nProcessing root 11761/74729\nProcessing root 11771/74729\nProcessing root 11781/74729\nProcessing root 11791/74729\nProcessing root 11801/74729\nProcessing root 11811/74729\nProcessing root 11821/74729\nProcessing root 11831/74729\nProcessing root 11841/74729\nProcessing root 11851/74729\nProcessing root 11861/74729\nProcessing root 11871/74729\nProcessing root 11881/74729\nProcessing root 11891/74729\nProcessing root 11901/74729\nProcessing root 11911/74729\nProcessing root 11921/74729\nProcessing root 11931/74729\nProcessing root 11941/74729\nProcessing root 11951/74729\nProcessing root 11961/74729\nProcessing root 11971/74729\nProcessing root 11981/74729\nProcessing root 11991/74729\nProcessing root 12001/74729\nProcessing root 12011/74729\nProcessing root 12021/74729\nProcessing root 12031/74729\nProcessing root 12041/74729\nProcessing root 12051/74729\nProcessing root 12061/74729\nProcessing root 12071/74729\nProcessing root 12081/74729\nProcessing root 12091/74729\nProcessing root 12101/74729\nProcessing root 12111/74729\nProcessing root 12121/74729\nProcessing root 12131/74729\nProcessing root 12141/74729\nProcessing root 12151/74729\nProcessing root 12161/74729\nProcessing root 12171/74729\nProcessing root 12181/74729\nProcessing root 12191/74729\nProcessing root 12201/74729\nProcessing root 12211/74729\nProcessing root 12221/74729\nProcessing root 12231/74729\nProcessing root 12241/74729\nProcessing root 12251/74729\nProcessing root 12261/74729\nProcessing root 12271/74729\nProcessing root 12281/74729\nProcessing root 12291/74729\nProcessing root 12301/74729\nProcessing root 12311/74729\nProcessing root 12321/74729\nProcessing root 12331/74729\nProcessing root 12341/74729\nProcessing root 12351/74729\nProcessing root 12361/74729\nProcessing root 12371/74729\nProcessing root 12381/74729\nProcessing root 12391/74729\nProcessing root 12401/74729\nProcessing root 12411/74729\nProcessing root 12421/74729\nProcessing root 12431/74729\nProcessing root 12441/74729\nProcessing root 12451/74729\nProcessing root 12461/74729\nProcessing root 12471/74729\nProcessing root 12481/74729\nProcessing root 12491/74729\nProcessing root 12501/74729\nProcessing root 12511/74729\nProcessing root 12521/74729\nProcessing root 12531/74729\nProcessing root 12541/74729\nProcessing root 12551/74729\nProcessing root 12561/74729\nProcessing root 12571/74729\nProcessing root 12581/74729\nProcessing root 12591/74729\nProcessing root 12601/74729\nProcessing root 12611/74729\nProcessing root 12621/74729\nProcessing root 12631/74729\nProcessing root 12641/74729\nProcessing root 12651/74729\nProcessing root 12661/74729\nProcessing root 12671/74729\nProcessing root 12681/74729\nProcessing root 12691/74729\nProcessing root 12701/74729\nProcessing root 12711/74729\nProcessing root 12721/74729\nProcessing root 12731/74729\nProcessing root 12741/74729\nProcessing root 12751/74729\nProcessing root 12761/74729\nProcessing root 12771/74729\nProcessing root 12781/74729\nProcessing root 12791/74729\nProcessing root 12801/74729\nProcessing root 12811/74729\nProcessing root 12821/74729\nProcessing root 12831/74729\nProcessing root 12841/74729\nProcessing root 12851/74729\nProcessing root 12861/74729\nProcessing root 12871/74729\nProcessing root 12881/74729\nProcessing root 12891/74729\nProcessing root 12901/74729\nProcessing root 12911/74729\nProcessing root 12921/74729\nProcessing root 12931/74729\nProcessing root 12941/74729\nProcessing root 12951/74729\nProcessing root 12961/74729\nProcessing root 12971/74729\nProcessing root 12981/74729\nProcessing root 12991/74729\nProcessing root 13001/74729\nProcessing root 13011/74729\nProcessing root 13021/74729\nProcessing root 13031/74729\nProcessing root 13041/74729\nProcessing root 13051/74729\nProcessing root 13061/74729\nProcessing root 13071/74729\nProcessing root 13081/74729\nProcessing root 13091/74729\nProcessing root 13101/74729\nProcessing root 13111/74729\nProcessing root 13121/74729\nProcessing root 13131/74729\nProcessing root 13141/74729\nProcessing root 13151/74729\nProcessing root 13161/74729\nProcessing root 13171/74729\nProcessing root 13181/74729\nProcessing root 13191/74729\nProcessing root 13201/74729\nProcessing root 13211/74729\nProcessing root 13221/74729\nProcessing root 13231/74729\nProcessing root 13241/74729\nProcessing root 13251/74729\nProcessing root 13261/74729\nProcessing root 13271/74729\nProcessing root 13281/74729\nProcessing root 13291/74729\nProcessing root 13301/74729\nProcessing root 13311/74729\nProcessing root 13321/74729\nProcessing root 13331/74729\nProcessing root 13341/74729\nProcessing root 13351/74729\nProcessing root 13361/74729\nProcessing root 13371/74729\nProcessing root 13381/74729\nProcessing root 13391/74729\nProcessing root 13401/74729\nProcessing root 13411/74729\nProcessing root 13421/74729\nProcessing root 13431/74729\nProcessing root 13441/74729\nProcessing root 13451/74729\nProcessing root 13461/74729\nProcessing root 13471/74729\nProcessing root 13481/74729\nProcessing root 13491/74729\nProcessing root 13501/74729\nProcessing root 13511/74729\nProcessing root 13521/74729\nProcessing root 13531/74729\nProcessing root 13541/74729\nProcessing root 13551/74729\nProcessing root 13561/74729\nProcessing root 13571/74729\nProcessing root 13581/74729\nProcessing root 13591/74729\nProcessing root 13601/74729\nProcessing root 13611/74729\nProcessing root 13621/74729\nProcessing root 13631/74729\nProcessing root 13641/74729\nProcessing root 13651/74729\nProcessing root 13661/74729\nProcessing root 13671/74729\nProcessing root 13681/74729\nProcessing root 13691/74729\nProcessing root 13701/74729\nProcessing root 13711/74729\nProcessing root 13721/74729\nProcessing root 13731/74729\nProcessing root 13741/74729\nProcessing root 13751/74729\nProcessing root 13761/74729\nProcessing root 13771/74729\nProcessing root 13781/74729\nProcessing root 13791/74729\nProcessing root 13801/74729\nProcessing root 13811/74729\nProcessing root 13821/74729\nProcessing root 13831/74729\nProcessing root 13841/74729\nProcessing root 13851/74729\nProcessing root 13861/74729\nProcessing root 13871/74729\nProcessing root 13881/74729\nProcessing root 13891/74729\nProcessing root 13901/74729\nProcessing root 13911/74729\nProcessing root 13921/74729\nProcessing root 13931/74729\nProcessing root 13941/74729\nProcessing root 13951/74729\nProcessing root 13961/74729\nProcessing root 13971/74729\nProcessing root 13981/74729\nProcessing root 13991/74729\nProcessing root 14001/74729\nProcessing root 14011/74729\nProcessing root 14021/74729\nProcessing root 14031/74729\nProcessing root 14041/74729\nProcessing root 14051/74729\nProcessing root 14061/74729\nProcessing root 14071/74729\nProcessing root 14081/74729\nProcessing root 14091/74729\nProcessing root 14101/74729\nProcessing root 14111/74729\nProcessing root 14121/74729\nProcessing root 14131/74729\nProcessing root 14141/74729\nProcessing root 14151/74729\nProcessing root 14161/74729\nProcessing root 14171/74729\nProcessing root 14181/74729\nProcessing root 14191/74729\nProcessing root 14201/74729\nProcessing root 14211/74729\nProcessing root 14221/74729\nProcessing root 14231/74729\nProcessing root 14241/74729\nProcessing root 14251/74729\nProcessing root 14261/74729\nProcessing root 14271/74729\nProcessing root 14281/74729\nProcessing root 14291/74729\nProcessing root 14301/74729\nProcessing root 14311/74729\nProcessing root 14321/74729\nProcessing root 14331/74729\nProcessing root 14341/74729\nProcessing root 14351/74729\nProcessing root 14361/74729\nProcessing root 14371/74729\nProcessing root 14381/74729\nProcessing root 14391/74729\nProcessing root 14401/74729\nProcessing root 14411/74729\nProcessing root 14421/74729\nProcessing root 14431/74729\nProcessing root 14441/74729\nProcessing root 14451/74729\nProcessing root 14461/74729\nProcessing root 14471/74729\nProcessing root 14481/74729\nProcessing root 14491/74729\nProcessing root 14501/74729\nProcessing root 14511/74729\nProcessing root 14521/74729\nProcessing root 14531/74729\nProcessing root 14541/74729\nProcessing root 14551/74729\nProcessing root 14561/74729\nProcessing root 14571/74729\nProcessing root 14581/74729\nProcessing root 14591/74729\nProcessing root 14601/74729\nProcessing root 14611/74729\nProcessing root 14621/74729\nProcessing root 14631/74729\nProcessing root 14641/74729\nProcessing root 14651/74729\nProcessing root 14661/74729\nProcessing root 14671/74729\nProcessing root 14681/74729\nProcessing root 14691/74729\nProcessing root 14701/74729\nProcessing root 14711/74729\nProcessing root 14721/74729\nProcessing root 14731/74729\nProcessing root 14741/74729\nProcessing root 14751/74729\nProcessing root 14761/74729\nProcessing root 14771/74729\nProcessing root 14781/74729\nProcessing root 14791/74729\nProcessing root 14801/74729\nProcessing root 14811/74729\nProcessing root 14821/74729\nProcessing root 14831/74729\nProcessing root 14841/74729\nProcessing root 14851/74729\nProcessing root 14861/74729\nProcessing root 14871/74729\nProcessing root 14881/74729\nProcessing root 14891/74729\nProcessing root 14901/74729\nProcessing root 14911/74729\nProcessing root 14921/74729\nProcessing root 14931/74729\nProcessing root 14941/74729\nProcessing root 14951/74729\nProcessing root 14961/74729\nProcessing root 14971/74729\nProcessing root 14981/74729\nProcessing root 14991/74729\nProcessing root 15001/74729\nProcessing root 15011/74729\nProcessing root 15021/74729\nProcessing root 15031/74729\nProcessing root 15041/74729\nProcessing root 15051/74729\nProcessing root 15061/74729\nProcessing root 15071/74729\nProcessing root 15081/74729\nProcessing root 15091/74729\nProcessing root 15101/74729\nProcessing root 15111/74729\nProcessing root 15121/74729\nProcessing root 15131/74729\nProcessing root 15141/74729\nProcessing root 15151/74729\nProcessing root 15161/74729\nProcessing root 15171/74729\nProcessing root 15181/74729\nProcessing root 15191/74729\nProcessing root 15201/74729\nProcessing root 15211/74729\nProcessing root 15221/74729\nProcessing root 15231/74729\nProcessing root 15241/74729\nProcessing root 15251/74729\nProcessing root 15261/74729\nProcessing root 15271/74729\nProcessing root 15281/74729\nProcessing root 15291/74729\nProcessing root 15301/74729\nProcessing root 15311/74729\nProcessing root 15321/74729\nProcessing root 15331/74729\nProcessing root 15341/74729\nProcessing root 15351/74729\nProcessing root 15361/74729\nProcessing root 15371/74729\nProcessing root 15381/74729\nProcessing root 15391/74729\nProcessing root 15401/74729\nProcessing root 15411/74729\nProcessing root 15421/74729\nProcessing root 15431/74729\nProcessing root 15441/74729\nProcessing root 15451/74729\nProcessing root 15461/74729\nProcessing root 15471/74729\nProcessing root 15481/74729\nProcessing root 15491/74729\nProcessing root 15501/74729\nProcessing root 15511/74729\nProcessing root 15521/74729\nProcessing root 15531/74729\nProcessing root 15541/74729\nProcessing root 15551/74729\nProcessing root 15561/74729\nProcessing root 15571/74729\nProcessing root 15581/74729\nProcessing root 15591/74729\nProcessing root 15601/74729\nProcessing root 15611/74729\nProcessing root 15621/74729\nProcessing root 15631/74729\nProcessing root 15641/74729\nProcessing root 15651/74729\nProcessing root 15661/74729\nProcessing root 15671/74729\nProcessing root 15681/74729\nProcessing root 15691/74729\nProcessing root 15701/74729\nProcessing root 15711/74729\nProcessing root 15721/74729\nProcessing root 15731/74729\nProcessing root 15741/74729\nProcessing root 15751/74729\nProcessing root 15761/74729\nProcessing root 15771/74729\nProcessing root 15781/74729\nProcessing root 15791/74729\nProcessing root 15801/74729\nProcessing root 15811/74729\nProcessing root 15821/74729\nProcessing root 15831/74729\nProcessing root 15841/74729\nProcessing root 15851/74729\nProcessing root 15861/74729\nProcessing root 15871/74729\nProcessing root 15881/74729\nProcessing root 15891/74729\nProcessing root 15901/74729\nProcessing root 15911/74729\nProcessing root 15921/74729\nProcessing root 15931/74729\nProcessing root 15941/74729\nProcessing root 15951/74729\nProcessing root 15961/74729\nProcessing root 15971/74729\nProcessing root 15981/74729\nProcessing root 15991/74729\nProcessing root 16001/74729\nProcessing root 16011/74729\nProcessing root 16021/74729\nProcessing root 16031/74729\nProcessing root 16041/74729\nProcessing root 16051/74729\nProcessing root 16061/74729\nProcessing root 16071/74729\nProcessing root 16081/74729\nProcessing root 16091/74729\nProcessing root 16101/74729\nProcessing root 16111/74729\nProcessing root 16121/74729\nProcessing root 16131/74729\nProcessing root 16141/74729\nProcessing root 16151/74729\nProcessing root 16161/74729\nProcessing root 16171/74729\nProcessing root 16181/74729\nProcessing root 16191/74729\nProcessing root 16201/74729\nProcessing root 16211/74729\nProcessing root 16221/74729\nProcessing root 16231/74729\nProcessing root 16241/74729\nProcessing root 16251/74729\nProcessing root 16261/74729\nProcessing root 16271/74729\nProcessing root 16281/74729\nProcessing root 16291/74729\nProcessing root 16301/74729\nProcessing root 16311/74729\nProcessing root 16321/74729\nProcessing root 16331/74729\nProcessing root 16341/74729\nProcessing root 16351/74729\nProcessing root 16361/74729\nProcessing root 16371/74729\nProcessing root 16381/74729\nProcessing root 16391/74729\nProcessing root 16401/74729\nProcessing root 16411/74729\nProcessing root 16421/74729\nProcessing root 16431/74729\nProcessing root 16441/74729\nProcessing root 16451/74729\nProcessing root 16461/74729\nProcessing root 16471/74729\nProcessing root 16481/74729\nProcessing root 16491/74729\nProcessing root 16501/74729\nProcessing root 16511/74729\nProcessing root 16521/74729\nProcessing root 16531/74729\nProcessing root 16541/74729\nProcessing root 16551/74729\nProcessing root 16561/74729\nProcessing root 16571/74729\nProcessing root 16581/74729\nProcessing root 16591/74729\nProcessing root 16601/74729\nProcessing root 16611/74729\nProcessing root 16621/74729\nProcessing root 16631/74729\nProcessing root 16641/74729\nProcessing root 16651/74729\nProcessing root 16661/74729\nProcessing root 16671/74729\nProcessing root 16681/74729\nProcessing root 16691/74729\nProcessing root 16701/74729\nProcessing root 16711/74729\nProcessing root 16721/74729\nProcessing root 16731/74729\nProcessing root 16741/74729\nProcessing root 16751/74729\nProcessing root 16761/74729\nProcessing root 16771/74729\nProcessing root 16781/74729\nProcessing root 16791/74729\nProcessing root 16801/74729\nProcessing root 16811/74729\nProcessing root 16821/74729\nProcessing root 16831/74729\nProcessing root 16841/74729\nProcessing root 16851/74729\nProcessing root 16861/74729\nProcessing root 16871/74729\nProcessing root 16881/74729\nProcessing root 16891/74729\nProcessing root 16901/74729\nProcessing root 16911/74729\nProcessing root 16921/74729\nProcessing root 16931/74729\nProcessing root 16941/74729\nProcessing root 16951/74729\nProcessing root 16961/74729\nProcessing root 16971/74729\nProcessing root 16981/74729\nProcessing root 16991/74729\nProcessing root 17001/74729\nProcessing root 17011/74729\nProcessing root 17021/74729\nProcessing root 17031/74729\nProcessing root 17041/74729\nProcessing root 17051/74729\nProcessing root 17061/74729\nProcessing root 17071/74729\nProcessing root 17081/74729\nProcessing root 17091/74729\nProcessing root 17101/74729\nProcessing root 17111/74729\nProcessing root 17121/74729\nProcessing root 17131/74729\nProcessing root 17141/74729\nProcessing root 17151/74729\nProcessing root 17161/74729\nProcessing root 17171/74729\nProcessing root 17181/74729\nProcessing root 17191/74729\nProcessing root 17201/74729\nProcessing root 17211/74729\nProcessing root 17221/74729\nProcessing root 17231/74729\nProcessing root 17241/74729\nProcessing root 17251/74729\nProcessing root 17261/74729\nProcessing root 17271/74729\nProcessing root 17281/74729\nProcessing root 17291/74729\nProcessing root 17301/74729\nProcessing root 17311/74729\nProcessing root 17321/74729\nProcessing root 17331/74729\nProcessing root 17341/74729\nProcessing root 17351/74729\nProcessing root 17361/74729\nProcessing root 17371/74729\nProcessing root 17381/74729\nProcessing root 17391/74729\nProcessing root 17401/74729\nProcessing root 17411/74729\nProcessing root 17421/74729\nProcessing root 17431/74729\nProcessing root 17441/74729\nProcessing root 17451/74729\nProcessing root 17461/74729\nProcessing root 17471/74729\nProcessing root 17481/74729\nProcessing root 17491/74729\nProcessing root 17501/74729\nProcessing root 17511/74729\nProcessing root 17521/74729\nProcessing root 17531/74729\nProcessing root 17541/74729\nProcessing root 17551/74729\nProcessing root 17561/74729\nProcessing root 17571/74729\nProcessing root 17581/74729\nProcessing root 17591/74729\nProcessing root 17601/74729\nProcessing root 17611/74729\nProcessing root 17621/74729\nProcessing root 17631/74729\nProcessing root 17641/74729\nProcessing root 17651/74729\nProcessing root 17661/74729\nProcessing root 17671/74729\nProcessing root 17681/74729\nProcessing root 17691/74729\nProcessing root 17701/74729\nProcessing root 17711/74729\nProcessing root 17721/74729\nProcessing root 17731/74729\nProcessing root 17741/74729\nProcessing root 17751/74729\nProcessing root 17761/74729\nProcessing root 17771/74729\nProcessing root 17781/74729\nProcessing root 17791/74729\nProcessing root 17801/74729\nProcessing root 17811/74729\nProcessing root 17821/74729\nProcessing root 17831/74729\nProcessing root 17841/74729\nProcessing root 17851/74729\nProcessing root 17861/74729\nProcessing root 17871/74729\nProcessing root 17881/74729\nProcessing root 17891/74729\nProcessing root 17901/74729\nProcessing root 17911/74729\nProcessing root 17921/74729\nProcessing root 17931/74729\nProcessing root 17941/74729\nProcessing root 17951/74729\nProcessing root 17961/74729\nProcessing root 17971/74729\nProcessing root 17981/74729\nProcessing root 17991/74729\nProcessing root 18001/74729\nProcessing root 18011/74729\nProcessing root 18021/74729\nProcessing root 18031/74729\nProcessing root 18041/74729\nProcessing root 18051/74729\nProcessing root 18061/74729\nProcessing root 18071/74729\nProcessing root 18081/74729\nProcessing root 18091/74729\nProcessing root 18101/74729\nProcessing root 18111/74729\nProcessing root 18121/74729\nProcessing root 18131/74729\nProcessing root 18141/74729\nProcessing root 18151/74729\nProcessing root 18161/74729\nProcessing root 18171/74729\nProcessing root 18181/74729\nProcessing root 18191/74729\nProcessing root 18201/74729\nProcessing root 18211/74729\nProcessing root 18221/74729\nProcessing root 18231/74729\nProcessing root 18241/74729\nProcessing root 18251/74729\nProcessing root 18261/74729\nProcessing root 18271/74729\nProcessing root 18281/74729\nProcessing root 18291/74729\nProcessing root 18301/74729\nProcessing root 18311/74729\nProcessing root 18321/74729\nProcessing root 18331/74729\nProcessing root 18341/74729\nProcessing root 18351/74729\nProcessing root 18361/74729\nProcessing root 18371/74729\nProcessing root 18381/74729\nProcessing root 18391/74729\nProcessing root 18401/74729\nProcessing root 18411/74729\nProcessing root 18421/74729\nProcessing root 18431/74729\nProcessing root 18441/74729\nProcessing root 18451/74729\nProcessing root 18461/74729\nProcessing root 18471/74729\nProcessing root 18481/74729\nProcessing root 18491/74729\nProcessing root 18501/74729\nProcessing root 18511/74729\nProcessing root 18521/74729\nProcessing root 18531/74729\nProcessing root 18541/74729\nProcessing root 18551/74729\nProcessing root 18561/74729\nProcessing root 18571/74729\nProcessing root 18581/74729\nProcessing root 18591/74729\nProcessing root 18601/74729\nProcessing root 18611/74729\nProcessing root 18621/74729\nProcessing root 18631/74729\nProcessing root 18641/74729\nProcessing root 18651/74729\nProcessing root 18661/74729\nProcessing root 18671/74729\nProcessing root 18681/74729\nProcessing root 18691/74729\nProcessing root 18701/74729\nProcessing root 18711/74729\nProcessing root 18721/74729\nProcessing root 18731/74729\nProcessing root 18741/74729\nProcessing root 18751/74729\nProcessing root 18761/74729\nProcessing root 18771/74729\nProcessing root 18781/74729\nProcessing root 18791/74729\nProcessing root 18801/74729\nProcessing root 18811/74729\nProcessing root 18821/74729\nProcessing root 18831/74729\nProcessing root 18841/74729\nProcessing root 18851/74729\nProcessing root 18861/74729\nProcessing root 18871/74729\nProcessing root 18881/74729\nProcessing root 18891/74729\nProcessing root 18901/74729\nProcessing root 18911/74729\nProcessing root 18921/74729\nProcessing root 18931/74729\nProcessing root 18941/74729\nProcessing root 18951/74729\nProcessing root 18961/74729\nProcessing root 18971/74729\nProcessing root 18981/74729\nProcessing root 18991/74729\nProcessing root 19001/74729\nProcessing root 19011/74729\nProcessing root 19021/74729\nProcessing root 19031/74729\nProcessing root 19041/74729\nProcessing root 19051/74729\nProcessing root 19061/74729\nProcessing root 19071/74729\nProcessing root 19081/74729\nProcessing root 19091/74729\nProcessing root 19101/74729\nProcessing root 19111/74729\nProcessing root 19121/74729\nProcessing root 19131/74729\nProcessing root 19141/74729\nProcessing root 19151/74729\nProcessing root 19161/74729\nProcessing root 19171/74729\nProcessing root 19181/74729\nProcessing root 19191/74729\nProcessing root 19201/74729\nProcessing root 19211/74729\nProcessing root 19221/74729\nProcessing root 19231/74729\nProcessing root 19241/74729\nProcessing root 19251/74729\nProcessing root 19261/74729\nProcessing root 19271/74729\nProcessing root 19281/74729\nProcessing root 19291/74729\nProcessing root 19301/74729\nProcessing root 19311/74729\nProcessing root 19321/74729\nProcessing root 19331/74729\nProcessing root 19341/74729\nProcessing root 19351/74729\nProcessing root 19361/74729\nProcessing root 19371/74729\nProcessing root 19381/74729\nProcessing root 19391/74729\nProcessing root 19401/74729\nProcessing root 19411/74729\nProcessing root 19421/74729\nProcessing root 19431/74729\nProcessing root 19441/74729\nProcessing root 19451/74729\nProcessing root 19461/74729\nProcessing root 19471/74729\nProcessing root 19481/74729\nProcessing root 19491/74729\nProcessing root 19501/74729\nProcessing root 19511/74729\nProcessing root 19521/74729\nProcessing root 19531/74729\nProcessing root 19541/74729\nProcessing root 19551/74729\nProcessing root 19561/74729\nProcessing root 19571/74729\nProcessing root 19581/74729\nProcessing root 19591/74729\nProcessing root 19601/74729\nProcessing root 19611/74729\nProcessing root 19621/74729\nProcessing root 19631/74729\nProcessing root 19641/74729\nProcessing root 19651/74729\nProcessing root 19661/74729\nProcessing root 19671/74729\nProcessing root 19681/74729\nProcessing root 19691/74729\nProcessing root 19701/74729\nProcessing root 19711/74729\nProcessing root 19721/74729\nProcessing root 19731/74729\nProcessing root 19741/74729\nProcessing root 19751/74729\nProcessing root 19761/74729\nProcessing root 19771/74729\nProcessing root 19781/74729\nProcessing root 19791/74729\nProcessing root 19801/74729\nProcessing root 19811/74729\nProcessing root 19821/74729\nProcessing root 19831/74729\nProcessing root 19841/74729\nProcessing root 19851/74729\nProcessing root 19861/74729\nProcessing root 19871/74729\nProcessing root 19881/74729\nProcessing root 19891/74729\nProcessing root 19901/74729\nProcessing root 19911/74729\nProcessing root 19921/74729\nProcessing root 19931/74729\nProcessing root 19941/74729\nProcessing root 19951/74729\nProcessing root 19961/74729\nProcessing root 19971/74729\nProcessing root 19981/74729\nProcessing root 19991/74729\nProcessing root 20001/74729\nProcessing root 20011/74729\nProcessing root 20021/74729\nProcessing root 20031/74729\nProcessing root 20041/74729\nProcessing root 20051/74729\nProcessing root 20061/74729\nProcessing root 20071/74729\nProcessing root 20081/74729\nProcessing root 20091/74729\nProcessing root 20101/74729\nProcessing root 20111/74729\nProcessing root 20121/74729\nProcessing root 20131/74729\nProcessing root 20141/74729\nProcessing root 20151/74729\nProcessing root 20161/74729\nProcessing root 20171/74729\nProcessing root 20181/74729\nProcessing root 20191/74729\nProcessing root 20201/74729\nProcessing root 20211/74729\nProcessing root 20221/74729\nProcessing root 20231/74729\nProcessing root 20241/74729\nProcessing root 20251/74729\nProcessing root 20261/74729\nProcessing root 20271/74729\nProcessing root 20281/74729\nProcessing root 20291/74729\nProcessing root 20301/74729\nProcessing root 20311/74729\nProcessing root 20321/74729\nProcessing root 20331/74729\nProcessing root 20341/74729\nProcessing root 20351/74729\nProcessing root 20361/74729\nProcessing root 20371/74729\nProcessing root 20381/74729\nProcessing root 20391/74729\nProcessing root 20401/74729\nProcessing root 20411/74729\nProcessing root 20421/74729\nProcessing root 20431/74729\nProcessing root 20441/74729\nProcessing root 20451/74729\nProcessing root 20461/74729\nProcessing root 20471/74729\nProcessing root 20481/74729\nProcessing root 20491/74729\nProcessing root 20501/74729\nProcessing root 20511/74729\nProcessing root 20521/74729\nProcessing root 20531/74729\nProcessing root 20541/74729\nProcessing root 20551/74729\nProcessing root 20561/74729\nProcessing root 20571/74729\nProcessing root 20581/74729\nProcessing root 20591/74729\nProcessing root 20601/74729\nProcessing root 20611/74729\nProcessing root 20621/74729\nProcessing root 20631/74729\nProcessing root 20641/74729\nProcessing root 20651/74729\nProcessing root 20661/74729\nProcessing root 20671/74729\nProcessing root 20681/74729\nProcessing root 20691/74729\nProcessing root 20701/74729\nProcessing root 20711/74729\nProcessing root 20721/74729\nProcessing root 20731/74729\nProcessing root 20741/74729\nProcessing root 20751/74729\nProcessing root 20761/74729\nProcessing root 20771/74729\nProcessing root 20781/74729\nProcessing root 20791/74729\nProcessing root 20801/74729\nProcessing root 20811/74729\nProcessing root 20821/74729\nProcessing root 20831/74729\nProcessing root 20841/74729\nProcessing root 20851/74729\nProcessing root 20861/74729\nProcessing root 20871/74729\nProcessing root 20881/74729\nProcessing root 20891/74729\nProcessing root 20901/74729\nProcessing root 20911/74729\nProcessing root 20921/74729\nProcessing root 20931/74729\nProcessing root 20941/74729\nProcessing root 20951/74729\nProcessing root 20961/74729\nProcessing root 20971/74729\nProcessing root 20981/74729\nProcessing root 20991/74729\nProcessing root 21001/74729\nProcessing root 21011/74729\nProcessing root 21021/74729\nProcessing root 21031/74729\nProcessing root 21041/74729\nProcessing root 21051/74729\nProcessing root 21061/74729\nProcessing root 21071/74729\nProcessing root 21081/74729\nProcessing root 21091/74729\nProcessing root 21101/74729\nProcessing root 21111/74729\nProcessing root 21121/74729\nProcessing root 21131/74729\nProcessing root 21141/74729\nProcessing root 21151/74729\nProcessing root 21161/74729\nProcessing root 21171/74729\nProcessing root 21181/74729\nProcessing root 21191/74729\nProcessing root 21201/74729\nProcessing root 21211/74729\nProcessing root 21221/74729\nProcessing root 21231/74729\nProcessing root 21241/74729\nProcessing root 21251/74729\nProcessing root 21261/74729\nProcessing root 21271/74729\nProcessing root 21281/74729\nProcessing root 21291/74729\nProcessing root 21301/74729\nProcessing root 21311/74729\nProcessing root 21321/74729\nProcessing root 21331/74729\nProcessing root 21341/74729\nProcessing root 21351/74729\nProcessing root 21361/74729\nProcessing root 21371/74729\nProcessing root 21381/74729\nProcessing root 21391/74729\nProcessing root 21401/74729\nProcessing root 21411/74729\nProcessing root 21421/74729\nProcessing root 21431/74729\nProcessing root 21441/74729\nProcessing root 21451/74729\nProcessing root 21461/74729\nProcessing root 21471/74729\nProcessing root 21481/74729\nProcessing root 21491/74729\nProcessing root 21501/74729\nProcessing root 21511/74729\nProcessing root 21521/74729\nProcessing root 21531/74729\nProcessing root 21541/74729\nProcessing root 21551/74729\nProcessing root 21561/74729\nProcessing root 21571/74729\nProcessing root 21581/74729\nProcessing root 21591/74729\nProcessing root 21601/74729\nProcessing root 21611/74729\nProcessing root 21621/74729\nProcessing root 21631/74729\nProcessing root 21641/74729\nProcessing root 21651/74729\nProcessing root 21661/74729\nProcessing root 21671/74729\nProcessing root 21681/74729\nProcessing root 21691/74729\nProcessing root 21701/74729\nProcessing root 21711/74729\nProcessing root 21721/74729\nProcessing root 21731/74729\nProcessing root 21741/74729\nProcessing root 21751/74729\nProcessing root 21761/74729\nProcessing root 21771/74729\nProcessing root 21781/74729\nProcessing root 21791/74729\nProcessing root 21801/74729\nProcessing root 21811/74729\nProcessing root 21821/74729\nProcessing root 21831/74729\nProcessing root 21841/74729\nProcessing root 21851/74729\nProcessing root 21861/74729\nProcessing root 21871/74729\nProcessing root 21881/74729\nProcessing root 21891/74729\nProcessing root 21901/74729\nProcessing root 21911/74729\nProcessing root 21921/74729\nProcessing root 21931/74729\nProcessing root 21941/74729\nProcessing root 21951/74729\nProcessing root 21961/74729\nProcessing root 21971/74729\nProcessing root 21981/74729\nProcessing root 21991/74729\nProcessing root 22001/74729\nProcessing root 22011/74729\nProcessing root 22021/74729\nProcessing root 22031/74729\nProcessing root 22041/74729\nProcessing root 22051/74729\nProcessing root 22061/74729\nProcessing root 22071/74729\nProcessing root 22081/74729\nProcessing root 22091/74729\nProcessing root 22101/74729\nProcessing root 22111/74729\nProcessing root 22121/74729\nProcessing root 22131/74729\nProcessing root 22141/74729\nProcessing root 22151/74729\nProcessing root 22161/74729\nProcessing root 22171/74729\nProcessing root 22181/74729\nProcessing root 22191/74729\nProcessing root 22201/74729\nProcessing root 22211/74729\nProcessing root 22221/74729\nProcessing root 22231/74729\nProcessing root 22241/74729\nProcessing root 22251/74729\nProcessing root 22261/74729\nProcessing root 22271/74729\nProcessing root 22281/74729\nProcessing root 22291/74729\nProcessing root 22301/74729\nProcessing root 22311/74729\nProcessing root 22321/74729\nProcessing root 22331/74729\nProcessing root 22341/74729\nProcessing root 22351/74729\nProcessing root 22361/74729\nProcessing root 22371/74729\nProcessing root 22381/74729\nProcessing root 22391/74729\nProcessing root 22401/74729\nProcessing root 22411/74729\nProcessing root 22421/74729\nProcessing root 22431/74729\nProcessing root 22441/74729\nProcessing root 22451/74729\nProcessing root 22461/74729\nProcessing root 22471/74729\nProcessing root 22481/74729\nProcessing root 22491/74729\nProcessing root 22501/74729\nProcessing root 22511/74729\nProcessing root 22521/74729\nProcessing root 22531/74729\nProcessing root 22541/74729\nProcessing root 22551/74729\nProcessing root 22561/74729\nProcessing root 22571/74729\nProcessing root 22581/74729\nProcessing root 22591/74729\nProcessing root 22601/74729\nProcessing root 22611/74729\nProcessing root 22621/74729\nProcessing root 22631/74729\nProcessing root 22641/74729\nProcessing root 22651/74729\nProcessing root 22661/74729\nProcessing root 22671/74729\nProcessing root 22681/74729\nProcessing root 22691/74729\nProcessing root 22701/74729\nProcessing root 22711/74729\nProcessing root 22721/74729\nProcessing root 22731/74729\nProcessing root 22741/74729\nProcessing root 22751/74729\nProcessing root 22761/74729\nProcessing root 22771/74729\nProcessing root 22781/74729\nProcessing root 22791/74729\nProcessing root 22801/74729\nProcessing root 22811/74729\nProcessing root 22821/74729\nProcessing root 22831/74729\nProcessing root 22841/74729\nProcessing root 22851/74729\nProcessing root 22861/74729\nProcessing root 22871/74729\nProcessing root 22881/74729\nProcessing root 22891/74729\nProcessing root 22901/74729\nProcessing root 22911/74729\nProcessing root 22921/74729\nProcessing root 22931/74729\nProcessing root 22941/74729\nProcessing root 22951/74729\nProcessing root 22961/74729\nProcessing root 22971/74729\nProcessing root 22981/74729\nProcessing root 22991/74729\nProcessing root 23001/74729\nProcessing root 23011/74729\nProcessing root 23021/74729\nProcessing root 23031/74729\nProcessing root 23041/74729\nProcessing root 23051/74729\nProcessing root 23061/74729\nProcessing root 23071/74729\nProcessing root 23081/74729\nProcessing root 23091/74729\nProcessing root 23101/74729\nProcessing root 23111/74729\nProcessing root 23121/74729\nProcessing root 23131/74729\nProcessing root 23141/74729\nProcessing root 23151/74729\nProcessing root 23161/74729\nProcessing root 23171/74729\nProcessing root 23181/74729\nProcessing root 23191/74729\nProcessing root 23201/74729\nProcessing root 23211/74729\nProcessing root 23221/74729\nProcessing root 23231/74729\nProcessing root 23241/74729\nProcessing root 23251/74729\nProcessing root 23261/74729\nProcessing root 23271/74729\nProcessing root 23281/74729\nProcessing root 23291/74729\nProcessing root 23301/74729\nProcessing root 23311/74729\nProcessing root 23321/74729\nProcessing root 23331/74729\nProcessing root 23341/74729\nProcessing root 23351/74729\nProcessing root 23361/74729\nProcessing root 23371/74729\nProcessing root 23381/74729\nProcessing root 23391/74729\nProcessing root 23401/74729\nProcessing root 23411/74729\nProcessing root 23421/74729\nProcessing root 23431/74729\nProcessing root 23441/74729\nProcessing root 23451/74729\nProcessing root 23461/74729\nProcessing root 23471/74729\nProcessing root 23481/74729\nProcessing root 23491/74729\nProcessing root 23501/74729\nProcessing root 23511/74729\nProcessing root 23521/74729\nProcessing root 23531/74729\nProcessing root 23541/74729\nProcessing root 23551/74729\nProcessing root 23561/74729\nProcessing root 23571/74729\nProcessing root 23581/74729\nProcessing root 23591/74729\nProcessing root 23601/74729\nProcessing root 23611/74729\nProcessing root 23621/74729\nProcessing root 23631/74729\nProcessing root 23641/74729\nProcessing root 23651/74729\nProcessing root 23661/74729\nProcessing root 23671/74729\nProcessing root 23681/74729\nProcessing root 23691/74729\nProcessing root 23701/74729\nProcessing root 23711/74729\nProcessing root 23721/74729\nProcessing root 23731/74729\nProcessing root 23741/74729\nProcessing root 23751/74729\nProcessing root 23761/74729\nProcessing root 23771/74729\nProcessing root 23781/74729\nProcessing root 23791/74729\nProcessing root 23801/74729\nProcessing root 23811/74729\nProcessing root 23821/74729\nProcessing root 23831/74729\nProcessing root 23841/74729\nProcessing root 23851/74729\nProcessing root 23861/74729\nProcessing root 23871/74729\nProcessing root 23881/74729\nProcessing root 23891/74729\nProcessing root 23901/74729\nProcessing root 23911/74729\nProcessing root 23921/74729\nProcessing root 23931/74729\nProcessing root 23941/74729\nProcessing root 23951/74729\nProcessing root 23961/74729\nProcessing root 23971/74729\nProcessing root 23981/74729\nProcessing root 23991/74729\nProcessing root 24001/74729\nProcessing root 24011/74729\nProcessing root 24021/74729\nProcessing root 24031/74729\nProcessing root 24041/74729\nProcessing root 24051/74729\nProcessing root 24061/74729\nProcessing root 24071/74729\nProcessing root 24081/74729\nProcessing root 24091/74729\nProcessing root 24101/74729\nProcessing root 24111/74729\nProcessing root 24121/74729\nProcessing root 24131/74729\nProcessing root 24141/74729\nProcessing root 24151/74729\nProcessing root 24161/74729\nProcessing root 24171/74729\nProcessing root 24181/74729\nProcessing root 24191/74729\nProcessing root 24201/74729\nProcessing root 24211/74729\nProcessing root 24221/74729\nProcessing root 24231/74729\nProcessing root 24241/74729\nProcessing root 24251/74729\nProcessing root 24261/74729\nProcessing root 24271/74729\nProcessing root 24281/74729\nProcessing root 24291/74729\nProcessing root 24301/74729\nProcessing root 24311/74729\nProcessing root 24321/74729\nProcessing root 24331/74729\nProcessing root 24341/74729\nProcessing root 24351/74729\nProcessing root 24361/74729\nProcessing root 24371/74729\nProcessing root 24381/74729\nProcessing root 24391/74729\nProcessing root 24401/74729\nProcessing root 24411/74729\nProcessing root 24421/74729\nProcessing root 24431/74729\nProcessing root 24441/74729\nProcessing root 24451/74729\nProcessing root 24461/74729\nProcessing root 24471/74729\nProcessing root 24481/74729\nProcessing root 24491/74729\nProcessing root 24501/74729\nProcessing root 24511/74729\nProcessing root 24521/74729\nProcessing root 24531/74729\nProcessing root 24541/74729\nProcessing root 24551/74729\nProcessing root 24561/74729\nProcessing root 24571/74729\nProcessing root 24581/74729\nProcessing root 24591/74729\nProcessing root 24601/74729\nProcessing root 24611/74729\nProcessing root 24621/74729\nProcessing root 24631/74729\nProcessing root 24641/74729\nProcessing root 24651/74729\nProcessing root 24661/74729\nProcessing root 24671/74729\nProcessing root 24681/74729\nProcessing root 24691/74729\nProcessing root 24701/74729\nProcessing root 24711/74729\nProcessing root 24721/74729\nProcessing root 24731/74729\nProcessing root 24741/74729\nProcessing root 24751/74729\nProcessing root 24761/74729\nProcessing root 24771/74729\nProcessing root 24781/74729\nProcessing root 24791/74729\nProcessing root 24801/74729\nProcessing root 24811/74729\nProcessing root 24821/74729\nProcessing root 24831/74729\nProcessing root 24841/74729\nProcessing root 24851/74729\nProcessing root 24861/74729\nProcessing root 24871/74729\nProcessing root 24881/74729\nProcessing root 24891/74729\nProcessing root 24901/74729\nProcessing root 24911/74729\nProcessing root 24921/74729\nProcessing root 24931/74729\nProcessing root 24941/74729\nProcessing root 24951/74729\nProcessing root 24961/74729\nProcessing root 24971/74729\nProcessing root 24981/74729\nProcessing root 24991/74729\nProcessing root 25001/74729\nProcessing root 25011/74729\nProcessing root 25021/74729\nProcessing root 25031/74729\nProcessing root 25041/74729\nProcessing root 25051/74729\nProcessing root 25061/74729\nProcessing root 25071/74729\nProcessing root 25081/74729\nProcessing root 25091/74729\nProcessing root 25101/74729\nProcessing root 25111/74729\nProcessing root 25121/74729\nProcessing root 25131/74729\nProcessing root 25141/74729\nProcessing root 25151/74729\nProcessing root 25161/74729\nProcessing root 25171/74729\nProcessing root 25181/74729\nProcessing root 25191/74729\nProcessing root 25201/74729\nProcessing root 25211/74729\nProcessing root 25221/74729\nProcessing root 25231/74729\nProcessing root 25241/74729\nProcessing root 25251/74729\nProcessing root 25261/74729\nProcessing root 25271/74729\nProcessing root 25281/74729\nProcessing root 25291/74729\nProcessing root 25301/74729\nProcessing root 25311/74729\nProcessing root 25321/74729\nProcessing root 25331/74729\nProcessing root 25341/74729\nProcessing root 25351/74729\nProcessing root 25361/74729\nProcessing root 25371/74729\nProcessing root 25381/74729\nProcessing root 25391/74729\nProcessing root 25401/74729\nProcessing root 25411/74729\nProcessing root 25421/74729\nProcessing root 25431/74729\nProcessing root 25441/74729\nProcessing root 25451/74729\nProcessing root 25461/74729\nProcessing root 25471/74729\nProcessing root 25481/74729\nProcessing root 25491/74729\nProcessing root 25501/74729\nProcessing root 25511/74729\nProcessing root 25521/74729\nProcessing root 25531/74729\nProcessing root 25541/74729\nProcessing root 25551/74729\nProcessing root 25561/74729\nProcessing root 25571/74729\nProcessing root 25581/74729\nProcessing root 25591/74729\nProcessing root 25601/74729\nProcessing root 25611/74729\nProcessing root 25621/74729\nProcessing root 25631/74729\nProcessing root 25641/74729\nProcessing root 25651/74729\nProcessing root 25661/74729\nProcessing root 25671/74729\nProcessing root 25681/74729\nProcessing root 25691/74729\nProcessing root 25701/74729\nProcessing root 25711/74729\nProcessing root 25721/74729\nProcessing root 25731/74729\nProcessing root 25741/74729\nProcessing root 25751/74729\nProcessing root 25761/74729\nProcessing root 25771/74729\nProcessing root 25781/74729\nProcessing root 25791/74729\nProcessing root 25801/74729\nProcessing root 25811/74729\nProcessing root 25821/74729\nProcessing root 25831/74729\nProcessing root 25841/74729\nProcessing root 25851/74729\nProcessing root 25861/74729\nProcessing root 25871/74729\nProcessing root 25881/74729\nProcessing root 25891/74729\nProcessing root 25901/74729\nProcessing root 25911/74729\nProcessing root 25921/74729\nProcessing root 25931/74729\nProcessing root 25941/74729\nProcessing root 25951/74729\nProcessing root 25961/74729\nProcessing root 25971/74729\nProcessing root 25981/74729\nProcessing root 25991/74729\nProcessing root 26001/74729\nProcessing root 26011/74729\nProcessing root 26021/74729\nProcessing root 26031/74729\nProcessing root 26041/74729\nProcessing root 26051/74729\nProcessing root 26061/74729\nProcessing root 26071/74729\nProcessing root 26081/74729\nProcessing root 26091/74729\nProcessing root 26101/74729\nProcessing root 26111/74729\nProcessing root 26121/74729\nProcessing root 26131/74729\nProcessing root 26141/74729\nProcessing root 26151/74729\nProcessing root 26161/74729\nProcessing root 26171/74729\nProcessing root 26181/74729\nProcessing root 26191/74729\nProcessing root 26201/74729\nProcessing root 26211/74729\nProcessing root 26221/74729\nProcessing root 26231/74729\nProcessing root 26241/74729\nProcessing root 26251/74729\nProcessing root 26261/74729\nProcessing root 26271/74729\nProcessing root 26281/74729\nProcessing root 26291/74729\nProcessing root 26301/74729\nProcessing root 26311/74729\nProcessing root 26321/74729\nProcessing root 26331/74729\nProcessing root 26341/74729\nProcessing root 26351/74729\nProcessing root 26361/74729\nProcessing root 26371/74729\nProcessing root 26381/74729\nProcessing root 26391/74729\nProcessing root 26401/74729\nProcessing root 26411/74729\nProcessing root 26421/74729\nProcessing root 26431/74729\nProcessing root 26441/74729\nProcessing root 26451/74729\nProcessing root 26461/74729\nProcessing root 26471/74729\nProcessing root 26481/74729\nProcessing root 26491/74729\nProcessing root 26501/74729\nProcessing root 26511/74729\nProcessing root 26521/74729\nProcessing root 26531/74729\nProcessing root 26541/74729\nProcessing root 26551/74729\nProcessing root 26561/74729\nProcessing root 26571/74729\nProcessing root 26581/74729\nProcessing root 26591/74729\nProcessing root 26601/74729\nProcessing root 26611/74729\nProcessing root 26621/74729\nProcessing root 26631/74729\nProcessing root 26641/74729\nProcessing root 26651/74729\nProcessing root 26661/74729\nProcessing root 26671/74729\nProcessing root 26681/74729\nProcessing root 26691/74729\nProcessing root 26701/74729\nProcessing root 26711/74729\nProcessing root 26721/74729\nProcessing root 26731/74729\nProcessing root 26741/74729\nProcessing root 26751/74729\nProcessing root 26761/74729\nProcessing root 26771/74729\nProcessing root 26781/74729\nProcessing root 26791/74729\nProcessing root 26801/74729\nProcessing root 26811/74729\nProcessing root 26821/74729\nProcessing root 26831/74729\nProcessing root 26841/74729\nProcessing root 26851/74729\nProcessing root 26861/74729\nProcessing root 26871/74729\nProcessing root 26881/74729\nProcessing root 26891/74729\nProcessing root 26901/74729\nProcessing root 26911/74729\nProcessing root 26921/74729\nProcessing root 26931/74729\nProcessing root 26941/74729\nProcessing root 26951/74729\nProcessing root 26961/74729\nProcessing root 26971/74729\nProcessing root 26981/74729\nProcessing root 26991/74729\nProcessing root 27001/74729\nProcessing root 27011/74729\nProcessing root 27021/74729\nProcessing root 27031/74729\nProcessing root 27041/74729\nProcessing root 27051/74729\nProcessing root 27061/74729\nProcessing root 27071/74729\nProcessing root 27081/74729\nProcessing root 27091/74729\nProcessing root 27101/74729\nProcessing root 27111/74729\nProcessing root 27121/74729\nProcessing root 27131/74729\nProcessing root 27141/74729\nProcessing root 27151/74729\nProcessing root 27161/74729\nProcessing root 27171/74729\nProcessing root 27181/74729\nProcessing root 27191/74729\nProcessing root 27201/74729\nProcessing root 27211/74729\nProcessing root 27221/74729\nProcessing root 27231/74729\nProcessing root 27241/74729\nProcessing root 27251/74729\nProcessing root 27261/74729\nProcessing root 27271/74729\nProcessing root 27281/74729\nProcessing root 27291/74729\nProcessing root 27301/74729\nProcessing root 27311/74729\nProcessing root 27321/74729\nProcessing root 27331/74729\nProcessing root 27341/74729\nProcessing root 27351/74729\nProcessing root 27361/74729\nProcessing root 27371/74729\nProcessing root 27381/74729\nProcessing root 27391/74729\nProcessing root 27401/74729\nProcessing root 27411/74729\nProcessing root 27421/74729\nProcessing root 27431/74729\nProcessing root 27441/74729\nProcessing root 27451/74729\nProcessing root 27461/74729\nProcessing root 27471/74729\nProcessing root 27481/74729\nProcessing root 27491/74729\nProcessing root 27501/74729\nProcessing root 27511/74729\nProcessing root 27521/74729\nProcessing root 27531/74729\nProcessing root 27541/74729\nProcessing root 27551/74729\nProcessing root 27561/74729\nProcessing root 27571/74729\nProcessing root 27581/74729\nProcessing root 27591/74729\nProcessing root 27601/74729\nProcessing root 27611/74729\nProcessing root 27621/74729\nProcessing root 27631/74729\nProcessing root 27641/74729\nProcessing root 27651/74729\nProcessing root 27661/74729\nProcessing root 27671/74729\nProcessing root 27681/74729\nProcessing root 27691/74729\nProcessing root 27701/74729\nProcessing root 27711/74729\nProcessing root 27721/74729\nProcessing root 27731/74729\nProcessing root 27741/74729\nProcessing root 27751/74729\nProcessing root 27761/74729\nProcessing root 27771/74729\nProcessing root 27781/74729\nProcessing root 27791/74729\nProcessing root 27801/74729\nProcessing root 27811/74729\nProcessing root 27821/74729\nProcessing root 27831/74729\nProcessing root 27841/74729\nProcessing root 27851/74729\nProcessing root 27861/74729\nProcessing root 27871/74729\nProcessing root 27881/74729\nProcessing root 27891/74729\nProcessing root 27901/74729\nProcessing root 27911/74729\nProcessing root 27921/74729\nProcessing root 27931/74729\nProcessing root 27941/74729\nProcessing root 27951/74729\nProcessing root 27961/74729\nProcessing root 27971/74729\nProcessing root 27981/74729\nProcessing root 27991/74729\nProcessing root 28001/74729\nProcessing root 28011/74729\nProcessing root 28021/74729\nProcessing root 28031/74729\nProcessing root 28041/74729\nProcessing root 28051/74729\nProcessing root 28061/74729\nProcessing root 28071/74729\nProcessing root 28081/74729\nProcessing root 28091/74729\nProcessing root 28101/74729\nProcessing root 28111/74729\nProcessing root 28121/74729\nProcessing root 28131/74729\nProcessing root 28141/74729\nProcessing root 28151/74729\nProcessing root 28161/74729\nProcessing root 28171/74729\nProcessing root 28181/74729\nProcessing root 28191/74729\nProcessing root 28201/74729\nProcessing root 28211/74729\nProcessing root 28221/74729\nProcessing root 28231/74729\nProcessing root 28241/74729\nProcessing root 28251/74729\nProcessing root 28261/74729\nProcessing root 28271/74729\nProcessing root 28281/74729\nProcessing root 28291/74729\nProcessing root 28301/74729\nProcessing root 28311/74729\nProcessing root 28321/74729\nProcessing root 28331/74729\nProcessing root 28341/74729\nProcessing root 28351/74729\nProcessing root 28361/74729\nProcessing root 28371/74729\nProcessing root 28381/74729\nProcessing root 28391/74729\nProcessing root 28401/74729\nProcessing root 28411/74729\nProcessing root 28421/74729\nProcessing root 28431/74729\nProcessing root 28441/74729\nProcessing root 28451/74729\nProcessing root 28461/74729\nProcessing root 28471/74729\nProcessing root 28481/74729\nProcessing root 28491/74729\nProcessing root 28501/74729\nProcessing root 28511/74729\nProcessing root 28521/74729\nProcessing root 28531/74729\nProcessing root 28541/74729\nProcessing root 28551/74729\nProcessing root 28561/74729\nProcessing root 28571/74729\nProcessing root 28581/74729\nProcessing root 28591/74729\nProcessing root 28601/74729\nProcessing root 28611/74729\nProcessing root 28621/74729\nProcessing root 28631/74729\nProcessing root 28641/74729\nProcessing root 28651/74729\nProcessing root 28661/74729\nProcessing root 28671/74729\nProcessing root 28681/74729\nProcessing root 28691/74729\nProcessing root 28701/74729\nProcessing root 28711/74729\nProcessing root 28721/74729\nProcessing root 28731/74729\nProcessing root 28741/74729\nProcessing root 28751/74729\nProcessing root 28761/74729\nProcessing root 28771/74729\nProcessing root 28781/74729\nProcessing root 28791/74729\nProcessing root 28801/74729\nProcessing root 28811/74729\nProcessing root 28821/74729\nProcessing root 28831/74729\nProcessing root 28841/74729\nProcessing root 28851/74729\nProcessing root 28861/74729\nProcessing root 28871/74729\nProcessing root 28881/74729\nProcessing root 28891/74729\nProcessing root 28901/74729\nProcessing root 28911/74729\nProcessing root 28921/74729\nProcessing root 28931/74729\nProcessing root 28941/74729\nProcessing root 28951/74729\nProcessing root 28961/74729\nProcessing root 28971/74729\nProcessing root 28981/74729\nProcessing root 28991/74729\nProcessing root 29001/74729\nProcessing root 29011/74729\nProcessing root 29021/74729\nProcessing root 29031/74729\nProcessing root 29041/74729\nProcessing root 29051/74729\nProcessing root 29061/74729\nProcessing root 29071/74729\nProcessing root 29081/74729\nProcessing root 29091/74729\nProcessing root 29101/74729\nProcessing root 29111/74729\nProcessing root 29121/74729\nProcessing root 29131/74729\nProcessing root 29141/74729\nProcessing root 29151/74729\nProcessing root 29161/74729\nProcessing root 29171/74729\nProcessing root 29181/74729\nProcessing root 29191/74729\nProcessing root 29201/74729\nProcessing root 29211/74729\nProcessing root 29221/74729\nProcessing root 29231/74729\nProcessing root 29241/74729\nProcessing root 29251/74729\nProcessing root 29261/74729\nProcessing root 29271/74729\nProcessing root 29281/74729\nProcessing root 29291/74729\nProcessing root 29301/74729\nProcessing root 29311/74729\nProcessing root 29321/74729\nProcessing root 29331/74729\nProcessing root 29341/74729\nProcessing root 29351/74729\nProcessing root 29361/74729\nProcessing root 29371/74729\nProcessing root 29381/74729\nProcessing root 29391/74729\nProcessing root 29401/74729\nProcessing root 29411/74729\nProcessing root 29421/74729\nProcessing root 29431/74729\nProcessing root 29441/74729\nProcessing root 29451/74729\nProcessing root 29461/74729\nProcessing root 29471/74729\nProcessing root 29481/74729\nProcessing root 29491/74729\nProcessing root 29501/74729\nProcessing root 29511/74729\nProcessing root 29521/74729\nProcessing root 29531/74729\nProcessing root 29541/74729\nProcessing root 29551/74729\nProcessing root 29561/74729\nProcessing root 29571/74729\nProcessing root 29581/74729\nProcessing root 29591/74729\nProcessing root 29601/74729\nProcessing root 29611/74729\nProcessing root 29621/74729\nProcessing root 29631/74729\nProcessing root 29641/74729\nProcessing root 29651/74729\nProcessing root 29661/74729\nProcessing root 29671/74729\nProcessing root 29681/74729\nProcessing root 29691/74729\nProcessing root 29701/74729\nProcessing root 29711/74729\nProcessing root 29721/74729\nProcessing root 29731/74729\nProcessing root 29741/74729\nProcessing root 29751/74729\nProcessing root 29761/74729\nProcessing root 29771/74729\nProcessing root 29781/74729\nProcessing root 29791/74729\nProcessing root 29801/74729\nProcessing root 29811/74729\nProcessing root 29821/74729\nProcessing root 29831/74729\nProcessing root 29841/74729\nProcessing root 29851/74729\nProcessing root 29861/74729\nProcessing root 29871/74729\nProcessing root 29881/74729\nProcessing root 29891/74729\nProcessing root 29901/74729\nProcessing root 29911/74729\nProcessing root 29921/74729\nProcessing root 29931/74729\nProcessing root 29941/74729\nProcessing root 29951/74729\nProcessing root 29961/74729\nProcessing root 29971/74729\nProcessing root 29981/74729\nProcessing root 29991/74729\nProcessing root 30001/74729\nProcessing root 30011/74729\nProcessing root 30021/74729\nProcessing root 30031/74729\nProcessing root 30041/74729\nProcessing root 30051/74729\nProcessing root 30061/74729\nProcessing root 30071/74729\nProcessing root 30081/74729\nProcessing root 30091/74729\nProcessing root 30101/74729\nProcessing root 30111/74729\nProcessing root 30121/74729\nProcessing root 30131/74729\nProcessing root 30141/74729\nProcessing root 30151/74729\nProcessing root 30161/74729\nProcessing root 30171/74729\nProcessing root 30181/74729\nProcessing root 30191/74729\nProcessing root 30201/74729\nProcessing root 30211/74729\nProcessing root 30221/74729\nProcessing root 30231/74729\nProcessing root 30241/74729\nProcessing root 30251/74729\nProcessing root 30261/74729\nProcessing root 30271/74729\nProcessing root 30281/74729\nProcessing root 30291/74729\nProcessing root 30301/74729\nProcessing root 30311/74729\nProcessing root 30321/74729\nProcessing root 30331/74729\nProcessing root 30341/74729\nProcessing root 30351/74729\nProcessing root 30361/74729\nProcessing root 30371/74729\nProcessing root 30381/74729\nProcessing root 30391/74729\nProcessing root 30401/74729\nProcessing root 30411/74729\nProcessing root 30421/74729\nProcessing root 30431/74729\nProcessing root 30441/74729\nProcessing root 30451/74729\nProcessing root 30461/74729\nProcessing root 30471/74729\nProcessing root 30481/74729\nProcessing root 30491/74729\nProcessing root 30501/74729\nProcessing root 30511/74729\nProcessing root 30521/74729\nProcessing root 30531/74729\nProcessing root 30541/74729\nProcessing root 30551/74729\nProcessing root 30561/74729\nProcessing root 30571/74729\nProcessing root 30581/74729\nProcessing root 30591/74729\nProcessing root 30601/74729\nProcessing root 30611/74729\nProcessing root 30621/74729\nProcessing root 30631/74729\nProcessing root 30641/74729\nProcessing root 30651/74729\nProcessing root 30661/74729\nProcessing root 30671/74729\nProcessing root 30681/74729\nProcessing root 30691/74729\nProcessing root 30701/74729\nProcessing root 30711/74729\nProcessing root 30721/74729\nProcessing root 30731/74729\nProcessing root 30741/74729\nProcessing root 30751/74729\nProcessing root 30761/74729\nProcessing root 30771/74729\nProcessing root 30781/74729\nProcessing root 30791/74729\nProcessing root 30801/74729\nProcessing root 30811/74729\nProcessing root 30821/74729\nProcessing root 30831/74729\nProcessing root 30841/74729\nProcessing root 30851/74729\nProcessing root 30861/74729\nProcessing root 30871/74729\nProcessing root 30881/74729\nProcessing root 30891/74729\nProcessing root 30901/74729\nProcessing root 30911/74729\nProcessing root 30921/74729\nProcessing root 30931/74729\nProcessing root 30941/74729\nProcessing root 30951/74729\nProcessing root 30961/74729\nProcessing root 30971/74729\nProcessing root 30981/74729\nProcessing root 30991/74729\nProcessing root 31001/74729\nProcessing root 31011/74729\nProcessing root 31021/74729\nProcessing root 31031/74729\nProcessing root 31041/74729\nProcessing root 31051/74729\nProcessing root 31061/74729\nProcessing root 31071/74729\nProcessing root 31081/74729\nProcessing root 31091/74729\nProcessing root 31101/74729\nProcessing root 31111/74729\nProcessing root 31121/74729\nProcessing root 31131/74729\nProcessing root 31141/74729\nProcessing root 31151/74729\nProcessing root 31161/74729\nProcessing root 31171/74729\nProcessing root 31181/74729\nProcessing root 31191/74729\nProcessing root 31201/74729\nProcessing root 31211/74729\nProcessing root 31221/74729\nProcessing root 31231/74729\nProcessing root 31241/74729\nProcessing root 31251/74729\nProcessing root 31261/74729\nProcessing root 31271/74729\nProcessing root 31281/74729\nProcessing root 31291/74729\nProcessing root 31301/74729\nProcessing root 31311/74729\nProcessing root 31321/74729\nProcessing root 31331/74729\nProcessing root 31341/74729\nProcessing root 31351/74729\nProcessing root 31361/74729\nProcessing root 31371/74729\nProcessing root 31381/74729\nProcessing root 31391/74729\nProcessing root 31401/74729\nProcessing root 31411/74729\nProcessing root 31421/74729\nProcessing root 31431/74729\nProcessing root 31441/74729\nProcessing root 31451/74729\nProcessing root 31461/74729\nProcessing root 31471/74729\nProcessing root 31481/74729\nProcessing root 31491/74729\nProcessing root 31501/74729\nProcessing root 31511/74729\nProcessing root 31521/74729\nProcessing root 31531/74729\nProcessing root 31541/74729\nProcessing root 31551/74729\nProcessing root 31561/74729\nProcessing root 31571/74729\nProcessing root 31581/74729\nProcessing root 31591/74729\nProcessing root 31601/74729\nProcessing root 31611/74729\nProcessing root 31621/74729\nProcessing root 31631/74729\nProcessing root 31641/74729\nProcessing root 31651/74729\nProcessing root 31661/74729\nProcessing root 31671/74729\nProcessing root 31681/74729\nProcessing root 31691/74729\nProcessing root 31701/74729\nProcessing root 31711/74729\nProcessing root 31721/74729\nProcessing root 31731/74729\nProcessing root 31741/74729\nProcessing root 31751/74729\nProcessing root 31761/74729\nProcessing root 31771/74729\nProcessing root 31781/74729\nProcessing root 31791/74729\nProcessing root 31801/74729\nProcessing root 31811/74729\nProcessing root 31821/74729\nProcessing root 31831/74729\nProcessing root 31841/74729\nProcessing root 31851/74729\nProcessing root 31861/74729\nProcessing root 31871/74729\nProcessing root 31881/74729\nProcessing root 31891/74729\nProcessing root 31901/74729\nProcessing root 31911/74729\nProcessing root 31921/74729\nProcessing root 31931/74729\nProcessing root 31941/74729\nProcessing root 31951/74729\nProcessing root 31961/74729\nProcessing root 31971/74729\nProcessing root 31981/74729\nProcessing root 31991/74729\nProcessing root 32001/74729\nProcessing root 32011/74729\nProcessing root 32021/74729\nProcessing root 32031/74729\nProcessing root 32041/74729\nProcessing root 32051/74729\nProcessing root 32061/74729\nProcessing root 32071/74729\nProcessing root 32081/74729\nProcessing root 32091/74729\nProcessing root 32101/74729\nProcessing root 32111/74729\nProcessing root 32121/74729\nProcessing root 32131/74729\nProcessing root 32141/74729\nProcessing root 32151/74729\nProcessing root 32161/74729\nProcessing root 32171/74729\nProcessing root 32181/74729\nProcessing root 32191/74729\nProcessing root 32201/74729\nProcessing root 32211/74729\nProcessing root 32221/74729\nProcessing root 32231/74729\nProcessing root 32241/74729\nProcessing root 32251/74729\nProcessing root 32261/74729\nProcessing root 32271/74729\nProcessing root 32281/74729\nProcessing root 32291/74729\nProcessing root 32301/74729\nProcessing root 32311/74729\nProcessing root 32321/74729\nProcessing root 32331/74729\nProcessing root 32341/74729\nProcessing root 32351/74729\nProcessing root 32361/74729\nProcessing root 32371/74729\nProcessing root 32381/74729\nProcessing root 32391/74729\nProcessing root 32401/74729\nProcessing root 32411/74729\nProcessing root 32421/74729\nProcessing root 32431/74729\nProcessing root 32441/74729\nProcessing root 32451/74729\nProcessing root 32461/74729\nProcessing root 32471/74729\nProcessing root 32481/74729\nProcessing root 32491/74729\nProcessing root 32501/74729\nProcessing root 32511/74729\nProcessing root 32521/74729\nProcessing root 32531/74729\nProcessing root 32541/74729\nProcessing root 32551/74729\nProcessing root 32561/74729\nProcessing root 32571/74729\nProcessing root 32581/74729\nProcessing root 32591/74729\nProcessing root 32601/74729\nProcessing root 32611/74729\nProcessing root 32621/74729\nProcessing root 32631/74729\nProcessing root 32641/74729\nProcessing root 32651/74729\nProcessing root 32661/74729\nProcessing root 32671/74729\nProcessing root 32681/74729\nProcessing root 32691/74729\nProcessing root 32701/74729\nProcessing root 32711/74729\nProcessing root 32721/74729\nProcessing root 32731/74729\nProcessing root 32741/74729\nProcessing root 32751/74729\nProcessing root 32761/74729\nProcessing root 32771/74729\nProcessing root 32781/74729\nProcessing root 32791/74729\nProcessing root 32801/74729\nProcessing root 32811/74729\nProcessing root 32821/74729\nProcessing root 32831/74729\nProcessing root 32841/74729\nProcessing root 32851/74729\nProcessing root 32861/74729\nProcessing root 32871/74729\nProcessing root 32881/74729\nProcessing root 32891/74729\nProcessing root 32901/74729\nProcessing root 32911/74729\nProcessing root 32921/74729\nProcessing root 32931/74729\nProcessing root 32941/74729\nProcessing root 32951/74729\nProcessing root 32961/74729\nProcessing root 32971/74729\nProcessing root 32981/74729\nProcessing root 32991/74729\nProcessing root 33001/74729\nProcessing root 33011/74729\nProcessing root 33021/74729\nProcessing root 33031/74729\nProcessing root 33041/74729\nProcessing root 33051/74729\nProcessing root 33061/74729\nProcessing root 33071/74729\nProcessing root 33081/74729\nProcessing root 33091/74729\nProcessing root 33101/74729\nProcessing root 33111/74729\nProcessing root 33121/74729\nProcessing root 33131/74729\nProcessing root 33141/74729\nProcessing root 33151/74729\nProcessing root 33161/74729\nProcessing root 33171/74729\nProcessing root 33181/74729\nProcessing root 33191/74729\nProcessing root 33201/74729\nProcessing root 33211/74729\nProcessing root 33221/74729\nProcessing root 33231/74729\nProcessing root 33241/74729\nProcessing root 33251/74729\nProcessing root 33261/74729\nProcessing root 33271/74729\nProcessing root 33281/74729\nProcessing root 33291/74729\nProcessing root 33301/74729\nProcessing root 33311/74729\nProcessing root 33321/74729\nProcessing root 33331/74729\nProcessing root 33341/74729\nProcessing root 33351/74729\nProcessing root 33361/74729\nProcessing root 33371/74729\nProcessing root 33381/74729\nProcessing root 33391/74729\nProcessing root 33401/74729\nProcessing root 33411/74729\nProcessing root 33421/74729\nProcessing root 33431/74729\nProcessing root 33441/74729\nProcessing root 33451/74729\nProcessing root 33461/74729\nProcessing root 33471/74729\nProcessing root 33481/74729\nProcessing root 33491/74729\nProcessing root 33501/74729\nProcessing root 33511/74729\nProcessing root 33521/74729\nProcessing root 33531/74729\nProcessing root 33541/74729\nProcessing root 33551/74729\nProcessing root 33561/74729\nProcessing root 33571/74729\nProcessing root 33581/74729\nProcessing root 33591/74729\nProcessing root 33601/74729\nProcessing root 33611/74729\nProcessing root 33621/74729\nProcessing root 33631/74729\nProcessing root 33641/74729\nProcessing root 33651/74729\nProcessing root 33661/74729\nProcessing root 33671/74729\nProcessing root 33681/74729\nProcessing root 33691/74729\nProcessing root 33701/74729\nProcessing root 33711/74729\nProcessing root 33721/74729\nProcessing root 33731/74729\nProcessing root 33741/74729\nProcessing root 33751/74729\nProcessing root 33761/74729\nProcessing root 33771/74729\nProcessing root 33781/74729\nProcessing root 33791/74729\nProcessing root 33801/74729\nProcessing root 33811/74729\nProcessing root 33821/74729\nProcessing root 33831/74729\nProcessing root 33841/74729\nProcessing root 33851/74729\nProcessing root 33861/74729\nProcessing root 33871/74729\nProcessing root 33881/74729\nProcessing root 33891/74729\nProcessing root 33901/74729\nProcessing root 33911/74729\nProcessing root 33921/74729\nProcessing root 33931/74729\nProcessing root 33941/74729\nProcessing root 33951/74729\nProcessing root 33961/74729\nProcessing root 33971/74729\nProcessing root 33981/74729\nProcessing root 33991/74729\nProcessing root 34001/74729\nProcessing root 34011/74729\nProcessing root 34021/74729\nProcessing root 34031/74729\nProcessing root 34041/74729\nProcessing root 34051/74729\nProcessing root 34061/74729\nProcessing root 34071/74729\nProcessing root 34081/74729\nProcessing root 34091/74729\nProcessing root 34101/74729\nProcessing root 34111/74729\nProcessing root 34121/74729\nProcessing root 34131/74729\nProcessing root 34141/74729\nProcessing root 34151/74729\nProcessing root 34161/74729\nProcessing root 34171/74729\nProcessing root 34181/74729\nProcessing root 34191/74729\nProcessing root 34201/74729\nProcessing root 34211/74729\nProcessing root 34221/74729\nProcessing root 34231/74729\nProcessing root 34241/74729\nProcessing root 34251/74729\nProcessing root 34261/74729\nProcessing root 34271/74729\nProcessing root 34281/74729\nProcessing root 34291/74729\nProcessing root 34301/74729\nProcessing root 34311/74729\nProcessing root 34321/74729\nProcessing root 34331/74729\nProcessing root 34341/74729\nProcessing root 34351/74729\nProcessing root 34361/74729\nProcessing root 34371/74729\nProcessing root 34381/74729\nProcessing root 34391/74729\nProcessing root 34401/74729\nProcessing root 34411/74729\nProcessing root 34421/74729\nProcessing root 34431/74729\nProcessing root 34441/74729\nProcessing root 34451/74729\nProcessing root 34461/74729\nProcessing root 34471/74729\nProcessing root 34481/74729\nProcessing root 34491/74729\nProcessing root 34501/74729\nProcessing root 34511/74729\nProcessing root 34521/74729\nProcessing root 34531/74729\nProcessing root 34541/74729\nProcessing root 34551/74729\nProcessing root 34561/74729\nProcessing root 34571/74729\nProcessing root 34581/74729\nProcessing root 34591/74729\nProcessing root 34601/74729\nProcessing root 34611/74729\nProcessing root 34621/74729\nProcessing root 34631/74729\nProcessing root 34641/74729\nProcessing root 34651/74729\nProcessing root 34661/74729\nProcessing root 34671/74729\nProcessing root 34681/74729\nProcessing root 34691/74729\nProcessing root 34701/74729\nProcessing root 34711/74729\nProcessing root 34721/74729\nProcessing root 34731/74729\nProcessing root 34741/74729\nProcessing root 34751/74729\nProcessing root 34761/74729\nProcessing root 34771/74729\nProcessing root 34781/74729\nProcessing root 34791/74729\nProcessing root 34801/74729\nProcessing root 34811/74729\nProcessing root 34821/74729\nProcessing root 34831/74729\nProcessing root 34841/74729\nProcessing root 34851/74729\nProcessing root 34861/74729\nProcessing root 34871/74729\nProcessing root 34881/74729\nProcessing root 34891/74729\nProcessing root 34901/74729\nProcessing root 34911/74729\nProcessing root 34921/74729\nProcessing root 34931/74729\nProcessing root 34941/74729\nProcessing root 34951/74729\nProcessing root 34961/74729\nProcessing root 34971/74729\nProcessing root 34981/74729\nProcessing root 34991/74729\nProcessing root 35001/74729\nProcessing root 35011/74729\nProcessing root 35021/74729\nProcessing root 35031/74729\nProcessing root 35041/74729\nProcessing root 35051/74729\nProcessing root 35061/74729\nProcessing root 35071/74729\nProcessing root 35081/74729\nProcessing root 35091/74729\nProcessing root 35101/74729\nProcessing root 35111/74729\nProcessing root 35121/74729\nProcessing root 35131/74729\nProcessing root 35141/74729\nProcessing root 35151/74729\nProcessing root 35161/74729\nProcessing root 35171/74729\nProcessing root 35181/74729\nProcessing root 35191/74729\nProcessing root 35201/74729\nProcessing root 35211/74729\nProcessing root 35221/74729\nProcessing root 35231/74729\nProcessing root 35241/74729\nProcessing root 35251/74729\nProcessing root 35261/74729\nProcessing root 35271/74729\nProcessing root 35281/74729\nProcessing root 35291/74729\nProcessing root 35301/74729\nProcessing root 35311/74729\nProcessing root 35321/74729\nProcessing root 35331/74729\nProcessing root 35341/74729\nProcessing root 35351/74729\nProcessing root 35361/74729\nProcessing root 35371/74729\nProcessing root 35381/74729\nProcessing root 35391/74729\nProcessing root 35401/74729\nProcessing root 35411/74729\nProcessing root 35421/74729\nProcessing root 35431/74729\nProcessing root 35441/74729\nProcessing root 35451/74729\nProcessing root 35461/74729\nProcessing root 35471/74729\nProcessing root 35481/74729\nProcessing root 35491/74729\nProcessing root 35501/74729\nProcessing root 35511/74729\nProcessing root 35521/74729\nProcessing root 35531/74729\nProcessing root 35541/74729\nProcessing root 35551/74729\nProcessing root 35561/74729\nProcessing root 35571/74729\nProcessing root 35581/74729\nProcessing root 35591/74729\nProcessing root 35601/74729\nProcessing root 35611/74729\nProcessing root 35621/74729\nProcessing root 35631/74729\nProcessing root 35641/74729\nProcessing root 35651/74729\nProcessing root 35661/74729\nProcessing root 35671/74729\nProcessing root 35681/74729\nProcessing root 35691/74729\nProcessing root 35701/74729\nProcessing root 35711/74729\nProcessing root 35721/74729\nProcessing root 35731/74729\nProcessing root 35741/74729\nProcessing root 35751/74729\nProcessing root 35761/74729\nProcessing root 35771/74729\nProcessing root 35781/74729\nProcessing root 35791/74729\nProcessing root 35801/74729\nProcessing root 35811/74729\nProcessing root 35821/74729\nProcessing root 35831/74729\nProcessing root 35841/74729\nProcessing root 35851/74729\nProcessing root 35861/74729\nProcessing root 35871/74729\nProcessing root 35881/74729\nProcessing root 35891/74729\nProcessing root 35901/74729\nProcessing root 35911/74729\nProcessing root 35921/74729\nProcessing root 35931/74729\nProcessing root 35941/74729\nProcessing root 35951/74729\nProcessing root 35961/74729\nProcessing root 35971/74729\nProcessing root 35981/74729\nProcessing root 35991/74729\nProcessing root 36001/74729\nProcessing root 36011/74729\nProcessing root 36021/74729\nProcessing root 36031/74729\nProcessing root 36041/74729\nProcessing root 36051/74729\nProcessing root 36061/74729\nProcessing root 36071/74729\nProcessing root 36081/74729\nProcessing root 36091/74729\nProcessing root 36101/74729\nProcessing root 36111/74729\nProcessing root 36121/74729\nProcessing root 36131/74729\nProcessing root 36141/74729\nProcessing root 36151/74729\nProcessing root 36161/74729\nProcessing root 36171/74729\nProcessing root 36181/74729\nProcessing root 36191/74729\nProcessing root 36201/74729\nProcessing root 36211/74729\nProcessing root 36221/74729\nProcessing root 36231/74729\nProcessing root 36241/74729\nProcessing root 36251/74729\nProcessing root 36261/74729\nProcessing root 36271/74729\nProcessing root 36281/74729\nProcessing root 36291/74729\nProcessing root 36301/74729\nProcessing root 36311/74729\nProcessing root 36321/74729\nProcessing root 36331/74729\nProcessing root 36341/74729\nProcessing root 36351/74729\nProcessing root 36361/74729\nProcessing root 36371/74729\nProcessing root 36381/74729\nProcessing root 36391/74729\nProcessing root 36401/74729\nProcessing root 36411/74729\nProcessing root 36421/74729\nProcessing root 36431/74729\nProcessing root 36441/74729\nProcessing root 36451/74729\nProcessing root 36461/74729\nProcessing root 36471/74729\nProcessing root 36481/74729\nProcessing root 36491/74729\nProcessing root 36501/74729\nProcessing root 36511/74729\nProcessing root 36521/74729\nProcessing root 36531/74729\nProcessing root 36541/74729\nProcessing root 36551/74729\nProcessing root 36561/74729\nProcessing root 36571/74729\nProcessing root 36581/74729\nProcessing root 36591/74729\nProcessing root 36601/74729\nProcessing root 36611/74729\nProcessing root 36621/74729\nProcessing root 36631/74729\nProcessing root 36641/74729\nProcessing root 36651/74729\nProcessing root 36661/74729\nProcessing root 36671/74729\nProcessing root 36681/74729\nProcessing root 36691/74729\nProcessing root 36701/74729\nProcessing root 36711/74729\nProcessing root 36721/74729\nProcessing root 36731/74729\nProcessing root 36741/74729\nProcessing root 36751/74729\nProcessing root 36761/74729\nProcessing root 36771/74729\nProcessing root 36781/74729\nProcessing root 36791/74729\nProcessing root 36801/74729\nProcessing root 36811/74729\nProcessing root 36821/74729\nProcessing root 36831/74729\nProcessing root 36841/74729\nProcessing root 36851/74729\nProcessing root 36861/74729\nProcessing root 36871/74729\nProcessing root 36881/74729\nProcessing root 36891/74729\nProcessing root 36901/74729\nProcessing root 36911/74729\nProcessing root 36921/74729\nProcessing root 36931/74729\nProcessing root 36941/74729\nProcessing root 36951/74729\nProcessing root 36961/74729\nProcessing root 36971/74729\nProcessing root 36981/74729\nProcessing root 36991/74729\nProcessing root 37001/74729\nProcessing root 37011/74729\nProcessing root 37021/74729\nProcessing root 37031/74729\nProcessing root 37041/74729\nProcessing root 37051/74729\nProcessing root 37061/74729\nProcessing root 37071/74729\nProcessing root 37081/74729\nProcessing root 37091/74729\nProcessing root 37101/74729\nProcessing root 37111/74729\nProcessing root 37121/74729\nProcessing root 37131/74729\nProcessing root 37141/74729\nProcessing root 37151/74729\nProcessing root 37161/74729\nProcessing root 37171/74729\nProcessing root 37181/74729\nProcessing root 37191/74729\nProcessing root 37201/74729\nProcessing root 37211/74729\nProcessing root 37221/74729\nProcessing root 37231/74729\nProcessing root 37241/74729\nProcessing root 37251/74729\nProcessing root 37261/74729\nProcessing root 37271/74729\nProcessing root 37281/74729\nProcessing root 37291/74729\nProcessing root 37301/74729\nProcessing root 37311/74729\nProcessing root 37321/74729\nProcessing root 37331/74729\nProcessing root 37341/74729\nProcessing root 37351/74729\nProcessing root 37361/74729\nProcessing root 37371/74729\nProcessing root 37381/74729\nProcessing root 37391/74729\nProcessing root 37401/74729\nProcessing root 37411/74729\nProcessing root 37421/74729\nProcessing root 37431/74729\nProcessing root 37441/74729\nProcessing root 37451/74729\nProcessing root 37461/74729\nProcessing root 37471/74729\nProcessing root 37481/74729\nProcessing root 37491/74729\nProcessing root 37501/74729\nProcessing root 37511/74729\nProcessing root 37521/74729\nProcessing root 37531/74729\nProcessing root 37541/74729\nProcessing root 37551/74729\nProcessing root 37561/74729\nProcessing root 37571/74729\nProcessing root 37581/74729\nProcessing root 37591/74729\nProcessing root 37601/74729\nProcessing root 37611/74729\nProcessing root 37621/74729\nProcessing root 37631/74729\nProcessing root 37641/74729\nProcessing root 37651/74729\nProcessing root 37661/74729\nProcessing root 37671/74729\nProcessing root 37681/74729\nProcessing root 37691/74729\nProcessing root 37701/74729\nProcessing root 37711/74729\nProcessing root 37721/74729\nProcessing root 37731/74729\nProcessing root 37741/74729\nProcessing root 37751/74729\nProcessing root 37761/74729\nProcessing root 37771/74729\nProcessing root 37781/74729\nProcessing root 37791/74729\nProcessing root 37801/74729\nProcessing root 37811/74729\nProcessing root 37821/74729\nProcessing root 37831/74729\nProcessing root 37841/74729\nProcessing root 37851/74729\nProcessing root 37861/74729\nProcessing root 37871/74729\nProcessing root 37881/74729\nProcessing root 37891/74729\nProcessing root 37901/74729\nProcessing root 37911/74729\nProcessing root 37921/74729\nProcessing root 37931/74729\nProcessing root 37941/74729\nProcessing root 37951/74729\nProcessing root 37961/74729\nProcessing root 37971/74729\nProcessing root 37981/74729\nProcessing root 37991/74729\nProcessing root 38001/74729\nProcessing root 38011/74729\nProcessing root 38021/74729\nProcessing root 38031/74729\nProcessing root 38041/74729\nProcessing root 38051/74729\nProcessing root 38061/74729\nProcessing root 38071/74729\nProcessing root 38081/74729\nProcessing root 38091/74729\nProcessing root 38101/74729\nProcessing root 38111/74729\nProcessing root 38121/74729\nProcessing root 38131/74729\nProcessing root 38141/74729\nProcessing root 38151/74729\nProcessing root 38161/74729\nProcessing root 38171/74729\nProcessing root 38181/74729\nProcessing root 38191/74729\nProcessing root 38201/74729\nProcessing root 38211/74729\nProcessing root 38221/74729\nProcessing root 38231/74729\nProcessing root 38241/74729\nProcessing root 38251/74729\nProcessing root 38261/74729\nProcessing root 38271/74729\nProcessing root 38281/74729\nProcessing root 38291/74729\nProcessing root 38301/74729\nProcessing root 38311/74729\nProcessing root 38321/74729\nProcessing root 38331/74729\nProcessing root 38341/74729\nProcessing root 38351/74729\nProcessing root 38361/74729\nProcessing root 38371/74729\nProcessing root 38381/74729\nProcessing root 38391/74729\nProcessing root 38401/74729\nProcessing root 38411/74729\nProcessing root 38421/74729\nProcessing root 38431/74729\nProcessing root 38441/74729\nProcessing root 38451/74729\nProcessing root 38461/74729\nProcessing root 38471/74729\nProcessing root 38481/74729\nProcessing root 38491/74729\nProcessing root 38501/74729\nProcessing root 38511/74729\nProcessing root 38521/74729\nProcessing root 38531/74729\nProcessing root 38541/74729\nProcessing root 38551/74729\nProcessing root 38561/74729\nProcessing root 38571/74729\nProcessing root 38581/74729\nProcessing root 38591/74729\nProcessing root 38601/74729\nProcessing root 38611/74729\nProcessing root 38621/74729\nProcessing root 38631/74729\nProcessing root 38641/74729\nProcessing root 38651/74729\nProcessing root 38661/74729\nProcessing root 38671/74729\nProcessing root 38681/74729\nProcessing root 38691/74729\nProcessing root 38701/74729\nProcessing root 38711/74729\nProcessing root 38721/74729\nProcessing root 38731/74729\nProcessing root 38741/74729\nProcessing root 38751/74729\nProcessing root 38761/74729\nProcessing root 38771/74729\nProcessing root 38781/74729\nProcessing root 38791/74729\nProcessing root 38801/74729\nProcessing root 38811/74729\nProcessing root 38821/74729\nProcessing root 38831/74729\nProcessing root 38841/74729\nProcessing root 38851/74729\nProcessing root 38861/74729\nProcessing root 38871/74729\nProcessing root 38881/74729\nProcessing root 38891/74729\nProcessing root 38901/74729\nProcessing root 38911/74729\nProcessing root 38921/74729\nProcessing root 38931/74729\nProcessing root 38941/74729\nProcessing root 38951/74729\nProcessing root 38961/74729\nProcessing root 38971/74729\nProcessing root 38981/74729\nProcessing root 38991/74729\nProcessing root 39001/74729\nProcessing root 39011/74729\nProcessing root 39021/74729\nProcessing root 39031/74729\nProcessing root 39041/74729\nProcessing root 39051/74729\nProcessing root 39061/74729\nProcessing root 39071/74729\nProcessing root 39081/74729\nProcessing root 39091/74729\nProcessing root 39101/74729\nProcessing root 39111/74729\nProcessing root 39121/74729\nProcessing root 39131/74729\nProcessing root 39141/74729\nProcessing root 39151/74729\nProcessing root 39161/74729\nProcessing root 39171/74729\nProcessing root 39181/74729\nProcessing root 39191/74729\nProcessing root 39201/74729\nProcessing root 39211/74729\nProcessing root 39221/74729\nProcessing root 39231/74729\nProcessing root 39241/74729\nProcessing root 39251/74729\nProcessing root 39261/74729\nProcessing root 39271/74729\nProcessing root 39281/74729\nProcessing root 39291/74729\nProcessing root 39301/74729\nProcessing root 39311/74729\nProcessing root 39321/74729\nProcessing root 39331/74729\nProcessing root 39341/74729\nProcessing root 39351/74729\nProcessing root 39361/74729\nProcessing root 39371/74729\nProcessing root 39381/74729\nProcessing root 39391/74729\nProcessing root 39401/74729\nProcessing root 39411/74729\nProcessing root 39421/74729\nProcessing root 39431/74729\nProcessing root 39441/74729\nProcessing root 39451/74729\nProcessing root 39461/74729\nProcessing root 39471/74729\nProcessing root 39481/74729\nProcessing root 39491/74729\nProcessing root 39501/74729\nProcessing root 39511/74729\nProcessing root 39521/74729\nProcessing root 39531/74729\nProcessing root 39541/74729\nProcessing root 39551/74729\nProcessing root 39561/74729\nProcessing root 39571/74729\nProcessing root 39581/74729\nProcessing root 39591/74729\nProcessing root 39601/74729\nProcessing root 39611/74729\nProcessing root 39621/74729\nProcessing root 39631/74729\nProcessing root 39641/74729\nProcessing root 39651/74729\nProcessing root 39661/74729\nProcessing root 39671/74729\nProcessing root 39681/74729\nProcessing root 39691/74729\nProcessing root 39701/74729\nProcessing root 39711/74729\nProcessing root 39721/74729\nProcessing root 39731/74729\nProcessing root 39741/74729\nProcessing root 39751/74729\nProcessing root 39761/74729\nProcessing root 39771/74729\nProcessing root 39781/74729\nProcessing root 39791/74729\nProcessing root 39801/74729\nProcessing root 39811/74729\nProcessing root 39821/74729\nProcessing root 39831/74729\nProcessing root 39841/74729\nProcessing root 39851/74729\nProcessing root 39861/74729\nProcessing root 39871/74729\nProcessing root 39881/74729\nProcessing root 39891/74729\nProcessing root 39901/74729\nProcessing root 39911/74729\nProcessing root 39921/74729\nProcessing root 39931/74729\nProcessing root 39941/74729\nProcessing root 39951/74729\nProcessing root 39961/74729\nProcessing root 39971/74729\nProcessing root 39981/74729\nProcessing root 39991/74729\nProcessing root 40001/74729\nProcessing root 40011/74729\nProcessing root 40021/74729\nProcessing root 40031/74729\nProcessing root 40041/74729\nProcessing root 40051/74729\nProcessing root 40061/74729\nProcessing root 40071/74729\nProcessing root 40081/74729\nProcessing root 40091/74729\nProcessing root 40101/74729\nProcessing root 40111/74729\nProcessing root 40121/74729\nProcessing root 40131/74729\nProcessing root 40141/74729\nProcessing root 40151/74729\nProcessing root 40161/74729\nProcessing root 40171/74729\nProcessing root 40181/74729\nProcessing root 40191/74729\nProcessing root 40201/74729\nProcessing root 40211/74729\nProcessing root 40221/74729\nProcessing root 40231/74729\nProcessing root 40241/74729\nProcessing root 40251/74729\nProcessing root 40261/74729\nProcessing root 40271/74729\nProcessing root 40281/74729\nProcessing root 40291/74729\nProcessing root 40301/74729\nProcessing root 40311/74729\nProcessing root 40321/74729\nProcessing root 40331/74729\nProcessing root 40341/74729\nProcessing root 40351/74729\nProcessing root 40361/74729\nProcessing root 40371/74729\nProcessing root 40381/74729\nProcessing root 40391/74729\nProcessing root 40401/74729\nProcessing root 40411/74729\nProcessing root 40421/74729\nProcessing root 40431/74729\nProcessing root 40441/74729\nProcessing root 40451/74729\nProcessing root 40461/74729\nProcessing root 40471/74729\nProcessing root 40481/74729\nProcessing root 40491/74729\nProcessing root 40501/74729\nProcessing root 40511/74729\nProcessing root 40521/74729\nProcessing root 40531/74729\nProcessing root 40541/74729\nProcessing root 40551/74729\nProcessing root 40561/74729\nProcessing root 40571/74729\nProcessing root 40581/74729\nProcessing root 40591/74729\nProcessing root 40601/74729\nProcessing root 40611/74729\nProcessing root 40621/74729\nProcessing root 40631/74729\nProcessing root 40641/74729\nProcessing root 40651/74729\nProcessing root 40661/74729\nProcessing root 40671/74729\nProcessing root 40681/74729\nProcessing root 40691/74729\nProcessing root 40701/74729\nProcessing root 40711/74729\nProcessing root 40721/74729\nProcessing root 40731/74729\nProcessing root 40741/74729\nProcessing root 40751/74729\nProcessing root 40761/74729\nProcessing root 40771/74729\nProcessing root 40781/74729\nProcessing root 40791/74729\nProcessing root 40801/74729\nProcessing root 40811/74729\nProcessing root 40821/74729\nProcessing root 40831/74729\nProcessing root 40841/74729\nProcessing root 40851/74729\nProcessing root 40861/74729\nProcessing root 40871/74729\nProcessing root 40881/74729\nProcessing root 40891/74729\nProcessing root 40901/74729\nProcessing root 40911/74729\nProcessing root 40921/74729\nProcessing root 40931/74729\nProcessing root 40941/74729\nProcessing root 40951/74729\nProcessing root 40961/74729\nProcessing root 40971/74729\nProcessing root 40981/74729\nProcessing root 40991/74729\nProcessing root 41001/74729\nProcessing root 41011/74729\nProcessing root 41021/74729\nProcessing root 41031/74729\nProcessing root 41041/74729\nProcessing root 41051/74729\nProcessing root 41061/74729\nProcessing root 41071/74729\nProcessing root 41081/74729\nProcessing root 41091/74729\nProcessing root 41101/74729\nProcessing root 41111/74729\nProcessing root 41121/74729\nProcessing root 41131/74729\nProcessing root 41141/74729\nProcessing root 41151/74729\nProcessing root 41161/74729\nProcessing root 41171/74729\nProcessing root 41181/74729\nProcessing root 41191/74729\nProcessing root 41201/74729\nProcessing root 41211/74729\nProcessing root 41221/74729\nProcessing root 41231/74729\nProcessing root 41241/74729\nProcessing root 41251/74729\nProcessing root 41261/74729\nProcessing root 41271/74729\nProcessing root 41281/74729\nProcessing root 41291/74729\nProcessing root 41301/74729\nProcessing root 41311/74729\nProcessing root 41321/74729\nProcessing root 41331/74729\nProcessing root 41341/74729\nProcessing root 41351/74729\nProcessing root 41361/74729\nProcessing root 41371/74729\nProcessing root 41381/74729\nProcessing root 41391/74729\nProcessing root 41401/74729\nProcessing root 41411/74729\nProcessing root 41421/74729\nProcessing root 41431/74729\nProcessing root 41441/74729\nProcessing root 41451/74729\nProcessing root 41461/74729\nProcessing root 41471/74729\nProcessing root 41481/74729\nProcessing root 41491/74729\nProcessing root 41501/74729\nProcessing root 41511/74729\nProcessing root 41521/74729\nProcessing root 41531/74729\nProcessing root 41541/74729\nProcessing root 41551/74729\nProcessing root 41561/74729\nProcessing root 41571/74729\nProcessing root 41581/74729\nProcessing root 41591/74729\nProcessing root 41601/74729\nProcessing root 41611/74729\nProcessing root 41621/74729\nProcessing root 41631/74729\nProcessing root 41641/74729\nProcessing root 41651/74729\nProcessing root 41661/74729\nProcessing root 41671/74729\nProcessing root 41681/74729\nProcessing root 41691/74729\nProcessing root 41701/74729\nProcessing root 41711/74729\nProcessing root 41721/74729\nProcessing root 41731/74729\nProcessing root 41741/74729\nProcessing root 41751/74729\nProcessing root 41761/74729\nProcessing root 41771/74729\nProcessing root 41781/74729\nProcessing root 41791/74729\nProcessing root 41801/74729\nProcessing root 41811/74729\nProcessing root 41821/74729\nProcessing root 41831/74729\nProcessing root 41841/74729\nProcessing root 41851/74729\nProcessing root 41861/74729\nProcessing root 41871/74729\nProcessing root 41881/74729\nProcessing root 41891/74729\nProcessing root 41901/74729\nProcessing root 41911/74729\nProcessing root 41921/74729\nProcessing root 41931/74729\nProcessing root 41941/74729\nProcessing root 41951/74729\nProcessing root 41961/74729\nProcessing root 41971/74729\nProcessing root 41981/74729\nProcessing root 41991/74729\nProcessing root 42001/74729\nProcessing root 42011/74729\nProcessing root 42021/74729\nProcessing root 42031/74729\nProcessing root 42041/74729\nProcessing root 42051/74729\nProcessing root 42061/74729\nProcessing root 42071/74729\nProcessing root 42081/74729\nProcessing root 42091/74729\nProcessing root 42101/74729\nProcessing root 42111/74729\nProcessing root 42121/74729\nProcessing root 42131/74729\nProcessing root 42141/74729\nProcessing root 42151/74729\nProcessing root 42161/74729\nProcessing root 42171/74729\nProcessing root 42181/74729\nProcessing root 42191/74729\nProcessing root 42201/74729\nProcessing root 42211/74729\nProcessing root 42221/74729\nProcessing root 42231/74729\nProcessing root 42241/74729\nProcessing root 42251/74729\nProcessing root 42261/74729\nProcessing root 42271/74729\nProcessing root 42281/74729\nProcessing root 42291/74729\nProcessing root 42301/74729\nProcessing root 42311/74729\nProcessing root 42321/74729\nProcessing root 42331/74729\nProcessing root 42341/74729\nProcessing root 42351/74729\nProcessing root 42361/74729\nProcessing root 42371/74729\nProcessing root 42381/74729\nProcessing root 42391/74729\nProcessing root 42401/74729\nProcessing root 42411/74729\nProcessing root 42421/74729\nProcessing root 42431/74729\nProcessing root 42441/74729\nProcessing root 42451/74729\nProcessing root 42461/74729\nProcessing root 42471/74729\nProcessing root 42481/74729\nProcessing root 42491/74729\nProcessing root 42501/74729\nProcessing root 42511/74729\nProcessing root 42521/74729\nProcessing root 42531/74729\nProcessing root 42541/74729\nProcessing root 42551/74729\nProcessing root 42561/74729\nProcessing root 42571/74729\nProcessing root 42581/74729\nProcessing root 42591/74729\nProcessing root 42601/74729\nProcessing root 42611/74729\nProcessing root 42621/74729\nProcessing root 42631/74729\nProcessing root 42641/74729\nProcessing root 42651/74729\nProcessing root 42661/74729\nProcessing root 42671/74729\nProcessing root 42681/74729\nProcessing root 42691/74729\nProcessing root 42701/74729\nProcessing root 42711/74729\nProcessing root 42721/74729\nProcessing root 42731/74729\nProcessing root 42741/74729\nProcessing root 42751/74729\nProcessing root 42761/74729\nProcessing root 42771/74729\nProcessing root 42781/74729\nProcessing root 42791/74729\nProcessing root 42801/74729\nProcessing root 42811/74729\nProcessing root 42821/74729\nProcessing root 42831/74729\nProcessing root 42841/74729\nProcessing root 42851/74729\nProcessing root 42861/74729\nProcessing root 42871/74729\nProcessing root 42881/74729\nProcessing root 42891/74729\nProcessing root 42901/74729\nProcessing root 42911/74729\nProcessing root 42921/74729\nProcessing root 42931/74729\nProcessing root 42941/74729\nProcessing root 42951/74729\nProcessing root 42961/74729\nProcessing root 42971/74729\nProcessing root 42981/74729\nProcessing root 42991/74729\nProcessing root 43001/74729\nProcessing root 43011/74729\nProcessing root 43021/74729\nProcessing root 43031/74729\nProcessing root 43041/74729\nProcessing root 43051/74729\nProcessing root 43061/74729\nProcessing root 43071/74729\nProcessing root 43081/74729\nProcessing root 43091/74729\nProcessing root 43101/74729\nProcessing root 43111/74729\nProcessing root 43121/74729\nProcessing root 43131/74729\nProcessing root 43141/74729\nProcessing root 43151/74729\nProcessing root 43161/74729\nProcessing root 43171/74729\nProcessing root 43181/74729\nProcessing root 43191/74729\nProcessing root 43201/74729\nProcessing root 43211/74729\nProcessing root 43221/74729\nProcessing root 43231/74729\nProcessing root 43241/74729\nProcessing root 43251/74729\nProcessing root 43261/74729\nProcessing root 43271/74729\nProcessing root 43281/74729\nProcessing root 43291/74729\nProcessing root 43301/74729\nProcessing root 43311/74729\nProcessing root 43321/74729\nProcessing root 43331/74729\nProcessing root 43341/74729\nProcessing root 43351/74729\nProcessing root 43361/74729\nProcessing root 43371/74729\nProcessing root 43381/74729\nProcessing root 43391/74729\nProcessing root 43401/74729\nProcessing root 43411/74729\nProcessing root 43421/74729\nProcessing root 43431/74729\nProcessing root 43441/74729\nProcessing root 43451/74729\nProcessing root 43461/74729\nProcessing root 43471/74729\nProcessing root 43481/74729\nProcessing root 43491/74729\nProcessing root 43501/74729\nProcessing root 43511/74729\nProcessing root 43521/74729\nProcessing root 43531/74729\nProcessing root 43541/74729\nProcessing root 43551/74729\nProcessing root 43561/74729\nProcessing root 43571/74729\nProcessing root 43581/74729\nProcessing root 43591/74729\nProcessing root 43601/74729\nProcessing root 43611/74729\nProcessing root 43621/74729\nProcessing root 43631/74729\nProcessing root 43641/74729\nProcessing root 43651/74729\nProcessing root 43661/74729\nProcessing root 43671/74729\nProcessing root 43681/74729\nProcessing root 43691/74729\nProcessing root 43701/74729\nProcessing root 43711/74729\nProcessing root 43721/74729\nProcessing root 43731/74729\nProcessing root 43741/74729\nProcessing root 43751/74729\nProcessing root 43761/74729\nProcessing root 43771/74729\nProcessing root 43781/74729\nProcessing root 43791/74729\nProcessing root 43801/74729\nProcessing root 43811/74729\nProcessing root 43821/74729\nProcessing root 43831/74729\nProcessing root 43841/74729\nProcessing root 43851/74729\nProcessing root 43861/74729\nProcessing root 43871/74729\nProcessing root 43881/74729\nProcessing root 43891/74729\nProcessing root 43901/74729\nProcessing root 43911/74729\nProcessing root 43921/74729\nProcessing root 43931/74729\nProcessing root 43941/74729\nProcessing root 43951/74729\nProcessing root 43961/74729\nProcessing root 43971/74729\nProcessing root 43981/74729\nProcessing root 43991/74729\nProcessing root 44001/74729\nProcessing root 44011/74729\nProcessing root 44021/74729\nProcessing root 44031/74729\nProcessing root 44041/74729\nProcessing root 44051/74729\nProcessing root 44061/74729\nProcessing root 44071/74729\nProcessing root 44081/74729\nProcessing root 44091/74729\nProcessing root 44101/74729\nProcessing root 44111/74729\nProcessing root 44121/74729\nProcessing root 44131/74729\nProcessing root 44141/74729\nProcessing root 44151/74729\nProcessing root 44161/74729\nProcessing root 44171/74729\nProcessing root 44181/74729\nProcessing root 44191/74729\nProcessing root 44201/74729\nProcessing root 44211/74729\nProcessing root 44221/74729\nProcessing root 44231/74729\nProcessing root 44241/74729\nProcessing root 44251/74729\nProcessing root 44261/74729\nProcessing root 44271/74729\nProcessing root 44281/74729\nProcessing root 44291/74729\nProcessing root 44301/74729\nProcessing root 44311/74729\nProcessing root 44321/74729\nProcessing root 44331/74729\nProcessing root 44341/74729\nProcessing root 44351/74729\nProcessing root 44361/74729\nProcessing root 44371/74729\nProcessing root 44381/74729\nProcessing root 44391/74729\nProcessing root 44401/74729\nProcessing root 44411/74729\nProcessing root 44421/74729\nProcessing root 44431/74729\nProcessing root 44441/74729\nProcessing root 44451/74729\nProcessing root 44461/74729\nProcessing root 44471/74729\nProcessing root 44481/74729\nProcessing root 44491/74729\nProcessing root 44501/74729\nProcessing root 44511/74729\nProcessing root 44521/74729\nProcessing root 44531/74729\nProcessing root 44541/74729\nProcessing root 44551/74729\nProcessing root 44561/74729\nProcessing root 44571/74729\nProcessing root 44581/74729\nProcessing root 44591/74729\nProcessing root 44601/74729\nProcessing root 44611/74729\nProcessing root 44621/74729\nProcessing root 44631/74729\nProcessing root 44641/74729\nProcessing root 44651/74729\nProcessing root 44661/74729\nProcessing root 44671/74729\nProcessing root 44681/74729\nProcessing root 44691/74729\nProcessing root 44701/74729\nProcessing root 44711/74729\nProcessing root 44721/74729\nProcessing root 44731/74729\nProcessing root 44741/74729\nProcessing root 44751/74729\nProcessing root 44761/74729\nProcessing root 44771/74729\nProcessing root 44781/74729\nProcessing root 44791/74729\nProcessing root 44801/74729\nProcessing root 44811/74729\nProcessing root 44821/74729\nProcessing root 44831/74729\nProcessing root 44841/74729\nProcessing root 44851/74729\nProcessing root 44861/74729\nProcessing root 44871/74729\nProcessing root 44881/74729\nProcessing root 44891/74729\nProcessing root 44901/74729\nProcessing root 44911/74729\nProcessing root 44921/74729\nProcessing root 44931/74729\nProcessing root 44941/74729\nProcessing root 44951/74729\nProcessing root 44961/74729\nProcessing root 44971/74729\nProcessing root 44981/74729\nProcessing root 44991/74729\nProcessing root 45001/74729\nProcessing root 45011/74729\nProcessing root 45021/74729\nProcessing root 45031/74729\nProcessing root 45041/74729\nProcessing root 45051/74729\nProcessing root 45061/74729\nProcessing root 45071/74729\nProcessing root 45081/74729\nProcessing root 45091/74729\nProcessing root 45101/74729\nProcessing root 45111/74729\nProcessing root 45121/74729\nProcessing root 45131/74729\nProcessing root 45141/74729\nProcessing root 45151/74729\nProcessing root 45161/74729\nProcessing root 45171/74729\nProcessing root 45181/74729\nProcessing root 45191/74729\nProcessing root 45201/74729\nProcessing root 45211/74729\nProcessing root 45221/74729\nProcessing root 45231/74729\nProcessing root 45241/74729\nProcessing root 45251/74729\nProcessing root 45261/74729\nProcessing root 45271/74729\nProcessing root 45281/74729\nProcessing root 45291/74729\nProcessing root 45301/74729\nProcessing root 45311/74729\nProcessing root 45321/74729\nProcessing root 45331/74729\nProcessing root 45341/74729\nProcessing root 45351/74729\nProcessing root 45361/74729\nProcessing root 45371/74729\nProcessing root 45381/74729\nProcessing root 45391/74729\nProcessing root 45401/74729\nProcessing root 45411/74729\nProcessing root 45421/74729\nProcessing root 45431/74729\nProcessing root 45441/74729\nProcessing root 45451/74729\nProcessing root 45461/74729\nProcessing root 45471/74729\nProcessing root 45481/74729\nProcessing root 45491/74729\nProcessing root 45501/74729\nProcessing root 45511/74729\nProcessing root 45521/74729\nProcessing root 45531/74729\nProcessing root 45541/74729\nProcessing root 45551/74729\nProcessing root 45561/74729\nProcessing root 45571/74729\nProcessing root 45581/74729\nProcessing root 45591/74729\nProcessing root 45601/74729\nProcessing root 45611/74729\nProcessing root 45621/74729\nProcessing root 45631/74729\nProcessing root 45641/74729\nProcessing root 45651/74729\nProcessing root 45661/74729\nProcessing root 45671/74729\nProcessing root 45681/74729\nProcessing root 45691/74729\nProcessing root 45701/74729\nProcessing root 45711/74729\nProcessing root 45721/74729\nProcessing root 45731/74729\nProcessing root 45741/74729\nProcessing root 45751/74729\nProcessing root 45761/74729\nProcessing root 45771/74729\nProcessing root 45781/74729\nProcessing root 45791/74729\nProcessing root 45801/74729\nProcessing root 45811/74729\nProcessing root 45821/74729\nProcessing root 45831/74729\nProcessing root 45841/74729\nProcessing root 45851/74729\nProcessing root 45861/74729\nProcessing root 45871/74729\nProcessing root 45881/74729\nProcessing root 45891/74729\nProcessing root 45901/74729\nProcessing root 45911/74729\nProcessing root 45921/74729\nProcessing root 45931/74729\nProcessing root 45941/74729\nProcessing root 45951/74729\nProcessing root 45961/74729\nProcessing root 45971/74729\nProcessing root 45981/74729\nProcessing root 45991/74729\nProcessing root 46001/74729\nProcessing root 46011/74729\nProcessing root 46021/74729\nProcessing root 46031/74729\nProcessing root 46041/74729\nProcessing root 46051/74729\nProcessing root 46061/74729\nProcessing root 46071/74729\nProcessing root 46081/74729\nProcessing root 46091/74729\nProcessing root 46101/74729\nProcessing root 46111/74729\nProcessing root 46121/74729\nProcessing root 46131/74729\nProcessing root 46141/74729\nProcessing root 46151/74729\nProcessing root 46161/74729\nProcessing root 46171/74729\nProcessing root 46181/74729\nProcessing root 46191/74729\nProcessing root 46201/74729\nProcessing root 46211/74729\nProcessing root 46221/74729\nProcessing root 46231/74729\nProcessing root 46241/74729\nProcessing root 46251/74729\nProcessing root 46261/74729\nProcessing root 46271/74729\nProcessing root 46281/74729\nProcessing root 46291/74729\nProcessing root 46301/74729\nProcessing root 46311/74729\nProcessing root 46321/74729\nProcessing root 46331/74729\nProcessing root 46341/74729\nProcessing root 46351/74729\nProcessing root 46361/74729\nProcessing root 46371/74729\nProcessing root 46381/74729\nProcessing root 46391/74729\nProcessing root 46401/74729\nProcessing root 46411/74729\nProcessing root 46421/74729\nProcessing root 46431/74729\nProcessing root 46441/74729\nProcessing root 46451/74729\nProcessing root 46461/74729\nProcessing root 46471/74729\nProcessing root 46481/74729\nProcessing root 46491/74729\nProcessing root 46501/74729\nProcessing root 46511/74729\nProcessing root 46521/74729\nProcessing root 46531/74729\nProcessing root 46541/74729\nProcessing root 46551/74729\nProcessing root 46561/74729\nProcessing root 46571/74729\nProcessing root 46581/74729\nProcessing root 46591/74729\nProcessing root 46601/74729\nProcessing root 46611/74729\nProcessing root 46621/74729\nProcessing root 46631/74729\nProcessing root 46641/74729\nProcessing root 46651/74729\nProcessing root 46661/74729\nProcessing root 46671/74729\nProcessing root 46681/74729\nProcessing root 46691/74729\nProcessing root 46701/74729\nProcessing root 46711/74729\nProcessing root 46721/74729\nProcessing root 46731/74729\nProcessing root 46741/74729\nProcessing root 46751/74729\nProcessing root 46761/74729\nProcessing root 46771/74729\nProcessing root 46781/74729\nProcessing root 46791/74729\nProcessing root 46801/74729\nProcessing root 46811/74729\nProcessing root 46821/74729\nProcessing root 46831/74729\nProcessing root 46841/74729\nProcessing root 46851/74729\nProcessing root 46861/74729\nProcessing root 46871/74729\nProcessing root 46881/74729\nProcessing root 46891/74729\nProcessing root 46901/74729\nProcessing root 46911/74729\nProcessing root 46921/74729\nProcessing root 46931/74729\nProcessing root 46941/74729\nProcessing root 46951/74729\nProcessing root 46961/74729\nProcessing root 46971/74729\nProcessing root 46981/74729\nProcessing root 46991/74729\nProcessing root 47001/74729\nProcessing root 47011/74729\nProcessing root 47021/74729\nProcessing root 47031/74729\nProcessing root 47041/74729\nProcessing root 47051/74729\nProcessing root 47061/74729\nProcessing root 47071/74729\nProcessing root 47081/74729\nProcessing root 47091/74729\nProcessing root 47101/74729\nProcessing root 47111/74729\nProcessing root 47121/74729\nProcessing root 47131/74729\nProcessing root 47141/74729\nProcessing root 47151/74729\nProcessing root 47161/74729\nProcessing root 47171/74729\nProcessing root 47181/74729\nProcessing root 47191/74729\nProcessing root 47201/74729\nProcessing root 47211/74729\nProcessing root 47221/74729\nProcessing root 47231/74729\nProcessing root 47241/74729\nProcessing root 47251/74729\nProcessing root 47261/74729\nProcessing root 47271/74729\nProcessing root 47281/74729\nProcessing root 47291/74729\nProcessing root 47301/74729\nProcessing root 47311/74729\nProcessing root 47321/74729\nProcessing root 47331/74729\nProcessing root 47341/74729\nProcessing root 47351/74729\nProcessing root 47361/74729\nProcessing root 47371/74729\nProcessing root 47381/74729\nProcessing root 47391/74729\nProcessing root 47401/74729\nProcessing root 47411/74729\nProcessing root 47421/74729\nProcessing root 47431/74729\nProcessing root 47441/74729\nProcessing root 47451/74729\nProcessing root 47461/74729\nProcessing root 47471/74729\nProcessing root 47481/74729\nProcessing root 47491/74729\nProcessing root 47501/74729\nProcessing root 47511/74729\nProcessing root 47521/74729\nProcessing root 47531/74729\nProcessing root 47541/74729\nProcessing root 47551/74729\nProcessing root 47561/74729\nProcessing root 47571/74729\nProcessing root 47581/74729\nProcessing root 47591/74729\nProcessing root 47601/74729\nProcessing root 47611/74729\nProcessing root 47621/74729\nProcessing root 47631/74729\nProcessing root 47641/74729\nProcessing root 47651/74729\nProcessing root 47661/74729\nProcessing root 47671/74729\nProcessing root 47681/74729\nProcessing root 47691/74729\nProcessing root 47701/74729\nProcessing root 47711/74729\nProcessing root 47721/74729\nProcessing root 47731/74729\nProcessing root 47741/74729\nProcessing root 47751/74729\nProcessing root 47761/74729\nProcessing root 47771/74729\nProcessing root 47781/74729\nProcessing root 47791/74729\nProcessing root 47801/74729\nProcessing root 47811/74729\nProcessing root 47821/74729\nProcessing root 47831/74729\nProcessing root 47841/74729\nProcessing root 47851/74729\nProcessing root 47861/74729\nProcessing root 47871/74729\nProcessing root 47881/74729\nProcessing root 47891/74729\nProcessing root 47901/74729\nProcessing root 47911/74729\nProcessing root 47921/74729\nProcessing root 47931/74729\nProcessing root 47941/74729\nProcessing root 47951/74729\nProcessing root 47961/74729\nProcessing root 47971/74729\nProcessing root 47981/74729\nProcessing root 47991/74729\nProcessing root 48001/74729\nProcessing root 48011/74729\nProcessing root 48021/74729\nProcessing root 48031/74729\nProcessing root 48041/74729\nProcessing root 48051/74729\nProcessing root 48061/74729\nProcessing root 48071/74729\nProcessing root 48081/74729\nProcessing root 48091/74729\nProcessing root 48101/74729\nProcessing root 48111/74729\nProcessing root 48121/74729\nProcessing root 48131/74729\nProcessing root 48141/74729\nProcessing root 48151/74729\nProcessing root 48161/74729\nProcessing root 48171/74729\nProcessing root 48181/74729\nProcessing root 48191/74729\nProcessing root 48201/74729\nProcessing root 48211/74729\nProcessing root 48221/74729\nProcessing root 48231/74729\nProcessing root 48241/74729\nProcessing root 48251/74729\nProcessing root 48261/74729\nProcessing root 48271/74729\nProcessing root 48281/74729\nProcessing root 48291/74729\nProcessing root 48301/74729\nProcessing root 48311/74729\nProcessing root 48321/74729\nProcessing root 48331/74729\nProcessing root 48341/74729\nProcessing root 48351/74729\nProcessing root 48361/74729\nProcessing root 48371/74729\nProcessing root 48381/74729\nProcessing root 48391/74729\nProcessing root 48401/74729\nProcessing root 48411/74729\nProcessing root 48421/74729\nProcessing root 48431/74729\nProcessing root 48441/74729\nProcessing root 48451/74729\nProcessing root 48461/74729\nProcessing root 48471/74729\nProcessing root 48481/74729\nProcessing root 48491/74729\nProcessing root 48501/74729\nProcessing root 48511/74729\nProcessing root 48521/74729\nProcessing root 48531/74729\nProcessing root 48541/74729\nProcessing root 48551/74729\nProcessing root 48561/74729\nProcessing root 48571/74729\nProcessing root 48581/74729\nProcessing root 48591/74729\nProcessing root 48601/74729\nProcessing root 48611/74729\nProcessing root 48621/74729\nProcessing root 48631/74729\nProcessing root 48641/74729\nProcessing root 48651/74729\nProcessing root 48661/74729\nProcessing root 48671/74729\nProcessing root 48681/74729\nProcessing root 48691/74729\nProcessing root 48701/74729\nProcessing root 48711/74729\nProcessing root 48721/74729\nProcessing root 48731/74729\nProcessing root 48741/74729\nProcessing root 48751/74729\nProcessing root 48761/74729\nProcessing root 48771/74729\nProcessing root 48781/74729\nProcessing root 48791/74729\nProcessing root 48801/74729\nProcessing root 48811/74729\nProcessing root 48821/74729\nProcessing root 48831/74729\nProcessing root 48841/74729\nProcessing root 48851/74729\nProcessing root 48861/74729\nProcessing root 48871/74729\nProcessing root 48881/74729\nProcessing root 48891/74729\nProcessing root 48901/74729\nProcessing root 48911/74729\nProcessing root 48921/74729\nProcessing root 48931/74729\nProcessing root 48941/74729\nProcessing root 48951/74729\nProcessing root 48961/74729\nProcessing root 48971/74729\nProcessing root 48981/74729\nProcessing root 48991/74729\nProcessing root 49001/74729\nProcessing root 49011/74729\nProcessing root 49021/74729\nProcessing root 49031/74729\nProcessing root 49041/74729\nProcessing root 49051/74729\nProcessing root 49061/74729\nProcessing root 49071/74729\nProcessing root 49081/74729\nProcessing root 49091/74729\nProcessing root 49101/74729\nProcessing root 49111/74729\nProcessing root 49121/74729\nProcessing root 49131/74729\nProcessing root 49141/74729\nProcessing root 49151/74729\nProcessing root 49161/74729\nProcessing root 49171/74729\nProcessing root 49181/74729\nProcessing root 49191/74729\nProcessing root 49201/74729\nProcessing root 49211/74729\nProcessing root 49221/74729\nProcessing root 49231/74729\nProcessing root 49241/74729\nProcessing root 49251/74729\nProcessing root 49261/74729\nProcessing root 49271/74729\nProcessing root 49281/74729\nProcessing root 49291/74729\nProcessing root 49301/74729\nProcessing root 49311/74729\nProcessing root 49321/74729\nProcessing root 49331/74729\nProcessing root 49341/74729\nProcessing root 49351/74729\nProcessing root 49361/74729\nProcessing root 49371/74729\nProcessing root 49381/74729\nProcessing root 49391/74729\nProcessing root 49401/74729\nProcessing root 49411/74729\nProcessing root 49421/74729\nProcessing root 49431/74729\nProcessing root 49441/74729\nProcessing root 49451/74729\nProcessing root 49461/74729\nProcessing root 49471/74729\nProcessing root 49481/74729\nProcessing root 49491/74729\nProcessing root 49501/74729\nProcessing root 49511/74729\nProcessing root 49521/74729\nProcessing root 49531/74729\nProcessing root 49541/74729\nProcessing root 49551/74729\nProcessing root 49561/74729\nProcessing root 49571/74729\nProcessing root 49581/74729\nProcessing root 49591/74729\nProcessing root 49601/74729\nProcessing root 49611/74729\nProcessing root 49621/74729\nProcessing root 49631/74729\nProcessing root 49641/74729\nProcessing root 49651/74729\nProcessing root 49661/74729\nProcessing root 49671/74729\nProcessing root 49681/74729\nProcessing root 49691/74729\nProcessing root 49701/74729\nProcessing root 49711/74729\nProcessing root 49721/74729\nProcessing root 49731/74729\nProcessing root 49741/74729\nProcessing root 49751/74729\nProcessing root 49761/74729\nProcessing root 49771/74729\nProcessing root 49781/74729\nProcessing root 49791/74729\nProcessing root 49801/74729\nProcessing root 49811/74729\nProcessing root 49821/74729\nProcessing root 49831/74729\nProcessing root 49841/74729\nProcessing root 49851/74729\nProcessing root 49861/74729\nProcessing root 49871/74729\nProcessing root 49881/74729\nProcessing root 49891/74729\nProcessing root 49901/74729\nProcessing root 49911/74729\nProcessing root 49921/74729\nProcessing root 49931/74729\nProcessing root 49941/74729\nProcessing root 49951/74729\nProcessing root 49961/74729\nProcessing root 49971/74729\nProcessing root 49981/74729\nProcessing root 49991/74729\nProcessing root 50001/74729\nProcessing root 50011/74729\nProcessing root 50021/74729\nProcessing root 50031/74729\nProcessing root 50041/74729\nProcessing root 50051/74729\nProcessing root 50061/74729\nProcessing root 50071/74729\nProcessing root 50081/74729\nProcessing root 50091/74729\nProcessing root 50101/74729\nProcessing root 50111/74729\nProcessing root 50121/74729\nProcessing root 50131/74729\nProcessing root 50141/74729\nProcessing root 50151/74729\nProcessing root 50161/74729\nProcessing root 50171/74729\nProcessing root 50181/74729\nProcessing root 50191/74729\nProcessing root 50201/74729\nProcessing root 50211/74729\nProcessing root 50221/74729\nProcessing root 50231/74729\nProcessing root 50241/74729\nProcessing root 50251/74729\nProcessing root 50261/74729\nProcessing root 50271/74729\nProcessing root 50281/74729\nProcessing root 50291/74729\nProcessing root 50301/74729\nProcessing root 50311/74729\nProcessing root 50321/74729\nProcessing root 50331/74729\nProcessing root 50341/74729\nProcessing root 50351/74729\nProcessing root 50361/74729\nProcessing root 50371/74729\nProcessing root 50381/74729\nProcessing root 50391/74729\nProcessing root 50401/74729\nProcessing root 50411/74729\nProcessing root 50421/74729\nProcessing root 50431/74729\nProcessing root 50441/74729\nProcessing root 50451/74729\nProcessing root 50461/74729\nProcessing root 50471/74729\nProcessing root 50481/74729\nProcessing root 50491/74729\nProcessing root 50501/74729\nProcessing root 50511/74729\nProcessing root 50521/74729\nProcessing root 50531/74729\nProcessing root 50541/74729\nProcessing root 50551/74729\nProcessing root 50561/74729\nProcessing root 50571/74729\nProcessing root 50581/74729\nProcessing root 50591/74729\nProcessing root 50601/74729\nProcessing root 50611/74729\nProcessing root 50621/74729\nProcessing root 50631/74729\nProcessing root 50641/74729\nProcessing root 50651/74729\nProcessing root 50661/74729\nProcessing root 50671/74729\nProcessing root 50681/74729\nProcessing root 50691/74729\nProcessing root 50701/74729\nProcessing root 50711/74729\nProcessing root 50721/74729\nProcessing root 50731/74729\nProcessing root 50741/74729\nProcessing root 50751/74729\nProcessing root 50761/74729\nProcessing root 50771/74729\nProcessing root 50781/74729\nProcessing root 50791/74729\nProcessing root 50801/74729\nProcessing root 50811/74729\nProcessing root 50821/74729\nProcessing root 50831/74729\nProcessing root 50841/74729\nProcessing root 50851/74729\nProcessing root 50861/74729\nProcessing root 50871/74729\nProcessing root 50881/74729\nProcessing root 50891/74729\nProcessing root 50901/74729\nProcessing root 50911/74729\nProcessing root 50921/74729\nProcessing root 50931/74729\nProcessing root 50941/74729\nProcessing root 50951/74729\nProcessing root 50961/74729\nProcessing root 50971/74729\nProcessing root 50981/74729\nProcessing root 50991/74729\nProcessing root 51001/74729\nProcessing root 51011/74729\nProcessing root 51021/74729\nProcessing root 51031/74729\nProcessing root 51041/74729\nProcessing root 51051/74729\nProcessing root 51061/74729\nProcessing root 51071/74729\nProcessing root 51081/74729\nProcessing root 51091/74729\nProcessing root 51101/74729\nProcessing root 51111/74729\nProcessing root 51121/74729\nProcessing root 51131/74729\nProcessing root 51141/74729\nProcessing root 51151/74729\nProcessing root 51161/74729\nProcessing root 51171/74729\nProcessing root 51181/74729\nProcessing root 51191/74729\nProcessing root 51201/74729\nProcessing root 51211/74729\nProcessing root 51221/74729\nProcessing root 51231/74729\nProcessing root 51241/74729\nProcessing root 51251/74729\nProcessing root 51261/74729\nProcessing root 51271/74729\nProcessing root 51281/74729\nProcessing root 51291/74729\nProcessing root 51301/74729\nProcessing root 51311/74729\nProcessing root 51321/74729\nProcessing root 51331/74729\nProcessing root 51341/74729\nProcessing root 51351/74729\nProcessing root 51361/74729\nProcessing root 51371/74729\nProcessing root 51381/74729\nProcessing root 51391/74729\nProcessing root 51401/74729\nProcessing root 51411/74729\nProcessing root 51421/74729\nProcessing root 51431/74729\nProcessing root 51441/74729\nProcessing root 51451/74729\nProcessing root 51461/74729\nProcessing root 51471/74729\nProcessing root 51481/74729\nProcessing root 51491/74729\nProcessing root 51501/74729\nProcessing root 51511/74729\nProcessing root 51521/74729\nProcessing root 51531/74729\nProcessing root 51541/74729\nProcessing root 51551/74729\nProcessing root 51561/74729\nProcessing root 51571/74729\nProcessing root 51581/74729\nProcessing root 51591/74729\nProcessing root 51601/74729\nProcessing root 51611/74729\nProcessing root 51621/74729\nProcessing root 51631/74729\nProcessing root 51641/74729\nProcessing root 51651/74729\nProcessing root 51661/74729\nProcessing root 51671/74729\nProcessing root 51681/74729\nProcessing root 51691/74729\nProcessing root 51701/74729\nProcessing root 51711/74729\nProcessing root 51721/74729\nProcessing root 51731/74729\nProcessing root 51741/74729\nProcessing root 51751/74729\nProcessing root 51761/74729\nProcessing root 51771/74729\nProcessing root 51781/74729\nProcessing root 51791/74729\nProcessing root 51801/74729\nProcessing root 51811/74729\nProcessing root 51821/74729\nProcessing root 51831/74729\nProcessing root 51841/74729\nProcessing root 51851/74729\nProcessing root 51861/74729\nProcessing root 51871/74729\nProcessing root 51881/74729\nProcessing root 51891/74729\nProcessing root 51901/74729\nProcessing root 51911/74729\nProcessing root 51921/74729\nProcessing root 51931/74729\nProcessing root 51941/74729\nProcessing root 51951/74729\nProcessing root 51961/74729\nProcessing root 51971/74729\nProcessing root 51981/74729\nProcessing root 51991/74729\nProcessing root 52001/74729\nProcessing root 52011/74729\nProcessing root 52021/74729\nProcessing root 52031/74729\nProcessing root 52041/74729\nProcessing root 52051/74729\nProcessing root 52061/74729\nProcessing root 52071/74729\nProcessing root 52081/74729\nProcessing root 52091/74729\nProcessing root 52101/74729\nProcessing root 52111/74729\nProcessing root 52121/74729\nProcessing root 52131/74729\nProcessing root 52141/74729\nProcessing root 52151/74729\nProcessing root 52161/74729\nProcessing root 52171/74729\nProcessing root 52181/74729\nProcessing root 52191/74729\nProcessing root 52201/74729\nProcessing root 52211/74729\nProcessing root 52221/74729\nProcessing root 52231/74729\nProcessing root 52241/74729\nProcessing root 52251/74729\nProcessing root 52261/74729\nProcessing root 52271/74729\nProcessing root 52281/74729\nProcessing root 52291/74729\nProcessing root 52301/74729\nProcessing root 52311/74729\nProcessing root 52321/74729\nProcessing root 52331/74729\nProcessing root 52341/74729\nProcessing root 52351/74729\nProcessing root 52361/74729\nProcessing root 52371/74729\nProcessing root 52381/74729\nProcessing root 52391/74729\nProcessing root 52401/74729\nProcessing root 52411/74729\nProcessing root 52421/74729\nProcessing root 52431/74729\nProcessing root 52441/74729\nProcessing root 52451/74729\nProcessing root 52461/74729\nProcessing root 52471/74729\nProcessing root 52481/74729\nProcessing root 52491/74729\nProcessing root 52501/74729\nProcessing root 52511/74729\nProcessing root 52521/74729\nProcessing root 52531/74729\nProcessing root 52541/74729\nProcessing root 52551/74729\nProcessing root 52561/74729\nProcessing root 52571/74729\nProcessing root 52581/74729\nProcessing root 52591/74729\nProcessing root 52601/74729\nProcessing root 52611/74729\nProcessing root 52621/74729\nProcessing root 52631/74729\nProcessing root 52641/74729\nProcessing root 52651/74729\nProcessing root 52661/74729\nProcessing root 52671/74729\nProcessing root 52681/74729\nProcessing root 52691/74729\nProcessing root 52701/74729\nProcessing root 52711/74729\nProcessing root 52721/74729\nProcessing root 52731/74729\nProcessing root 52741/74729\nProcessing root 52751/74729\nProcessing root 52761/74729\nProcessing root 52771/74729\nProcessing root 52781/74729\nProcessing root 52791/74729\nProcessing root 52801/74729\nProcessing root 52811/74729\nProcessing root 52821/74729\nProcessing root 52831/74729\nProcessing root 52841/74729\nProcessing root 52851/74729\nProcessing root 52861/74729\nProcessing root 52871/74729\nProcessing root 52881/74729\nProcessing root 52891/74729\nProcessing root 52901/74729\nProcessing root 52911/74729\nProcessing root 52921/74729\nProcessing root 52931/74729\nProcessing root 52941/74729\nProcessing root 52951/74729\nProcessing root 52961/74729\nProcessing root 52971/74729\nProcessing root 52981/74729\nProcessing root 52991/74729\nProcessing root 53001/74729\nProcessing root 53011/74729\nProcessing root 53021/74729\nProcessing root 53031/74729\nProcessing root 53041/74729\nProcessing root 53051/74729\nProcessing root 53061/74729\nProcessing root 53071/74729\nProcessing root 53081/74729\nProcessing root 53091/74729\nProcessing root 53101/74729\nProcessing root 53111/74729\nProcessing root 53121/74729\nProcessing root 53131/74729\nProcessing root 53141/74729\nProcessing root 53151/74729\nProcessing root 53161/74729\nProcessing root 53171/74729\nProcessing root 53181/74729\nProcessing root 53191/74729\nProcessing root 53201/74729\nProcessing root 53211/74729\nProcessing root 53221/74729\nProcessing root 53231/74729\nProcessing root 53241/74729\nProcessing root 53251/74729\nProcessing root 53261/74729\nProcessing root 53271/74729\nProcessing root 53281/74729\nProcessing root 53291/74729\nProcessing root 53301/74729\nProcessing root 53311/74729\nProcessing root 53321/74729\nProcessing root 53331/74729\nProcessing root 53341/74729\nProcessing root 53351/74729\nProcessing root 53361/74729\nProcessing root 53371/74729\nProcessing root 53381/74729\nProcessing root 53391/74729\nProcessing root 53401/74729\nProcessing root 53411/74729\nProcessing root 53421/74729\nProcessing root 53431/74729\nProcessing root 53441/74729\nProcessing root 53451/74729\nProcessing root 53461/74729\nProcessing root 53471/74729\nProcessing root 53481/74729\nProcessing root 53491/74729\nProcessing root 53501/74729\nProcessing root 53511/74729\nProcessing root 53521/74729\nProcessing root 53531/74729\nProcessing root 53541/74729\nProcessing root 53551/74729\nProcessing root 53561/74729\nProcessing root 53571/74729\nProcessing root 53581/74729\nProcessing root 53591/74729\nProcessing root 53601/74729\nProcessing root 53611/74729\nProcessing root 53621/74729\nProcessing root 53631/74729\nProcessing root 53641/74729\nProcessing root 53651/74729\nProcessing root 53661/74729\nProcessing root 53671/74729\nProcessing root 53681/74729\nProcessing root 53691/74729\nProcessing root 53701/74729\nProcessing root 53711/74729\nProcessing root 53721/74729\nProcessing root 53731/74729\nProcessing root 53741/74729\nProcessing root 53751/74729\nProcessing root 53761/74729\nProcessing root 53771/74729\nProcessing root 53781/74729\nProcessing root 53791/74729\nProcessing root 53801/74729\nProcessing root 53811/74729\nProcessing root 53821/74729\nProcessing root 53831/74729\nProcessing root 53841/74729\nProcessing root 53851/74729\nProcessing root 53861/74729\nProcessing root 53871/74729\nProcessing root 53881/74729\nProcessing root 53891/74729\nProcessing root 53901/74729\nProcessing root 53911/74729\nProcessing root 53921/74729\nProcessing root 53931/74729\nProcessing root 53941/74729\nProcessing root 53951/74729\nProcessing root 53961/74729\nProcessing root 53971/74729\nProcessing root 53981/74729\nProcessing root 53991/74729\nProcessing root 54001/74729\nProcessing root 54011/74729\nProcessing root 54021/74729\nProcessing root 54031/74729\nProcessing root 54041/74729\nProcessing root 54051/74729\nProcessing root 54061/74729\nProcessing root 54071/74729\nProcessing root 54081/74729\nProcessing root 54091/74729\nProcessing root 54101/74729\nProcessing root 54111/74729\nProcessing root 54121/74729\nProcessing root 54131/74729\nProcessing root 54141/74729\nProcessing root 54151/74729\nProcessing root 54161/74729\nProcessing root 54171/74729\nProcessing root 54181/74729\nProcessing root 54191/74729\nProcessing root 54201/74729\nProcessing root 54211/74729\nProcessing root 54221/74729\nProcessing root 54231/74729\nProcessing root 54241/74729\nProcessing root 54251/74729\nProcessing root 54261/74729\nProcessing root 54271/74729\nProcessing root 54281/74729\nProcessing root 54291/74729\nProcessing root 54301/74729\nProcessing root 54311/74729\nProcessing root 54321/74729\nProcessing root 54331/74729\nProcessing root 54341/74729\nProcessing root 54351/74729\nProcessing root 54361/74729\nProcessing root 54371/74729\nProcessing root 54381/74729\nProcessing root 54391/74729\nProcessing root 54401/74729\nProcessing root 54411/74729\nProcessing root 54421/74729\nProcessing root 54431/74729\nProcessing root 54441/74729\nProcessing root 54451/74729\nProcessing root 54461/74729\nProcessing root 54471/74729\nProcessing root 54481/74729\nProcessing root 54491/74729\nProcessing root 54501/74729\nProcessing root 54511/74729\nProcessing root 54521/74729\nProcessing root 54531/74729\nProcessing root 54541/74729\nProcessing root 54551/74729\nProcessing root 54561/74729\nProcessing root 54571/74729\nProcessing root 54581/74729\nProcessing root 54591/74729\nProcessing root 54601/74729\nProcessing root 54611/74729\nProcessing root 54621/74729\nProcessing root 54631/74729\nProcessing root 54641/74729\nProcessing root 54651/74729\nProcessing root 54661/74729\nProcessing root 54671/74729\nProcessing root 54681/74729\nProcessing root 54691/74729\nProcessing root 54701/74729\nProcessing root 54711/74729\nProcessing root 54721/74729\nProcessing root 54731/74729\nProcessing root 54741/74729\nProcessing root 54751/74729\nProcessing root 54761/74729\nProcessing root 54771/74729\nProcessing root 54781/74729\nProcessing root 54791/74729\nProcessing root 54801/74729\nProcessing root 54811/74729\nProcessing root 54821/74729\nProcessing root 54831/74729\nProcessing root 54841/74729\nProcessing root 54851/74729\nProcessing root 54861/74729\nProcessing root 54871/74729\nProcessing root 54881/74729\nProcessing root 54891/74729\nProcessing root 54901/74729\nProcessing root 54911/74729\nProcessing root 54921/74729\nProcessing root 54931/74729\nProcessing root 54941/74729\nProcessing root 54951/74729\nProcessing root 54961/74729\nProcessing root 54971/74729\nProcessing root 54981/74729\nProcessing root 54991/74729\nProcessing root 55001/74729\nProcessing root 55011/74729\nProcessing root 55021/74729\nProcessing root 55031/74729\nProcessing root 55041/74729\nProcessing root 55051/74729\nProcessing root 55061/74729\nProcessing root 55071/74729\nProcessing root 55081/74729\nProcessing root 55091/74729\nProcessing root 55101/74729\nProcessing root 55111/74729\nProcessing root 55121/74729\nProcessing root 55131/74729\nProcessing root 55141/74729\nProcessing root 55151/74729\nProcessing root 55161/74729\nProcessing root 55171/74729\nProcessing root 55181/74729\nProcessing root 55191/74729\nProcessing root 55201/74729\nProcessing root 55211/74729\nProcessing root 55221/74729\nProcessing root 55231/74729\nProcessing root 55241/74729\nProcessing root 55251/74729\nProcessing root 55261/74729\nProcessing root 55271/74729\nProcessing root 55281/74729\nProcessing root 55291/74729\nProcessing root 55301/74729\nProcessing root 55311/74729\nProcessing root 55321/74729\nProcessing root 55331/74729\nProcessing root 55341/74729\nProcessing root 55351/74729\nProcessing root 55361/74729\nProcessing root 55371/74729\nProcessing root 55381/74729\nProcessing root 55391/74729\nProcessing root 55401/74729\nProcessing root 55411/74729\nProcessing root 55421/74729\nProcessing root 55431/74729\nProcessing root 55441/74729\nProcessing root 55451/74729\nProcessing root 55461/74729\nProcessing root 55471/74729\nProcessing root 55481/74729\nProcessing root 55491/74729\nProcessing root 55501/74729\nProcessing root 55511/74729\nProcessing root 55521/74729\nProcessing root 55531/74729\nProcessing root 55541/74729\nProcessing root 55551/74729\nProcessing root 55561/74729\nProcessing root 55571/74729\nProcessing root 55581/74729\nProcessing root 55591/74729\nProcessing root 55601/74729\nProcessing root 55611/74729\nProcessing root 55621/74729\nProcessing root 55631/74729\nProcessing root 55641/74729\nProcessing root 55651/74729\nProcessing root 55661/74729\nProcessing root 55671/74729\nProcessing root 55681/74729\nProcessing root 55691/74729\nProcessing root 55701/74729\nProcessing root 55711/74729\nProcessing root 55721/74729\nProcessing root 55731/74729\nProcessing root 55741/74729\nProcessing root 55751/74729\nProcessing root 55761/74729\nProcessing root 55771/74729\nProcessing root 55781/74729\nProcessing root 55791/74729\nProcessing root 55801/74729\nProcessing root 55811/74729\nProcessing root 55821/74729\nProcessing root 55831/74729\nProcessing root 55841/74729\nProcessing root 55851/74729\nProcessing root 55861/74729\nProcessing root 55871/74729\nProcessing root 55881/74729\nProcessing root 55891/74729\nProcessing root 55901/74729\nProcessing root 55911/74729\nProcessing root 55921/74729\nProcessing root 55931/74729\nProcessing root 55941/74729\nProcessing root 55951/74729\nProcessing root 55961/74729\nProcessing root 55971/74729\nProcessing root 55981/74729\nProcessing root 55991/74729\nProcessing root 56001/74729\nProcessing root 56011/74729\nProcessing root 56021/74729\nProcessing root 56031/74729\nProcessing root 56041/74729\nProcessing root 56051/74729\nProcessing root 56061/74729\nProcessing root 56071/74729\nProcessing root 56081/74729\nProcessing root 56091/74729\nProcessing root 56101/74729\nProcessing root 56111/74729\nProcessing root 56121/74729\nProcessing root 56131/74729\nProcessing root 56141/74729\nProcessing root 56151/74729\nProcessing root 56161/74729\nProcessing root 56171/74729\nProcessing root 56181/74729\nProcessing root 56191/74729\nProcessing root 56201/74729\nProcessing root 56211/74729\nProcessing root 56221/74729\nProcessing root 56231/74729\nProcessing root 56241/74729\nProcessing root 56251/74729\nProcessing root 56261/74729\nProcessing root 56271/74729\nProcessing root 56281/74729\nProcessing root 56291/74729\nProcessing root 56301/74729\nProcessing root 56311/74729\nProcessing root 56321/74729\nProcessing root 56331/74729\nProcessing root 56341/74729\nProcessing root 56351/74729\nProcessing root 56361/74729\nProcessing root 56371/74729\nProcessing root 56381/74729\nProcessing root 56391/74729\nProcessing root 56401/74729\nProcessing root 56411/74729\nProcessing root 56421/74729\nProcessing root 56431/74729\nProcessing root 56441/74729\nProcessing root 56451/74729\nProcessing root 56461/74729\nProcessing root 56471/74729\nProcessing root 56481/74729\nProcessing root 56491/74729\nProcessing root 56501/74729\nProcessing root 56511/74729\nProcessing root 56521/74729\nProcessing root 56531/74729\nProcessing root 56541/74729\nProcessing root 56551/74729\nProcessing root 56561/74729\nProcessing root 56571/74729\nProcessing root 56581/74729\nProcessing root 56591/74729\nProcessing root 56601/74729\nProcessing root 56611/74729\nProcessing root 56621/74729\nProcessing root 56631/74729\nProcessing root 56641/74729\nProcessing root 56651/74729\nProcessing root 56661/74729\nProcessing root 56671/74729\nProcessing root 56681/74729\nProcessing root 56691/74729\nProcessing root 56701/74729\nProcessing root 56711/74729\nProcessing root 56721/74729\nProcessing root 56731/74729\nProcessing root 56741/74729\nProcessing root 56751/74729\nProcessing root 56761/74729\nProcessing root 56771/74729\nProcessing root 56781/74729\nProcessing root 56791/74729\nProcessing root 56801/74729\nProcessing root 56811/74729\nProcessing root 56821/74729\nProcessing root 56831/74729\nProcessing root 56841/74729\nProcessing root 56851/74729\nProcessing root 56861/74729\nProcessing root 56871/74729\nProcessing root 56881/74729\nProcessing root 56891/74729\nProcessing root 56901/74729\nProcessing root 56911/74729\nProcessing root 56921/74729\nProcessing root 56931/74729\nProcessing root 56941/74729\nProcessing root 56951/74729\nProcessing root 56961/74729\nProcessing root 56971/74729\nProcessing root 56981/74729\nProcessing root 56991/74729\nProcessing root 57001/74729\nProcessing root 57011/74729\nProcessing root 57021/74729\nProcessing root 57031/74729\nProcessing root 57041/74729\nProcessing root 57051/74729\nProcessing root 57061/74729\nProcessing root 57071/74729\nProcessing root 57081/74729\nProcessing root 57091/74729\nProcessing root 57101/74729\nProcessing root 57111/74729\nProcessing root 57121/74729\nProcessing root 57131/74729\nProcessing root 57141/74729\nProcessing root 57151/74729\nProcessing root 57161/74729\nProcessing root 57171/74729\nProcessing root 57181/74729\nProcessing root 57191/74729\nProcessing root 57201/74729\nProcessing root 57211/74729\nProcessing root 57221/74729\nProcessing root 57231/74729\nProcessing root 57241/74729\nProcessing root 57251/74729\nProcessing root 57261/74729\nProcessing root 57271/74729\nProcessing root 57281/74729\nProcessing root 57291/74729\nProcessing root 57301/74729\nProcessing root 57311/74729\nProcessing root 57321/74729\nProcessing root 57331/74729\nProcessing root 57341/74729\nProcessing root 57351/74729\nProcessing root 57361/74729\nProcessing root 57371/74729\nProcessing root 57381/74729\nProcessing root 57391/74729\nProcessing root 57401/74729\nProcessing root 57411/74729\nProcessing root 57421/74729\nProcessing root 57431/74729\nProcessing root 57441/74729\nProcessing root 57451/74729\nProcessing root 57461/74729\nProcessing root 57471/74729\nProcessing root 57481/74729\nProcessing root 57491/74729\nProcessing root 57501/74729\nProcessing root 57511/74729\nProcessing root 57521/74729\nProcessing root 57531/74729\nProcessing root 57541/74729\nProcessing root 57551/74729\nProcessing root 57561/74729\nProcessing root 57571/74729\nProcessing root 57581/74729\nProcessing root 57591/74729\nProcessing root 57601/74729\nProcessing root 57611/74729\nProcessing root 57621/74729\nProcessing root 57631/74729\nProcessing root 57641/74729\nProcessing root 57651/74729\nProcessing root 57661/74729\nProcessing root 57671/74729\nProcessing root 57681/74729\nProcessing root 57691/74729\nProcessing root 57701/74729\nProcessing root 57711/74729\nProcessing root 57721/74729\nProcessing root 57731/74729\nProcessing root 57741/74729\nProcessing root 57751/74729\nProcessing root 57761/74729\nProcessing root 57771/74729\nProcessing root 57781/74729\nProcessing root 57791/74729\nProcessing root 57801/74729\nProcessing root 57811/74729\nProcessing root 57821/74729\nProcessing root 57831/74729\nProcessing root 57841/74729\nProcessing root 57851/74729\nProcessing root 57861/74729\nProcessing root 57871/74729\nProcessing root 57881/74729\nProcessing root 57891/74729\nProcessing root 57901/74729\nProcessing root 57911/74729\nProcessing root 57921/74729\nProcessing root 57931/74729\nProcessing root 57941/74729\nProcessing root 57951/74729\nProcessing root 57961/74729\nProcessing root 57971/74729\nProcessing root 57981/74729\nProcessing root 57991/74729\nProcessing root 58001/74729\nProcessing root 58011/74729\nProcessing root 58021/74729\nProcessing root 58031/74729\nProcessing root 58041/74729\nProcessing root 58051/74729\nProcessing root 58061/74729\nProcessing root 58071/74729\nProcessing root 58081/74729\nProcessing root 58091/74729\nProcessing root 58101/74729\nProcessing root 58111/74729\nProcessing root 58121/74729\nProcessing root 58131/74729\nProcessing root 58141/74729\nProcessing root 58151/74729\nProcessing root 58161/74729\nProcessing root 58171/74729\nProcessing root 58181/74729\nProcessing root 58191/74729\nProcessing root 58201/74729\nProcessing root 58211/74729\nProcessing root 58221/74729\nProcessing root 58231/74729\nProcessing root 58241/74729\nProcessing root 58251/74729\nProcessing root 58261/74729\nProcessing root 58271/74729\nProcessing root 58281/74729\nProcessing root 58291/74729\nProcessing root 58301/74729\nProcessing root 58311/74729\nProcessing root 58321/74729\nProcessing root 58331/74729\nProcessing root 58341/74729\nProcessing root 58351/74729\nProcessing root 58361/74729\nProcessing root 58371/74729\nProcessing root 58381/74729\nProcessing root 58391/74729\nProcessing root 58401/74729\nProcessing root 58411/74729\nProcessing root 58421/74729\nProcessing root 58431/74729\nProcessing root 58441/74729\nProcessing root 58451/74729\nProcessing root 58461/74729\nProcessing root 58471/74729\nProcessing root 58481/74729\nProcessing root 58491/74729\nProcessing root 58501/74729\nProcessing root 58511/74729\nProcessing root 58521/74729\nProcessing root 58531/74729\nProcessing root 58541/74729\nProcessing root 58551/74729\nProcessing root 58561/74729\nProcessing root 58571/74729\nProcessing root 58581/74729\nProcessing root 58591/74729\nProcessing root 58601/74729\nProcessing root 58611/74729\nProcessing root 58621/74729\nProcessing root 58631/74729\nProcessing root 58641/74729\nProcessing root 58651/74729\nProcessing root 58661/74729\nProcessing root 58671/74729\nProcessing root 58681/74729\nProcessing root 58691/74729\nProcessing root 58701/74729\nProcessing root 58711/74729\nProcessing root 58721/74729\nProcessing root 58731/74729\nProcessing root 58741/74729\nProcessing root 58751/74729\nProcessing root 58761/74729\nProcessing root 58771/74729\nProcessing root 58781/74729\nProcessing root 58791/74729\nProcessing root 58801/74729\nProcessing root 58811/74729\nProcessing root 58821/74729\nProcessing root 58831/74729\nProcessing root 58841/74729\nProcessing root 58851/74729\nProcessing root 58861/74729\nProcessing root 58871/74729\nProcessing root 58881/74729\nProcessing root 58891/74729\nProcessing root 58901/74729\nProcessing root 58911/74729\nProcessing root 58921/74729\nProcessing root 58931/74729\nProcessing root 58941/74729\nProcessing root 58951/74729\nProcessing root 58961/74729\nProcessing root 58971/74729\nProcessing root 58981/74729\nProcessing root 58991/74729\nProcessing root 59001/74729\nProcessing root 59011/74729\nProcessing root 59021/74729\nProcessing root 59031/74729\nProcessing root 59041/74729\nProcessing root 59051/74729\nProcessing root 59061/74729\nProcessing root 59071/74729\nProcessing root 59081/74729\nProcessing root 59091/74729\nProcessing root 59101/74729\nProcessing root 59111/74729\nProcessing root 59121/74729\nProcessing root 59131/74729\nProcessing root 59141/74729\nProcessing root 59151/74729\nProcessing root 59161/74729\nProcessing root 59171/74729\nProcessing root 59181/74729\nProcessing root 59191/74729\nProcessing root 59201/74729\nProcessing root 59211/74729\nProcessing root 59221/74729\nProcessing root 59231/74729\nProcessing root 59241/74729\nProcessing root 59251/74729\nProcessing root 59261/74729\nProcessing root 59271/74729\nProcessing root 59281/74729\nProcessing root 59291/74729\nProcessing root 59301/74729\nProcessing root 59311/74729\nProcessing root 59321/74729\nProcessing root 59331/74729\nProcessing root 59341/74729\nProcessing root 59351/74729\nProcessing root 59361/74729\nProcessing root 59371/74729\nProcessing root 59381/74729\nProcessing root 59391/74729\nProcessing root 59401/74729\nProcessing root 59411/74729\nProcessing root 59421/74729\nProcessing root 59431/74729\nProcessing root 59441/74729\nProcessing root 59451/74729\nProcessing root 59461/74729\nProcessing root 59471/74729\nProcessing root 59481/74729\nProcessing root 59491/74729\nProcessing root 59501/74729\nProcessing root 59511/74729\nProcessing root 59521/74729\nProcessing root 59531/74729\nProcessing root 59541/74729\nProcessing root 59551/74729\nProcessing root 59561/74729\nProcessing root 59571/74729\nProcessing root 59581/74729\nProcessing root 59591/74729\nProcessing root 59601/74729\nProcessing root 59611/74729\nProcessing root 59621/74729\nProcessing root 59631/74729\nProcessing root 59641/74729\nProcessing root 59651/74729\nProcessing root 59661/74729\nProcessing root 59671/74729\nProcessing root 59681/74729\nProcessing root 59691/74729\nProcessing root 59701/74729\nProcessing root 59711/74729\nProcessing root 59721/74729\nProcessing root 59731/74729\nProcessing root 59741/74729\nProcessing root 59751/74729\nProcessing root 59761/74729\nProcessing root 59771/74729\nProcessing root 59781/74729\nProcessing root 59791/74729\nProcessing root 59801/74729\nProcessing root 59811/74729\nProcessing root 59821/74729\nProcessing root 59831/74729\nProcessing root 59841/74729\nProcessing root 59851/74729\nProcessing root 59861/74729\nProcessing root 59871/74729\nProcessing root 59881/74729\nProcessing root 59891/74729\nProcessing root 59901/74729\nProcessing root 59911/74729\nProcessing root 59921/74729\nProcessing root 59931/74729\nProcessing root 59941/74729\nProcessing root 59951/74729\nProcessing root 59961/74729\nProcessing root 59971/74729\nProcessing root 59981/74729\nProcessing root 59991/74729\nProcessing root 60001/74729\nProcessing root 60011/74729\nProcessing root 60021/74729\nProcessing root 60031/74729\nProcessing root 60041/74729\nProcessing root 60051/74729\nProcessing root 60061/74729\nProcessing root 60071/74729\nProcessing root 60081/74729\nProcessing root 60091/74729\nProcessing root 60101/74729\nProcessing root 60111/74729\nProcessing root 60121/74729\nProcessing root 60131/74729\nProcessing root 60141/74729\nProcessing root 60151/74729\nProcessing root 60161/74729\nProcessing root 60171/74729\nProcessing root 60181/74729\nProcessing root 60191/74729\nProcessing root 60201/74729\nProcessing root 60211/74729\nProcessing root 60221/74729\nProcessing root 60231/74729\nProcessing root 60241/74729\nProcessing root 60251/74729\nProcessing root 60261/74729\nProcessing root 60271/74729\nProcessing root 60281/74729\nProcessing root 60291/74729\nProcessing root 60301/74729\nProcessing root 60311/74729\nProcessing root 60321/74729\nProcessing root 60331/74729\nProcessing root 60341/74729\nProcessing root 60351/74729\nProcessing root 60361/74729\nProcessing root 60371/74729\nProcessing root 60381/74729\nProcessing root 60391/74729\nProcessing root 60401/74729\nProcessing root 60411/74729\nProcessing root 60421/74729\nProcessing root 60431/74729\nProcessing root 60441/74729\nProcessing root 60451/74729\nProcessing root 60461/74729\nProcessing root 60471/74729\nProcessing root 60481/74729\nProcessing root 60491/74729\nProcessing root 60501/74729\nProcessing root 60511/74729\nProcessing root 60521/74729\nProcessing root 60531/74729\nProcessing root 60541/74729\nProcessing root 60551/74729\nProcessing root 60561/74729\nProcessing root 60571/74729\nProcessing root 60581/74729\nProcessing root 60591/74729\nProcessing root 60601/74729\nProcessing root 60611/74729\nProcessing root 60621/74729\nProcessing root 60631/74729\nProcessing root 60641/74729\nProcessing root 60651/74729\nProcessing root 60661/74729\nProcessing root 60671/74729\nProcessing root 60681/74729\nProcessing root 60691/74729\nProcessing root 60701/74729\nProcessing root 60711/74729\nProcessing root 60721/74729\nProcessing root 60731/74729\nProcessing root 60741/74729\nProcessing root 60751/74729\nProcessing root 60761/74729\nProcessing root 60771/74729\nProcessing root 60781/74729\nProcessing root 60791/74729\nProcessing root 60801/74729\nProcessing root 60811/74729\nProcessing root 60821/74729\nProcessing root 60831/74729\nProcessing root 60841/74729\nProcessing root 60851/74729\nProcessing root 60861/74729\nProcessing root 60871/74729\nProcessing root 60881/74729\nProcessing root 60891/74729\nProcessing root 60901/74729\nProcessing root 60911/74729\nProcessing root 60921/74729\nProcessing root 60931/74729\nProcessing root 60941/74729\nProcessing root 60951/74729\nProcessing root 60961/74729\nProcessing root 60971/74729\nProcessing root 60981/74729\nProcessing root 60991/74729\nProcessing root 61001/74729\nProcessing root 61011/74729\nProcessing root 61021/74729\nProcessing root 61031/74729\nProcessing root 61041/74729\nProcessing root 61051/74729\nProcessing root 61061/74729\nProcessing root 61071/74729\nProcessing root 61081/74729\nProcessing root 61091/74729\nProcessing root 61101/74729\nProcessing root 61111/74729\nProcessing root 61121/74729\nProcessing root 61131/74729\nProcessing root 61141/74729\nProcessing root 61151/74729\nProcessing root 61161/74729\nProcessing root 61171/74729\nProcessing root 61181/74729\nProcessing root 61191/74729\nProcessing root 61201/74729\nProcessing root 61211/74729\nProcessing root 61221/74729\nProcessing root 61231/74729\nProcessing root 61241/74729\nProcessing root 61251/74729\nProcessing root 61261/74729\nProcessing root 61271/74729\nProcessing root 61281/74729\nProcessing root 61291/74729\nProcessing root 61301/74729\nProcessing root 61311/74729\nProcessing root 61321/74729\nProcessing root 61331/74729\nProcessing root 61341/74729\nProcessing root 61351/74729\nProcessing root 61361/74729\nProcessing root 61371/74729\nProcessing root 61381/74729\nProcessing root 61391/74729\nProcessing root 61401/74729\nProcessing root 61411/74729\nProcessing root 61421/74729\nProcessing root 61431/74729\nProcessing root 61441/74729\nProcessing root 61451/74729\nProcessing root 61461/74729\nProcessing root 61471/74729\nProcessing root 61481/74729\nProcessing root 61491/74729\nProcessing root 61501/74729\nProcessing root 61511/74729\nProcessing root 61521/74729\nProcessing root 61531/74729\nProcessing root 61541/74729\nProcessing root 61551/74729\nProcessing root 61561/74729\nProcessing root 61571/74729\nProcessing root 61581/74729\nProcessing root 61591/74729\nProcessing root 61601/74729\nProcessing root 61611/74729\nProcessing root 61621/74729\nProcessing root 61631/74729\nProcessing root 61641/74729\nProcessing root 61651/74729\nProcessing root 61661/74729\nProcessing root 61671/74729\nProcessing root 61681/74729\nProcessing root 61691/74729\nProcessing root 61701/74729\nProcessing root 61711/74729\nProcessing root 61721/74729\nProcessing root 61731/74729\nProcessing root 61741/74729\nProcessing root 61751/74729\nProcessing root 61761/74729\nProcessing root 61771/74729\nProcessing root 61781/74729\nProcessing root 61791/74729\nProcessing root 61801/74729\nProcessing root 61811/74729\nProcessing root 61821/74729\nProcessing root 61831/74729\nProcessing root 61841/74729\nProcessing root 61851/74729\nProcessing root 61861/74729\nProcessing root 61871/74729\nProcessing root 61881/74729\nProcessing root 61891/74729\nProcessing root 61901/74729\nProcessing root 61911/74729\nProcessing root 61921/74729\nProcessing root 61931/74729\nProcessing root 61941/74729\nProcessing root 61951/74729\nProcessing root 61961/74729\nProcessing root 61971/74729\nProcessing root 61981/74729\nProcessing root 61991/74729\nProcessing root 62001/74729\nProcessing root 62011/74729\nProcessing root 62021/74729\nProcessing root 62031/74729\nProcessing root 62041/74729\nProcessing root 62051/74729\nProcessing root 62061/74729\nProcessing root 62071/74729\nProcessing root 62081/74729\nProcessing root 62091/74729\nProcessing root 62101/74729\nProcessing root 62111/74729\nProcessing root 62121/74729\nProcessing root 62131/74729\nProcessing root 62141/74729\nProcessing root 62151/74729\nProcessing root 62161/74729\nProcessing root 62171/74729\nProcessing root 62181/74729\nProcessing root 62191/74729\nProcessing root 62201/74729\nProcessing root 62211/74729\nProcessing root 62221/74729\nProcessing root 62231/74729\nProcessing root 62241/74729\nProcessing root 62251/74729\nProcessing root 62261/74729\nProcessing root 62271/74729\nProcessing root 62281/74729\nProcessing root 62291/74729\nProcessing root 62301/74729\nProcessing root 62311/74729\nProcessing root 62321/74729\nProcessing root 62331/74729\nProcessing root 62341/74729\nProcessing root 62351/74729\nProcessing root 62361/74729\nProcessing root 62371/74729\nProcessing root 62381/74729\nProcessing root 62391/74729\nProcessing root 62401/74729\nProcessing root 62411/74729\nProcessing root 62421/74729\nProcessing root 62431/74729\nProcessing root 62441/74729\nProcessing root 62451/74729\nProcessing root 62461/74729\nProcessing root 62471/74729\nProcessing root 62481/74729\nProcessing root 62491/74729\nProcessing root 62501/74729\nProcessing root 62511/74729\nProcessing root 62521/74729\nProcessing root 62531/74729\nProcessing root 62541/74729\nProcessing root 62551/74729\nProcessing root 62561/74729\nProcessing root 62571/74729\nProcessing root 62581/74729\nProcessing root 62591/74729\nProcessing root 62601/74729\nProcessing root 62611/74729\nProcessing root 62621/74729\nProcessing root 62631/74729\nProcessing root 62641/74729\nProcessing root 62651/74729\nProcessing root 62661/74729\nProcessing root 62671/74729\nProcessing root 62681/74729\nProcessing root 62691/74729\nProcessing root 62701/74729\nProcessing root 62711/74729\nProcessing root 62721/74729\nProcessing root 62731/74729\nProcessing root 62741/74729\nProcessing root 62751/74729\nProcessing root 62761/74729\nProcessing root 62771/74729\nProcessing root 62781/74729\nProcessing root 62791/74729\nProcessing root 62801/74729\nProcessing root 62811/74729\nProcessing root 62821/74729\nProcessing root 62831/74729\nProcessing root 62841/74729\nProcessing root 62851/74729\nProcessing root 62861/74729\nProcessing root 62871/74729\nProcessing root 62881/74729\nProcessing root 62891/74729\nProcessing root 62901/74729\nProcessing root 62911/74729\nProcessing root 62921/74729\nProcessing root 62931/74729\nProcessing root 62941/74729\nProcessing root 62951/74729\nProcessing root 62961/74729\nProcessing root 62971/74729\nProcessing root 62981/74729\nProcessing root 62991/74729\nProcessing root 63001/74729\nProcessing root 63011/74729\nProcessing root 63021/74729\nProcessing root 63031/74729\nProcessing root 63041/74729\nProcessing root 63051/74729\nProcessing root 63061/74729\nProcessing root 63071/74729\nProcessing root 63081/74729\nProcessing root 63091/74729\nProcessing root 63101/74729\nProcessing root 63111/74729\nProcessing root 63121/74729\nProcessing root 63131/74729\nProcessing root 63141/74729\nProcessing root 63151/74729\nProcessing root 63161/74729\nProcessing root 63171/74729\nProcessing root 63181/74729\nProcessing root 63191/74729\nProcessing root 63201/74729\nProcessing root 63211/74729\nProcessing root 63221/74729\nProcessing root 63231/74729\nProcessing root 63241/74729\nProcessing root 63251/74729\nProcessing root 63261/74729\nProcessing root 63271/74729\nProcessing root 63281/74729\nProcessing root 63291/74729\nProcessing root 63301/74729\nProcessing root 63311/74729\nProcessing root 63321/74729\nProcessing root 63331/74729\nProcessing root 63341/74729\nProcessing root 63351/74729\nProcessing root 63361/74729\nProcessing root 63371/74729\nProcessing root 63381/74729\nProcessing root 63391/74729\nProcessing root 63401/74729\nProcessing root 63411/74729\nProcessing root 63421/74729\nProcessing root 63431/74729\nProcessing root 63441/74729\nProcessing root 63451/74729\nProcessing root 63461/74729\nProcessing root 63471/74729\nProcessing root 63481/74729\nProcessing root 63491/74729\nProcessing root 63501/74729\nProcessing root 63511/74729\nProcessing root 63521/74729\nProcessing root 63531/74729\nProcessing root 63541/74729\nProcessing root 63551/74729\nProcessing root 63561/74729\nProcessing root 63571/74729\nProcessing root 63581/74729\nProcessing root 63591/74729\nProcessing root 63601/74729\nProcessing root 63611/74729\nProcessing root 63621/74729\nProcessing root 63631/74729\nProcessing root 63641/74729\nProcessing root 63651/74729\nProcessing root 63661/74729\nProcessing root 63671/74729\nProcessing root 63681/74729\nProcessing root 63691/74729\nProcessing root 63701/74729\nProcessing root 63711/74729\nProcessing root 63721/74729\nProcessing root 63731/74729\nProcessing root 63741/74729\nProcessing root 63751/74729\nProcessing root 63761/74729\nProcessing root 63771/74729\nProcessing root 63781/74729\nProcessing root 63791/74729\nProcessing root 63801/74729\nProcessing root 63811/74729\nProcessing root 63821/74729\nProcessing root 63831/74729\nProcessing root 63841/74729\nProcessing root 63851/74729\nProcessing root 63861/74729\nProcessing root 63871/74729\nProcessing root 63881/74729\nProcessing root 63891/74729\nProcessing root 63901/74729\nProcessing root 63911/74729\nProcessing root 63921/74729\nProcessing root 63931/74729\nProcessing root 63941/74729\nProcessing root 63951/74729\nProcessing root 63961/74729\nProcessing root 63971/74729\nProcessing root 63981/74729\nProcessing root 63991/74729\nProcessing root 64001/74729\nProcessing root 64011/74729\nProcessing root 64021/74729\nProcessing root 64031/74729\nProcessing root 64041/74729\nProcessing root 64051/74729\nProcessing root 64061/74729\nProcessing root 64071/74729\nProcessing root 64081/74729\nProcessing root 64091/74729\nProcessing root 64101/74729\nProcessing root 64111/74729\nProcessing root 64121/74729\nProcessing root 64131/74729\nProcessing root 64141/74729\nProcessing root 64151/74729\nProcessing root 64161/74729\nProcessing root 64171/74729\nProcessing root 64181/74729\nProcessing root 64191/74729\nProcessing root 64201/74729\nProcessing root 64211/74729\nProcessing root 64221/74729\nProcessing root 64231/74729\nProcessing root 64241/74729\nProcessing root 64251/74729\nProcessing root 64261/74729\nProcessing root 64271/74729\nProcessing root 64281/74729\nProcessing root 64291/74729\nProcessing root 64301/74729\nProcessing root 64311/74729\nProcessing root 64321/74729\nProcessing root 64331/74729\nProcessing root 64341/74729\nProcessing root 64351/74729\nProcessing root 64361/74729\nProcessing root 64371/74729\nProcessing root 64381/74729\nProcessing root 64391/74729\nProcessing root 64401/74729\nProcessing root 64411/74729\nProcessing root 64421/74729\nProcessing root 64431/74729\nProcessing root 64441/74729\nProcessing root 64451/74729\nProcessing root 64461/74729\nProcessing root 64471/74729\nProcessing root 64481/74729\nProcessing root 64491/74729\nProcessing root 64501/74729\nProcessing root 64511/74729\nProcessing root 64521/74729\nProcessing root 64531/74729\nProcessing root 64541/74729\nProcessing root 64551/74729\nProcessing root 64561/74729\nProcessing root 64571/74729\nProcessing root 64581/74729\nProcessing root 64591/74729\nProcessing root 64601/74729\nProcessing root 64611/74729\nProcessing root 64621/74729\nProcessing root 64631/74729\nProcessing root 64641/74729\nProcessing root 64651/74729\nProcessing root 64661/74729\nProcessing root 64671/74729\nProcessing root 64681/74729\nProcessing root 64691/74729\nProcessing root 64701/74729\nProcessing root 64711/74729\nProcessing root 64721/74729\nProcessing root 64731/74729\nProcessing root 64741/74729\nProcessing root 64751/74729\nProcessing root 64761/74729\nProcessing root 64771/74729\nProcessing root 64781/74729\nProcessing root 64791/74729\nProcessing root 64801/74729\nProcessing root 64811/74729\nProcessing root 64821/74729\nProcessing root 64831/74729\nProcessing root 64841/74729\nProcessing root 64851/74729\nProcessing root 64861/74729\nProcessing root 64871/74729\nProcessing root 64881/74729\nProcessing root 64891/74729\nProcessing root 64901/74729\nProcessing root 64911/74729\nProcessing root 64921/74729\nProcessing root 64931/74729\nProcessing root 64941/74729\nProcessing root 64951/74729\nProcessing root 64961/74729\nProcessing root 64971/74729\nProcessing root 64981/74729\nProcessing root 64991/74729\nProcessing root 65001/74729\nProcessing root 65011/74729\nProcessing root 65021/74729\nProcessing root 65031/74729\nProcessing root 65041/74729\nProcessing root 65051/74729\nProcessing root 65061/74729\nProcessing root 65071/74729\nProcessing root 65081/74729\nProcessing root 65091/74729\nProcessing root 65101/74729\nProcessing root 65111/74729\nProcessing root 65121/74729\nProcessing root 65131/74729\nProcessing root 65141/74729\nProcessing root 65151/74729\nProcessing root 65161/74729\nProcessing root 65171/74729\nProcessing root 65181/74729\nProcessing root 65191/74729\nProcessing root 65201/74729\nProcessing root 65211/74729\nProcessing root 65221/74729\nProcessing root 65231/74729\nProcessing root 65241/74729\nProcessing root 65251/74729\nProcessing root 65261/74729\nProcessing root 65271/74729\nProcessing root 65281/74729\nProcessing root 65291/74729\nProcessing root 65301/74729\nProcessing root 65311/74729\nProcessing root 65321/74729\nProcessing root 65331/74729\nProcessing root 65341/74729\nProcessing root 65351/74729\nProcessing root 65361/74729\nProcessing root 65371/74729\nProcessing root 65381/74729\nProcessing root 65391/74729\nProcessing root 65401/74729\nProcessing root 65411/74729\nProcessing root 65421/74729\nProcessing root 65431/74729\nProcessing root 65441/74729\nProcessing root 65451/74729\nProcessing root 65461/74729\nProcessing root 65471/74729\nProcessing root 65481/74729\nProcessing root 65491/74729\nProcessing root 65501/74729\nProcessing root 65511/74729\nProcessing root 65521/74729\nProcessing root 65531/74729\nProcessing root 65541/74729\nProcessing root 65551/74729\nProcessing root 65561/74729\nProcessing root 65571/74729\nProcessing root 65581/74729\nProcessing root 65591/74729\nProcessing root 65601/74729\nProcessing root 65611/74729\nProcessing root 65621/74729\nProcessing root 65631/74729\nProcessing root 65641/74729\nProcessing root 65651/74729\nProcessing root 65661/74729\nProcessing root 65671/74729\nProcessing root 65681/74729\nProcessing root 65691/74729\nProcessing root 65701/74729\nProcessing root 65711/74729\nProcessing root 65721/74729\nProcessing root 65731/74729\nProcessing root 65741/74729\nProcessing root 65751/74729\nProcessing root 65761/74729\nProcessing root 65771/74729\nProcessing root 65781/74729\nProcessing root 65791/74729\nProcessing root 65801/74729\nProcessing root 65811/74729\nProcessing root 65821/74729\nProcessing root 65831/74729\nProcessing root 65841/74729\nProcessing root 65851/74729\nProcessing root 65861/74729\nProcessing root 65871/74729\nProcessing root 65881/74729\nProcessing root 65891/74729\nProcessing root 65901/74729\nProcessing root 65911/74729\nProcessing root 65921/74729\nProcessing root 65931/74729\nProcessing root 65941/74729\nProcessing root 65951/74729\nProcessing root 65961/74729\nProcessing root 65971/74729\nProcessing root 65981/74729\nProcessing root 65991/74729\nProcessing root 66001/74729\nProcessing root 66011/74729\nProcessing root 66021/74729\nProcessing root 66031/74729\nProcessing root 66041/74729\nProcessing root 66051/74729\nProcessing root 66061/74729\nProcessing root 66071/74729\nProcessing root 66081/74729\nProcessing root 66091/74729\nProcessing root 66101/74729\nProcessing root 66111/74729\nProcessing root 66121/74729\nProcessing root 66131/74729\nProcessing root 66141/74729\nProcessing root 66151/74729\nProcessing root 66161/74729\nProcessing root 66171/74729\nProcessing root 66181/74729\nProcessing root 66191/74729\nProcessing root 66201/74729\nProcessing root 66211/74729\nProcessing root 66221/74729\nProcessing root 66231/74729\nProcessing root 66241/74729\nProcessing root 66251/74729\nProcessing root 66261/74729\nProcessing root 66271/74729\nProcessing root 66281/74729\nProcessing root 66291/74729\nProcessing root 66301/74729\nProcessing root 66311/74729\nProcessing root 66321/74729\nProcessing root 66331/74729\nProcessing root 66341/74729\nProcessing root 66351/74729\nProcessing root 66361/74729\nProcessing root 66371/74729\nProcessing root 66381/74729\nProcessing root 66391/74729\nProcessing root 66401/74729\nProcessing root 66411/74729\nProcessing root 66421/74729\nProcessing root 66431/74729\nProcessing root 66441/74729\nProcessing root 66451/74729\nProcessing root 66461/74729\nProcessing root 66471/74729\nProcessing root 66481/74729\nProcessing root 66491/74729\nProcessing root 66501/74729\nProcessing root 66511/74729\nProcessing root 66521/74729\nProcessing root 66531/74729\nProcessing root 66541/74729\nProcessing root 66551/74729\nProcessing root 66561/74729\nProcessing root 66571/74729\nProcessing root 66581/74729\nProcessing root 66591/74729\nProcessing root 66601/74729\nProcessing root 66611/74729\nProcessing root 66621/74729\nProcessing root 66631/74729\nProcessing root 66641/74729\nProcessing root 66651/74729\nProcessing root 66661/74729\nProcessing root 66671/74729\nProcessing root 66681/74729\nProcessing root 66691/74729\nProcessing root 66701/74729\nProcessing root 66711/74729\nProcessing root 66721/74729\nProcessing root 66731/74729\nProcessing root 66741/74729\nProcessing root 66751/74729\nProcessing root 66761/74729\nProcessing root 66771/74729\nProcessing root 66781/74729\nProcessing root 66791/74729\nProcessing root 66801/74729\nProcessing root 66811/74729\nProcessing root 66821/74729\nProcessing root 66831/74729\nProcessing root 66841/74729\nProcessing root 66851/74729\nProcessing root 66861/74729\nProcessing root 66871/74729\nProcessing root 66881/74729\nProcessing root 66891/74729\nProcessing root 66901/74729\nProcessing root 66911/74729\nProcessing root 66921/74729\nProcessing root 66931/74729\nProcessing root 66941/74729\nProcessing root 66951/74729\nProcessing root 66961/74729\nProcessing root 66971/74729\nProcessing root 66981/74729\nProcessing root 66991/74729\nProcessing root 67001/74729\nProcessing root 67011/74729\nProcessing root 67021/74729\nProcessing root 67031/74729\nProcessing root 67041/74729\nProcessing root 67051/74729\nProcessing root 67061/74729\nProcessing root 67071/74729\nProcessing root 67081/74729\nProcessing root 67091/74729\nProcessing root 67101/74729\nProcessing root 67111/74729\nProcessing root 67121/74729\nProcessing root 67131/74729\nProcessing root 67141/74729\nProcessing root 67151/74729\nProcessing root 67161/74729\nProcessing root 67171/74729\nProcessing root 67181/74729\nProcessing root 67191/74729\nProcessing root 67201/74729\nProcessing root 67211/74729\nProcessing root 67221/74729\nProcessing root 67231/74729\nProcessing root 67241/74729\nProcessing root 67251/74729\nProcessing root 67261/74729\nProcessing root 67271/74729\nProcessing root 67281/74729\nProcessing root 67291/74729\nProcessing root 67301/74729\nProcessing root 67311/74729\nProcessing root 67321/74729\nProcessing root 67331/74729\nProcessing root 67341/74729\nProcessing root 67351/74729\nProcessing root 67361/74729\nProcessing root 67371/74729\nProcessing root 67381/74729\nProcessing root 67391/74729\nProcessing root 67401/74729\nProcessing root 67411/74729\nProcessing root 67421/74729\nProcessing root 67431/74729\nProcessing root 67441/74729\nProcessing root 67451/74729\nProcessing root 67461/74729\nProcessing root 67471/74729\nProcessing root 67481/74729\nProcessing root 67491/74729\nProcessing root 67501/74729\nProcessing root 67511/74729\nProcessing root 67521/74729\nProcessing root 67531/74729\nProcessing root 67541/74729\nProcessing root 67551/74729\nProcessing root 67561/74729\nProcessing root 67571/74729\nProcessing root 67581/74729\nProcessing root 67591/74729\nProcessing root 67601/74729\nProcessing root 67611/74729\nProcessing root 67621/74729\nProcessing root 67631/74729\nProcessing root 67641/74729\nProcessing root 67651/74729\nProcessing root 67661/74729\nProcessing root 67671/74729\nProcessing root 67681/74729\nProcessing root 67691/74729\nProcessing root 67701/74729\nProcessing root 67711/74729\nProcessing root 67721/74729\nProcessing root 67731/74729\nProcessing root 67741/74729\nProcessing root 67751/74729\nProcessing root 67761/74729\nProcessing root 67771/74729\nProcessing root 67781/74729\nProcessing root 67791/74729\nProcessing root 67801/74729\nProcessing root 67811/74729\nProcessing root 67821/74729\nProcessing root 67831/74729\nProcessing root 67841/74729\nProcessing root 67851/74729\nProcessing root 67861/74729\nProcessing root 67871/74729\nProcessing root 67881/74729\nProcessing root 67891/74729\nProcessing root 67901/74729\nProcessing root 67911/74729\nProcessing root 67921/74729\nProcessing root 67931/74729\nProcessing root 67941/74729\nProcessing root 67951/74729\nProcessing root 67961/74729\nProcessing root 67971/74729\nProcessing root 67981/74729\nProcessing root 67991/74729\nProcessing root 68001/74729\nProcessing root 68011/74729\nProcessing root 68021/74729\nProcessing root 68031/74729\nProcessing root 68041/74729\nProcessing root 68051/74729\nProcessing root 68061/74729\nProcessing root 68071/74729\nProcessing root 68081/74729\nProcessing root 68091/74729\nProcessing root 68101/74729\nProcessing root 68111/74729\nProcessing root 68121/74729\nProcessing root 68131/74729\nProcessing root 68141/74729\nProcessing root 68151/74729\nProcessing root 68161/74729\nProcessing root 68171/74729\nProcessing root 68181/74729\nProcessing root 68191/74729\nProcessing root 68201/74729\nProcessing root 68211/74729\nProcessing root 68221/74729\nProcessing root 68231/74729\nProcessing root 68241/74729\nProcessing root 68251/74729\nProcessing root 68261/74729\nProcessing root 68271/74729\nProcessing root 68281/74729\nProcessing root 68291/74729\nProcessing root 68301/74729\nProcessing root 68311/74729\nProcessing root 68321/74729\nProcessing root 68331/74729\nProcessing root 68341/74729\nProcessing root 68351/74729\nProcessing root 68361/74729\nProcessing root 68371/74729\nProcessing root 68381/74729\nProcessing root 68391/74729\nProcessing root 68401/74729\nProcessing root 68411/74729\nProcessing root 68421/74729\nProcessing root 68431/74729\nProcessing root 68441/74729\nProcessing root 68451/74729\nProcessing root 68461/74729\nProcessing root 68471/74729\nProcessing root 68481/74729\nProcessing root 68491/74729\nProcessing root 68501/74729\nProcessing root 68511/74729\nProcessing root 68521/74729\nProcessing root 68531/74729\nProcessing root 68541/74729\nProcessing root 68551/74729\nProcessing root 68561/74729\nProcessing root 68571/74729\nProcessing root 68581/74729\nProcessing root 68591/74729\nProcessing root 68601/74729\nProcessing root 68611/74729\nProcessing root 68621/74729\nProcessing root 68631/74729\nProcessing root 68641/74729\nProcessing root 68651/74729\nProcessing root 68661/74729\nProcessing root 68671/74729\nProcessing root 68681/74729\nProcessing root 68691/74729\nProcessing root 68701/74729\nProcessing root 68711/74729\nProcessing root 68721/74729\nProcessing root 68731/74729\nProcessing root 68741/74729\nProcessing root 68751/74729\nProcessing root 68761/74729\nProcessing root 68771/74729\nProcessing root 68781/74729\nProcessing root 68791/74729\nProcessing root 68801/74729\nProcessing root 68811/74729\nProcessing root 68821/74729\nProcessing root 68831/74729\nProcessing root 68841/74729\nProcessing root 68851/74729\nProcessing root 68861/74729\nProcessing root 68871/74729\nProcessing root 68881/74729\nProcessing root 68891/74729\nProcessing root 68901/74729\nProcessing root 68911/74729\nProcessing root 68921/74729\nProcessing root 68931/74729\nProcessing root 68941/74729\nProcessing root 68951/74729\nProcessing root 68961/74729\nProcessing root 68971/74729\nProcessing root 68981/74729\nProcessing root 68991/74729\nProcessing root 69001/74729\nProcessing root 69011/74729\nProcessing root 69021/74729\nProcessing root 69031/74729\nProcessing root 69041/74729\nProcessing root 69051/74729\nProcessing root 69061/74729\nProcessing root 69071/74729\nProcessing root 69081/74729\nProcessing root 69091/74729\nProcessing root 69101/74729\nProcessing root 69111/74729\nProcessing root 69121/74729\nProcessing root 69131/74729\nProcessing root 69141/74729\nProcessing root 69151/74729\nProcessing root 69161/74729\nProcessing root 69171/74729\nProcessing root 69181/74729\nProcessing root 69191/74729\nProcessing root 69201/74729\nProcessing root 69211/74729\nProcessing root 69221/74729\nProcessing root 69231/74729\nProcessing root 69241/74729\nProcessing root 69251/74729\nProcessing root 69261/74729\nProcessing root 69271/74729\nProcessing root 69281/74729\nProcessing root 69291/74729\nProcessing root 69301/74729\nProcessing root 69311/74729\nProcessing root 69321/74729\nProcessing root 69331/74729\nProcessing root 69341/74729\nProcessing root 69351/74729\nProcessing root 69361/74729\nProcessing root 69371/74729\nProcessing root 69381/74729\nProcessing root 69391/74729\nProcessing root 69401/74729\nProcessing root 69411/74729\nProcessing root 69421/74729\nProcessing root 69431/74729\nProcessing root 69441/74729\nProcessing root 69451/74729\nProcessing root 69461/74729\nProcessing root 69471/74729\nProcessing root 69481/74729\nProcessing root 69491/74729\nProcessing root 69501/74729\nProcessing root 69511/74729\nProcessing root 69521/74729\nProcessing root 69531/74729\nProcessing root 69541/74729\nProcessing root 69551/74729\nProcessing root 69561/74729\nProcessing root 69571/74729\nProcessing root 69581/74729\nProcessing root 69591/74729\nProcessing root 69601/74729\nProcessing root 69611/74729\nProcessing root 69621/74729\nProcessing root 69631/74729\nProcessing root 69641/74729\nProcessing root 69651/74729\nProcessing root 69661/74729\nProcessing root 69671/74729\nProcessing root 69681/74729\nProcessing root 69691/74729\nProcessing root 69701/74729\nProcessing root 69711/74729\nProcessing root 69721/74729\nProcessing root 69731/74729\nProcessing root 69741/74729\nProcessing root 69751/74729\nProcessing root 69761/74729\nProcessing root 69771/74729\nProcessing root 69781/74729\nProcessing root 69791/74729\nProcessing root 69801/74729\nProcessing root 69811/74729\nProcessing root 69821/74729\nProcessing root 69831/74729\nProcessing root 69841/74729\nProcessing root 69851/74729\nProcessing root 69861/74729\nProcessing root 69871/74729\nProcessing root 69881/74729\nProcessing root 69891/74729\nProcessing root 69901/74729\nProcessing root 69911/74729\nProcessing root 69921/74729\nProcessing root 69931/74729\nProcessing root 69941/74729\nProcessing root 69951/74729\nProcessing root 69961/74729\nProcessing root 69971/74729\nProcessing root 69981/74729\nProcessing root 69991/74729\nProcessing root 70001/74729\nProcessing root 70011/74729\nProcessing root 70021/74729\nProcessing root 70031/74729\nProcessing root 70041/74729\nProcessing root 70051/74729\nProcessing root 70061/74729\nProcessing root 70071/74729\nProcessing root 70081/74729\nProcessing root 70091/74729\nProcessing root 70101/74729\nProcessing root 70111/74729\nProcessing root 70121/74729\nProcessing root 70131/74729\nProcessing root 70141/74729\nProcessing root 70151/74729\nProcessing root 70161/74729\nProcessing root 70171/74729\nProcessing root 70181/74729\nProcessing root 70191/74729\nProcessing root 70201/74729\nProcessing root 70211/74729\nProcessing root 70221/74729\nProcessing root 70231/74729\nProcessing root 70241/74729\nProcessing root 70251/74729\nProcessing root 70261/74729\nProcessing root 70271/74729\nProcessing root 70281/74729\nProcessing root 70291/74729\nProcessing root 70301/74729\nProcessing root 70311/74729\nProcessing root 70321/74729\nProcessing root 70331/74729\nProcessing root 70341/74729\nProcessing root 70351/74729\nProcessing root 70361/74729\nProcessing root 70371/74729\nProcessing root 70381/74729\nProcessing root 70391/74729\nProcessing root 70401/74729\nProcessing root 70411/74729\nProcessing root 70421/74729\nProcessing root 70431/74729\nProcessing root 70441/74729\nProcessing root 70451/74729\nProcessing root 70461/74729\nProcessing root 70471/74729\nProcessing root 70481/74729\nProcessing root 70491/74729\nProcessing root 70501/74729\nProcessing root 70511/74729\nProcessing root 70521/74729\nProcessing root 70531/74729\nProcessing root 70541/74729\nProcessing root 70551/74729\nProcessing root 70561/74729\nProcessing root 70571/74729\nProcessing root 70581/74729\nProcessing root 70591/74729\nProcessing root 70601/74729\nProcessing root 70611/74729\nProcessing root 70621/74729\nProcessing root 70631/74729\nProcessing root 70641/74729\nProcessing root 70651/74729\nProcessing root 70661/74729\nProcessing root 70671/74729\nProcessing root 70681/74729\nProcessing root 70691/74729\nProcessing root 70701/74729\nProcessing root 70711/74729\nProcessing root 70721/74729\nProcessing root 70731/74729\nProcessing root 70741/74729\nProcessing root 70751/74729\nProcessing root 70761/74729\nProcessing root 70771/74729\nProcessing root 70781/74729\nProcessing root 70791/74729\nProcessing root 70801/74729\nProcessing root 70811/74729\nProcessing root 70821/74729\nProcessing root 70831/74729\nProcessing root 70841/74729\nProcessing root 70851/74729\nProcessing root 70861/74729\nProcessing root 70871/74729\nProcessing root 70881/74729\nProcessing root 70891/74729\nProcessing root 70901/74729\nProcessing root 70911/74729\nProcessing root 70921/74729\nProcessing root 70931/74729\nProcessing root 70941/74729\nProcessing root 70951/74729\nProcessing root 70961/74729\nProcessing root 70971/74729\nProcessing root 70981/74729\nProcessing root 70991/74729\nProcessing root 71001/74729\nProcessing root 71011/74729\nProcessing root 71021/74729\nProcessing root 71031/74729\nProcessing root 71041/74729\nProcessing root 71051/74729\nProcessing root 71061/74729\nProcessing root 71071/74729\nProcessing root 71081/74729\nProcessing root 71091/74729\nProcessing root 71101/74729\nProcessing root 71111/74729\nProcessing root 71121/74729\nProcessing root 71131/74729\nProcessing root 71141/74729\nProcessing root 71151/74729\nProcessing root 71161/74729\nProcessing root 71171/74729\nProcessing root 71181/74729\nProcessing root 71191/74729\nProcessing root 71201/74729\nProcessing root 71211/74729\nProcessing root 71221/74729\nProcessing root 71231/74729\nProcessing root 71241/74729\nProcessing root 71251/74729\nProcessing root 71261/74729\nProcessing root 71271/74729\nProcessing root 71281/74729\nProcessing root 71291/74729\nProcessing root 71301/74729\nProcessing root 71311/74729\nProcessing root 71321/74729\nProcessing root 71331/74729\nProcessing root 71341/74729\nProcessing root 71351/74729\nProcessing root 71361/74729\nProcessing root 71371/74729\nProcessing root 71381/74729\nProcessing root 71391/74729\nProcessing root 71401/74729\nProcessing root 71411/74729\nProcessing root 71421/74729\nProcessing root 71431/74729\nProcessing root 71441/74729\nProcessing root 71451/74729\nProcessing root 71461/74729\nProcessing root 71471/74729\nProcessing root 71481/74729\nProcessing root 71491/74729\nProcessing root 71501/74729\nProcessing root 71511/74729\nProcessing root 71521/74729\nProcessing root 71531/74729\nProcessing root 71541/74729\nProcessing root 71551/74729\nProcessing root 71561/74729\nProcessing root 71571/74729\nProcessing root 71581/74729\nProcessing root 71591/74729\nProcessing root 71601/74729\nProcessing root 71611/74729\nProcessing root 71621/74729\nProcessing root 71631/74729\nProcessing root 71641/74729\nProcessing root 71651/74729\nProcessing root 71661/74729\nProcessing root 71671/74729\nProcessing root 71681/74729\nProcessing root 71691/74729\nProcessing root 71701/74729\nProcessing root 71711/74729\nProcessing root 71721/74729\nProcessing root 71731/74729\nProcessing root 71741/74729\nProcessing root 71751/74729\nProcessing root 71761/74729\nProcessing root 71771/74729\nProcessing root 71781/74729\nProcessing root 71791/74729\nProcessing root 71801/74729\nProcessing root 71811/74729\nProcessing root 71821/74729\nProcessing root 71831/74729\nProcessing root 71841/74729\nProcessing root 71851/74729\nProcessing root 71861/74729\nProcessing root 71871/74729\nProcessing root 71881/74729\nProcessing root 71891/74729\nProcessing root 71901/74729\nProcessing root 71911/74729\nProcessing root 71921/74729\nProcessing root 71931/74729\nProcessing root 71941/74729\nProcessing root 71951/74729\nProcessing root 71961/74729\nProcessing root 71971/74729\nProcessing root 71981/74729\nProcessing root 71991/74729\nProcessing root 72001/74729\nProcessing root 72011/74729\nProcessing root 72021/74729\nProcessing root 72031/74729\nProcessing root 72041/74729\nProcessing root 72051/74729\nProcessing root 72061/74729\nProcessing root 72071/74729\nProcessing root 72081/74729\nProcessing root 72091/74729\nProcessing root 72101/74729\nProcessing root 72111/74729\nProcessing root 72121/74729\nProcessing root 72131/74729\nProcessing root 72141/74729\nProcessing root 72151/74729\nProcessing root 72161/74729\nProcessing root 72171/74729\nProcessing root 72181/74729\nProcessing root 72191/74729\nProcessing root 72201/74729\nProcessing root 72211/74729\nProcessing root 72221/74729\nProcessing root 72231/74729\nProcessing root 72241/74729\nProcessing root 72251/74729\nProcessing root 72261/74729\nProcessing root 72271/74729\nProcessing root 72281/74729\nProcessing root 72291/74729\nProcessing root 72301/74729\nProcessing root 72311/74729\nProcessing root 72321/74729\nProcessing root 72331/74729\nProcessing root 72341/74729\nProcessing root 72351/74729\nProcessing root 72361/74729\nProcessing root 72371/74729\nProcessing root 72381/74729\nProcessing root 72391/74729\nProcessing root 72401/74729\nProcessing root 72411/74729\nProcessing root 72421/74729\nProcessing root 72431/74729\nProcessing root 72441/74729\nProcessing root 72451/74729\nProcessing root 72461/74729\nProcessing root 72471/74729\nProcessing root 72481/74729\nProcessing root 72491/74729\nProcessing root 72501/74729\nProcessing root 72511/74729\nProcessing root 72521/74729\nProcessing root 72531/74729\nProcessing root 72541/74729\nProcessing root 72551/74729\nProcessing root 72561/74729\nProcessing root 72571/74729\nProcessing root 72581/74729\nProcessing root 72591/74729\nProcessing root 72601/74729\nProcessing root 72611/74729\nProcessing root 72621/74729\nProcessing root 72631/74729\nProcessing root 72641/74729\nProcessing root 72651/74729\nProcessing root 72661/74729\nProcessing root 72671/74729\nProcessing root 72681/74729\nProcessing root 72691/74729\nProcessing root 72701/74729\nProcessing root 72711/74729\nProcessing root 72721/74729\nProcessing root 72731/74729\nProcessing root 72741/74729\nProcessing root 72751/74729\nProcessing root 72761/74729\nProcessing root 72771/74729\nProcessing root 72781/74729\nProcessing root 72791/74729\nProcessing root 72801/74729\nProcessing root 72811/74729\nProcessing root 72821/74729\nProcessing root 72831/74729\nProcessing root 72841/74729\nProcessing root 72851/74729\nProcessing root 72861/74729\nProcessing root 72871/74729\nProcessing root 72881/74729\nProcessing root 72891/74729\nProcessing root 72901/74729\nProcessing root 72911/74729\nProcessing root 72921/74729\nProcessing root 72931/74729\nProcessing root 72941/74729\nProcessing root 72951/74729\nProcessing root 72961/74729\nProcessing root 72971/74729\nProcessing root 72981/74729\nProcessing root 72991/74729\nProcessing root 73001/74729\nProcessing root 73011/74729\nProcessing root 73021/74729\nProcessing root 73031/74729\nProcessing root 73041/74729\nProcessing root 73051/74729\nProcessing root 73061/74729\nProcessing root 73071/74729\nProcessing root 73081/74729\nProcessing root 73091/74729\nProcessing root 73101/74729\nProcessing root 73111/74729\nProcessing root 73121/74729\nProcessing root 73131/74729\nProcessing root 73141/74729\nProcessing root 73151/74729\nProcessing root 73161/74729\nProcessing root 73171/74729\nProcessing root 73181/74729\nProcessing root 73191/74729\nProcessing root 73201/74729\nProcessing root 73211/74729\nProcessing root 73221/74729\nProcessing root 73231/74729\nProcessing root 73241/74729\nProcessing root 73251/74729\nProcessing root 73261/74729\nProcessing root 73271/74729\nProcessing root 73281/74729\nProcessing root 73291/74729\nProcessing root 73301/74729\nProcessing root 73311/74729\nProcessing root 73321/74729\nProcessing root 73331/74729\nProcessing root 73341/74729\nProcessing root 73351/74729\nProcessing root 73361/74729\nProcessing root 73371/74729\nProcessing root 73381/74729\nProcessing root 73391/74729\nProcessing root 73401/74729\nProcessing root 73411/74729\nProcessing root 73421/74729\nProcessing root 73431/74729\nProcessing root 73441/74729\nProcessing root 73451/74729\nProcessing root 73461/74729\nProcessing root 73471/74729\nProcessing root 73481/74729\nProcessing root 73491/74729\nProcessing root 73501/74729\nProcessing root 73511/74729\nProcessing root 73521/74729\nProcessing root 73531/74729\nProcessing root 73541/74729\nProcessing root 73551/74729\nProcessing root 73561/74729\nProcessing root 73571/74729\nProcessing root 73581/74729\nProcessing root 73591/74729\nProcessing root 73601/74729\nProcessing root 73611/74729\nProcessing root 73621/74729\nProcessing root 73631/74729\nProcessing root 73641/74729\nProcessing root 73651/74729\nProcessing root 73661/74729\nProcessing root 73671/74729\nProcessing root 73681/74729\nProcessing root 73691/74729\nProcessing root 73701/74729\nProcessing root 73711/74729\nProcessing root 73721/74729\nProcessing root 73731/74729\nProcessing root 73741/74729\nProcessing root 73751/74729\nProcessing root 73761/74729\nProcessing root 73771/74729\nProcessing root 73781/74729\nProcessing root 73791/74729\nProcessing root 73801/74729\nProcessing root 73811/74729\nProcessing root 73821/74729\nProcessing root 73831/74729\nProcessing root 73841/74729\nProcessing root 73851/74729\nProcessing root 73861/74729\nProcessing root 73871/74729\nProcessing root 73881/74729\nProcessing root 73891/74729\nProcessing root 73901/74729\nProcessing root 73911/74729\nProcessing root 73921/74729\nProcessing root 73931/74729\nProcessing root 73941/74729\nProcessing root 73951/74729\nProcessing root 73961/74729\nProcessing root 73971/74729\nProcessing root 73981/74729\nProcessing root 73991/74729\nProcessing root 74001/74729\nProcessing root 74011/74729\nProcessing root 74021/74729\nProcessing root 74031/74729\nProcessing root 74041/74729\nProcessing root 74051/74729\nProcessing root 74061/74729\nProcessing root 74071/74729\nProcessing root 74081/74729\nProcessing root 74091/74729\nProcessing root 74101/74729\nProcessing root 74111/74729\nProcessing root 74121/74729\nProcessing root 74131/74729\nProcessing root 74141/74729\nProcessing root 74151/74729\nProcessing root 74161/74729\nProcessing root 74171/74729\nProcessing root 74181/74729\nProcessing root 74191/74729\nProcessing root 74201/74729\nProcessing root 74211/74729\nProcessing root 74221/74729\nProcessing root 74231/74729\nProcessing root 74241/74729\nProcessing root 74251/74729\nProcessing root 74261/74729\nProcessing root 74271/74729\nProcessing root 74281/74729\nProcessing root 74291/74729\nProcessing root 74301/74729\nProcessing root 74311/74729\nProcessing root 74321/74729\nProcessing root 74331/74729\nProcessing root 74341/74729\nProcessing root 74351/74729\nProcessing root 74361/74729\nProcessing root 74371/74729\nProcessing root 74381/74729\nProcessing root 74391/74729\nProcessing root 74401/74729\nProcessing root 74411/74729\nProcessing root 74421/74729\nProcessing root 74431/74729\nProcessing root 74441/74729\nProcessing root 74451/74729\nProcessing root 74461/74729\nProcessing root 74471/74729\nProcessing root 74481/74729\nProcessing root 74491/74729\nProcessing root 74501/74729\nProcessing root 74511/74729\nProcessing root 74521/74729\nProcessing root 74531/74729\nProcessing root 74541/74729\nProcessing root 74551/74729\nProcessing root 74561/74729\nProcessing root 74571/74729\nProcessing root 74581/74729\nProcessing root 74591/74729\nProcessing root 74601/74729\nProcessing root 74611/74729\nProcessing root 74621/74729\nProcessing root 74631/74729\nProcessing root 74641/74729\nProcessing root 74651/74729\nProcessing root 74661/74729\nProcessing root 74671/74729\nProcessing root 74681/74729\nProcessing root 74691/74729\nProcessing root 74701/74729\nProcessing root 74711/74729\nProcessing root 74721/74729\n</pre> In\u00a0[70]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=240, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=240, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 167 nodes and 5784 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([167, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 5784 nodes and 3542 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3542])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 3542 nodes and 812 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3542, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([812])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 812 nodes and 156 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([812, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([156])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre>"},{"location":"tutorial/temporal_graphs/#temporal-graphs-and-path-data","title":"Temporal Graphs and Path Data\u00b6","text":""},{"location":"tutorial/temporal_graphs/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/temporal_graphs/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In this tutorial we will introduce the representation of temporal graph data in the <code>Temporal Graph</code> class and how such data can be used to calculate time respecting paths.</p>"},{"location":"tutorial/temporal_graphs/#temporal-graphs","title":"Temporal Graphs\u00b6","text":""},{"location":"tutorial/temporal_graphs/#extracting-time-respecting-paths","title":"Extracting Time-Respecting Paths\u00b6","text":""},{"location":"tutorial/temporal_graphs/#higher-order-de-bruijn-graph-models-for-time-respecting-paths","title":"Higher-Order De Bruijn Graph Models for Time-Respecting Paths\u00b6","text":""},{"location":"tutorial/temporal_graphs/#analysis-of-empirical-temporal-graphs","title":"Analysis of empirical temporal graphs\u00b6","text":""},{"location":"tutorial/temporal_shortest_paths/","title":"Temporal shortest paths","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\nimport torch\n\nfrom scipy.sparse.csgraph import bellman_ford, dijkstra\nimport numpy as np\n\nfrom collections import defaultdict\n\n\nfrom tqdm import tqdm\n</pre> import pathpyG as pp from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index import torch  from scipy.sparse.csgraph import bellman_ford, dijkstra import numpy as np  from collections import defaultdict   from tqdm import tqdm In\u00a0[2]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected()\nprint(t_sp)\nprint(torch.unique(t_sp.data.t).size(0))\n</pre> t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected() print(t_sp) print(torch.unique(t_sp.data.t).size(0)) <pre>Temporal Graph with 327 nodes, 11636 unique edges and 377016 events in [1385982080.0, 1386345600.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\n1157\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 't', 'src'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[2]: Copied! <pre>t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges')\nprint(t_ants)\n</pre> t_ants = pp.TemporalGraph.from_csv('../data/ants_2_2_val.tedges') print(t_ants) <pre>Temporal Graph with 68 nodes, 506 unique edges and 1045 events in [899.0, 1796.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1045])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 't', 'src'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[3]: Copied! <pre>c = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60)\nprint(c)\n</pre> c = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 5479.47it/s]</pre> <pre>Created temporal event DAG with 1181 nodes and 4023 edges\n[[ 0.  1. inf ... inf inf inf]\n [ 1.  0. inf ... inf inf inf]\n [ 5.  3.  0. ...  2. inf inf]\n ...\n [inf inf inf ...  0. inf inf]\n [inf inf inf ... inf  0. inf]\n [inf inf inf ...  1. inf  0.]]\n{'JJJJ': 1399.0180458430464, 'WGG_': 1491.1753968253968, '_Y_B': 1461.7166666666667, 'HHHH': 996.0666666666666, 'WGRB': 1834.2047619047619, 'WYWY': 1540.441666666667, 'WY_G': 761.1371794871794, 'XXXX': 1670.8789682539682, 'LLLL': 1182.7095238095237, 'FFFF': 1062.2448773448773, 'WYG_': 1978.7333333333331, 'WW__': 1790.2027777777776, 'WRWB': 1743.196428571429, 'AAAA': 581.3047619047619, 'WGYW': 1155.8297619047619, 'WBYY': 968.8944444444444, '_R__': 880.7575396825396, 'WYBG': 1448.1039682539683, 'W__W': 1546.319877344877, 'RRRR': 924.1214285714285, 'WYRW': 1601.938095238095, 'WYYB': 865.6825396825396, 'WG_W': 1494.8178571428573, 'WRR_': 1195.2853174603176, 'W__G': 867.9182900432901, '_WRR': 622.8873015873016, 'WY_R': 1549.3750000000002, '_YYY': 1706.9047619047617, 'WRGG': 1571.4158730158733, 'WWGY': 1374.6964285714284, 'WW_W': 1325.6428571428573, 'W_W_': 842.7908730158728, 'WYYR': 798.6825396825395, 'ZZZZ': 662.777922077922, 'W_RG': 1339.8936507936507, 'WBGW': 512.55, 'WBGG': 1543.3130952380955, 'WWRY': 965.0658730158731, 'W___': 518.640909090909, 'VVVV': 394.82142857142856, 'WGGY': 402.0, 'WG__': 402.0, 'WY__': 1094.4130952380951, 'W_GY': 847.5990842490843, 'WYWW': 383.8191197691197, 'OOOO': 866.3738095238094, 'W_BG': 1306.0214285714287, 'TTTT': 549.4, 'WBWY': 1183.2944444444443, 'WWY_': 1060.354761904762, 'WBGR': 67.0, 'WGWY': 597.4166666666666, 'PPPP': 1146.8166666666664, 'WGGW': 917.4214285714285, 'EEEE': 617.1976190476189, '__YR': 134.0, 'WYYG': 548.8972582972583, 'WGGG': 207.70000000000002, 'IIII': 409.81666666666666, 'MMMM': 201.0, 'UUUU': 67.0, 'W_WG': 67.0, 'WYY_': 134.0, 'WWR_': 134.0, 'QQQQ': 415.4, 'WR__': 1117.5440476190474, 'W_GW': 167.5, 'AAAB': 0.0}\n</pre> <pre>\n</pre> In\u00a0[47]: Copied! <pre>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nc = pp.algorithms.centrality.temporal_closeness_centrality(t, 5)\nprint(c)\n</pre> tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),               ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),               ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),               ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),               ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)] t = pp.TemporalGraph.from_edge_list(tedges) c = pp.algorithms.centrality.temporal_closeness_centrality(t, 5) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:00&lt;00:00, 5773.07it/s]</pre> <pre>Created temporal event DAG with 38 nodes and 47 edges\n(9, 38)\n(9, 9)\n[[ 0.  1.  1.  3.  3. inf  1.  2. inf]\n [inf  0.  1.  2.  2.  1. inf inf  1.]\n [ 2. inf  0.  1.  1.  1.  3.  1.  1.]\n [inf inf inf  0. inf inf inf inf inf]\n [inf inf inf inf  0. inf inf inf inf]\n [ 1. inf inf inf inf  0.  2.  1. inf]\n [inf inf inf inf inf inf  0.  1. inf]\n [inf inf inf inf inf  1. inf  0.  1.]\n [inf  1. inf inf inf inf inf inf  0.]]\n{'a': 12.0, 'b': 16.0, 'c': 16.0, 'd': 14.666666666666666, 'e': 14.666666666666666, 'f': 24.0, 'g': 14.666666666666666, 'h': 28.0, 'i': 24.0}\n</pre> <pre>\n</pre> In\u00a0[49]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2), (1,4,3)])\nprint(t)\n</pre> t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2), (1,4,3)]) print(t) <pre>Temporal Graph with 5 nodes, 6 unique edges and 6 events in [0.0, 3.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 't', 'src'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[5]: Copied! <pre>c = pp.algorithms.centrality.temporal_closeness_centrality(t, delta=1)\nprint(c)\n</pre> c = pp.algorithms.centrality.temporal_closeness_centrality(t, delta=1) print(c) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 262.99it/s]</pre> <pre>Created temporal event DAG with 17 nodes and 15 edges\n{0.0: 0.0, 1.0: 4.0, 2.0: 8.0, 3.0: 6.0, 4.0: 9.333333333333332}\n</pre> <pre>\n</pre> In\u00a0[2]: Copied! <pre># old code with explosive memory usage due to computation of all second-order edges irrespective of time stamps\ndef lift_order_not_efficient(g: pp.TemporalGraph, delta=1):\n    # first-order edge index\n    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n    print(edge_index)\n    # second-order edge index with time-respective filtering\n    null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))    \n    # Update node sequences\n    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n    # Remove non-time-respecting higher-order edges\n    time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n    non_negative_mask = time_diff &gt; 0\n    delta_mask = time_diff &lt;= delta\n    time_respecting_mask = non_negative_mask &amp; delta_mask\n    edge_index = null_model_edge_index[:, time_respecting_mask]\n    return edge_index\n</pre> # old code with explosive memory usage due to computation of all second-order edges irrespective of time stamps def lift_order_not_efficient(g: pp.TemporalGraph, delta=1):     # first-order edge index     edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)     node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)     print(edge_index)     # second-order edge index with time-respective filtering     null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))         # Update node sequences     node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)     # Remove non-time-respecting higher-order edges     time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]     non_negative_mask = time_diff &gt; 0     delta_mask = time_diff &lt;= delta     time_respecting_mask = non_negative_mask &amp; delta_mask     edge_index = null_model_edge_index[:, time_respecting_mask]     return edge_index In\u00a0[3]: Copied! <pre># new memory-efficient code\ndef lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):\n\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.t\n    # print(edge_index)\n\n    indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)\n\n    unique_t = torch.unique(timestamps, sorted=True)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for i in tqdm(range(unique_t.size(0))):\n        t = unique_t[i]\n        #print('timestamp index ', i)\n        #print('timestamp ', t)\n        \n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = (timestamps == t)\n        src_edges = edge_index[:,src_time_mask]\n        src_edge_idx = indices[src_time_mask]\n        #print(src_edges)\n        #print(src_edge_idx)\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)\n        dst_edges = edge_index[:,dst_time_mask]        \n        dst_edge_idx = indices[dst_time_mask]\n        #print(dst_edges)\n        #print(dst_edge_idx)\n\n        if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:\n\n            # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges        \n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n            src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n            dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n            #print(src_edges)\n            #print(dst_edges)\n            ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n            second_order.append(ho_edge_index)\n            #print(ho_edge_index) \n            \n            # #print('dst', dst)\n            # src_mask = (edge_index[:,mask][0]==dst)\n            # ctd = edge_index[:,mask][:,src_mask]\n            # #print('continuations', ctd)\n            # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]        \n            # #print('ctd indx', ctd_indices)\n            # count += ctd_indices.size(0)\n    ho_index = torch.cat(second_order, dim=1)    \n    return ho_index\n</pre> # new memory-efficient code def lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):      # first-order edge index     edge_index, timestamps = g.data.edge_index, g.data.t     # print(edge_index)      indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)      unique_t = torch.unique(timestamps, sorted=True)     second_order = []      # lift order: find possible continuations for edges in each time stamp     for i in tqdm(range(unique_t.size(0))):         t = unique_t[i]         #print('timestamp index ', i)         #print('timestamp ', t)                  # find indices of all source edges that occur at unique timestamp t         src_time_mask = (timestamps == t)         src_edges = edge_index[:,src_time_mask]         src_edge_idx = indices[src_time_mask]         #print(src_edges)         #print(src_edge_idx)          # find indices of all edges that can possibly continue edges occurring at time t for the given delta         dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)         dst_edges = edge_index[:,dst_time_mask]                 dst_edge_idx = indices[dst_time_mask]         #print(dst_edges)         #print(dst_edge_idx)          if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:              # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges                     x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()             src_edges = torch.index_select(edge_index, dim=1, index=x[0])             dst_edges = torch.index_select(edge_index, dim=1, index=x[1])             #print(src_edges)             #print(dst_edges)             ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]             second_order.append(ho_edge_index)             #print(ho_edge_index)                           # #print('dst', dst)             # src_mask = (edge_index[:,mask][0]==dst)             # ctd = edge_index[:,mask][:,src_mask]             # #print('continuations', ctd)             # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]                     # #print('ctd indx', ctd_indices)             # count += ctd_indices.size(0)     ho_index = torch.cat(second_order, dim=1)         return ho_index In\u00a0[5]: Copied! <pre>def fo_nodes(ho_edge, g):\n    src_edge = ho_edge[0]\n    dst_edge = ho_edge[1]\n    return g.data.edge_index[:,src_edge][0], g.data.edge_index[:,dst_edge][0], g.data.edge_index[:,dst_edge][1]\n\n\ndef temporal_shortest_paths_all(g: pp.TemporalGraph, delta: int):\n    # generate temporal event DAG\n    edge_index = lift_order_efficient(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in TEG\n    src_edges_src = g.data.edge_index[0,:] + g.data.edge_index.size(1)\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))    \n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.data.edge_index[1,:] + 2*g.data.edge_index.size(1)\n\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    event_graph = pp.Graph.from_edge_index(edge_index)\n    \n    # initialize distance matrix \n    dist = torch.full((g.N, event_graph.N), float(\"inf\"), device=g.data.edge_index.device)\n\n    # predecessor lists\n    pred = defaultdict(lambda: defaultdict(list))\n\n    # Fastest known single source SP in DAG (Cormen, Leiserson): single scan of edges in DAG\n    # trick: index of second-order nodes = topological sorting of event DAG assuming that edges are given in chronological order    \n    # scan second-order nodes in topological order and relax distances between first-order nodes\n\n    # TODO: correct algorithm\n    for src in tqdm(g.nodes):\n        dist[g.mapping.to_idx(src), g.mapping.to_idx(src) + g.data.edge_index.size(1)] = 0\n        for v in event_graph.nodes:\n            for w in event_graph.successors(v):\n                dist[g.mapping.to_idx(src), w] = min(dist[g.mapping.to_idx(src), w], dist[g.mapping.to_idx(src), v]+1)\n    \n    dist_fo = dist[:,2*g.M:] - 1\n    dist_fo.fill_diagonal_(0)\n    return dist_fo, pred\n\n\ndef temporal_shortest_paths(g: pp.TemporalGraph, delta: int):\n    # generate temporal event DAG\n    edge_index = lift_order_efficient(g, delta)    \n\n    # Add indices of g.N first-order nodes as source nodes of paths in augmented TEG\n    src_edges_src = g.M + g.data.edge_index[0,:]\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    # Add indices of g.N first-order nodes as target nodes of paths in augmented TEG\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n    dst_edges_dst = g.M + g.N + g.data.edge_index[1,:]\n\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.M + 2 * g.N)\n    m = event_graph.get_sparse_adj_matrix()\n    print(m.shape)\n    # compute shortest paths from all source nodes to all nodes \n    dist, pred = dijkstra(m, directed=True, indices = np.arange(g.M, g.M+g.N),  return_predecessors=True, unweighted=True)\n    print(dist.shape)\n    print(g.N + g.M)\n    # we are only interested in target nodes, whose indices start at G.M + G.N\n    dist_fo = dist[:,g.M+g.N:] - 1\n    np.fill_diagonal(dist_fo, 0)\n    pred_fo = pred[:,g.N+g.M:]\n    return dist_fo, pred_fo\n\n\n    \ndef temporal_closeness_centrality(g: pp.TemporalGraph, delta: int) -&gt; dict:\n\n    centralities = dict()\n    dist, _ = temporal_shortest_paths(g, delta)\n    for x in g.nodes:\n        centralities[x] = sum((g.N - 1) / dist[np.arange(g.N)!=x, g.mapping.to_idx(x)])\n\n    return centralities\n</pre> def fo_nodes(ho_edge, g):     src_edge = ho_edge[0]     dst_edge = ho_edge[1]     return g.data.edge_index[:,src_edge][0], g.data.edge_index[:,dst_edge][0], g.data.edge_index[:,dst_edge][1]   def temporal_shortest_paths_all(g: pp.TemporalGraph, delta: int):     # generate temporal event DAG     edge_index = lift_order_efficient(g, delta)      # Add indices of first-order nodes as src and dst of paths in TEG     src_edges_src = g.data.edge_index[0,:] + g.data.edge_index.size(1)     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))         dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.data.edge_index[1,:] + 2*g.data.edge_index.size(1)      src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      event_graph = pp.Graph.from_edge_index(edge_index)          # initialize distance matrix      dist = torch.full((g.N, event_graph.N), float(\"inf\"), device=g.data.edge_index.device)      # predecessor lists     pred = defaultdict(lambda: defaultdict(list))      # Fastest known single source SP in DAG (Cormen, Leiserson): single scan of edges in DAG     # trick: index of second-order nodes = topological sorting of event DAG assuming that edges are given in chronological order         # scan second-order nodes in topological order and relax distances between first-order nodes      # TODO: correct algorithm     for src in tqdm(g.nodes):         dist[g.mapping.to_idx(src), g.mapping.to_idx(src) + g.data.edge_index.size(1)] = 0         for v in event_graph.nodes:             for w in event_graph.successors(v):                 dist[g.mapping.to_idx(src), w] = min(dist[g.mapping.to_idx(src), w], dist[g.mapping.to_idx(src), v]+1)          dist_fo = dist[:,2*g.M:] - 1     dist_fo.fill_diagonal_(0)     return dist_fo, pred   def temporal_shortest_paths(g: pp.TemporalGraph, delta: int):     # generate temporal event DAG     edge_index = lift_order_efficient(g, delta)          # Add indices of g.N first-order nodes as source nodes of paths in augmented TEG     src_edges_src = g.M + g.data.edge_index[0,:]     src_edges_dst = torch.arange(0, g.data.edge_index.size(1))      # Add indices of g.N first-order nodes as target nodes of paths in augmented TEG     dst_edges_src = torch.arange(0, g.data.edge_index.size(1))     dst_edges_dst = g.M + g.N + g.data.edge_index[1,:]      src_edges = torch.stack([src_edges_src, src_edges_dst])     dst_edges = torch.stack([dst_edges_src, dst_edges_dst])     edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)      event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.M + 2 * g.N)     m = event_graph.get_sparse_adj_matrix()     print(m.shape)     # compute shortest paths from all source nodes to all nodes      dist, pred = dijkstra(m, directed=True, indices = np.arange(g.M, g.M+g.N),  return_predecessors=True, unweighted=True)     print(dist.shape)     print(g.N + g.M)     # we are only interested in target nodes, whose indices start at G.M + G.N     dist_fo = dist[:,g.M+g.N:] - 1     np.fill_diagonal(dist_fo, 0)     pred_fo = pred[:,g.N+g.M:]     return dist_fo, pred_fo        def temporal_closeness_centrality(g: pp.TemporalGraph, delta: int) -&gt; dict:      centralities = dict()     dist, _ = temporal_shortest_paths(g, delta)     for x in g.nodes:         centralities[x] = sum((g.N - 1) / dist[np.arange(g.N)!=x, g.mapping.to_idx(x)])      return centralities In\u00a0[6]: Copied! <pre>dist, pred = temporal_shortest_paths(t_ants, delta=30)\nprint(dist.shape)\nprint(t_ants.N)\nprint(t_ants.M)\n</pre> dist, pred = temporal_shortest_paths(t_ants, delta=30) print(dist.shape) print(t_ants.N) print(t_ants.M) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 594/594 [00:00&lt;00:00, 6304.91it/s]</pre> <pre>(1181, 1181)\n(68, 1181)\n1113\n(68, 68)\n68\n1045\n</pre> <pre>\n</pre> In\u00a0[11]: Copied! <pre>idx[:,1]\n</pre> idx[:,1] <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 idx[:,1]\n\nNameError: name 'idx' is not defined</pre> In\u00a0[\u00a0]: Copied! <pre>edge_index = lift_order_efficient(t)\nprint(edge_index)\n</pre> edge_index = lift_order_efficient(t) print(edge_index) In\u00a0[50]: Copied! <pre>print(t.data.edge_index)\ndist, pred = temporal_shortest_paths(t, delta=1)\n\nprint(dist)\nprint(pred)\n</pre> print(t.data.edge_index) dist, pred = temporal_shortest_paths(t, delta=1)  print(dist) print(pred) <pre>tensor([[0, 0, 1, 1, 3, 1],\n        [1, 2, 2, 3, 4, 4]])\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 2955.30it/s]</pre> <pre>(16, 16)\n(5, 16)\n11\n[[ 0.  1.  1.  2.  3.]\n [inf  0.  1.  1.  1.]\n [inf inf  0. inf inf]\n [inf inf inf  0.  1.]\n [inf inf inf inf  0.]]\n[[-9999     0     1     3     4]\n [-9999 -9999     2     3     5]\n [-9999 -9999 -9999 -9999 -9999]\n [-9999 -9999 -9999 -9999     4]\n [-9999 -9999 -9999 -9999 -9999]]\n</pre> <pre>\n</pre> In\u00a0[51]: Copied! <pre>dist[:,4]\n</pre> dist[:,4] Out[51]: <pre>array([ 3.,  1., inf,  1.,  0.])</pre> In\u00a0[\u00a0]: Copied! <pre>t.mapping.node_ids\n</pre> t.mapping.node_ids In\u00a0[\u00a0]: Copied! <pre>print(temporal_closeness_centrality(t, delta=1))\nprint(t.N)\n</pre> print(temporal_closeness_centrality(t, delta=1)) print(t.N) In\u00a0[\u00a0]: Copied! <pre>temporal_shortest_paths(t_sp, delta=3600)\n</pre> temporal_shortest_paths(t_sp, delta=3600) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>edge_index[0,:]\n</pre> edge_index[0,:] In\u00a0[\u00a0]: Copied! <pre>t.data.edge_index[:,edge_index[0,:]][0]\n</pre> t.data.edge_index[:,edge_index[0,:]][0] In\u00a0[\u00a0]: Copied! <pre>t.data.edge_index[:,edge_index[1,:]][1]\n</pre> t.data.edge_index[:,edge_index[1,:]][1] In\u00a0[\u00a0]: Copied! <pre>#print(t.data.edge_index)\nprint(t_sp)\ng = temporal_shortest_paths(t_sp, delta=300)\n</pre> #print(t.data.edge_index) print(t_sp) g = temporal_shortest_paths(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>indeg = degree(g.data.edge_index[1])\nroots = torch.where(indeg==0)[0]\nprint(roots)\n</pre> indeg = degree(g.data.edge_index[1]) roots = torch.where(indeg==0)[0] print(roots) In\u00a0[\u00a0]: Copied! <pre>def traverse(g, path):\n    if g.get_successors(path[-1]).size(0) == 0:\n        pass\n    else:\n        for w in g.successors(path[-1]):\n            traverse(g, path + (w,))\n</pre> def traverse(g, path):     if g.get_successors(path[-1]).size(0) == 0:         pass     else:         for w in g.successors(path[-1]):             traverse(g, path + (w,)) In\u00a0[\u00a0]: Copied! <pre>i = 0\nfor x in roots:\n    print(x)\n    traverse(g, (x,))\n</pre> i = 0 for x in roots:     print(x)     traverse(g, (x,)) In\u00a0[\u00a0]: Copied! <pre>ho_index = lift_order_not_efficient(t, delta=1)\nprint(ho_index)\n</pre> ho_index = lift_order_not_efficient(t, delta=1) print(ho_index) In\u00a0[\u00a0]: Copied! <pre>ho_index = lift_order_efficient(t, delta=1)\nprint(ho_index)\n</pre> ho_index = lift_order_efficient(t, delta=1) print(ho_index) In\u00a0[\u00a0]: Copied! <pre>print(t.data.edge_index)\n</pre> print(t.data.edge_index) In\u00a0[\u00a0]: Copied! <pre>node_sequence = torch.arange(t.data.num_nodes, device=t.data.edge_index.device).unsqueeze(1)\nprint(node_sequence)\nnode_sequence = torch.cat([node_sequence[t.data.edge_index[0]], node_sequence[t.data.edge_index[1]][:, -1:]], dim=1)\nprint(node_sequence)\n</pre> node_sequence = torch.arange(t.data.num_nodes, device=t.data.edge_index.device).unsqueeze(1) print(node_sequence) node_sequence = torch.cat([node_sequence[t.data.edge_index[0]], node_sequence[t.data.edge_index[1]][:, -1:]], dim=1) print(node_sequence) In\u00a0[\u00a0]: Copied! <pre>lift_order_not_efficient(t_sp, delta=300)\n</pre> lift_order_not_efficient(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>lift_order_efficient(t_sp, delta=300)\n</pre> lift_order_efficient(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>lift_order_not_efficient(t_sp, delta=300)\n</pre> lift_order_not_efficient(t_sp, delta=300) In\u00a0[\u00a0]: Copied! <pre>x = torch.cartesian_prod(torch.tensor([0,1]), torch.tensor([1,3])).t()\n# edge 0 = 0-&gt;1\n# edge 1 = 1-&gt;2\n# edge 2 = 0-&gt;1\n\n# combination 0,1:     0-&gt;1, 1-&gt;2\n# combination 0,2:     0-&gt;1, 0-&gt;1\nprint(x)\n</pre> x = torch.cartesian_prod(torch.tensor([0,1]), torch.tensor([1,3])).t() # edge 0 = 0-&gt;1 # edge 1 = 1-&gt;2 # edge 2 = 0-&gt;1  # combination 0,1:     0-&gt;1, 1-&gt;2 # combination 0,2:     0-&gt;1, 0-&gt;1 print(x) In\u00a0[\u00a0]: Copied! <pre>src_edges = torch.index_select(t.data.edge_index, dim=1, index=x[0])\nprint(src_edges)\n</pre> src_edges = torch.index_select(t.data.edge_index, dim=1, index=x[0]) print(src_edges) In\u00a0[\u00a0]: Copied! <pre>dst_edges = torch.index_select(t.data.edge_index, dim=1, index=x[1])\nprint(dst_edges)\n</pre> dst_edges = torch.index_select(t.data.edge_index, dim=1, index=x[1]) print(dst_edges) In\u00a0[\u00a0]: Copied! <pre>#select all indices where \ntorch.where(src_edges[1,:] == dst_edges[0,:])[0]\nx[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n</pre>  #select all indices where  torch.where(src_edges[1,:] == dst_edges[0,:])[0] x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]] In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/time_respecting_paths_gpu/","title":"Time respecting paths gpu","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nimport torch\nfrom torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\n\nfrom tqdm import tqdm\n</pre> import pathpyG as pp import torch from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index  from tqdm import tqdm In\u00a0[2]: Copied! <pre>t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected()\nprint(t_sp)\nprint(torch.unique(t_sp.data.t).size(0))\n</pre> t_sp = pp.TemporalGraph.from_csv('sociopatterns_highschool_2013.tedges').to_undirected() print(t_sp) print(torch.unique(t_sp.data.t).size(0)) <pre>Temporal Graph with 327 nodes, 11636 unique edges and 377016 events in [1385982080.0, 1386345600.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([377016])\n\n1157\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 'src', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[4]: Copied! <pre>t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2)])\nprint(t)\n</pre> t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2)]) print(t) <pre>Temporal Graph with 5 nodes, 5 unique edges and 5 events in [0.0, 2.0]\n\nGraph attributes\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\n\n</pre> In\u00a0[5]: Copied! <pre># new memory-efficient code copied from `temporal_shortest_paths.ipynb`\ndef lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):\n\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.t\n\n    #print(edge_index)\n    #print(timestamps)\n\n    indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)\n\n    unique_t, reverse_idx = torch.unique(timestamps, sorted=True, return_inverse=True)\n    second_order = []\n    count = 0\n\n    # lift order: find possible continuations for edges in each time stamp\n    for i in tqdm(range(unique_t.size(0))):\n        t = unique_t[i]\n        #print('timestamp index ', i)\n        #print('timestamp ', t)\n        \n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = (timestamps == t)\n        src_edges = edge_index[:,src_time_mask]\n        src_edge_idx = indices[src_time_mask]\n        #print(src_edges)\n        #print(src_edge_idx)\n\n        # find indices of all edges that can continue edges at tine t for given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)\n        dst_edges = edge_index[:,dst_time_mask]        \n        dst_edge_idx = indices[dst_time_mask]\n        #print(dst_edges)\n        #print(dst_edge_idx)\n\n        if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:\n\n            # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges        \n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n            src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n            dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n            #print(src_edges)\n            #print(dst_edges)\n            ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n            second_order.append(ho_edge_index)\n            #print(ho_edge_index) \n            \n            # #print('dst', dst)\n            # src_mask = (edge_index[:,mask][0]==dst)\n            # ctd = edge_index[:,mask][:,src_mask]\n            # #print('continuations', ctd)\n            # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]        \n            # #print('ctd indx', ctd_indices)\n            # count += ctd_indices.size(0)\n    ho_index = torch.cat(second_order, dim=1)    \n    return ho_index.size(1), ho_index\n</pre> # new memory-efficient code copied from `temporal_shortest_paths.ipynb` def lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):      # first-order edge index     edge_index, timestamps = g.data.edge_index, g.data.t      #print(edge_index)     #print(timestamps)      indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)      unique_t, reverse_idx = torch.unique(timestamps, sorted=True, return_inverse=True)     second_order = []     count = 0      # lift order: find possible continuations for edges in each time stamp     for i in tqdm(range(unique_t.size(0))):         t = unique_t[i]         #print('timestamp index ', i)         #print('timestamp ', t)                  # find indices of all source edges that occur at unique timestamp t         src_time_mask = (timestamps == t)         src_edges = edge_index[:,src_time_mask]         src_edge_idx = indices[src_time_mask]         #print(src_edges)         #print(src_edge_idx)          # find indices of all edges that can continue edges at tine t for given delta         dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t+delta)         dst_edges = edge_index[:,dst_time_mask]                 dst_edge_idx = indices[dst_time_mask]         #print(dst_edges)         #print(dst_edge_idx)          if dst_edge_idx.size(0)&gt;0 and src_edge_idx.size(0)&gt;0:              # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges                     x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()             src_edges = torch.index_select(edge_index, dim=1, index=x[0])             dst_edges = torch.index_select(edge_index, dim=1, index=x[1])             #print(src_edges)             #print(dst_edges)             ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]             second_order.append(ho_edge_index)             #print(ho_edge_index)                           # #print('dst', dst)             # src_mask = (edge_index[:,mask][0]==dst)             # ctd = edge_index[:,mask][:,src_mask]             # #print('continuations', ctd)             # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]                     # #print('ctd indx', ctd_indices)             # count += ctd_indices.size(0)     ho_index = torch.cat(second_order, dim=1)         return ho_index.size(1), ho_index In\u00a0[4]: Copied! <pre>def time_respecting_paths(g: pp.TemporalGraph, delta: int) -&gt; dict:\n    \"\"\"\n    Calculate all longest time-respecting paths in a temporal graph.\n    \"\"\"\n    paths_of_length = {}\n\n    node_sequence = torch.arange(g.data.num_nodes, device=g.data.edge_index.device).unsqueeze(1)\n    node_sequence = torch.cat([node_sequence[g.data.edge_index[0]], node_sequence[g.data.edge_index[1]][:, -1:]], dim=1)\n    edge_index = lift_order_efficient(g, delta)[1]\n    \n    # calculate degrees\n    out_degree = degree(edge_index[0], num_nodes=g.M, dtype=torch.long)\n    in_degree = degree(edge_index[1], num_nodes=g.M, dtype=torch.long)\n    # identify root nodes with in-degree zero\n    roots = torch.where(in_degree == 0)[0]\n    leafs = (out_degree == 0)\n    # print(\"Roots:\", roots)\n    # print(\"Leafs:\", leafs)\n    paths = node_sequence[roots]\n    paths_of_length[1] = paths[leafs[roots]].cpu()\n\n    paths = paths[~leafs[roots]]\n    nodes = roots[~leafs[roots]]\n\n    ptrs = cumsum(out_degree, dim=0)\n\n\n    # count all longest time-respecting paths in the temporal graph\n    step = 1\n    while nodes.size(0) &gt; 0:\n        # print(\"step\", step)\n        # print(\"Paths: \", paths)\n        # print(\"Nodes: \", nodes)\n        idx_repeat = torch.repeat_interleave(out_degree[nodes])\n        next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])\n        idx_correction = torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]\n        next_idx += idx_correction\n        next_nodes = edge_index[1][next_idx]\n        paths = torch.cat([paths[idx_repeat], node_sequence[next_nodes, 1:]], dim=1)\n        paths_of_length[step] = paths[leafs[next_nodes]].tolist()\n        paths = paths[~leafs[next_nodes]]\n        nodes = next_nodes[~leafs[next_nodes]]\n        step += 1\n\n    return paths_of_length\n</pre> def time_respecting_paths(g: pp.TemporalGraph, delta: int) -&gt; dict:     \"\"\"     Calculate all longest time-respecting paths in a temporal graph.     \"\"\"     paths_of_length = {}      node_sequence = torch.arange(g.data.num_nodes, device=g.data.edge_index.device).unsqueeze(1)     node_sequence = torch.cat([node_sequence[g.data.edge_index[0]], node_sequence[g.data.edge_index[1]][:, -1:]], dim=1)     edge_index = lift_order_efficient(g, delta)[1]          # calculate degrees     out_degree = degree(edge_index[0], num_nodes=g.M, dtype=torch.long)     in_degree = degree(edge_index[1], num_nodes=g.M, dtype=torch.long)     # identify root nodes with in-degree zero     roots = torch.where(in_degree == 0)[0]     leafs = (out_degree == 0)     # print(\"Roots:\", roots)     # print(\"Leafs:\", leafs)     paths = node_sequence[roots]     paths_of_length[1] = paths[leafs[roots]].cpu()      paths = paths[~leafs[roots]]     nodes = roots[~leafs[roots]]      ptrs = cumsum(out_degree, dim=0)       # count all longest time-respecting paths in the temporal graph     step = 1     while nodes.size(0) &gt; 0:         # print(\"step\", step)         # print(\"Paths: \", paths)         # print(\"Nodes: \", nodes)         idx_repeat = torch.repeat_interleave(out_degree[nodes])         next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])         idx_correction = torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]         next_idx += idx_correction         next_nodes = edge_index[1][next_idx]         paths = torch.cat([paths[idx_repeat], node_sequence[next_nodes, 1:]], dim=1)         paths_of_length[step] = paths[leafs[next_nodes]].tolist()         paths = paths[~leafs[next_nodes]]         nodes = next_nodes[~leafs[next_nodes]]         step += 1      return paths_of_length  In\u00a0[6]: Copied! <pre>lift_order_efficient(t_sp, delta=300)\n</pre> lift_order_efficient(t_sp, delta=300) <pre>  0%|          | 0/1157 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1157/1157 [00:08&lt;00:00, 134.85it/s]\n</pre> Out[6]: <pre>(3693050,\n tensor([[     0,      0,      0,  ..., 376991, 376991, 376991],\n         [   835,    885,    933,  ..., 376995, 377000, 377004]]))</pre> In\u00a0[7]: Copied! <pre># lift_order_efficient(t_sp, delta=300)\n</pre> # lift_order_efficient(t_sp, delta=300) In\u00a0[11]: Copied! <pre>t.data.edge_index, t.data.t\n</pre> t.data.edge_index, t.data.t Out[11]: <pre>(tensor([[0, 0, 1, 1, 3],\n         [1, 2, 2, 3, 4]]),\n tensor([0., 0., 1., 1., 2.]))</pre> In\u00a0[5]: Copied! <pre>time_respecting_paths(t_sp, delta=300)\n</pre> time_respecting_paths(t_sp, delta=300) <pre>  0%|          | 0/1157 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1157/1157 [00:07&lt;00:00, 150.48it/s]\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/visualisation/","title":"Interactive Graph Visualisation","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[2]: Copied! <pre>import pathpyG as pp\nimport torch\nprint('Running on', pp.config['torch']['device'])\n</pre> import pathpyG as pp import torch print('Running on', pp.config['torch']['device']) <pre>Running on cpu\n</pre> <p>With these preparations complete, we are ready to construct our first graph. This is achieved through the <code>Graph.from_edge_list</code> constructor provided by <code>pathpyG</code>, a method that allows us to transform a list of edges into a basic graphical representation.</p> In\u00a0[3]: Copied! <pre>g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']])\npp.plot(g, node_label=g.mapping.node_ids, edge_color='gray')\n</pre> g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']]) pp.plot(g, node_label=g.mapping.node_ids, edge_color='gray') Out[3]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9c5ad5b190&gt;</pre> <p>After successfully creating a simple graph using <code>pathpyG</code>, our next step is to examine its structure. This is a crucial part of the process as it gives us an initial understanding of the complexity and scale of our graph. By printing out the number of nodes and edges, we gain insight into the size and connectivity of the graph.</p> <p>Although it may seem unnecessary for this simple graph, it's good practice to gather information about the number of nodes and edges before attempting to visualize it. This preemptive step is crucial, especially when dealing with larger graphs. Visualizing extensive networks can be a time-consuming or even unfeasible task, depending on the sheer volume of elements that need to be represented. Therefore, understanding the graph's scale upfront helps in efficiently planning the visualization process and avoiding potential complications that could arise with larger datasets.</p> In\u00a0[4]: Copied! <pre>f'Our graph has {g.N} nodes and {g.M} edges.'\n</pre> f'Our graph has {g.N} nodes and {g.M} edges.' Out[4]: <pre>'Our graph has 3 nodes and 2 edges.'</pre> In\u00a0[5]: Copied! <pre>pp.plot(g)\n</pre> pp.plot(g) Out[5]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9c5ad5aa10&gt;</pre> In\u00a0[6]: Copied! <pre>pp.plot(g,backend='matplotlib');\n</pre> pp.plot(g,backend='matplotlib'); In\u00a0[7]: Copied! <pre>pp.plot(g,backend='matplotlib',layout='fr')\n</pre> pp.plot(g,backend='matplotlib',layout='fr') Out[7]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d344610&gt;</pre> <p>Additionally, <code>pathpyG</code> offers the flexibility to incorporate custom layout algorithms. If you have developed your own method or have specific requirements for node positioning, you can directly provide the node coordinates to the visualization. This capability ensures that <code>pathpyG</code> can cater to a wide range of visualization needs, from simple and automatic layouts to highly customized and complex arrangements, making it a versatile tool in the field of data visualization.</p> In\u00a0[8]: Copied! <pre>layout = {'a':[0,0],'b':[1,1],\"c\":[2,2]}\npp.plot(g,backend='matplotlib',layout=layout)\n</pre> layout = {'a':[0,0],'b':[1,1],\"c\":[2,2]} pp.plot(g,backend='matplotlib',layout=layout) Out[8]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9c5ad5a1a0&gt;</pre> In\u00a0[9]: Copied! <pre>style = {}\nstyle['node_color'] = (255,1,255) # RGB tuple\nstyle['edge_color'] = 'green'     # Color name as str\npp.plot(g,**style)\n</pre> style = {} style['node_color'] = (255,1,255) # RGB tuple style['edge_color'] = 'green'     # Color name as str pp.plot(g,**style) Out[9]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d17ca90&gt;</pre> <p>In <code>pathpyG</code>, there are various methods for assigning styles to objects, each offering a different level of customization and control. A straightforward approach, as previously shown, involves using a single value, such as a color string (e.g., <code>'green'</code>) or an RGB tuple (e.g., <code>(255,1,255)</code>). Applying this single value uniformly alters the appearance of all elements within a specific category, providing a quick and easy way to set a general style. However, for more detailed styling, one can utilize a <code>list</code> of values. In this approach, each value in the <code>list</code> is associated with an element according to its index position. This method is particularly familiar and efficient when working with tensors, where the association of values to elements is often index-based.</p> <p>Additionally, a more tailored approach can be employed through the use of dictionaries. In this case, each element id is paired with a corresponding value in the <code>dict</code>. Elements not included in the dictionary are assigned default values, ensuring that every element is styled, albeit some with custom and others with default styles. The types of values that can be used in these styling methods are diverse, including strings, integers, floats, and tuples, each type depending on the specific styling parameter being adjusted. This flexibility in value types and assignment methods allows for a high degree of customization, enabling the creation of visually distinct and information-rich visualizations.</p> In\u00a0[10]: Copied! <pre>style = {}\nstyle['node_color'] = ['red', 'green','blue'] # list based approach\nstyle['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach\nstyle['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value\nstyle['edge_color'] = ['orange','#00FF00']    # hex based color\npp.plot(g,**style)\n</pre> style = {} style['node_color'] = ['red', 'green','blue'] # list based approach style['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach style['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value style['edge_color'] = ['orange','#00FF00']    # hex based color pp.plot(g,**style) Out[10]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d1a7f40&gt;</pre> In\u00a0[11]: Copied! <pre>from matplotlib.pyplot import get_cmap\nmy_map = get_cmap()\nmy_map\n</pre> from matplotlib.pyplot import get_cmap my_map = get_cmap() my_map Out[11]: viridis  underbad over  In\u00a0[12]: Copied! <pre>style = {}\nstyle['edge_color'] = [1, 9]      # int values\n\nstyle['node_color'] = pp.algorithms.centrality.betweenness_centrality(g)\nstyle['node_cmap'] = my_map       # new color map from matplotlib for nodes\npp.plot(g,**style)\n</pre> style = {} style['edge_color'] = [1, 9]      # int values  style['node_color'] = pp.algorithms.centrality.betweenness_centrality(g) style['node_cmap'] = my_map       # new color map from matplotlib for nodes pp.plot(g,**style) Out[12]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5e745780&gt;</pre> In\u00a0[13]: Copied! <pre>pp.plot(g,filename='test_plot.html')\n</pre> pp.plot(g,filename='test_plot.html') Out[13]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d142ef0&gt;</pre> In\u00a0[14]: Copied! <pre>n = pp.io.read_netzschleuder_network('karate', '77')\n</pre> n = pp.io.read_netzschleuder_network('karate', '77') In\u00a0[15]: Copied! <pre>pp.plot(n)\n</pre> pp.plot(n) Out[15]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d143670&gt;</pre> In\u00a0[16]: Copied! <pre>node_color = [n['node_groups',v][0] for v in n.nodes]\npp.plot(n, edge_color='gray',node_color=node_color)\n</pre> node_color = [n['node_groups',v][0] for v in n.nodes] pp.plot(n, edge_color='gray',node_color=node_color) Out[16]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f9b5d140880&gt;</pre> In\u00a0[17]: Copied! <pre>t = pp.TemporalGraph.from_edge_list(\n        [\n            (\"a\", \"b\", 1),\n            (\"b\", \"c\", 5),\n            (\"c\", \"d\", 9),\n            (\"d\", \"a\", 9),\n            (\"a\", \"b\", 10),\n            (\"b\", \"c\", 10),\n        ]\n    )\n</pre> t = pp.TemporalGraph.from_edge_list(         [             (\"a\", \"b\", 1),             (\"b\", \"c\", 5),             (\"c\", \"d\", 9),             (\"d\", \"a\", 9),             (\"a\", \"b\", 10),             (\"b\", \"c\", 10),         ]     ) In\u00a0[18]: Copied! <pre>pp.plot(t)\n</pre> pp.plot(t) Out[18]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f9b5d143550&gt;</pre> <p>Besides the standard formatting options available in <code>pathpyG</code>, temporal plots come with specific options tailored to their unique nature. These specialized settings allow for precise control over the time dimension of the visualization. With the <code>start</code> and <code>end</code> parameters, you can define the exact start time and end time of the simulation, effectively setting the temporal boundaries of your graph. This feature is crucial for focusing on a particular time frame within your dataset. Additionally, the <code>delta</code> option lets you adjust the progression speed through the time steps of your visualization. Here, a value of 1000 translates to a one-second interval, providing a way to calibrate the pace at which the temporal data unfolds. Moreover, the <code>interval</code> option offers the flexibility to either widen or narrow the time intervals considered in the visualization. This feature is particularly useful for either zooming in on finer time-scaled details or zooming out for a broader, more comprehensive view of the temporal dynamics in your network.</p> In\u00a0[19]: Copied! <pre>color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"}\npp.plot(t,node_color=color,start=-1,end=25,delta=1000)\n</pre> color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"} pp.plot(t,node_color=color,start=-1,end=25,delta=1000) Out[19]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f9b5d1415d0&gt;</pre>"},{"location":"tutorial/visualisation/#interactiv-graph-visualization","title":"Interactiv Graph Visualization\u00b6","text":""},{"location":"tutorial/visualisation/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/visualisation/#motivation","title":"Motivation\u00b6","text":"<p>This tutorial is specifically designed to guide you through the process of visualizing your data using <code>pathpyG</code>, an advanced data visualization tool. Data visualization is a crucial aspect of data analysis and interpretation, allowing for the transformation of complex datasets into visually appealing and easy-to-understand formats. pathpyG excels in this area by providing a range of functionalities that cater to both beginners and advanced users. Throughout this tutorial, you will be introduced to the basic and advanced features of pathpyG, empowering you to effectively visualize your data. This will not only enhance your understanding of your data but also enable you to communicate your findings more effectively to others.</p> <p>Visualization is a core concept of <code>pathpyG</code> because it bridges the gap between raw data and meaningful visual representations. We, as humans, are wired to process visual information much more rapidly compared to text or audio. This innate ability enables us to quickly identify patterns, outliers, and trends in visual data. Data visualization leverages this capability by graphically representing data, thereby facilitating the swift interpretation of large and complex datasets. Interactive visualizations further this advantage by allowing users to directly engage with the data, exploring and analyzing it in an intuitive and insightful manner. Whether it's understanding the intricate details of microscopic structures or grasping the dynamics of global phenomena, visualizations are instrumental in helping researchers and analysts gain deeper insights and effectively communicate their findings.</p>"},{"location":"tutorial/visualisation/#learning-objectives","title":"Learning objectives\u00b6","text":"<p>In this tutorial, you will learn to master the art of creating simple yet powerful interactive visualizations using <code>pathpyG</code>. You will learn the nuances of customizing the style of your visualizations, enabling you to tailor them to your specific needs and preferences. This customization extends to the aesthetics, layout, and interactive elements, ensuring that your visualizations are not only informative but also engaging. Additionally, the tutorial covers the essential skills needed to save your visualizations in various formats, making it easier to share your work across different platforms and audiences. Lastly, a significant part of the tutorial is dedicated to creating temporal visualizations. These types of visualizations are particularly useful in understanding and presenting data that changes over time, offering dynamic insights into trends and patterns that static visualizations cannot capture. By the end of this tutorial, you will have a comprehensive understanding of how to effectively use pathpyG to create and customize a wide range of visualizations.</p>"},{"location":"tutorial/visualisation/#lets-get-started","title":"Let's Get Started\u00b6","text":"<p>To embark on our journey of visualizing data with <code>pathpyG</code>, the initial step involves initializing and loading the required modules, a crucial process that sets the foundation for our data visualization work. This preparation ensures that all necessary tools and functionalities from <code>pathpyG</code> are at our disposal.</p> <p>In anticipation of enhancing our graphs with additional attributes, we also include the <code>torch</code> package in our setup. <code>torch</code> is renowned for its robust capabilities in data processing and machine learning, and its inclusion allows us to enrich our graphs with more complex and informative attributes.</p>"},{"location":"tutorial/visualisation/#the-plot-function","title":"The <code>plot</code> Function\u00b6","text":"<p>The <code>plot</code> function in <code>pathpyG</code> stands out as the simplest and most direct method for creating visualizations. Designed to encapsulate all the plotting capabilities of <code>pathpyG</code> in a single command, it streamlines the process of generating quick and efficient plots. This functionality is particularly beneficial for users who seek immediate visual feedback from their data without delving into more complex coding. The only prerequisite for using this function is the <code>Graph</code> object, which serves as the foundation for the visualization. Moreover, when working within an interactive environment, such as a <code>Jupyter notebook</code>, the <code>plot</code> function is particularly powerful. In such settings, invoking the <code>plot</code> command will automatically generate and display an interactive visualization. This feature is particularly beneficial as it allows for immediate visual feedback, making it an ideal tool for exploratory data analysis where quick and efficient visualization is key.</p>"},{"location":"tutorial/visualisation/#kwargs-in-the-plot-function","title":"<code>kwargs</code> in the <code>plot</code> function\u00b6","text":"<p>In <code>pathpyG</code>, the customization of your plot is managed through keyword arguments (kwargs), where each customization is specified as a keyword followed by its corresponding value. This approach is what gives the <code>plot</code> function its remarkable flexibility, allowing it to adapt to a wide variety of plotting requirements. Whether you're aiming for a simple graph or a complex, multi-faceted visualization, the keyword arguments provide the tools to tailor your plot precisely to your needs.</p> <p>However, this wealth of options can be somewhat overwhelming for beginners, given the extensive range of available choices. But worry not, as we will guide you through the most essential and basic options, ensuring you have a solid foundation to start from. By mastering these fundamental aspects, you'll be well on your way to effectively utilizing <code>pathpyG</code>'s plot function, gradually building up to more advanced features as you gain confidence and expertise.</p>"},{"location":"tutorial/visualisation/#plotting-backends","title":"Plotting Backends\u00b6","text":"<p>In the diverse world of data visualization, there is no one-size-fits-all technique, as different scenarios demand different approaches. Recognizing this, <code>pathpyG</code> offers a variety of plotting backends, each tailored for specific use cases, ensuring that users have the right tools for their unique requirements.</p> <ul> <li><p>For instance, <code>pathpyG</code> facilitates interactive visualizations, as previously demonstrated, which are immensely useful for dynamic exploration of data. This feature is particularly beneficial in educational settings, exploratory data analysis, and communication, where interaction with the data can lead to deeper understanding and insights.</p> </li> <li><p>On the other hand, <code>pathpyG</code> also integrates with matplotlib, a widely recognized package for creating static plots. This is especially efficient for visualizing large graphs where interactivity might be less critical.</p> </li> <li><p>Additionally, <code>pathpyG</code> caters to the academic and publication community by offering tikz plots, which are highly valued in formal publications for their precision and quality. (Note that for generating tikz plots, currently, the installation of <code>latexmk</code> is necessary to produce the corresponding <code>.tex</code> and <code>.pdf</code> files.)</p> </li> </ul> <p>Let's generate a static png image using the <code>matplotlib</code> backend:</p>"},{"location":"tutorial/visualisation/#quick-introduction-to-layouts","title":"Quick Introduction to Layouts\u00b6","text":"<p>An important aspect to consider is the layout of your plot. The previous plot we generated is static, meaning the positions of the nodes are fixed and do not change. This fixed arrangement presents a unique challenge, as finding the optimal placement for nodes and edges to convey information effectively is not a straightforward task. To assist with this, <code>pathpyG</code> supports simple layout functions designed to create visually appealing and coherent graphs. By default, nodes are assigned random locations for computational efficiency. However, this arrangement can be significantly improved with the use of the <code>layout</code> keyword in the <code>plot</code> function, allowing for more structured and meaningful representations of your graph.</p> <p>For example, <code>pathpyG</code> includes support for sophisticated layout algorithms, such as the Fruchterman-Reingold algorithm for force-directed layouts. This can be activated using the <code>\"fr\"</code> option, which applies a physics-based approach to arrange nodes and edges in a way that visually represents their relational dynamics. Such force-directed layouts are particularly useful for highlighting the underlying structure and relationships within the data.</p>"},{"location":"tutorial/visualisation/#styling-your-plots","title":"Styling Your Plots\u00b6","text":"<p>To enhance the effectiveness and appeal of our visualizations in <code>pathpyG</code>, styling of our plots becomes a key aspect. The ability to style your plots is not just about aesthetic appeal; it is about effectively conveying more information through visual means. Depending on the type of plot you are working with, there are multiple styling options available to tailor your visualization to your specific needs. The fundamental principle here is that the styles applied to your plot should not be dependent on the data of your model. In other words, you should be able to present the same data in different styles, depending on the context or the information you wish to highlight. To facilitate this, styles are organized in dictionaries, which are then incorporated into the <code>plot</code> function.</p> <p>For network plots, where the focus is on the topology of the data, there are several basic styling options you can adjust, including the <code>size</code>, <code>color</code>, and <code>opacity</code> of each node and edge object. These options provide a foundational level of customization, allowing you to make your graph more readable and visually appealing. However, the styling possibilities extend further, varying according to the specific kind of plot you are creating. To distinguish between the styling of edges and nodes, a prefix corresponding to each element type is added to the keyword, such as <code>node_size</code>. This distinction ensures that your styling choices are accurately applied to the intended elements of the graph, further enhancing the clarity and effectiveness of your visualization.</p>"},{"location":"tutorial/visualisation/#colormaps","title":"Colormaps\u00b6","text":"<p>In many instances, particularly when visualizing numerical data, the use of color gradients to represent values can greatly enhance the clarity and effectiveness of a plot. <code>pathpyG</code> addresses this need through its native support for <code>colormaps</code>. When the colors of node or edge elements are defined using <code>int</code> or <code>float</code> values, <code>pathpyG</code> automatically assigns colors based on these colormaps, effectively interpolating the correct color value for each element. By default, <code>pathpyG</code> offers a simple colormap that transitions from red to green, sufficient for many basic visualization needs. However, for more customized or advanced styling, users have the option to utilize any colormap from the extensive color palettes provided by <code>matplotlib</code> or <code>seaborn</code>. These libraries offer a wide range of color schemes, enabling you to select the perfect palette to convey the nuances of your data.</p>"},{"location":"tutorial/visualisation/#saving-plots","title":"Saving Plots\u00b6","text":"<p>In <code>pathpyG</code>, sharing your plots or incorporating them into various mediums is facilitated by the ability to save them as files. This functionality is conveniently accessed by simply adding the <code>filename</code> keyword within the plot function. When you specify a filename, <code>pathpyG</code> assigns the appropriate backend to use based on the file extension provided. For instance, if you save your file with an <code>.html</code> extension, <code>pathpyG</code> generates a standalone interactive visualization, perfect for web applications or interactive presentations. On the other hand, if you choose to save your plot as a <code>.png</code> file, a static image is created using the <code>matplotlib</code> backend, ideal for including in documents, reports, or presentations where interactivity is not required. Additionally, for those seeking to incorporate plots into academic papers or publications, saving the file with a <code>.tex</code> extension activates the <code>tikz</code> backend. This feature is particularly beneficial for creating high-quality, publication-ready figures.</p>"},{"location":"tutorial/visualisation/#larger-network-visualizations","title":"Larger Network Visualizations\u00b6","text":"<p>Having covered the basics, we are now well-prepared to venture into the realm of larger network visualizations using <code>pathpyG</code>.</p>"},{"location":"tutorial/visualisation/#temporal-network-visualizations","title":"Temporal Network Visualizations\u00b6","text":"<p>In the realm of network analysis, <code>pathpyG</code> particularly excels in handling and visualizing temporal graphs, a domain where both nodes and edges can change their properties over time. This dynamic aspect of temporal graphs adds a layer of complexity and richness to data analysis, capturing the evolution of relationships and properties within the network. <code>pathpyG</code> supports this advanced functionality, allowing users to apply the same versatile <code>plot</code> function used for static graphs to <code>TemporalGraph</code> data structures. This integration means that all the customization options, styling features, and layout choices previously explored for static network visualizations are also applicable to temporal graphs. The ability to utilize these tools in the context of temporal data opens up a world of possibilities for in-depth analysis and insightful visualization of networks where time plays a crucial role. Whether you're tracking changes in social networks, analyzing traffic patterns, or studying dynamic biological systems, <code>pathpyG</code>'s capabilities in temporal network visualization provide a powerful tool to uncover and illustrate the temporal dynamics inherent in these complex systems.</p>"},{"location":"tutorial/xx_temporal_centralities/","title":"Xx temporal centralities","text":"In\u00a0[2]: Copied! <pre>import torch\n\nimport pathpyG as pp\n\nprint('Running on', pp.config['torch']['device'])\n</pre> import torch  import pathpyG as pp  print('Running on', pp.config['torch']['device']) <pre>Running on cpu\n</pre> In\u00a0[3]: Copied! <pre># Put this as his in conftest as 'simple_paths_centralities'\npaths = pp.WalkData()\npaths.add(torch.tensor([[2, 1, 3], [1, 3, 5]]))  \npaths.add(torch.tensor([[0, 1], [1, 3]]))  \npaths.add(torch.tensor([[3], [4]]))\n\nsimple_paths_centralities = paths\n</pre> # Put this as his in conftest as 'simple_paths_centralities' paths = pp.WalkData() paths.add(torch.tensor([[2, 1, 3], [1, 3, 5]]))   paths.add(torch.tensor([[0, 1], [1, 3]]))   paths.add(torch.tensor([[3], [4]]))  simple_paths_centralities = paths In\u00a0[4]: Copied! <pre># paths = pp.PathData()\n# paths.add_walk(torch.tensor([[0,2,3],[2,3,4]]),freq=3) # A -&gt; C -&gt; D\n# paths.add_walk(torch.tensor([[0,2],[2,3]])) # A -&gt; C -&gt; D\n# paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E\n# paths.add_walk(torch.tensor([[4],[5]]))\n# paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E\n</pre> # paths = pp.PathData() # paths.add_walk(torch.tensor([[0,2,3],[2,3,4]]),freq=3) # A -&gt; C -&gt; D # paths.add_walk(torch.tensor([[0,2],[2,3]])) # A -&gt; C -&gt; D # paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E # paths.add_walk(torch.tensor([[4],[5]])) # paths.add_walk(torch.tensor([[1,2],[2,4]])) # B -&gt; C -&gt; E  In\u00a0[5]: Copied! <pre>index, edge_weights = paths.edge_index_k_weighted(k=2)\nindex, edge_weights\n</pre> index, edge_weights = paths.edge_index_k_weighted(k=2) index, edge_weights Out[5]: <pre>(tensor([[[0, 1],\n          [1, 3],\n          [2, 1]],\n \n         [[1, 3],\n          [3, 5],\n          [1, 3]]]),\n tensor([1., 1., 1.]))</pre> In\u00a0[6]: Copied! <pre>index, edge_weights = paths.edge_index_k_weighted(k=1)\n</pre> index, edge_weights = paths.edge_index_k_weighted(k=1) In\u00a0[7]: Copied! <pre>from collections import defaultdict\n\ndef node_traversals(paths):\n    \"\"\"Calculates the number of times any path traverses each of the nodes.\n\n    Parameters\n    ----------\n    paths: Paths\n\n    Returns\n    -------\n    dict\n    \"\"\"\n    traversals = defaultdict(lambda: 0)\n    for path_id, path_edgelist in paths.paths.items():\n        path_seq = paths.walk_to_node_seq(path_edgelist)\n        for node in path_seq:\n            traversals[node.item()] += paths.path_freq[path_id]\n    return traversals\n</pre> from collections import defaultdict  def node_traversals(paths):     \"\"\"Calculates the number of times any path traverses each of the nodes.      Parameters     ----------     paths: Paths      Returns     -------     dict     \"\"\"     traversals = defaultdict(lambda: 0)     for path_id, path_edgelist in paths.paths.items():         path_seq = paths.walk_to_node_seq(path_edgelist)         for node in path_seq:             traversals[node.item()] += paths.path_freq[path_id]     return traversals In\u00a0[10]: Copied! <pre>from pathpyG.algorithms.centrality import node_traversals\n</pre> from pathpyG.algorithms.centrality import node_traversals In\u00a0[11]: Copied! <pre>node_traversals(paths)\n</pre> node_traversals(paths) <pre>\n---------------------------------------------------------------------------\nRecursionError                            Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 node_traversals(paths)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\n    [... skipping similar frames: __getattr__.&lt;locals&gt;.wrapper at line 311 (2968 times)]\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:299, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    298 def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n--&gt; 299     if len(args) == 0:\n    300         raise RuntimeError(f'Did not find method {name} with no arguments')\n    301     if isinstance(args[0], TemporalGraph):\n\nRecursionError: maximum recursion depth exceeded while calling a Python object</pre> In\u00a0[13]: Copied! <pre>from pathpyG.algorithms.centrality import visitation_probabilities\n</pre> from pathpyG.algorithms.centrality import visitation_probabilities In\u00a0[14]: Copied! <pre>def test_visitation_probabilities(simple_paths_centralities):\n    traversals_dict = visitation_probabilities(simple_paths_centralities)\n    assert set(traversals_dict.keys()) == {0,1,2,3,4,5}\n    assert traversals_dict[0] == 1/9\n    assert traversals_dict[1] == 2/9\n    assert traversals_dict[2] == 1/9\n    assert traversals_dict[3] == 3/9\n    assert traversals_dict[4] == 1/9\n    assert traversals_dict[5] == 1/9\n\ntest_visitation_probabilities(simple_paths_centralities)\n</pre> def test_visitation_probabilities(simple_paths_centralities):     traversals_dict = visitation_probabilities(simple_paths_centralities)     assert set(traversals_dict.keys()) == {0,1,2,3,4,5}     assert traversals_dict[0] == 1/9     assert traversals_dict[1] == 2/9     assert traversals_dict[2] == 1/9     assert traversals_dict[3] == 3/9     assert traversals_dict[4] == 1/9     assert traversals_dict[5] == 1/9  test_visitation_probabilities(simple_paths_centralities) <pre>\n---------------------------------------------------------------------------\nRecursionError                            Traceback (most recent call last)\nCell In[14], line 11\n      8     assert traversals_dict[4] == 1/9\n      9     assert traversals_dict[5] == 1/9\n---&gt; 11 test_visitation_probabilities(simple_paths_centralities)\n\nCell In[14], line 2, in test_visitation_probabilities(simple_paths_centralities)\n      1 def test_visitation_probabilities(simple_paths_centralities):\n----&gt; 2     traversals_dict = visitation_probabilities(simple_paths_centralities)\n      3     assert set(traversals_dict.keys()) == {0,1,2,3,4,5}\n      4     assert traversals_dict[0] == 1/9\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\n    [... skipping similar frames: __getattr__.&lt;locals&gt;.wrapper at line 311 (2967 times)]\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:311, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    309     return r\n    310 else:\n--&gt; 311     return wrapper(*args, **kwargs)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/centrality.py:299, in __getattr__.&lt;locals&gt;.wrapper(*args, **kwargs)\n    298 def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n--&gt; 299     if len(args) == 0:\n    300         raise RuntimeError(f'Did not find method {name} with no arguments')\n    301     if isinstance(args[0], TemporalGraph):\n\nRecursionError: maximum recursion depth exceeded while calling a Python object</pre> In\u00a0[339]: Copied! <pre>test_shortest_paths(paths)\n</pre> test_shortest_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> In\u00a0[340]: Copied! <pre># @betweenness.register(Paths)\ndef betweenness(paths, normalized=False):\n    \"\"\"Calculates the betweenness of nodes based on observed shortest paths\n    between all pairs of nodes\n\n    Parameters\n    ----------\n    paths:\n        Paths object\n    normalized: bool\n        normalize such that largest value is 1.0\n\n    Returns\n    -------\n    dict\n    \"\"\"\n    assert isinstance(paths, pp.PathData), \"argument must be an instance of pathpy.Paths\"\n    node_centralities = defaultdict(lambda: 0)\n\n    # Log.add('Calculating betweenness in paths ...', Severity.INFO)\n\n    all_paths = shortest_paths(paths)\n\n    for s in all_paths:\n        for d in all_paths[s]:\n            for p in all_paths[s][d]:\n                for x in p[1:-1]:\n                    if s != d != x:\n                        node_centralities[x.item()] += 1.0 / len(all_paths[s][d])\n    if normalized:\n        max_centr = max(node_centralities.values())\n        for v in node_centralities:\n            node_centralities[v] /= max_centr\n    # assign zero values to nodes not occurring on shortest paths\n    nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)]\n    for v in nodes:\n        node_centralities[v] += 0\n    # Log.add('finished.')\n    return node_centralities\n\nbetweenness(paths,normalized=False)\n</pre> # @betweenness.register(Paths) def betweenness(paths, normalized=False):     \"\"\"Calculates the betweenness of nodes based on observed shortest paths     between all pairs of nodes      Parameters     ----------     paths:         Paths object     normalized: bool         normalize such that largest value is 1.0      Returns     -------     dict     \"\"\"     assert isinstance(paths, pp.PathData), \"argument must be an instance of pathpy.Paths\"     node_centralities = defaultdict(lambda: 0)      # Log.add('Calculating betweenness in paths ...', Severity.INFO)      all_paths = shortest_paths(paths)      for s in all_paths:         for d in all_paths[s]:             for p in all_paths[s][d]:                 for x in p[1:-1]:                     if s != d != x:                         node_centralities[x.item()] += 1.0 / len(all_paths[s][d])     if normalized:         max_centr = max(node_centralities.values())         for v in node_centralities:             node_centralities[v] /= max_centr     # assign zero values to nodes not occurring on shortest paths     nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)]     for v in nodes:         node_centralities[v] += 0     # Log.add('finished.')     return node_centralities  betweenness(paths,normalized=False) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> Out[340]: <pre>defaultdict(&lt;function __main__.betweenness.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {1: 3.0, 3: 2.0, 0: 0, 2: 0, 4: 0, 5: 0})</pre> In\u00a0[346]: Copied! <pre>def test_betweenness_paths(simple_paths_centralities):\n    bw = betweenness(simple_paths_centralities,normalized=False)\n    # 1 is in the shortest path between 0-5,2-3,2-5\n    assert bw[1] == 3.0\n    # 1 is in the shortest path between 2-5,1-5\n    assert bw[3] == 2.0\n\ntest_betweenness_paths(paths)\n</pre> def test_betweenness_paths(simple_paths_centralities):     bw = betweenness(simple_paths_centralities,normalized=False)     # 1 is in the shortest path between 0-5,2-3,2-5     assert bw[1] == 3.0     # 1 is in the shortest path between 2-5,1-5     assert bw[3] == 2.0  test_betweenness_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> In\u00a0[347]: Copied! <pre>def distance_matrix(paths):\n    \"\"\"\n    Calculates shortest path distances between all pairs of\n    nodes based on the observed shortest paths (and subpaths)\n    \"\"\"\n    dist = defaultdict(lambda: defaultdict(lambda: _np.inf))\n    # Log.add('Calculating distance matrix based on empirical paths ...', Severity.INFO)\n    nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject\n    for v in nodes:\n        dist[v][v] = 0\n\n    p_length = 1\n    index, edge_weights = paths.edge_index_k_weighted(k=p_length)\n    sources = index[0]\n    destinations = index[-1]\n    for e, (s, d) in enumerate(zip(sources, destinations)):\n        s = s.item()\n        d = d.item()\n        dist[s][d] = p_length\n        # s_p[s][d] = set({torch.tensor([s,d])})\n    p_length += 1\n    while True: # until max path length\n        try:\n            index, edge_weights = paths.edge_index_k_weighted(k=p_length)\n            sources = index[0, :, 0]\n            destinations = index[1, :, -1]\n            for e, (s, d) in enumerate(zip(sources, destinations)):\n                s = s.item()\n                d = d.item()\n                if p_length &lt; dist[s][d]:\n                    # update shortest path length\n                    dist[s][d] = p_length\n            p_length += 1\n        except IndexError:\n            print(f\"IndexError occurred. Reached maximum path length of {p_length}\")\n            break\n    return dist\ndistance_matrix(paths)\n</pre>  def distance_matrix(paths):     \"\"\"     Calculates shortest path distances between all pairs of     nodes based on the observed shortest paths (and subpaths)     \"\"\"     dist = defaultdict(lambda: defaultdict(lambda: _np.inf))     # Log.add('Calculating distance matrix based on empirical paths ...', Severity.INFO)     nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject     for v in nodes:         dist[v][v] = 0      p_length = 1     index, edge_weights = paths.edge_index_k_weighted(k=p_length)     sources = index[0]     destinations = index[-1]     for e, (s, d) in enumerate(zip(sources, destinations)):         s = s.item()         d = d.item()         dist[s][d] = p_length         # s_p[s][d] = set({torch.tensor([s,d])})     p_length += 1     while True: # until max path length         try:             index, edge_weights = paths.edge_index_k_weighted(k=p_length)             sources = index[0, :, 0]             destinations = index[1, :, -1]             for e, (s, d) in enumerate(zip(sources, destinations)):                 s = s.item()                 d = d.item()                 if p_length &lt; dist[s][d]:                     # update shortest path length                     dist[s][d] = p_length             p_length += 1         except IndexError:             print(f\"IndexError occurred. Reached maximum path length of {p_length}\")             break     return dist distance_matrix(paths)      <pre>IndexError occurred. Reached maximum path length of 4\n</pre> Out[347]: <pre>defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {0: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {0: 0, 1: 1, 3: 2}),\n             1: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {1: 0, 3: 1, 5: 2}),\n             2: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {2: 0, 1: 1, 3: 2, 5: 3}),\n             3: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {3: 0, 4: 1, 5: 1}),\n             4: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {4: 0}),\n             5: defaultdict(&lt;function __main__.distance_matrix.&lt;locals&gt;.&lt;lambda&gt;.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n                         {5: 0})})</pre> In\u00a0[352]: Copied! <pre>def test_distance_matrix_paths(simple_paths_centralities):\n    dm = distance_matrix(simple_paths_centralities)\n    assert dm[0] == {0: 0, 1: 1, 3: 2}\n    assert dm[1] == {1: 0, 3: 1, 5: 2}\n    assert dm[2] == {2: 0, 1: 1, 3: 2, 5: 3}\n    assert dm[3] == {3: 0, 4: 1, 5: 1}\n    assert dm[4] == {4: 0}\n    assert dm[5] == {5: 0}\n\ntest_distance_matrix_paths(paths)\n</pre> def test_distance_matrix_paths(simple_paths_centralities):     dm = distance_matrix(simple_paths_centralities)     assert dm[0] == {0: 0, 1: 1, 3: 2}     assert dm[1] == {1: 0, 3: 1, 5: 2}     assert dm[2] == {2: 0, 1: 1, 3: 2, 5: 3}     assert dm[3] == {3: 0, 4: 1, 5: 1}     assert dm[4] == {4: 0}     assert dm[5] == {5: 0}  test_distance_matrix_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> In\u00a0[355]: Copied! <pre>def closeness(paths, normalized=False):\n    \"\"\"Calculates the closeness of nodes based on observed shortest paths\n    between all nodes\n\n    Parameters\n    ----------\n    paths: Paths\n    normalized: bool\n        normalize such that largest value is 1.0\n\n    Returns\n    -------\n    dict\n    \"\"\"\n    node_centralities = defaultdict(lambda: 0)\n    distances = distance_matrix(paths)\n    nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject\n\n    for x in nodes:\n        # calculate closeness centrality of x\n        for d in nodes:\n            if x != d and distances[d][x] &lt; _np.inf:\n                node_centralities[x] += 1.0 / distances[d][x]\n\n    # assign zero values to nodes not occurring\n    \n    for v in nodes:\n        node_centralities[v] += 0.0\n\n    if normalized:\n        m = max(node_centralities.values())\n        for v in nodes:\n            node_centralities[v] /= m\n\n    return node_centralities\ncloseness(paths, normalized=False)\n</pre> def closeness(paths, normalized=False):     \"\"\"Calculates the closeness of nodes based on observed shortest paths     between all nodes      Parameters     ----------     paths: Paths     normalized: bool         normalize such that largest value is 1.0      Returns     -------     dict     \"\"\"     node_centralities = defaultdict(lambda: 0)     distances = distance_matrix(paths)     nodes = [v.item() for v in paths.edge_index.reshape(-1).unique(dim=0)] # NOTE: modify once set of nodes can be obtained from path obeject      for x in nodes:         # calculate closeness centrality of x         for d in nodes:             if x != d and distances[d][x] &lt; _np.inf:                 node_centralities[x] += 1.0 / distances[d][x]      # assign zero values to nodes not occurring          for v in nodes:         node_centralities[v] += 0.0      if normalized:         m = max(node_centralities.values())         for v in nodes:             node_centralities[v] /= m      return node_centralities closeness(paths, normalized=False) <pre>IndexError occurred. Reached maximum path length of 4\n</pre> Out[355]: <pre>defaultdict(&lt;function __main__.closeness.&lt;locals&gt;.&lt;lambda&gt;()&gt;,\n            {1: 2.0, 3: 2.0, 4: 1.0, 5: 1.8333333333333333, 0: 0.0, 2: 0.0})</pre> In\u00a0[360]: Copied! <pre>def test_closeness_paths(simple_paths_centralities):\n    c = closeness(simple_paths_centralities, normalized=False)\n    assert c[0] == 0.0\n    # 1 reachable from 0 and 2 in one step\n    assert c[1] == 1/1 + 1/1\n    assert c[2] == 0\n    # 3 reachable from 1 in one step, from 0 and 3 in two steps\n    assert c[3] == 1 + 1/2 + 1/2\n    assert c[4] == 1\n    # 5 reachable from 3 in one step, from 1 in two steps, from 2 in three steps\n    assert c[5] == 1 + 1/2 + 1/3\ntest_closeness_paths(paths)\n</pre> def test_closeness_paths(simple_paths_centralities):     c = closeness(simple_paths_centralities, normalized=False)     assert c[0] == 0.0     # 1 reachable from 0 and 2 in one step     assert c[1] == 1/1 + 1/1     assert c[2] == 0     # 3 reachable from 1 in one step, from 0 and 3 in two steps     assert c[3] == 1 + 1/2 + 1/2     assert c[4] == 1     # 5 reachable from 3 in one step, from 1 in two steps, from 2 in three steps     assert c[5] == 1 + 1/2 + 1/3 test_closeness_paths(paths) <pre>IndexError occurred. Reached maximum path length of 4\n</pre>"},{"location":"tutorial/xx_test_random_walks/","title":"Xx test random walks","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nprint('Running on', pp.config['torch']['device'])\nimport torch\nfrom pathpyG.processes.random_walk import RandomWalk, HigherOrderRandomWalk\n</pre> import pathpyG as pp print('Running on', pp.config['torch']['device']) import torch from pathpyG.processes.random_walk import RandomWalk, HigherOrderRandomWalk  <pre>Running on cpu\n</pre> In\u00a0[2]: Copied! <pre>g = pp.io.read_netzschleuder_network('karate', '77')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_network('karate', '77') print(g) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n\nNode attributes\n\tnode__pos\t\t&lt;class 'list'&gt;\n\tnode_name\t\t&lt;class 'list'&gt;\n\tnode_groups\t\t&lt;class 'list'&gt;\n\nGraph attributes\n\turl\t\t&lt;class 'str'&gt;\n\tcitation\t\t&lt;class 'str'&gt;\n\tdescription\t\t&lt;class 'str'&gt;\n\tname\t\t&lt;class 'str'&gt;\n\ttags\t\t&lt;class 'list'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[3]: Copied! <pre>rw = RandomWalk(g)\n</pre> rw = RandomWalk(g) In\u00a0[4]: Copied! <pre>data = rw.run_experiment(steps=100,runs=range(34))\n</pre> data = rw.run_experiment(steps=100,runs=range(34)) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 34/34 [00:00&lt;00:00, 347.70it/s]\n</pre> In\u00a0[5]: Copied! <pre>data\n</pre> data Out[5]: run_id seed time node state 0 0 0 0 0 True 1 0 0 0 1 False 2 0 0 0 2 False 3 0 0 0 3 False 4 0 0 0 4 False ... ... ... ... ... ... 7951 33 33 98 1 False 7952 33 33 99 0 True 7953 33 33 99 21 False 7954 33 33 100 3 True 7955 33 33 100 0 False <p>7956 rows \u00d7 5 columns</p> In\u00a0[7]: Copied! <pre>paths = rw.get_paths(data)\n</pre> paths = rw.get_paths(data) <pre>[0, 8, 32, 31, 32, 22, 32, 8, 33, 30, 1, 30, 32, 20, 33, 14, 32, 15, 33, 13, 1, 21, 1, 30, 33, 13, 1, 19, 1, 7, 0, 13, 33, 9, 33, 18, 33, 13, 0, 5, 6, 0, 1, 2, 7, 0, 12, 0, 12, 0, 17, 1, 30, 32, 23, 32, 22, 32, 23, 25, 24, 25, 23, 33, 23, 29, 33, 27, 24, 25, 23, 25, 24, 27, 23, 25, 23, 27, 24, 31, 33, 23, 33, 13, 2, 7, 0, 19, 0, 6, 16, 5, 10, 0, 5, 10, 0, 19, 33, 27, 24]\n[1, 0, 31, 0, 5, 6, 4, 6, 16, 6, 16, 6, 0, 1, 30, 32, 31, 32, 30, 1, 30, 33, 20, 32, 2, 8, 2, 28, 2, 0, 10, 4, 6, 4, 10, 0, 8, 32, 20, 32, 18, 32, 31, 24, 25, 31, 25, 31, 32, 2, 27, 2, 3, 1, 3, 13, 33, 29, 23, 29, 32, 29, 33, 30, 33, 23, 29, 32, 20, 33, 29, 26, 33, 28, 31, 25, 23, 29, 32, 14, 32, 14, 33, 32, 2, 28, 2, 3, 2, 32, 8, 32, 18, 33, 9, 2, 28, 33, 27, 33, 29]\n[2, 0, 19, 33, 31, 32, 30, 1, 3, 0, 21, 1, 7, 0, 19, 1, 3, 2, 27, 2, 13, 2, 27, 33, 23, 33, 29, 32, 33, 20, 32, 20, 33, 32, 33, 31, 25, 23, 27, 33, 9, 33, 30, 8, 30, 8, 0, 19, 33, 15, 32, 29, 23, 25, 24, 27, 33, 27, 2, 28, 31, 24, 25, 24, 27, 24, 25, 31, 33, 27, 24, 31, 32, 2, 32, 15, 33, 23, 25, 23, 25, 31, 0, 3, 0, 5, 0, 11, 0, 4, 6, 4, 10, 0, 11, 0, 2, 9, 33, 28, 31]\n[3, 7, 0, 5, 16, 6, 16, 6, 5, 6, 16, 6, 0, 3, 0, 3, 13, 1, 7, 0, 7, 3, 2, 1, 19, 0, 11, 0, 31, 33, 9, 33, 19, 33, 27, 23, 29, 26, 29, 32, 8, 0, 11, 0, 17, 1, 17, 1, 2, 27, 24, 31, 25, 23, 32, 20, 32, 23, 32, 22, 32, 29, 33, 26, 33, 18, 33, 20, 32, 22, 32, 29, 26, 33, 28, 2, 8, 30, 8, 2, 27, 24, 27, 23, 32, 30, 33, 20, 33, 28, 33, 27, 23, 29, 26, 33, 18, 32, 30, 32, 29]\n[4, 10, 0, 12, 3, 1, 0, 2, 0, 7, 1, 0, 19, 33, 26, 33, 13, 3, 0, 7, 0, 3, 2, 28, 31, 0, 11, 0, 6, 4, 6, 4, 10, 0, 12, 0, 11, 0, 3, 0, 31, 33, 28, 2, 8, 2, 28, 33, 8, 30, 32, 18, 32, 33, 23, 27, 33, 14, 32, 29, 23, 25, 23, 29, 33, 15, 32, 14, 33, 32, 30, 32, 8, 0, 2, 27, 23, 27, 24, 25, 23, 27, 23, 29, 26, 33, 13, 2, 32, 31, 32, 2, 28, 33, 13, 3, 0, 10, 0, 2, 9]\n[5, 6, 0, 10, 5, 10, 0, 5, 0, 11, 0, 4, 6, 16, 5, 0, 21, 1, 0, 13, 0, 1, 17, 0, 31, 32, 20, 33, 14, 33, 28, 33, 20, 32, 20, 32, 15, 32, 14, 33, 29, 26, 29, 32, 18, 32, 2, 9, 33, 26, 33, 26, 33, 26, 29, 23, 27, 33, 31, 32, 8, 30, 1, 0, 2, 13, 0, 10, 5, 6, 0, 31, 24, 31, 33, 31, 0, 2, 1, 19, 1, 17, 0, 4, 0, 17, 1, 17, 1, 13, 3, 0, 10, 0, 5, 6, 4, 0, 17, 0, 19]\n[6, 0, 10, 5, 16, 6, 4, 6, 5, 6, 0, 31, 32, 2, 7, 3, 12, 3, 0, 13, 33, 31, 25, 31, 33, 20, 33, 23, 27, 33, 18, 32, 22, 32, 30, 33, 13, 1, 0, 6, 5, 16, 6, 5, 0, 7, 0, 13, 2, 13, 2, 3, 1, 19, 1, 17, 0, 6, 5, 0, 3, 0, 6, 5, 6, 4, 6, 0, 3, 1, 21, 0, 4, 10, 5, 16, 5, 6, 16, 5, 0, 12, 0, 31, 32, 31, 25, 31, 32, 30, 33, 20, 32, 30, 33, 15, 32, 22, 32, 23, 33]\n[7, 0, 8, 2, 7, 2, 9, 33, 15, 32, 29, 23, 29, 32, 23, 25, 24, 25, 23, 27, 23, 32, 15, 32, 30, 8, 0, 7, 1, 19, 0, 17, 0, 21, 0, 4, 6, 16, 6, 0, 10, 4, 10, 5, 10, 5, 10, 0, 6, 0, 11, 0, 5, 10, 4, 6, 16, 5, 10, 5, 0, 17, 1, 30, 8, 2, 32, 33, 29, 33, 13, 3, 2, 0, 10, 0, 1, 19, 33, 27, 23, 32, 15, 32, 33, 30, 8, 0, 21, 1, 21, 1, 13, 33, 26, 33, 19, 0, 8, 2, 9]\n[8, 32, 33, 26, 29, 32, 15, 32, 20, 32, 31, 24, 27, 33, 27, 23, 25, 24, 25, 24, 25, 31, 24, 31, 24, 25, 23, 32, 29, 33, 31, 25, 24, 27, 23, 27, 2, 3, 7, 2, 32, 29, 33, 27, 33, 23, 33, 23, 27, 33, 23, 25, 24, 25, 31, 32, 14, 33, 31, 28, 31, 33, 15, 33, 27, 23, 29, 33, 20, 33, 28, 33, 13, 3, 2, 27, 24, 31, 0, 19, 33, 14, 33, 31, 0, 1, 19, 33, 32, 33, 28, 33, 13, 0, 8, 32, 8, 32, 22, 32, 8]\n[9, 33, 23, 33, 31, 25, 23, 25, 24, 31, 25, 24, 25, 24, 25, 23, 29, 23, 25, 24, 25, 31, 28, 2, 13, 0, 7, 2, 3, 0, 11, 0, 21, 0, 17, 0, 8, 30, 1, 7, 1, 3, 7, 3, 12, 3, 2, 8, 2, 0, 2, 32, 23, 29, 33, 28, 2, 7, 1, 30, 1, 0, 19, 33, 32, 8, 30, 33, 13, 0, 31, 25, 23, 27, 24, 31, 28, 2, 32, 33, 9, 2, 1, 3, 1, 21, 1, 2, 27, 23, 33, 23, 32, 30, 8, 2, 13, 1, 0, 11, 0]\n[10, 4, 10, 4, 10, 4, 10, 4, 10, 4, 0, 13, 33, 28, 31, 24, 31, 25, 24, 27, 23, 32, 15, 32, 23, 27, 24, 25, 23, 29, 23, 27, 23, 32, 22, 32, 2, 7, 0, 5, 0, 4, 6, 5, 16, 5, 16, 6, 0, 19, 33, 26, 29, 32, 8, 30, 8, 32, 14, 33, 18, 32, 20, 32, 31, 28, 31, 25, 31, 0, 5, 16, 5, 10, 4, 0, 31, 0, 10, 5, 6, 5, 16, 6, 4, 6, 16, 5, 6, 5, 6, 0, 11, 0, 4, 10, 5, 16, 5, 16, 5]\n[11, 0, 2, 9, 33, 27, 24, 27, 2, 7, 1, 21, 0, 5, 0, 1, 19, 33, 20, 32, 23, 29, 26, 29, 33, 18, 33, 13, 0, 5, 0, 6, 16, 5, 6, 4, 6, 0, 5, 10, 0, 11, 0, 4, 6, 5, 0, 31, 25, 31, 24, 25, 24, 25, 24, 27, 33, 15, 33, 30, 1, 3, 12, 0, 8, 30, 33, 29, 26, 29, 33, 31, 25, 31, 33, 23, 25, 23, 32, 8, 32, 2, 9, 33, 9, 2, 32, 15, 33, 14, 32, 8, 30, 33, 29, 32, 2, 32, 33, 9, 2]\n[12, 0, 6, 16, 6, 0, 21, 1, 30, 8, 2, 0, 4, 10, 5, 6, 5, 0, 3, 12, 0, 1, 0, 8, 30, 1, 19, 1, 21, 1, 21, 0, 17, 0, 13, 33, 29, 23, 33, 30, 1, 21, 1, 13, 33, 14, 33, 32, 2, 32, 18, 32, 18, 33, 18, 32, 15, 33, 18, 33, 32, 14, 32, 30, 1, 13, 1, 17, 0, 5, 6, 16, 6, 4, 6, 0, 8, 33, 27, 2, 9, 33, 30, 33, 13, 0, 1, 21, 0, 1, 13, 1, 17, 0, 7, 2, 27, 2, 32, 30, 32]\n[13, 3, 2, 3, 12, 3, 0, 11, 0, 1, 2, 27, 2, 1, 2, 28, 33, 29, 33, 18, 33, 31, 28, 2, 0, 17, 1, 3, 1, 21, 1, 17, 1, 17, 0, 1, 7, 1, 13, 1, 2, 8, 32, 14, 33, 31, 28, 31, 28, 2, 7, 2, 28, 2, 27, 33, 15, 32, 14, 33, 23, 33, 32, 20, 32, 8, 33, 8, 30, 1, 2, 1, 13, 0, 6, 0, 13, 1, 2, 27, 23, 29, 23, 27, 2, 27, 2, 8, 0, 13, 1, 3, 0, 5, 16, 5, 16, 5, 10, 0, 13]\n[14, 32, 8, 30, 32, 33, 23, 29, 32, 33, 8, 30, 33, 27, 24, 27, 33, 8, 0, 31, 24, 27, 24, 31, 25, 23, 32, 33, 19, 33, 19, 1, 17, 0, 5, 16, 6, 0, 8, 30, 32, 23, 25, 31, 28, 31, 0, 4, 6, 16, 6, 4, 10, 5, 10, 0, 7, 0, 19, 1, 19, 1, 2, 8, 2, 8, 30, 8, 0, 5, 16, 5, 0, 17, 0, 17, 1, 21, 0, 19, 1, 30, 33, 31, 24, 25, 24, 31, 28, 2, 13, 2, 9, 33, 19, 1, 3, 13, 0, 11, 0]\n[15, 33, 26, 33, 27, 23, 29, 23, 27, 2, 8, 33, 15, 33, 27, 23, 25, 31, 33, 9, 33, 29, 32, 23, 33, 20, 33, 31, 33, 30, 1, 21, 1, 13, 3, 1, 2, 28, 31, 25, 24, 27, 33, 8, 30, 1, 2, 13, 33, 30, 32, 31, 28, 33, 30, 8, 0, 2, 0, 31, 25, 23, 33, 27, 23, 32, 18, 33, 28, 31, 25, 23, 32, 8, 33, 20, 32, 23, 33, 8, 33, 18, 33, 31, 24, 27, 23, 27, 23, 33, 8, 0, 8, 2, 32, 14, 33, 19, 1, 0, 6]\n[16, 5, 16, 6, 5, 6, 4, 10, 0, 2, 28, 33, 19, 1, 19, 0, 7, 2, 7, 2, 7, 0, 7, 1, 2, 7, 0, 19, 1, 13, 0, 5, 10, 0, 13, 3, 13, 2, 27, 24, 27, 24, 25, 31, 0, 8, 33, 8, 32, 2, 9, 33, 18, 32, 29, 23, 25, 31, 33, 29, 33, 30, 8, 2, 13, 2, 3, 13, 33, 19, 33, 29, 32, 2, 1, 21, 0, 2, 27, 23, 32, 14, 33, 20, 32, 31, 32, 18, 33, 9, 2, 27, 24, 31, 32, 15, 33, 13, 2, 3, 1]\n[17, 0, 10, 0, 7, 0, 12, 3, 12, 3, 2, 0, 19, 33, 29, 23, 29, 23, 33, 26, 33, 20, 33, 9, 2, 1, 19, 0, 8, 30, 8, 32, 22, 32, 15, 32, 20, 33, 32, 23, 27, 2, 27, 24, 27, 23, 29, 23, 33, 29, 32, 15, 32, 14, 33, 32, 22, 32, 15, 32, 23, 29, 33, 19, 1, 21, 1, 2, 13, 1, 7, 1, 0, 31, 25, 24, 27, 23, 33, 30, 8, 32, 14, 33, 31, 0, 6, 16, 6, 16, 6, 16, 5, 16, 5, 10, 4, 6, 16, 5, 0]\n[18, 32, 20, 33, 29, 23, 29, 26, 29, 26, 29, 26, 29, 32, 2, 8, 32, 15, 33, 9, 33, 19, 1, 7, 0, 13, 2, 28, 31, 33, 26, 29, 23, 32, 15, 32, 30, 33, 26, 33, 19, 0, 10, 5, 6, 4, 10, 5, 6, 16, 6, 4, 6, 4, 0, 10, 5, 0, 17, 1, 0, 21, 1, 19, 33, 32, 22, 32, 29, 23, 32, 18, 33, 8, 30, 1, 2, 32, 20, 33, 31, 33, 20, 32, 23, 32, 30, 33, 26, 33, 28, 33, 15, 33, 26, 29, 33, 13, 33, 28, 31]\n[19, 0, 12, 0, 19, 0, 17, 0, 13, 1, 3, 12, 3, 2, 0, 2, 8, 32, 2, 27, 23, 33, 32, 31, 25, 31, 28, 33, 28, 33, 19, 0, 31, 24, 27, 24, 25, 24, 31, 33, 23, 27, 23, 33, 28, 31, 25, 31, 33, 32, 15, 33, 18, 33, 29, 33, 32, 20, 32, 15, 32, 30, 1, 30, 32, 33, 23, 27, 2, 13, 1, 21, 1, 30, 32, 2, 9, 33, 18, 33, 19, 1, 13, 2, 9, 33, 32, 29, 33, 8, 33, 32, 14, 32, 20, 32, 8, 0, 3, 1, 30]\n[20, 33, 8, 32, 23, 25, 31, 33, 8, 30, 32, 2, 8, 33, 14, 32, 8, 30, 1, 17, 0, 5, 16, 5, 0, 17, 0, 3, 12, 0, 19, 1, 17, 0, 13, 0, 6, 5, 16, 5, 0, 31, 24, 27, 24, 31, 33, 30, 1, 7, 1, 19, 1, 21, 1, 17, 0, 3, 12, 3, 13, 2, 0, 11, 0, 2, 32, 18, 33, 9, 33, 13, 0, 6, 16, 6, 0, 31, 25, 23, 32, 15, 33, 32, 31, 28, 2, 0, 11, 0, 8, 30, 32, 29, 32, 22, 32, 29, 23, 25, 31]\n[21, 1, 30, 32, 18, 32, 33, 15, 32, 8, 33, 32, 29, 33, 15, 33, 27, 2, 32, 22, 32, 30, 8, 32, 8, 2, 27, 24, 27, 24, 27, 23, 27, 2, 13, 0, 17, 0, 2, 13, 0, 21, 1, 30, 1, 2, 7, 3, 7, 1, 2, 13, 0, 17, 1, 13, 0, 1, 19, 0, 8, 30, 1, 17, 1, 21, 1, 2, 9, 33, 15, 32, 33, 20, 33, 15, 32, 20, 32, 30, 33, 13, 3, 13, 3, 13, 1, 30, 32, 31, 24, 25, 24, 27, 2, 28, 2, 8, 30, 32, 29]\n[22, 32, 8, 32, 33, 29, 32, 22, 32, 18, 32, 29, 32, 31, 24, 25, 23, 29, 33, 28, 33, 28, 2, 3, 13, 0, 7, 2, 28, 33, 14, 32, 14, 33, 15, 32, 31, 28, 31, 28, 33, 26, 33, 8, 30, 1, 30, 33, 20, 33, 32, 20, 32, 2, 27, 2, 9, 33, 26, 33, 18, 32, 20, 33, 29, 23, 29, 26, 29, 33, 27, 2, 32, 30, 8, 30, 33, 27, 23, 29, 32, 20, 32, 18, 32, 33, 26, 29, 32, 14, 32, 15, 32, 31, 33, 20, 32, 23, 33, 15, 32]\n[23, 25, 23, 32, 29, 26, 33, 9, 2, 1, 17, 1, 21, 1, 7, 0, 21, 1, 30, 32, 15, 33, 9, 33, 9, 33, 27, 24, 25, 23, 33, 27, 33, 32, 14, 32, 22, 32, 31, 28, 31, 25, 31, 32, 14, 33, 27, 23, 25, 24, 27, 24, 31, 25, 24, 25, 23, 27, 2, 27, 23, 32, 18, 33, 19, 0, 1, 7, 0, 10, 4, 10, 5, 16, 6, 16, 6, 5, 6, 16, 5, 10, 5, 16, 5, 6, 4, 10, 4, 10, 5, 16, 5, 6, 5, 10, 0, 2, 1, 19, 1]\n[24, 25, 23, 25, 31, 32, 29, 33, 30, 32, 15, 32, 23, 32, 30, 8, 30, 33, 31, 28, 2, 9, 2, 3, 2, 8, 2, 27, 23, 32, 14, 33, 19, 1, 3, 12, 3, 0, 12, 3, 13, 3, 1, 17, 1, 21, 1, 13, 3, 12, 3, 13, 1, 21, 1, 21, 1, 13, 3, 1, 7, 1, 19, 1, 2, 7, 1, 0, 5, 6, 0, 2, 7, 2, 0, 12, 3, 7, 1, 2, 3, 7, 2, 3, 12, 3, 1, 19, 0, 11, 0, 17, 1, 30, 8, 32, 20, 32, 30, 1, 17]\n[25, 31, 0, 11, 0, 31, 24, 25, 24, 31, 24, 27, 33, 19, 33, 20, 32, 14, 32, 2, 8, 2, 3, 12, 3, 1, 2, 0, 13, 2, 7, 1, 30, 32, 2, 0, 10, 0, 6, 0, 8, 32, 31, 28, 2, 13, 0, 1, 17, 0, 10, 4, 0, 2, 7, 0, 17, 0, 21, 1, 13, 2, 1, 7, 2, 1, 30, 33, 23, 29, 23, 32, 2, 7, 3, 1, 21, 0, 12, 0, 13, 1, 3, 7, 3, 0, 4, 10, 5, 10, 0, 3, 12, 3, 12, 0, 5, 6, 5, 0, 8]\n[26, 29, 23, 27, 24, 25, 24, 25, 31, 0, 2, 9, 33, 8, 32, 22, 32, 22, 32, 33, 32, 14, 33, 26, 33, 23, 29, 26, 33, 27, 33, 28, 31, 24, 31, 0, 11, 0, 13, 33, 27, 2, 9, 2, 1, 0, 2, 13, 33, 19, 33, 15, 33, 15, 32, 22, 32, 23, 25, 24, 25, 24, 31, 0, 31, 0, 13, 2, 0, 3, 0, 3, 2, 27, 24, 25, 24, 25, 24, 31, 32, 33, 32, 29, 33, 9, 2, 32, 22, 32, 14, 32, 8, 33, 14, 33, 26, 33, 31, 28, 33]\n[27, 24, 27, 2, 7, 2, 0, 12, 0, 10, 5, 10, 5, 16, 5, 16, 6, 0, 13, 0, 1, 17, 1, 7, 2, 0, 12, 0, 10, 0, 21, 1, 30, 33, 30, 32, 31, 0, 6, 4, 0, 12, 0, 19, 33, 20, 32, 29, 26, 33, 8, 0, 2, 13, 3, 1, 13, 2, 27, 24, 27, 2, 3, 7, 1, 30, 8, 30, 1, 2, 32, 22, 32, 23, 33, 8, 32, 31, 32, 33, 8, 32, 31, 33, 8, 32, 2, 0, 17, 0, 21, 0, 7, 3, 2, 1, 17, 0, 11, 0, 8]\n[28, 31, 24, 31, 33, 30, 1, 3, 2, 7, 2, 3, 2, 8, 2, 9, 33, 23, 29, 26, 33, 27, 33, 18, 33, 29, 33, 13, 0, 10, 0, 11, 0, 4, 0, 4, 10, 0, 31, 24, 27, 33, 15, 32, 22, 32, 30, 32, 29, 26, 29, 23, 33, 14, 32, 14, 32, 22, 32, 14, 32, 23, 29, 23, 29, 32, 22, 32, 14, 32, 8, 30, 8, 32, 23, 25, 31, 28, 2, 0, 7, 0, 17, 0, 7, 3, 0, 17, 0, 31, 33, 29, 23, 29, 32, 30, 32, 8, 2, 27, 33]\n[29, 26, 29, 33, 19, 33, 15, 32, 8, 2, 1, 2, 27, 23, 25, 23, 27, 23, 32, 2, 27, 33, 31, 32, 31, 0, 2, 27, 23, 27, 2, 3, 0, 2, 3, 0, 3, 13, 33, 19, 0, 4, 0, 12, 0, 3, 7, 0, 6, 0, 17, 0, 13, 2, 27, 2, 7, 2, 27, 23, 29, 33, 27, 33, 20, 33, 31, 28, 31, 25, 31, 24, 25, 24, 31, 0, 31, 32, 31, 24, 31, 28, 2, 27, 2, 1, 0, 5, 6, 0, 13, 0, 6, 0, 19, 33, 27, 2, 0, 13, 33]\n[30, 33, 9, 2, 3, 13, 3, 13, 0, 10, 5, 6, 16, 6, 4, 0, 2, 28, 2, 9, 2, 3, 13, 33, 26, 29, 33, 31, 24, 27, 24, 31, 28, 31, 33, 13, 0, 13, 3, 13, 1, 30, 1, 17, 0, 12, 3, 12, 0, 2, 3, 12, 3, 0, 10, 4, 0, 2, 13, 2, 3, 2, 9, 33, 13, 3, 2, 9, 33, 32, 23, 25, 24, 25, 23, 32, 23, 29, 32, 15, 32, 8, 0, 17, 0, 19, 1, 2, 9, 2, 13, 3, 2, 13, 33, 19, 1, 30, 32, 33, 20]\n[31, 0, 3, 2, 0, 4, 6, 0, 13, 1, 19, 33, 13, 0, 8, 33, 23, 29, 26, 29, 26, 29, 33, 27, 24, 25, 31, 0, 13, 1, 30, 1, 7, 0, 7, 2, 28, 31, 25, 23, 32, 14, 33, 28, 2, 3, 0, 7, 2, 13, 3, 1, 0, 5, 16, 5, 0, 21, 1, 0, 21, 0, 21, 1, 13, 1, 21, 0, 2, 32, 18, 33, 30, 32, 8, 2, 27, 24, 31, 33, 19, 1, 0, 17, 0, 12, 0, 4, 10, 5, 10, 4, 10, 4, 6, 0, 6, 5, 6, 16, 6]\n[32, 22, 32, 29, 26, 33, 20, 33, 9, 2, 13, 3, 0, 5, 16, 6, 16, 6, 5, 10, 5, 6, 5, 16, 6, 0, 2, 9, 2, 9, 33, 20, 33, 15, 33, 30, 8, 30, 33, 18, 33, 14, 33, 28, 2, 13, 33, 20, 32, 33, 30, 33, 23, 25, 24, 27, 23, 33, 23, 27, 33, 19, 33, 18, 32, 29, 32, 23, 27, 24, 31, 33, 18, 33, 9, 2, 32, 23, 29, 33, 31, 28, 33, 27, 23, 29, 23, 32, 22, 32, 33, 26, 29, 33, 28, 33, 27, 24, 27, 2, 7]\n[33, 15, 33, 20, 32, 2, 27, 24, 31, 28, 31, 32, 22, 32, 30, 33, 32, 30, 8, 32, 20, 32, 23, 29, 26, 33, 19, 1, 21, 0, 6, 16, 6, 0, 1, 0, 3, 0, 4, 6, 5, 16, 6, 4, 6, 16, 6, 5, 6, 4, 6, 16, 6, 4, 10, 5, 0, 13, 0, 17, 0, 6, 0, 4, 10, 0, 10, 4, 6, 16, 6, 4, 0, 7, 1, 17, 0, 8, 33, 13, 2, 32, 8, 30, 32, 14, 33, 14, 33, 9, 2, 13, 3, 1, 30, 1, 3, 1, 21, 0, 3]\n</pre> In\u00a0[14]: Copied! <pre>paths.dags[0].edge_index\n</pre> paths.dags[0].edge_index Out[14]: <pre>tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n          98,  99],\n        [  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n          99, 100]])</pre> In\u00a0[8]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(paths, max_order=3)\ng2 = m.layers[2]\nprint(g2)\n</pre> m = pp.MultiOrderModel.from_DAGs(paths, max_order=3) g2 = m.layers[2] print(g2) <pre>Directed graph with 154 nodes and 1005 edges\n\nNode attributes\n\tnode_sequences\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([154, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1005])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[9]: Copied! <pre>#print(g_ho)\n</pre> #print(g_ho) In\u00a0[10]: Copied! <pre>#for v in g_ho.nodes:\n#    print(v)\n</pre> #for v in g_ho.nodes: #    print(v) In\u00a0[9]: Copied! <pre>g2= pp.Graph.from_edge_list([\n    ['a', 'b'],\n    ['b', 'c'],\n    ['c', 'd'],\n    ['d', 'e'],\n    ['e', 'f'],\n    ['f', 'g'],\n    ['g', 'h'],\n    ['h', 'i'],\n    ['i', 'j'],\n    ['j', 'k'],\n    ['k', 'l'],\n    ['l', 'm'],\n    ['m', 'n'],\n    ['n', 'o'],\n    ['o', 'a']\n])\n</pre> g2= pp.Graph.from_edge_list([     ['a', 'b'],     ['b', 'c'],     ['c', 'd'],     ['d', 'e'],     ['e', 'f'],     ['f', 'g'],     ['g', 'h'],     ['h', 'i'],     ['i', 'j'],     ['j', 'k'],     ['k', 'l'],     ['l', 'm'],     ['m', 'n'],     ['n', 'o'],     ['o', 'a'] ]) In\u00a0[10]: Copied! <pre>g2.mapping.to_idx('b')\n</pre> g2.mapping.to_idx('b') Out[10]: <pre>1</pre> In\u00a0[11]: Copied! <pre>rw2 = RandomWalk(g2)\n</pre> rw2 = RandomWalk(g2) In\u00a0[13]: Copied! <pre>data2 = rw2.run_experiment(steps=20,runs=['a','b'])\n</pre> data2 = rw2.run_experiment(steps=20,runs=['a','b']) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00, 1900.02it/s]\n</pre> In\u00a0[15]: Copied! <pre>data2\n</pre> data2 Out[15]: run_id seed time node state 0 0 a 0 a True 1 0 a 0 b False 2 0 a 0 c False 3 0 a 0 d False 4 0 a 0 e False ... ... ... ... ... ... 105 1 b 18 d False 106 1 b 19 f True 107 1 b 19 e False 108 1 b 20 g True 109 1 b 20 f False <p>110 rows \u00d7 5 columns</p> In\u00a0[16]: Copied! <pre>paths2 = rw2.get_paths(data2)\n\npaths2.paths\n</pre> paths2 = rw2.get_paths(data2)  paths2.paths Out[16]: <pre>{0: tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,\n           3,  4],\n         [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,\n           4,  5]], dtype=torch.int32),\n 1: tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,\n           4,  5],\n         [ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  0,  1,  2,  3,  4,\n           5,  6]], dtype=torch.int32)}</pre> In\u00a0[17]: Copied! <pre>pp.plot(g2);\n</pre> pp.plot(g2); In\u00a0[18]: Copied! <pre>g2.mapping.idx_to_id\n</pre> g2.mapping.idx_to_id Out[18]: <pre>{0: 'a',\n 1: 'b',\n 2: 'c',\n 3: 'd',\n 4: 'e',\n 5: 'f',\n 6: 'g',\n 7: 'h',\n 8: 'i',\n 9: 'j',\n 10: 'k',\n 11: 'l',\n 12: 'm',\n 13: 'n',\n 14: 'o'}</pre> In\u00a0[19]: Copied! <pre>g2_ho = pp.HigherOrderGraph(paths2, order = 2)\n</pre> g2_ho = pp.HigherOrderGraph(paths2, order = 2) In\u00a0[20]: Copied! <pre>pp.plot(g2_ho,node_label=[g2_ho.mapping.to_id(x) for x in range(g2_ho.N)]);\n</pre> pp.plot(g2_ho,node_label=[g2_ho.mapping.to_id(x) for x in range(g2_ho.N)]); In\u00a0[14]: Copied! <pre>g3 = pp.Graph.from_edge_list([\n    ['a','b'],\n    ['b','c'],\n    ['c','a'],\n    ['c','d'],\n    ['d','a']\n    ])\n\ng3.data['edge_weight'] = torch.tensor([[1],[1],[2],[1],[1]])\n</pre> g3 = pp.Graph.from_edge_list([     ['a','b'],     ['b','c'],     ['c','a'],     ['c','d'],     ['d','a']     ])  g3.data['edge_weight'] = torch.tensor([[1],[1],[2],[1],[1]]) In\u00a0[15]: Copied! <pre>pp.plot(g3, node_label= [g3.mapping.to_id(x) for x in range(g3.N)]);\n</pre> pp.plot(g3, node_label= [g3.mapping.to_id(x) for x in range(g3.N)]); In\u00a0[23]: Copied! <pre>g3.mapping.id_to_idx\n</pre> g3.mapping.id_to_idx Out[23]: <pre>{'a': 0, 'b': 1, 'c': 2, 'd': 3}</pre> In\u00a0[18]: Copied! <pre>paths = pp.DAGData(g3.mapping)\npaths.append_walk(['a','b','c'],weight=1)\npaths.append_walk(['b','c','a'],weight=1)\npaths.append_walk(['b','c','d'],weight=0.2)\npaths.append_walk(['c','a','b'],weight=1)\npaths.append_walk(['c','d','a'],weight=0.2)\npaths.append_walk(['d','a','b'],weight=1)\n</pre> paths = pp.DAGData(g3.mapping) paths.append_walk(['a','b','c'],weight=1) paths.append_walk(['b','c','a'],weight=1) paths.append_walk(['b','c','d'],weight=0.2) paths.append_walk(['c','a','b'],weight=1) paths.append_walk(['c','d','a'],weight=0.2) paths.append_walk(['d','a','b'],weight=1) In\u00a0[19]: Copied! <pre>paths.dags\n</pre> paths.dags Out[19]: <pre>[Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=0.20000000298023224),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=0.20000000298023224),\n Data(edge_index=[2, 2], node_sequences=[3, 1], num_nodes=3, weight=1)]</pre> In\u00a0[20]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(paths, max_order=3)\ng3_ho = m.layers[2]\n</pre> m = pp.MultiOrderModel.from_DAGs(paths, max_order=3) g3_ho = m.layers[2] In\u00a0[22]: Copied! <pre>pp.plot(g3_ho, node_label = [g3_ho.mapping.to_id(x) for x in range(g3_ho.N)]);\n</pre> pp.plot(g3_ho, node_label = [g3_ho.mapping.to_id(x) for x in range(g3_ho.N)]); In\u00a0[23]: Copied! <pre>rw = HigherOrderRandomWalk(g3_ho, g3, weight=True)\n</pre> rw = HigherOrderRandomWalk(g3_ho, g3, weight=True) In\u00a0[24]: Copied! <pre>data = rw.run_experiment(steps=100, runs=list(g3_ho.nodes))\n</pre> data = rw.run_experiment(steps=100, runs=list(g3_ho.nodes)) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:00&lt;00:00, 511.38it/s]\n</pre> In\u00a0[25]: Copied! <pre>data\n</pre> data Out[25]: run_id seed time node state 0 0 (a, b) 0 (a, b) True 1 0 (a, b) 0 (b, c) False 2 0 (a, b) 0 (c, a) False 3 0 (a, b) 0 (c, d) False 4 0 (a, b) 0 (d, a) False ... ... ... ... ... ... 1020 4 (d, a) 98 (b, c) False 1021 4 (d, a) 99 (d, a) True 1022 4 (d, a) 99 (c, d) False 1023 4 (d, a) 100 (a, b) True 1024 4 (d, a) 100 (d, a) False <p>1025 rows \u00d7 5 columns</p> In\u00a0[29]: Copied! <pre>path = rw.get_paths(data,[0,1])\nprint(path)\n</pre> path = rw.get_paths(data,[0,1]) print(path) <pre>DAGData with 2 dags with total weight 2.0\n</pre> In\u00a0[30]: Copied! <pre>path.get_walk(0)\n</pre> path.get_walk(0) Out[30]: <pre>('a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'd',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b',\n 'c',\n 'a',\n 'b')</pre> In\u00a0[51]: Copied! <pre>g3.mapping.idx_to_id\n</pre> g3.mapping.idx_to_id Out[51]: <pre>{0: 'a', 1: 'b', 2: 'c', 3: 'd'}</pre> In\u00a0[56]: Copied! <pre>for time,_ in rw.simulation_run(steps=50, seed=('a','b')):\n    print('Current node = {0}'.format(rw.first_order_node(rw.current_node)))\n    print(rw._first_order_visitations)\n</pre> for time,_ in rw.simulation_run(steps=50, seed=('a','b')):     print('Current node = {0}'.format(rw.first_order_node(rw.current_node)))     print(rw._first_order_visitations)  <pre>Current node = c\n[0. 1. 1. 0.]\nCurrent node = a\n[1. 1. 1. 0.]\nCurrent node = b\n[1. 2. 1. 0.]\nCurrent node = c\n[1. 2. 2. 0.]\nCurrent node = a\n[2. 2. 2. 0.]\nCurrent node = b\n[2. 3. 2. 0.]\nCurrent node = c\n[2. 3. 3. 0.]\nCurrent node = a\n[3. 3. 3. 0.]\nCurrent node = b\n[3. 4. 3. 0.]\nCurrent node = c\n[3. 4. 4. 0.]\nCurrent node = a\n[4. 4. 4. 0.]\nCurrent node = b\n[4. 5. 4. 0.]\nCurrent node = c\n[4. 5. 5. 0.]\nCurrent node = d\n[4. 5. 5. 1.]\nCurrent node = a\n[5. 5. 5. 1.]\nCurrent node = b\n[5. 6. 5. 1.]\nCurrent node = c\n[5. 6. 6. 1.]\nCurrent node = d\n[5. 6. 6. 2.]\nCurrent node = a\n[6. 6. 6. 2.]\nCurrent node = b\n[6. 7. 6. 2.]\nCurrent node = c\n[6. 7. 7. 2.]\nCurrent node = a\n[7. 7. 7. 2.]\nCurrent node = b\n[7. 8. 7. 2.]\nCurrent node = c\n[7. 8. 8. 2.]\nCurrent node = a\n[8. 8. 8. 2.]\nCurrent node = b\n[8. 9. 8. 2.]\nCurrent node = c\n[8. 9. 9. 2.]\nCurrent node = d\n[8. 9. 9. 3.]\nCurrent node = a\n[9. 9. 9. 3.]\nCurrent node = b\n[ 9. 10.  9.  3.]\nCurrent node = c\n[ 9. 10. 10.  3.]\nCurrent node = a\n[10. 10. 10.  3.]\nCurrent node = b\n[10. 11. 10.  3.]\nCurrent node = c\n[10. 11. 11.  3.]\nCurrent node = a\n[11. 11. 11.  3.]\nCurrent node = b\n[11. 12. 11.  3.]\nCurrent node = c\n[11. 12. 12.  3.]\nCurrent node = a\n[12. 12. 12.  3.]\nCurrent node = b\n[12. 13. 12.  3.]\nCurrent node = c\n[12. 13. 13.  3.]\nCurrent node = a\n[13. 13. 13.  3.]\nCurrent node = b\n[13. 14. 13.  3.]\nCurrent node = c\n[13. 14. 14.  3.]\nCurrent node = a\n[14. 14. 14.  3.]\nCurrent node = b\n[14. 15. 14.  3.]\nCurrent node = c\n[14. 15. 15.  3.]\nCurrent node = d\n[14. 15. 15.  4.]\nCurrent node = a\n[15. 15. 15.  4.]\nCurrent node = b\n[15. 16. 15.  4.]\nCurrent node = c\n[15. 16. 16.  4.]\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/xx_test_random_walks/#higher-order-random-walk","title":"Higher Order Random Walk\u00b6","text":""}]}