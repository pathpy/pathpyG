{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathpyG as pp\n",
    "from torch_geometric.utils import cumsum, coalesce, degree, sort_edge_index\n",
    "import torch\n",
    "\n",
    "from scipy.sparse.csgraph import bellman_ford, dijkstra\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Graph with 327 nodes, 11636 unique edges and 754032 events in [1385982080.0, 1386345600.0]\n",
      "\n",
      "Graph attributes\n",
      "\tdst\t\t<class 'torch.Tensor'> -> torch.Size([754032])\n",
      "\tsrc\t\t<class 'torch.Tensor'> -> torch.Size([754032])\n",
      "\tt\t\t<class 'torch.Tensor'> -> torch.Size([754032])\n",
      "\n",
      "1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 'src', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t_sp = pp.io.read_csv_temporal_graph('sociopatterns_highschool_2013.tedges', header=False).to_undirected()\n",
    "print(t_sp)\n",
    "print(torch.unique(t_sp.data.t).size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Graph with 68 nodes, 752 unique edges and 2090 events in [899.0, 1796.0]\n",
      "\n",
      "Graph attributes\n",
      "\tdst\t\t<class 'torch.Tensor'> -> torch.Size([2090])\n",
      "\tsrc\t\t<class 'torch.Tensor'> -> torch.Size([2090])\n",
      "\tt\t\t<class 'torch.Tensor'> -> torch.Size([2090])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 'src', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t_ants = pp.io.read_csv_temporal_graph('../data/ants_2_2_val.tedges', header=False)\n",
    "print(t_ants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:00<00:00, 5479.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created temporal event DAG with 1181 nodes and 4023 edges\n",
      "[[ 0.  1. inf ... inf inf inf]\n",
      " [ 1.  0. inf ... inf inf inf]\n",
      " [ 5.  3.  0. ...  2. inf inf]\n",
      " ...\n",
      " [inf inf inf ...  0. inf inf]\n",
      " [inf inf inf ... inf  0. inf]\n",
      " [inf inf inf ...  1. inf  0.]]\n",
      "{'JJJJ': 1399.0180458430464, 'WGG_': 1491.1753968253968, '_Y_B': 1461.7166666666667, 'HHHH': 996.0666666666666, 'WGRB': 1834.2047619047619, 'WYWY': 1540.441666666667, 'WY_G': 761.1371794871794, 'XXXX': 1670.8789682539682, 'LLLL': 1182.7095238095237, 'FFFF': 1062.2448773448773, 'WYG_': 1978.7333333333331, 'WW__': 1790.2027777777776, 'WRWB': 1743.196428571429, 'AAAA': 581.3047619047619, 'WGYW': 1155.8297619047619, 'WBYY': 968.8944444444444, '_R__': 880.7575396825396, 'WYBG': 1448.1039682539683, 'W__W': 1546.319877344877, 'RRRR': 924.1214285714285, 'WYRW': 1601.938095238095, 'WYYB': 865.6825396825396, 'WG_W': 1494.8178571428573, 'WRR_': 1195.2853174603176, 'W__G': 867.9182900432901, '_WRR': 622.8873015873016, 'WY_R': 1549.3750000000002, '_YYY': 1706.9047619047617, 'WRGG': 1571.4158730158733, 'WWGY': 1374.6964285714284, 'WW_W': 1325.6428571428573, 'W_W_': 842.7908730158728, 'WYYR': 798.6825396825395, 'ZZZZ': 662.777922077922, 'W_RG': 1339.8936507936507, 'WBGW': 512.55, 'WBGG': 1543.3130952380955, 'WWRY': 965.0658730158731, 'W___': 518.640909090909, 'VVVV': 394.82142857142856, 'WGGY': 402.0, 'WG__': 402.0, 'WY__': 1094.4130952380951, 'W_GY': 847.5990842490843, 'WYWW': 383.8191197691197, 'OOOO': 866.3738095238094, 'W_BG': 1306.0214285714287, 'TTTT': 549.4, 'WBWY': 1183.2944444444443, 'WWY_': 1060.354761904762, 'WBGR': 67.0, 'WGWY': 597.4166666666666, 'PPPP': 1146.8166666666664, 'WGGW': 917.4214285714285, 'EEEE': 617.1976190476189, '__YR': 134.0, 'WYYG': 548.8972582972583, 'WGGG': 207.70000000000002, 'IIII': 409.81666666666666, 'MMMM': 201.0, 'UUUU': 67.0, 'W_WG': 67.0, 'WYY_': 134.0, 'WWR_': 134.0, 'QQQQ': 415.4, 'WR__': 1117.5440476190474, 'W_GW': 167.5, 'AAAB': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 5773.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created temporal event DAG with 38 nodes and 47 edges\n",
      "(9, 38)\n",
      "(9, 9)\n",
      "[[ 0.  1.  1.  3.  3. inf  1.  2. inf]\n",
      " [inf  0.  1.  2.  2.  1. inf inf  1.]\n",
      " [ 2. inf  0.  1.  1.  1.  3.  1.  1.]\n",
      " [inf inf inf  0. inf inf inf inf inf]\n",
      " [inf inf inf inf  0. inf inf inf inf]\n",
      " [ 1. inf inf inf inf  0.  2.  1. inf]\n",
      " [inf inf inf inf inf inf  0.  1. inf]\n",
      " [inf inf inf inf inf  1. inf  0.  1.]\n",
      " [inf  1. inf inf inf inf inf inf  0.]]\n",
      "{'a': 12.0, 'b': 16.0, 'c': 16.0, 'd': 14.666666666666666, 'e': 14.666666666666666, 'f': 24.0, 'g': 14.666666666666666, 'h': 28.0, 'i': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n",
    "              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n",
    "              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n",
    "              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n",
    "              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n",
    "t = pp.TemporalGraph.from_edge_list(tedges)\n",
    "c = pp.algorithms.centrality.temporal_closeness_centrality(t, 5)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Graph with 5 nodes, 6 unique edges and 6 events in [0.0, 3.0]\n",
      "\n",
      "Graph attributes\n",
      "\tdst\t\t<class 'torch.Tensor'> -> torch.Size([6])\n",
      "\tt\t\t<class 'torch.Tensor'> -> torch.Size([6])\n",
      "\tsrc\t\t<class 'torch.Tensor'> -> torch.Size([6])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'dst', 't', 'src'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t = pp.TemporalGraph.from_edge_list([(0,1,0), (0,2,0), (1,2,1), (1,3,1), (3,4,2), (1,4,3)])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 262.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created temporal event DAG with 17 nodes and 15 edges\n",
      "{0.0: 0.0, 1.0: 4.0, 2.0: 8.0, 3.0: 6.0, 4.0: 9.333333333333332}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c = pp.algorithms.centrality.temporal_closeness_centrality(t, delta=1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code with explosive memory usage due to computation of all second-order edges irrespective of time stamps\n",
    "def lift_order_not_efficient(g: pp.TemporalGraph, delta=1):\n",
    "    # first-order edge index\n",
    "    edge_index, timestamps = sort_edge_index(g.data.edge_index, g.data.t)\n",
    "    node_sequence = torch.arange(g.data.num_nodes, device=edge_index.device).unsqueeze(1)\n",
    "    print(edge_index)\n",
    "    # second-order edge index with time-respective filtering\n",
    "    null_model_edge_index = pp.MultiOrderModel.lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))    \n",
    "    # Update node sequences\n",
    "    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n",
    "    # Remove non-time-respecting higher-order edges\n",
    "    time_diff = timestamps[null_model_edge_index[1]] - timestamps[null_model_edge_index[0]]\n",
    "    non_negative_mask = time_diff > 0\n",
    "    delta_mask = time_diff <= delta\n",
    "    time_respecting_mask = non_negative_mask & delta_mask\n",
    "    edge_index = null_model_edge_index[:, time_respecting_mask]\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new memory-efficient code\n",
    "def lift_order_efficient(g: pp.TemporalGraph, delta: int = 1):\n",
    "\n",
    "    # first-order edge index\n",
    "    edge_index, timestamps = g.data.edge_index, g.data.t\n",
    "    # print(edge_index)\n",
    "\n",
    "    indices = torch.arange(0, edge_index.size(1), device=g.data.edge_index.device)\n",
    "\n",
    "    unique_t = torch.unique(timestamps, sorted=True)\n",
    "    second_order = []\n",
    "\n",
    "    # lift order: find possible continuations for edges in each time stamp\n",
    "    for i in tqdm(range(unique_t.size(0))):\n",
    "        t = unique_t[i]\n",
    "        #print('timestamp index ', i)\n",
    "        #print('timestamp ', t)\n",
    "        \n",
    "        # find indices of all source edges that occur at unique timestamp t\n",
    "        src_time_mask = (timestamps == t)\n",
    "        src_edges = edge_index[:,src_time_mask]\n",
    "        src_edge_idx = indices[src_time_mask]\n",
    "        #print(src_edges)\n",
    "        #print(src_edge_idx)\n",
    "\n",
    "        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n",
    "        dst_time_mask = (timestamps > t) & (timestamps <= t+delta)\n",
    "        dst_edges = edge_index[:,dst_time_mask]        \n",
    "        dst_edge_idx = indices[dst_time_mask]\n",
    "        #print(dst_edges)\n",
    "        #print(dst_edge_idx)\n",
    "\n",
    "        if dst_edge_idx.size(0)>0 and src_edge_idx.size(0)>0:\n",
    "\n",
    "            # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges        \n",
    "            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n",
    "            src_edges = torch.index_select(edge_index, dim=1, index=x[0])\n",
    "            dst_edges = torch.index_select(edge_index, dim=1, index=x[1])\n",
    "            #print(src_edges)\n",
    "            #print(dst_edges)\n",
    "            ho_edge_index = x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]\n",
    "            second_order.append(ho_edge_index)\n",
    "            #print(ho_edge_index) \n",
    "            \n",
    "            # #print('dst', dst)\n",
    "            # src_mask = (edge_index[:,mask][0]==dst)\n",
    "            # ctd = edge_index[:,mask][:,src_mask]\n",
    "            # #print('continuations', ctd)\n",
    "            # ctd_indices = torch.where(edge_index[:,mask][0]==dst)[0]        \n",
    "            # #print('ctd indx', ctd_indices)\n",
    "            # count += ctd_indices.size(0)\n",
    "    ho_index = torch.cat(second_order, dim=1)    \n",
    "    return ho_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fo_nodes(ho_edge, g):\n",
    "    src_edge = ho_edge[0]\n",
    "    dst_edge = ho_edge[1]\n",
    "    return g.data.edge_index[:,src_edge][0], g.data.edge_index[:,dst_edge][0], g.data.edge_index[:,dst_edge][1]\n",
    "\n",
    "\n",
    "def temporal_shortest_paths_all(g: pp.TemporalGraph, delta: int):\n",
    "    # generate temporal event DAG\n",
    "    edge_index = lift_order_efficient(g, delta)\n",
    "\n",
    "    # Add indices of first-order nodes as src and dst of paths in TEG\n",
    "    src_edges_src = g.data.edge_index[0,:] + g.data.edge_index.size(1)\n",
    "    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))    \n",
    "    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n",
    "    dst_edges_dst = g.data.edge_index[1,:] + 2*g.data.edge_index.size(1)\n",
    "\n",
    "    src_edges = torch.stack([src_edges_src, src_edges_dst])\n",
    "    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n",
    "    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n",
    "\n",
    "    event_graph = pp.Graph.from_edge_index(edge_index)\n",
    "    \n",
    "    # initialize distance matrix \n",
    "    dist = torch.full((g.n, event_graph.n), float(\"inf\"), device=g.data.edge_index.device)\n",
    "\n",
    "    # predecessor lists\n",
    "    pred = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    # Fastest known single source SP in DAG (Cormen, Leiserson): single scan of edges in DAG\n",
    "    # trick: index of second-order nodes = topological sorting of event DAG assuming that edges are given in chronological order    \n",
    "    # scan second-order nodes in topological order and relax distances between first-order nodes\n",
    "\n",
    "    # TODO: correct algorithm\n",
    "    for src in tqdm(g.nodes):\n",
    "        dist[g.mapping.to_idx(src), g.mapping.to_idx(src) + g.data.edge_index.size(1)] = 0\n",
    "        for v in event_graph.nodes:\n",
    "            for w in event_graph.successors(v):\n",
    "                dist[g.mapping.to_idx(src), w] = min(dist[g.mapping.to_idx(src), w], dist[g.mapping.to_idx(src), v]+1)\n",
    "    \n",
    "    dist_fo = dist[:,2*g.m:] - 1\n",
    "    dist_fo.fill_diagonal_(0)\n",
    "    return dist_fo, pred\n",
    "\n",
    "\n",
    "def temporal_shortest_paths(g: pp.TemporalGraph, delta: int):\n",
    "    # generate temporal event DAG\n",
    "    edge_index = lift_order_efficient(g, delta)    \n",
    "\n",
    "    # Add indices of g.n first-order nodes as source nodes of paths in augmented TEG\n",
    "    src_edges_src = g.m + g.data.edge_index[0,:]\n",
    "    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n",
    "\n",
    "    # Add indices of g.n first-order nodes as target nodes of paths in augmented TEG\n",
    "    dst_edges_src = torch.arange(0, g.data.edge_index.size(1))\n",
    "    dst_edges_dst = g.m + g.n + g.data.edge_index[1,:]\n",
    "\n",
    "    src_edges = torch.stack([src_edges_src, src_edges_dst])\n",
    "    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n",
    "    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n",
    "\n",
    "    event_graph = pp.Graph.from_edge_index(edge_index, num_nodes=g.m + 2 * g.n)\n",
    "    m = event_graph.sparse_adj_matrix()\n",
    "    print(m.shape)\n",
    "    # compute shortest paths from all source nodes to all nodes \n",
    "    dist, pred = dijkstra(m, directed=True, indices = np.arange(g.m, g.m+g.n),  return_predecessors=True, unweighted=True)\n",
    "    print(dist.shape)\n",
    "    print(g.n + g.m)\n",
    "    # we are only interested in target nodes, whose indices start at G.m + G.n\n",
    "    dist_fo = dist[:,g.m+g.n:] - 1\n",
    "    np.fill_diagonal(dist_fo, 0)\n",
    "    pred_fo = pred[:,g.n+g.m:]\n",
    "    return dist_fo, pred_fo\n",
    "\n",
    "\n",
    "    \n",
    "def temporal_closeness_centrality(g: pp.TemporalGraph, delta: int) -> dict:\n",
    "\n",
    "    centralities = dict()\n",
    "    dist, _ = temporal_shortest_paths(g, delta)\n",
    "    for x in g.nodes:\n",
    "        centralities[x] = sum((g.n - 1) / dist[np.arange(g.n)!=x, g.mapping.to_idx(x)])\n",
    "\n",
    "    return centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:00<00:00, 6304.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1181, 1181)\n",
      "(68, 1181)\n",
      "1113\n",
      "(68, 68)\n",
      "68\n",
      "1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dist, pred = temporal_shortest_paths(t_ants, delta=30)\n",
    "print(dist.shape)\n",
    "print(t_ants.n)\n",
    "print(t_ants.m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43midx\u001b[49m[:,\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "idx[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = lift_order_efficient(t)\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 1, 3, 1],\n",
      "        [1, 2, 2, 3, 4, 4]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 2955.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n",
      "(5, 16)\n",
      "11\n",
      "[[ 0.  1.  1.  2.  3.]\n",
      " [inf  0.  1.  1.  1.]\n",
      " [inf inf  0. inf inf]\n",
      " [inf inf inf  0.  1.]\n",
      " [inf inf inf inf  0.]]\n",
      "[[-9999     0     1     3     4]\n",
      " [-9999 -9999     2     3     5]\n",
      " [-9999 -9999 -9999 -9999 -9999]\n",
      " [-9999 -9999 -9999 -9999     4]\n",
      " [-9999 -9999 -9999 -9999 -9999]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(t.data.edge_index)\n",
    "dist, pred = temporal_shortest_paths(t, delta=1)\n",
    "\n",
    "print(dist)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  1., inf,  1.,  0.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.mapping.node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temporal_closeness_centrality(t, delta=1))\n",
    "print(t.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_shortest_paths(t_sp, delta=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data.edge_index[:,edge_index[0,:]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data.edge_index[:,edge_index[1,:]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(t.data.edge_index)\n",
    "print(t_sp)\n",
    "g = temporal_shortest_paths(t_sp, delta=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeg = degree(g.data.edge_index[1])\n",
    "roots = torch.where(indeg==0)[0]\n",
    "print(roots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(g, path):\n",
    "    if g.get_successors(path[-1]).size(0) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        for w in g.successors(path[-1]):\n",
    "            traverse(g, path + (w,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x in roots:\n",
    "    print(x)\n",
    "    traverse(g, (x,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ho_index = lift_order_not_efficient(t, delta=1)\n",
    "print(ho_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ho_index = lift_order_efficient(t, delta=1)\n",
    "print(ho_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sequence = torch.arange(t.data.num_nodes, device=t.data.edge_index.device).unsqueeze(1)\n",
    "print(node_sequence)\n",
    "node_sequence = torch.cat([node_sequence[t.data.edge_index[0]], node_sequence[t.data.edge_index[1]][:, -1:]], dim=1)\n",
    "print(node_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_order_not_efficient(t_sp, delta=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_order_efficient(t_sp, delta=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_order_not_efficient(t_sp, delta=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cartesian_prod(torch.tensor([0,1]), torch.tensor([1,3])).t()\n",
    "# edge 0 = 0->1\n",
    "# edge 1 = 1->2\n",
    "# edge 2 = 0->1\n",
    "\n",
    "# combination 0,1:     0->1, 1->2\n",
    "# combination 0,2:     0->1, 0->1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_edges = torch.index_select(t.data.edge_index, dim=1, index=x[0])\n",
    "print(src_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_edges = torch.index_select(t.data.edge_index, dim=1, index=x[1])\n",
    "print(dst_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #select all indices where \n",
    "torch.where(src_edges[1,:] == dst_edges[0,:])[0]\n",
    "x[:,torch.where(src_edges[1,:] == dst_edges[0,:])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
