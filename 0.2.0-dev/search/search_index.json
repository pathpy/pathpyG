{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pathpyG","text":"<p>This is the index page of the pathpyG documentation.</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#what-is-pathpyg","title":"What is pathpyG?","text":"<p>pathpyG is an Open Source package facilitating GPU-accelerated next-generation network analytics and graph learning for time series data on graphs.</p> <p>pathpyG is tailored to analyse time-stamped network data as well as sequential data that capture multiple short walks or paths observed in a graph or network. Examples for data that can be analysed with pathpyG include high-resolution time-stamped network data, dynamic social networks, user click streams on the Web, biological pathway data, directed acyclic graphs like citation networks, passenger trajectories in transportation networks, or trajectories of information propagation in social networks.</p> <p>pathpyG is fully integrated with jupyter, providing rich interactive visualisations of networks, temporal networks, and higher-order models. Visualisations can be exported to HTML5 files that can be shared and published on the Web.</p>"},{"location":"about/#what-is-the-science-behind-pathpyg","title":"What is the science behind pathpyG?","text":"<p>The theoretical foundation of this package, higher- and multi-order network models, was developed in the following peer-reviewed research articles:</p> <ol> <li>L Qarkaxhija, V Perri, I Scholtes: De Bruijn goes Neural: Causality-Aware Graph Neural Networks for Time Series Data on Dynamic Graphs, In Proceedings of the First Learning on Graphs Conference, PMLR 198:51:1-51:21, December 2022</li> <li>L Petrovic, I Scholtes: Learning the Markov order of paths in graphs, In Proceedings of WWW '22: The Web Conference 2022, Lyon, France, April 2022</li> <li>V Perri, I Scholtes: HOTVis: Higher-Order Time-Aware Visualisation of Dynamic Graphs, In Proceedings of the 28<sup>th</sup> International Symposium on Graph Drawing and Network Visualization (GD 2020), Vancouver, BC, Canada, September 15-18, 2020</li> <li>I Scholtes: When is a network a network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks, In KDD'17 - Proceedings of the 23<sup>rd</sup> ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, Nova Scotia, Canada, August 13-17, 2017</li> <li>I Scholtes, N Wider, A Garas: Higher-Order Aggregate Networks in the Analysis of Temporal Networks: Path structures and centralities, The European Physical Journal B, 89:61, March 2016</li> <li>I Scholtes, N Wider, R Pfitzner, A Garas, CJ Tessone, F Schweitzer: Causality-driven slow-down and speed-up of diffusion in non-Markovian temporal networks, Nature Communications, 5, September 2014</li> <li>R Pfitzner, I Scholtes, A Garas, CJ Tessone, F Schweitzer: Betweenness preference: Quantifying correlations in the topological dynamics of temporal networks, Phys Rev Lett, 110(19), 198701, May 2013</li> </ol> <p>A broader view on the importance of higher-order graph models for complex systems can be found in this overview article. </p>"},{"location":"contributing/","title":"Contributing","text":"<p>This project is open source and welcomes contributions. In the following sections, you will find information about how to contribute to this project, set up your environment correctly, how to document your code and more.</p>"},{"location":"contributing/#overview","title":"Overview","text":"<ul> <li>Setting up your environment</li> <li>Documentation</li> <li>Code Style</li> <li>Formatting</li> <li>Testing</li> <li>Benchmarking</li> </ul>"},{"location":"contributing/#setting-up-your-environment","title":"Setting up your environment","text":""},{"location":"contributing/#clone-the-repository","title":"Clone the Repository","text":"<p>The first step is to clone the repository. You can do this by running the following command: <pre><code>git clone https://github.com/pathpy/pathpyG\n</code></pre> If you do not have the rights to push to the repository, you can also fork the repository and clone your fork instead. From there you can create a pull request to the original repository.</p>"},{"location":"contributing/#installation","title":"Installation","text":"<p>To ensure version consistency, we use a Development Container for this project.   VSCode provides an easy-to-use extension for this. Check out their official documentation for more information. Once you've installed the extension successfully,   VSCode will recommend reopening the project in the Dev Container. You can also do this manually by clicking on the button in the bottom left corner of   VSCode and then selecting <code>Reopen in Container</code>.</p> Setup without Dev Containers <p>If you do not want to use Dev Containers, you can also install the dependencies into your virtual Python environment manually. We recommend that you follow the instructions provided on our getting started page. As last step, install the package in editable mode and include the dependencies necessary for testing, documentation and general development: <pre><code>pip install -e '.[dev,test,doc]'\n</code></pre></p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>This project uses <code>MkDocs</code> for documentation. It is a static site generator that creates the necessary <code>html</code>-files automatically from the <code>markdown</code>-files and  Group.svg Created using Figma 0.90  Jupyter notebooks in the <code>docs/</code>-directory and the <code>Python</code>-files in <code>src/</code>. The documentation is hosted on GitHub Pages.</p>"},{"location":"contributing/#hosting-the-documentation-locally","title":"Hosting the documentation locally","text":"<p>You can host the documentation locally with the following command: <pre><code>mkdocs serve\n</code></pre> The documentation is then available at <code>http://localhost:8000/</code>.</p> Actual Deployment <p>The development version of the documentation is deployed automatically to GitHub Pages when something is pushed to the <code>main</code>-branch. The workflow for deploying a new stable version needs to be triggered manually. You can find it in the <code>Actions</code>-tab of the repository. Both workflows use <code>mike</code> instead of <code>MkDocs</code> to enable versioning.</p>"},{"location":"contributing/#code-reference","title":"Code Reference","text":"<p>The <code>Code Reference</code> is generated automatically from the   Python source files using <code>docs/gen_ref_pages.py</code>. The docstrings should be formatted according to the Google Python Style Guide. Be sure to also use the advanced stuff like notes, tips and more. They can e.g. look as follows:</p> DocstringResult <pre><code>\"\"\"\nNote:\n    This is a note.\n\nTip: This is a heading\n    This is a tip.\n\"\"\"\n</code></pre> <p>Note</p> <p>This is a note.</p> <p>This is a heading</p> <p>This is a tip.</p> <p>See the documentation of the underlying griffe package for more details.</p> <p>To get an overview for each package, <code>mkdocstrings</code> automatically uses the docstrings from the <code>__init__.py</code> files in each package as description. Thus, do not forget to add a docstring to each <code>__init__.py</code> file. If a package starts with an underscore (<code>_</code>), the underscore will be removed from the name in the documentation. </p>"},{"location":"contributing/#replace-automatic-code-reference","title":"Replace Automatic Code Reference","text":"<p>While the docstrings include rich functionality, it is easier to write long and detailed descriptions using <code>.md</code>-files. Therefore, you can replace the automatically generated documentation for a module by adding a <code>.md</code>-file with the same name as the module in the <code>docs/reference/</code>-directory. The file will be rendered instead of the automatically generated documentation. You can find an example in <code>docs/reference/pathpyG/index.md</code>.</p> <p>Replacing package documentation in the <code>__init__.py</code>-file</p> <p>The Overview for each package can be provided in the <code>__init__.py</code>-file. If you want to replace the <code>__init__.py</code>-file to provide a better documentation using <code>markdown</code>, make sure to name the file <code>index.md</code> instead.</p>"},{"location":"contributing/#ignore-specific-py-files","title":"Ignore specific <code>.py</code>-files","text":"<p>If you want to ignore specific <code>.py</code>-files in the code reference, you can add them to <code>docs/reference/ignored_modules.yaml</code>. All files listed there will be ignored when generating the code reference. If you include all files in a package-directory, the whole package will not be shown in the documentation.</p>"},{"location":"contributing/#tutorials","title":"Tutorials","text":"<p>The tutorials are written in  Group.svg Created using Figma 0.90  Jupyter notebooks. They are located in the <code>docs/</code>-directory. You can add new tutorials by adding the notebook to the <code>docs/tutorial/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The tutorials are automatically converted to <code>html</code>-files when the documentation is built.</p>"},{"location":"contributing/#adding-new-pages","title":"Adding new pages","text":"<p>You can add more pages to the documentation by adding a <code>markdown</code>-file to the <code>docs/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The pages are automatically converted to <code>html</code>-files when the documentation is built. We are using Material for MkDocs as a theme. It includes many great features like annotations, code blocks, diagrams, admonitions and more. Check out their documentation for more information.</p>"},{"location":"contributing/#code-style","title":"Code Style","text":"<p>We (soon) enforce code style guidelines with <code>ruff</code> and <code>mypy</code>. These packages are configured as defaults in the Dev Container setup via <code>VSCode</code> and the settings are saved in <code>pyproject.toml</code>. You can run them locally with the following commands:</p> <ul> <li><code>ruff</code>: A linter that checks for errors and code style violations.     <pre><code>ruff check . # (1)!\n</code></pre><ol> <li>This runs <code>ruff</code> as a linter on all files in the current directory. You can also run <code>ruff</code> on a single file by specifying the path to the file instead. If you want to automatically fix all issues that can be fixed automatically, you can use <code>ruff check . --fix</code>.</li> </ol> </li> <li><code>mypy</code>: A static type checker for Python.     <pre><code>mypy src/ # (1)!\n</code></pre><ol> <li>This runs <code>mypy</code> on all files in <code>src/</code>. You can also run <code>mypy</code> on a single file by specifying the path to the file instead.</li> </ol> </li> </ul>"},{"location":"contributing/#formatting","title":"Formatting","text":"<p>We use <code>ruff</code> for formatting. You can run it locally with the following command:</p> <pre><code>ruff format . # (1)!\n</code></pre> <ol> <li>This command will format all files in the current directory. You can also run <code>ruff</code> on a single file or a subdirectory by specifying the path accordingly.</li> </ol> <p>The default keyboard shortcut for formatting in <code>VSCode</code> is <code>Alt + Shift + F</code>.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>We are using <code>pytest</code> for testing. You can run the tests locally with the following command: <pre><code>pytest\n</code></pre> The tests are located in the <code>tests/</code>-directory. We use <code>pytest-cov</code> to measure the test coverage and are aiming for 100% coverage with a hard limit of 80%. Tests will fail if the coverage drops below 80%.</p> <p>Add tests</p> <p>We are currently only at 60% coverage. So the lines above are currently pure fiction.</p> <p>Test that use a GPU are located in the <code>tests/gpu</code>-directory. They are currently disabled for CI but can be manually executed with <pre><code>pytest -m gpu\n</code></pre></p>"},{"location":"contributing/#benchmarking","title":"Benchmarking","text":"<p>For optimal runtime, we continually measure the execution time of our core functions using pytest benchmarks. These benchmarks are located in <code>tests/benchmarks/</code> and are unit-tests that utilize the <code>benchmark</code> fixture from <code>pytest-benchmark</code>. All of them are marked with the benchmark decorator (<code>@pytest.mark.benchmark</code>) to exclude them from the normal unit-tests. You can run all benchmarks in the command line using <pre><code>pytest -m benchmark\n</code></pre> If you are working on runtime improvements, you can compare the runtime of your changes to the runtime of the main branch by saving the results of each run with <pre><code>pytest -m benchmark --benchmark-autosave\n</code></pre> or with a custom name <code>&lt;custom-name&gt;</code> <pre><code>pytest -m benchmark --benchmark-save=&lt;custom-name&gt;\n</code></pre> After running the benchmarks both in your current branch and in the main branch, you can compare them as follows: <pre><code>pytest-benchmark compare # (1)!\n</code></pre></p> <ol> <li>This will compare all runs that are currently saved in <code>.benchmarks/</code>. If you want to compare specific runs, you can add the number of the runs at the end of the command. The numbering usually starts with <code>0001</code>.</li> </ol> <p>Note</p> <p>Since the runtime is strongly dependent on the underlying machine, we do not keep any up-to-date results on <code>git</code> and recommend to do any comparisons locally.</p>"},{"location":"docker_installation/","title":"Docker Installation","text":"<p>  PyTorch provides a  Docker image with PyTorch preinstalled. Using this image, the Dockerfile below creates a Docker image with PathpyG installed.</p> GPUCPU <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre> <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu # CPU only\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html # CPU only\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate the code reference pages and navigation.\"\"\"\n# See for more detail: https://mkdocstrings.github.io/recipes/\n</pre> \"\"\"Generate the code reference pages and navigation.\"\"\" # See for more detail: https://mkdocstrings.github.io/recipes/ In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import yaml\nimport mkdocs_gen_files\n</pre> import yaml import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n# Load the ignored modules from the YAML file\nignored_modules_path = Path(\"docs\", \"reference\", \"ignored_modules.yaml\")\nignored_modules = yaml.safe_load(ignored_modules_path.read_text(\"utf-8\"))\n</pre> nav = mkdocs_gen_files.Nav() # Load the ignored modules from the YAML file ignored_modules_path = Path(\"docs\", \"reference\", \"ignored_modules.yaml\") ignored_modules = yaml.safe_load(ignored_modules_path.read_text(\"utf-8\")) In\u00a0[\u00a0]: Copied! <pre>for path in sorted(Path(\"src\").rglob(\"*.py\")):\n    if str(path.relative_to(\".\")) in ignored_modules:\n        print(f\"Skipping {path} as it is in the ignored modules list.\")\n        continue\n    module_path = path.relative_to(\"src\").with_suffix(\"\")\n    doc_path = path.relative_to(\"src\").with_suffix(\".md\")\n    full_doc_path = Path(\"reference\", doc_path)\n\n    parts = tuple(module_path.parts)\n\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1] == \"__main__\":\n        continue\n\n    nav[(part.split(\"_\")[-1] for part in parts)] = doc_path.as_posix()\n\n    print(f\"Checking {full_doc_path}\")\n    if not (Path(\"docs\") / full_doc_path).exists():\n        with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n            ident = \".\".join(parts)\n            fd.write(f\"::: {ident}\")\n    else:\n        print(f\"File {full_doc_path} already exists, skipping.\")\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path)\n</pre> for path in sorted(Path(\"src\").rglob(\"*.py\")):     if str(path.relative_to(\".\")) in ignored_modules:         print(f\"Skipping {path} as it is in the ignored modules list.\")         continue     module_path = path.relative_to(\"src\").with_suffix(\"\")     doc_path = path.relative_to(\"src\").with_suffix(\".md\")     full_doc_path = Path(\"reference\", doc_path)      parts = tuple(module_path.parts)      if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1] == \"__main__\":         continue      nav[(part.split(\"_\")[-1] for part in parts)] = doc_path.as_posix()      print(f\"Checking {full_doc_path}\")     if not (Path(\"docs\") / full_doc_path).exists():         with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:             ident = \".\".join(parts)             fd.write(f\"::: {ident}\")     else:         print(f\"File {full_doc_path} already exists, skipping.\")      mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path) In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"getting_started/","title":"Getting Started","text":"<p>The following will guide you through the installation of the package and the first steps to use it.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>PathpyG is available for   Python versions 3.10 and above. It is not recommended to install it on your system Python. Instead, we recommend using a virtual environment such as   conda or virtualenv. You can also set up a   Docker image as described in the next section.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<p>Once you have an environment up and running, you can install the package simply via pip. But first make sure that you installed the necessary dependencies.</p>"},{"location":"getting_started/#dependencies","title":"Dependencies","text":"<p>This package is based on   PyTorch and   PyTorch Geometric. Please install both libraries before installing PathpyG. You can follow the installation instructions in their respective documentation (  PyTorch and   PyG). Alternatively, you can install the correct versions of both libraries using <code>uv</code> to install the optional dependencies of PathpyG. You can choose between a CPU-only installation or a CUDA installation for a specific CUDA version. For example, to install the CPU-only version, run:</p> <p><pre><code>uv pip install pathpyg[cpu]\n</code></pre> Or, to install the CUDA 12.9 version, run:</p> <pre><code>uv pip install pathpyg[cu129]\n</code></pre> <p>Warning</p> <p>We currently only support PyG version 2.5.0 and above.</p>"},{"location":"getting_started/#install-stable-release","title":"Install Stable Release","text":"<p>You can install the latest stable release of PathpyG via pip:</p> <p>TODO</p> <p>This is not yet available. We will release the first stable version soon.</p> <pre><code>pip install pathpyg\n</code></pre>"},{"location":"getting_started/#install-latest-development-version","title":"Install Latest Development Version","text":"<p>If you want to install the latest development version, you can do so via pip directly from the GitHub repository:</p> <pre><code>pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"getting_started/#optional-visualisation-backends","title":"Optional Visualisation Backends","text":"<p>We provide multiple visualisation backends for PathpyG. The default backend D3.js does not require any additional dependencies. We further provide a Matplotlib backend that is installed by default. Additionally, we implemented a Manim backend that is not installed by default due to its dependencies that are required for installation. Please refer to the Manim installation instructions for more information. Once installed, you can use the Manim backend for visualisation by setting the <code>backend</code> in the <code>PathpyG.plot</code> function to <code>manim</code>:  <pre><code>import pathpyg as pp\n\nt_graph = TemporalGraph.from_edge_list([('a', 'b', 1),('b', 'a', 3), ('b', 'c', 3)])\npp.plot(t_graph, backend='manim')\n</code></pre></p>"},{"location":"plot_tutorial/","title":"Develop Custom Plot Functions","text":"<p>This tutorial guides you through the process of creating your own plotting functions in pathpyG.</p> <p>The visualization framework of pathpyg is designed in such a way that is easy to extend it according your own needs.</p> <p>For this tutorial we want to implement capabilities to plot histograms.</p> <p>You will learn:</p> <ul> <li>How to set up a generic plot function</li> <li>How to convert <code>pathpyG</code> data to plot data</li> <li>How to plot with <code>d3js</code> </li> <li>How to plot with <code>tikz</code></li> <li>How to plot with <code>matplotlib</code></li> </ul>"},{"location":"plot_tutorial/#structure","title":"Structure","text":"<p>Plotting commands and functions are located under <code>/src/pathpyG/visualisation/</code></p> <pre><code>\ud83d\udcc1 visualisation\n\u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u251c\u2500\u2500 \ud83d\udcc1 _d3js\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc1 _matplotlib\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc1 _tikz\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 ...\n\u251c\u2500\u2500 \ud83d\udcc4 layout.py\n\u251c\u2500\u2500 \ud83d\udcc4 network_plots.py\n\u251c\u2500\u2500 \ud83d\udcc4 plot.py\n\u2514\u2500\u2500 \ud83d\udcc4 utils.py\n</code></pre> <p>Folders with <code>_...</code> indicate the supported backends. We will have a look at them later.</p> <p>The <code>layout.py</code> file includes algorithms to calculate the positions of the nodes.</p> <p>In the <code>utils.py</code> file are useful helper functions collected. E.g. among others a function that converts <code>hex_to_rgb</code>, <code>rgb_to_hex</code>, or a simple [<code>Colormap</code>][pathpyG.visualisations.utils.Colormap] class. If your plot needs generic functions which might be helpful for other plots as well, this would be a good place to store them.</p> <p>The <code>network_plots.py</code> file includes all plots related to network visualization. We will create in this tutorial a similar collection for histograms.</p> <p>Finally, the <code>plot.py</code> file contains our generic [<code>PathPyPlot</code>][pathpyG.visualisations.plot.PathPyPlot] class which we will use to build our own class. </p> <p>This abstract class has a property <code>_kind</code> which will specify the type of plot for the generic plot function. Similar to <code>pandas</code> we should be able to call:</p> <pre><code>pp.plot(graph, kind=\"hist\")\n</code></pre> <p>This abstract class has two dict variables <code>self.data</code> and <code>self.config</code>. The <code>self.data</code> variable is used to store the data needed for the plot, while the <code>self.config</code> stores all the configurations passed to the plot.</p> <p>Furthermore this class has three abstract methods we have to define later for our supported backends: <code>generate</code> to generate the plot, <code>save</code> to save the plot to a file, <code>show</code> to show the current plot.</p>"},{"location":"plot_tutorial/#lets-get-started","title":"Let's get started","text":"<p>In order to get started, we have to create a new python file where we will store our histogram plots. So let's generate a new file <code>hist_plots.py</code></p> <pre><code>touch hist_plots.py\n</code></pre> <p>We start with creating a function which allows us later to plot a histogram.</p> <p>This function will take a <code>Graph</code> object as input and has the parameters <code>key</code> and <code>bins</code> as well as a dict of <code>kwargs</code> for furthermore specifications.</p> <p>We will use the <code>key</code> variable to define the data type of the histogram e.g. <code>by='betweenes'</code> to get the betweenes centrality plotted. With the <code>bins</code> parameters we will change the amount of bins in the histogram. all other options will by passed to the function as keyword arguments and can be backend specific.</p> <pre><code>\"\"\"Histogram plot classes.\"\"\"\nfrom __future__ import annotations\n\nimport logging\n\nfrom typing import TYPE_CHECKING, Any\n\n# pseudo load class for type checking\nif TYPE_CHECKING:\n    from pathpyG.core.graph import Graph\n\n# create logger\nlogger = logging.getLogger(\"pathpyG\")\n\n\ndef hist(network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre> <p>pathpyG is using logging to print out messages and errors. It's a good habit to use it also for your plotting function.</p> <p>Our <code>hist</code> function will be callable via the package. e.g. <code>pp.hist(...)</code>. Itself it will return a plotting class which we have to create.</p> <pre><code>from pathpyG.visualisations.plot import PathPyPlot\n\nclass HistogramPlot(PathPyPlot):\n    \"\"\"Histogram plot class for a network properties.\"\"\"\n\n    _kind = \"hist\"\n\n    def __init__(self, network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot class.\"\"\"\n        super().__init__()\n        self.network = network\n        self.config = kwargs\n        self.config['bins'] = bins\n        self.config['key'] = key\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n</code></pre> <p>The <code>HistogramPlot</code> plotting class is a child from our abstract <code>PathPyPlot</code> function. We will overwrite the abstract <code>generate()</code> function in order to get the data needed for our plot.</p> <p>By convention we assume <code>d3js</code> will be the default plot backend, hence the final data generated by this function should provide the necessary data structure for this backend. </p> <p>For other backends, this data might be needed to be converted e.g. keywords might be different. We will address this later in our tutorial.</p>"},{"location":"plot_tutorial/#testing-testing-testing","title":"Testing, Testing, Testing","text":"<p>Before we start developing our histogram plot, we should set up a test environment so that we can directly develop the unit test next to our plot function.</p> <p>Therefore we are going to our testing folder an create a new test file.</p> <pre><code>cd ../../../tests/\ntouch test_hist.py\n</code></pre> <p>Now we can create a simple test environment with a simple graph and call our <code>hist(...)</code> function.</p> <pre><code>from pathpyG.core.graph import Graph\nfrom pathpyG.visualisations.hist_plots import hist\n\n\ndef test_hist_plot() -&gt; None:\n    \"\"\"Test to plot a histogram.\"\"\"\n    net = Graph.from_edge_list([[\"a\", \"b\"], [\"b\", \"c\"], [\"a\", \"c\"]])\n    hist(net)\n</code></pre> <p>Note: If you only want to run this function and not all other test you can use:</p> <pre><code>pytest -s -k 'test_hist_plot'\n</code></pre>"},{"location":"plot_tutorial/#generating-the-plot-data","title":"Generating the plot data","text":"<p>To plot our histogram we first have to generate the required data from our graph.</p> <p>In the future we might want to add more options for histograms, hence we use the <code>match</code>-<code>case</code> function form python.</p> <pre><code>    def generate(self) -&gt; None:\n        \"\"\"Generate the plot.\"\"\"\n        logger.debug(\"Generate histogram.\")\n\n        data: dict = {}\n\n        match self.config[\"key\"]:\n            case \"indegrees\":\n                logger.debug(\"Generate data for in-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"in\").values())\n            case \"outdegrees\":\n                logger.debug(\"Generate data for out-degrees\")\n                data[\"values\"] = list(self.network.degrees(mode=\"out\").values())\n            case _:\n                logger.error(\n                    f\"The &lt;{self.config['key']}&gt; property\",\n                    \"is currently not supported for hist plots.\",\n                )\n                raise KeyError\n\n        data[\"title\"] = self.config[\"key\"]\n        self.data[\"data\"] = data\n</code></pre> <p>First we initialize a dictionary <code>data</code> to store our values. In this case we are interested in the in and out-degrees of our graph, which are already implemented in <code>pathpyG</code> (state 2023-11-26). </p> <p>If the keyword is not supported the function will raise a <code>KeyError</code>.</p> <p>To provide a default title for our plot we also store the keyword in the data dict. If further data is required for the plot it can be stored here.</p> <p>Finally, we add the data dict to our <code>self.data</code> variable of the plotting class. This variable will be used later in the backend classes.</p> <p>With this our basic histogram plot function is finished. We are now able to call the plot function, get the data from our graph and create a data-set which can be passed down to the backend for visualization.</p>"},{"location":"plot_tutorial/#the-matplotlib-backend","title":"The matplotlib backend","text":"<p>Let's open the <code>_matplotlib</code> folder located under <code>/src/pathpyG/visualisation/_matplotlib</code>, where all matplotlib functions are stored.</p> <pre><code>\ud83d\udcc1 _matplotlib\n\u251c\u2500\u2500 \ud83d\udcc4 __init__.py\n\u251c\u2500\u2500 \ud83d\udcc4 core.py\n\u2514\u2500\u2500 \ud83d\udcc4 network_plots.py\n</code></pre> <p>The <code>_init_.py</code> holds the configuration for the plot function, which we will modify later. The <code>core.py</code> file contains the generic <code>MatplotlibPlot</code> class, which provides <code>save</code> and <code>show</code> functionalities for our plots. We do not need to modify these functions. Instead, we have to generate a translation function from our generic data dict (see above) to a histogram in matplotlib. To do so, lets create first a new python file named <code>hist_plots.py</code></p> <pre><code>cd _matplotlib\ntouch hist_plots.py\n</code></pre> <p>Here we will add our missing piece for a functional matplotlib plot.</p> <pre><code>\"\"\"Histogram plot classes.\"\"\"\nfrom __future__ import annotations\n\nimport logging\n\nfrom typing import TYPE_CHECKING, Any\n\n# pseudo load class for type checking\nif TYPE_CHECKING:\n    from pathpyG.core.graph import Graph\n\n# create logger\nlogger = logging.getLogger(\"pathpyG\")\n\n\ndef hist(network: Graph, key: str = 'degree', bins: int = 10, **kwargs: Any) -&gt; HistogramPlot:\n    \"\"\"Plot a histogram.\"\"\"\n    return HistogramPlot(network, key, bins, **kwargs)\n</code></pre>"},{"location":"tutorial/","title":"Overview","text":"<p>In this tutorial, we will introduce basic concepts of pathpyG. pathpyG can be used as a wrapper around pytorch-geometric that facilitates network analysis, graph learning, and interactive data visualization. However, its real power comes into play when modelling causal path structures in time series data on networks, such as trajectories on graphs or temporal graphs with time-stamped interactions. pathpyG allows to compute causal paths in temporal graphs and model them based on higher-order De Bruijn graphs, a higher-dimensional generalization of standard graph models for relational data.</p> <p>The following introductory video explains the basic idea of higher-order De Bruijn graph models for causal path structures in time series data:</p> <p>The science behind pathpyG has been published in outlets like SIGKDD, WWW, Learning on Graphs, Nature Communications, Nature Physics, and Physical Review Letters. Please check here for more details on key scientific works that have laid the foundations for this package.</p> <p>Different from previous versions of pathpy, the latest version pathpyG fully utilizes the power of torch and tensor-based representations of sparse graph models to failitate the use of higher-order De Bruijn graph models. pathpyG's data structures naturally generalize the concepts of pytorch-geometric, which makes it easy to apply it in (temnporal) graph learning tasks.</p> <p>Finally, pathpyG comes with an implementation of De Bruijn Graph Neural Networks (DBGNN), a causality-aware deep learning architecture for temporal graph data. In the tutorial, we illustrate this temporal graph learning approach in a simple toy example.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>pathpyG<ul> <li>algorithms<ul> <li>centrality</li> <li>components</li> <li>models</li> <li>order</li> <li>window</li> <li>paths</li> <li>temporal</li> <li>leman</li> </ul> </li> <li>core<ul> <li>graph</li> <li>map</li> <li>model</li> <li>data</li> </ul> </li> <li>io<ul> <li>netzschleuder</li> <li>pandas</li> </ul> </li> <li>nn<ul> <li>dbgnn</li> </ul> </li> <li>processes<ul> <li>process</li> <li>walk</li> <li>sampling</li> </ul> </li> <li>statistics<ul> <li>clustering</li> <li>degrees</li> <li>similarities</li> </ul> </li> <li>utils<ul> <li>config</li> <li>convert</li> <li>dbgnn</li> <li>logger</li> <li>progress</li> </ul> </li> <li>visualisations<ul> <li>manim</li> <li>plot</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/pathpyG/","title":"pathpyG","text":"<p>pathpyG is an Open Source package facilitating next-generation network analytics and graph learning for time series data on graphs.</p> <p>Building on the industry-proven data structures and concepts of <code>pytorch</code> and <code>torch_geometric</code>, pathpyG makes it easier than ever to apply machine learning to temporal graph data.</p> <p>pathpyG is jointly developed at University of Wuerzburg, Princeton University, and University of Zurich. The research behind pathpyG has been funded by the Swiss National Science Foundation via  grant 176938.</p>"},{"location":"reference/pathpyG/algorithms/","title":"algorithms","text":"<p>Algorithms for temporal path calculation and graph metrics.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG\nimport pathpyG as pp\n\n# Generate a toy example for a temporal graph.\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)\n])\n\n# Extract DAG capturing causal interaction sequences in temporal graph.\ne_i = pp.algorithms.lift_order_temporal(g, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\nprint(dag)\n\n# Calculate shortest time-respecting pathas\ndist, pred = pp.algorithms.temporal.temporal_shortest_paths(g, delta=1)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if \"num_nodes\" not in data and \"edge_index\" in data:            \n            data.num_nodes = data.edge_index.max().item() + 1\n            logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if (\n            data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n            or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n        ):\n            logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n            raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n        self.data = data\n\n        # sort EdgeIndex and validate\n        data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        data.edge_index.validate()\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n        # create node_sequence mapping for higher-order graphs\n        if \"node_sequence\" not in self.data:\n            self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n        Examples:\n            You can create a graph from an edge index tensor as follows:\n\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            &gt;&gt;&gt; print(g)\n            Directed graph with 3 nodes and 3 edges ...\n\n            You can also include a mapping of node IDs:\n\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n            &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n            &gt;&gt;&gt; print(g.mapping)\n            a -&gt; 0\n            b -&gt; 1\n            c -&gt; 2\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else:\n            if mapping is not None and mapping.num_ids() != num_nodes:\n                logger.error(\"Number of node IDs in mapping must match num_nodes\")\n                raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(d, mapping=mapping)\n\n    @staticmethod\n    def from_edge_list(\n        edge_list: Iterable[Tuple[str, str]],\n        is_undirected: bool = False,\n        mapping: Optional[IndexMap] = None,\n        device: Optional[torch.device] = None,\n    ) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            device: optional torch device where tensors shall be stored\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n            &gt;&gt;&gt; print(list(g.edges))\n            [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        \"\"\"\n\n        # handle empty graph\n        if len(edge_list) == 0:\n            return Graph(\n                Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n                mapping=IndexMap(),\n            )\n\n        if mapping is None:\n            edge_array = np.array(edge_list)\n            node_ids = np.unique(edge_array)\n            if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n                node_ids = np.sort(node_ids.astype(int)).astype(str)\n            mapping = IndexMap(node_ids)\n\n        num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex(\n            mapping.to_idxs(edge_list, device=device).T.contiguous(),\n            sparse_size=(num_nodes, num_nodes),\n            is_undirected=is_undirected,\n        )\n        return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"Return an undirected version of this directed graph.\n\n        This method creates a new undirected Graph from the current graph instance by\n        adding all directed edges in opposite direction.\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            &gt;&gt;&gt; g_u = g.to_undirected()\n            &gt;&gt;&gt; print(g_u)\n            Undirected graph with 3 nodes and 6 (directed) edges\n        \"\"\"\n        # create undirected edge index by coalescing the directed edges and keep\n        # track of the original edge index for the edge attributes\n        attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n        edge_index, attr_idx = to_undirected(\n            self.data.edge_index,\n            edge_attr=attr_idx,\n            num_nodes=self.data.num_nodes,\n            reduce=\"min\",\n        )\n\n        data = Data(\n            edge_index=EdgeIndex(\n                data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n            ),\n            num_nodes=self.data.num_nodes,\n        )\n        # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n        # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n        # make sure to copy all node and (undirected) edge attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        for edge_attr in self.edge_attrs():\n            if edge_attr != \"edge_index\":\n                data[edge_attr] = self.data[edge_attr][attr_idx]\n\n        return Graph(data, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n        If the graph contains multiple edges between the same nodes, this method will coalesce\n        them into a single edge with an additional weight attribute called `edge_weight` that\n        contains the number of coalesced edges. The method returns a new graph instance with\n        the coalesced edges.\n\n        Returns:\n            Graph: Graph with coalesced edges\n        \"\"\"\n        i, w = torch_geometric.utils.coalesce(\n            self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n\n    def to(self, device: torch.device) -&gt; Graph:\n        \"\"\"Move all tensors to the given device.\n\n        Args:\n            device: torch device to which all tensors shall be moved\n\n        Returns:\n            Graph: self\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.node_sequence = self.data.node_sequence.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n\n        self.row = self.row.to(device)\n        self.row_ptr = self.row_ptr.to(device)\n        self.col = self.col.to(device)\n        self.col_ptr = self.col_ptr.to(device)\n\n        return self\n\n    def node_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_sequence` attribute.\n\n        Returns:\n            list: list of node attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n\n        Returns:\n            list: list of edge attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; list:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a list object that contains all nodes.\n        If an IndexMap is used, nodes are returned as string IDs.\n        If no IndexMap is used, nodes are returned as integer indices.\n\n        Returns:\n            list: list of all nodes using IDs or indices (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(np.arange(self.n)).tolist()\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    @property\n    def edges(self) -&gt; list:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a list object that contains all edges, where each\n        edge is a tuple of two elements. If an IndexMap is used to map node\n        indices to string IDs, edges are returned as tuples of string IDs.\n        If no mapping is used, edges are returned as tuples of integer indices.\n\n        Returns:\n            list: list object yielding all edges using IDs or indices (if no mapping is used)\n        \"\"\"\n        edge_list = self.mapping.to_ids(self.data.edge_index.t()).tolist()\n        if self.order &gt; 1:\n            return [tuple(map(tuple, x)) for x in edge_list]\n        return list(map(tuple, edge_list))\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n        \"\"\"\n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def successors(self, node: Union[int, str] | tuple) -&gt; list:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n\n        Returns:\n            list: list with all successors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n\n        node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n\n        Returns:\n            list: list with all predecessors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID\n\n        Returns:\n            bool: True if edge exists, False otherwise\n        \"\"\"\n        row = self.mapping.to_idx(v)\n        row_start = self.row_ptr[row]\n        row_end = self.row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in self.col[row_start:row_end]\n\n    def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted in-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing in-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted out-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing out-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                     torch.tensor]:\n        \"\"\"\n        Return (weighted) degrees of nodes.\n\n        Args:\n            mode: `in` or `out` to calculate in- or out-degree for\n                directed networks.\n            edge_attr: Optional numerical edge attribute that will \n                be used to compute weighted degrees\n            return_tensor: if True the function returns a degree tensor, if False (default)\n                a dictionary will be returned that can be indexed by nodes\n        Returns:\n            dict: dictionary containing node degrees\n        \"\"\"\n        if mode == \"in\":\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        else:\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        if return_tensor:\n            return d\n        else:\n            return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n\n    def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n        \"\"\"\n        Compute transition probabilities based on (weighted) outdegrees.\n\n        Args:\n            edge_attr: Optional name of numerical edge attribute that will\n                        will be used to calculate weighted out-degrees for the\n                        visitation probabilities.\n\n        Returns:\n            tensor: Transition probabilities.\n        \"\"\"\n        weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n        source_ids = self.data.edge_index[0]        \n        edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n        if edge_attr:\n            edge_weight = getattr(self.data, edge_attr, None)\n        return edge_weight / weighted_outdegree[source_ids]\n\n    def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization: normalization parameter passed to pyG `get_laplacian`\n                function\n            edge_attr: optinal name of numerical edge attribute that shall\n                be passed to pyG `get_laplacian` function as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(), normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(),\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key.startswith(\"node_\"):\n                if val.size(0) != self.n:\n                    raise ValueError(\"Attribute must have same length as number of nodes\")\n                self.data[key] = val\n            elif key.startswith(\"edge_\"):\n                if val.size(0) != self.m:\n                    raise ValueError(\"Attribute must have same length as number of edges\")\n                self.data[key] = val\n            else:\n                self.data[key] = val\n        elif key[0].startswith(\"node_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif key[0].startswith(\"edge_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n\n    @property\n    def n(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns:\n            int: number of nodes in the graph\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def m(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the number of \n        undirected edges (accounting for self-loops) is returned, i.e. in an undirected\n        graph the directed edges (a,b) and (b,a) will be counted only once.\n\n        Returns:\n            int: number of edges in the graph\n        \"\"\"\n        if self.is_directed():\n            return self.data.num_edges  # type: ignore\n        else:\n            num_self_loops = (self.data.edge_index[0] == self.data.edge_index[1]).sum().item()\n            num_edges_wo_self_loops = self.data.edge_index.size(1) - int(num_self_loops)\n            return int(num_edges_wo_self_loops/2 + num_self_loops) # type: ignore\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"\n        Return order of graph.\n\n        Returns:\n            int: order of the (De Bruijn) graph\n        \"\"\"\n        return self.data.node_sequence.size(1)  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\n\n        Returns:\n            bool: True if graph is directed, False otherwise\n        \"\"\"\n        return not self.data.edge_index.is_undirected\n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\n\n        Returns:\n            bool: True if graph is undirected, False otherwise\n        \"\"\"\n        return self.data.edge_index.is_undirected\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\n\n        Returns:\n            bool: True if graph contains self-loops, False otherwise\n        \"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Args:\n            other: Other graph to be combined with this graph\n            reduce: Reduction method for node attributes of nodes that are present in both graphs.\n                Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n        Examples:\n            Adding two graphs without node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 6 edges\n\n            Adding two graphs with identical node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 4 edges\n\n            Adding two graphs with non-overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 6 nodes and 4 edges\n\n            Adding two graphs with partly overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 5 nodes and 4 edges\n        \"\"\"\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n        mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n        d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n        d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n        d = d1.concat(d2)\n        d.num_nodes = mapping.num_ids()\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n        # For higher-order graphs, we need to update the inverse_idx attribute\n        if \"inverse_idx\" in d:\n            d.inverse_idx = mapping.to_idxs(\n                np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n                device=d.inverse_idx.device,\n            )\n\n        # If both graphs contain node attributes, reduce them using the specified method\n        for k in d1.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                if isinstance(d[k], torch.Tensor):\n                    d[k] = torch_geometric.utils.scatter(\n                        d[k],\n                        mapping.to_idxs(\n                            np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                            device=d[k].device,\n                        ),\n                        dim_size=d.num_nodes,\n                        reduce=reduce,\n                    )\n                else:\n                    raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a list object that contains all edges, where each edge is a tuple of two elements. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of string IDs. If no mapping is used, edges are returned as tuples of integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list object yielding all edges using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.in_degrees","title":"<code>in_degrees</code>  <code>property</code>","text":"<p>Return unweighted in-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing in-degrees of nodes</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.m","title":"<code>m</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the number of  undirected edges (accounting for self-loops) is returned, i.e. in an undirected graph the directed edges (a,b) and (b,a) will be counted only once.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of edges in the graph</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.n","title":"<code>n</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of nodes in the graph</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a list object that contains all nodes. If an IndexMap is used, nodes are returned as string IDs. If no IndexMap is used, nodes are returned as integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list of all nodes using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order of graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>order of the (De Bruijn) graph</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.out_degrees","title":"<code>out_degrees</code>  <code>property</code>","text":"<p>Return unweighted out-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing out-degrees of nodes</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>pathpyG.core.graph.Graph</code> <p>Other graph to be combined with this graph</p> required <code>reduce</code> <code>str</code> <p>Reduction method for node attributes of nodes that are present in both graphs. Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".</p> <code>'sum'</code> <p>Examples:</p> <p>Adding two graphs without node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 6 edges\n</code></pre> <p>Adding two graphs with identical node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 4 edges\n</code></pre> <p>Adding two graphs with non-overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 6 nodes and 4 edges\n</code></pre> <p>Adding two graphs with partly overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 5 nodes and 4 edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Args:\n        other: Other graph to be combined with this graph\n        reduce: Reduction method for node attributes of nodes that are present in both graphs.\n            Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n    Examples:\n        Adding two graphs without node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 6 edges\n\n        Adding two graphs with identical node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 4 edges\n\n        Adding two graphs with non-overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 6 nodes and 4 edges\n\n        Adding two graphs with partly overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 5 nodes and 4 edges\n    \"\"\"\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n    mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n    d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n    d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n    d = d1.concat(d2)\n    d.num_nodes = mapping.num_ids()\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n    # For higher-order graphs, we need to update the inverse_idx attribute\n    if \"inverse_idx\" in d:\n        d.inverse_idx = mapping.to_idxs(\n            np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n            device=d.inverse_idx.device,\n        )\n\n    # If both graphs contain node attributes, reduce them using the specified method\n    for k in d1.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            if isinstance(d[k], torch.Tensor):\n                d[k] = torch_geometric.utils.scatter(\n                    d[k],\n                    mapping.to_idxs(\n                        np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                        device=d[k].device,\n                    ),\n                    dim_size=d.num_nodes,\n                    reduce=reduce,\n                )\n            else:\n                raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if \"num_nodes\" not in data and \"edge_index\" in data:            \n        data.num_nodes = data.edge_index.max().item() + 1\n        logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if (\n        data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n        or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n    ):\n        logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n        raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n    self.data = data\n\n    # sort EdgeIndex and validate\n    data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    data.edge_index.validate()\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    # create node_sequence mapping for higher-order graphs\n    if \"node_sequence\" not in self.data:\n        self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key.startswith(\"node_\"):\n            if val.size(0) != self.n:\n                raise ValueError(\"Attribute must have same length as number of nodes\")\n            self.data[key] = val\n        elif key.startswith(\"edge_\"):\n            if val.size(0) != self.m:\n                raise ValueError(\"Attribute must have same length as number of edges\")\n            self.data[key] = val\n        else:\n            self.data[key] = val\n    elif key[0].startswith(\"node_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif key[0].startswith(\"edge_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return (weighted) degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate in- or out-degree for directed networks.</p> <code>'in'</code> <code>edge_attr</code> <code>typing.Any</code> <p>Optional numerical edge attribute that will  be used to compute weighted degrees</p> <code>None</code> <code>return_tensor</code> <code>bool</code> <p>if True the function returns a degree tensor, if False (default) a dictionary will be returned that can be indexed by nodes</p> <code>False</code> <p>Returns:     dict: dictionary containing node degrees</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                 torch.tensor]:\n    \"\"\"\n    Return (weighted) degrees of nodes.\n\n    Args:\n        mode: `in` or `out` to calculate in- or out-degree for\n            directed networks.\n        edge_attr: Optional numerical edge attribute that will \n            be used to compute weighted degrees\n        return_tensor: if True the function returns a degree tensor, if False (default)\n            a dictionary will be returned that can be indexed by nodes\n    Returns:\n        dict: dictionary containing node degrees\n    \"\"\"\n    if mode == \"in\":\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    else:\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    if return_tensor:\n        return d\n    else:\n        return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of edge attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def edge_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n\n    Returns:\n        list: list of edge attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <code>int</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.</p> <code>None</code> <p>Examples:</p> <p>You can create a graph from an edge index tensor as follows:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n&gt;&gt;&gt; print(g)\nDirected graph with 3 nodes and 3 edges ...\n</code></pre> <p>You can also include a mapping of node IDs:</p> <pre><code>&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n&gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n&gt;&gt;&gt; print(g.mapping)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n    Examples:\n        You can create a graph from an edge index tensor as follows:\n\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        &gt;&gt;&gt; print(g)\n        Directed graph with 3 nodes and 3 edges ...\n\n        You can also include a mapping of node IDs:\n\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n        &gt;&gt;&gt; print(g.mapping)\n        a -&gt; 0\n        b -&gt; 1\n        c -&gt; 2\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else:\n        if mapping is not None and mapping.num_ids() != num_nodes:\n            logger.error(\"Number of node IDs in mapping must match num_nodes\")\n            raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>device</code> <code>typing.Optional[torch.device]</code> <p>optional torch device where tensors shall be stored</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n&gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n&gt;&gt;&gt; print(list(g.edges))\n[('a', 'b'), ('a', 'c'), ('b', 'c')]\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(\n    edge_list: Iterable[Tuple[str, str]],\n    is_undirected: bool = False,\n    mapping: Optional[IndexMap] = None,\n    device: Optional[torch.device] = None,\n) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        device: optional torch device where tensors shall be stored\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n        &gt;&gt;&gt; print(list(g.edges))\n        [('a', 'b'), ('a', 'c'), ('b', 'c')]\n    \"\"\"\n\n    # handle empty graph\n    if len(edge_list) == 0:\n        return Graph(\n            Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n            mapping=IndexMap(),\n        )\n\n    if mapping is None:\n        edge_array = np.array(edge_list)\n        node_ids = np.unique(edge_array)\n        if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n            node_ids = np.sort(node_ids.astype(int)).astype(str)\n        mapping = IndexMap(node_ids)\n\n    num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex(\n        mapping.to_idxs(edge_list, device=device).T.contiguous(),\n        sparse_size=(num_nodes, num_nodes),\n        is_undirected=is_undirected,\n    )\n    return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all predecessor nodes of the node indexed by <code>col_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n    \"\"\"\n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all successor nodes of the node indexed by <code>row_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph contains self-loops, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\n\n    Returns:\n        bool: True if graph contains self-loops, False otherwise\n    \"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is directed, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\n\n    Returns:\n        bool: True if graph is directed, False otherwise\n    \"\"\"\n    return not self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if edge exists, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID\n\n    Returns:\n        bool: True if edge exists, False otherwise\n    \"\"\"\n    row = self.mapping.to_idx(v)\n    row_start = self.row_ptr[row]\n    row_end = self.row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in self.col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is undirected, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\n\n    Returns:\n        bool: True if graph is undirected, False otherwise\n    \"\"\"\n    return self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.laplacian","title":"<code>laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code> function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: Laplacian matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization: normalization parameter passed to pyG `get_laplacian`\n            function\n        edge_attr: optinal name of numerical edge attribute that shall\n            be passed to pyG `get_laplacian` function as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(), normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(),\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_sequence</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of node attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def node_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_sequence` attribute.\n\n    Returns:\n        list: list of node attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all predecessors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n\n    Returns:\n        list: list with all predecessors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n    node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.sparse_adj_matrix","title":"<code>sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n        )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all successors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) -&gt; list:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n\n    Returns:\n        list: list with all successors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n\n    node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to","title":"<code>to</code>","text":"<p>Move all tensors to the given device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>torch device to which all tensors shall be moved</p> required <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>self</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; Graph:\n    \"\"\"Move all tensors to the given device.\n\n    Args:\n        device: torch device to which all tensors shall be moved\n\n    Returns:\n        Graph: self\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.node_sequence = self.data.node_sequence.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n\n    self.row = self.row.to(device)\n    self.row_ptr = self.row_ptr.to(device)\n    self.col = self.col.to(device)\n    self.col_ptr = self.col_ptr.to(device)\n\n    return self\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of this directed graph.</p> <p>This method creates a new undirected Graph from the current graph instance by adding all directed edges in opposite direction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n&gt;&gt;&gt; g_u = g.to_undirected()\n&gt;&gt;&gt; print(g_u)\nUndirected graph with 3 nodes and 6 (directed) edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"Return an undirected version of this directed graph.\n\n    This method creates a new undirected Graph from the current graph instance by\n    adding all directed edges in opposite direction.\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        &gt;&gt;&gt; g_u = g.to_undirected()\n        &gt;&gt;&gt; print(g_u)\n        Undirected graph with 3 nodes and 6 (directed) edges\n    \"\"\"\n    # create undirected edge index by coalescing the directed edges and keep\n    # track of the original edge index for the edge attributes\n    attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n    edge_index, attr_idx = to_undirected(\n        self.data.edge_index,\n        edge_attr=attr_idx,\n        num_nodes=self.data.num_nodes,\n        reduce=\"min\",\n    )\n\n    data = Data(\n        edge_index=EdgeIndex(\n            data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n        ),\n        num_nodes=self.data.num_nodes,\n    )\n    # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n    # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n    # make sure to copy all node and (undirected) edge attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    for edge_attr in self.edge_attrs():\n        if edge_attr != \"edge_index\":\n            data[edge_attr] = self.data[edge_attr][attr_idx]\n\n    return Graph(data, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> <p>If the graph contains multiple edges between the same nodes, this method will coalesce them into a single edge with an additional weight attribute called <code>edge_weight</code> that contains the number of coalesced edges. The method returns a new graph instance with the coalesced edges.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>Graph with coalesced edges</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n    If the graph contains multiple edges between the same nodes, this method will coalesce\n    them into a single edge with an additional weight attribute called `edge_weight` that\n    contains the number of coalesced edges. The method returns a new graph instance with\n    the coalesced edges.\n\n    Returns:\n        Graph: Graph with coalesced edges\n    \"\"\"\n    i, w = torch_geometric.utils.coalesce(\n        self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n    )\n    return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Compute transition probabilities based on (weighted) outdegrees.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>Optional name of numerical edge attribute that will         will be used to calculate weighted out-degrees for the         visitation probabilities.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Transition probabilities.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n    \"\"\"\n    Compute transition probabilities based on (weighted) outdegrees.\n\n    Args:\n        edge_attr: Optional name of numerical edge attribute that will\n                    will be used to calculate weighted out-degrees for the\n                    visitation probabilities.\n\n    Returns:\n        tensor: Transition probabilities.\n    \"\"\"\n    weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n    source_ids = self.data.edge_index[0]        \n    edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n    if edge_attr:\n        edge_weight = getattr(self.data, edge_attr, None)\n    return edge_weight / weighted_outdegree[source_ids]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph","title":"<code>TemporalGraph</code>","text":"<p>               Bases: <code>pathpyG.Graph</code></p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>class TemporalGraph(Graph):\n    def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n        \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n        Args:\n            data: PyG `Data` object containing edges saved in `edge_index` and timestamps in `time`.\n            mapping: Optional mapping from node IDs to indices.\n\n        Example:\n            ```py\n            from pytorch_geometric.data import TemporalData\n            import pathpyG as pp\n\n            d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n            t = pp.TemporalGraph(d, mapping)\n            print(t)\n            ```\n        \"\"\"\n        self.data = data\n        if not isinstance(self.data.edge_index, EdgeIndex):\n            self.data.edge_index = EdgeIndex(\n                data=self.data.edge_index.contiguous(), sparse_size=(self.data.num_nodes, self.data.num_nodes)\n            )\n\n        # reorder temporal data\n        # Note that we do not use `torch_geometric.self.data.Data.sort_by_time` because it cannot sort numpy arrays`\n        sorted_idx = torch.argsort(self.data.time)\n        for edge_attr in set(self.data.edge_attrs()).union(set([\"time\"])):\n            if edge_attr == \"edge_index\":\n                self.data.edge_index = self.data.edge_index[:, sorted_idx]\n            else:\n                self.data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        if mapping is not None:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n\n        # create mapping between edge index and edge tuples\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate(self.data.edge_index.t())\n        }\n        self.tedge_to_index = {\n            (e[0].item(), e[1].item(), t.item()): i for i, (e, t) in enumerate(zip([e for e in self.data.edge_index.t()], self.data.time))\n        }\n\n        self.start_time = self.data.time[0].item()\n        self.end_time = self.data.time[-1].item()\n\n    @staticmethod\n    def from_edge_list(edge_list, num_nodes: Optional[int] = None, device: Optional[torch.device] = None) -&gt; TemporalGraph:  # type: ignore\n        \"\"\"Create a temporal graph from a list of tuples containing edges with timestamps.\"\"\"\n        edge_array = np.array(edge_list)\n\n        # Convert timestamps to tensor\n        if isinstance(edge_list[0][2], int):\n            ts = torch.tensor(edge_array[:, 2].astype(np.int_), device=device)\n        else:\n            ts = torch.tensor(edge_array[:, 2].astype(np.double), device=device)\n\n        index_map = IndexMap(np.unique(edge_array[:, :2]))\n        edge_index = index_map.to_idxs(edge_array[:, :2].T, device=device)\n\n        if not num_nodes:\n            num_nodes = index_map.num_ids()\n\n        return TemporalGraph(\n            data=Data(\n                edge_index=edge_index,\n                time=ts,\n                num_nodes=num_nodes,\n            ),\n            mapping=index_map,\n        )\n\n    @property\n    def temporal_edges(self) -&gt; list:\n        \"\"\"Return all temporal edges as a list of tuples (source, destination, timestamp).\n\n        Returns:\n            list: A list of tuples representing temporal edges in the format (source, destination, timestamp).\n\n        Examples:\n            Get the list of temporal edges:\n\n            &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            &gt;&gt;&gt; print(g.temporal_edges)\n            [('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)]\n\n            Iterate over temporal edges:\n            &gt;&gt;&gt; for edge in g.temporal_edges:\n            &gt;&gt;&gt;     print(edge)\n            ('a', 'b', 1)\n            ('b', 'c', 2)\n            ('c', 'a', 3)\n        \"\"\"\n        return [(*self.mapping.to_ids(e), t.item()) for e, t in zip(self.data.edge_index.t(), self.data.time)]\n\n    def to(self, device: torch.device) -&gt; TemporalGraph:\n        \"\"\"Moves all graph data to the specified device (CPU or GPU).\n\n        Args:\n            device: The target device to move the graph data to.\n\n        Returns:\n            TemporalGraph: A new TemporalGraph instance with data on the specified device.\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.time = self.data.time.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        return self\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"Return order 1, since all temporal graphs must be order one.\"\"\"\n        return 1\n\n    def shuffle_time(self) -&gt; None:\n        \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n        self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n\n    def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n        \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n        Args:\n            weighted: whether or not to return a weighted time-aggregated graph\n            time_window: A tuple with start and end time of the aggregation window\n\n        Returns:\n            Graph: A static graph object\n        \"\"\"\n        if time_window is not None:\n            idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n            edge_index = self.data.edge_index[:, idx]\n        else:\n            edge_index = self.data.edge_index\n\n        n = edge_index.max().item() + 1\n\n        if weighted:\n            i, w = torch_geometric.utils.coalesce(\n                edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n            )\n            return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n        else:\n            return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n\n    def to_undirected(self) -&gt; TemporalGraph:\n        \"\"\"Return an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        rev_edge_index = self.data.edge_index.flip([0])\n        edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n        times = torch.cat([self.data.time, self.data.time])\n        return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n\n    def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n        \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given batch defined by start and (non-inclusive) end, where start\n        and end refer to the index of the first and last event in the time-ordered list of events.\"\"\"\n\n        return TemporalGraph(\n            data=Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx]),\n            mapping=self.mapping,\n        )\n\n    def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n        \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given time window defined by start and (non-inclusive) end, where start\n        and end refer to the time stamps\"\"\"\n\n        return TemporalGraph(data=self.data.snapshot(start_time, end_time), mapping=self.mapping)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, temporal edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            # TODO: Get item for non-temporal edges will only return the last occurence of the edge\n            #       This is a limitation and should be fixed in the future.\n            if len(key) == 3:\n                return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n            else:\n                return self.data[key[0]][self.tedge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2]), key[3]]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the graph\n        \"\"\"\n        s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n            self.data.num_nodes,\n            self.data.edge_index.unique(dim=1).size(dim=1),\n            self.data.edge_index.size(1),\n            self.start_time,\n            self.end_time,\n        )\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order 1, since all temporal graphs must be order one.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.temporal_edges","title":"<code>temporal_edges</code>  <code>property</code>","text":"<p>Return all temporal edges as a list of tuples (source, destination, timestamp).</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of tuples representing temporal edges in the format (source, destination, timestamp).</p> <p>Examples:</p> <p>Get the list of temporal edges:</p> <pre><code>&gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n&gt;&gt;&gt; print(g.temporal_edges)\n[('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)]\n</code></pre> <p>Iterate over temporal edges:</p> <pre><code>&gt;&gt;&gt; for edge in g.temporal_edges:\n&gt;&gt;&gt;     print(edge)\n('a', 'b', 1)\n('b', 'c', 2)\n('c', 'a', 3)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, temporal edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, temporal edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        # TODO: Get item for non-temporal edges will only return the last occurence of the edge\n        #       This is a limitation and should be fixed in the future.\n        if len(key) == 3:\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            return self.data[key[0]][self.tedge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2]), key[3]]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__init__","title":"<code>__init__</code>","text":"<p>Creates an instance of a temporal graph from a <code>TemporalData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>PyG <code>Data</code> object containing edges saved in <code>edge_index</code> and timestamps in <code>time</code>.</p> required <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>Optional mapping from node IDs to indices.</p> <code>None</code> Example <pre><code>from pytorch_geometric.data import TemporalData\nimport pathpyG as pp\n\nd = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\nt = pp.TemporalGraph(d, mapping)\nprint(t)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n    \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n    Args:\n        data: PyG `Data` object containing edges saved in `edge_index` and timestamps in `time`.\n        mapping: Optional mapping from node IDs to indices.\n\n    Example:\n        ```py\n        from pytorch_geometric.data import TemporalData\n        import pathpyG as pp\n\n        d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n        t = pp.TemporalGraph(d, mapping)\n        print(t)\n        ```\n    \"\"\"\n    self.data = data\n    if not isinstance(self.data.edge_index, EdgeIndex):\n        self.data.edge_index = EdgeIndex(\n            data=self.data.edge_index.contiguous(), sparse_size=(self.data.num_nodes, self.data.num_nodes)\n        )\n\n    # reorder temporal data\n    # Note that we do not use `torch_geometric.self.data.Data.sort_by_time` because it cannot sort numpy arrays`\n    sorted_idx = torch.argsort(self.data.time)\n    for edge_attr in set(self.data.edge_attrs()).union(set([\"time\"])):\n        if edge_attr == \"edge_index\":\n            self.data.edge_index = self.data.edge_index[:, sorted_idx]\n        else:\n            self.data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    if mapping is not None:\n        self.mapping = mapping\n    else:\n        self.mapping = IndexMap()\n\n    # create mapping between edge index and edge tuples\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate(self.data.edge_index.t())\n    }\n    self.tedge_to_index = {\n        (e[0].item(), e[1].item(), t.item()): i for i, (e, t) in enumerate(zip([e for e in self.data.edge_index.t()], self.data.time))\n    }\n\n    self.start_time = self.data.time[0].item()\n    self.end_time = self.data.time[-1].item()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the graph\n    \"\"\"\n    s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n        self.data.num_nodes,\n        self.data.edge_index.unique(dim=1).size(dim=1),\n        self.data.edge_index.size(1),\n        self.start_time,\n        self.end_time,\n    )\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Create a temporal graph from a list of tuples containing edges with timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(edge_list, num_nodes: Optional[int] = None, device: Optional[torch.device] = None) -&gt; TemporalGraph:  # type: ignore\n    \"\"\"Create a temporal graph from a list of tuples containing edges with timestamps.\"\"\"\n    edge_array = np.array(edge_list)\n\n    # Convert timestamps to tensor\n    if isinstance(edge_list[0][2], int):\n        ts = torch.tensor(edge_array[:, 2].astype(np.int_), device=device)\n    else:\n        ts = torch.tensor(edge_array[:, 2].astype(np.double), device=device)\n\n    index_map = IndexMap(np.unique(edge_array[:, :2]))\n    edge_index = index_map.to_idxs(edge_array[:, :2].T, device=device)\n\n    if not num_nodes:\n        num_nodes = index_map.num_ids()\n\n    return TemporalGraph(\n        data=Data(\n            edge_index=edge_index,\n            time=ts,\n            num_nodes=num_nodes,\n        ),\n        mapping=index_map,\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.get_batch","title":"<code>get_batch</code>","text":"<p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given batch defined by start and (non-inclusive) end, where start and end refer to the index of the first and last event in the time-ordered list of events.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n    \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given batch defined by start and (non-inclusive) end, where start\n    and end refer to the index of the first and last event in the time-ordered list of events.\"\"\"\n\n    return TemporalGraph(\n        data=Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx]),\n        mapping=self.mapping,\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.get_window","title":"<code>get_window</code>","text":"<p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given time window defined by start and (non-inclusive) end, where start and end refer to the time stamps</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n    \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given time window defined by start and (non-inclusive) end, where start\n    and end refer to the time stamps\"\"\"\n\n    return TemporalGraph(data=self.data.snapshot(start_time, end_time), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.shuffle_time","title":"<code>shuffle_time</code>","text":"<p>Randomly shuffle the temporal order of edges by randomly permuting timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def shuffle_time(self) -&gt; None:\n    \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n    self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to","title":"<code>to</code>","text":"<p>Moves all graph data to the specified device (CPU or GPU).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>The target device to move the graph data to.</p> required <p>Returns:</p> Name Type Description <code>TemporalGraph</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>A new TemporalGraph instance with data on the specified device.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; TemporalGraph:\n    \"\"\"Moves all graph data to the specified device (CPU or GPU).\n\n    Args:\n        device: The target device to move the graph data to.\n\n    Returns:\n        TemporalGraph: A new TemporalGraph instance with data on the specified device.\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.time = self.data.time.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    return self\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to_static_graph","title":"<code>to_static_graph</code>","text":"<p>Return weighted time-aggregated instance of <code>Graph</code> graph.</p> <p>Parameters:</p> Name Type Description Default <code>weighted</code> <code>bool</code> <p>whether or not to return a weighted time-aggregated graph</p> <code>False</code> <code>time_window</code> <code>typing.Optional[typing.Tuple[int, int]]</code> <p>A tuple with start and end time of the aggregation window</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.Graph</code> <p>A static graph object</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n    \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n    Args:\n        weighted: whether or not to return a weighted time-aggregated graph\n        time_window: A tuple with start and end time of the aggregation window\n\n    Returns:\n        Graph: A static graph object\n    \"\"\"\n    if time_window is not None:\n        idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n        edge_index = self.data.edge_index[:, idx]\n    else:\n        edge_index = self.data.edge_index\n\n    n = edge_index.max().item() + 1\n\n    if weighted:\n        i, w = torch_geometric.utils.coalesce(\n            edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n    else:\n        return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_undirected(self) -&gt; TemporalGraph:\n    \"\"\"Return an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    rev_edge_index = self.data.edge_index.flip([0])\n    edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n    times = torch.cat([self.data.time, self.data.time])\n    return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.lift_order_temporal","title":"<code>lift_order_temporal</code>","text":"<p>Lift a temporal graph to a second-order temporal event graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to lift.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events to consider them connected.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>ho_index</code> <p>Edge index of the second-order temporal event graph.</p> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def lift_order_temporal(g: TemporalGraph, delta: int = 1):\n    \"\"\"Lift a temporal graph to a second-order temporal event graph.\n\n    Args:\n        g: Temporal graph to lift.\n        delta: Maximum time difference between events to consider them connected.\n\n    Returns:\n        ho_index: Edge index of the second-order temporal event graph.\n    \"\"\"\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.time\n\n    delta = torch.tensor(delta, device=edge_index.device)\n    indices = torch.arange(0, edge_index.size(1), device=edge_index.device)\n\n    unique_t = torch.unique(timestamps, sorted=True)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for t in tqdm(unique_t):\n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = timestamps == t\n        src_edge_idx = indices[src_time_mask]\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t + delta)\n        dst_edge_idx = indices[dst_time_mask]\n\n        if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n            # compute second-order edges between src and dst idx\n            # for all edges where dst in src_edges (edge_index[1, x[:, 0]]) matches src in dst_edges (edge_index[0, x[:, 1]])\n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx)\n            ho_edge_index = x[edge_index[1, x[:, 0]] == edge_index[0, x[:, 1]]]\n            second_order.append(ho_edge_index)\n\n    ho_index = torch.cat(second_order, dim=0).t().contiguous()\n    return ho_index\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.temporal_shortest_paths","title":"<code>temporal_shortest_paths</code>","text":"<p>Compute shortest time-respecting paths in a temporal graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to compute shortest paths on.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events in a path.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Tuple of two numpy arrays:</p> <code>numpy.ndarray</code> <ul> <li>dist: Shortest time-respecting path distances between all first-order nodes.</li> </ul> <code>typing.Tuple[numpy.ndarray, numpy.ndarray]</code> <ul> <li>pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.</li> </ul> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def temporal_shortest_paths(g: TemporalGraph, delta: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute shortest time-respecting paths in a temporal graph.\n\n    Args:\n        g: Temporal graph to compute shortest paths on.\n        delta: Maximum time difference between events in a path.\n\n    Returns:\n        Tuple of two numpy arrays:\n        - dist: Shortest time-respecting path distances between all first-order nodes.\n        - pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n    dst_edges_dst = g.data.edge_index[1] + g.m + g.n\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.m + 2 * g.n)\n    m = event_graph.sparse_adj_matrix()\n\n    # print(f\"Created temporal event DAG with {event_graph.n} nodes and {event_graph.m} edges\")\n\n    # run disjktra for all source nodes\n    dist, pred = dijkstra(\n        m, directed=True, indices=np.arange(g.m, g.m + g.n), return_predecessors=True, unweighted=True\n    )\n\n    # limit to first-order destinations and correct distances\n    dist_fo = dist[:, g.m + g.n :] - 1\n    np.fill_diagonal(dist_fo, 0)\n\n    # limit to first-order destinations and correct predecessors\n    pred_fo = pred[:, g.n + g.m :]\n    pred_fo[pred_fo == -9999] = -1\n    idx_map = np.concatenate([to_numpy(g.data.edge_index[0].cpu()), [-1]])\n    pred_fo = idx_map[pred_fo]\n    np.fill_diagonal(pred_fo, np.arange(g.n))\n\n    return dist_fo, pred_fo\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.to_numpy","title":"<code>to_numpy</code>","text":"<p>Convert an iterable (including a tensor or tensor subclasses like <code>torch_geometric.Edge_Index</code>) to numpy.</p> <p>Parameters:</p> Name Type Description Default <code>input_iterable</code> <code>torch.Tensor | numpy.ndarray | list</code> <p>Tensor, tensor subclass, numpy array or list.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Numpy array.</p> Source code in <code>src/pathpyG/utils/convert.py</code> <pre><code>def to_numpy(input_iterable: torch.Tensor | np.ndarray | list) -&gt; np.ndarray:\n    \"\"\"\n    Convert an iterable (including a tensor or tensor subclasses like `torch_geometric.Edge_Index`) to numpy.\n\n    Args:\n        input_iterable: Tensor, tensor subclass, numpy array or list.\n\n    Returns:\n        Numpy array.\n    \"\"\"\n    if isinstance(input_iterable, (EdgeIndex, Index)):\n        return input_iterable.as_tensor().cpu().numpy()\n    elif isinstance(input_iterable, torch.Tensor):\n        return input_iterable.cpu().numpy()\n    elif isinstance(input_iterable, (list, tuple)):\n        return np.array(input_iterable)\n    elif isinstance(input_iterable, np.ndarray):\n        return input_iterable\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/","title":"centrality","text":"<p>Algorithms to calculate centralities in (temporal) graphs.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG\nimport pathpyG as pp\n\n# Generate toy example for temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)\n])\n\nbw_t = pp.algorithms.temporal_betweenness_centrality(g, delta=1)\ncl_t = pp.algorithms.temporal_closeness_centrality(g, delta=1)\n\nstatic_graph = g.to_static_graph()\nbw_s = pp.algorithms.betweenness_centrality(static_graph)\nbw_s = pp.algorithms.closeness_centrality(static_graph)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.__getattr__","title":"<code>__getattr__</code>","text":"<p>Map to corresponding functions in centrality module of networkx.</p> <p>Any call to a function that is not implemented in the module centrality and whose first argument is of type Graph will be delegated to the corresponding function in the networkx module <code>centrality</code>. Please refer to the networkx documentation for a reference of available functions.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>the name of the function that shall be called</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def __getattr__(name: str) -&gt; Any:\n    \"\"\"Map to corresponding functions in centrality module of networkx.\n\n    Any call to a function that is not implemented in the module centrality\n    and whose first argument is of type Graph will be delegated to the\n    corresponding function in the networkx module `centrality`. Please\n    refer to the [networkx documentation](https://networkx.org/documentation/stable/reference/algorithms/centrality.html)\n    for a reference of available functions.\n\n    Args:\n        name: the name of the function that shall be called\n    \"\"\"\n\n    def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n        if len(args) == 0:\n            raise RuntimeError(f\"Did not find method {name} with no arguments\")\n        if isinstance(args[0], TemporalGraph):\n            raise NotImplementedError(f\"Missing implementation of {name} for temporal graphs\")\n        # if first argument is of type Graph, delegate to networkx function\n        if isinstance(args[0], Graph):\n            g = to_networkx(args[0].data)\n            r = getattr(centrality, name)(g, *args[1:], **kwargs)\n            if name.index(\"centrality\") &gt; 0 and isinstance(r, dict):\n                return map_to_nodes(args[0], r)\n            return r\n        else:\n            return wrapper(*args, **kwargs)\n            # raise RuntimeError(f'Did not find method {name} that accepts first argument of type {type(args[0])}')\n\n    return wrapper\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.betweenness_centrality","title":"<code>betweenness_centrality</code>","text":"<p>Calculate the betweenness centrality of nodes based on the fast algorithm proposed by Brandes:</p> <p>U. Brandes: A faster algorithm for betweenness centrality, The Journal of Mathematical Sociology, 2001</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.graph.Graph</code> <p><code>Graph</code> object for which betweenness centrality will be computed</p> required <code>sources</code> <p>optional list of source nodes for BFS-based shortest path calculation</p> <code>None</code> Example <pre><code>import pathpyG as pp\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                    ('b', 'd'), ('c', 'e'), ('d', 'e')])\nbw = pp.algorithms.betweenness_centrality(g)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def betweenness_centrality(g: Graph, sources=None) -&gt; dict[str, float]:\n    \"\"\"Calculate the betweenness centrality of nodes based on the fast algorithm\n    proposed by Brandes:\n\n    U. Brandes: A faster algorithm for betweenness centrality, The Journal of\n    Mathematical Sociology, 2001\n\n    Args:\n        g: `Graph` object for which betweenness centrality will be computed\n        sources: optional list of source nodes for BFS-based shortest path calculation\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                            ('b', 'd'), ('c', 'e'), ('d', 'e')])\n        bw = pp.algorithms.betweenness_centrality(g)\n        ```\n    \"\"\"\n    bw = defaultdict(lambda: 0.0)\n\n    if sources == None:\n        sources = [v for v in g.nodes]\n\n    for s in sources:\n        S = list()\n        P = defaultdict(list)\n\n        sigma = defaultdict(lambda: 0)\n        sigma[s] = 1\n\n        d = defaultdict(lambda: -1)\n        d[s] = 0\n\n        Q = [s]\n        while Q:\n            v = Q.pop(0)\n            S.append(v)\n            for w in g.successors(v):\n                if d[w] &lt; 0:\n                    Q.append(w)\n                    d[w] = d[v] + 1\n                if d[w] == d[v] + 1:\n                    # we found shortest path from s via v to w\n                    sigma[w] = sigma[w] + sigma[v]\n                    P[w].append(v)\n        delta = defaultdict(lambda: 0.0)\n        while S:\n            w = S.pop()\n            for v in P[w]:\n                delta[v] = delta[v] + sigma[v] / sigma[w] * (1 + delta[w])\n                if v != w:\n                    bw[w] = bw[w] + delta[w]\n    return bw\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.map_to_nodes","title":"<code>map_to_nodes</code>","text":"<p>Map node-level centralities in dictionary to node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.graph.Graph</code> <p>Graph object</p> required <code>c</code> <code>typing.Dict</code> <p>dictionary mapping node indices to metrics</p> required Example <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n...                               node_id=['a', 'b', 'c'])\n&gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n&gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n&gt;&gt;&gt; print(c_mapped)\n{'a': 0.5, 'b': 2.7, 'c': 0.3}\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def map_to_nodes(g: Graph, c: Dict) -&gt; Dict:\n    \"\"\"Map node-level centralities in dictionary to node IDs.\n\n    Args:\n        g: Graph object\n        c: dictionary mapping node indices to metrics\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        ...                               node_id=['a', 'b', 'c'])\n        &gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n        &gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n        &gt;&gt;&gt; print(c_mapped)\n        {'a': 0.5, 'b': 2.7, 'c': 0.3}\n        ```\n    \"\"\"\n    return {g.mapping.to_id(i): c[i] for i in c}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_node_traversals","title":"<code>path_node_traversals</code>","text":"<p>Calculate the number of times any path traverses each of the nodes.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>pathpyG.core.path_data.PathData</code> <p><code>PathData</code> object that contains observations of paths in a graph</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_node_traversals(paths: PathData) -&gt; dict:\n    \"\"\"Calculate the number of times any path traverses each of the nodes.\n\n    Args:\n        paths: `PathData` object that contains observations of paths in a graph\n    \"\"\"\n    unique_node_seq, traversal_counts = torch.unique(paths.data.node_sequence, return_counts=True)\n    return {paths.mapping.to_id(node): count.item() for node, count in zip(unique_node_seq, traversal_counts)}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_visitation_probabilities","title":"<code>path_visitation_probabilities</code>","text":"<p>Calculate the probabilities that a randomly chosen path passes through each of the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be assigned a visitation probability of 0.05. This measure can be interpreted as ground truth for the notion of importance captured by PageRank applied to a graphical abstraction of the paths.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>pathpyG.core.path_data.PathData</code> <p>PathData object that contains path data</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_visitation_probabilities(paths: PathData) -&gt; dict:\n    \"\"\"Calculate the probabilities that a randomly chosen path passes through each of\n    the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be\n    assigned a visitation probability of 0.05. This measure can be interpreted as ground\n    truth for the notion of importance captured by PageRank applied to a graphical\n    abstraction of the paths.\n\n    Args:\n        paths: PathData object that contains path data\n    \"\"\"\n    # entries capture the probability that a given node is visited on an arbitrary path\n    # Note: this is identical to the subpath count of zero-length paths\n    # (i.e. the relative frequencies of nodes across all pathways)\n    visit_probabilities = path_node_traversals(paths)\n\n    # total number of visits\n    visits = 0.0\n    for v in visit_probabilities:\n        visits += visit_probabilities[v]\n\n    for v in visit_probabilities:\n        visit_probabilities[v] /= visits\n    return visit_probabilities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_betweenness_centrality","title":"<code>temporal_betweenness_centrality</code>","text":"<p>Calculate the temporal betweenness of nodes in a temporal graph.</p> <p>The temporal betweenness centrality definition is based on shortest time-respecting paths with a given maximum time difference delta, where the length of a path is given as the number of traversed edges (i.e. not the temporal duration of a path or the earliest arrival at a node).</p> <p>The algorithm is an adaptation of Brandes' fast algorithm for betweenness centrality based on the following work:</p> <p>S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal Betweenness, arXiv:2006.08668v2</p> <p>Different from the algorithm proposed above, the temporal betweenness centrality implemented in pathpyG is based on a directed acyclic event graph representation of a temporal graph and it considers a maximum waiting time of delta. The complexity is in O(nm) where n is the number of nodes in the temporal graph and m is the number of time-stamped edges.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> <code>1</code> Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\nbw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_betweenness_centrality(g: TemporalGraph, delta: int = 1) -&gt; dict[str, float]:\n    \"\"\"Calculate the temporal betweenness of nodes in a temporal graph.\n\n    The temporal betweenness centrality definition is based on shortest\n    time-respecting paths with a given maximum time difference delta, where\n    the length of a path is given as the number of traversed edges (i.e. not\n    the temporal duration of a path or the earliest arrival at a node).\n\n    The algorithm is an adaptation of Brandes' fast algorithm for betweenness\n    centrality based on the following work:\n\n    S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal\n    Betweenness, arXiv:2006.08668v2\n\n    Different from the algorithm proposed above, the temporal betweenness centrality\n    implemented in pathpyG is based on a directed acyclic event graph representation of\n    a temporal graph and it considers a maximum waiting time of delta. The complexity\n    is in O(nm) where n is the number of nodes in the temporal graph and m is the number\n    of time-stamped edges.\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        bw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    # add edges from first-order source nodes to edge events\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges], dim=1)\n    src_indices = torch.unique(src_edges_src).tolist()\n\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.m + g.n)\n\n    e_i = to_numpy(g.data.edge_index)\n\n    fo_nodes = dict()\n    for v in range(g.m + g.n):\n        if v &lt; g.m:  # return first-order target node otherwise\n            fo_nodes[v] = e_i[1, v]\n        else:\n            fo_nodes[v] = v - g.m\n\n    bw: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n    # for all first-order nodes\n    for s in tqdm(src_indices):\n\n        # for any given s, d[v] is the shortest path distance from s to v\n        # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)\n        delta_: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n        # for any given s, sigma[v] counts shortest paths from s to v\n        sigma: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma[s] = 1.0\n\n        sigma_fo: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma_fo[fo_nodes[s]] = 1.0\n\n        dist: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist[s] = 0\n\n        dist_fo: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist_fo[fo_nodes[s]] = 0\n\n        # for any given s, P[v] is the set of predecessors of v on shortest paths from s\n        P = defaultdict(set)\n\n        # Q is a queue, so we append at the right and pop from the left\n        Q: deque = deque()\n        Q.append(s)\n\n        # S is a stack, so we append at the end and pop from the end\n        S = list()\n\n        # dijkstra with path counting\n        while Q:\n            v = Q.popleft()\n            # for all successor events within delta\n            for w in event_graph.successors(v):\n\n                # we dicover w for the first time\n                if dist[w] == -1:\n                    dist[w] = dist[v] + 1\n                    if dist_fo[fo_nodes[w]] == -1:\n                        dist_fo[fo_nodes[w]] = dist[v] + 1\n                    S.append(w)\n                    Q.append(w)\n                # we found a shortest path to event w via event v\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[v]\n                    P[w].add(v)\n                    # we found a shortest path to first-order node of event w\n                    if dist[w] == dist_fo[fo_nodes[w]]:\n                        sigma_fo[fo_nodes[w]] += sigma[v]\n\n        c = 0.0\n        for i in dist_fo:\n            if dist_fo[i] &gt;= 0:\n                c += 1.0\n        bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1.0\n\n        while S:\n            w = S.pop()\n            # work backwards through paths to all targets and sum delta and sigma\n            if dist[w] == dist_fo[fo_nodes[w]]:\n                x = sigma[w] / sigma_fo[fo_nodes[w]]\n                if isnan(x):\n                    x = 0.0\n                delta_[w] += x\n            for v in P[w]:\n                x = sigma[v] / sigma[w]\n                if isnan(x):\n                    x = 0.0\n                delta_[v] += x * delta_[w]\n                bw[fo_nodes[v]] += delta_[w] * x\n\n    # map index-based centralities to node IDs\n    bw_id = defaultdict(lambda: 0.0)\n    for idx in bw:\n        bw_id[g.mapping.to_id(idx)] = bw[idx]\n    return bw_id\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_closeness_centrality","title":"<code>temporal_closeness_centrality</code>","text":"<p>Calculates the temporal closeness centrality of nodes based on observed shortest time-respecting paths between all nodes.</p> <p>Following the definition by M. A. Beauchamp 1965 (https://doi.org/10.1002/bs.3830100205).</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> required Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\ncl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_closeness_centrality(g: TemporalGraph, delta: int) -&gt; dict[str, float]:\n    \"\"\"Calculates the temporal closeness centrality of nodes based on\n    observed shortest time-respecting paths between all nodes.\n\n    Following the definition by M. A. Beauchamp 1965\n    (https://doi.org/10.1002/bs.3830100205).\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        cl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    centralities = dict()\n    dist, _ = temporal_shortest_paths(g, delta)\n    for x in g.nodes:\n        centralities[x] = sum((g.n - 1) / dist[_np.arange(g.n) != g.mapping.to_idx(x), g.mapping.to_idx(x)])\n\n    return centralities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/components/","title":"components","text":"<p>Algorithms to calculate connected components</p>"},{"location":"reference/pathpyG/algorithms/generative_models/","title":"models","text":"<p>Algorithms to generate random graphs</p> <p>The functions in this module allow to generate graphs based on different probabilistic generative models.</p> Example <pre><code>import pathpyG as pp\n\ng = pp.algorithms.generative_models.erdos_renyi_gnm(n=100, m=200)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnm","title":"<code>erdos_renyi_gnm</code>","text":"<p>Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>the number of nodes of the graph</p> required <code>m</code> <code>int</code> <p>the number of random directed or undirected edges to be generated</p> required <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>optional given mapping of n nodes to node IDs. If this is not given a mapping is created</p> <code>None</code> <code>self_loops</code> <code>bool</code> <p>whether or not to allow self-loops (v,v) to be generated</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>whether or not multiple identical edges are allowed</p> <code>False</code> <code>directed</code> <code>bool</code> <p>whether or not to generate a directed graph</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>graph object</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnm(n: int, m: int, mapping: IndexMap | None = None,\n                    self_loops: bool = False, multi_edges: bool = False,\n                    directed: bool = False) -&gt; Graph:\n    \"\"\"Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.\n\n    Args:\n        n: the number of nodes of the graph\n        m: the number of random directed or undirected edges to be generated\n        mapping: optional given mapping of n nodes to node IDs. If this is not given a mapping is created\n        self_loops: whether or not to allow self-loops (v,v) to be generated\n        multi_edges: whether or not multiple identical edges are allowed\n        directed: whether or not to generate a directed graph\n\n    Returns:\n        Graph: graph object\n    \"\"\"\n    if m &gt; max_edges(n, directed=directed, self_loops=self_loops, multi_edges=multi_edges):\n        logger.error(\"Given number of edges is larger than theoretical maximum\")\n        raise ValueError(\"Given number of edges is larger than theoretical maximum\")\n\n    edges = set()\n    edges_added: int = 0\n\n    if mapping is None:\n        # make sure that we have indices for all n nodes even if not all\n        # nodes have incident edges\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    # Add m edges at random\n    while edges_added &lt; m:\n\n        # Choose two random nodes (with replacement if self-loops are included)\n        v, w = _np.random.choice(n, size=2, replace=self_loops)\n\n        # avoid multi-edges\n        if multi_edges or (mapping.to_id(v), mapping.to_id(w)) not in edges:\n            edges.add((mapping.to_id(v), mapping.to_id(w)))\n            if not directed and v != w:\n                edges.add((mapping.to_id(w), mapping.to_id(v)))\n            edges_added += 1\n\n    return Graph.from_edge_list(list(edges), is_undirected=not directed, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnm_randomize","title":"<code>erdos_renyi_gnm_randomize</code>","text":"<p>Generate a random graph whose number of nodes, edges, edge directedness and node IDs match the corresponding values of a given network instance. Useful to generate a randomized version of a network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>A given network used to determine number of nodes, edges, node uids, and edge directedness</p> required <code>self_loops</code> <code>bool</code> <p>Whether or not the generated network can contain loops.</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>Whether or not multiple edges can be added to the same node pair</p> <code>False</code> <p>Example: <pre><code>    # Generate undirected network\n    import pathpyG as pp\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('d', 'e')])\n    r = pp.algorithms.generative_models.G_nm_randomize(g)\n</code></pre></p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnm_randomize(graph: Graph, self_loops: bool = False, multi_edges: bool = False) -&gt; Graph:\n    \"\"\"Generate a random graph whose number of nodes, edges, edge directedness and node IDs\n    match the corresponding values of a given network instance. Useful to generate a randomized\n    version of a network.\n\n    Args:\n        graph: A given network used to determine number of nodes, edges, node uids, and edge directedness\n        self_loops: Whether or not the generated network can contain loops.\n        multi_edges: Whether or not multiple edges can be added to the same node pair\n\n    Example:\n    ```py\n        # Generate undirected network\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('d', 'e')])\n        r = pp.algorithms.generative_models.G_nm_randomize(g)\n    ```\n    \"\"\"\n    return erdos_renyi_gnm(\n        graph.n, graph.m, directed=graph.is_directed(),\n        self_loops=self_loops,\n        multi_edges=multi_edges,\n        mapping=graph.mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp","title":"<code>erdos_renyi_gnp</code>","text":"<p>Generate an Erd\u00f6s-Renyi random graph with n nodes and  link probability p, using the G(n,p) model by Edgar Nelson Gilbert.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>the number of nodes of the graph</p> required <code>p</code> <code>float</code> <p>the link probability</p> required <code>self_loops</code> <code>bool</code> <p>whether or not to allow self-loops (v,v) to be generated</p> <code>False</code> <code>directed</code> <code>bool</code> <p>whether or not to generate a directed graph</p> <code>False</code> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp(n: int, p: float, mapping: IndexMap | None = None,\n                    self_loops: bool = False, directed: bool = False) -&gt; Graph:\n    \"\"\"Generate an Erd\u00f6s-Renyi random graph with n nodes and \n    link probability p, using the G(n,p) model by Edgar Nelson Gilbert.\n\n    Args:\n        n: the number of nodes of the graph\n        p: the link probability\n        self_loops: whether or not to allow self-loops (v,v) to be generated\n        directed: whether or not to generate a directed graph\n    \"\"\"\n    edges = set()\n\n    if mapping is None:\n        # make sure that we have indices for all n nodes even if not all\n        # nodes have incident edges\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    # fast handling of special case p = 0\n    if p == 0.0:\n        return Graph.from_edge_list([], is_undirected=not directed)\n\n    # connect pairs of nodes with probability p\n    for s in range(n):\n        if directed:\n            x = n\n        else:\n            x = s + 1\n        for t in range(x):\n            if not self_loops and t == s:\n                continue\n            if _np.random.random() &lt;= p:\n                edges.add((mapping.to_id(s), mapping.to_id(t)))\n                if not directed and s != t:\n                    edges.add((mapping.to_id(t), mapping.to_id(s)))\n\n    return Graph.from_edge_list(list(edges), is_undirected=not directed, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_likelihood","title":"<code>erdos_renyi_gnp_likelihood</code>","text":"<p>Calculate the likelihood of parameter p for a G(n,p) model and a given undirected graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_likelihood(p: float, graph: Graph) -&gt; float:\n    \"\"\"Calculate the likelihood of parameter p for a G(n,p) model and a given undirected graph\"\"\"\n    if graph.is_directed():\n        logger.error(\"erdos_renyi_gnp_likelihood does not support directed graphs\")\n        raise NotImplementedError(\"erdos_renyi_gnp_likelihood does not support directed graphs\")\n    return p**graph.n * (1 - p) ** (scipy.special.binom(graph.n, 2) - graph.m)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_log_likelihood","title":"<code>erdos_renyi_gnp_log_likelihood</code>","text":"<p>Calculate the log-likelihood of parameter p for a G(n,p) model and a given undirected graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_log_likelihood(p: float, graph: Graph) -&gt; float:\n    \"\"\"Calculate the log-likelihood of parameter p for a G(n,p) model and a given undirected graph\"\"\"\n    if graph.is_directed():\n        logger.error(\"erdos_renyi_gnp_log_likelihood does not support directed graphs\")\n        raise NotImplementedError(\"erdos_renyi_gnp_log_likelihood does not support directed graphs\")\n    return graph.m * _np.log10(p) + (scipy.special.binom(graph.n, 2) - (graph.m)) * _np.log10(1 - p)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_mle","title":"<code>erdos_renyi_gnp_mle</code>","text":"<p>Calculate the maximum likelihood estimate of parameter p for a G(n,p) model and a given undirected graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_mle(graph: Graph) -&gt; float:\n    \"\"\"Calculate the maximum likelihood estimate of parameter p for a G(n,p) model and a given undirected graph\"\"\"\n    if graph.is_directed():\n        logger.error(\"erdos_renyi_gnp_mle does not support directed graphs\")\n        raise NotImplementedError(\"erdos_renyi_gnp_mle does not support directed graphs\")\n    return graph.m / scipy.special.binom(graph.n, 2)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_randomize","title":"<code>erdos_renyi_gnp_randomize</code>","text":"<p>Randomize a given graph based on the Erd\u00f6s-Renyi random graph G(n,p) model.</p> <p>The number of nodes, expected number of edges, edge directedness and node uids of the generated graph match the corresponding values of the graph given as parameter.</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_randomize(graph: Graph, self_loops: bool = False) -&gt; Graph:\n    \"\"\"Randomize a given graph based on the Erd\u00f6s-Renyi random graph G(n,p) model.\n\n    The number of nodes, expected number of edges, edge directedness and node uids of the\n    generated graph match the corresponding values of the graph given as parameter.\n    \"\"\"\n    M = max_edges(graph.n, directed=graph.is_directed(), self_loops=self_loops)\n    p = graph.m / M\n    return erdos_renyi_gnp(n=graph.n, p=p, directed=graph.is_directed(), \n                           self_loops=self_loops, mapping=graph.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.generate_degree_sequence","title":"<code>generate_degree_sequence</code>","text":"<p>Generates a random graphic degree sequence drawn from a given degree distribution</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def generate_degree_sequence(\n    n: int,\n    distribution: Dict[float, float] | scipy.stats.rv_continuous | scipy.stats.rv_discrete,\n    **distribution_args: Any,\n) -&gt; _np.ndarray:\n    \"\"\"Generates a random graphic degree sequence drawn from a given degree distribution\"\"\"\n    s = _np.array([1])\n    # create rv_discrete object with custom distribution and generate degree sequence\n    if isinstance(distribution, dict):\n        degrees = [k for k in distribution]\n        probs = [distribution[k] for k in degrees]\n\n        dist = scipy.stats.rv_discrete(name=\"custom\", values=(degrees, probs))\n\n        while not is_graphic_erdos_gallai(s):\n            s = dist.rvs(size=n, **distribution_args)\n        return s\n    # use scipy rv objects to generate graphic degree sequence\n    elif hasattr(distribution, \"rvs\"):\n        while not is_graphic_erdos_gallai(s):\n            s = distribution.rvs(size=n, **distribution_args)\n            # Check if the distribution is discrete\n            if s.dtype != int:\n                s = _np.rint(s)\n        return s\n    else:\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.is_graphic_erdos_gallai","title":"<code>is_graphic_erdos_gallai</code>","text":"<p>Check Erd\u00f6s and Gallai condition.</p> <p>Checks whether the condition by Erd\u00f6s and Gallai (1967) for a graphic degree sequence is fulfilled.</p> <p>Parameters:</p> Name Type Description Default <code>degrees</code> <code>list[int] | numpy.ndarray</code> <p>List of integer node degrees to be tested.</p> required Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def is_graphic_erdos_gallai(degrees: list[int] | _np.ndarray) -&gt; bool:\n    \"\"\"Check Erd\u00f6s and Gallai condition.\n\n    Checks whether the condition by Erd\u00f6s and Gallai (1967) for a graphic degree\n    sequence is fulfilled.\n\n    Args:\n        degrees: List of integer node degrees to be tested.\n    \"\"\"\n    degree_sequence = sorted(degrees, reverse=True)\n    S = sum(degree_sequence)\n    n = len(degree_sequence)\n    if S % 2 != 0:\n        return False\n    for r in range(1, n):\n        M = 0\n        S = 0\n        for i in range(1, r + 1):\n            S += degree_sequence[i - 1]\n        for i in range(r + 1, n + 1):\n            M += min(r, degree_sequence[i - 1])\n        if S &gt; r * (r - 1) + M:\n            return False\n    return True\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.k_regular_random","title":"<code>k_regular_random</code>","text":"<p>Generate a random graph in which all nodes have exactly degree k</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>degree of all nodes in the generated network.</p> required <code>node_ids</code> <code>typing.Optional[list]</code> <p>Optional list of node uids that will be used.</p> <code>None</code> <p>Examples:</p> <pre><code>Generate random undirected network with given degree sequence\n\n&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n&gt;&gt;&gt; print(random_network.summary())\n...\n\nNetwork generation fails for non-graphic sequences\n\n&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n&gt;&gt;&gt; print(random_network)\nNone\n</code></pre> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def k_regular_random(k: int, n: Optional[int] = None, node_ids: Optional[list] = None) -&gt; Optional[Graph]:\n    \"\"\"Generate a random graph in which all nodes have exactly degree k\n\n    Args:\n        k: degree of all nodes in the generated network.\n        node_ids: Optional list of node uids that will be used.\n\n    Examples:\n\n        Generate random undirected network with given degree sequence\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n        &gt;&gt;&gt; print(random_network.summary())\n        ...\n\n        Network generation fails for non-graphic sequences\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n        &gt;&gt;&gt; print(random_network)\n        None\n    \"\"\"\n    if k &lt; 0:\n        msg = 'Degree parameter k must be non-negative'\n        raise ValueError(msg)\n    if n is None and node_ids is None:\n        msg = 'You must either pass a list of node ids or a number of nodes to generate'\n        raise ValueError(msg)\n\n    if n is None:\n        n = len(node_ids)\n\n    return molloy_reed([k]*n, multiedge=False, relax=False, node_ids=node_ids)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.max_edges","title":"<code>max_edges</code>","text":"<p>Returns the maximum number of edges that a directed or undirected network with n nodes can possible have (with or without loops).</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of nodes in the network</p> required <code>directed</code> <code>bool</code> <p>If True, return the maximum number of edges in a directed network.</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>If True, multiple edges between each node pair are allowed. In this case np.inf is returned.</p> <code>False</code> <code>self_loops</code> <code>bool</code> <p>If True, include self-loops.</p> <code>False</code> <p>Examples:</p> <p>Compute maximum number of edges in undirected network without self-loops and 100 nodes</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100)\n4950\n</code></pre> <p>Directed networks without self-loops</p> <pre><code>&gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True)\n9900\n</code></pre> <p>Directed networks with self-loops </p> <pre><code>&gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True, loops=True)\n10000\n</code></pre> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def max_edges(n: int, directed: bool = False, multi_edges: bool = False, self_loops: bool = False) -&gt; int | float:\n    \"\"\"Returns the maximum number of edges that a directed or undirected network with n nodes can\n    possible have (with or without loops).\n\n    Args:\n        n: The number of nodes in the network\n        directed: If True, return the maximum number of edges in a directed network.\n        multi_edges: If True, multiple edges between each node pair are allowed. In this case np.inf is returned.\n        self_loops: If True, include self-loops.\n\n    Examples:\n        Compute maximum number of edges in undirected network without self-loops and 100 nodes\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100)\n        4950\n\n        Directed networks without self-loops\n\n        &gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True)\n        9900\n\n        Directed networks with self-loops \n\n        &gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True, loops=True)\n        10000\n    \"\"\"\n\n    if multi_edges:\n        return _np.inf\n    elif self_loops and directed:\n        return int(n**2)\n    elif self_loops and not directed:\n        return int(n * (n + 1) / 2)\n    elif not self_loops and not directed:\n        return int(n * (n - 1) / 2)\n    else:  # not loops and directed:\n        return int(n * (n - 1))\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.molloy_reed","title":"<code>molloy_reed</code>","text":"<p>Generate Molloy-Reed graph.</p> <p>Generates a random undirected network without self-loops, with given degree sequence based on the Molloy-Reed algorithm. The condition proposed by Erd\u00f6s and Gallai (1967) is used to test whether the degree sequence is graphic, i.e. whether a network with the given degree sequence exists.</p> <p>Parameters:</p> Name Type Description Default <code>degrees</code> <p>List of integer node degrees. The number of nodes of the generated</p> required <code>relax</code> <code>bool</code> <p>If True, we conceptually allow self-loops and multi-edges, but do not</p> <code>False</code> <code>node_ids </code> <p>Optional list of node IDs that will be used for Indexmapping.</p> required <p>Examples:</p> <p>Generate random undirected network with given degree sequence</p> <p>import pathpyG as pp random_network = pp.algorithms.generative_models.molloy_reed([1,0]) print(random_network) ...</p> <p>Network generation fails for non-graphic degree sequence</p> <p>import pathpyG as pp random_network = pp.algorithms.generative_models.molloy_reed([1,0]) raises AttributeError</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def molloy_reed(degree_sequence: _np.array | Dict[int, float],\n                multiedge: bool = False,\n                relax: bool = False,\n                node_ids: Optional[list] = None) -&gt; Graph:\n    \"\"\"Generate Molloy-Reed graph.\n\n    Generates a random undirected network without self-loops, with given degree sequence based on\n    the Molloy-Reed algorithm. The condition proposed by Erd\u00f6s and Gallai (1967)\n    is used to test whether the degree sequence is graphic, i.e. whether a network\n    with the given degree sequence exists.\n\n    Args:\n        degrees: List of integer node degrees. The number of nodes of the generated\n        network corresponds to len(degrees).\n\n        relax: If True, we conceptually allow self-loops and multi-edges, but do not\n        add them to the network. This implies that the generated graph may not\n        have exactly sum(degrees)/2 edges, but it ensures that the algorithm\n        always finishes.\n\n        node_ids : Optional list of node IDs that will be used for Indexmapping.\n\n    Examples:\n\n    Generate random undirected network with given degree sequence\n\n    &gt;&gt;&gt; import pathpyG as pp\n    &gt;&gt;&gt; random_network = pp.algorithms.generative_models.molloy_reed([1,0])\n    &gt;&gt;&gt; print(random_network)\n    ...\n\n    Network generation fails for non-graphic degree sequence\n\n    &gt;&gt;&gt; import pathpyG as pp\n    &gt;&gt;&gt; random_network = pp.algorithms.generative_models.molloy_reed([1,0])\n    raises AttributeError\n\n    \"\"\"\n\n    # assume that we are given a graphical degree sequence\n    if not is_graphic_erdos_gallai(degree_sequence):\n        logger.error(\"given degree sequence is not graphic\")\n        raise ValueError('gicen degree sequence is not graphic')\n\n    # create empty network with n nodes\n    n = len(degree_sequence)\n    edges: list = []\n\n    if node_ids is None or len(node_ids) != n:\n        node_ids: list = []\n        for i in range(n):\n            node_ids.append(i)\n\n    # generate edge stubs based on degree sequence\n    stubs: list = []\n    for i in range(n):\n        for _ in range(int(degree_sequence[i])):\n            stubs.append(node_ids[i])\n\n    # connect randomly chosen pairs of stubs\n    while len(stubs) &gt; 0:\n        # find candidate node pair to connect\n        v, w = _np.random.choice(stubs, 2, replace=False)\n\n        # we encountered candidate edge that we cannot add\n        if v == w or (((v, w) in edges or (w, v) in edges) and not multiedge and not relax):\n            # break up random edge and add back stubs to avoid\n            # infinite loop\n            if len(edges) &gt; 0:\n                e = random.choice(edges)\n                edges.remove(e)\n                stubs.append(e[0])\n                stubs.append(e[1])\n        elif v != w:\n            edges.append((v, w))\n            stubs.remove(v)\n            stubs.remove(w)\n\n    return Graph.from_edge_list(edges).to_undirected()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.molloy_reed_randomize","title":"<code>molloy_reed_randomize</code>","text":"<p>Generates a randomized realization of a given undirected network based on the observed degree sequence.</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def molloy_reed_randomize(g: Graph) -&gt; Optional[Graph]:\n    \"\"\"Generates a randomized realization of a given undirected network based on the observed degree sequence.\n    \"\"\"\n    if g.is_directed():\n        logger.error(\"molloy_reed_randomize is only implemented for undirected graphs\")\n        raise NotImplementedError('molloy_reed_randomize is only implemented for undirected graphs')\n    # degrees are listed in order of node indices\n    degrees = degree(g.data.edge_index[1], num_nodes=g.n, dtype=torch.int).tolist()\n\n    return molloy_reed(degrees, node_ids=g.nodes).to_undirected()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.stochastic_block_model","title":"<code>stochastic_block_model</code>","text":"<p>Generate a random undirected graph based on the stochastic block model</p> <p>Parameters:</p> Name Type Description Default <code>M</code> <code>numpy.matrix</code> <p>n x n stochastic block matrix, where entry M[i,j] gives probability of edge to be generated between nodes in blocks i and j</p> required <code>z</code> <code>numpy.array</code> <p>n-dimensional block assignment vector, where z[i] gives block assignment of i-th node</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of node IDs to indices. If not given, a standard mapping based on integer IDs will be created</p> <code>None</code> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def stochastic_block_model(M: _np.matrix, z: _np.array, mapping: Optional[IndexMap] = None) -&gt; Graph:\n    \"\"\"Generate a random undirected graph based on the stochastic block model\n\n    Args:\n        M: n x n stochastic block matrix, where entry M[i,j] gives probability of edge to be generated\n            between nodes in blocks i and j\n        z: n-dimensional block assignment vector, where z[i] gives block assignment of i-th node\n        mapping: optional mapping of node IDs to indices. If not given, a standard\n            mapping based on integer IDs will be created\n    \"\"\"\n    # the number of nodes is implicitly given by the length of block assignment vector z\n    n = len(z)\n\n    # we can use pre-defined node names, if not given, we use contiguous numbers\n    if mapping is None:\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    edges = []\n\n    # randomly generate links with probabilities given by entries of the stochastic block matrix M\n    for u in range(n):\n        for v in range(u):\n            if _np.random.random() &lt;= M[z[u], z[v]]:\n                edges.append((mapping.to_id(u), mapping.to_id(v)))\n                edges.append((mapping.to_id(v), mapping.to_id(u)))\n\n    g = Graph.from_edge_list(edges, mapping=mapping).to_undirected()\n    return g\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.watts_strogatz","title":"<code>watts_strogatz</code>","text":"<p>Generate a Watts-Strogatz small-world graph.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of nodes in the graph.</p> required <code>s</code> <code>int</code> <p>The number of edges to attach from a new node to existing nodes.</p> required <code>p</code> <code>float</code> <p>The probability of rewiring each edge.</p> <code>0.0</code> <code>undirected</code> <code>bool</code> <p>If True, the graph will be undirected.</p> <code>True</code> <code>allow_duplicate_edges</code> <code>bool</code> <p>If True, allow duplicate edges in the graph. This is faster but may result in fewer edges than requested in the undirected case or duplicates in the directed case.</p> <code>True</code> <code>allow_self_loops</code> <code>bool</code> <p>If True, allow self-loops in the graph. This is faster but may result in fewer edges than requested in the undirected case.</p> <code>True</code> <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>A mapping from the node indices to node names.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>A Watts-Strogatz small-world graph.</p> <p>Examples:</p> <pre><code>g = Watts_Strogatz(100, 4, 0.1, mapping=pp.IndexMap([f\"n_{i}\" for i in range(100)])\n</code></pre> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def watts_strogatz(\n    n: int,\n    s: int,\n    p: float = 0.0,\n    undirected: bool = True,\n    allow_duplicate_edges: bool = True,\n    allow_self_loops: bool = True,\n    mapping: IndexMap | None = None,\n) -&gt; Graph:\n    \"\"\"Generate a Watts-Strogatz small-world graph.\n\n    Args:\n        n: The number of nodes in the graph.\n        s: The number of edges to attach from a new node to existing nodes.\n        p: The probability of rewiring each edge.\n        undirected: If True, the graph will be undirected.\n        allow_duplicate_edges: If True, allow duplicate edges in the graph.\n            This is faster but may result in fewer edges than requested in the undirected case\n            or duplicates in the directed case.\n        allow_self_loops: If True, allow self-loops in the graph.\n            This is faster but may result in fewer edges than requested in the undirected case.\n        mapping: A mapping from the node indices to node names.\n\n    Returns:\n        Graph: A Watts-Strogatz small-world graph.\n\n    Examples:\n        ```py\n        g = Watts_Strogatz(100, 4, 0.1, mapping=pp.IndexMap([f\"n_{i}\" for i in range(100)])\n        ```\n    \"\"\"\n\n    nodes = torch.arange(n)\n\n    # construct a ring lattice (dimension 1)\n    edges = (\n        torch.stack([torch.stack((nodes, torch.roll(nodes, shifts=-i, dims=0))) for i in range(1, s + 1)], dim=0)\n        .permute(1, 0, 2)\n        .reshape(2, -1)\n    )\n\n    if not allow_duplicate_edges:\n        if n * (n - 1) &lt; edges.shape[1]:\n            logger.error(\"number of edges is greater than the number of possible edges in the graph. Set `allow_duplicate_edges=True` to allow this.\")\n            raise ValueError(\n                \"number of edges is greater than the number of possible edges in the graph. Set `allow_duplicate_edges=True` to allow this.\"\n            )\n        elif n * (n - 1) * 0.5 &lt; edges.shape[1] and p &gt; 0.3:\n            logger.info(\n                \"Avoding duplicate in graphs with high connectivity and high rewiring probability may be slow. Consider setting `allow_duplicate_edges=True`.\"\n            )\n\n    # Rewire each link with probability p\n    rand_vals = torch.rand(edges.shape[1])\n    rewire_mask = rand_vals &lt; p\n\n    # Generate random nodes excluding the current node for each edge that needs to be rewired, also avoid duplicate edges\n    edges[1, rewire_mask] = torch.randint(n, (rewire_mask.sum(),))\n\n    # In the undirected case, make sure the edges all point in the same direction\n    # to avoid duplicate edges pointing in opposite directions\n    if undirected:\n        edges = edges.sort(dim=0)[0]\n    final_edges = edges\n\n    if not allow_duplicate_edges:\n        # Remove duplicate edges\n        final_edges, counts = edges.unique(dim=1, return_counts=True)\n        if final_edges.shape[0] &lt; edges.shape[1]:\n            for i, edge in enumerate(final_edges[:, counts &gt; 1].T):\n                for _ in range(counts[counts &gt; 1][i] - 1):\n                    while True:\n                        new_edge = torch.tensor([edge[0], torch.randint(n, (1,))]).sort()[0].unsqueeze(1)\n                        # Check if the new edge is already in the final edges\n                        # and add it if not\n                        if (new_edge != final_edges).any(dim=0).all():\n                            final_edges = torch.cat((final_edges, new_edge), dim=1)\n                            break\n\n    if not allow_self_loops:\n        self_loop_edges = final_edges[:, final_edges[0] == final_edges[1]]\n        final_edges = final_edges[:, final_edges[0] != final_edges[1]]\n        for self_loop_edge in self_loop_edges.T:\n            while True:\n                new_edge = torch.tensor([self_loop_edge[0], torch.randint(n, (1,))]).sort()[0].unsqueeze(1)\n                # Check if the new edge is already in the final edges\n                # and add it if not\n                if (new_edge != final_edges).any(dim=0).all() and new_edge[0] != new_edge[1]:\n                    final_edges = torch.cat((final_edges, new_edge), dim=1)\n                    break\n\n    g = Graph.from_edge_index(final_edges, mapping=mapping)\n    if undirected:\n        g = g.to_undirected()\n    return g\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/","title":"order","text":"<p>Utility functions for lifting the order of a graph (line-graph transformation).</p>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.aggregate_edge_index","title":"<code>aggregate_edge_index</code>","text":"<p>Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object containing the (higher-order) edge index without duplicates and the node sequences.</p> <p>This method can be seen as a higher-order generalization of the <code>torch_geometric.utils.coalesce</code> method. It is used for example to generate the DeBruijn graph of a given order from the corresponding line graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of a (higher-order) graph where each source and destination node corresponds to a node which is an edge in the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of first order nodes that each node in the edge index corresponds to.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights corresponding to the edge index.</p> <code>None</code> <p>Returns:</p> Type Description <code>pathpyG.core.graph.Graph</code> <p>A graph object containing the aggregated edge index, the node sequences, the edge weights and the inverse index.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def aggregate_edge_index(\n    edge_index: torch.Tensor, node_sequence: torch.Tensor, edge_weight: torch.Tensor | None = None, aggr: str = \"sum\"\n) -&gt; Graph:\n    \"\"\"\n    Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object\n    containing the (higher-order) edge index without duplicates and the node sequences.\n\n    This method can be seen as a higher-order generalization of the `torch_geometric.utils.coalesce` method.\n    It is used for example to generate the DeBruijn graph of a given order from the corresponding line graph.\n\n    Args:\n        edge_index: The edge index of a (higher-order) graph where each source and destination node\n            corresponds to a node which is an edge in the (k-1)-th order graph.\n        node_sequence: The node sequences of first order nodes that each node in the edge index corresponds to.\n        edge_weight: The edge weights corresponding to the edge index.\n\n    Returns:\n        A graph object containing the aggregated edge index, the node sequences, the edge weights and the inverse index.\n    \"\"\"\n    if edge_weight is None:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n\n    unique_nodes, inverse_idx = torch.unique(node_sequence, dim=0, return_inverse=True)\n    # If first order, then the indices in the node sequence are the inverse idx we would need already\n    if node_sequence.size(1) == 1:\n        mapped_edge_index = node_sequence.squeeze()[edge_index]\n    else:\n        mapped_edge_index = inverse_idx[edge_index]\n    aggregated_edge_index, edge_weight = coalesce(\n        mapped_edge_index,\n        edge_attr=edge_weight,\n        num_nodes=unique_nodes.size(0),\n        reduce=aggr,\n    )\n    data = Data(\n        edge_index=aggregated_edge_index,\n        num_nodes=unique_nodes.size(0),\n        node_sequence=unique_nodes,\n        edge_weight=edge_weight,\n        inverse_idx=inverse_idx,\n    )\n    return Graph(data)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.aggregate_node_attributes","title":"<code>aggregate_node_attributes</code>","text":"<p>Aggregate the node attributes of each pair of nodes in the edge index</p> <p>This method aggregates the node attributes of each pair of nodes in the edge index using the aggregation method specified. The method returns an attribute for each edge. The aggregation methods are: - \"src\": Use the attribute of the source node for each edge. - \"dst\": Use the attribute of the destination node for each edge. - \"max\": Use the maximum of the attributes of the source and destination nodes for each edge. - \"mul\": Use the product of the attributes of the source and destination nodes for each edge. - \"add\": Use the sum of the attributes of the source and destination nodes for each edge.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of the graph.</p> required <code>node_attribute</code> <code>torch.Tensor</code> <p>The node attribute tensor.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".</p> <code>'src'</code> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>The aggregated node attributes for each edge.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def aggregate_node_attributes(\n    edge_index: torch.Tensor, node_attribute: torch.Tensor, aggr: str = \"src\"\n) -&gt; torch.Tensor:\n    \"\"\"\n    Aggregate the node attributes of each pair of nodes in the edge index\n\n    This method aggregates the node attributes of each pair of nodes in the edge index\n    using the aggregation method specified. The method returns an attribute for each edge.\n    The aggregation methods are:\n    - \"src\": Use the attribute of the source node for each edge.\n    - \"dst\": Use the attribute of the destination node for each edge.\n    - \"max\": Use the maximum of the attributes of the source and destination nodes for each edge.\n    - \"mul\": Use the product of the attributes of the source and destination nodes for each edge.\n    - \"add\": Use the sum of the attributes of the source and destination nodes for each edge.\n\n    Args:\n        edge_index: The edge index of the graph.\n        node_attribute: The node attribute tensor.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".\n\n    Returns:\n        The aggregated node attributes for each edge.\n    \"\"\"\n    if aggr == \"src\":\n        aggr_attributes = node_attribute[edge_index[0]]\n    elif aggr == \"dst\":\n        aggr_attributes = node_attribute[edge_index[1]]\n    elif aggr == \"max\":\n        aggr_attributes = torch.maximum(node_attribute[edge_index[0]], node_attribute[edge_index[1]])\n    elif aggr == \"mul\":\n        aggr_attributes = node_attribute[edge_index[0]] * node_attribute[edge_index[1]]\n    elif aggr == \"add\":\n        aggr_attributes = node_attribute[edge_index[0]] + node_attribute[edge_index[1]]\n    else:\n        raise ValueError(f\"Unknown aggregation method {aggr}\")\n    return aggr_attributes\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.lift_order_edge_index","title":"<code>lift_order_edge_index</code>","text":"<p>Line graph transformation.</p> <p>Do a line graph transformation on the edge index to lift the order of the graph by one. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>num_nodes</code> <code>int | None</code> <p>The number of nodes in the graph. If not given, it will be inferred from the edge index (maximum node index + 1).</p> <code>None</code> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>The edge index of the lifted (line) graph.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int | None = None) -&gt; torch.Tensor:\n    \"\"\"Line graph transformation.\n\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        num_nodes: The number of nodes in the graph. If not given,\n            it will be inferred from the edge index (maximum node index + 1).\n\n    Returns:\n        The edge index of the lifted (line) graph.\n    \"\"\"\n    if num_nodes is None:\n        num_nodes = int(edge_index.max()) + 1\n\n    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n    # Map outdegree to each destination node to create an edge for each combination\n    # of incoming and outgoing edges for each destination node\n    outdegree_per_dst = outdegree[edge_index[1]]\n    # Create sources of the new higher-order edges\n    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n    # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n    # of all previous nodes in the ordered sequence of nodes\n    ptrs = cumsum(outdegree, dim=0)[:-1]\n    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n    idx_correction = torch.arange(ho_edge_srcs.size(0), dtype=torch.long, device=edge_index.device)\n    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n    ho_edge_dsts += idx_correction\n    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.lift_order_edge_index_weighted","title":"<code>lift_order_edge_index_weighted</code>","text":"<p>Weighted line graph transformation.</p> <p>Do a line graph transformation on the edge index to lift the order of the graph by one. Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>edge_weight</code> <code>torch.Tensor</code> <p>The edge weights of the (k-1)th order graph.</p> required <code>num_nodes</code> <code>int | None</code> <p>The number of nodes in the graph.</p> <code>None</code> <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".</p> <code>'src'</code> <p>Returns:</p> Type Description <code>tuple[torch.Tensor, torch.Tensor]</code> <p>A tuple containing the edge index of the lifted (line) graph and the aggregated edge weights.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def lift_order_edge_index_weighted(\n    edge_index: torch.Tensor, edge_weight: torch.Tensor, num_nodes: int | None = None, aggr: str = \"src\"\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Weighted line graph transformation.\n\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        edge_weight: The edge weights of the (k-1)th order graph.\n        num_nodes: The number of nodes in the graph.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".\n\n    Returns:\n        A tuple containing the edge index of the lifted (line) graph and the aggregated edge weights.\n    \"\"\"\n    if num_nodes is None:\n        num_nodes = int(edge_index.max()) + 1\n\n    ho_index = lift_order_edge_index(edge_index, num_nodes)\n    ho_edge_weight = aggregate_node_attributes(ho_index, edge_weight, aggr)\n\n    return ho_index, ho_edge_weight\n</code></pre>"},{"location":"reference/pathpyG/algorithms/rolling_time_window/","title":"window","text":"<p>Iterator interface for rolling time window analysis in temporal graphs.</p>"},{"location":"reference/pathpyG/algorithms/rolling_time_window/#pathpyG.algorithms.rolling_time_window.RollingTimeWindow","title":"<code>RollingTimeWindow</code>","text":"<p>An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.</p> Source code in <code>src/pathpyG/algorithms/rolling_time_window.py</code> <pre><code>class RollingTimeWindow:\n    \"\"\"An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.\"\"\"\n\n    def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n        \"\"\"Initialize a RollingTimeWindow instance that can be used to\n        iterate through a sequence of time-slice networks for a given\n        TemporalNetwork instance.\n\n        Args:\n            temporal_graph: TemporalGraphinstance that will be used to generate the\n                sequence of time-slice networks.\n            window_size: The width of the rolling time window used to create time-slice networks.\n            step_size: The step size in time units by which the starting\n                time of the rolling window will be incremented on each iteration.\n            return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n            weighted: Whether or not to return a weighted graph\n\n        Example:\n            ```py\n            tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n            t = pp.TemporalGraph.from_edge_list(tedges)\n            r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n            for g, w in r:\n                print('Time window ', w)\n                print(g)\n                print(g.data.edge_index)\n                print('---')\n            ```\n        \"\"\"\n        self.g = temporal_graph\n        self.window_size = window_size\n        self.step_size = step_size\n        self.current_time = self.g.start_time\n        self.return_window = return_window\n        self.weighted = weighted\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.current_time &lt;= self.g.end_time:\n            time_window = (self.current_time, self.current_time + self.window_size)\n            s = self.g.to_static_graph(weighted=self.weighted, time_window=time_window)\n            self.current_time += self.step_size\n            if self.return_window:\n                return s, time_window\n            else:\n                return s\n        else:\n            raise StopIteration()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/rolling_time_window/#pathpyG.algorithms.rolling_time_window.RollingTimeWindow.__init__","title":"<code>__init__</code>","text":"<p>Initialize a RollingTimeWindow instance that can be used to iterate through a sequence of time-slice networks for a given TemporalNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>temporal_graph</code> <p>TemporalGraphinstance that will be used to generate the sequence of time-slice networks.</p> required <code>window_size</code> <p>The width of the rolling time window used to create time-slice networks.</p> required <code>step_size</code> <p>The step size in time units by which the starting time of the rolling window will be incremented on each iteration.</p> <code>1</code> <code>return_window</code> <p>Whether or not the iterator shall return the current time window as a second return value. Default is False.</p> <code>False</code> <code>weighted</code> <p>Whether or not to return a weighted graph</p> <code>True</code> Example <pre><code>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n  ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n  ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n  ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n  ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nr = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</code></pre> Source code in <code>src/pathpyG/algorithms/rolling_time_window.py</code> <pre><code>def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n    \"\"\"Initialize a RollingTimeWindow instance that can be used to\n    iterate through a sequence of time-slice networks for a given\n    TemporalNetwork instance.\n\n    Args:\n        temporal_graph: TemporalGraphinstance that will be used to generate the\n            sequence of time-slice networks.\n        window_size: The width of the rolling time window used to create time-slice networks.\n        step_size: The step size in time units by which the starting\n            time of the rolling window will be incremented on each iteration.\n        return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n        weighted: Whether or not to return a weighted graph\n\n    Example:\n        ```py\n        tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n          ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n          ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n          ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n          ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n        t = pp.TemporalGraph.from_edge_list(tedges)\n        r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n        for g, w in r:\n            print('Time window ', w)\n            print(g)\n            print(g.data.edge_index)\n            print('---')\n        ```\n    \"\"\"\n    self.g = temporal_graph\n    self.window_size = window_size\n    self.step_size = step_size\n    self.current_time = self.g.start_time\n    self.return_window = return_window\n    self.weighted = weighted\n</code></pre>"},{"location":"reference/pathpyG/algorithms/shortest_paths/","title":"paths","text":"<p>Algorithms to calculate shortest paths in static networks</p> <p>The functions  in this module allow to compute shortest paths in static networks.</p>"},{"location":"reference/pathpyG/algorithms/shortest_paths/#pathpyG.algorithms.shortest_paths.avg_path_length","title":"<code>avg_path_length</code>","text":"<p>Compute the average path length of the graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>Input graph.</p> required <p>Returns:     float: The average path length of the graph.</p> Source code in <code>src/pathpyG/algorithms/shortest_paths.py</code> <pre><code>def avg_path_length(graph: Graph) -&gt; float:\n    \"\"\"Compute the average path length of the graph.\n\n    Args:\n        graph (Graph): Input graph.\n    Returns:\n        float: The average path length of the graph.\n    \"\"\"\n    m = graph.sparse_adj_matrix()\n    dist = dijkstra(m, directed=graph.is_directed(), return_predecessors=False, unweighted=True)\n    return _np.sum(dist) / (graph.n * (graph.n - 1))\n</code></pre>"},{"location":"reference/pathpyG/algorithms/shortest_paths/#pathpyG.algorithms.shortest_paths.diameter","title":"<code>diameter</code>","text":"<p>Compute the diameter of the graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>Input graph.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The diameter of the graph.</p> Source code in <code>src/pathpyG/algorithms/shortest_paths.py</code> <pre><code>def diameter(graph: Graph) -&gt; float:\n    \"\"\"Compute the diameter of the graph.\n\n    Args:\n        graph (Graph): Input graph.\n\n    Returns:\n        float: The diameter of the graph.\n    \"\"\"\n    m = graph.sparse_adj_matrix()\n    dist = dijkstra(m, directed=graph.is_directed(), return_predecessors=False, unweighted=True)\n    return _np.max(dist)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/shortest_paths/#pathpyG.algorithms.shortest_paths.shortest_paths_dijkstra","title":"<code>shortest_paths_dijkstra</code>","text":"<p>Compute shortest paths using Dijkstra's algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>Input graph.</p> required <p>Returns:</p> Type Description <code>tuple[numpy.ndarray, numpy.ndarray]</code> <p>tuple[np.ndarray, np.ndarray]: A tuple containing the distance matrix and the predecessor matrix.</p> Source code in <code>src/pathpyG/algorithms/shortest_paths.py</code> <pre><code>def shortest_paths_dijkstra(graph: Graph) -&gt; tuple[_np.ndarray, _np.ndarray]:\n    \"\"\"Compute shortest paths using Dijkstra's algorithm.\n\n    Args:\n        graph (Graph): Input graph.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple containing the distance matrix and the predecessor matrix.\n    \"\"\"\n    m = graph.sparse_adj_matrix()\n    dist, pred = dijkstra(m, directed=graph.is_directed(), return_predecessors=True, unweighted=True)\n    return dist, pred\n</code></pre>"},{"location":"reference/pathpyG/algorithms/temporal/","title":"temporal","text":"<p>Algorithms for the analysis of time-respecting paths in temporal graphs.</p>"},{"location":"reference/pathpyG/algorithms/temporal/#pathpyG.algorithms.temporal.lift_order_temporal","title":"<code>lift_order_temporal</code>","text":"<p>Lift a temporal graph to a second-order temporal event graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to lift.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events to consider them connected.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>ho_index</code> <p>Edge index of the second-order temporal event graph.</p> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def lift_order_temporal(g: TemporalGraph, delta: int = 1):\n    \"\"\"Lift a temporal graph to a second-order temporal event graph.\n\n    Args:\n        g: Temporal graph to lift.\n        delta: Maximum time difference between events to consider them connected.\n\n    Returns:\n        ho_index: Edge index of the second-order temporal event graph.\n    \"\"\"\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.time\n\n    delta = torch.tensor(delta, device=edge_index.device)\n    indices = torch.arange(0, edge_index.size(1), device=edge_index.device)\n\n    unique_t = torch.unique(timestamps, sorted=True)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for t in tqdm(unique_t):\n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = timestamps == t\n        src_edge_idx = indices[src_time_mask]\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t + delta)\n        dst_edge_idx = indices[dst_time_mask]\n\n        if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n            # compute second-order edges between src and dst idx\n            # for all edges where dst in src_edges (edge_index[1, x[:, 0]]) matches src in dst_edges (edge_index[0, x[:, 1]])\n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx)\n            ho_edge_index = x[edge_index[1, x[:, 0]] == edge_index[0, x[:, 1]]]\n            second_order.append(ho_edge_index)\n\n    ho_index = torch.cat(second_order, dim=0).t().contiguous()\n    return ho_index\n</code></pre>"},{"location":"reference/pathpyG/algorithms/temporal/#pathpyG.algorithms.temporal.temporal_shortest_paths","title":"<code>temporal_shortest_paths</code>","text":"<p>Compute shortest time-respecting paths in a temporal graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to compute shortest paths on.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events in a path.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Tuple of two numpy arrays:</p> <code>numpy.ndarray</code> <ul> <li>dist: Shortest time-respecting path distances between all first-order nodes.</li> </ul> <code>typing.Tuple[numpy.ndarray, numpy.ndarray]</code> <ul> <li>pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.</li> </ul> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def temporal_shortest_paths(g: TemporalGraph, delta: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute shortest time-respecting paths in a temporal graph.\n\n    Args:\n        g: Temporal graph to compute shortest paths on.\n        delta: Maximum time difference between events in a path.\n\n    Returns:\n        Tuple of two numpy arrays:\n        - dist: Shortest time-respecting path distances between all first-order nodes.\n        - pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n    dst_edges_dst = g.data.edge_index[1] + g.m + g.n\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.m + 2 * g.n)\n    m = event_graph.sparse_adj_matrix()\n\n    # print(f\"Created temporal event DAG with {event_graph.n} nodes and {event_graph.m} edges\")\n\n    # run disjktra for all source nodes\n    dist, pred = dijkstra(\n        m, directed=True, indices=np.arange(g.m, g.m + g.n), return_predecessors=True, unweighted=True\n    )\n\n    # limit to first-order destinations and correct distances\n    dist_fo = dist[:, g.m + g.n :] - 1\n    np.fill_diagonal(dist_fo, 0)\n\n    # limit to first-order destinations and correct predecessors\n    pred_fo = pred[:, g.n + g.m :]\n    pred_fo[pred_fo == -9999] = -1\n    idx_map = np.concatenate([to_numpy(g.data.edge_index[0].cpu()), [-1]])\n    pred_fo = idx_map[pred_fo]\n    np.fill_diagonal(pred_fo, np.arange(g.n))\n\n    return dist_fo, pred_fo\n</code></pre>"},{"location":"reference/pathpyG/algorithms/weisfeiler_leman/","title":"leman","text":""},{"location":"reference/pathpyG/algorithms/weisfeiler_leman/#pathpyG.algorithms.weisfeiler_leman.WeisfeilerLeman_test","title":"<code>WeisfeilerLeman_test</code>","text":"<p>Run Weisfeiler-Leman isomorphism test on two graphs.</p> <p>The algorithm heuristically checks whether two graphs are isomorphic. If it returns False, we can be sure that the graphs are non-isomoprhic. If the test returns True we did not find conclusive evidence that they are not isomorphic, i.e. the graphs may or may not be isomophic.</p> <p>The two graphs must have IndexMap mappings that assign different node IDs to the nodes in both graphs. The function will raise an error if the node labels of both graphs overlap.</p> <p>The function returns a tuple (bool, list, list), where the first entry is the result of the test and the two lists represent the fingerprints of the two graphs. If the test yields true the fingerprints are identical. If the test fails, the fingerprints do not correspond.</p> <p>Parameters:</p> Name Type Description Default <code>g1</code> <code>pathpyG.core.graph.Graph</code> <p>pp.Graph</p> required <code>g2</code> <code>pathpyG.core.graph.Graph</code> <p>pp.Graph</p> required Source code in <code>src/pathpyG/algorithms/weisfeiler_leman.py</code> <pre><code>def WeisfeilerLeman_test(\n    g1: Graph, g2: Graph, features_g1: dict = None, features_g2: dict = None\n) -&gt; Tuple[bool, List[str], List[str]]:\n    \"\"\"Run Weisfeiler-Leman isomorphism test on two graphs.\n\n    The algorithm heuristically checks whether two graphs are isomorphic. If it returns False,\n    we can be sure that the graphs are non-isomoprhic. If the test returns True we did not find\n    conclusive evidence that they are not isomorphic, i.e. the graphs may or may not be isomophic.\n\n    The two graphs must have IndexMap mappings that assign different node IDs to the nodes\n    in both graphs. The function will raise an error if the node labels of both graphs overlap.\n\n    The function returns a tuple (bool, list, list), where the first entry is the result of the test\n    and the two lists represent the fingerprints of the two graphs. If the test yields true the fingerprints\n    are identical. If the test fails, the fingerprints do not correspond.\n\n    Args:\n        g1: pp.Graph\n        g2: pp.Graph\n    \"\"\"\n    if g1.mapping is None or g2.mapping is None:\n        raise Exception(\"Graphs must contain IndexMap that assigns node IDs\")\n    if len(set(g1.mapping.node_ids).intersection(g2.mapping.node_ids)) &gt; 0:\n        raise Exception(\"node identifiers of graphs must not overlap\")\n    g_combined = g1 + g2\n    # initialize labels of all nodes to zero\n    if features_g1 is None or features_g2 is None:\n        fingerprint: Dict[str | int, str] = {v: \"0\" for v in g_combined.nodes}\n    else:\n        fingerprint = features_g1.copy()\n        fingerprint.update(features_g2)\n    labels = {}\n    label_count = 1\n    stop = False\n    while not stop:\n        new_fingerprint = {}\n        for node in g_combined.nodes:\n            # create new label based on own label and sorted labels of all neighbors\n            n_label = [fingerprint[x] for x in g_combined.successors(node)]\n            n_label.sort()\n            label = str(fingerprint[node]) + str(n_label)\n            # previously unknown label\n            if label not in labels:\n                # create a new label based on next consecutive number\n                labels[label] = label_count\n                label_count += 1\n            new_fingerprint[node] = labels[label]\n        if len(set(fingerprint.values())) == len(set(new_fingerprint.values())):\n            # we processed all nodes in both graphs without encountering a new label, so we stop\n            stop = True\n        else:\n            # update fingerprint and continue\n            fingerprint = new_fingerprint.copy()\n\n    # Reduce fingerprints to nodes of g1 and g2 respectively\n    fingerprint_1 = [fingerprint[v] for v in g1.nodes]\n    fingerprint_1_sorted = fingerprint_1.copy()\n    fingerprint_1_sorted.sort()\n    fingerprint_2 = [fingerprint[v] for v in g2.nodes]\n    fingerprint_2_sorted = fingerprint_2.copy()\n    fingerprint_2_sorted.sort()\n\n    # perform WL-test\n    if fingerprint_1_sorted == fingerprint_2_sorted:\n        return True, fingerprint_1, fingerprint_2\n    return False, fingerprint_1, fingerprint_2\n</code></pre>"},{"location":"reference/pathpyG/core/","title":"core","text":"<p>Core classes for (temporal) graphs, paths, and higher-order De Bruijn graphs.</p> <p>The classes in the <code>core</code> module can be used to implement integrated pipelines to preprocess time-stamped network data, do inference and model selection of higher-order De Bruijn graph models and address temporal graph learning tasks based on time-aware graph neural networks.</p> Example <pre><code>import pathpyG as pp\n\n# Generate toy example temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)],\n    device='cuda'\n)\n\n# Create Multi-Order model that models time-respecting paths\nm = pp.MultiOrderModel.from_temporal_graph(g, delta=1, max_order=3)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\n</code></pre>"},{"location":"reference/pathpyG/core/graph/","title":"Graph","text":""},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if \"num_nodes\" not in data and \"edge_index\" in data:            \n            data.num_nodes = data.edge_index.max().item() + 1\n            logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if (\n            data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n            or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n        ):\n            logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n            raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n        self.data = data\n\n        # sort EdgeIndex and validate\n        data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        data.edge_index.validate()\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n        # create node_sequence mapping for higher-order graphs\n        if \"node_sequence\" not in self.data:\n            self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n        Examples:\n            You can create a graph from an edge index tensor as follows:\n\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            &gt;&gt;&gt; print(g)\n            Directed graph with 3 nodes and 3 edges ...\n\n            You can also include a mapping of node IDs:\n\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n            &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n            &gt;&gt;&gt; print(g.mapping)\n            a -&gt; 0\n            b -&gt; 1\n            c -&gt; 2\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else:\n            if mapping is not None and mapping.num_ids() != num_nodes:\n                logger.error(\"Number of node IDs in mapping must match num_nodes\")\n                raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(d, mapping=mapping)\n\n    @staticmethod\n    def from_edge_list(\n        edge_list: Iterable[Tuple[str, str]],\n        is_undirected: bool = False,\n        mapping: Optional[IndexMap] = None,\n        device: Optional[torch.device] = None,\n    ) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            device: optional torch device where tensors shall be stored\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n            &gt;&gt;&gt; print(list(g.edges))\n            [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        \"\"\"\n\n        # handle empty graph\n        if len(edge_list) == 0:\n            return Graph(\n                Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n                mapping=IndexMap(),\n            )\n\n        if mapping is None:\n            edge_array = np.array(edge_list)\n            node_ids = np.unique(edge_array)\n            if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n                node_ids = np.sort(node_ids.astype(int)).astype(str)\n            mapping = IndexMap(node_ids)\n\n        num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex(\n            mapping.to_idxs(edge_list, device=device).T.contiguous(),\n            sparse_size=(num_nodes, num_nodes),\n            is_undirected=is_undirected,\n        )\n        return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"Return an undirected version of this directed graph.\n\n        This method creates a new undirected Graph from the current graph instance by\n        adding all directed edges in opposite direction.\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            &gt;&gt;&gt; g_u = g.to_undirected()\n            &gt;&gt;&gt; print(g_u)\n            Undirected graph with 3 nodes and 6 (directed) edges\n        \"\"\"\n        # create undirected edge index by coalescing the directed edges and keep\n        # track of the original edge index for the edge attributes\n        attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n        edge_index, attr_idx = to_undirected(\n            self.data.edge_index,\n            edge_attr=attr_idx,\n            num_nodes=self.data.num_nodes,\n            reduce=\"min\",\n        )\n\n        data = Data(\n            edge_index=EdgeIndex(\n                data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n            ),\n            num_nodes=self.data.num_nodes,\n        )\n        # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n        # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n        # make sure to copy all node and (undirected) edge attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        for edge_attr in self.edge_attrs():\n            if edge_attr != \"edge_index\":\n                data[edge_attr] = self.data[edge_attr][attr_idx]\n\n        return Graph(data, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n        If the graph contains multiple edges between the same nodes, this method will coalesce\n        them into a single edge with an additional weight attribute called `edge_weight` that\n        contains the number of coalesced edges. The method returns a new graph instance with\n        the coalesced edges.\n\n        Returns:\n            Graph: Graph with coalesced edges\n        \"\"\"\n        i, w = torch_geometric.utils.coalesce(\n            self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n\n    def to(self, device: torch.device) -&gt; Graph:\n        \"\"\"Move all tensors to the given device.\n\n        Args:\n            device: torch device to which all tensors shall be moved\n\n        Returns:\n            Graph: self\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.node_sequence = self.data.node_sequence.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n\n        self.row = self.row.to(device)\n        self.row_ptr = self.row_ptr.to(device)\n        self.col = self.col.to(device)\n        self.col_ptr = self.col_ptr.to(device)\n\n        return self\n\n    def node_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_sequence` attribute.\n\n        Returns:\n            list: list of node attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n\n        Returns:\n            list: list of edge attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; list:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a list object that contains all nodes.\n        If an IndexMap is used, nodes are returned as string IDs.\n        If no IndexMap is used, nodes are returned as integer indices.\n\n        Returns:\n            list: list of all nodes using IDs or indices (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(np.arange(self.n)).tolist()\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    @property\n    def edges(self) -&gt; list:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a list object that contains all edges, where each\n        edge is a tuple of two elements. If an IndexMap is used to map node\n        indices to string IDs, edges are returned as tuples of string IDs.\n        If no mapping is used, edges are returned as tuples of integer indices.\n\n        Returns:\n            list: list object yielding all edges using IDs or indices (if no mapping is used)\n        \"\"\"\n        edge_list = self.mapping.to_ids(self.data.edge_index.t()).tolist()\n        if self.order &gt; 1:\n            return [tuple(map(tuple, x)) for x in edge_list]\n        return list(map(tuple, edge_list))\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n        \"\"\"\n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def successors(self, node: Union[int, str] | tuple) -&gt; list:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n\n        Returns:\n            list: list with all successors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n\n        node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n\n        Returns:\n            list: list with all predecessors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID\n\n        Returns:\n            bool: True if edge exists, False otherwise\n        \"\"\"\n        row = self.mapping.to_idx(v)\n        row_start = self.row_ptr[row]\n        row_end = self.row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in self.col[row_start:row_end]\n\n    def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted in-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing in-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted out-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing out-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                     torch.tensor]:\n        \"\"\"\n        Return (weighted) degrees of nodes.\n\n        Args:\n            mode: `in` or `out` to calculate in- or out-degree for\n                directed networks.\n            edge_attr: Optional numerical edge attribute that will \n                be used to compute weighted degrees\n            return_tensor: if True the function returns a degree tensor, if False (default)\n                a dictionary will be returned that can be indexed by nodes\n        Returns:\n            dict: dictionary containing node degrees\n        \"\"\"\n        if mode == \"in\":\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        else:\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        if return_tensor:\n            return d\n        else:\n            return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n\n    def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n        \"\"\"\n        Compute transition probabilities based on (weighted) outdegrees.\n\n        Args:\n            edge_attr: Optional name of numerical edge attribute that will\n                        will be used to calculate weighted out-degrees for the\n                        visitation probabilities.\n\n        Returns:\n            tensor: Transition probabilities.\n        \"\"\"\n        weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n        source_ids = self.data.edge_index[0]        \n        edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n        if edge_attr:\n            edge_weight = getattr(self.data, edge_attr, None)\n        return edge_weight / weighted_outdegree[source_ids]\n\n    def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization: normalization parameter passed to pyG `get_laplacian`\n                function\n            edge_attr: optinal name of numerical edge attribute that shall\n                be passed to pyG `get_laplacian` function as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(), normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(),\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key.startswith(\"node_\"):\n                if val.size(0) != self.n:\n                    raise ValueError(\"Attribute must have same length as number of nodes\")\n                self.data[key] = val\n            elif key.startswith(\"edge_\"):\n                if val.size(0) != self.m:\n                    raise ValueError(\"Attribute must have same length as number of edges\")\n                self.data[key] = val\n            else:\n                self.data[key] = val\n        elif key[0].startswith(\"node_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif key[0].startswith(\"edge_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n\n    @property\n    def n(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns:\n            int: number of nodes in the graph\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def m(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the number of \n        undirected edges (accounting for self-loops) is returned, i.e. in an undirected\n        graph the directed edges (a,b) and (b,a) will be counted only once.\n\n        Returns:\n            int: number of edges in the graph\n        \"\"\"\n        if self.is_directed():\n            return self.data.num_edges  # type: ignore\n        else:\n            num_self_loops = (self.data.edge_index[0] == self.data.edge_index[1]).sum().item()\n            num_edges_wo_self_loops = self.data.edge_index.size(1) - int(num_self_loops)\n            return int(num_edges_wo_self_loops/2 + num_self_loops) # type: ignore\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"\n        Return order of graph.\n\n        Returns:\n            int: order of the (De Bruijn) graph\n        \"\"\"\n        return self.data.node_sequence.size(1)  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\n\n        Returns:\n            bool: True if graph is directed, False otherwise\n        \"\"\"\n        return not self.data.edge_index.is_undirected\n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\n\n        Returns:\n            bool: True if graph is undirected, False otherwise\n        \"\"\"\n        return self.data.edge_index.is_undirected\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\n\n        Returns:\n            bool: True if graph contains self-loops, False otherwise\n        \"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Args:\n            other: Other graph to be combined with this graph\n            reduce: Reduction method for node attributes of nodes that are present in both graphs.\n                Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n        Examples:\n            Adding two graphs without node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 6 edges\n\n            Adding two graphs with identical node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 4 edges\n\n            Adding two graphs with non-overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 6 nodes and 4 edges\n\n            Adding two graphs with partly overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 5 nodes and 4 edges\n        \"\"\"\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n        mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n        d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n        d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n        d = d1.concat(d2)\n        d.num_nodes = mapping.num_ids()\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n        # For higher-order graphs, we need to update the inverse_idx attribute\n        if \"inverse_idx\" in d:\n            d.inverse_idx = mapping.to_idxs(\n                np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n                device=d.inverse_idx.device,\n            )\n\n        # If both graphs contain node attributes, reduce them using the specified method\n        for k in d1.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                if isinstance(d[k], torch.Tensor):\n                    d[k] = torch_geometric.utils.scatter(\n                        d[k],\n                        mapping.to_idxs(\n                            np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                            device=d[k].device,\n                        ),\n                        dim_size=d.num_nodes,\n                        reduce=reduce,\n                    )\n                else:\n                    raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a list object that contains all edges, where each edge is a tuple of two elements. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of string IDs. If no mapping is used, edges are returned as tuples of integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list object yielding all edges using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.in_degrees","title":"<code>in_degrees</code>  <code>property</code>","text":"<p>Return unweighted in-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing in-degrees of nodes</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.m","title":"<code>m</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the number of  undirected edges (accounting for self-loops) is returned, i.e. in an undirected graph the directed edges (a,b) and (b,a) will be counted only once.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of edges in the graph</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.n","title":"<code>n</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of nodes in the graph</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a list object that contains all nodes. If an IndexMap is used, nodes are returned as string IDs. If no IndexMap is used, nodes are returned as integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list of all nodes using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order of graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>order of the (De Bruijn) graph</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.out_degrees","title":"<code>out_degrees</code>  <code>property</code>","text":"<p>Return unweighted out-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing out-degrees of nodes</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>pathpyG.core.graph.Graph</code> <p>Other graph to be combined with this graph</p> required <code>reduce</code> <code>str</code> <p>Reduction method for node attributes of nodes that are present in both graphs. Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".</p> <code>'sum'</code> <p>Examples:</p> <p>Adding two graphs without node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 6 edges\n</code></pre> <p>Adding two graphs with identical node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 4 edges\n</code></pre> <p>Adding two graphs with non-overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 6 nodes and 4 edges\n</code></pre> <p>Adding two graphs with partly overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 5 nodes and 4 edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Args:\n        other: Other graph to be combined with this graph\n        reduce: Reduction method for node attributes of nodes that are present in both graphs.\n            Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n    Examples:\n        Adding two graphs without node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 6 edges\n\n        Adding two graphs with identical node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 4 edges\n\n        Adding two graphs with non-overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 6 nodes and 4 edges\n\n        Adding two graphs with partly overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 5 nodes and 4 edges\n    \"\"\"\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n    mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n    d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n    d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n    d = d1.concat(d2)\n    d.num_nodes = mapping.num_ids()\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n    # For higher-order graphs, we need to update the inverse_idx attribute\n    if \"inverse_idx\" in d:\n        d.inverse_idx = mapping.to_idxs(\n            np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n            device=d.inverse_idx.device,\n        )\n\n    # If both graphs contain node attributes, reduce them using the specified method\n    for k in d1.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            if isinstance(d[k], torch.Tensor):\n                d[k] = torch_geometric.utils.scatter(\n                    d[k],\n                    mapping.to_idxs(\n                        np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                        device=d[k].device,\n                    ),\n                    dim_size=d.num_nodes,\n                    reduce=reduce,\n                )\n            else:\n                raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if \"num_nodes\" not in data and \"edge_index\" in data:            \n        data.num_nodes = data.edge_index.max().item() + 1\n        logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if (\n        data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n        or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n    ):\n        logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n        raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n    self.data = data\n\n    # sort EdgeIndex and validate\n    data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    data.edge_index.validate()\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    # create node_sequence mapping for higher-order graphs\n    if \"node_sequence\" not in self.data:\n        self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key.startswith(\"node_\"):\n            if val.size(0) != self.n:\n                raise ValueError(\"Attribute must have same length as number of nodes\")\n            self.data[key] = val\n        elif key.startswith(\"edge_\"):\n            if val.size(0) != self.m:\n                raise ValueError(\"Attribute must have same length as number of edges\")\n            self.data[key] = val\n        else:\n            self.data[key] = val\n    elif key[0].startswith(\"node_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif key[0].startswith(\"edge_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return (weighted) degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate in- or out-degree for directed networks.</p> <code>'in'</code> <code>edge_attr</code> <code>typing.Any</code> <p>Optional numerical edge attribute that will  be used to compute weighted degrees</p> <code>None</code> <code>return_tensor</code> <code>bool</code> <p>if True the function returns a degree tensor, if False (default) a dictionary will be returned that can be indexed by nodes</p> <code>False</code> <p>Returns:     dict: dictionary containing node degrees</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                 torch.tensor]:\n    \"\"\"\n    Return (weighted) degrees of nodes.\n\n    Args:\n        mode: `in` or `out` to calculate in- or out-degree for\n            directed networks.\n        edge_attr: Optional numerical edge attribute that will \n            be used to compute weighted degrees\n        return_tensor: if True the function returns a degree tensor, if False (default)\n            a dictionary will be returned that can be indexed by nodes\n    Returns:\n        dict: dictionary containing node degrees\n    \"\"\"\n    if mode == \"in\":\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    else:\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    if return_tensor:\n        return d\n    else:\n        return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of edge attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def edge_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n\n    Returns:\n        list: list of edge attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <code>int</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.</p> <code>None</code> <p>Examples:</p> <p>You can create a graph from an edge index tensor as follows:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n&gt;&gt;&gt; print(g)\nDirected graph with 3 nodes and 3 edges ...\n</code></pre> <p>You can also include a mapping of node IDs:</p> <pre><code>&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n&gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n&gt;&gt;&gt; print(g.mapping)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n    Examples:\n        You can create a graph from an edge index tensor as follows:\n\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        &gt;&gt;&gt; print(g)\n        Directed graph with 3 nodes and 3 edges ...\n\n        You can also include a mapping of node IDs:\n\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n        &gt;&gt;&gt; print(g.mapping)\n        a -&gt; 0\n        b -&gt; 1\n        c -&gt; 2\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else:\n        if mapping is not None and mapping.num_ids() != num_nodes:\n            logger.error(\"Number of node IDs in mapping must match num_nodes\")\n            raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>device</code> <code>typing.Optional[torch.device]</code> <p>optional torch device where tensors shall be stored</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n&gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n&gt;&gt;&gt; print(list(g.edges))\n[('a', 'b'), ('a', 'c'), ('b', 'c')]\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(\n    edge_list: Iterable[Tuple[str, str]],\n    is_undirected: bool = False,\n    mapping: Optional[IndexMap] = None,\n    device: Optional[torch.device] = None,\n) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        device: optional torch device where tensors shall be stored\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n        &gt;&gt;&gt; print(list(g.edges))\n        [('a', 'b'), ('a', 'c'), ('b', 'c')]\n    \"\"\"\n\n    # handle empty graph\n    if len(edge_list) == 0:\n        return Graph(\n            Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n            mapping=IndexMap(),\n        )\n\n    if mapping is None:\n        edge_array = np.array(edge_list)\n        node_ids = np.unique(edge_array)\n        if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n            node_ids = np.sort(node_ids.astype(int)).astype(str)\n        mapping = IndexMap(node_ids)\n\n    num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex(\n        mapping.to_idxs(edge_list, device=device).T.contiguous(),\n        sparse_size=(num_nodes, num_nodes),\n        is_undirected=is_undirected,\n    )\n    return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all predecessor nodes of the node indexed by <code>col_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n    \"\"\"\n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all successor nodes of the node indexed by <code>row_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph contains self-loops, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\n\n    Returns:\n        bool: True if graph contains self-loops, False otherwise\n    \"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is directed, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\n\n    Returns:\n        bool: True if graph is directed, False otherwise\n    \"\"\"\n    return not self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if edge exists, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID\n\n    Returns:\n        bool: True if edge exists, False otherwise\n    \"\"\"\n    row = self.mapping.to_idx(v)\n    row_start = self.row_ptr[row]\n    row_end = self.row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in self.col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is undirected, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\n\n    Returns:\n        bool: True if graph is undirected, False otherwise\n    \"\"\"\n    return self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.laplacian","title":"<code>laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code> function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: Laplacian matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization: normalization parameter passed to pyG `get_laplacian`\n            function\n        edge_attr: optinal name of numerical edge attribute that shall\n            be passed to pyG `get_laplacian` function as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(), normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(),\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_sequence</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of node attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def node_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_sequence` attribute.\n\n    Returns:\n        list: list of node attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all predecessors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n\n    Returns:\n        list: list with all predecessors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n    node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.sparse_adj_matrix","title":"<code>sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all successors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) -&gt; list:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n\n    Returns:\n        list: list with all successors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n\n    node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.to","title":"<code>to</code>","text":"<p>Move all tensors to the given device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>torch device to which all tensors shall be moved</p> required <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>self</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; Graph:\n    \"\"\"Move all tensors to the given device.\n\n    Args:\n        device: torch device to which all tensors shall be moved\n\n    Returns:\n        Graph: self\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.node_sequence = self.data.node_sequence.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n\n    self.row = self.row.to(device)\n    self.row_ptr = self.row_ptr.to(device)\n    self.col = self.col.to(device)\n    self.col_ptr = self.col_ptr.to(device)\n\n    return self\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of this directed graph.</p> <p>This method creates a new undirected Graph from the current graph instance by adding all directed edges in opposite direction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n&gt;&gt;&gt; g_u = g.to_undirected()\n&gt;&gt;&gt; print(g_u)\nUndirected graph with 3 nodes and 6 (directed) edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"Return an undirected version of this directed graph.\n\n    This method creates a new undirected Graph from the current graph instance by\n    adding all directed edges in opposite direction.\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        &gt;&gt;&gt; g_u = g.to_undirected()\n        &gt;&gt;&gt; print(g_u)\n        Undirected graph with 3 nodes and 6 (directed) edges\n    \"\"\"\n    # create undirected edge index by coalescing the directed edges and keep\n    # track of the original edge index for the edge attributes\n    attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n    edge_index, attr_idx = to_undirected(\n        self.data.edge_index,\n        edge_attr=attr_idx,\n        num_nodes=self.data.num_nodes,\n        reduce=\"min\",\n    )\n\n    data = Data(\n        edge_index=EdgeIndex(\n            data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n        ),\n        num_nodes=self.data.num_nodes,\n    )\n    # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n    # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n    # make sure to copy all node and (undirected) edge attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    for edge_attr in self.edge_attrs():\n        if edge_attr != \"edge_index\":\n            data[edge_attr] = self.data[edge_attr][attr_idx]\n\n    return Graph(data, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> <p>If the graph contains multiple edges between the same nodes, this method will coalesce them into a single edge with an additional weight attribute called <code>edge_weight</code> that contains the number of coalesced edges. The method returns a new graph instance with the coalesced edges.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>Graph with coalesced edges</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n    If the graph contains multiple edges between the same nodes, this method will coalesce\n    them into a single edge with an additional weight attribute called `edge_weight` that\n    contains the number of coalesced edges. The method returns a new graph instance with\n    the coalesced edges.\n\n    Returns:\n        Graph: Graph with coalesced edges\n    \"\"\"\n    i, w = torch_geometric.utils.coalesce(\n        self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n    )\n    return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Compute transition probabilities based on (weighted) outdegrees.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>Optional name of numerical edge attribute that will         will be used to calculate weighted out-degrees for the         visitation probabilities.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Transition probabilities.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n    \"\"\"\n    Compute transition probabilities based on (weighted) outdegrees.\n\n    Args:\n        edge_attr: Optional name of numerical edge attribute that will\n                    will be used to calculate weighted out-degrees for the\n                    visitation probabilities.\n\n    Returns:\n        tensor: Transition probabilities.\n    \"\"\"\n    weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n    source_ids = self.data.edge_index[0]        \n    edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n    if edge_attr:\n        edge_weight = getattr(self.data, edge_attr, None)\n    return edge_weight / weighted_outdegree[source_ids]\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/","title":"map","text":"<p>IndexMap class for mapping node indices to IDs.</p>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap","title":"<code>IndexMap</code>","text":"<p>Maps node indices to IDs.</p> <p>This class keeps a mapping from any node ID, e.g. names (strings) or higher-order IDs (tuples), to an index of the corresponding node in the initial list of IDs, enabling fast lookup of node IDs from a <code>torch_geometric.data.Data</code> object.</p> <p>Attributes:</p> Name Type Description <code>node_ids</code> <code>numpy.ndarray | None</code> <p><code>numpy.ndarray</code> storing the node IDs, enabling fast lookup of multiple node IDs from indices.</p> <code>id_to_idx</code> <code>dict</code> <p><code>dict</code> mapping each node ID to its index.</p> <code>id_shape</code> <code>tuple</code> <p><code>tuple</code> storing the shape of the ID. The default shape is (-1,) for first-order IDs. For higher-order IDs, the shape will be <code>(-1, k)</code> with order <code>k</code>.</p> <p>Examples:</p> <p>Initialize an <code>IndexMap</code> object with a list of string IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\n</code></pre> <p>Add additional IDs to the mapping:</p> <pre><code>&gt;&gt;&gt; index_map.add_id(\"D\")\n&gt;&gt;&gt; print(index_map.to_idx(\"D\"))\n3\n</code></pre> <p>Map indices to IDs. Use <code>to_id</code> for single indices and <code>to_ids</code> for multiple indices. Note that the shape of the given index list will be preserved in the output:</p> <pre><code>&gt;&gt;&gt; print(index_map.to_id(1))\nB\n&gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n['A' 'C']\n</code></pre> <p>Map IDs to indices. Works analogously to the reversed mapping and can, e.g., be used to create an <code>edge_index</code> tensor from a list of edges given by source and destination node IDs:</p> <pre><code>&gt;&gt;&gt; edge_index = index_map.to_idxs([[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]).T\n</code></pre> <p>Create a higher-order ID mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n&gt;&gt;&gt; print(index_map)\n('A', 'B') -&gt; 0\n('A', 'C') -&gt; 1\n('B', 'C') -&gt; 2\n</code></pre> <p>The methods above work analogously for higher-order IDs:</p> <pre><code>&gt;&gt;&gt; print(index_map.to_id(1))\n('A', 'C')\n&gt;&gt;&gt; print(index_map.to_ids([[0], [2]]))\n[[('A', 'B')], [('B', 'C')]]\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>class IndexMap:\n    \"\"\"Maps node indices to IDs.\n\n    This class keeps a mapping from any node ID, e.g. names (strings) or higher-order IDs (tuples),\n    to an index of the corresponding node in the initial list of IDs, enabling fast lookup of node IDs\n    from a `torch_geometric.data.Data` object.\n\n    Attributes:\n        node_ids: `numpy.ndarray` storing the node IDs, enabling fast lookup of multiple node IDs from indices.\n        id_to_idx: `dict` mapping each node ID to its index.\n        id_shape: `tuple` storing the shape of the ID. The default shape is (-1,) for first-order IDs.\n            For higher-order IDs, the shape will be `(-1, k)` with order `k`.\n\n    Examples:\n        Initialize an `IndexMap` object with a list of string IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n\n        Add additional IDs to the mapping:\n\n        &gt;&gt;&gt; index_map.add_id(\"D\")\n        &gt;&gt;&gt; print(index_map.to_idx(\"D\"))\n        3\n\n        Map indices to IDs. Use `to_id` for single indices and `to_ids` for multiple indices.\n        Note that the shape of the given index list will be preserved in the output:\n\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        B\n        &gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n        ['A' 'C']\n\n        Map IDs to indices. Works analogously to the reversed mapping and can, e.g., be used to\n        create an `edge_index` tensor from a list of edges given by source and destination node IDs:\n\n        &gt;&gt;&gt; edge_index = index_map.to_idxs([[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]).T\n\n        Create a higher-order ID mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n        &gt;&gt;&gt; print(index_map)\n        ('A', 'B') -&gt; 0\n        ('A', 'C') -&gt; 1\n        ('B', 'C') -&gt; 2\n\n        The methods above work analogously for higher-order IDs:\n\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        ('A', 'C')\n        &gt;&gt;&gt; print(index_map.to_ids([[0], [2]]))\n        [[('A', 'B')], [('B', 'C')]]\n    \"\"\"\n\n    def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n        \"\"\"Initialize mapping from indices to node IDs.\n\n        The mapping will keep the ordering of the IDs as provided by `node_ids`. If the IDs are not unique,\n        an error will be raised.\n\n        Args:\n            node_ids: List of node IDs to initialize mapping.\n\n        Raises:\n            ValueError: If IDs are not unique.\n\n        Examples:\n            Initialize an `IndexMap` object with a list of string IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"C\", \"B\"])\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            C -&gt; 1\n            B -&gt; 2\n\n            Handle non-unique IDs and sort IDs lexicographically:\n\n            &gt;&gt;&gt; node_ids = [\"A\", \"C\", \"B\", \"A\"]\n            &gt;&gt;&gt; index_map = IndexMap(np.unique(node_ids))\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n        \"\"\"\n        self.node_ids: np.ndarray | None = None\n        self.id_to_idx: dict = {}\n        self.id_shape: tuple = (-1,)  # If the index map is higher order, this will be the shape of the ID\n        if node_ids is not None:\n            self.add_ids(node_ids)\n\n    @property\n    def has_ids(self) -&gt; bool:\n        \"\"\"Return whether mapping has IDs.\n\n        Returns:\n            Whether mapping has IDs.\n\n        Examples:\n            Check if mapping has IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.has_ids)\n            False\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.has_ids)\n            True\n        \"\"\"\n        return self.node_ids is not None\n\n    def num_ids(self) -&gt; int:\n        \"\"\"Return number of IDs. If mapping is not defined, return 0.\n\n        Returns:\n            Number of IDs.\n\n        Examples:\n            Get number of IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.num_ids())\n            0\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.num_ids())\n            3\n\n            &gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n            &gt;&gt;&gt; print(index_map.num_ids())\n            3\n        \"\"\"\n        if self.node_ids is None:\n            return 0\n        else:\n            return len(self.node_ids)\n\n    def add_id(self, node_id: Any) -&gt; None:\n        \"\"\"Assigns additional ID to the next consecutive index.\n\n        Args:\n            node_id: ID to assign.\n\n        Raises:\n            ValueError: If ID is already present in the mapping.\n\n        Examples:\n            Add an additional ID to the mapping:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; index_map.add_id(\"D\")\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n            D -&gt; 3\n        \"\"\"\n        if node_id not in self.id_to_idx:\n            idx = self.num_ids()\n            if isinstance(node_id, (list, tuple)):\n                node_id = to_numpy(node_id)\n                self.id_shape = (-1, *node_id.shape)\n            self.node_ids = (\n                np.concatenate((self.node_ids, to_numpy([node_id])))\n                if self.node_ids is not None\n                else to_numpy([node_id])\n            )\n            self.id_to_idx[node_id] = idx\n        else:\n            raise ValueError(\"ID already present in the mapping.\")\n\n    def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n        \"\"\"Assigns additional IDs to next consecutive indices. The order of IDs is preserved.\n\n        Args:\n            node_ids: IDs to assign\n\n        Raises:\n            ValueError: If IDs are not unique or already present in the mapping.\n\n        Examples:\n            Add additional IDs to the mapping:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; index_map.add_ids([\"E\", \"D\"])\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n            E -&gt; 3\n            D -&gt; 4\n        \"\"\"\n        cur_num_ids = self.num_ids()\n        if isinstance(node_ids, list) and isinstance(node_ids[0], (list, tuple)):\n            self.id_shape = (-1, *to_numpy(node_ids[0]).shape)\n\n        if not isinstance(node_ids, np.ndarray):\n            node_ids = to_numpy(node_ids)\n\n        all_ids = np.concatenate((self.node_ids, node_ids)) if self.node_ids is not None else node_ids\n        unique_ids = np.unique(all_ids, axis=0 if self.id_shape != (-1,) else None)\n\n        if len(unique_ids) != len(all_ids):\n            raise ValueError(\"IDs are not unique or already present in the mapping.\")\n\n        self.node_ids = all_ids\n        self.id_to_idx.update(\n            {tuple(v) if self.id_shape != (-1,) else v: i + cur_num_ids for i, v in enumerate(node_ids)}\n        )\n\n    def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n        \"\"\"Map index to ID if mapping is defined, return index otherwise.\n\n        Args:\n            idx: Index to map.\n\n        Returns:\n            ID if mapping is defined, index otherwise.\n\n        Examples:\n            Map index to ID:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_id(1))\n            B\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_id(1))\n            1\n        \"\"\"\n        if self.has_ids:\n            if self.id_shape == (-1,):\n                return self.node_ids[idx]  # type: ignore\n            else:\n                return tuple(self.node_ids[idx])  # type: ignore\n        else:\n            return idx\n\n    def to_ids(self, idxs: list | tuple | np.ndarray) -&gt; np.ndarray:\n        \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise. The shape of the given index\n        list will be preserved in the output.\n\n        Args:\n            idxs: Indices to map.\n\n        Returns:\n            IDs if mapping is defined, indices otherwise.\n\n        Examples:\n            Map list of indices to IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n            ['A' 'C']\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_ids(torch.tensor([0, 2])))\n            tensor([0 2])\n\n            Map edge_index tensor to array of edges:\n\n            &gt;&gt;&gt; edge_index = torch.tensor([[0, 2, 2, 3], [1, 1, 3, 0]])\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\", \"D\"])\n            &gt;&gt;&gt; print(index_map.to_ids(edge_index.T))\n            [['A' 'B']\n             ['C' 'B']\n             ['C' 'D']\n             ['D' 'A']]\n        \"\"\"\n        if self.has_ids:\n            if not isinstance(idxs, np.ndarray):\n                idxs = to_numpy(idxs)\n            return self.node_ids[idxs]  # type: ignore\n        else:\n            return idxs  # type: ignore\n\n    def to_idx(self, node: str | int | tuple[str] | tuple[int]) -&gt; int | tuple[int]:\n        \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\n\n        Args:\n            node: ID or index to map.\n\n        Returns:\n            Index if mapping is defined, argument otherwise.\n\n        Examples:\n            Map ID to index:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_idx(\"B\"))\n            1\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_idx(1))\n            1\n        \"\"\"\n        n: str | int | tuple[str] | tuple[int] = node\n        if self.has_ids:\n            if self.id_shape != (-1,):\n                n = tuple(n)\n            return self.id_to_idx[n]\n        else:\n            return n\n\n    def to_idxs(self, nodes: list | tuple | np.ndarray, device: Optional[torch.device] = None) -&gt; torch.Tensor:\n        \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise. The shape\n        of the given argument list will be preserved in the output.\n\n        Args:\n            nodes: IDs or indices to map.\n\n        Returns:\n            Indices if mapping is defined, arguments otherwise.\n\n        Examples:\n            Map list of IDs to indices:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_idxs([\"B\", \"A\"]))\n            tensor([1, 0])\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_idxs(torch.tensor([1, 0])))\n            tensor([1, 0])\n\n            Map list of edges to edge_index tensor:\n\n            &gt;&gt;&gt; edges = [[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]\n            &gt;&gt;&gt; index_map = IndexMap(np.unique(edges))\n            &gt;&gt;&gt; print(index_map.to_idxs(edges).T)\n            tensor([[0, 1, 2],\n                    [1, 2, 3]])\n        \"\"\"\n        if self.has_ids:\n            if not isinstance(nodes, np.ndarray):\n                nodes = to_numpy(nodes)\n\n            shape = nodes.shape\n            if self.id_shape == (-1,):\n                return torch.tensor([self.id_to_idx[node] for node in nodes.flatten()], device=device).reshape(shape)\n            else:\n                return torch.tensor([self.id_to_idx[tuple(node)] for node in nodes.reshape(self.id_shape)], device=device).reshape(\n                    shape[: -len(self.id_shape) + 1]\n                )\n        else:\n            return torch.tensor(nodes, device=device)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of the mapping.\n\n        Returns:\n            String representation of the mapping.\n\n        Examples:\n            Print string representation of the mapping:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n        \"\"\"\n        s = \"\"\n        for v in self.id_to_idx:\n            s += str(v) + \" -&gt; \" + str(self.to_idx(v)) + \"\\n\"\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.has_ids","title":"<code>has_ids</code>  <code>property</code>","text":"<p>Return whether mapping has IDs.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether mapping has IDs.</p> <p>Examples:</p> <p>Check if mapping has IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.has_ids)\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.has_ids)\nTrue\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.__init__","title":"<code>__init__</code>","text":"<p>Initialize mapping from indices to node IDs.</p> <p>The mapping will keep the ordering of the IDs as provided by <code>node_ids</code>. If the IDs are not unique, an error will be raised.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>typing.Union[typing.List[str], None]</code> <p>List of node IDs to initialize mapping.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If IDs are not unique.</p> <p>Examples:</p> <p>Initialize an <code>IndexMap</code> object with a list of string IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"C\", \"B\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nC -&gt; 1\nB -&gt; 2\n</code></pre> <p>Handle non-unique IDs and sort IDs lexicographically:</p> <pre><code>&gt;&gt;&gt; node_ids = [\"A\", \"C\", \"B\", \"A\"]\n&gt;&gt;&gt; index_map = IndexMap(np.unique(node_ids))\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n    \"\"\"Initialize mapping from indices to node IDs.\n\n    The mapping will keep the ordering of the IDs as provided by `node_ids`. If the IDs are not unique,\n    an error will be raised.\n\n    Args:\n        node_ids: List of node IDs to initialize mapping.\n\n    Raises:\n        ValueError: If IDs are not unique.\n\n    Examples:\n        Initialize an `IndexMap` object with a list of string IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"C\", \"B\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        C -&gt; 1\n        B -&gt; 2\n\n        Handle non-unique IDs and sort IDs lexicographically:\n\n        &gt;&gt;&gt; node_ids = [\"A\", \"C\", \"B\", \"A\"]\n        &gt;&gt;&gt; index_map = IndexMap(np.unique(node_ids))\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n    \"\"\"\n    self.node_ids: np.ndarray | None = None\n    self.id_to_idx: dict = {}\n    self.id_shape: tuple = (-1,)  # If the index map is higher order, this will be the shape of the ID\n    if node_ids is not None:\n        self.add_ids(node_ids)\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.__str__","title":"<code>__str__</code>","text":"<p>Return string representation of the mapping.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the mapping.</p> <p>Examples:</p> <p>Print string representation of the mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of the mapping.\n\n    Returns:\n        String representation of the mapping.\n\n    Examples:\n        Print string representation of the mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n    \"\"\"\n    s = \"\"\n    for v in self.id_to_idx:\n        s += str(v) + \" -&gt; \" + str(self.to_idx(v)) + \"\\n\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.add_id","title":"<code>add_id</code>","text":"<p>Assigns additional ID to the next consecutive index.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>typing.Any</code> <p>ID to assign.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If ID is already present in the mapping.</p> <p>Examples:</p> <p>Add an additional ID to the mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; index_map.add_id(\"D\")\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\nD -&gt; 3\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def add_id(self, node_id: Any) -&gt; None:\n    \"\"\"Assigns additional ID to the next consecutive index.\n\n    Args:\n        node_id: ID to assign.\n\n    Raises:\n        ValueError: If ID is already present in the mapping.\n\n    Examples:\n        Add an additional ID to the mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; index_map.add_id(\"D\")\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n        D -&gt; 3\n    \"\"\"\n    if node_id not in self.id_to_idx:\n        idx = self.num_ids()\n        if isinstance(node_id, (list, tuple)):\n            node_id = to_numpy(node_id)\n            self.id_shape = (-1, *node_id.shape)\n        self.node_ids = (\n            np.concatenate((self.node_ids, to_numpy([node_id])))\n            if self.node_ids is not None\n            else to_numpy([node_id])\n        )\n        self.id_to_idx[node_id] = idx\n    else:\n        raise ValueError(\"ID already present in the mapping.\")\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.add_ids","title":"<code>add_ids</code>","text":"<p>Assigns additional IDs to next consecutive indices. The order of IDs is preserved.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>list | numpy.ndarray</code> <p>IDs to assign</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If IDs are not unique or already present in the mapping.</p> <p>Examples:</p> <p>Add additional IDs to the mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; index_map.add_ids([\"E\", \"D\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\nE -&gt; 3\nD -&gt; 4\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n    \"\"\"Assigns additional IDs to next consecutive indices. The order of IDs is preserved.\n\n    Args:\n        node_ids: IDs to assign\n\n    Raises:\n        ValueError: If IDs are not unique or already present in the mapping.\n\n    Examples:\n        Add additional IDs to the mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; index_map.add_ids([\"E\", \"D\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n        E -&gt; 3\n        D -&gt; 4\n    \"\"\"\n    cur_num_ids = self.num_ids()\n    if isinstance(node_ids, list) and isinstance(node_ids[0], (list, tuple)):\n        self.id_shape = (-1, *to_numpy(node_ids[0]).shape)\n\n    if not isinstance(node_ids, np.ndarray):\n        node_ids = to_numpy(node_ids)\n\n    all_ids = np.concatenate((self.node_ids, node_ids)) if self.node_ids is not None else node_ids\n    unique_ids = np.unique(all_ids, axis=0 if self.id_shape != (-1,) else None)\n\n    if len(unique_ids) != len(all_ids):\n        raise ValueError(\"IDs are not unique or already present in the mapping.\")\n\n    self.node_ids = all_ids\n    self.id_to_idx.update(\n        {tuple(v) if self.id_shape != (-1,) else v: i + cur_num_ids for i, v in enumerate(node_ids)}\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.num_ids","title":"<code>num_ids</code>","text":"<p>Return number of IDs. If mapping is not defined, return 0.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of IDs.</p> <p>Examples:</p> <p>Get number of IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.num_ids())\n0\n</code></pre> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.num_ids())\n3\n</code></pre> <pre><code>&gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n&gt;&gt;&gt; print(index_map.num_ids())\n3\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def num_ids(self) -&gt; int:\n    \"\"\"Return number of IDs. If mapping is not defined, return 0.\n\n    Returns:\n        Number of IDs.\n\n    Examples:\n        Get number of IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.num_ids())\n        0\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.num_ids())\n        3\n\n        &gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n        &gt;&gt;&gt; print(index_map.num_ids())\n        3\n    \"\"\"\n    if self.node_ids is None:\n        return 0\n    else:\n        return len(self.node_ids)\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_id","title":"<code>to_id</code>","text":"<p>Map index to ID if mapping is defined, return index otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index to map.</p> required <p>Returns:</p> Type Description <code>typing.Union[int, str, tuple]</code> <p>ID if mapping is defined, index otherwise.</p> <p>Examples:</p> <p>Map index to ID:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_id(1))\nB\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_id(1))\n1\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n    \"\"\"Map index to ID if mapping is defined, return index otherwise.\n\n    Args:\n        idx: Index to map.\n\n    Returns:\n        ID if mapping is defined, index otherwise.\n\n    Examples:\n        Map index to ID:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        B\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        1\n    \"\"\"\n    if self.has_ids:\n        if self.id_shape == (-1,):\n            return self.node_ids[idx]  # type: ignore\n        else:\n            return tuple(self.node_ids[idx])  # type: ignore\n    else:\n        return idx\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_ids","title":"<code>to_ids</code>","text":"<p>Map list of indices to IDs if mapping is defined, return indices otherwise. The shape of the given index list will be preserved in the output.</p> <p>Parameters:</p> Name Type Description Default <code>idxs</code> <code>list | tuple | numpy.ndarray</code> <p>Indices to map.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>IDs if mapping is defined, indices otherwise.</p> <p>Examples:</p> <p>Map list of indices to IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n['A' 'C']\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_ids(torch.tensor([0, 2])))\ntensor([0 2])\n</code></pre> <p>Map edge_index tensor to array of edges:</p> <pre><code>&gt;&gt;&gt; edge_index = torch.tensor([[0, 2, 2, 3], [1, 1, 3, 0]])\n&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\", \"D\"])\n&gt;&gt;&gt; print(index_map.to_ids(edge_index.T))\n[['A' 'B']\n ['C' 'B']\n ['C' 'D']\n ['D' 'A']]\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_ids(self, idxs: list | tuple | np.ndarray) -&gt; np.ndarray:\n    \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise. The shape of the given index\n    list will be preserved in the output.\n\n    Args:\n        idxs: Indices to map.\n\n    Returns:\n        IDs if mapping is defined, indices otherwise.\n\n    Examples:\n        Map list of indices to IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n        ['A' 'C']\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_ids(torch.tensor([0, 2])))\n        tensor([0 2])\n\n        Map edge_index tensor to array of edges:\n\n        &gt;&gt;&gt; edge_index = torch.tensor([[0, 2, 2, 3], [1, 1, 3, 0]])\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\", \"D\"])\n        &gt;&gt;&gt; print(index_map.to_ids(edge_index.T))\n        [['A' 'B']\n         ['C' 'B']\n         ['C' 'D']\n         ['D' 'A']]\n    \"\"\"\n    if self.has_ids:\n        if not isinstance(idxs, np.ndarray):\n            idxs = to_numpy(idxs)\n        return self.node_ids[idxs]  # type: ignore\n    else:\n        return idxs  # type: ignore\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_idx","title":"<code>to_idx</code>","text":"<p>Map argument (ID or index) to index if mapping is defined, return argument otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str | int | tuple[str] | tuple[int]</code> <p>ID or index to map.</p> required <p>Returns:</p> Type Description <code>int | tuple[int]</code> <p>Index if mapping is defined, argument otherwise.</p> <p>Examples:</p> <p>Map ID to index:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_idx(\"B\"))\n1\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_idx(1))\n1\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_idx(self, node: str | int | tuple[str] | tuple[int]) -&gt; int | tuple[int]:\n    \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\n\n    Args:\n        node: ID or index to map.\n\n    Returns:\n        Index if mapping is defined, argument otherwise.\n\n    Examples:\n        Map ID to index:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_idx(\"B\"))\n        1\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_idx(1))\n        1\n    \"\"\"\n    n: str | int | tuple[str] | tuple[int] = node\n    if self.has_ids:\n        if self.id_shape != (-1,):\n            n = tuple(n)\n        return self.id_to_idx[n]\n    else:\n        return n\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_idxs","title":"<code>to_idxs</code>","text":"<p>Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise. The shape of the given argument list will be preserved in the output.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list | tuple | numpy.ndarray</code> <p>IDs or indices to map.</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Indices if mapping is defined, arguments otherwise.</p> <p>Examples:</p> <p>Map list of IDs to indices:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_idxs([\"B\", \"A\"]))\ntensor([1, 0])\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_idxs(torch.tensor([1, 0])))\ntensor([1, 0])\n</code></pre> <p>Map list of edges to edge_index tensor:</p> <pre><code>&gt;&gt;&gt; edges = [[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]\n&gt;&gt;&gt; index_map = IndexMap(np.unique(edges))\n&gt;&gt;&gt; print(index_map.to_idxs(edges).T)\ntensor([[0, 1, 2],\n        [1, 2, 3]])\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_idxs(self, nodes: list | tuple | np.ndarray, device: Optional[torch.device] = None) -&gt; torch.Tensor:\n    \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise. The shape\n    of the given argument list will be preserved in the output.\n\n    Args:\n        nodes: IDs or indices to map.\n\n    Returns:\n        Indices if mapping is defined, arguments otherwise.\n\n    Examples:\n        Map list of IDs to indices:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_idxs([\"B\", \"A\"]))\n        tensor([1, 0])\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_idxs(torch.tensor([1, 0])))\n        tensor([1, 0])\n\n        Map list of edges to edge_index tensor:\n\n        &gt;&gt;&gt; edges = [[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]\n        &gt;&gt;&gt; index_map = IndexMap(np.unique(edges))\n        &gt;&gt;&gt; print(index_map.to_idxs(edges).T)\n        tensor([[0, 1, 2],\n                [1, 2, 3]])\n    \"\"\"\n    if self.has_ids:\n        if not isinstance(nodes, np.ndarray):\n            nodes = to_numpy(nodes)\n\n        shape = nodes.shape\n        if self.id_shape == (-1,):\n            return torch.tensor([self.id_to_idx[node] for node in nodes.flatten()], device=device).reshape(shape)\n        else:\n            return torch.tensor([self.id_to_idx[tuple(node)] for node in nodes.reshape(self.id_shape)], device=device).reshape(\n                shape[: -len(self.id_shape) + 1]\n            )\n    else:\n        return torch.tensor(nodes, device=device)\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/","title":"model","text":""},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel","title":"<code>MultiOrderModel</code>","text":"<p>MultiOrderModel based on torch_geometric.Data.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>class MultiOrderModel:\n    \"\"\"MultiOrderModel based on torch_geometric.Data.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.layers: dict[int, Graph] = {}\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the higher-order graph.\"\"\"\n        max_order = max(list(self.layers.keys())) if self.layers else 0\n        s = f\"MultiOrderModel with max. order {max_order}\"\n        return s\n\n    def to(self, device: torch.device) -&gt; MultiOrderModel:\n        \"\"\"Convert the graph layers to the given device.\n\n        Args:\n            device: The device to convert the graph layers to.\n\n        Returns: The MultiOrderModel with graph layers on the given device.\n        \"\"\"\n        for g in self.layers.values():\n            g.to(device)\n        return self\n\n    @staticmethod\n    def iterate_lift_order(\n        edge_index: torch.Tensor,\n        node_sequence: torch.Tensor,\n        mapping: IndexMap,\n        edge_weight: torch.Tensor | None = None,\n        aggr: str = \"src\",\n        save: bool = True,\n    ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n        \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n        This is a helper function that should not be called directly.\n        Only use for edge_indices after the special cases have been handled e.g.\n        in the from_temporal_graph (filtering non-time-respecting paths of order 2).\n\n        Args:\n            edge_index: The edge index of the (k-1)-th order graph.\n            node_sequence: The node sequences of the (k-1)-th order graph.\n            edge_weight: The edge weights of the (k-1)-th order graph.\n            k: The order of the graph that should be computed.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n            save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n        \"\"\"\n        # Lift order\n        if edge_weight is None:\n            ho_index = lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n        else:\n            ho_index, edge_weight = lift_order_edge_index_weighted(\n                edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n            )\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n        # Aggregate\n        if save:\n            gk = aggregate_edge_index(ho_index, node_sequence, edge_weight)\n            gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n        else:\n            gk = None\n        return ho_index, node_sequence, edge_weight, gk\n\n    @staticmethod\n    def from_temporal_graph(\n        g: TemporalGraph,\n        delta: float | int = 1,\n        max_order: int = 1,\n        weight: str = \"edge_weight\",\n        cached: bool = True,\n        event_graph: Optional[torch.Tensor] = None,\n    ) -&gt; MultiOrderModel:\n        \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\n\n        Args:\n            g: The temporal graph.\n            delta: The maximum time difference between two consecutive edges in a path.\n            max_order: The maximum order of the MultiOrderModel that should be computed.\n            weight: The edge attribute to use as edge weight.\n            cached: Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.\n            event_graph: precomputed event graph edge index for given delta to be used for model generation. Useful to prevent the same event graph\n            from being computed twice.\n\n        Returns:\n            MultiOrderModel: A multi-order model where each layer is a De Bruijn graph with order k.\n        \"\"\"\n        m = MultiOrderModel()\n        if not g.data.is_sorted_by_time():\n            data = g.data.sort_by_time()\n        else:\n            data = g.data\n        edge_index = data.edge_index\n        node_sequence = torch.arange(data.num_nodes, device=edge_index.device).unsqueeze(1)\n        if weight in data:\n            edge_weight = data[weight]\n        else:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n        if cached or max_order == 1:\n            m.layers[1] = aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[1].mapping = g.mapping\n\n        if max_order &gt; 1:\n            node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n            if event_graph is None:\n                edge_index = lift_order_temporal(g, delta)\n            else:\n                edge_index = event_graph\n            edge_weight = aggregate_node_attributes(edge_index, edge_weight, \"src\")\n\n            # Aggregate\n            if cached or max_order == 2:\n                m.layers[2] = aggregate_edge_index(\n                    edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n                )\n                m.layers[2].mapping = IndexMap(\n                    [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n                )\n\n            for k in range(3, max_order + 1):\n                edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                    edge_index=edge_index,\n                    node_sequence=node_sequence,\n                    mapping=g.mapping,\n                    edge_weight=edge_weight,\n                    aggr=\"src\",\n                    save=cached or k == max_order,\n                )\n                if cached or k == max_order:\n                    m.layers[k] = gk\n        return m\n\n    @staticmethod\n    def from_path_data(\n        path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"\n        Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n        Args:\n            path_data: `PathData` object containing paths as list of PyG Data objects\n                with sorted edge indices, node sequences and num_nodes.\n            max_order: The maximum order of the MultiOrderModel that should be computed\n            mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n            cached: Whether to save the aggregated higher-order graphs smaller than max order\n                in the MultiOrderModel.\n\n        Returns:\n            MultiOrderModel: The MultiOrderModel.\n        \"\"\"\n        m = MultiOrderModel()\n\n        # We assume that paths are sorted\n        path_graph = path_data.data\n        edge_index = path_graph.edge_index\n        node_sequence = path_graph.node_sequence\n        edge_weight = path_graph.dag_weight.repeat_interleave(path_graph.dag_num_edges)\n        if mode == \"diffusion\":\n            edge_weight = (\n                edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n            )\n            aggr = \"mul\"\n        elif mode == \"propagation\":\n            aggr = \"src\"\n\n        m.layers[1] = aggregate_edge_index(edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight)\n        m.layers[1].mapping = path_data.mapping\n\n        for k in range(2, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=m.layers[1].mapping,\n                edge_weight=edge_weight,\n                aggr=aggr,\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n        return m\n\n    def get_mon_dof(self, max_order: Optional[int] = None, assumption: str = \"paths\") -&gt; int:\n        \"\"\"\n        The degrees of freedom for the kth layer of a multi-order model. This depends on the number of different paths of exactly length `k` in the graph.\n        Therefore, we can obtain these values by summing the entries of the `k`-th power of the binary adjacency matrix of the graph.\n        Finally, we must consider that, due the conservation of probablility, all non-zero rows of the transition matrix of the higher-order network must sum to one.\n        This poses one additional constraint per row that respects the condition, which should be removed from the total count of degrees of freedom.\n\n        Args:\n            m (MultiOrderModel): The multi-order model.\n            max_order (int, optional): The maximum order up to which model layers\n                shall be taken into account. Defaults to None, meaning it considers\n                all available layers.\n            assumption (str, optional): If set to 'paths', only paths in the\n                first-order network topology will be considered for the degree of\n                freedom calculation. If set to 'ngrams', all possible n-grams will\n                be considered, independent of whether they are valid paths in the\n                first-order network or not. Defaults to 'paths'.\n\n        Returns:\n            int: The degrees of freedom for the multi-order model.\n\n        Raises:\n            ValueError: If max_order is larger than the maximum order of\n                the multi-order network.\n            ValueError: If the assumption is not 'paths' or 'ngrams'.\n        \"\"\"\n        if max_order is None:\n            max_order = max(self.layers)\n\n        if max_order &gt; max(self.layers):\n            logger.error(\"max_order cannot be larger than maximum order of multi-order network\")\n            raise ValueError(\"max_order cannot be larger than maximum order of multi-order network\")\n\n\n        dof = self.layers[1].data.num_nodes - 1  # Degrees of freedom for zeroth order\n\n        if assumption == \"paths\":\n            # COMPUTING CONTRIBUTION FROM NUM PATHS AND NONZERO OUTDEGREES SEPARATELY\n            # TODO: CAN IT BE DONE TOGETHER?\n\n            edge_index = self.layers[1].data.edge_index\n            # Adding dof from Number of paths of length k\n            for k in range(1, max_order + 1):\n                if k &gt; 1:\n                    num_nodes = 0 if edge_index.numel() == 0 else edge_index.max().item() + 1\n                    edge_index = lift_order_edge_index(edge_index, num_nodes)\n                # counting number of len k paths\n                num_len_k_paths = edge_index.shape[1]  # edge_index.max().item() +1  # Number of paths of length k\n                dof += num_len_k_paths\n\n            # removing dof from total probability of nonzero degree nodes\n            for k in range(1, max_order + 1):\n                if k == 1:\n                    # edge_index of temporal graph is sorted by time by default\n                    # For matrix multiplication, we need to sort it by row\n                    edge_index_adj = self.layers[1].data.edge_index.sort_by(\"row\")[0]\n                    edge_index = edge_index_adj\n                else:\n                    edge_index, _ = edge_index.matmul(edge_index_adj)\n                num_nonzero_outdegrees = torch.unique(edge_index[0]).size(0)\n                dof -= num_nonzero_outdegrees\n\n        elif assumption == \"ngrams\":\n            for order in range(1, max_order + 1):\n                dof += (self.layers[1].data.num_nodes**order) * (self.layers[1].data.num_nodes - 1)\n        else:\n            logger.error(\"Unknown assumption %s. Only 'path' and 'ngram' are accepted.\", assumption)\n            raise ValueError(\n                f\"Unknown assumption {assumption}. Only 'path' and 'ngram' are accepted.\"\n            )\n\n        return int(dof)\n\n    def get_zeroth_order_log_likelihood(self, dag_graph: Data) -&gt; float:\n        \"\"\"\n        Compute the zeroth order log likelihood.\n\n        Args:\n            dag_graph (Data): Input DAG graph data.\n\n        Returns:\n            float: Zeroth order log likelihood.\n        \"\"\"\n        # Get frequencies\n        # getting the index of the last edge of each path (to be used to extract weights)\n        frequencies = dag_graph.dag_weight\n\n        # Get ixs starting nodes\n        # Q: Is dag_graph.path_index[:-1] enough to get the start_ixs?\n        mask = torch.ones(dag_graph.num_nodes, dtype=bool)\n        mask[dag_graph.edge_index[1]] = False\n        start_ixs = dag_graph.node_sequence.squeeze()[mask]\n\n        # Compute node emission probabilities\n        # TODOL modify once we have zeroth order in mon\n        _, counts = torch.unique(dag_graph.node_sequence, return_counts=True)\n        # WARNING: Only works if all nodes in the first-order graph are also in `node_sequence`\n        # Otherwise the missing nodes will not be included in `counts` which can lead to elements at the wrong index.\n        node_emission_probabilities = counts / counts.sum()\n        return torch.mul(frequencies, torch.log(node_emission_probabilities[start_ixs])).sum().item()\n\n    def get_intermediate_order_log_likelihood(self, dag_graph: Data, order: int) -&gt; float:\n        \"\"\"\n        Compute the intermediate order log likelihood.\n\n        Args:\n            m (MultiOrderModel): Multi-order model.\n            dag_graph (Data): Input DAG graph data.\n            order (int): Order of the intermediate log likelihood.\n\n        Returns:\n            float: Intermediate order log likelihood.\n        \"\"\"\n        # Get frequencies\n        frequencies = dag_graph.dag_weight\n        path_lengths = dag_graph.dag_num_nodes\n        # paths shrink by 'order' if we encode them using higher-order nodes\n        paths_lenghts_ho = path_lengths - order\n        # selecting only path that didn t shrink to zero due to higher-order transformation\n        paths_lenghts_ho_filtered = paths_lenghts_ho[paths_lenghts_ho &gt; 0]\n        frequencies = frequencies[paths_lenghts_ho &gt; 0]\n        # start index of the path in the higher order space\n        ixs_start_paths_ho = cumsum(paths_lenghts_ho_filtered)[:-1]\n\n        transition_probabilities = self.layers[order].transition_probabilities()[\n            self.layers[order + 1].data.inverse_idx[ixs_start_paths_ho]\n        ]\n\n        log_transition_probabilities = torch.log(transition_probabilities)\n        llh_by_subpath = torch.mul(frequencies, log_transition_probabilities)\n        return llh_by_subpath.sum().item()\n\n    def get_mon_log_likelihood(self, dag_graph: Data, max_order: int = 1) -&gt; float:\n        \"\"\"\n        Compute the likelihood of the walks given a multi-order model.\n\n        Args:\n            m (MultiOrderModel): The multi-order model.\n            dag_graph (Data): Dataset containing the walks.\n            max_order (int, optional): The maximum order up to which model layers\n                shall be taken into account. Defaults to 1.\n\n        Returns:\n            float: The log likelihood of the walks given the multi-order model.\n        \"\"\"\n        llh = 0\n\n        # Adding likelihood of zeroth order\n        llh += self.get_zeroth_order_log_likelihood(dag_graph)\n\n        # Adding the likelihood for all the intermediate orders\n        for order in range(1, max_order):\n            llh += self.get_intermediate_order_log_likelihood(dag_graph, order)\n\n        # Adding the likelihood of highest/stationary order\n        if max_order &gt; 0:\n            transition_probabilities = self.layers[max_order].transition_probabilities(edge_attr=\"edge_weight\")\n            log_transition_probabilities = torch.log(transition_probabilities)\n            llh_by_subpath = log_transition_probabilities * self.layers[max_order].data.edge_weight\n            llh += llh_by_subpath.sum().item()\n        else:\n            # Compute likelihood for zeroth order (to be modified)\n            # TODO: modify once we have zeroth order in mon\n            # (then won t need to compute emission probs from dag_graph -- which also hinders us from computing the lh that a new set of paths was generated by the model)\n            frequencies = dag_graph.dag_weight\n            counts = torch.bincount(\n                dag_graph.node_sequence.squeeze(), frequencies.repeat_interleave(dag_graph.dag_num_nodes)\n            )\n            node_emission_probabilities = counts / counts.sum()\n            llh = torch.mul(torch.log(node_emission_probabilities), counts).sum().item()\n\n        return llh\n\n    def likelihood_ratio_test(\n        self,\n        dag_graph: Data,\n        max_order_null: int = 0,\n        max_order: int = 1,\n        assumption: str = \"paths\",\n        significance_threshold: float = 0.01,\n    ) -&gt; tuple:\n        \"\"\"\n        Perform a likelihood ratio test to compare two models of different order.\n\n        Args:\n            dag_graph (Data): The input DAG graph data.\n            max_order_null (int, optional): The maximum order of the null hypothesis model.\n                Defaults to 0.\n            max_order (int, optional): The maximum order of the alternative hypothesis model.\n                Defaults to 1.\n            assumption (str, optional): The assumption to use for the degrees of freedom calculation.\n                Can be 'paths' or 'ngrams'. Defaults to 'paths'.\n            significance_threshold (float, optional): The significance threshold for the test.\n                Defaults to 0.01.\n\n        Returns:\n            tuple: A tuple containing a boolean indicating whether the null hypothesis is rejected\n                and the p-value of the test.\n        \"\"\"\n        if max_order_null &gt;= max_order:\n            logger.error(\"order of null hypothesis must be smaller than order of alternative hypothesis\")\n            raise ValueError(\"order of null hypothesis must be smaller than order of alternative hypothesis\")\n        if max_order &gt; max(self.layers):\n            logger.error(\"order of hypotheses must be smaller than max. order of MultiOrderModel\")\n            raise ValueError(f\"order of hypotheses ({max_order_null} and {max_order}) must be smaller than max. order of MultiOrderModel {max(self.layers)}\")\n        # let L0 be the likelihood for the null model and L1 be the likelihood for the alternative model\n\n        # we first compute a test statistic x = -2 * log (L0/L1) = -2 * (log L0 - log L1)\n        x = -2 * (\n            self.get_mon_log_likelihood(dag_graph, max_order=max_order_null)\n            - self.get_mon_log_likelihood(dag_graph, max_order=max_order)\n        )\n\n        # we calculate the additional degrees of freedom in the alternative model\n        dof_diff = self.get_mon_dof(max_order, assumption=assumption) - self.get_mon_dof(\n            max_order_null, assumption=assumption\n        )\n\n        # if the p-value is *below* the significance threshold, we reject the null hypothesis\n        p = 1 - chi2.cdf(x, dof_diff)\n        return (p &lt; significance_threshold), p\n\n    def estimate_order(self, dag_data: PathData, max_order: Optional[int] = None, significance_threshold: float = 0.01) -&gt; int:\n        \"\"\"\n        Selects the optimal maximum order of a multi-order network model for the\n        observed paths, based on a likelihood ratio test with p-value threshold of p\n        By default, all orders up to the maximum order of the multi-order model will be tested.\n\n        Args:\n            dag_data (DAGData): The path statistics data for which to estimate the optimal order.\n            max_order (int, optional): The maximum order to consider during the estimation process.\n                If not provided, the maximum order of the multi-order model is used.\n            significance_threshold (float, optional): The p-value threshold for the likelihood ratio test.\n                An order is accepted if the improvement in likelihood is significant at this threshold.\n\n        Returns:\n            int: The estimated optimal maximum order for the multi-order network model.\n\n        Raises:\n            ValueError: If the provided max_order is larger than the maximum order of the multi-order model\n                or if the input DAGData does not have the same set of nodes as the multi-order network\n        \"\"\"\n        if max_order is None:\n            max_order = max(self.layers)\n        if max_order &gt; max(self.layers):\n            logger.error(\"max_order cannot be larger than maximum order of multi-order network\")\n            raise ValueError(\"max_order cannot be larger than maximum order of multi-order network\")\n        if max_order &lt;= 1:\n            logger.error(\"max_order must be larger than one\")\n            raise ValueError(\"max_order must be larger than one\")\n        if set(dag_data.mapping.node_ids).intersection(set(self.layers[1].mapping.node_ids)) != set(dag_data.mapping.node_ids):\n            logger.error(\"Input paths do not have same set of nodes as multi-order network\")\n            raise ValueError(\"Input paths do not have same set of nodes as multi-order network\")        \n\n        max_accepted_order = 1\n        dag_graph = dag_data.data\n\n        # Test for highest order that passes\n        # likelihood ratio test against null model\n        for k in range(2, max_order + 1):\n            if self.likelihood_ratio_test(\n                dag_graph, max_order_null=k - 1, max_order=k, significance_threshold=significance_threshold\n            )[0]:\n                max_accepted_order = k\n\n        return max_accepted_order\n\n    def to_dbgnn_data(self, max_order: int = 2, mapping: str = \"last\") -&gt; Data:\n        \"\"\"\n        Convert the MultiOrderModel to a De Bruijn graph for the given maximum order\n        that can be used in `pathpyG.nn.dbgnn.DBGNN`.\n\n        Args:\n            max_order: The maximum order of the De Bruijn graph to be computed.\n            mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n\n        Returns:\n            Data: The De Bruijn graph data.\n        \"\"\"\n        if max_order not in self.layers:\n            logger.error(\"Higher-order graph of specified order not found.\")\n            raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n        g = self.layers[1]\n        g_max_order = self.layers[max_order]\n        num_nodes = g.data.num_nodes\n        num_ho_nodes = g_max_order.data.num_nodes\n        if g.data.x is not None:\n            x = g.data.x\n        else:\n            x = torch.eye(num_nodes, num_nodes, device=g.data.edge_index.device)\n        x_max_order = torch.eye(num_ho_nodes, num_ho_nodes, device=g_max_order.data.edge_index.device)\n        edge_index = g.data.edge_index\n        edge_index_max_order = g_max_order.data.edge_index\n        edge_weight = g.data.edge_weight\n        edge_weight_max_order = g_max_order.data.edge_weight\n        bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping, device=edge_index.device)\n\n        if g.data.y is not None:\n            y = g.data.y\n\n        return Data(\n            num_nodes=num_nodes,\n            num_ho_nodes=num_ho_nodes,\n            x=x,\n            x_h=x_max_order,\n            edge_index=edge_index,\n            edge_index_higher_order=edge_index_max_order,\n            edge_weights=edge_weight.float(),\n            edge_weights_higher_order=edge_weight_max_order.float(),\n            bipartite_edge_index=bipartite_edge_index,\n            y=y if \"y\" in locals() else None,\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the higher-order graph.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the higher-order graph.\"\"\"\n    max_order = max(list(self.layers.keys())) if self.layers else 0\n    s = f\"MultiOrderModel with max. order {max_order}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.estimate_order","title":"<code>estimate_order</code>","text":"<p>Selects the optimal maximum order of a multi-order network model for the observed paths, based on a likelihood ratio test with p-value threshold of p By default, all orders up to the maximum order of the multi-order model will be tested.</p> <p>Parameters:</p> Name Type Description Default <code>dag_data</code> <code>DAGData</code> <p>The path statistics data for which to estimate the optimal order.</p> required <code>max_order</code> <code>int</code> <p>The maximum order to consider during the estimation process. If not provided, the maximum order of the multi-order model is used.</p> <code>None</code> <code>significance_threshold</code> <code>float</code> <p>The p-value threshold for the likelihood ratio test. An order is accepted if the improvement in likelihood is significant at this threshold.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The estimated optimal maximum order for the multi-order network model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided max_order is larger than the maximum order of the multi-order model or if the input DAGData does not have the same set of nodes as the multi-order network</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def estimate_order(self, dag_data: PathData, max_order: Optional[int] = None, significance_threshold: float = 0.01) -&gt; int:\n    \"\"\"\n    Selects the optimal maximum order of a multi-order network model for the\n    observed paths, based on a likelihood ratio test with p-value threshold of p\n    By default, all orders up to the maximum order of the multi-order model will be tested.\n\n    Args:\n        dag_data (DAGData): The path statistics data for which to estimate the optimal order.\n        max_order (int, optional): The maximum order to consider during the estimation process.\n            If not provided, the maximum order of the multi-order model is used.\n        significance_threshold (float, optional): The p-value threshold for the likelihood ratio test.\n            An order is accepted if the improvement in likelihood is significant at this threshold.\n\n    Returns:\n        int: The estimated optimal maximum order for the multi-order network model.\n\n    Raises:\n        ValueError: If the provided max_order is larger than the maximum order of the multi-order model\n            or if the input DAGData does not have the same set of nodes as the multi-order network\n    \"\"\"\n    if max_order is None:\n        max_order = max(self.layers)\n    if max_order &gt; max(self.layers):\n        logger.error(\"max_order cannot be larger than maximum order of multi-order network\")\n        raise ValueError(\"max_order cannot be larger than maximum order of multi-order network\")\n    if max_order &lt;= 1:\n        logger.error(\"max_order must be larger than one\")\n        raise ValueError(\"max_order must be larger than one\")\n    if set(dag_data.mapping.node_ids).intersection(set(self.layers[1].mapping.node_ids)) != set(dag_data.mapping.node_ids):\n        logger.error(\"Input paths do not have same set of nodes as multi-order network\")\n        raise ValueError(\"Input paths do not have same set of nodes as multi-order network\")        \n\n    max_accepted_order = 1\n    dag_graph = dag_data.data\n\n    # Test for highest order that passes\n    # likelihood ratio test against null model\n    for k in range(2, max_order + 1):\n        if self.likelihood_ratio_test(\n            dag_graph, max_order_null=k - 1, max_order=k, significance_threshold=significance_threshold\n        )[0]:\n            max_accepted_order = k\n\n    return max_accepted_order\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.from_path_data","title":"<code>from_path_data</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graphs modelling paths in PathData.</p> <p>Parameters:</p> Name Type Description Default <code>path_data</code> <code>pathpyG.core.path_data.PathData</code> <p><code>PathData</code> object containing paths as list of PyG Data objects with sorted edge indices, node sequences and num_nodes.</p> required <code>max_order</code> <code>int</code> <p>The maximum order of the MultiOrderModel that should be computed</p> <code>1</code> <code>mode</code> <code>str</code> <p>The process that we assume. Can be \"diffusion\" or \"propagation\".</p> <code>'propagation'</code> <code>cached</code> <code>bool</code> <p>Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>MultiOrderModel</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The MultiOrderModel.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>@staticmethod\ndef from_path_data(\n    path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"\n    Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n    Args:\n        path_data: `PathData` object containing paths as list of PyG Data objects\n            with sorted edge indices, node sequences and num_nodes.\n        max_order: The maximum order of the MultiOrderModel that should be computed\n        mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n        cached: Whether to save the aggregated higher-order graphs smaller than max order\n            in the MultiOrderModel.\n\n    Returns:\n        MultiOrderModel: The MultiOrderModel.\n    \"\"\"\n    m = MultiOrderModel()\n\n    # We assume that paths are sorted\n    path_graph = path_data.data\n    edge_index = path_graph.edge_index\n    node_sequence = path_graph.node_sequence\n    edge_weight = path_graph.dag_weight.repeat_interleave(path_graph.dag_num_edges)\n    if mode == \"diffusion\":\n        edge_weight = (\n            edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n        )\n        aggr = \"mul\"\n    elif mode == \"propagation\":\n        aggr = \"src\"\n\n    m.layers[1] = aggregate_edge_index(edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight)\n    m.layers[1].mapping = path_data.mapping\n\n    for k in range(2, max_order + 1):\n        edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n            edge_index=edge_index,\n            node_sequence=node_sequence,\n            mapping=m.layers[1].mapping,\n            edge_weight=edge_weight,\n            aggr=aggr,\n            save=cached or k == max_order,\n        )\n        if cached or k == max_order:\n            m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.from_temporal_graph","title":"<code>from_temporal_graph</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>The temporal graph.</p> required <code>delta</code> <code>float | int</code> <p>The maximum time difference between two consecutive edges in a path.</p> <code>1</code> <code>max_order</code> <code>int</code> <p>The maximum order of the MultiOrderModel that should be computed.</p> <code>1</code> <code>weight</code> <code>str</code> <p>The edge attribute to use as edge weight.</p> <code>'edge_weight'</code> <code>cached</code> <code>bool</code> <p>Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.</p> <code>True</code> <code>event_graph</code> <code>typing.Optional[torch.Tensor]</code> <p>precomputed event graph edge index for given delta to be used for model generation. Useful to prevent the same event graph</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MultiOrderModel</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>A multi-order model where each layer is a De Bruijn graph with order k.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>@staticmethod\ndef from_temporal_graph(\n    g: TemporalGraph,\n    delta: float | int = 1,\n    max_order: int = 1,\n    weight: str = \"edge_weight\",\n    cached: bool = True,\n    event_graph: Optional[torch.Tensor] = None,\n) -&gt; MultiOrderModel:\n    \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\n\n    Args:\n        g: The temporal graph.\n        delta: The maximum time difference between two consecutive edges in a path.\n        max_order: The maximum order of the MultiOrderModel that should be computed.\n        weight: The edge attribute to use as edge weight.\n        cached: Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.\n        event_graph: precomputed event graph edge index for given delta to be used for model generation. Useful to prevent the same event graph\n        from being computed twice.\n\n    Returns:\n        MultiOrderModel: A multi-order model where each layer is a De Bruijn graph with order k.\n    \"\"\"\n    m = MultiOrderModel()\n    if not g.data.is_sorted_by_time():\n        data = g.data.sort_by_time()\n    else:\n        data = g.data\n    edge_index = data.edge_index\n    node_sequence = torch.arange(data.num_nodes, device=edge_index.device).unsqueeze(1)\n    if weight in data:\n        edge_weight = data[weight]\n    else:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n    if cached or max_order == 1:\n        m.layers[1] = aggregate_edge_index(\n            edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n        )\n        m.layers[1].mapping = g.mapping\n\n    if max_order &gt; 1:\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n        if event_graph is None:\n            edge_index = lift_order_temporal(g, delta)\n        else:\n            edge_index = event_graph\n        edge_weight = aggregate_node_attributes(edge_index, edge_weight, \"src\")\n\n        # Aggregate\n        if cached or max_order == 2:\n            m.layers[2] = aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[2].mapping = IndexMap(\n                [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n            )\n\n        for k in range(3, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=g.mapping,\n                edge_weight=edge_weight,\n                aggr=\"src\",\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_intermediate_order_log_likelihood","title":"<code>get_intermediate_order_log_likelihood</code>","text":"<p>Compute the intermediate order log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>Multi-order model.</p> required <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>Input DAG graph data.</p> required <code>order</code> <code>int</code> <p>Order of the intermediate log likelihood.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Intermediate order log likelihood.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_intermediate_order_log_likelihood(self, dag_graph: Data, order: int) -&gt; float:\n    \"\"\"\n    Compute the intermediate order log likelihood.\n\n    Args:\n        m (MultiOrderModel): Multi-order model.\n        dag_graph (Data): Input DAG graph data.\n        order (int): Order of the intermediate log likelihood.\n\n    Returns:\n        float: Intermediate order log likelihood.\n    \"\"\"\n    # Get frequencies\n    frequencies = dag_graph.dag_weight\n    path_lengths = dag_graph.dag_num_nodes\n    # paths shrink by 'order' if we encode them using higher-order nodes\n    paths_lenghts_ho = path_lengths - order\n    # selecting only path that didn t shrink to zero due to higher-order transformation\n    paths_lenghts_ho_filtered = paths_lenghts_ho[paths_lenghts_ho &gt; 0]\n    frequencies = frequencies[paths_lenghts_ho &gt; 0]\n    # start index of the path in the higher order space\n    ixs_start_paths_ho = cumsum(paths_lenghts_ho_filtered)[:-1]\n\n    transition_probabilities = self.layers[order].transition_probabilities()[\n        self.layers[order + 1].data.inverse_idx[ixs_start_paths_ho]\n    ]\n\n    log_transition_probabilities = torch.log(transition_probabilities)\n    llh_by_subpath = torch.mul(frequencies, log_transition_probabilities)\n    return llh_by_subpath.sum().item()\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_mon_dof","title":"<code>get_mon_dof</code>","text":"<p>The degrees of freedom for the kth layer of a multi-order model. This depends on the number of different paths of exactly length <code>k</code> in the graph. Therefore, we can obtain these values by summing the entries of the <code>k</code>-th power of the binary adjacency matrix of the graph. Finally, we must consider that, due the conservation of probablility, all non-zero rows of the transition matrix of the higher-order network must sum to one. This poses one additional constraint per row that respects the condition, which should be removed from the total count of degrees of freedom.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The multi-order model.</p> required <code>max_order</code> <code>int</code> <p>The maximum order up to which model layers shall be taken into account. Defaults to None, meaning it considers all available layers.</p> <code>None</code> <code>assumption</code> <code>str</code> <p>If set to 'paths', only paths in the first-order network topology will be considered for the degree of freedom calculation. If set to 'ngrams', all possible n-grams will be considered, independent of whether they are valid paths in the first-order network or not. Defaults to 'paths'.</p> <code>'paths'</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The degrees of freedom for the multi-order model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If max_order is larger than the maximum order of the multi-order network.</p> <code>ValueError</code> <p>If the assumption is not 'paths' or 'ngrams'.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_mon_dof(self, max_order: Optional[int] = None, assumption: str = \"paths\") -&gt; int:\n    \"\"\"\n    The degrees of freedom for the kth layer of a multi-order model. This depends on the number of different paths of exactly length `k` in the graph.\n    Therefore, we can obtain these values by summing the entries of the `k`-th power of the binary adjacency matrix of the graph.\n    Finally, we must consider that, due the conservation of probablility, all non-zero rows of the transition matrix of the higher-order network must sum to one.\n    This poses one additional constraint per row that respects the condition, which should be removed from the total count of degrees of freedom.\n\n    Args:\n        m (MultiOrderModel): The multi-order model.\n        max_order (int, optional): The maximum order up to which model layers\n            shall be taken into account. Defaults to None, meaning it considers\n            all available layers.\n        assumption (str, optional): If set to 'paths', only paths in the\n            first-order network topology will be considered for the degree of\n            freedom calculation. If set to 'ngrams', all possible n-grams will\n            be considered, independent of whether they are valid paths in the\n            first-order network or not. Defaults to 'paths'.\n\n    Returns:\n        int: The degrees of freedom for the multi-order model.\n\n    Raises:\n        ValueError: If max_order is larger than the maximum order of\n            the multi-order network.\n        ValueError: If the assumption is not 'paths' or 'ngrams'.\n    \"\"\"\n    if max_order is None:\n        max_order = max(self.layers)\n\n    if max_order &gt; max(self.layers):\n        logger.error(\"max_order cannot be larger than maximum order of multi-order network\")\n        raise ValueError(\"max_order cannot be larger than maximum order of multi-order network\")\n\n\n    dof = self.layers[1].data.num_nodes - 1  # Degrees of freedom for zeroth order\n\n    if assumption == \"paths\":\n        # COMPUTING CONTRIBUTION FROM NUM PATHS AND NONZERO OUTDEGREES SEPARATELY\n        # TODO: CAN IT BE DONE TOGETHER?\n\n        edge_index = self.layers[1].data.edge_index\n        # Adding dof from Number of paths of length k\n        for k in range(1, max_order + 1):\n            if k &gt; 1:\n                num_nodes = 0 if edge_index.numel() == 0 else edge_index.max().item() + 1\n                edge_index = lift_order_edge_index(edge_index, num_nodes)\n            # counting number of len k paths\n            num_len_k_paths = edge_index.shape[1]  # edge_index.max().item() +1  # Number of paths of length k\n            dof += num_len_k_paths\n\n        # removing dof from total probability of nonzero degree nodes\n        for k in range(1, max_order + 1):\n            if k == 1:\n                # edge_index of temporal graph is sorted by time by default\n                # For matrix multiplication, we need to sort it by row\n                edge_index_adj = self.layers[1].data.edge_index.sort_by(\"row\")[0]\n                edge_index = edge_index_adj\n            else:\n                edge_index, _ = edge_index.matmul(edge_index_adj)\n            num_nonzero_outdegrees = torch.unique(edge_index[0]).size(0)\n            dof -= num_nonzero_outdegrees\n\n    elif assumption == \"ngrams\":\n        for order in range(1, max_order + 1):\n            dof += (self.layers[1].data.num_nodes**order) * (self.layers[1].data.num_nodes - 1)\n    else:\n        logger.error(\"Unknown assumption %s. Only 'path' and 'ngram' are accepted.\", assumption)\n        raise ValueError(\n            f\"Unknown assumption {assumption}. Only 'path' and 'ngram' are accepted.\"\n        )\n\n    return int(dof)\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_mon_log_likelihood","title":"<code>get_mon_log_likelihood</code>","text":"<p>Compute the likelihood of the walks given a multi-order model.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The multi-order model.</p> required <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>Dataset containing the walks.</p> required <code>max_order</code> <code>int</code> <p>The maximum order up to which model layers shall be taken into account. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The log likelihood of the walks given the multi-order model.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_mon_log_likelihood(self, dag_graph: Data, max_order: int = 1) -&gt; float:\n    \"\"\"\n    Compute the likelihood of the walks given a multi-order model.\n\n    Args:\n        m (MultiOrderModel): The multi-order model.\n        dag_graph (Data): Dataset containing the walks.\n        max_order (int, optional): The maximum order up to which model layers\n            shall be taken into account. Defaults to 1.\n\n    Returns:\n        float: The log likelihood of the walks given the multi-order model.\n    \"\"\"\n    llh = 0\n\n    # Adding likelihood of zeroth order\n    llh += self.get_zeroth_order_log_likelihood(dag_graph)\n\n    # Adding the likelihood for all the intermediate orders\n    for order in range(1, max_order):\n        llh += self.get_intermediate_order_log_likelihood(dag_graph, order)\n\n    # Adding the likelihood of highest/stationary order\n    if max_order &gt; 0:\n        transition_probabilities = self.layers[max_order].transition_probabilities(edge_attr=\"edge_weight\")\n        log_transition_probabilities = torch.log(transition_probabilities)\n        llh_by_subpath = log_transition_probabilities * self.layers[max_order].data.edge_weight\n        llh += llh_by_subpath.sum().item()\n    else:\n        # Compute likelihood for zeroth order (to be modified)\n        # TODO: modify once we have zeroth order in mon\n        # (then won t need to compute emission probs from dag_graph -- which also hinders us from computing the lh that a new set of paths was generated by the model)\n        frequencies = dag_graph.dag_weight\n        counts = torch.bincount(\n            dag_graph.node_sequence.squeeze(), frequencies.repeat_interleave(dag_graph.dag_num_nodes)\n        )\n        node_emission_probabilities = counts / counts.sum()\n        llh = torch.mul(torch.log(node_emission_probabilities), counts).sum().item()\n\n    return llh\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_zeroth_order_log_likelihood","title":"<code>get_zeroth_order_log_likelihood</code>","text":"<p>Compute the zeroth order log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>Input DAG graph data.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Zeroth order log likelihood.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_zeroth_order_log_likelihood(self, dag_graph: Data) -&gt; float:\n    \"\"\"\n    Compute the zeroth order log likelihood.\n\n    Args:\n        dag_graph (Data): Input DAG graph data.\n\n    Returns:\n        float: Zeroth order log likelihood.\n    \"\"\"\n    # Get frequencies\n    # getting the index of the last edge of each path (to be used to extract weights)\n    frequencies = dag_graph.dag_weight\n\n    # Get ixs starting nodes\n    # Q: Is dag_graph.path_index[:-1] enough to get the start_ixs?\n    mask = torch.ones(dag_graph.num_nodes, dtype=bool)\n    mask[dag_graph.edge_index[1]] = False\n    start_ixs = dag_graph.node_sequence.squeeze()[mask]\n\n    # Compute node emission probabilities\n    # TODOL modify once we have zeroth order in mon\n    _, counts = torch.unique(dag_graph.node_sequence, return_counts=True)\n    # WARNING: Only works if all nodes in the first-order graph are also in `node_sequence`\n    # Otherwise the missing nodes will not be included in `counts` which can lead to elements at the wrong index.\n    node_emission_probabilities = counts / counts.sum()\n    return torch.mul(frequencies, torch.log(node_emission_probabilities[start_ixs])).sum().item()\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.iterate_lift_order","title":"<code>iterate_lift_order</code>  <code>staticmethod</code>","text":"<p>Lift order by one and save the result in the layers dictionary of the object. This is a helper function that should not be called directly. Only use for edge_indices after the special cases have been handled e.g. in the from_temporal_graph (filtering non-time-respecting paths of order 2).</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of the (k-1)-th order graph.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights of the (k-1)-th order graph.</p> <code>None</code> <code>k</code> <p>The order of the graph that should be computed.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> <code>save</code> <code>bool</code> <p>Whether to compute the aggregated graph and later save it in the layers dictionary.</p> <code>True</code> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>@staticmethod\ndef iterate_lift_order(\n    edge_index: torch.Tensor,\n    node_sequence: torch.Tensor,\n    mapping: IndexMap,\n    edge_weight: torch.Tensor | None = None,\n    aggr: str = \"src\",\n    save: bool = True,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n    \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n    This is a helper function that should not be called directly.\n    Only use for edge_indices after the special cases have been handled e.g.\n    in the from_temporal_graph (filtering non-time-respecting paths of order 2).\n\n    Args:\n        edge_index: The edge index of the (k-1)-th order graph.\n        node_sequence: The node sequences of the (k-1)-th order graph.\n        edge_weight: The edge weights of the (k-1)-th order graph.\n        k: The order of the graph that should be computed.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n    \"\"\"\n    # Lift order\n    if edge_weight is None:\n        ho_index = lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n    else:\n        ho_index, edge_weight = lift_order_edge_index_weighted(\n            edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n        )\n    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n    # Aggregate\n    if save:\n        gk = aggregate_edge_index(ho_index, node_sequence, edge_weight)\n        gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n    else:\n        gk = None\n    return ho_index, node_sequence, edge_weight, gk\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.likelihood_ratio_test","title":"<code>likelihood_ratio_test</code>","text":"<p>Perform a likelihood ratio test to compare two models of different order.</p> <p>Parameters:</p> Name Type Description Default <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>The input DAG graph data.</p> required <code>max_order_null</code> <code>int</code> <p>The maximum order of the null hypothesis model. Defaults to 0.</p> <code>0</code> <code>max_order</code> <code>int</code> <p>The maximum order of the alternative hypothesis model. Defaults to 1.</p> <code>1</code> <code>assumption</code> <code>str</code> <p>The assumption to use for the degrees of freedom calculation. Can be 'paths' or 'ngrams'. Defaults to 'paths'.</p> <code>'paths'</code> <code>significance_threshold</code> <code>float</code> <p>The significance threshold for the test. Defaults to 0.01.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>A tuple containing a boolean indicating whether the null hypothesis is rejected and the p-value of the test.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def likelihood_ratio_test(\n    self,\n    dag_graph: Data,\n    max_order_null: int = 0,\n    max_order: int = 1,\n    assumption: str = \"paths\",\n    significance_threshold: float = 0.01,\n) -&gt; tuple:\n    \"\"\"\n    Perform a likelihood ratio test to compare two models of different order.\n\n    Args:\n        dag_graph (Data): The input DAG graph data.\n        max_order_null (int, optional): The maximum order of the null hypothesis model.\n            Defaults to 0.\n        max_order (int, optional): The maximum order of the alternative hypothesis model.\n            Defaults to 1.\n        assumption (str, optional): The assumption to use for the degrees of freedom calculation.\n            Can be 'paths' or 'ngrams'. Defaults to 'paths'.\n        significance_threshold (float, optional): The significance threshold for the test.\n            Defaults to 0.01.\n\n    Returns:\n        tuple: A tuple containing a boolean indicating whether the null hypothesis is rejected\n            and the p-value of the test.\n    \"\"\"\n    if max_order_null &gt;= max_order:\n        logger.error(\"order of null hypothesis must be smaller than order of alternative hypothesis\")\n        raise ValueError(\"order of null hypothesis must be smaller than order of alternative hypothesis\")\n    if max_order &gt; max(self.layers):\n        logger.error(\"order of hypotheses must be smaller than max. order of MultiOrderModel\")\n        raise ValueError(f\"order of hypotheses ({max_order_null} and {max_order}) must be smaller than max. order of MultiOrderModel {max(self.layers)}\")\n    # let L0 be the likelihood for the null model and L1 be the likelihood for the alternative model\n\n    # we first compute a test statistic x = -2 * log (L0/L1) = -2 * (log L0 - log L1)\n    x = -2 * (\n        self.get_mon_log_likelihood(dag_graph, max_order=max_order_null)\n        - self.get_mon_log_likelihood(dag_graph, max_order=max_order)\n    )\n\n    # we calculate the additional degrees of freedom in the alternative model\n    dof_diff = self.get_mon_dof(max_order, assumption=assumption) - self.get_mon_dof(\n        max_order_null, assumption=assumption\n    )\n\n    # if the p-value is *below* the significance threshold, we reject the null hypothesis\n    p = 1 - chi2.cdf(x, dof_diff)\n    return (p &lt; significance_threshold), p\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.to","title":"<code>to</code>","text":"<p>Convert the graph layers to the given device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>The device to convert the graph layers to.</p> required <p>Returns: The MultiOrderModel with graph layers on the given device.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def to(self, device: torch.device) -&gt; MultiOrderModel:\n    \"\"\"Convert the graph layers to the given device.\n\n    Args:\n        device: The device to convert the graph layers to.\n\n    Returns: The MultiOrderModel with graph layers on the given device.\n    \"\"\"\n    for g in self.layers.values():\n        g.to(device)\n    return self\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.to_dbgnn_data","title":"<code>to_dbgnn_data</code>","text":"<p>Convert the MultiOrderModel to a De Bruijn graph for the given maximum order that can be used in <code>pathpyG.nn.dbgnn.DBGNN</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_order</code> <code>int</code> <p>The maximum order of the De Bruijn graph to be computed.</p> <code>2</code> <code>mapping</code> <code>str</code> <p>The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".</p> <code>'last'</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>torch_geometric.data.Data</code> <p>The De Bruijn graph data.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def to_dbgnn_data(self, max_order: int = 2, mapping: str = \"last\") -&gt; Data:\n    \"\"\"\n    Convert the MultiOrderModel to a De Bruijn graph for the given maximum order\n    that can be used in `pathpyG.nn.dbgnn.DBGNN`.\n\n    Args:\n        max_order: The maximum order of the De Bruijn graph to be computed.\n        mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n\n    Returns:\n        Data: The De Bruijn graph data.\n    \"\"\"\n    if max_order not in self.layers:\n        logger.error(\"Higher-order graph of specified order not found.\")\n        raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n    g = self.layers[1]\n    g_max_order = self.layers[max_order]\n    num_nodes = g.data.num_nodes\n    num_ho_nodes = g_max_order.data.num_nodes\n    if g.data.x is not None:\n        x = g.data.x\n    else:\n        x = torch.eye(num_nodes, num_nodes, device=g.data.edge_index.device)\n    x_max_order = torch.eye(num_ho_nodes, num_ho_nodes, device=g_max_order.data.edge_index.device)\n    edge_index = g.data.edge_index\n    edge_index_max_order = g_max_order.data.edge_index\n    edge_weight = g.data.edge_weight\n    edge_weight_max_order = g_max_order.data.edge_weight\n    bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping, device=edge_index.device)\n\n    if g.data.y is not None:\n        y = g.data.y\n\n    return Data(\n        num_nodes=num_nodes,\n        num_ho_nodes=num_ho_nodes,\n        x=x,\n        x_h=x_max_order,\n        edge_index=edge_index,\n        edge_index_higher_order=edge_index_max_order,\n        edge_weights=edge_weight.float(),\n        edge_weights_higher_order=edge_weight_max_order.float(),\n        bipartite_edge_index=bipartite_edge_index,\n        y=y if \"y\" in locals() else None,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/","title":"data","text":""},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData","title":"<code>PathData</code>","text":"<p>Class that can be used to store multiple observations of node sequences representing paths or walks</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; # Generate toy example graph\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'c'),\n&gt;&gt;&gt;                      ('b', 'c'),\n&gt;&gt;&gt;                      ('c', 'd'),\n&gt;&gt;&gt;                      ('c', 'e')])\n&gt;&gt;&gt; # Store observations of walks using the index mapping\n&gt;&gt;&gt; # from the graph above\n&gt;&gt;&gt; paths = pp.PathData(g.mapping)\n&gt;&gt;&gt; paths.append_walk(('a', 'c', 'd'), weight=2.0)\n&gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=2.0)\n&gt;&gt;&gt; print(paths)\nPathData with 2 paths with total weight 4.0\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>class PathData:\n    \"\"\"Class that can be used to store multiple observations of\n    node sequences representing paths or walks\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; # Generate toy example graph\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'c'),\n        &gt;&gt;&gt;                      ('b', 'c'),\n        &gt;&gt;&gt;                      ('c', 'd'),\n        &gt;&gt;&gt;                      ('c', 'e')])\n        &gt;&gt;&gt; # Store observations of walks using the index mapping\n        &gt;&gt;&gt; # from the graph above\n        &gt;&gt;&gt; paths = pp.PathData(g.mapping)\n        &gt;&gt;&gt; paths.append_walk(('a', 'c', 'd'), weight=2.0)\n        &gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=2.0)\n        &gt;&gt;&gt; print(paths)\n        PathData with 2 paths with total weight 4.0\n    \"\"\"\n\n    def __init__(self, mapping: IndexMap | None = None, device: torch.device | None = None) -&gt; None:\n        if mapping:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n        self.data: Data = Data(\n            edge_index=torch.empty((2, 0), dtype=torch.long, device=device),\n            node_sequence=torch.empty((0, 1), dtype=torch.long, device=device),\n            dag_weight=torch.empty(0, dtype=torch.float, device=device),\n            dag_num_edges=torch.empty(0, dtype=torch.long, device=device),\n            dag_num_nodes=torch.empty(0, dtype=torch.long, device=device),\n        )\n        self.data.num_nodes = 0\n\n    @property\n    def num_paths(self) -&gt; int:\n        \"\"\"Return the number of stored paths.\"\"\"\n        return len(self.data.dag_num_edges)\n\n    def _append_data(\n        self,\n        edge_index: torch.Tensor,\n        node_sequence: torch.Tensor,\n        weights: torch.Tensor,\n        num_edges: torch.Tensor,\n        num_nodes: torch.Tensor,\n    ) -&gt; None:\n        \"\"\"\n        Append a edge_index and node_sequence to the PathData object and\n        reassign the indices so that there is no overlap.\n\n        Args:\n            edge_index: Edge index of the new path(s)\n            node_sequence: Node sequence of the new path(s)\n            weights: Weights of the new path(s)\n            num_edges: Number of edges in the new path(s)\n            num_nodes: Number of nodes in the new path(s)\n        \"\"\"\n        new_edge_index = edge_index + self.data.num_nodes\n        self.data.edge_index = torch.cat([self.data.edge_index, new_edge_index], dim=1)\n        self.data.node_sequence = torch.cat([self.data.node_sequence, node_sequence])\n        self.data.dag_weight = torch.cat([self.data.dag_weight, weights])\n        self.data.dag_num_edges = torch.cat([self.data.dag_num_edges, num_edges])\n        self.data.dag_num_nodes = torch.cat([self.data.dag_num_nodes, num_nodes])\n        self.data.num_nodes += num_nodes.sum().item()\n\n    def to(self, device: torch.device) -&gt; PathData:\n        \"\"\"Moves all paths to the given device.\"\"\"\n        self.data = self.data.to(device)\n        return self\n\n    def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n        \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n        Args:\n            node_seq: List or tuple of node IDs\n            weight: Weight of the walk\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n            &gt;&gt;&gt; walks = pp.PathData(mapping)\n            &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n            &gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=1.0)\n        \"\"\"\n        idx_seq = self.mapping.to_idxs(node_seq, device=self.data.edge_index.device).unsqueeze(1)\n        idx = torch.arange(len(node_seq), device=self.data.edge_index.device)\n        edge_index = torch.stack([idx[:-1], idx[1:]])\n\n        self._append_data(\n            edge_index=edge_index,\n            node_sequence=idx_seq,\n            weights=torch.tensor([weight], device=self.data.edge_index.device),\n            num_edges=torch.tensor([edge_index.shape[1]], device=self.data.edge_index.device),\n            num_nodes=torch.tensor([len(node_seq)], device=self.data.edge_index.device),\n        )\n\n    def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n        \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\n\n        Args:\n            node_seqs: List or tuple of lists or tuples of node IDs\n            weights: List or tuple of weights for each walk\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n            &gt;&gt;&gt; walks = pp.PathData(mapping)\n            &gt;&gt;&gt; walks.append_walks([['a', 'c', 'd'], ['b', 'c', 'e']], [2.0, 1.0])\n        \"\"\"\n        idx_seqs = torch.cat([self.mapping.to_idxs(seq, device=self.data.edge_index.device) for seq in node_seqs]).unsqueeze(1)\n        dag_num_nodes = torch.tensor([len(seq) for seq in node_seqs], device=self.data.edge_index.device)\n\n        big_idx = torch.arange(dag_num_nodes.sum(), device=self.data.edge_index.device)\n        big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n\n        # remove the edges that connect different walks\n        mask = torch.ones(big_edge_index.size(1), dtype=torch.bool, device=self.data.edge_index.device)\n        cum_sum = cumsum(dag_num_nodes, 0)\n        mask[cum_sum[1:-1] - 1] = False\n        big_edge_index = big_edge_index[:, mask]\n\n        self._append_data(\n            edge_index=big_edge_index,\n            node_sequence=idx_seqs,\n            weights=torch.tensor(weights, device=self.data.edge_index.device),\n            num_edges=dag_num_nodes - 1,\n            num_nodes=dag_num_nodes,\n        )\n\n    def get_walk(self, i: int) -&gt; tuple:\n        \"\"\"Return the i-th walk (based on when it was appended) as a tuple of node IDs\n\n        Args:\n            i: Index of the walk to retrieve\n\n        Returns:\n            Tuple of node IDs representing the i-th walk\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n            &gt;&gt;&gt; walks = pp.PathData(mapping)\n            &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n            &gt;&gt;&gt; walks.get_walk(0)\n            ('a', 'c', 'd')\n        \"\"\"\n        start = self.data.dag_num_nodes[:i].sum().item()\n        end = start + self.data.dag_num_nodes[i].item()\n        return tuple(self.mapping.to_ids(self.data.node_sequence[start:end].squeeze()))\n\n    def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n        \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n        return self.mapping.to_ids(node_seq).tolist()\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the PathData object.\"\"\"\n        weight = self.data.dag_weight.sum().item()\n        s = f\"PathData with {self.num_paths} paths with total weight {weight}\"\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.num_paths","title":"<code>num_paths</code>  <code>property</code>","text":"<p>Return the number of stored paths.</p>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the PathData object.</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the PathData object.\"\"\"\n    weight = self.data.dag_weight.sum().item()\n    s = f\"PathData with {self.num_paths} paths with total weight {weight}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.append_walk","title":"<code>append_walk</code>","text":"<p>Add an observation of a walk based on a list or tuple of node IDs or indices</p> <p>Parameters:</p> Name Type Description Default <code>node_seq</code> <code>list | tuple</code> <p>List or tuple of node IDs</p> required <code>weight</code> <code>float</code> <p>Weight of the walk</p> <code>1.0</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n&gt;&gt;&gt; walks = pp.PathData(mapping)\n&gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n&gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=1.0)\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n    \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n    Args:\n        node_seq: List or tuple of node IDs\n        weight: Weight of the walk\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n        &gt;&gt;&gt; walks = pp.PathData(mapping)\n        &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n        &gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=1.0)\n    \"\"\"\n    idx_seq = self.mapping.to_idxs(node_seq, device=self.data.edge_index.device).unsqueeze(1)\n    idx = torch.arange(len(node_seq), device=self.data.edge_index.device)\n    edge_index = torch.stack([idx[:-1], idx[1:]])\n\n    self._append_data(\n        edge_index=edge_index,\n        node_sequence=idx_seq,\n        weights=torch.tensor([weight], device=self.data.edge_index.device),\n        num_edges=torch.tensor([edge_index.shape[1]], device=self.data.edge_index.device),\n        num_nodes=torch.tensor([len(node_seq)], device=self.data.edge_index.device),\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.append_walks","title":"<code>append_walks</code>","text":"<p>Add multiple observations of walks based on lists or tuples of node IDs or indices</p> <p>Parameters:</p> Name Type Description Default <code>node_seqs</code> <code>list | tuple</code> <p>List or tuple of lists or tuples of node IDs</p> required <code>weights</code> <code>list | tuple</code> <p>List or tuple of weights for each walk</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n&gt;&gt;&gt; walks = pp.PathData(mapping)\n&gt;&gt;&gt; walks.append_walks([['a', 'c', 'd'], ['b', 'c', 'e']], [2.0, 1.0])\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n    \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\n\n    Args:\n        node_seqs: List or tuple of lists or tuples of node IDs\n        weights: List or tuple of weights for each walk\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n        &gt;&gt;&gt; walks = pp.PathData(mapping)\n        &gt;&gt;&gt; walks.append_walks([['a', 'c', 'd'], ['b', 'c', 'e']], [2.0, 1.0])\n    \"\"\"\n    idx_seqs = torch.cat([self.mapping.to_idxs(seq, device=self.data.edge_index.device) for seq in node_seqs]).unsqueeze(1)\n    dag_num_nodes = torch.tensor([len(seq) for seq in node_seqs], device=self.data.edge_index.device)\n\n    big_idx = torch.arange(dag_num_nodes.sum(), device=self.data.edge_index.device)\n    big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n\n    # remove the edges that connect different walks\n    mask = torch.ones(big_edge_index.size(1), dtype=torch.bool, device=self.data.edge_index.device)\n    cum_sum = cumsum(dag_num_nodes, 0)\n    mask[cum_sum[1:-1] - 1] = False\n    big_edge_index = big_edge_index[:, mask]\n\n    self._append_data(\n        edge_index=big_edge_index,\n        node_sequence=idx_seqs,\n        weights=torch.tensor(weights, device=self.data.edge_index.device),\n        num_edges=dag_num_nodes - 1,\n        num_nodes=dag_num_nodes,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.get_walk","title":"<code>get_walk</code>","text":"<p>Return the i-th walk (based on when it was appended) as a tuple of node IDs</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>Index of the walk to retrieve</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple of node IDs representing the i-th walk</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n&gt;&gt;&gt; walks = pp.PathData(mapping)\n&gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n&gt;&gt;&gt; walks.get_walk(0)\n('a', 'c', 'd')\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def get_walk(self, i: int) -&gt; tuple:\n    \"\"\"Return the i-th walk (based on when it was appended) as a tuple of node IDs\n\n    Args:\n        i: Index of the walk to retrieve\n\n    Returns:\n        Tuple of node IDs representing the i-th walk\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n        &gt;&gt;&gt; walks = pp.PathData(mapping)\n        &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n        &gt;&gt;&gt; walks.get_walk(0)\n        ('a', 'c', 'd')\n    \"\"\"\n    start = self.data.dag_num_nodes[:i].sum().item()\n    end = start + self.data.dag_num_nodes[i].item()\n    return tuple(self.mapping.to_ids(self.data.node_sequence[start:end].squeeze()))\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.map_node_seq","title":"<code>map_node_seq</code>","text":"<p>Map a sequence of node indices (e.g. representing a higher-order node) to node IDs</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n    \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n    return self.mapping.to_ids(node_seq).tolist()\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.to","title":"<code>to</code>","text":"<p>Moves all paths to the given device.</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def to(self, device: torch.device) -&gt; PathData:\n    \"\"\"Moves all paths to the given device.\"\"\"\n    self.data = self.data.to(device)\n    return self\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/","title":"graph","text":""},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph","title":"<code>TemporalGraph</code>","text":"<p>               Bases: <code>pathpyG.Graph</code></p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>class TemporalGraph(Graph):\n    def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n        \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n        Args:\n            data: PyG `Data` object containing edges saved in `edge_index` and timestamps in `time`.\n            mapping: Optional mapping from node IDs to indices.\n\n        Example:\n            ```py\n            from pytorch_geometric.data import TemporalData\n            import pathpyG as pp\n\n            d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n            t = pp.TemporalGraph(d, mapping)\n            print(t)\n            ```\n        \"\"\"\n        self.data = data\n        if not isinstance(self.data.edge_index, EdgeIndex):\n            self.data.edge_index = EdgeIndex(\n                data=self.data.edge_index.contiguous(), sparse_size=(self.data.num_nodes, self.data.num_nodes)\n            )\n\n        # reorder temporal data\n        # Note that we do not use `torch_geometric.self.data.Data.sort_by_time` because it cannot sort numpy arrays`\n        sorted_idx = torch.argsort(self.data.time)\n        for edge_attr in set(self.data.edge_attrs()).union(set([\"time\"])):\n            if edge_attr == \"edge_index\":\n                self.data.edge_index = self.data.edge_index[:, sorted_idx]\n            else:\n                self.data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        if mapping is not None:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n\n        # create mapping between edge index and edge tuples\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate(self.data.edge_index.t())\n        }\n        self.tedge_to_index = {\n            (e[0].item(), e[1].item(), t.item()): i for i, (e, t) in enumerate(zip([e for e in self.data.edge_index.t()], self.data.time))\n        }\n\n        self.start_time = self.data.time[0].item()\n        self.end_time = self.data.time[-1].item()\n\n    @staticmethod\n    def from_edge_list(edge_list, num_nodes: Optional[int] = None, device: Optional[torch.device] = None) -&gt; TemporalGraph:  # type: ignore\n        \"\"\"Create a temporal graph from a list of tuples containing edges with timestamps.\"\"\"\n        edge_array = np.array(edge_list)\n\n        # Convert timestamps to tensor\n        if isinstance(edge_list[0][2], int):\n            ts = torch.tensor(edge_array[:, 2].astype(np.int_), device=device)\n        else:\n            ts = torch.tensor(edge_array[:, 2].astype(np.double), device=device)\n\n        index_map = IndexMap(np.unique(edge_array[:, :2]))\n        edge_index = index_map.to_idxs(edge_array[:, :2].T, device=device)\n\n        if not num_nodes:\n            num_nodes = index_map.num_ids()\n\n        return TemporalGraph(\n            data=Data(\n                edge_index=edge_index,\n                time=ts,\n                num_nodes=num_nodes,\n            ),\n            mapping=index_map,\n        )\n\n    @property\n    def temporal_edges(self) -&gt; list:\n        \"\"\"Return all temporal edges as a list of tuples (source, destination, timestamp).\n\n        Returns:\n            list: A list of tuples representing temporal edges in the format (source, destination, timestamp).\n\n        Examples:\n            Get the list of temporal edges:\n\n            &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            &gt;&gt;&gt; print(g.temporal_edges)\n            [('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)]\n\n            Iterate over temporal edges:\n            &gt;&gt;&gt; for edge in g.temporal_edges:\n            &gt;&gt;&gt;     print(edge)\n            ('a', 'b', 1)\n            ('b', 'c', 2)\n            ('c', 'a', 3)\n        \"\"\"\n        return [(*self.mapping.to_ids(e), t.item()) for e, t in zip(self.data.edge_index.t(), self.data.time)]\n\n    def to(self, device: torch.device) -&gt; TemporalGraph:\n        \"\"\"Moves all graph data to the specified device (CPU or GPU).\n\n        Args:\n            device: The target device to move the graph data to.\n\n        Returns:\n            TemporalGraph: A new TemporalGraph instance with data on the specified device.\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.time = self.data.time.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        return self\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"Return order 1, since all temporal graphs must be order one.\"\"\"\n        return 1\n\n    def shuffle_time(self) -&gt; None:\n        \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n        self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n\n    def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n        \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n        Args:\n            weighted: whether or not to return a weighted time-aggregated graph\n            time_window: A tuple with start and end time of the aggregation window\n\n        Returns:\n            Graph: A static graph object\n        \"\"\"\n        if time_window is not None:\n            idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n            edge_index = self.data.edge_index[:, idx]\n        else:\n            edge_index = self.data.edge_index\n\n        n = edge_index.max().item() + 1\n\n        if weighted:\n            i, w = torch_geometric.utils.coalesce(\n                edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n            )\n            return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n        else:\n            return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n\n    def to_undirected(self) -&gt; TemporalGraph:\n        \"\"\"Return an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        rev_edge_index = self.data.edge_index.flip([0])\n        edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n        times = torch.cat([self.data.time, self.data.time])\n        return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n\n    def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n        \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given batch defined by start and (non-inclusive) end, where start\n        and end refer to the index of the first and last event in the time-ordered list of events.\"\"\"\n\n        return TemporalGraph(\n            data=Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx]),\n            mapping=self.mapping,\n        )\n\n    def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n        \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given time window defined by start and (non-inclusive) end, where start\n        and end refer to the time stamps\"\"\"\n\n        return TemporalGraph(data=self.data.snapshot(start_time, end_time), mapping=self.mapping)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, temporal edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            # TODO: Get item for non-temporal edges will only return the last occurence of the edge\n            #       This is a limitation and should be fixed in the future.\n            if len(key) == 3:\n                return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n            else:\n                return self.data[key[0]][self.tedge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2]), key[3]]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the graph\n        \"\"\"\n        s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n            self.data.num_nodes,\n            self.data.edge_index.unique(dim=1).size(dim=1),\n            self.data.edge_index.size(1),\n            self.start_time,\n            self.end_time,\n        )\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order 1, since all temporal graphs must be order one.</p>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.temporal_edges","title":"<code>temporal_edges</code>  <code>property</code>","text":"<p>Return all temporal edges as a list of tuples (source, destination, timestamp).</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of tuples representing temporal edges in the format (source, destination, timestamp).</p> <p>Examples:</p> <p>Get the list of temporal edges:</p> <pre><code>&gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n&gt;&gt;&gt; print(g.temporal_edges)\n[('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)]\n</code></pre> <p>Iterate over temporal edges:</p> <pre><code>&gt;&gt;&gt; for edge in g.temporal_edges:\n&gt;&gt;&gt;     print(edge)\n('a', 'b', 1)\n('b', 'c', 2)\n('c', 'a', 3)\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, temporal edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, temporal edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        # TODO: Get item for non-temporal edges will only return the last occurence of the edge\n        #       This is a limitation and should be fixed in the future.\n        if len(key) == 3:\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            return self.data[key[0]][self.tedge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2]), key[3]]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.__init__","title":"<code>__init__</code>","text":"<p>Creates an instance of a temporal graph from a <code>TemporalData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>PyG <code>Data</code> object containing edges saved in <code>edge_index</code> and timestamps in <code>time</code>.</p> required <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>Optional mapping from node IDs to indices.</p> <code>None</code> Example <pre><code>from pytorch_geometric.data import TemporalData\nimport pathpyG as pp\n\nd = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\nt = pp.TemporalGraph(d, mapping)\nprint(t)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n    \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n    Args:\n        data: PyG `Data` object containing edges saved in `edge_index` and timestamps in `time`.\n        mapping: Optional mapping from node IDs to indices.\n\n    Example:\n        ```py\n        from pytorch_geometric.data import TemporalData\n        import pathpyG as pp\n\n        d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n        t = pp.TemporalGraph(d, mapping)\n        print(t)\n        ```\n    \"\"\"\n    self.data = data\n    if not isinstance(self.data.edge_index, EdgeIndex):\n        self.data.edge_index = EdgeIndex(\n            data=self.data.edge_index.contiguous(), sparse_size=(self.data.num_nodes, self.data.num_nodes)\n        )\n\n    # reorder temporal data\n    # Note that we do not use `torch_geometric.self.data.Data.sort_by_time` because it cannot sort numpy arrays`\n    sorted_idx = torch.argsort(self.data.time)\n    for edge_attr in set(self.data.edge_attrs()).union(set([\"time\"])):\n        if edge_attr == \"edge_index\":\n            self.data.edge_index = self.data.edge_index[:, sorted_idx]\n        else:\n            self.data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    if mapping is not None:\n        self.mapping = mapping\n    else:\n        self.mapping = IndexMap()\n\n    # create mapping between edge index and edge tuples\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate(self.data.edge_index.t())\n    }\n    self.tedge_to_index = {\n        (e[0].item(), e[1].item(), t.item()): i for i, (e, t) in enumerate(zip([e for e in self.data.edge_index.t()], self.data.time))\n    }\n\n    self.start_time = self.data.time[0].item()\n    self.end_time = self.data.time[-1].item()\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the graph\n    \"\"\"\n    s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n        self.data.num_nodes,\n        self.data.edge_index.unique(dim=1).size(dim=1),\n        self.data.edge_index.size(1),\n        self.start_time,\n        self.end_time,\n    )\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Create a temporal graph from a list of tuples containing edges with timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(edge_list, num_nodes: Optional[int] = None, device: Optional[torch.device] = None) -&gt; TemporalGraph:  # type: ignore\n    \"\"\"Create a temporal graph from a list of tuples containing edges with timestamps.\"\"\"\n    edge_array = np.array(edge_list)\n\n    # Convert timestamps to tensor\n    if isinstance(edge_list[0][2], int):\n        ts = torch.tensor(edge_array[:, 2].astype(np.int_), device=device)\n    else:\n        ts = torch.tensor(edge_array[:, 2].astype(np.double), device=device)\n\n    index_map = IndexMap(np.unique(edge_array[:, :2]))\n    edge_index = index_map.to_idxs(edge_array[:, :2].T, device=device)\n\n    if not num_nodes:\n        num_nodes = index_map.num_ids()\n\n    return TemporalGraph(\n        data=Data(\n            edge_index=edge_index,\n            time=ts,\n            num_nodes=num_nodes,\n        ),\n        mapping=index_map,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.get_batch","title":"<code>get_batch</code>","text":"<p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given batch defined by start and (non-inclusive) end, where start and end refer to the index of the first and last event in the time-ordered list of events.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n    \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given batch defined by start and (non-inclusive) end, where start\n    and end refer to the index of the first and last event in the time-ordered list of events.\"\"\"\n\n    return TemporalGraph(\n        data=Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx]),\n        mapping=self.mapping,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.get_window","title":"<code>get_window</code>","text":"<p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given time window defined by start and (non-inclusive) end, where start and end refer to the time stamps</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n    \"\"\"Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given time window defined by start and (non-inclusive) end, where start\n    and end refer to the time stamps\"\"\"\n\n    return TemporalGraph(data=self.data.snapshot(start_time, end_time), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.shuffle_time","title":"<code>shuffle_time</code>","text":"<p>Randomly shuffle the temporal order of edges by randomly permuting timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def shuffle_time(self) -&gt; None:\n    \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n    self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.to","title":"<code>to</code>","text":"<p>Moves all graph data to the specified device (CPU or GPU).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>The target device to move the graph data to.</p> required <p>Returns:</p> Name Type Description <code>TemporalGraph</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>A new TemporalGraph instance with data on the specified device.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; TemporalGraph:\n    \"\"\"Moves all graph data to the specified device (CPU or GPU).\n\n    Args:\n        device: The target device to move the graph data to.\n\n    Returns:\n        TemporalGraph: A new TemporalGraph instance with data on the specified device.\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.time = self.data.time.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    return self\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.to_static_graph","title":"<code>to_static_graph</code>","text":"<p>Return weighted time-aggregated instance of <code>Graph</code> graph.</p> <p>Parameters:</p> Name Type Description Default <code>weighted</code> <code>bool</code> <p>whether or not to return a weighted time-aggregated graph</p> <code>False</code> <code>time_window</code> <code>typing.Optional[typing.Tuple[int, int]]</code> <p>A tuple with start and end time of the aggregation window</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.Graph</code> <p>A static graph object</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n    \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n    Args:\n        weighted: whether or not to return a weighted time-aggregated graph\n        time_window: A tuple with start and end time of the aggregation window\n\n    Returns:\n        Graph: A static graph object\n    \"\"\"\n    if time_window is not None:\n        idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n        edge_index = self.data.edge_index[:, idx]\n    else:\n        edge_index = self.data.edge_index\n\n    n = edge_index.max().item() + 1\n\n    if weighted:\n        i, w = torch_geometric.utils.coalesce(\n            edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n    else:\n        return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_undirected(self) -&gt; TemporalGraph:\n    \"\"\"Return an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    rev_edge_index = self.data.edge_index.flip([0])\n    edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n    times = torch.cat([self.data.time, self.data.time])\n    return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/io/","title":"io","text":""},{"location":"reference/pathpyG/io/netzschleuder/","title":"netzschleuder","text":""},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.list_netzschleuder_records","title":"<code>list_netzschleuder_records</code>","text":"<p>Read a list of data sets available at the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <code>**kwargs</code> <code>typing.Any</code> <p>Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters. For supported parameters see https://networks.skewed.de/api</p> <code>{}</code> <p>Examples:</p> <p>Return a list of all data sets</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; pp.io.list_netzschleuder_records()\n['karate', 'reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a list of all data sets with a given tag</p> <pre><code>&gt;&gt;&gt; pp.io.list_netzschleuder_records(tags='temporal')\n['reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a dictionary containing all data set names (keys) as well as all network attributes</p> <pre><code>&gt;&gt;&gt; pp.io.list_netzschleuder_records(full=True)\n{ 'reality_mining': [...], 'karate': [...] }\n</code></pre> <p>Returns:</p> Type Description <code>typing.Union[list, dict]</code> <p>Either a list of data set names or a dictionary containing all data set names and network attributes.</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def list_netzschleuder_records(base_url: str = \"https://networks.skewed.de\", **kwargs: Any) -&gt; Union[list, dict]:\n    \"\"\"\n    Read a list of data sets available at the netzschleuder repository.\n\n    Args:\n        base_url: Base URL of netzschleuder repository\n        **kwargs: Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters.\n            For supported parameters see https://networks.skewed.de/api\n\n\n    Examples:\n        Return a list of all data sets\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; pp.io.list_netzschleuder_records()\n        ['karate', 'reality_mining', 'sp_hypertext', ...]\n\n        Return a list of all data sets with a given tag\n\n        &gt;&gt;&gt; pp.io.list_netzschleuder_records(tags='temporal')\n        ['reality_mining', 'sp_hypertext', ...]\n\n        Return a dictionary containing all data set names (keys) as well as all network attributes\n\n        &gt;&gt;&gt; pp.io.list_netzschleuder_records(full=True)\n        { 'reality_mining': [...], 'karate': [...] }\n\n\n    Returns:\n        Either a list of data set names or a dictionary containing all data set names and network attributes.\n\n    \"\"\"\n    url = \"/api/nets\"\n    for k, v in kwargs.items():\n        url += \"?{0}={1}\".format(k, v)\n    try:\n        f = request.urlopen(base_url + url).read()\n        return json.loads(f)\n    except HTTPError:\n        msg = \"Could not connect to netzschleuder repository at {0}\".format(base_url)\n        # LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_graph","title":"<code>read_netzschleuder_graph</code>","text":"<p>Read a graph or temporal graph from the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the network data set to read from</p> required <code>network</code> <code>typing.Optional[str]</code> <p>Identifier of the network within the data set to read. For data sets containing a single network only, this can be set to None.</p> <code>None</code> <code>ignore_temporal</code> <p>If False, this function will return a static or temporal network depending on whether edges contain a time attribute. If True, pathpy will not interpret time attributes and thus always return a static network.</p> required <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <p>Examples:</p> <p>Read network '77' from karate club data set</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; n = pp.io.read_netzschleuder_network(name='karate', network='77')\n&gt;&gt;&gt; print(type(n))\n&gt;&gt;&gt; pp.plot(n)\npp.Graph\n</code></pre> <p>Returns:</p> Type Description <code>typing.Union[pathpyG.core.graph.Graph, pathpyG.core.temporal_graph.TemporalGraph]</code> <p>Graph or TemporalGraph object</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_graph(\n    name: str,\n    network: Optional[str] = None,\n    multiedges: bool = False,\n    time_attr: Optional[str] = None,\n    base_url: str = \"https://networks.skewed.de\"\n) -&gt; Union[Graph, TemporalGraph]:\n    \"\"\"Read a graph or temporal graph from the netzschleuder repository.\n\n    Args:\n        name: Name of the network data set to read from\n        network: Identifier of the network within the data set to read. For data sets\n            containing a single network only, this can be set to None.\n        ignore_temporal: If False, this function will return a static or temporal network depending\n            on whether edges contain a time attribute. If True, pathpy will not interpret\n            time attributes and thus always return a static network.\n        base_url: Base URL of netzschleuder repository\n\n    Examples:\n        Read network '77' from karate club data set\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; n = pp.io.read_netzschleuder_network(name='karate', network='77')\n        &gt;&gt;&gt; print(type(n))\n        &gt;&gt;&gt; pp.plot(n)\n        pp.Graph\n\n    Returns:\n        Graph or TemporalGraph object\n    \"\"\"\n    # build URL\n    try:\n        # retrieve properties of data record via API\n        properties = json.loads(request.urlopen(f\"{base_url}/api/net/{name}\").read())\n\n        timestamps = not (time_attr is None)\n\n        if not network:\n            analyses = properties[\"analyses\"]\n            network = name\n        else:\n            analyses = properties[\"analyses\"][network]\n\n        try:\n            is_directed = analyses[\"is_directed\"]\n            num_nodes = analyses[\"num_vertices\"]\n        except KeyError as exc:\n            raise Exception(f\"Record {name} contains multiple networks, please specify network name.\") from exc\n\n        # Retrieve CSV data\n        url = f\"{base_url}/net/{name}/files/{network}.csv.zip\"\n        try:\n            response = request.urlopen(url)\n\n            # decompress zip into temporary folder\n            data = BytesIO(response.read())\n\n            with zipfile.ZipFile(data, \"r\") as zip_ref:\n                with tempfile.TemporaryDirectory() as temp_dir:\n                    zip_ref.extractall(path=temp_dir)\n\n                    # the gprop file contains lines with property name/value pairs\n                    # gprops = pd.read_csv(f'{temp_dir}/gprops.csv', header=0, sep=',', \n                    #           skip_blank_lines=True, skipinitialspace=True)\n\n                    # nodes.csv contains node indices with node properties (like name)\n                    edges = pd.read_csv(\n                        f\"{temp_dir}/edges.csv\", header=0, sep=\",\", skip_blank_lines=True, skipinitialspace=True\n                    )\n\n                    # rename columns\n                    edges.rename(columns={\"# source\": \"v\", \"target\": \"w\"}, inplace=True)\n                    if timestamps and time_attr:\n                        edges.rename(columns={time_attr: \"t\"}, inplace=True)\n\n                    # construct graph and assign edge attributes\n                    if timestamps:\n                        g = df_to_temporal_graph(df=edges, multiedges=multiedges, num_nodes=num_nodes)\n                    else:\n                        g = df_to_graph(df=edges, multiedges=multiedges,\n                                        is_undirected=not is_directed, num_nodes=num_nodes)\n\n                    node_attrs = pd.read_csv(\n                        f\"{temp_dir}/nodes.csv\", header=0, sep=\",\", skip_blank_lines=True, skipinitialspace=True\n                    )\n                    node_attrs.rename(columns={\"# index\": \"index\"}, inplace=True)\n\n                    add_node_attributes(node_attrs, g)\n\n                    # add graph-level attributes\n                    for x in analyses:\n                        g.data[\"analyses_\" + x] = analyses[x]\n\n                    return g\n        except HTTPError as exc:\n            msg = f\"Could not retrieve netzschleuder record at {url}\"\n            raise Exception(msg) from exc\n    except HTTPError as exc:\n        msg = f\"Could not retrieve netzschleuder record at {base_url}/api/net/{name}\"\n        raise Exception(msg) from exc\n    return None\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_record","title":"<code>read_netzschleuder_record</code>","text":"<p>Read metadata of a single data record with given name from the netzschleuder repository</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the data set for which to retrieve the metadata</p> required <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <p>Examples:</p> <p>Retrieve metadata of karate club network</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; metdata = pp.io.read_netzschleuder_record('karate')\n&gt;&gt;&gt; print(metadata)\n{\n    'analyses': {'77': {'average_degree': 4.52... } }\n}\n</code></pre> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing key-value pairs of metadata</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_record(name: str, base_url: str = \"https://networks.skewed.de\") -&gt; dict:\n    \"\"\"\n    Read metadata of a single data record with given name from the netzschleuder repository\n\n    Args:\n        name: Name of the data set for which to retrieve the metadata\n        base_url: Base URL of netzschleuder repository\n\n    Examples:\n        Retrieve metadata of karate club network\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; metdata = pp.io.read_netzschleuder_record('karate')\n        &gt;&gt;&gt; print(metadata)\n        {\n            'analyses': {'77': {'average_degree': 4.52... } }\n        }\n\n    Returns:\n        Dictionary containing key-value pairs of metadata\n    \"\"\"\n    url = f\"/api/net/{name}\"\n    try:\n        return json.loads(request.urlopen(base_url + url).read())\n    except HTTPError as exc:\n        msg = f\"Could not connect to netzschleuder repository at {base_url}\"\n        # LOG.error(msg)\n        raise Exception(msg) from exc\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/","title":"pandas","text":""},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.add_edge_attributes","title":"<code>add_edge_attributes</code>","text":"<p>Add (temporal) edge attributes from pandas data frame to existing <code>Graph</code>.</p> <p>Add edge attributes from <code>pandas.DataFrame</code> to existing <code>Graph</code>, where source/target node IDs are given in columns <code>v</code> and <code>w</code>  and edge attributes x are given in columns <code>edge_x</code>. If <code>time_attr</code> is not None, the dataframe is expected to contain temporal data with a timestamp in a column named as specified in <code>time_attr</code>.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>A DataFrame with rows containing edges and optional edge attributes.</p> required <code>g</code> <code>pathpyG.core.graph.Graph</code> <p>The graph to which the edge attributes should be added.</p> required <code>time_attr</code> <code>str | None</code> <p>If not None, the name of the column containing time stamps for temporal edges.</p> <code>None</code> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def add_edge_attributes(df: pd.DataFrame, g: Graph, time_attr: str | None = None) -&gt; None:\n    \"\"\"Add (temporal) edge attributes from pandas data frame to existing `Graph`.\n\n    Add edge attributes from `pandas.DataFrame` to existing `Graph`, where source/target node\n    IDs are given in columns `v` and `w`  and edge attributes x are given in columns `edge_x`.\n    If `time_attr` is not None, the dataframe is expected to contain temporal data with a timestamp\n    in a column named as specified in `time_attr`.\n\n    Args:\n        df: A DataFrame with rows containing edges and optional edge attributes.\n        g: The graph to which the edge attributes should be added.\n        time_attr: If not None, the name of the column containing time stamps for temporal edges.\n    \"\"\"\n    if \"v\" not in df or \"w\" not in df:\n        logger.error(\"Data frame must have columns `v` and `w` for source and target nodes\")\n        raise ValueError(\"Data frame must have columns `v` and `w` for source and target nodes\")\n\n    # check for non-existent nodes\n    node_ids = set(df[\"v\"]).union(set(df[\"w\"]))\n    if not node_ids.issubset(set(g.nodes)):\n        raise ValueError(\n            f\"DataFrame contains nodes {node_ids - set(g.nodes)} that do not exist in the graph. \"\n            \"Please ensure all nodes in the DataFrame are present in the graph.\"\n        )\n\n    # check if the number of edges in the data frame is consistent with the graph\n    if g.m != len(df):\n        raise ValueError(\n            f\"DataFrame contains {len(df)} edges, but the graph has {g.m} edges. \"\n            \"Please ensure the DataFrame matches the number of edges in the graph.\"\n        )\n\n    # extract indices of source/target node of edges\n    src = g.mapping.to_idxs(df[\"v\"].tolist())\n    tgt = g.mapping.to_idxs(df[\"w\"].tolist())\n\n    edge_attrs = [attr for attr in df.columns if attr not in [\"v\", \"w\"]]\n\n    if time_attr is not None:\n        if time_attr not in df:\n            logger.error(\"Data frame must have column %s for time stamps\", time_attr)\n            raise ValueError(f\"Data frame must have column {time_attr} for time stamps\")\n\n        time = df[time_attr].values\n        edge_attrs.remove(time_attr)\n\n        # find indices of edges in temporal edge_index\n        edge_idx = []\n        for src_i, tgt_i, time_i in zip(src, tgt, time):\n            edge = g.tedge_to_index.get((src_i.item(), tgt_i.item(), time_i.item()), None)  # type: ignore\n            if edge is None:\n                logger.error(\"found non-existing edge in temporal graph\")\n                raise ValueError(\n                    f\"Edge ({src_i.item()}, {tgt_i.item()}) does not exist at time {time_i.item()} in the graph.\"\n                )\n            edge_idx.append(edge)\n    else:\n        # find indices of edges in edge_index\n        edge_idx = []\n        for src_i, tgt_i in zip(src, tgt):\n            edge = g.edge_to_index.get((src_i.item(), tgt_i.item()), None)\n            if edge is None:\n                logger.error(\"found non-existing edge in temporal graph\")\n                raise ValueError(f\"Edge ({src_i.item()}, {tgt_i.item()}) does not exist in the graph.\")\n            edge_idx.append(edge)\n\n    for attr in edge_attrs:\n        if attr.startswith(\"edge_\"):\n            prefix = \"\"\n        else:\n            prefix = \"edge_\"\n\n        # parse column and add to graph\n        _parse_df_column(\n            df=df.iloc[edge_idx],\n            data=g.data,\n            attr=attr,\n            prefix=prefix,\n        )\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.add_node_attributes","title":"<code>add_node_attributes</code>","text":"<p>Add node attributes from <code>DataFrame</code> to existing <code>Graph</code>.</p> <p>Add node attributes from <code>pandas.DataFrame</code> to existing graph, where node IDs or indices are given in column <code>v</code> and node attributes x are given in columns <code>node_x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>A DataFrame with rows containing nodes and optional node attributes.</p> required <code>g</code> <code>pathpyG.core.graph.Graph</code> <p>The graph to which the node attributes should be added.</p> required Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def add_node_attributes(df: pd.DataFrame, g: Graph):\n    \"\"\"Add node attributes from `DataFrame` to existing `Graph`.\n\n    Add node attributes from `pandas.DataFrame` to existing graph, where node\n    IDs or indices are given in column `v` and node attributes x are given in columns `node_x`.\n\n    Args:\n        df: A DataFrame with rows containing nodes and optional node attributes.\n        g: The graph to which the node attributes should be added.\n    \"\"\"\n    if \"v\" in df:\n        logger.debug(\"Mapping node attributes based on node names in column `v`\")\n        attributed_nodes = list(df[\"v\"])\n    elif \"index\" in df:\n        logger.debug(\"Mapping node attributes based on node indices in column `index`\")\n        attributed_nodes = list(df[\"index\"])\n    else:\n        raise ValueError(\"DataFrame must either have `index` or `v` column\")\n\n    # check for duplicated node attributes\n    if len(set(attributed_nodes)) &lt; len(attributed_nodes):\n        raise ValueError(\"DataFrame cannot contain multiple attribute values for single node\")\n\n    # check for difference between nodes in graph and nodes in attributes\n    if \"v\" in df:\n        if set(attributed_nodes) != set([v for v in g.nodes]):\n            raise ValueError(\"Mismatch between nodes in DataFrame and nodes in graph\")\n\n        # get indices of nodes in tensor\n        node_idx = g.mapping.to_idxs(attributed_nodes).tolist()\n    else:\n        if set(attributed_nodes) != set([i for i in range(g.n)]):\n            raise ValueError(\"Mismatch between nodes in DataFrame and nodes in graph\")\n\n        # get indices of nodes in tensor\n        node_idx = attributed_nodes\n\n    # assign node property tensors\n    cols = [attr for attr in df.columns if attr not in [\"v\", \"index\"]]\n    for attr in cols:\n        # prefix attribute names that are not already prefixed\n        if attr.startswith(\"node_\"):\n            prefix = \"\"\n        else:\n            prefix = \"node_\"\n\n        _parse_df_column(\n            df=df,\n            data=g.data,\n            idx=node_idx,\n            attr=attr,\n            prefix=prefix,\n        )\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.df_to_graph","title":"<code>df_to_graph</code>","text":"<p>Reads a network from a pandas data frame.</p> <p>The data frame is expected to have a minimum of two columns that give the source and target nodes of edges. Additional columns in the data frame will be mapped to edge attributes.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>A data frame with rows containing edges and optional edge attributes. If the data frame contains column names, the source and target columns must be called 'v' and 'w' respectively. If no column names are used the first two columns are interpreted as source and target.</p> required <code>is_undirected</code> <code>bool</code> <p>Whether or not to interpret edges as undirected.</p> <code>False</code> <code>multiedges</code> <code>bool</code> <p>Whether or not to allow multiple edges between the same node pair. By default multi edges are ignored.</p> <code>False</code> <code>num_nodes</code> <code>int | None</code> <p>The number of nodes in the graph. If None, the number of unique nodes in the data frame is used.</p> <code>None</code> Example <pre><code>import pathpyG as pp\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'v': ['a', 'b', 'c'],\n    'w': ['b', 'c', 'a'],\n    'edge_weight': [1.0, 5.0, 2.0]\n    })\ng = pp.io.df_to_graph(df)\nprint(n)\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def df_to_graph(\n    df: pd.DataFrame, is_undirected: bool = False, multiedges: bool = False, num_nodes: int | None = None\n) -&gt; Graph:\n    \"\"\"Reads a network from a pandas data frame.\n\n    The data frame is expected to have a minimum of two columns\n    that give the source and target nodes of edges. Additional columns in the\n    data frame will be mapped to edge attributes.\n\n    Args:\n        df: A data frame with rows containing edges and optional edge attributes. If the\n            data frame contains column names, the source and target columns must be called\n            'v' and 'w' respectively. If no column names are used the first two columns\n            are interpreted as source and target.\n        is_undirected: Whether or not to interpret edges as undirected.\n        multiedges: Whether or not to allow multiple edges between the same node pair. By\n            default multi edges are ignored.\n        num_nodes: The number of nodes in the graph. If None, the number of unique nodes\n            in the data frame is used.\n\n    Example:\n        ```py\n\n        import pathpyG as pp\n        import pandas as pd\n\n        df = pd.DataFrame({\n            'v': ['a', 'b', 'c'],\n            'w': ['b', 'c', 'a'],\n            'edge_weight': [1.0, 5.0, 2.0]\n            })\n        g = pp.io.df_to_graph(df)\n        print(n)\n        ```\n    \"\"\"\n    # assign column names if no header is present\n    no_header = all(isinstance(x, int) for x in df.columns.values.tolist())\n\n    if no_header:\n        # interpret first two columns as source and target\n        col_names = [\"v\", \"w\"]\n        # interpret remaining columns as edge attributes\n        for i in range(2, len(df.columns.values.tolist())):\n            col_names += [f\"edge_attr_{i - 2}\"]\n        df.columns = col_names\n\n    # optionally remove multiedges\n    if not multiedges and df[[\"v\", \"w\"]].duplicated().any():\n        logger.debug(\"Data frame contains multiple edges, but multiedges is set to False. Removing duplicates.\")\n        df = df.drop_duplicates(subset=[\"v\", \"w\"])\n\n    # Create index mapping and data object\n    mapping = IndexMap(node_ids=np.unique(df[[\"v\", \"w\"]].values).tolist())\n    data = Data(\n        edge_index=mapping.to_idxs(df[[\"v\", \"w\"]].values.T),\n        num_nodes=num_nodes if num_nodes is not None else mapping.node_ids.shape[0],  # type: ignore\n    )\n\n    # Parse all columns except 'v' and 'w' as edge attributes\n    cols = df.columns.tolist()\n    cols.remove(\"v\")\n    cols.remove(\"w\")\n    for col in cols:\n        if col.startswith(\"edge_\"):\n            prefix = \"\"\n        else:\n            prefix = \"edge_\"\n\n        _parse_df_column(df=df, data=data, attr=col, prefix=prefix)\n\n    # Create graph object\n    g = Graph(data=data, mapping=mapping)\n    # If the graph should be undirected, convert it to an undirected graph\n    if is_undirected:\n        g = g.to_undirected()\n\n    return g\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.df_to_temporal_graph","title":"<code>df_to_temporal_graph</code>","text":"<p>Read a temporal graph from a DataFrame.</p> <p>The DataFrame is expected to have a minimum of two columns <code>v</code> and <code>w</code> that give the source and target nodes of edges. Each row in the DataFrame is mapped to one temporal edge. Additional columns in the DataFrame will be mapped to edge attributes.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>pandas.DataFrame with rows containing time-stamped edges and optional edge attributes.</p> required <code>multiedges</code> <code>bool</code> <p>Whether or not to allow multiple edges between the same node pair. By default multi edges are ignored.</p> <code>False</code> <code>timestamp_format</code> <p>The format of the time stamps in the <code>t</code> column.</p> <code>'%Y-%m-%d %H:%M:%S'</code> <code>time_rescale</code> <p>The factor by which to rescale the time stamps. Defaults to 1, meaning no rescaling.</p> <code>1</code> <code>num_nodes</code> <code>int | None</code> <p>The number of nodes in the graph. If None, the number of unique nodes in the DataFrame is used.</p> <code>None</code> Example <pre><code>import pathpyG as pp\nimport pandas as pd\ndf = pd.DataFrame({\n    'v': ['a', 'b', 'c'],\n    'w': ['b', 'c', 'a'],\n    't': [1, 2, 3]})\ng = pp.io.df_to_temporal_graph(df)\nprint(g)\n\ndf = pd.DataFrame([\n    ['a', 'b', 'c'],\n    ['b', 'c', 'a'],\n    [1, 2, 3]\n    ])\ng = pp.io.df_to_temporal_graph(df)\nprint(g)\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def df_to_temporal_graph(\n    df: pd.DataFrame,\n    multiedges: bool = False,\n    timestamp_format=\"%Y-%m-%d %H:%M:%S\",\n    time_rescale=1,\n    num_nodes: int | None = None,\n) -&gt; TemporalGraph:\n    \"\"\"Read a temporal graph from a DataFrame.\n\n    The DataFrame is expected to have a minimum of two columns `v` and `w`\n    that give the source and target nodes of edges. Each row in the DataFrame is\n    mapped to one temporal edge. Additional columns in the DataFrame will be\n    mapped to edge attributes.\n\n    Args:\n        df: pandas.DataFrame with rows containing time-stamped edges and optional edge\n            attributes.\n        multiedges: Whether or not to allow multiple edges between the same node pair. By\n            default multi edges are ignored.\n        timestamp_format: The format of the time stamps in the `t` column.\n        time_rescale: The factor by which to rescale the time stamps. Defaults to 1, meaning no rescaling.\n        num_nodes: The number of nodes in the graph. If None, the number of unique nodes\n            in the DataFrame is used.\n\n    Example:\n        ```py\n\n        import pathpyG as pp\n        import pandas as pd\n        df = pd.DataFrame({\n            'v': ['a', 'b', 'c'],\n            'w': ['b', 'c', 'a'],\n            't': [1, 2, 3]})\n        g = pp.io.df_to_temporal_graph(df)\n        print(g)\n\n        df = pd.DataFrame([\n            ['a', 'b', 'c'],\n            ['b', 'c', 'a'],\n            [1, 2, 3]\n            ])\n        g = pp.io.df_to_temporal_graph(df)\n        print(g)\n        ```\n    \"\"\"\n    # assign column names if no header is present\n    no_header = all(isinstance(x, int) for x in df.columns.values.tolist())\n\n    if no_header:\n        # interpret first two columns as source and target\n        logger.info(\"Interpreting first three columns as v, w, t\")\n        col_names = [\"v\", \"w\", \"t\"]\n        # interpret remaining columns as edge attributes\n        for i in range(3, len(df.columns.values.tolist())):\n            col_names += [\"edge_attr_{0}\".format(i - 2)]\n        df.columns = col_names\n\n    # parse the time stamp column \"t\"\n    _parse_timestamp(df=df, timestamp_format=timestamp_format, time_rescale=time_rescale)\n\n    # optionally remove multiedges\n    if not multiedges:\n        df = df.drop_duplicates(subset=[\"v\", \"w\", \"t\"])\n\n    # Create index mapping and data object\n    mapping = IndexMap(node_ids=np.unique(df[[\"v\", \"w\"]].values))\n    data = Data(\n        edge_index=mapping.to_idxs(df[[\"v\", \"w\"]].values.T),\n        time=torch.tensor(df[\"t\"].values),\n        num_nodes=num_nodes if num_nodes is not None else mapping.node_ids.shape[0],  # type: ignore\n    )\n\n    # add edge attributes\n    cols = [col for col in df.columns if col not in [\"v\", \"w\", \"t\"]]\n    for col in cols:\n        if col.startswith(\"edge_\"):\n            prefix = \"\"\n        else:\n            prefix = \"edge_\"\n\n        _parse_df_column(df=df, data=data, attr=col, prefix=prefix)\n\n    # Create temporal graph object\n    g = TemporalGraph(data=data, mapping=mapping)\n\n    return g\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.graph_to_df","title":"<code>graph_to_df</code>","text":"<p>Return a DataFrame for a given graph.</p> <p>Returns a <code>pandas.DataFrame</code> that contains all edges including edge attributes. Node and network-level attributes are not included. To facilitate the import into network analysis tools that only support integer node identifiers, node uids can be replaced by a consecutive, zero-based index.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph to export as pandas DataFrame</p> required <code>node_indices</code> <code>typing.Optional[bool]</code> <p>whether nodes should be exported as integer indices</p> <code>False</code> Example <pre><code>import pathpyG as pp\n\nn = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\ndf = pp.io.to_dataframe(n)\nprint(df)\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def graph_to_df(graph: Graph, node_indices: Optional[bool] = False) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame for a given graph.\n\n    Returns a `pandas.DataFrame` that contains all edges including edge\n    attributes. Node and network-level attributes are not included. To\n    facilitate the import into network analysis tools that only support integer\n    node identifiers, node uids can be replaced by a consecutive, zero-based\n    index.\n\n    Args:\n        graph: The graph to export as pandas DataFrame\n        node_indices: whether nodes should be exported as integer indices\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        n = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        df = pp.io.to_dataframe(n)\n        print(df)\n        ```\n    \"\"\"\n    if node_indices:\n        vs = to_numpy(graph.data.edge_index[0])\n        ws = to_numpy(graph.data.edge_index[1])\n    else:\n        vs = graph.mapping.to_ids(to_numpy(graph.data.edge_index[0]))\n        ws = graph.mapping.to_ids(to_numpy(graph.data.edge_index[1]))\n    df = pd.DataFrame({**{\"v\": vs, \"w\": ws}, **{a: graph.data[a].tolist() for a in graph.edge_attrs()}})\n\n    return df\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.read_csv_graph","title":"<code>read_csv_graph</code>","text":"<p>Read a <code>Graph</code> from a csv file.</p> <p>This method reads a graph from a <code>.csv</code>-file and converts it to a <code>Graph</code> object. To read a temporal graph, the csv file must have a header with column <code>t</code> containing time stamps of edges</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to the csv file containing the graph data.</p> required <code>sep</code> <code>str</code> <p>character separating columns in the csv file</p> <code>','</code> <code>header</code> <code>bool</code> <p>whether or not the first line of the csv file is interpreted as header with column names</p> <code>True</code> <code>is_undirected</code> <code>bool</code> <p>whether or not to interpret edges as undirected</p> <code>False</code> <code>multiedges</code> <code>bool</code> <p>whether or not to allow multiple edges between the same node pair. By default multi edges are ignored.</p> <code>False</code> <code>**kwargs</code> <code>typing.Any</code> <p>Additional keyword arguments passed to the <code>df_to_graph</code> function.</p> <code>{}</code> Example <pre><code>import pathpyG as pp\n\ng = pp.io.read_csv('example_graph.csv')\ng = pp.io.read_csv('example_temporal_graph.csv')\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def read_csv_graph(\n    filename: str,\n    sep: str = \",\",\n    header: bool = True,\n    is_undirected: bool = False,\n    multiedges: bool = False,\n    **kwargs: Any,\n) -&gt; Graph:\n    \"\"\"Read a `Graph` from a csv file.\n\n    This method reads a graph from a `.csv`-file and converts it to a\n    `Graph` object. To read a temporal graph, the csv file must have\n    a header with column `t` containing time stamps of edges\n\n    Args:\n        filename: The path to the csv file containing the graph data.\n        sep: character separating columns in the csv file\n        header: whether or not the first line of the csv file is interpreted as header with column names\n        is_undirected: whether or not to interpret edges as undirected\n        multiedges: whether or not to allow multiple edges between the same node pair. By default multi edges are\n            ignored.\n        **kwargs: Additional keyword arguments passed to the `df_to_graph` function.\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.io.read_csv('example_graph.csv')\n        g = pp.io.read_csv('example_temporal_graph.csv')\n        ```\n    \"\"\"\n    if header:\n        df = pd.read_csv(filename, header=0, sep=sep)\n    else:\n        df = pd.read_csv(filename, header=None, sep=sep)\n\n    return df_to_graph(df, is_undirected=is_undirected, multiedges=multiedges, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.read_csv_path_data","title":"<code>read_csv_path_data</code>","text":"<p>Read multiple paths stored in an n-gram csv file</p> <p>Parameters:</p> Name Type Description Default <code>path_or_buf</code> <code>typing.Any</code> <p>File, path or file-like object that the <code>pandas.read_table</code> function will read from        </p> <code>None</code> <code>weight</code> <code>bool</code> <p>If True the last column of each row in the CSV file will be interpreted as a count or weight</p> <code>True</code> <code>sep</code> <p>character that separates the nodes (and weight) in each line of the input file</p> <code>','</code> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def read_csv_path_data(path_or_buf: Any = None, weight: bool = True, sep=',',\n                       device: Optional[torch.device] = None, **pdargs: Any) -&gt; PathData:\n    \"\"\"Read multiple paths stored in an n-gram csv file\n\n\n    Args:\n        path_or_buf: File, path or file-like object that the `pandas.read_table` function will read from        \n        weight: If True the last column of each row in the CSV file will be interpreted as a count or weight\n        sep: character that separates the nodes (and weight) in each line of the input file\n    \"\"\"\n\n    # Read raw data\n    df = pd.read_table(filepath_or_buffer=path_or_buf, header=None)\n    # split and expand non-uniform rows\n    df = df[0].str.split(sep, expand=True)\n\n    paths = []\n    weights = []\n\n    # extract node sequences and edges\n    for row in df.itertuples(index=False):\n        p = [x for x in row if x]\n        if weight:\n            weights.append(float(p[-1]))\n            p.pop()\n        else:\n            weights.append(1.0)\n        paths.append(p)\n\n    # create index mapping\n    mapping = IndexMap()\n    mapping.add_ids(np.unique(np.hstack(paths)))\n\n    # create path_data object\n    pathdata = PathData(mapping, device)\n    pathdata.append_walks(node_seqs=paths, weights=weights)\n    return pathdata\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.read_csv_temporal_graph","title":"<code>read_csv_temporal_graph</code>","text":"<p>Read a <code>TemporalGraph</code> from a csv file.</p> <p>This method reads a temporal graph from a <code>.csv</code>-file and converts it to a <code>TemporalGraph</code> object. The csv file is expected to have a header with columns <code>v</code>, <code>w</code>, and <code>t</code> containing source nodes, target nodes, and time stamps of edges, respectively. Additional columns in the csv file will be interpreted as edge attributes.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to the csv file containing the temporal graph data.</p> required <code>sep</code> <code>str</code> <p>character separating columns in the csv file</p> <code>','</code> <code>header</code> <code>bool</code> <p>whether or not the first line of the csv file is interpreted as header with column names</p> <code>True</code> <code>timestamp_format</code> <code>str</code> <p>The format of the time stamps in the <code>t</code> column.</p> <code>'%Y-%m-%d %H:%M:%S'</code> <code>time_rescale</code> <code>int</code> <p>The factor by which to rescale the time stamps. Defaults to 1, meaning no rescaling.</p> <code>1</code> <code>**kwargs</code> <code>typing.Any</code> <p>Additional keyword arguments passed to the <code>df_to_temporal_graph</code> function.</p> <code>{}</code> Example <pre><code>import pathpyG as pp\n\ng = pp.io.read_csv('example_temporal_graph.csv')\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def read_csv_temporal_graph(\n    filename: str,\n    sep: str = \",\",\n    header: bool = True,\n    timestamp_format: str = \"%Y-%m-%d %H:%M:%S\",\n    time_rescale: int = 1,\n    **kwargs: Any,\n) -&gt; TemporalGraph:\n    \"\"\"Read a `TemporalGraph` from a csv file.\n\n    This method reads a temporal graph from a `.csv`-file and converts it to a\n    `TemporalGraph` object. The csv file is expected to have a header with columns\n    `v`, `w`, and `t` containing source nodes, target nodes, and time stamps of edges,\n    respectively. Additional columns in the csv file will be interpreted as edge attributes.\n\n    Args:\n        filename: The path to the csv file containing the temporal graph data.\n        sep: character separating columns in the csv file\n        header: whether or not the first line of the csv file is interpreted as header with column names\n        timestamp_format: The format of the time stamps in the `t` column.\n        time_rescale: The factor by which to rescale the time stamps. Defaults to 1, meaning no rescaling.\n        **kwargs: Additional keyword arguments passed to the `df_to_temporal_graph` function.\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.io.read_csv('example_temporal_graph.csv')\n        ```\n    \"\"\"\n    if header:\n        df = pd.read_csv(filename, header=0, sep=sep)\n    else:\n        df = pd.read_csv(filename, header=None, sep=sep)\n    return df_to_temporal_graph(df, timestamp_format=timestamp_format, time_rescale=time_rescale, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.temporal_graph_to_df","title":"<code>temporal_graph_to_df</code>","text":"<p>Return a DataFrame for a given temporal graph.</p> <p>Returns a <code>pandas.DataFrame</code> that contains all edges including edge attributes. Node and network-level attributes are not included. To facilitate the import into network analysis tools that only support integer node identifiers, node uids can be replaced by a consecutive, zero-based index.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>The graph to export as pandas DataFrame</p> required <code>node_indices</code> <code>typing.Optional[bool]</code> <p>whether nodes should be exported as integer indices</p> <code>False</code> Example <pre><code>import pathpyG as pp\n\nn = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ndf = pp.io.to_df(n)\nprint(df)\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def temporal_graph_to_df(graph: TemporalGraph, node_indices: Optional[bool] = False) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame for a given temporal graph.\n\n    Returns a `pandas.DataFrame` that contains all edges including edge\n    attributes. Node and network-level attributes are not included. To\n    facilitate the import into network analysis tools that only support integer\n    node identifiers, node uids can be replaced by a consecutive, zero-based\n    index.\n\n    Args:\n        graph: The graph to export as pandas DataFrame\n        node_indices: whether nodes should be exported as integer indices\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        n = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        df = pp.io.to_df(n)\n        print(df)\n        ```\n    \"\"\"\n    if node_indices:\n        vs = to_numpy(graph.data.edge_index[0])\n        ws = to_numpy(graph.data.edge_index[1])\n    else:\n        vs = graph.mapping.to_ids(to_numpy(graph.data.edge_index[0]))\n        ws = graph.mapping.to_ids(to_numpy(graph.data.edge_index[1]))\n    df = pd.DataFrame(\n        {\n            **{\"v\": vs, \"w\": ws, \"t\": graph.data.time.tolist()},\n            **{a: graph.data[a].tolist() for a in graph.edge_attrs()},\n        }\n    )\n\n    return df\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.write_csv","title":"<code>write_csv</code>","text":"<p>Store all edges of a graph or temporal graph in a csv file.</p> <p>This method stores a <code>Graph</code> or <code>TemporalGraph</code> as a <code>.csv</code> file. The csv file will contain all edges including edge attributes. Node and network-level attributes are not included. To facilitate the import into network analysis tools that only support integer node identifiers, node uids can be replaced by a consecutive, zero-based index.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>typing.Union[pathpyG.core.graph.Graph, pathpyG.core.temporal_graph.TemporalGraph]</code> <p>The graph to export as pandas DataFrame</p> required <code>node_indices</code> <code>bool</code> <p>whether nodes should be exported as integer indices</p> <code>False</code> <code>path_or_buf</code> <code>typing.Any</code> <p>String, path, or file-like object (see documentation of <code>pandas.DaatFrame.to_csv</code>)</p> <code>None</code> <code>**pdargs</code> <code>typing.Any</code> <p>Additional keyword arguments passed to <code>pandas.DataFrame.to_csv</code>.</p> <code>{}</code> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def write_csv(graph: Union[Graph, TemporalGraph], node_indices: bool = False, \n              path_or_buf: Any = None, **pdargs: Any) -&gt; None:\n    \"\"\"Store all edges of a graph or temporal graph in a csv file.\n\n    This method stores a `Graph` or `TemporalGraph` as a `.csv` file. The csv file\n    will contain all edges including edge attributes. Node and network-level attributes\n    are not included. To facilitate the import into network analysis tools that only\n    support integer node identifiers, node uids can be replaced by a consecutive,\n    zero-based index.\n\n    Args:\n        graph: The graph to export as pandas DataFrame\n        node_indices: whether nodes should be exported as integer indices\n        path_or_buf: String, path, or file-like object (see documentation of `pandas.DaatFrame.to_csv`)\n        **pdargs: Additional keyword arguments passed to `pandas.DataFrame.to_csv`.\n    \"\"\"\n    if isinstance(graph, TemporalGraph):\n        frame = temporal_graph_to_df(graph=graph, node_indices=node_indices)\n    else:\n        frame = graph_to_df(graph=graph, node_indices=node_indices)\n    frame.to_csv(index=False, path_or_buf=path_or_buf, **pdargs)\n</code></pre>"},{"location":"reference/pathpyG/nn/","title":"nn","text":""},{"location":"reference/pathpyG/nn/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/nn/dbgnn/#pathpyG.nn.dbgnn.DBGNN","title":"<code>DBGNN</code>","text":"<p>               Bases: <code>torch.nn.Module</code></p> <p>Implementation of time-aware graph neural network DBGNN (Reference paper).</p> <p>Parameters:</p> Name Type Description Default <code>num_classes</code> <code>int</code> <p>number of classes</p> required <code>num_features</code> <code>list[int]</code> <p>number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]</p> required <code>hidden_dims</code> <code>list[int]</code> <p>number of hidden dimensions per each layer in the first/higher order network</p> required <code>p_dropout</code> <code>float</code> <p>drop-out probability</p> <code>0.0</code> Source code in <code>src/pathpyG/nn/dbgnn.py</code> <pre><code>class DBGNN(Module):\n    \"\"\"Implementation of time-aware graph neural network DBGNN ([Reference paper](https://openreview.net/pdf?id=Dbkqs1EhTr)).\n\n    Args:\n        num_classes: number of classes\n        num_features: number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]\n        hidden_dims: number of hidden dimensions per each layer in the first/higher order network\n        p_dropout: drop-out probability\n    \"\"\"\n\n    def __init__(self, num_classes: int, num_features: list[int], hidden_dims: list[int], p_dropout: float = 0.0):\n        super().__init__()\n\n        self.num_features = num_features\n        self.num_classes = num_classes\n        self.hidden_dims = hidden_dims\n        self.p_dropout = p_dropout\n\n        # higher-order layers\n        self.higher_order_layers = ModuleList()\n        self.higher_order_layers.append(GCNConv(self.num_features[1], self.hidden_dims[0]))\n\n        # first-order layers\n        self.first_order_layers = ModuleList()\n        self.first_order_layers.append(GCNConv(self.num_features[0], self.hidden_dims[0]))\n\n        for dim in range(1, len(self.hidden_dims) - 1):\n            # higher-order layers\n            self.higher_order_layers.append(GCNConv(self.hidden_dims[dim - 1], self.hidden_dims[dim]))\n            # first-order layers\n            self.first_order_layers.append(GCNConv(self.hidden_dims[dim - 1], self.hidden_dims[dim]))\n\n        self.bipartite_layer = BipartiteGraphOperator(self.hidden_dims[-2], self.hidden_dims[-1])\n\n        # Linear layer\n        self.lin = torch.nn.Linear(self.hidden_dims[-1], num_classes)\n\n    def forward(self, data):\n\n        x = data.x\n        x_h = data.x_h\n\n        # First-order convolutions\n        for layer in self.first_order_layers:\n            x = F.dropout(x, p=self.p_dropout, training=self.training)\n            x = F.elu(layer(x, data.edge_index, data.edge_weights))\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Second-order convolutions\n        for layer in self.higher_order_layers:\n            x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n            x_h = F.elu(layer(x_h, data.edge_index_higher_order, data.edge_weights_higher_order))\n        x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n\n        # Bipartite message passing\n        x = torch.nn.functional.elu(\n            self.bipartite_layer((x_h, x), data.bipartite_edge_index, N=data.num_ho_nodes, M=data.num_nodes)\n        )\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Linear layer\n        x = self.lin(x)\n\n        return x\n</code></pre>"},{"location":"reference/pathpyG/processes/","title":"processes","text":"<p>Module for pathpy processes.</p>"},{"location":"reference/pathpyG/processes/process/","title":"process","text":"<p>Base classes for simulation of dynamical processes</p>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess","title":"<code>BaseProcess</code>","text":"<p>Abstract base class for all implementations of discrete-time dynamical processes.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>class BaseProcess:\n    \"\"\"Abstract base class for all implementations of discrete-time dynamical processes.\"\"\"\n\n    def __init__(self, network: Graph):\n        \"\"\"initialize process.\"\"\"\n        self._network = network\n        self.init(self.random_seed())\n\n    @property\n    def network(self) -&gt; Graph:\n        return self._network\n\n    @abc.abstractmethod\n    def init(self, seed: Any) -&gt; None:\n        \"\"\"Abstract method to initialize the process with a given seed state.\"\"\"\n\n    @abc.abstractmethod\n    def random_seed(self) -&gt; Any:\n        \"\"\"Abstract method to generate a random seed state for the process.\"\"\"\n\n    @abc.abstractmethod\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"Abstract method to simulate a single step of the process. Returns\n        an iterable of node uids whose state has been changed in this step.\"\"\"\n\n    @abc.abstractproperty\n    def time(self) -&gt; int:\n        \"\"\"Abstract property returning the current time.\"\"\"\n\n    @abc.abstractmethod\n    def state_to_color(self, Any) -&gt; Union[Tuple[int, int, int], str]:\n        \"\"\"Abstract method mapping node states to RGB colors or color names.\"\"\"\n\n    @abc.abstractmethod\n    def node_state(self, v: str) -&gt; Any:\n        \"\"\"Abstract method returning the current state of a given node.\"\"\"\n\n    def simulation_run(self, steps: int, seed: Optional[Any] = None) -&gt; Tuple[int, Set[str]]:\n        \"\"\"Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.\"\"\"\n        if seed == None:\n            self.init(self.random_seed())\n        else:\n            self.init(seed)\n        for _ in range(steps):\n            ret = self.step()\n            if ret is not None:\n                yield self.time, ret\n            else:\n                return None\n\n    def run_experiment(self, steps: int, runs: Optional[Union[int, Iterable[Any]]] = 1) -&gt; DataFrame:\n        \"\"\"Perform one or more simulation runs of the process with a given number of steps.\"\"\"\n\n        # Generate initializations for different runs\n        seeds: List = list()\n        if type(runs) == int:\n            for s in range(runs):\n                seeds.append(self.random_seed())\n        else:\n            for s in runs:\n                seeds.append(s)\n\n        results = list()\n        run_id: int = 0\n        for seed in tqdm(seeds):\n\n            # initialize seed state and record initial state\n            self.init(seed)\n            for v in self.network.nodes:\n                results.append(\n                    {\"run_id\": run_id, \"seed\": seed, \"time\": self.time, \"node\": v, \"state\": self.node_state(v)}\n                )\n\n            # simulate the given number of steps\n            for time, updated_nodes in self.simulation_run(steps, seed):\n                # print(updated_nodes)\n                # record the new state of each changed node\n                for v in updated_nodes:\n                    results.append(\n                        {\"run_id\": run_id, \"seed\": seed, \"time\": time, \"node\": v, \"state\": self.node_state(v)}\n                    )\n            run_id += 1\n\n        return DataFrame.from_dict(results)\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.__init__","title":"<code>__init__</code>","text":"<p>initialize process.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def __init__(self, network: Graph):\n    \"\"\"initialize process.\"\"\"\n    self._network = network\n    self.init(self.random_seed())\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.init","title":"<code>init</code>  <code>abstractmethod</code>","text":"<p>Abstract method to initialize the process with a given seed state.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef init(self, seed: Any) -&gt; None:\n    \"\"\"Abstract method to initialize the process with a given seed state.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.node_state","title":"<code>node_state</code>  <code>abstractmethod</code>","text":"<p>Abstract method returning the current state of a given node.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef node_state(self, v: str) -&gt; Any:\n    \"\"\"Abstract method returning the current state of a given node.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.random_seed","title":"<code>random_seed</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate a random seed state for the process.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef random_seed(self) -&gt; Any:\n    \"\"\"Abstract method to generate a random seed state for the process.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.run_experiment","title":"<code>run_experiment</code>","text":"<p>Perform one or more simulation runs of the process with a given number of steps.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def run_experiment(self, steps: int, runs: Optional[Union[int, Iterable[Any]]] = 1) -&gt; DataFrame:\n    \"\"\"Perform one or more simulation runs of the process with a given number of steps.\"\"\"\n\n    # Generate initializations for different runs\n    seeds: List = list()\n    if type(runs) == int:\n        for s in range(runs):\n            seeds.append(self.random_seed())\n    else:\n        for s in runs:\n            seeds.append(s)\n\n    results = list()\n    run_id: int = 0\n    for seed in tqdm(seeds):\n\n        # initialize seed state and record initial state\n        self.init(seed)\n        for v in self.network.nodes:\n            results.append(\n                {\"run_id\": run_id, \"seed\": seed, \"time\": self.time, \"node\": v, \"state\": self.node_state(v)}\n            )\n\n        # simulate the given number of steps\n        for time, updated_nodes in self.simulation_run(steps, seed):\n            # print(updated_nodes)\n            # record the new state of each changed node\n            for v in updated_nodes:\n                results.append(\n                    {\"run_id\": run_id, \"seed\": seed, \"time\": time, \"node\": v, \"state\": self.node_state(v)}\n                )\n        run_id += 1\n\n    return DataFrame.from_dict(results)\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.simulation_run","title":"<code>simulation_run</code>","text":"<p>Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>def simulation_run(self, steps: int, seed: Optional[Any] = None) -&gt; Tuple[int, Set[str]]:\n    \"\"\"Abstract generator method that initializes the process, runs a number of steps and yields a tuple consisting of the current time and the set of nodes whose state has changed in each step.\"\"\"\n    if seed == None:\n        self.init(self.random_seed())\n    else:\n        self.init(seed)\n    for _ in range(steps):\n        ret = self.step()\n        if ret is not None:\n            yield self.time, ret\n        else:\n            return None\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.state_to_color","title":"<code>state_to_color</code>  <code>abstractmethod</code>","text":"<p>Abstract method mapping node states to RGB colors or color names.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef state_to_color(self, Any) -&gt; Union[Tuple[int, int, int], str]:\n    \"\"\"Abstract method mapping node states to RGB colors or color names.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.step","title":"<code>step</code>  <code>abstractmethod</code>","text":"<p>Abstract method to simulate a single step of the process. Returns an iterable of node uids whose state has been changed in this step.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractmethod\ndef step(self) -&gt; Iterable[str]:\n    \"\"\"Abstract method to simulate a single step of the process. Returns\n    an iterable of node uids whose state has been changed in this step.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/process/#pathpyG.processes.process.BaseProcess.time","title":"<code>time</code>","text":"<p>Abstract property returning the current time.</p> Source code in <code>src/pathpyG/processes/process.py</code> <pre><code>@abc.abstractproperty\ndef time(self) -&gt; int:\n    \"\"\"Abstract property returning the current time.\"\"\"\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/","title":"walk","text":"<p>Classes to simlate random walks on static, temporal, and higher-order networks.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk","title":"<code>HigherOrderRandomWalk</code>","text":"<p>               Bases: <code>pathpyG.processes.random_walk.RandomWalk</code></p> <p>Class that implements a biased random walk process in a higher-order network.</p> <p>Instances of this class can be used to simulate random walk processes in higher-order networks for arbitrary orders k. The random walk process can include weighted edges as well as a restart probability, i.e. a per-step probability to teleport to a randomly chosen higher-order node.</p> <p>Different from the class RandomWalk, instances of class HigherOrderRandomWalk automatically project states to the corresponding first-order network, i.e. paths and visualisations are given in terms of the nodes in the first-order network, while the dynamics of the random walk is governed by the underlying higher-order network.</p> <p>The implementation follows the general concept to simulate discrete-time (stochastic) processes as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface to iterate through the steps of a single random walk process, or use the <code>run_experiment</code> function to simulate multiple runs of a random walk with different start nodes (i.e. seeds).</p> <p>The <code>run_experiment</code> function returns a pandas DataFrame object that contains all node state changes during the process' evolution. This data frame can be converted to Path and PathCollection objects and it can be visualized using the plot function.</p> <p>Examples:</p> <p>Generate and visualize a single random walk with 10 steps on a higher-order network</p> <pre><code>&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n&gt;&gt;&gt; paths = pp.WalkData(g3.mapping)\n&gt;&gt;&gt; paths.add_walk_seq(['a','b','c'],freq=1)\n&gt;&gt;&gt; paths.add_walk_seq(['b','c','a'],freq=1)\n&gt;&gt;&gt; paths.add_walk_seq(['b','c','d'],freq=0.2)\n&gt;&gt;&gt; paths.add_walk_seq(['c','a','b'],freq=1)\n&gt;&gt;&gt; paths.add_walk_seq(['c','d','a'],freq=0.2)\n&gt;&gt;&gt; paths.add_walk_seq(['d','a','b'],freq=1)\n&gt;&gt;&gt; g_ho = pp.HigherOrderGraph(paths, order =2)\n</code></pre> <pre><code>&gt;&gt;&gt; rw = pp.processes.HigherOrderRandomWalk(g_ho, weight=True)\n&gt;&gt;&gt; data = rw.run_experiment(steps=10, runs=[('b','c')])\n&gt;&gt;&gt; rw.plot(data)\n[interactive visualization in first-order network]\n</code></pre> <p>Use <code>plot</code> function of base class to visualize random walk in second-order network</p> <pre><code>&gt;&gt;&gt; pp.processes.RandomWalk.plot(rw, data)\n[interactive visualization in second-order network]\n</code></pre> <p>Generate a single random walk with 10 steps starting from node 'b-c' and return a first-order path</p> <pre><code>&gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['b-c']))\n&gt;&gt;&gt; pprint([v.uid for v in p.nodes ])\n[ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n</code></pre> <p>Use <code>get_path</code> function of base class to return path with second-order nodes</p> <pre><code>&gt;&gt;&gt; p = pp.processes.RandomWalk.get_path(rw2, data)\n&gt;&gt;&gt; print([ v.uid for v in p.nodes ])\n</code></pre> <p>Generate one random walk with 10 steps starting from each node and return a WalkData instance with first-order paths</p> <pre><code>&gt;&gt;&gt; paths = rw.get_paths(rw.run_experiment(steps=10, runs=g_ho.nodes))\n&gt;&gt;&gt; pprint([v.uid for v in p.nodes ])\n[ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n[ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n[ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n[ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n</code></pre> <p>Simulate a random walk using the iterator interface, which provides full access to the state after each simulation step</p> <pre><code>&gt;&gt;&gt; for time, _ in rw2.simulation_run(steps=50, seed='b-c'):\n&gt;&gt;&gt;     print('Current node = {0}'.format(rw2.first_order_node(rw2.current_node)))\n&gt;&gt;&gt;     print(rw2._first_order_visitation_frequencies)\nCurrent node = b\n[0.33333333 0.33333333 0.33333333 0.        ]\nCurrent node = c\n[0.32142857 0.32142857 0.35714286 0.        ]\nCurrent node = a\n[0.34482759 0.31034483 0.34482759 0.        ]\nCurrent node = b\n[0.33333333 0.33333333 0.33333333 0.        ]\nCurrent node = c\n[0.32258065 0.32258065 0.35483871 0.        ]\nCurrent node = a\n</code></pre> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>class HigherOrderRandomWalk(RandomWalk):\n    \"\"\"Class that implements a biased random walk process in a higher-order network.\n\n    Instances of this class can be used to simulate random walk processes in higher-order networks for\n    arbitrary orders k. The random walk process can include weighted edges as well as a\n    restart probability, i.e. a per-step probability to teleport to a\n    randomly chosen higher-order node.\n\n    Different from the class RandomWalk, instances of class HigherOrderRandomWalk automatically project states to the corresponding first-order network, i.e. paths and visualisations are given\n    in terms of the nodes in the first-order network, while the dynamics of the random walk is governed by the underlying higher-order network.\n\n    The implementation follows the general concept to simulate discrete-time (stochastic) processes\n    as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface\n    to iterate through the steps of a single random walk process, or use the `run_experiment` function\n    to simulate multiple runs of a random walk with different start nodes (i.e. seeds).\n\n    The `run_experiment` function returns a pandas DataFrame object that contains all node state changes\n    during the process' evolution. This data frame can be converted to Path and PathCollection objects\n    and it can be visualized using the plot function.\n\n    Examples:\n        Generate and visualize a single random walk with 10 steps on a higher-order network\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n        &gt;&gt;&gt; paths = pp.WalkData(g3.mapping)\n        &gt;&gt;&gt; paths.add_walk_seq(['a','b','c'],freq=1)\n        &gt;&gt;&gt; paths.add_walk_seq(['b','c','a'],freq=1)\n        &gt;&gt;&gt; paths.add_walk_seq(['b','c','d'],freq=0.2)\n        &gt;&gt;&gt; paths.add_walk_seq(['c','a','b'],freq=1)\n        &gt;&gt;&gt; paths.add_walk_seq(['c','d','a'],freq=0.2)\n        &gt;&gt;&gt; paths.add_walk_seq(['d','a','b'],freq=1)\n        &gt;&gt;&gt; g_ho = pp.HigherOrderGraph(paths, order =2)\n\n        &gt;&gt;&gt; rw = pp.processes.HigherOrderRandomWalk(g_ho, weight=True)\n        &gt;&gt;&gt; data = rw.run_experiment(steps=10, runs=[('b','c')])\n        &gt;&gt;&gt; rw.plot(data)\n        [interactive visualization in first-order network]\n\n        Use `plot` function of base class to visualize random walk in second-order network\n\n        &gt;&gt;&gt; pp.processes.RandomWalk.plot(rw, data)\n        [interactive visualization in second-order network]\n\n        Generate a single random walk with 10 steps starting from node 'b-c' and\n        return a first-order path\n\n        &gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['b-c']))\n        &gt;&gt;&gt; pprint([v.uid for v in p.nodes ])\n        [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n\n        Use `get_path` function of base class to return path with second-order nodes\n\n        &gt;&gt;&gt; p = pp.processes.RandomWalk.get_path(rw2, data)\n        &gt;&gt;&gt; print([ v.uid for v in p.nodes ])\n\n        Generate one random walk with 10 steps starting from each node and\n        return a WalkData instance with first-order paths\n\n        &gt;&gt;&gt; paths = rw.get_paths(rw.run_experiment(steps=10, runs=g_ho.nodes))\n        &gt;&gt;&gt; pprint([v.uid for v in p.nodes ])\n        [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n        [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n        [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n        [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n\n        Simulate a random walk using the iterator interface, which provides full access\n        to the state after each simulation step\n\n        &gt;&gt;&gt; for time, _ in rw2.simulation_run(steps=50, seed='b-c'):\n        &gt;&gt;&gt;     print('Current node = {0}'.format(rw2.first_order_node(rw2.current_node)))\n        &gt;&gt;&gt;     print(rw2._first_order_visitation_frequencies)\n        Current node = b\n        [0.33333333 0.33333333 0.33333333 0.        ]\n        Current node = c\n        [0.32142857 0.32142857 0.35714286 0.        ]\n        Current node = a\n        [0.34482759 0.31034483 0.34482759 0.        ]\n        Current node = b\n        [0.33333333 0.33333333 0.33333333 0.        ]\n        Current node = c\n        [0.32258065 0.32258065 0.35483871 0.        ]\n        Current node = a\n    \"\"\"\n\n    def __init__(\n        self, higher_order_network: Graph, first_order_network, weight: Optional[Weight] = None, restart_prob: float = 0\n    ) -&gt; None:\n        \"\"\"Creates a biased random walk process in a network.\n\n        Args:\n            higher_order_network: The higher-order network instance on which to perform the random walk process.\n            first_order_network: The first-order network instance to be used for mapping the process to first-order nodes\n            weight: If specified, the given numerical edge attribute will be used to bias\n                the random walk transition probabilities.\n            restart_probability: The per-step probability that a random walker restarts in a random (higher-order) node\n        \"\"\"\n        self._first_order_network = first_order_network\n        RandomWalk.__init__(self, higher_order_network, weight, restart_prob)\n\n    def init(self, seed) -&gt; None:\n\n        # set number of times each first-order node has been visited\n        self._first_order_visitations = np.ravel(np.zeros(shape=(1, self._first_order_network.n)))\n        self._first_order_visitations[self._first_order_network.mapping.to_idx(seed[-1])] = 1\n        RandomWalk.init(self, seed)\n\n    @property\n    def first_order_visitation_frequencies(self) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n        the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n        \"\"\"\n        return np.nan_to_num(self._first_order_visitations / (self._t + 1))\n\n    def first_order_stationary_state(self, **kwargs) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n        the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n        \"\"\"\n        first_order_stationary_state = np.ravel(np.zeros(shape=(1, self._first_order_network.n)))\n        higher_order_stationary_dist = RandomWalk.stationary_state(self, **kwargs)\n        for v in self._network.nodes:\n            # newly visited node in first_order network\n            v1 = v.relations[-1]\n            first_order_stationary_state[self._first_order_network.mapping.to_idx[v1]] += higher_order_stationary_dist[\n                self._network.mapping.to_idx[v]\n            ]\n        return first_order_stationary_state\n\n    @property\n    def first_order_total_variation_distance(self) -&gt; float:\n        \"\"\"Returns the total variation distance between stationary\n        visitation probabilities and the current visitation frequencies, projected\n        to nodes in the first_order_network.\n\n        Computes the total variation distance between the current (first-order) node visitation\n        probabilities and the (first-order) stationary node visitation probabilities. This quantity converges to zero for HigherOrderRandomWalk.time -&gt; np.infty and its magnitude indicates the\n        current relaxation of the higher-order random walk process.\n        \"\"\"\n        return self.TVD(self.first_order_stationary_state(), self.first_order_visitation_frequencies)\n\n    def first_order_node(self, higher_order_node: tuple) -&gt; str:\n        \"\"\"\n        Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.\n\n        Args:\n            higher_order_node: Tuple that represents the higher-order node\n\n        Returns:\n            String of the corresponding first-order node\n        \"\"\"\n        return higher_order_node[-1]\n\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"\n        Function that will be called for each step of the random walk. This function\n        returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.\n\n        Use the `first_order_node` function to map those nodes to nodes in the first-order network\n        \"\"\"\n        (current_node, previous_node) = RandomWalk.step(self)\n\n        self._first_order_visitations[self._first_order_network.mapping.to_idx(current_node[-1])] += 1\n\n        return (current_node, previous_node)\n\n    def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = 0) -&gt; PathData:\n        \"\"\"Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.\n\n        Args:\n            data: Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n            run_uid: Uid of the random walk simulations to be returned as WalkData (default: 0).\n\n        Returns:\n            WalkData object containing the sequences of nodes traversed by the random walks\n        \"\"\"\n        # list of traversed nodes starting with seed node\n\n        if not run_ids:  # generate paths for all run_ids in the data frame\n            runs = data[\"run_id\"].unique()\n        else:\n            runs = run_ids\n\n        paths = PathData(mapping=self._first_order_network.mapping)\n        for run in runs:\n            walk_steps = list(data.loc[(data[\"run_id\"] == run) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n            # for higher-order random walk, seed node is a higher-order node\n            # consisting of one or more edges\n            seed = walk_steps[0]\n            walk = [v for v in seed]\n\n            # map higher-order nodes to first-order nodes\n            for i in range(1, len(walk_steps)):\n                walk.append(walk_steps[i][-1])\n            paths.append_walk(walk)\n        return paths\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_total_variation_distance","title":"<code>first_order_total_variation_distance</code>  <code>property</code>","text":"<p>Returns the total variation distance between stationary visitation probabilities and the current visitation frequencies, projected to nodes in the first_order_network.</p> <p>Computes the total variation distance between the current (first-order) node visitation probabilities and the (first-order) stationary node visitation probabilities. This quantity converges to zero for HigherOrderRandomWalk.time -&gt; np.infty and its magnitude indicates the current relaxation of the higher-order random walk process.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_visitation_frequencies","title":"<code>first_order_visitation_frequencies</code>  <code>property</code>","text":"<p>Returns current normalized visitation frequencies of first-order nodes based on the history of the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.__init__","title":"<code>__init__</code>","text":"<p>Creates a biased random walk process in a network.</p> <p>Parameters:</p> Name Type Description Default <code>higher_order_network</code> <code>pathpyG.Graph</code> <p>The higher-order network instance on which to perform the random walk process.</p> required <code>first_order_network</code> <p>The first-order network instance to be used for mapping the process to first-order nodes</p> required <code>weight</code> <code>typing.Optional[pathpyG.processes.random_walk.Weight]</code> <p>If specified, the given numerical edge attribute will be used to bias the random walk transition probabilities.</p> <code>None</code> <code>restart_probability</code> <p>The per-step probability that a random walker restarts in a random (higher-order) node</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def __init__(\n    self, higher_order_network: Graph, first_order_network, weight: Optional[Weight] = None, restart_prob: float = 0\n) -&gt; None:\n    \"\"\"Creates a biased random walk process in a network.\n\n    Args:\n        higher_order_network: The higher-order network instance on which to perform the random walk process.\n        first_order_network: The first-order network instance to be used for mapping the process to first-order nodes\n        weight: If specified, the given numerical edge attribute will be used to bias\n            the random walk transition probabilities.\n        restart_probability: The per-step probability that a random walker restarts in a random (higher-order) node\n    \"\"\"\n    self._first_order_network = first_order_network\n    RandomWalk.__init__(self, higher_order_network, weight, restart_prob)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_node","title":"<code>first_order_node</code>","text":"<p>Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.</p> <p>Parameters:</p> Name Type Description Default <code>higher_order_node</code> <code>tuple</code> <p>Tuple that represents the higher-order node</p> required <p>Returns:</p> Type Description <code>str</code> <p>String of the corresponding first-order node</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def first_order_node(self, higher_order_node: tuple) -&gt; str:\n    \"\"\"\n    Maps a given uid of a node in the higher-order network to the uid of the corresponding first-order node.\n\n    Args:\n        higher_order_node: Tuple that represents the higher-order node\n\n    Returns:\n        String of the corresponding first-order node\n    \"\"\"\n    return higher_order_node[-1]\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.first_order_stationary_state","title":"<code>first_order_stationary_state</code>","text":"<p>Returns current normalized visitation frequencies of first-order nodes based on the history of the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def first_order_stationary_state(self, **kwargs) -&gt; np.array:\n    \"\"\"Returns current normalized visitation frequencies of first-order nodes based on the history of\n    the higher-order random walk. Initially, all visitation probabilities are zero except for the last node of the higher-order seed node.\n    \"\"\"\n    first_order_stationary_state = np.ravel(np.zeros(shape=(1, self._first_order_network.n)))\n    higher_order_stationary_dist = RandomWalk.stationary_state(self, **kwargs)\n    for v in self._network.nodes:\n        # newly visited node in first_order network\n        v1 = v.relations[-1]\n        first_order_stationary_state[self._first_order_network.mapping.to_idx[v1]] += higher_order_stationary_dist[\n            self._network.mapping.to_idx[v]\n        ]\n    return first_order_stationary_state\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.get_paths","title":"<code>get_paths</code>","text":"<p>Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pandas.DataFrame</code> <p>Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of <code>run_experiment</code></p> required <code>run_uid</code> <p>Uid of the random walk simulations to be returned as WalkData (default: 0).</p> required <p>Returns:</p> Type Description <code>pathpyG.PathData</code> <p>WalkData object containing the sequences of nodes traversed by the random walks</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = 0) -&gt; PathData:\n    \"\"\"Returns paths that represent the sequences of (first-order) nodes traversed by random walks with given run ids.\n\n    Args:\n        data: Pandas data frame containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n        run_uid: Uid of the random walk simulations to be returned as WalkData (default: 0).\n\n    Returns:\n        WalkData object containing the sequences of nodes traversed by the random walks\n    \"\"\"\n    # list of traversed nodes starting with seed node\n\n    if not run_ids:  # generate paths for all run_ids in the data frame\n        runs = data[\"run_id\"].unique()\n    else:\n        runs = run_ids\n\n    paths = PathData(mapping=self._first_order_network.mapping)\n    for run in runs:\n        walk_steps = list(data.loc[(data[\"run_id\"] == run) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n        # for higher-order random walk, seed node is a higher-order node\n        # consisting of one or more edges\n        seed = walk_steps[0]\n        walk = [v for v in seed]\n\n        # map higher-order nodes to first-order nodes\n        for i in range(1, len(walk_steps)):\n            walk.append(walk_steps[i][-1])\n        paths.append_walk(walk)\n    return paths\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.HigherOrderRandomWalk.step","title":"<code>step</code>","text":"<p>Function that will be called for each step of the random walk. This function returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.</p> <p>Use the <code>first_order_node</code> function to map those nodes to nodes in the first-order network</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def step(self) -&gt; Iterable[str]:\n    \"\"\"\n    Function that will be called for each step of the random walk. This function\n    returns a tuple, where the first entry is the uids of the currently visited higher-order node and the second entry is the uid of the previously visited higher-order node.\n\n    Use the `first_order_node` function to map those nodes to nodes in the first-order network\n    \"\"\"\n    (current_node, previous_node) = RandomWalk.step(self)\n\n    self._first_order_visitations[self._first_order_network.mapping.to_idx(current_node[-1])] += 1\n\n    return (current_node, previous_node)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk","title":"<code>RandomWalk</code>","text":"<p>               Bases: <code>pathpyG.processes.process.BaseProcess</code></p> <p>Class that implements a biased random walk process in a network.</p> <p>Instances of this class can be used to simulate random walk processes in any instance of the class Graph. The random walk process can include weighted edges as well as a restart probability, i.e. a per-step probability to teleport to a randomly chosen node.</p> <p>Since any instance of HigherOrderGraph is also an instance of Graph, this class can be directly be applied to simulate random walks in higher-order networks. However, the state space of such a random walk is given by the higher-order nodes. If you wish to simulate a higher-order random walk while projecting states to the corresponding first-order network, you should use the class HigherOrderRandomWalk instead.</p> <p>The implementation follows the general concept to simulate discrete-time (stochastic) processes as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface to iterate through the steps of a single random walk process, or use the <code>run_experiment</code> function to simulate multiple runs of a random walk with different start nodes (i.e. seeds).</p> <p>The <code>run_experiment</code> function returns a pandas DataFrame object that contains all node state changes during the process' evolution. This data frame can be converted to Path and PathCollection objects and it can be visualized using the plot function.</p> <p>Examples:</p> <p>Generate and visualize a single biased random walk with 10 steps on a network</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n&gt;&gt;&gt; rw = pp.processes.RandomWalk(g, weight='edge_weight')\n&gt;&gt;&gt; data = rw.run_experiment(steps=10, seed='a')\n&gt;&gt;&gt; rw.plot(data)\n[interactive visualization]\n</code></pre> <p>Generate a single random walk with 10 steps starting from node 'a' and return a WalkData instance</p> <pre><code>&gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['a']))\n</code></pre> <p>Generate one random walk with 10 steps starting from each node and return a PathCollection instance</p> <pre><code>&gt;&gt;&gt; pc = rw.get_paths(rw.run_experiment(steps=10, runs=g.nodes))\n[ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n[ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n[ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n[ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n</code></pre> <p>Simulate a random walk using the iterator interface, which provides full access to the state after each simulation step</p> <pre><code>&gt;&gt;&gt; for time, _ in rw.simulation_run(steps=5, seed='a'):\n&gt;&gt;&gt;     print('Current node = {0}'.format(rw.current_node))\n&gt;&gt;&gt;     print(rw.visitation_frequencies)\nCurrent node = b\n[0.5 0.5 0.  0. ]\nCurrent node = c\n[0.33333333 0.33333333 0.33333333 0. ]\nCurrent node = d\n[0.25 0.25 0.25 0.25]\nCurrent node = a\n[0.4 0.2 0.2 0.2]\nCurrent node = b\n[0.33333333 0.33333333 0.16666667 0.16666667]\nCurrent node = a\n[0.42857143 0.28571429 0.14285714 0.14285714]\nCurrent node = c\n[0.375 0.25  0.25  0.125]\nCurrent node = a\n[0.44444444 0.22222222 0.22222222 0.11111111]\nCurrent node = b\n[0.4 0.3 0.2 0.1]\nCurrent node = a\n[0.45454545 0.27272727 0.18181818 0.09090909]\n</code></pre> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>class RandomWalk(BaseProcess):\n    \"\"\"Class that implements a biased random walk process in a network.\n\n    Instances of this class can be used to simulate random walk processes in any instance\n    of the class Graph. The random walk process can include weighted edges as well as a\n    restart probability, i.e. a per-step probability to teleport to a\n    randomly chosen node.\n\n    Since any instance of HigherOrderGraph is also an instance of Graph, this class\n    can be directly be applied to simulate random walks in higher-order networks. However,\n    the state space of such a random walk is given by the higher-order nodes. If you wish to\n    simulate a higher-order random walk while projecting states to the corresponding first-order\n    network, you should use the class HigherOrderRandomWalk instead.\n\n    The implementation follows the general concept to simulate discrete-time (stochastic) processes\n    as implemented in the base class BaseProcess. Hence, the user can either use the iterator interface\n    to iterate through the steps of a single random walk process, or use the `run_experiment` function\n    to simulate multiple runs of a random walk with different start nodes (i.e. seeds).\n\n    The `run_experiment` function returns a pandas DataFrame object that contains all node state changes\n    during the process' evolution. This data frame can be converted to Path and PathCollection objects\n    and it can be visualized using the plot function.\n\n    Examples:\n        Generate and visualize a single biased random walk with 10 steps on a network\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([['a','b'], ['b','c'], ['c','a'], ['c','d'], ['d','a']])\n        &gt;&gt;&gt; rw = pp.processes.RandomWalk(g, weight='edge_weight')\n        &gt;&gt;&gt; data = rw.run_experiment(steps=10, seed='a')\n        &gt;&gt;&gt; rw.plot(data)\n        [interactive visualization]\n\n        Generate a single random walk with 10 steps starting from node 'a' and\n        return a WalkData instance\n\n        &gt;&gt;&gt; p = rw.get_path(rw.run_experiment(steps=10, runs=['a']))\n\n        Generate one random walk with 10 steps starting from each node and\n        return a PathCollection instance\n\n        &gt;&gt;&gt; pc = rw.get_paths(rw.run_experiment(steps=10, runs=g.nodes))\n        [ 'a', 'b', 'c', 'a', 'a', 'b', 'c', 'd', 'a', 'b']\n        [ 'd', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b', 'c' ]\n        [ 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c' ]\n        [ 'b', 'c', 'a', 'b', 'c', 'd', 'a', 'b', 'c', 'a', 'b' ]\n\n        Simulate a random walk using the iterator interface, which provides full access\n        to the state after each simulation step\n\n        &gt;&gt;&gt; for time, _ in rw.simulation_run(steps=5, seed='a'):\n        &gt;&gt;&gt;     print('Current node = {0}'.format(rw.current_node))\n        &gt;&gt;&gt;     print(rw.visitation_frequencies)\n        Current node = b\n        [0.5 0.5 0.  0. ]\n        Current node = c\n        [0.33333333 0.33333333 0.33333333 0. ]\n        Current node = d\n        [0.25 0.25 0.25 0.25]\n        Current node = a\n        [0.4 0.2 0.2 0.2]\n        Current node = b\n        [0.33333333 0.33333333 0.16666667 0.16666667]\n        Current node = a\n        [0.42857143 0.28571429 0.14285714 0.14285714]\n        Current node = c\n        [0.375 0.25  0.25  0.125]\n        Current node = a\n        [0.44444444 0.22222222 0.22222222 0.11111111]\n        Current node = b\n        [0.4 0.3 0.2 0.1]\n        Current node = a\n        [0.45454545 0.27272727 0.18181818 0.09090909]\n    \"\"\"\n\n    def __init__(self, network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n        \"\"\"Creates a biased random walk process in a network.\n\n        Args:\n            network: The network instance on which to perform the random walk process. Can also\n                be an instance of HigherOrderNetwork.\n            weight: If specified, the given numerical edge attribute will be used to bias\n                the random walk transition probabilities.\n            restart_probability: The per-step probability that a random walker restarts in a random node\n        \"\"\"\n\n        # transition matrix of random walk\n        self._transition_matrix = RandomWalk.compute_transition_matrix(network, weight, restart_prob)\n\n        # initialize Vose Alias Samplers\n\n        self.samplers = {\n            v: VoseAliasSampling(\n                np.nan_to_num(np.ravel(self._transition_matrix[network.mapping.to_idx(v), :].todense()))\n            )\n            for v in network.nodes\n        }\n\n        # compute eigenvectors and eigenvalues of transition matrix\n        if network.n &gt; 2:\n            _, eigenvectors = spl.eigs(self._transition_matrix.transpose(), k=1, which=\"LM\")\n            pi = eigenvectors.reshape(\n                eigenvectors.size,\n            )\n        else:\n            eigenvals, eigenvectors = spla.eig(self._transition_matrix.transpose().toarray())\n            x = np.argsort(-eigenvals)\n            pi = eigenvectors[x][:, 0]\n\n        # calculate stationary visitation probabilities\n        self._stationary_probabilities = np.real(pi / np.sum(pi))\n\n        self._network = network\n        self.init(self.random_seed())\n\n    def init(self, seed: str) -&gt; None:\n        \"\"\"\n        Initializes the random walk state with a given seed/source node\n\n        Args:\n            seed: Id of node in which the random walk will start\n        \"\"\"\n        # reset currently visited node (or higher-order node)\n        self._current_node = seed\n\n        # set time\n        self._t = 0\n\n        # set number of times each node has been visited\n        self._visitations = np.ravel(np.zeros(shape=(1, self._network.n)))\n        self._visitations[self._network.mapping.to_idx(seed)] = 1\n\n    def random_seed(self) -&gt; Any:\n        \"\"\"\n        Returns a random node from the network, chosen uniformly at random\n        \"\"\"\n        x = np.random.choice(range(self._network.n))\n        return self._network.mapping.to_id(x)\n\n    def step(self) -&gt; Iterable[str]:\n        \"\"\"\n        Function that will be called for each step of the random walk. This function\n        returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.\n        \"\"\"\n\n        # determine next node\n        next_node = self.network.mapping.to_id(self.samplers[self._current_node].sample())\n        # TODO: assertion will not hold if restart_prob &gt; 0\n        # assert (self._current_node, next_node) in self._network.edges, 'Assertion Error: {0} not in edge list'.format(\n        #     (self._current_node, next_node))\n\n        previous_node = self._current_node\n        self._current_node = next_node\n\n        # increment visitations and current time\n        self._visitations[self._network.mapping.to_idx(self._current_node)] += 1\n        self._t += 1\n\n        # return tuple of changed nodes, where the first node is the currently visited node\n        return (self._current_node, previous_node)\n\n    def node_state(self, v) -&gt; bool:\n        \"\"\"\n        Returns a boolean variable indicating whether the walker is currently\n        visiting (first-order) node v\n        \"\"\"\n        if v in self._network.nodes:\n            return v == self._current_node\n        # TODO: Error here!\n        elif type(self._network) == HigherOrderGraph:\n            return v == self._network.mapping.to_id(self._current_node)[-1]\n        else:\n            raise NotImplementedError(\"Random walk not implemented for network of type {0}\".format(type(self._network)))\n\n    @property\n    def time(self) -&gt; int:\n        \"\"\"\n        The current time of the random walk process, i.e. the number of steps taken since the start node.\n        \"\"\"\n        return self._t\n\n    def state_to_color(self, state: bool) -&gt; str:\n        \"\"\"\n        Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.\n\n        Args:\n            state: Current visitation state\n        \"\"\"\n        if state:\n            return \"red\"\n        else:\n            return \"blue\"\n\n    @staticmethod\n    def compute_transition_matrix(\n        network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0\n    ) -&gt; sp.sparse.csr_matrix:\n        \"\"\"Returns the transition matrix of a (biased) random walk in the given network.\n\n        Returns a transition matrix that describes a random walk process in the\n        given network.\n\n        Args:\n            network: The network for which the transition matrix will be created.\n            weight: If specified, the numerical edge attribute that shall be used in the biased\n                transition probabilities of the random walk.\n\n        \"\"\"\n        if weight is None or weight is False:\n            A = network.sparse_adj_matrix().todense()\n        elif weight is True:\n            A = network.sparse_adj_matrix(edge_attr=\"edge_weight\").todense()\n        else:\n            A = network.sparse_adj_matrix(edge_attr=weight).todense()\n        D = A.sum(axis=1)\n        n = network.n\n        T = sp.sparse.lil_matrix((n, n))\n        zero_deg = 0\n        for i in range(n):\n            if D[i] == 0:\n                zero_deg += 1\n            for j in range(n):\n                if D[i] &gt; 0:\n                    T[i, j] = restart_prob * (1.0 / n) + (1 - restart_prob) * A[i, j] / D[i]\n                else:\n                    if restart_prob &gt; 0:\n                        T[i, j] = 1.0 / n\n                    else:\n                        T[i, j] = 0.0\n        # if zero_deg &gt; 0:\n        #     LOG.warning(\n        #         'Network contains {0} nodes with zero out-degree'.format(zero_deg))\n        return T.tocsr()\n\n    @property\n    def transition_matrix(self) -&gt; sp.sparse.csr_matrix:\n        \"\"\"Returns the transition matrix of the random walk\"\"\"\n        return self._transition_matrix\n\n    def transition_probabilities(self, node: str) -&gt; np.array:\n        \"\"\"Returns a vector that contains transition probabilities.\n\n        Returns a vector that contains transition probabilities from a given\n        node to all other nodes in the network.\n        \"\"\"\n        return np.nan_to_num(np.ravel(self._transition_matrix[self._network.mapping.to_idx(node), :].todense()))\n\n    def visitation_probabilities(self, t, seed: str) -&gt; np.ndarray:\n        \"\"\"Calculates visitation probabilities of nodes after t steps for a given start node\n\n        Initially, all visitation probabilities are zero except for the start node.\n        \"\"\"\n        assert seed in self._network.nodes\n\n        initial_dist = np.zeros(self._network.n)\n        initial_dist[self._network.mapping.to_idx(seed)] = 1.0\n        return np.dot(initial_dist, (self._transition_matrix**t).todense())\n\n    def transition_matrix_pd(self) -&gt; DataFrame:\n        \"\"\"\n        Returns the transition matrix as pandas DataFrame with proper row/column labels.\n        \"\"\"\n        return DataFrame(\n            self.transition_matrix.todense(),\n            columns=[v for v in self._network.nodes],\n            index=[v for v in self._network.nodes],\n        )\n\n    @property\n    def current_node(self) -&gt; str:\n        return self._current_node\n\n    def get_path(self, data: DataFrame, run_id: Optional[int] = 0, first_order: Optional[bool] = True) -&gt; PathData:\n        \"\"\"Returns a path that represents the sequence of (first-order) nodes traversed\n        by a single random walk.\n\n        Args:\n            data: Pandas `DataFrame` containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n            run_uid: Uid of the random walk simulation to be returns as Path (default: 0).\n\n        Returns:\n            Path object containing the sequence of nodes traversed by the random walk\n        \"\"\"\n        # list of traversed nodes starting with seed node\n        walk_steps = list(data.loc[(data[\"run_id\"] == run_id) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n        # generate Path\n        path = PathData(self._network.mapping)\n        path.append_walk([walk_steps[i] for i in range(len(walk_steps))])\n        return path\n\n    def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = None) -&gt; PathData:\n        \"\"\"Return a PathData object where each path is one random walk trajectory\n\n        Args:\n            data: Pandas `DataFrame` containing the trajectory of one or more random walks, generated by `run_experiment`\n            run_ids: UIDs of random walk simulation runs to be included in the `PathData`. If None (default), all runs will be included.\n        \"\"\"\n\n        if not run_ids:  # generate paths for all run_ids in the data frame\n            runs = data[\"run_id\"].unique()\n        else:\n            runs = run_ids\n\n        walks = PathData(self._network.mapping)\n        for id in runs:\n            walk_steps = list(data.loc[(data[\"run_id\"] == id) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n            # add walk to PathData\n            walks.append_walk(walk_steps)\n\n        return walks\n\n    def stationary_state(self, **kwargs: Any) -&gt; np.array:\n        \"\"\"Compute stationary visitation probabilities of random walk.\n\n        Computes stationary visitation probabilities of nodes based on the\n        leading eigenvector of the transition matrix.\n\n        Args:\n            kwargs: Arbitrary key-value pairs to bee passed to the\n            scipy.sparse.linalg.eigs function.\n        \"\"\"\n        _p = self._stationary_probabilities\n        if kwargs:\n            _, eigenvectors = sp.sparse.linalg.eigs(self._transition_matrix.transpose(), k=1, which=\"LM\", **kwargs)\n            pi = eigenvectors.reshape(\n                eigenvectors.size,\n            )\n            _p = np.real(pi / np.sum(pi))\n        return _p\n\n    @property\n    def visitation_frequencies(self) -&gt; np.array:\n        \"\"\"Returns current normalized visitation frequencies of nodes based on the history of\n        the random walk. Initially, all visitation probabilities are zero except for the start node.\n        \"\"\"\n        return np.nan_to_num(self._visitations / (self._t + 1))\n\n    @property\n    def total_variation_distance(self) -&gt; float:\n        \"\"\"Returns the total variation distance between stationary\n        visitation probabilities and the current visitation frequencies\n\n        Computes the total variation distance between the current visitation\n        probabilities and the stationary probabilities. This quantity converges\n        to zero for RandomWalk.t -&gt; np.infty and its magnitude indicates the\n        current relaxation of the random walk process.\n        \"\"\"\n        return self.TVD(self.stationary_state(), self.visitation_frequencies)\n\n    @staticmethod\n    def TVD(a: np.array, b: np.array) -&gt; float:\n        \"\"\"Calculates the total variation distance between two probability vectors\"\"\"\n        return np.abs(a - b).sum() / 2.0\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.time","title":"<code>time</code>  <code>property</code>","text":"<p>The current time of the random walk process, i.e. the number of steps taken since the start node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.total_variation_distance","title":"<code>total_variation_distance</code>  <code>property</code>","text":"<p>Returns the total variation distance between stationary visitation probabilities and the current visitation frequencies</p> <p>Computes the total variation distance between the current visitation probabilities and the stationary probabilities. This quantity converges to zero for RandomWalk.t -&gt; np.infty and its magnitude indicates the current relaxation of the random walk process.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_matrix","title":"<code>transition_matrix</code>  <code>property</code>","text":"<p>Returns the transition matrix of the random walk</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.visitation_frequencies","title":"<code>visitation_frequencies</code>  <code>property</code>","text":"<p>Returns current normalized visitation frequencies of nodes based on the history of the random walk. Initially, all visitation probabilities are zero except for the start node.</p>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.TVD","title":"<code>TVD</code>  <code>staticmethod</code>","text":"<p>Calculates the total variation distance between two probability vectors</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>@staticmethod\ndef TVD(a: np.array, b: np.array) -&gt; float:\n    \"\"\"Calculates the total variation distance between two probability vectors\"\"\"\n    return np.abs(a - b).sum() / 2.0\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.__init__","title":"<code>__init__</code>","text":"<p>Creates a biased random walk process in a network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.Graph</code> <p>The network instance on which to perform the random walk process. Can also be an instance of HigherOrderNetwork.</p> required <code>weight</code> <code>typing.Optional[pathpyG.processes.random_walk.Weight]</code> <p>If specified, the given numerical edge attribute will be used to bias the random walk transition probabilities.</p> <code>None</code> <code>restart_probability</code> <p>The per-step probability that a random walker restarts in a random node</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def __init__(self, network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0) -&gt; None:\n    \"\"\"Creates a biased random walk process in a network.\n\n    Args:\n        network: The network instance on which to perform the random walk process. Can also\n            be an instance of HigherOrderNetwork.\n        weight: If specified, the given numerical edge attribute will be used to bias\n            the random walk transition probabilities.\n        restart_probability: The per-step probability that a random walker restarts in a random node\n    \"\"\"\n\n    # transition matrix of random walk\n    self._transition_matrix = RandomWalk.compute_transition_matrix(network, weight, restart_prob)\n\n    # initialize Vose Alias Samplers\n\n    self.samplers = {\n        v: VoseAliasSampling(\n            np.nan_to_num(np.ravel(self._transition_matrix[network.mapping.to_idx(v), :].todense()))\n        )\n        for v in network.nodes\n    }\n\n    # compute eigenvectors and eigenvalues of transition matrix\n    if network.n &gt; 2:\n        _, eigenvectors = spl.eigs(self._transition_matrix.transpose(), k=1, which=\"LM\")\n        pi = eigenvectors.reshape(\n            eigenvectors.size,\n        )\n    else:\n        eigenvals, eigenvectors = spla.eig(self._transition_matrix.transpose().toarray())\n        x = np.argsort(-eigenvals)\n        pi = eigenvectors[x][:, 0]\n\n    # calculate stationary visitation probabilities\n    self._stationary_probabilities = np.real(pi / np.sum(pi))\n\n    self._network = network\n    self.init(self.random_seed())\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.compute_transition_matrix","title":"<code>compute_transition_matrix</code>  <code>staticmethod</code>","text":"<p>Returns the transition matrix of a (biased) random walk in the given network.</p> <p>Returns a transition matrix that describes a random walk process in the given network.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.Graph</code> <p>The network for which the transition matrix will be created.</p> required <code>weight</code> <code>typing.Optional[pathpyG.processes.random_walk.Weight]</code> <p>If specified, the numerical edge attribute that shall be used in the biased transition probabilities of the random walk.</p> <code>None</code> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>@staticmethod\ndef compute_transition_matrix(\n    network: Graph, weight: Optional[Weight] = None, restart_prob: float = 0\n) -&gt; sp.sparse.csr_matrix:\n    \"\"\"Returns the transition matrix of a (biased) random walk in the given network.\n\n    Returns a transition matrix that describes a random walk process in the\n    given network.\n\n    Args:\n        network: The network for which the transition matrix will be created.\n        weight: If specified, the numerical edge attribute that shall be used in the biased\n            transition probabilities of the random walk.\n\n    \"\"\"\n    if weight is None or weight is False:\n        A = network.sparse_adj_matrix().todense()\n    elif weight is True:\n        A = network.sparse_adj_matrix(edge_attr=\"edge_weight\").todense()\n    else:\n        A = network.sparse_adj_matrix(edge_attr=weight).todense()\n    D = A.sum(axis=1)\n    n = network.n\n    T = sp.sparse.lil_matrix((n, n))\n    zero_deg = 0\n    for i in range(n):\n        if D[i] == 0:\n            zero_deg += 1\n        for j in range(n):\n            if D[i] &gt; 0:\n                T[i, j] = restart_prob * (1.0 / n) + (1 - restart_prob) * A[i, j] / D[i]\n            else:\n                if restart_prob &gt; 0:\n                    T[i, j] = 1.0 / n\n                else:\n                    T[i, j] = 0.0\n    # if zero_deg &gt; 0:\n    #     LOG.warning(\n    #         'Network contains {0} nodes with zero out-degree'.format(zero_deg))\n    return T.tocsr()\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_path","title":"<code>get_path</code>","text":"<p>Returns a path that represents the sequence of (first-order) nodes traversed by a single random walk.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pandas.DataFrame</code> <p>Pandas <code>DataFrame</code> containing the trajectory of one or more (higher-order) random walks, generated by a call of <code>run_experiment</code></p> required <code>run_uid</code> <p>Uid of the random walk simulation to be returns as Path (default: 0).</p> required <p>Returns:</p> Type Description <code>pathpyG.PathData</code> <p>Path object containing the sequence of nodes traversed by the random walk</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_path(self, data: DataFrame, run_id: Optional[int] = 0, first_order: Optional[bool] = True) -&gt; PathData:\n    \"\"\"Returns a path that represents the sequence of (first-order) nodes traversed\n    by a single random walk.\n\n    Args:\n        data: Pandas `DataFrame` containing the trajectory of one or more (higher-order) random walks, generated by a call of `run_experiment`\n        run_uid: Uid of the random walk simulation to be returns as Path (default: 0).\n\n    Returns:\n        Path object containing the sequence of nodes traversed by the random walk\n    \"\"\"\n    # list of traversed nodes starting with seed node\n    walk_steps = list(data.loc[(data[\"run_id\"] == run_id) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n    # generate Path\n    path = PathData(self._network.mapping)\n    path.append_walk([walk_steps[i] for i in range(len(walk_steps))])\n    return path\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.get_paths","title":"<code>get_paths</code>","text":"<p>Return a PathData object where each path is one random walk trajectory</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>pandas.DataFrame</code> <p>Pandas <code>DataFrame</code> containing the trajectory of one or more random walks, generated by <code>run_experiment</code></p> required <code>run_ids</code> <code>typing.Optional[typing.Iterable]</code> <p>UIDs of random walk simulation runs to be included in the <code>PathData</code>. If None (default), all runs will be included.</p> <code>None</code> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def get_paths(self, data: DataFrame, run_ids: Optional[Iterable] = None) -&gt; PathData:\n    \"\"\"Return a PathData object where each path is one random walk trajectory\n\n    Args:\n        data: Pandas `DataFrame` containing the trajectory of one or more random walks, generated by `run_experiment`\n        run_ids: UIDs of random walk simulation runs to be included in the `PathData`. If None (default), all runs will be included.\n    \"\"\"\n\n    if not run_ids:  # generate paths for all run_ids in the data frame\n        runs = data[\"run_id\"].unique()\n    else:\n        runs = run_ids\n\n    walks = PathData(self._network.mapping)\n    for id in runs:\n        walk_steps = list(data.loc[(data[\"run_id\"] == id) &amp; (data[\"state\"] == True)][\"node\"].values)\n\n        # add walk to PathData\n        walks.append_walk(walk_steps)\n\n    return walks\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.init","title":"<code>init</code>","text":"<p>Initializes the random walk state with a given seed/source node</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>str</code> <p>Id of node in which the random walk will start</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def init(self, seed: str) -&gt; None:\n    \"\"\"\n    Initializes the random walk state with a given seed/source node\n\n    Args:\n        seed: Id of node in which the random walk will start\n    \"\"\"\n    # reset currently visited node (or higher-order node)\n    self._current_node = seed\n\n    # set time\n    self._t = 0\n\n    # set number of times each node has been visited\n    self._visitations = np.ravel(np.zeros(shape=(1, self._network.n)))\n    self._visitations[self._network.mapping.to_idx(seed)] = 1\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.node_state","title":"<code>node_state</code>","text":"<p>Returns a boolean variable indicating whether the walker is currently visiting (first-order) node v</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def node_state(self, v) -&gt; bool:\n    \"\"\"\n    Returns a boolean variable indicating whether the walker is currently\n    visiting (first-order) node v\n    \"\"\"\n    if v in self._network.nodes:\n        return v == self._current_node\n    # TODO: Error here!\n    elif type(self._network) == HigherOrderGraph:\n        return v == self._network.mapping.to_id(self._current_node)[-1]\n    else:\n        raise NotImplementedError(\"Random walk not implemented for network of type {0}\".format(type(self._network)))\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.random_seed","title":"<code>random_seed</code>","text":"<p>Returns a random node from the network, chosen uniformly at random</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def random_seed(self) -&gt; Any:\n    \"\"\"\n    Returns a random node from the network, chosen uniformly at random\n    \"\"\"\n    x = np.random.choice(range(self._network.n))\n    return self._network.mapping.to_id(x)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.state_to_color","title":"<code>state_to_color</code>","text":"<p>Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>bool</code> <p>Current visitation state</p> required Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def state_to_color(self, state: bool) -&gt; str:\n    \"\"\"\n    Maps the current (visitation) state of nodes to colors for visualization. The state is True for the currently visited node and False for all other nodes.\n\n    Args:\n        state: Current visitation state\n    \"\"\"\n    if state:\n        return \"red\"\n    else:\n        return \"blue\"\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.stationary_state","title":"<code>stationary_state</code>","text":"<p>Compute stationary visitation probabilities of random walk.</p> <p>Computes stationary visitation probabilities of nodes based on the leading eigenvector of the transition matrix.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>typing.Any</code> <p>Arbitrary key-value pairs to bee passed to the</p> <code>{}</code> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def stationary_state(self, **kwargs: Any) -&gt; np.array:\n    \"\"\"Compute stationary visitation probabilities of random walk.\n\n    Computes stationary visitation probabilities of nodes based on the\n    leading eigenvector of the transition matrix.\n\n    Args:\n        kwargs: Arbitrary key-value pairs to bee passed to the\n        scipy.sparse.linalg.eigs function.\n    \"\"\"\n    _p = self._stationary_probabilities\n    if kwargs:\n        _, eigenvectors = sp.sparse.linalg.eigs(self._transition_matrix.transpose(), k=1, which=\"LM\", **kwargs)\n        pi = eigenvectors.reshape(\n            eigenvectors.size,\n        )\n        _p = np.real(pi / np.sum(pi))\n    return _p\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.step","title":"<code>step</code>","text":"<p>Function that will be called for each step of the random walk. This function returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def step(self) -&gt; Iterable[str]:\n    \"\"\"\n    Function that will be called for each step of the random walk. This function\n    returns a tuple, where the first entry is the id of the currently visited node and the second entry is the id of the previously visited node.\n    \"\"\"\n\n    # determine next node\n    next_node = self.network.mapping.to_id(self.samplers[self._current_node].sample())\n    # TODO: assertion will not hold if restart_prob &gt; 0\n    # assert (self._current_node, next_node) in self._network.edges, 'Assertion Error: {0} not in edge list'.format(\n    #     (self._current_node, next_node))\n\n    previous_node = self._current_node\n    self._current_node = next_node\n\n    # increment visitations and current time\n    self._visitations[self._network.mapping.to_idx(self._current_node)] += 1\n    self._t += 1\n\n    # return tuple of changed nodes, where the first node is the currently visited node\n    return (self._current_node, previous_node)\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_matrix_pd","title":"<code>transition_matrix_pd</code>","text":"<p>Returns the transition matrix as pandas DataFrame with proper row/column labels.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def transition_matrix_pd(self) -&gt; DataFrame:\n    \"\"\"\n    Returns the transition matrix as pandas DataFrame with proper row/column labels.\n    \"\"\"\n    return DataFrame(\n        self.transition_matrix.todense(),\n        columns=[v for v in self._network.nodes],\n        index=[v for v in self._network.nodes],\n    )\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Returns a vector that contains transition probabilities.</p> <p>Returns a vector that contains transition probabilities from a given node to all other nodes in the network.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def transition_probabilities(self, node: str) -&gt; np.array:\n    \"\"\"Returns a vector that contains transition probabilities.\n\n    Returns a vector that contains transition probabilities from a given\n    node to all other nodes in the network.\n    \"\"\"\n    return np.nan_to_num(np.ravel(self._transition_matrix[self._network.mapping.to_idx(node), :].todense()))\n</code></pre>"},{"location":"reference/pathpyG/processes/random_walk/#pathpyG.processes.random_walk.RandomWalk.visitation_probabilities","title":"<code>visitation_probabilities</code>","text":"<p>Calculates visitation probabilities of nodes after t steps for a given start node</p> <p>Initially, all visitation probabilities are zero except for the start node.</p> Source code in <code>src/pathpyG/processes/random_walk.py</code> <pre><code>def visitation_probabilities(self, t, seed: str) -&gt; np.ndarray:\n    \"\"\"Calculates visitation probabilities of nodes after t steps for a given start node\n\n    Initially, all visitation probabilities are zero except for the start node.\n    \"\"\"\n    assert seed in self._network.nodes\n\n    initial_dist = np.zeros(self._network.n)\n    initial_dist[self._network.mapping.to_idx(seed)] = 1.0\n    return np.dot(initial_dist, (self._transition_matrix**t).todense())\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/","title":"sampling","text":"<p>Classes for efficient random sampling from discrete distributions</p>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling","title":"<code>VoseAliasSampling</code>","text":"<p>Implementation of fast biased sampling of discrete values [0, ..., n]</p> <p>For a concise explanation see https://www.keithschwarz.com/darts-dice-coins/</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <code>typing.Union[numpy.array, list]</code> <p>relative weights of the n events, where weights[i] is the relative statistical weight of event i. The weights do not need to be normalized.</p> <p>For an array with length n, generated random values will be from range(n).</p> required <p>Examples:</p> <p>Create a VoseAliasSampling instance</p> <pre><code>&gt;&gt;&gt; from pathpy.processes import VoseAliasSampling\n&gt;&gt;&gt; sampler = VoseAliasSampling([1,1,2])\n</code></pre> <p>Fast biased sampling in O(1)</p> <pre><code>&gt;&gt;&gt; [ sampler.sample() for i in range(10) ]\n[ 0 2 0 1 2 1 2 1 2 0 2 2 ]\n</code></pre> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>class VoseAliasSampling:\n    \"\"\"\n    Implementation of fast biased sampling of discrete values [0, ..., n]\n\n    For a concise explanation see https://www.keithschwarz.com/darts-dice-coins/\n\n    Args:\n        weights: relative weights of the n events, where weights[i] is the relative\n            statistical weight of event i. The weights do not need to be\n            normalized.\n\n            For an array with length n, generated random values\n            will be from range(n).\n\n    Examples:\n        Create a VoseAliasSampling instance\n\n        &gt;&gt;&gt; from pathpy.processes import VoseAliasSampling\n        &gt;&gt;&gt; sampler = VoseAliasSampling([1,1,2])\n\n        Fast biased sampling in O(1)\n\n        &gt;&gt;&gt; [ sampler.sample() for i in range(10) ]\n        [ 0 2 0 1 2 1 2 1 2 0 2 2 ]\n    \"\"\"\n\n    def __init__(self, weights: Union[np.array, list]) -&gt; None:\n        \"\"\"\n        Initializes probability and alias tables\n        \"\"\"\n        self.n = len(weights)\n        self.probs = dict()\n        self.scaled_probs = dict()\n        self.aliases = dict()\n\n        small = list()\n        large = list()\n\n        for i in range(1, self.n + 1):\n            self.probs[i] = weights[i - 1]\n            self.scaled_probs[i] = self.n * weights[i - 1]\n            if self.scaled_probs[i] &gt; 1:\n                large.append(i)\n            elif self.scaled_probs[i] &lt;= 1:\n                small.append(i)\n\n        while small and large:\n            l = small.pop()\n            g = large.pop()\n\n            self.probs[l] = self.scaled_probs[l]\n            self.aliases[l] = g\n            self.scaled_probs[g] = self.scaled_probs[l] + self.scaled_probs[g] - 1\n\n            if self.scaled_probs[g] &lt; 1:\n                small.append(g)\n            else:\n                large.append(g)\n        while large:\n            g = large.pop()\n            self.probs[g] = 1\n        while small:\n            l = small.pop()\n            self.probs[l] = 1\n\n    def sample(self) -&gt; int:\n        \"\"\"\n        Biased sampling of discrete value in O(1)\n\n        Returns: integer value from range(n), where n is the length\n            of the weight array used to create the instance.\n        \"\"\"\n        i = np.random.randint(1, self.n + 1)\n        x = np.random.rand()\n        if x &lt; self.probs[i]:\n            return i - 1\n        else:\n            return self.aliases[i] - 1\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling.__init__","title":"<code>__init__</code>","text":"<p>Initializes probability and alias tables</p> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>def __init__(self, weights: Union[np.array, list]) -&gt; None:\n    \"\"\"\n    Initializes probability and alias tables\n    \"\"\"\n    self.n = len(weights)\n    self.probs = dict()\n    self.scaled_probs = dict()\n    self.aliases = dict()\n\n    small = list()\n    large = list()\n\n    for i in range(1, self.n + 1):\n        self.probs[i] = weights[i - 1]\n        self.scaled_probs[i] = self.n * weights[i - 1]\n        if self.scaled_probs[i] &gt; 1:\n            large.append(i)\n        elif self.scaled_probs[i] &lt;= 1:\n            small.append(i)\n\n    while small and large:\n        l = small.pop()\n        g = large.pop()\n\n        self.probs[l] = self.scaled_probs[l]\n        self.aliases[l] = g\n        self.scaled_probs[g] = self.scaled_probs[l] + self.scaled_probs[g] - 1\n\n        if self.scaled_probs[g] &lt; 1:\n            small.append(g)\n        else:\n            large.append(g)\n    while large:\n        g = large.pop()\n        self.probs[g] = 1\n    while small:\n        l = small.pop()\n        self.probs[l] = 1\n</code></pre>"},{"location":"reference/pathpyG/processes/sampling/#pathpyG.processes.sampling.VoseAliasSampling.sample","title":"<code>sample</code>","text":"<p>Biased sampling of discrete value in O(1)</p> <p>integer value from range(n), where n is the length</p> Type Description <code>int</code> <p>of the weight array used to create the instance.</p> Source code in <code>src/pathpyG/processes/sampling.py</code> <pre><code>def sample(self) -&gt; int:\n    \"\"\"\n    Biased sampling of discrete value in O(1)\n\n    Returns: integer value from range(n), where n is the length\n        of the weight array used to create the instance.\n    \"\"\"\n    i = np.random.randint(1, self.n + 1)\n    x = np.random.rand()\n    if x &lt; self.probs[i]:\n        return i - 1\n    else:\n        return self.aliases[i] - 1\n</code></pre>"},{"location":"reference/pathpyG/statistics/","title":"statistics","text":"<p>Functions to compute various graph statistics.</p> <p>The functions in this module allow to compute  various statistics on graphs</p> Example <pre><code>import pathpyG as pp\n\n# Generate a toy example graph.\ng = pp.Graph.from_edge_list([\n    ('b', 'c'),\n    ('a', 'b'),\n    ('c', 'd'),\n    ('d', 'a'),\n    ('b', 'd')\n])\n\n# Calculate degree distribution and raw moments\nd_dist = pp.statistics.degree_distribution(g)\nk_1 = pp.statistics.degree_raw_moment(g, k=1)\nk_2 = pp.statistics.degree_raw_moment(g, k=2)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if \"num_nodes\" not in data and \"edge_index\" in data:            \n            data.num_nodes = data.edge_index.max().item() + 1\n            logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if (\n            data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n            or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n        ):\n            logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n            raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n        self.data = data\n\n        # sort EdgeIndex and validate\n        data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        data.edge_index.validate()\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n        # create node_sequence mapping for higher-order graphs\n        if \"node_sequence\" not in self.data:\n            self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n        Examples:\n            You can create a graph from an edge index tensor as follows:\n\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            &gt;&gt;&gt; print(g)\n            Directed graph with 3 nodes and 3 edges ...\n\n            You can also include a mapping of node IDs:\n\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n            &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n            &gt;&gt;&gt; print(g.mapping)\n            a -&gt; 0\n            b -&gt; 1\n            c -&gt; 2\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else:\n            if mapping is not None and mapping.num_ids() != num_nodes:\n                logger.error(\"Number of node IDs in mapping must match num_nodes\")\n                raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(d, mapping=mapping)\n\n    @staticmethod\n    def from_edge_list(\n        edge_list: Iterable[Tuple[str, str]],\n        is_undirected: bool = False,\n        mapping: Optional[IndexMap] = None,\n        device: Optional[torch.device] = None,\n    ) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            device: optional torch device where tensors shall be stored\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n            &gt;&gt;&gt; print(list(g.edges))\n            [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        \"\"\"\n\n        # handle empty graph\n        if len(edge_list) == 0:\n            return Graph(\n                Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n                mapping=IndexMap(),\n            )\n\n        if mapping is None:\n            edge_array = np.array(edge_list)\n            node_ids = np.unique(edge_array)\n            if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n                node_ids = np.sort(node_ids.astype(int)).astype(str)\n            mapping = IndexMap(node_ids)\n\n        num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex(\n            mapping.to_idxs(edge_list, device=device).T.contiguous(),\n            sparse_size=(num_nodes, num_nodes),\n            is_undirected=is_undirected,\n        )\n        return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"Return an undirected version of this directed graph.\n\n        This method creates a new undirected Graph from the current graph instance by\n        adding all directed edges in opposite direction.\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            &gt;&gt;&gt; g_u = g.to_undirected()\n            &gt;&gt;&gt; print(g_u)\n            Undirected graph with 3 nodes and 6 (directed) edges\n        \"\"\"\n        # create undirected edge index by coalescing the directed edges and keep\n        # track of the original edge index for the edge attributes\n        attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n        edge_index, attr_idx = to_undirected(\n            self.data.edge_index,\n            edge_attr=attr_idx,\n            num_nodes=self.data.num_nodes,\n            reduce=\"min\",\n        )\n\n        data = Data(\n            edge_index=EdgeIndex(\n                data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n            ),\n            num_nodes=self.data.num_nodes,\n        )\n        # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n        # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n        # make sure to copy all node and (undirected) edge attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        for edge_attr in self.edge_attrs():\n            if edge_attr != \"edge_index\":\n                data[edge_attr] = self.data[edge_attr][attr_idx]\n\n        return Graph(data, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n        If the graph contains multiple edges between the same nodes, this method will coalesce\n        them into a single edge with an additional weight attribute called `edge_weight` that\n        contains the number of coalesced edges. The method returns a new graph instance with\n        the coalesced edges.\n\n        Returns:\n            Graph: Graph with coalesced edges\n        \"\"\"\n        i, w = torch_geometric.utils.coalesce(\n            self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n\n    def to(self, device: torch.device) -&gt; Graph:\n        \"\"\"Move all tensors to the given device.\n\n        Args:\n            device: torch device to which all tensors shall be moved\n\n        Returns:\n            Graph: self\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.node_sequence = self.data.node_sequence.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n\n        self.row = self.row.to(device)\n        self.row_ptr = self.row_ptr.to(device)\n        self.col = self.col.to(device)\n        self.col_ptr = self.col_ptr.to(device)\n\n        return self\n\n    def node_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_sequence` attribute.\n\n        Returns:\n            list: list of node attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n\n        Returns:\n            list: list of edge attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; list:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a list object that contains all nodes.\n        If an IndexMap is used, nodes are returned as string IDs.\n        If no IndexMap is used, nodes are returned as integer indices.\n\n        Returns:\n            list: list of all nodes using IDs or indices (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(np.arange(self.n)).tolist()\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    @property\n    def edges(self) -&gt; list:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a list object that contains all edges, where each\n        edge is a tuple of two elements. If an IndexMap is used to map node\n        indices to string IDs, edges are returned as tuples of string IDs.\n        If no mapping is used, edges are returned as tuples of integer indices.\n\n        Returns:\n            list: list object yielding all edges using IDs or indices (if no mapping is used)\n        \"\"\"\n        edge_list = self.mapping.to_ids(self.data.edge_index.t()).tolist()\n        if self.order &gt; 1:\n            return [tuple(map(tuple, x)) for x in edge_list]\n        return list(map(tuple, edge_list))\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n        \"\"\"\n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def successors(self, node: Union[int, str] | tuple) -&gt; list:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n\n        Returns:\n            list: list with all successors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n\n        node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n\n        Returns:\n            list: list with all predecessors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID\n\n        Returns:\n            bool: True if edge exists, False otherwise\n        \"\"\"\n        row = self.mapping.to_idx(v)\n        row_start = self.row_ptr[row]\n        row_end = self.row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in self.col[row_start:row_end]\n\n    def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted in-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing in-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted out-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing out-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                     torch.tensor]:\n        \"\"\"\n        Return (weighted) degrees of nodes.\n\n        Args:\n            mode: `in` or `out` to calculate in- or out-degree for\n                directed networks.\n            edge_attr: Optional numerical edge attribute that will \n                be used to compute weighted degrees\n            return_tensor: if True the function returns a degree tensor, if False (default)\n                a dictionary will be returned that can be indexed by nodes\n        Returns:\n            dict: dictionary containing node degrees\n        \"\"\"\n        if mode == \"in\":\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        else:\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        if return_tensor:\n            return d\n        else:\n            return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n\n    def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n        \"\"\"\n        Compute transition probabilities based on (weighted) outdegrees.\n\n        Args:\n            edge_attr: Optional name of numerical edge attribute that will\n                        will be used to calculate weighted out-degrees for the\n                        visitation probabilities.\n\n        Returns:\n            tensor: Transition probabilities.\n        \"\"\"\n        weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n        source_ids = self.data.edge_index[0]        \n        edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n        if edge_attr:\n            edge_weight = getattr(self.data, edge_attr, None)\n        return edge_weight / weighted_outdegree[source_ids]\n\n    def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization: normalization parameter passed to pyG `get_laplacian`\n                function\n            edge_attr: optinal name of numerical edge attribute that shall\n                be passed to pyG `get_laplacian` function as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(), normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(),\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key.startswith(\"node_\"):\n                if val.size(0) != self.n:\n                    raise ValueError(\"Attribute must have same length as number of nodes\")\n                self.data[key] = val\n            elif key.startswith(\"edge_\"):\n                if val.size(0) != self.m:\n                    raise ValueError(\"Attribute must have same length as number of edges\")\n                self.data[key] = val\n            else:\n                self.data[key] = val\n        elif key[0].startswith(\"node_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif key[0].startswith(\"edge_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n\n    @property\n    def n(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns:\n            int: number of nodes in the graph\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def m(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the number of \n        undirected edges (accounting for self-loops) is returned, i.e. in an undirected\n        graph the directed edges (a,b) and (b,a) will be counted only once.\n\n        Returns:\n            int: number of edges in the graph\n        \"\"\"\n        if self.is_directed():\n            return self.data.num_edges  # type: ignore\n        else:\n            num_self_loops = (self.data.edge_index[0] == self.data.edge_index[1]).sum().item()\n            num_edges_wo_self_loops = self.data.edge_index.size(1) - int(num_self_loops)\n            return int(num_edges_wo_self_loops/2 + num_self_loops) # type: ignore\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"\n        Return order of graph.\n\n        Returns:\n            int: order of the (De Bruijn) graph\n        \"\"\"\n        return self.data.node_sequence.size(1)  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\n\n        Returns:\n            bool: True if graph is directed, False otherwise\n        \"\"\"\n        return not self.data.edge_index.is_undirected\n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\n\n        Returns:\n            bool: True if graph is undirected, False otherwise\n        \"\"\"\n        return self.data.edge_index.is_undirected\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\n\n        Returns:\n            bool: True if graph contains self-loops, False otherwise\n        \"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Args:\n            other: Other graph to be combined with this graph\n            reduce: Reduction method for node attributes of nodes that are present in both graphs.\n                Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n        Examples:\n            Adding two graphs without node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 6 edges\n\n            Adding two graphs with identical node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 4 edges\n\n            Adding two graphs with non-overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 6 nodes and 4 edges\n\n            Adding two graphs with partly overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 5 nodes and 4 edges\n        \"\"\"\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n        mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n        d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n        d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n        d = d1.concat(d2)\n        d.num_nodes = mapping.num_ids()\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n        # For higher-order graphs, we need to update the inverse_idx attribute\n        if \"inverse_idx\" in d:\n            d.inverse_idx = mapping.to_idxs(\n                np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n                device=d.inverse_idx.device,\n            )\n\n        # If both graphs contain node attributes, reduce them using the specified method\n        for k in d1.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                if isinstance(d[k], torch.Tensor):\n                    d[k] = torch_geometric.utils.scatter(\n                        d[k],\n                        mapping.to_idxs(\n                            np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                            device=d[k].device,\n                        ),\n                        dim_size=d.num_nodes,\n                        reduce=reduce,\n                    )\n                else:\n                    raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a list object that contains all edges, where each edge is a tuple of two elements. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of string IDs. If no mapping is used, edges are returned as tuples of integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list object yielding all edges using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.in_degrees","title":"<code>in_degrees</code>  <code>property</code>","text":"<p>Return unweighted in-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing in-degrees of nodes</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.m","title":"<code>m</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the number of  undirected edges (accounting for self-loops) is returned, i.e. in an undirected graph the directed edges (a,b) and (b,a) will be counted only once.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of edges in the graph</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.n","title":"<code>n</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of nodes in the graph</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a list object that contains all nodes. If an IndexMap is used, nodes are returned as string IDs. If no IndexMap is used, nodes are returned as integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list of all nodes using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order of graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>order of the (De Bruijn) graph</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.out_degrees","title":"<code>out_degrees</code>  <code>property</code>","text":"<p>Return unweighted out-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing out-degrees of nodes</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>pathpyG.core.graph.Graph</code> <p>Other graph to be combined with this graph</p> required <code>reduce</code> <code>str</code> <p>Reduction method for node attributes of nodes that are present in both graphs. Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".</p> <code>'sum'</code> <p>Examples:</p> <p>Adding two graphs without node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 6 edges\n</code></pre> <p>Adding two graphs with identical node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 4 edges\n</code></pre> <p>Adding two graphs with non-overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 6 nodes and 4 edges\n</code></pre> <p>Adding two graphs with partly overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 5 nodes and 4 edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Args:\n        other: Other graph to be combined with this graph\n        reduce: Reduction method for node attributes of nodes that are present in both graphs.\n            Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n    Examples:\n        Adding two graphs without node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 6 edges\n\n        Adding two graphs with identical node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 4 edges\n\n        Adding two graphs with non-overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 6 nodes and 4 edges\n\n        Adding two graphs with partly overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 5 nodes and 4 edges\n    \"\"\"\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n    mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n    d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n    d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n    d = d1.concat(d2)\n    d.num_nodes = mapping.num_ids()\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n    # For higher-order graphs, we need to update the inverse_idx attribute\n    if \"inverse_idx\" in d:\n        d.inverse_idx = mapping.to_idxs(\n            np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n            device=d.inverse_idx.device,\n        )\n\n    # If both graphs contain node attributes, reduce them using the specified method\n    for k in d1.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            if isinstance(d[k], torch.Tensor):\n                d[k] = torch_geometric.utils.scatter(\n                    d[k],\n                    mapping.to_idxs(\n                        np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                        device=d[k].device,\n                    ),\n                    dim_size=d.num_nodes,\n                    reduce=reduce,\n                )\n            else:\n                raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if \"num_nodes\" not in data and \"edge_index\" in data:            \n        data.num_nodes = data.edge_index.max().item() + 1\n        logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if (\n        data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n        or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n    ):\n        logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n        raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n    self.data = data\n\n    # sort EdgeIndex and validate\n    data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    data.edge_index.validate()\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    # create node_sequence mapping for higher-order graphs\n    if \"node_sequence\" not in self.data:\n        self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key.startswith(\"node_\"):\n            if val.size(0) != self.n:\n                raise ValueError(\"Attribute must have same length as number of nodes\")\n            self.data[key] = val\n        elif key.startswith(\"edge_\"):\n            if val.size(0) != self.m:\n                raise ValueError(\"Attribute must have same length as number of edges\")\n            self.data[key] = val\n        else:\n            self.data[key] = val\n    elif key[0].startswith(\"node_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif key[0].startswith(\"edge_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return (weighted) degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate in- or out-degree for directed networks.</p> <code>'in'</code> <code>edge_attr</code> <code>typing.Any</code> <p>Optional numerical edge attribute that will  be used to compute weighted degrees</p> <code>None</code> <code>return_tensor</code> <code>bool</code> <p>if True the function returns a degree tensor, if False (default) a dictionary will be returned that can be indexed by nodes</p> <code>False</code> <p>Returns:     dict: dictionary containing node degrees</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                 torch.tensor]:\n    \"\"\"\n    Return (weighted) degrees of nodes.\n\n    Args:\n        mode: `in` or `out` to calculate in- or out-degree for\n            directed networks.\n        edge_attr: Optional numerical edge attribute that will \n            be used to compute weighted degrees\n        return_tensor: if True the function returns a degree tensor, if False (default)\n            a dictionary will be returned that can be indexed by nodes\n    Returns:\n        dict: dictionary containing node degrees\n    \"\"\"\n    if mode == \"in\":\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    else:\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    if return_tensor:\n        return d\n    else:\n        return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of edge attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def edge_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n\n    Returns:\n        list: list of edge attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <code>int</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.</p> <code>None</code> <p>Examples:</p> <p>You can create a graph from an edge index tensor as follows:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n&gt;&gt;&gt; print(g)\nDirected graph with 3 nodes and 3 edges ...\n</code></pre> <p>You can also include a mapping of node IDs:</p> <pre><code>&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n&gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n&gt;&gt;&gt; print(g.mapping)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n    Examples:\n        You can create a graph from an edge index tensor as follows:\n\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        &gt;&gt;&gt; print(g)\n        Directed graph with 3 nodes and 3 edges ...\n\n        You can also include a mapping of node IDs:\n\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n        &gt;&gt;&gt; print(g.mapping)\n        a -&gt; 0\n        b -&gt; 1\n        c -&gt; 2\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else:\n        if mapping is not None and mapping.num_ids() != num_nodes:\n            logger.error(\"Number of node IDs in mapping must match num_nodes\")\n            raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>device</code> <code>typing.Optional[torch.device]</code> <p>optional torch device where tensors shall be stored</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n&gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n&gt;&gt;&gt; print(list(g.edges))\n[('a', 'b'), ('a', 'c'), ('b', 'c')]\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(\n    edge_list: Iterable[Tuple[str, str]],\n    is_undirected: bool = False,\n    mapping: Optional[IndexMap] = None,\n    device: Optional[torch.device] = None,\n) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        device: optional torch device where tensors shall be stored\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n        &gt;&gt;&gt; print(list(g.edges))\n        [('a', 'b'), ('a', 'c'), ('b', 'c')]\n    \"\"\"\n\n    # handle empty graph\n    if len(edge_list) == 0:\n        return Graph(\n            Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n            mapping=IndexMap(),\n        )\n\n    if mapping is None:\n        edge_array = np.array(edge_list)\n        node_ids = np.unique(edge_array)\n        if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n            node_ids = np.sort(node_ids.astype(int)).astype(str)\n        mapping = IndexMap(node_ids)\n\n    num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex(\n        mapping.to_idxs(edge_list, device=device).T.contiguous(),\n        sparse_size=(num_nodes, num_nodes),\n        is_undirected=is_undirected,\n    )\n    return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all predecessor nodes of the node indexed by <code>col_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n    \"\"\"\n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all successor nodes of the node indexed by <code>row_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph contains self-loops, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\n\n    Returns:\n        bool: True if graph contains self-loops, False otherwise\n    \"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is directed, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\n\n    Returns:\n        bool: True if graph is directed, False otherwise\n    \"\"\"\n    return not self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if edge exists, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID\n\n    Returns:\n        bool: True if edge exists, False otherwise\n    \"\"\"\n    row = self.mapping.to_idx(v)\n    row_start = self.row_ptr[row]\n    row_end = self.row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in self.col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is undirected, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\n\n    Returns:\n        bool: True if graph is undirected, False otherwise\n    \"\"\"\n    return self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.laplacian","title":"<code>laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code> function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: Laplacian matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization: normalization parameter passed to pyG `get_laplacian`\n            function\n        edge_attr: optinal name of numerical edge attribute that shall\n            be passed to pyG `get_laplacian` function as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(), normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(),\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_sequence</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of node attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def node_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_sequence` attribute.\n\n    Returns:\n        list: list of node attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all predecessors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n\n    Returns:\n        list: list with all predecessors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n    node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.sparse_adj_matrix","title":"<code>sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n        )\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all successors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) -&gt; list:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n\n    Returns:\n        list: list with all successors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n\n    node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to","title":"<code>to</code>","text":"<p>Move all tensors to the given device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>torch device to which all tensors shall be moved</p> required <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>self</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; Graph:\n    \"\"\"Move all tensors to the given device.\n\n    Args:\n        device: torch device to which all tensors shall be moved\n\n    Returns:\n        Graph: self\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.node_sequence = self.data.node_sequence.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n\n    self.row = self.row.to(device)\n    self.row_ptr = self.row_ptr.to(device)\n    self.col = self.col.to(device)\n    self.col_ptr = self.col_ptr.to(device)\n\n    return self\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of this directed graph.</p> <p>This method creates a new undirected Graph from the current graph instance by adding all directed edges in opposite direction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n&gt;&gt;&gt; g_u = g.to_undirected()\n&gt;&gt;&gt; print(g_u)\nUndirected graph with 3 nodes and 6 (directed) edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"Return an undirected version of this directed graph.\n\n    This method creates a new undirected Graph from the current graph instance by\n    adding all directed edges in opposite direction.\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        &gt;&gt;&gt; g_u = g.to_undirected()\n        &gt;&gt;&gt; print(g_u)\n        Undirected graph with 3 nodes and 6 (directed) edges\n    \"\"\"\n    # create undirected edge index by coalescing the directed edges and keep\n    # track of the original edge index for the edge attributes\n    attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n    edge_index, attr_idx = to_undirected(\n        self.data.edge_index,\n        edge_attr=attr_idx,\n        num_nodes=self.data.num_nodes,\n        reduce=\"min\",\n    )\n\n    data = Data(\n        edge_index=EdgeIndex(\n            data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n        ),\n        num_nodes=self.data.num_nodes,\n    )\n    # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n    # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n    # make sure to copy all node and (undirected) edge attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    for edge_attr in self.edge_attrs():\n        if edge_attr != \"edge_index\":\n            data[edge_attr] = self.data[edge_attr][attr_idx]\n\n    return Graph(data, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> <p>If the graph contains multiple edges between the same nodes, this method will coalesce them into a single edge with an additional weight attribute called <code>edge_weight</code> that contains the number of coalesced edges. The method returns a new graph instance with the coalesced edges.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>Graph with coalesced edges</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n    If the graph contains multiple edges between the same nodes, this method will coalesce\n    them into a single edge with an additional weight attribute called `edge_weight` that\n    contains the number of coalesced edges. The method returns a new graph instance with\n    the coalesced edges.\n\n    Returns:\n        Graph: Graph with coalesced edges\n    \"\"\"\n    i, w = torch_geometric.utils.coalesce(\n        self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n    )\n    return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Compute transition probabilities based on (weighted) outdegrees.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>Optional name of numerical edge attribute that will         will be used to calculate weighted out-degrees for the         visitation probabilities.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Transition probabilities.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n    \"\"\"\n    Compute transition probabilities based on (weighted) outdegrees.\n\n    Args:\n        edge_attr: Optional name of numerical edge attribute that will\n                    will be used to calculate weighted out-degrees for the\n                    visitation probabilities.\n\n    Returns:\n        tensor: Transition probabilities.\n    \"\"\"\n    weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n    source_ids = self.data.edge_index[0]        \n    edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n    if edge_attr:\n        edge_weight = getattr(self.data, edge_attr, None)\n    return edge_weight / weighted_outdegree[source_ids]\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.closed_triads","title":"<code>closed_triads</code>","text":"<p>Calculates the set of edges that represent a closed triad around a given node v.</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.closed_triads--parameters","title":"Parameters","text":"<p>network : Network</p> <pre><code>The network in which to calculate the list of closed triads\n</code></pre> Source code in <code>src/pathpyG/statistics/clustering.py</code> <pre><code>def closed_triads(g: Graph, v: str) -&gt; Set:\n    \"\"\"Calculates the set of edges that represent a closed triad\n    around a given node v.\n\n    Parameters\n    ----------\n\n    network : Network\n\n        The network in which to calculate the list of closed triads\n\n    \"\"\"\n    c_triads: set = set()\n    edges = set()\n\n    # Collect all edges of successors\n    for x in g.successors(v):\n        for y in g.successors(x):\n            edges.add((x, y))\n\n    for x, y in edges:\n        if y in g.successors(v):\n            c_triads.add((x, y))\n    return c_triads\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_assortativity","title":"<code>degree_assortativity</code>","text":"<p>Calculate the degree assortativity</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_assortativity(g: Graph, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculate the degree assortativity\"\"\"\n\n    A = g.sparse_adj_matrix().todense()\n    m = _np.sum(A)\n\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n    elif not g.is_directed():\n        m = m / 2.0\n\n    cov = 0.0\n    var = 0.0\n    for i in g.nodes:\n        for j in g.nodes:\n            cov += (A[g.mapping.to_idx(i), g.mapping.to_idx(j)] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n            if i != j:\n                var -= (d[i] * d[j]) / (2 * m) * d[i] * d[j]\n            else:\n                var += (d[i] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n    return cov / var\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_central_moment","title":"<code>degree_central_moment</code>","text":"<p>Calculates the k-th central moment of the degree distribution.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which to calculate the k-th central moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_central_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th central moment of the degree distribution.\n\n    Args:\n        graph: The graph for which to calculate the k-th central moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mean = _np.mean(degree_sequence(graph, mode=mode))\n    m = 0.0\n    for x in p_k:\n        m += (x - mean) ** k * p_k[x]\n    return m\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_distribution","title":"<code>degree_distribution</code>","text":"<p>Calculates the (unweighted) degree distribution of a graph</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_distribution(g: Graph, mode: str = \"total\") -&gt; Dict[int, float]:\n    \"\"\"Calculates the (unweighted) degree distribution of a graph\"\"\"\n    d = g.degrees(mode, return_tensor=False)    \n\n    cnt: defaultdict = defaultdict(float)\n    for v in g.nodes:\n        cnt[d[v]] += 1.0 / g.n\n    return cnt\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_generating_function","title":"<code>degree_generating_function</code>","text":"<p>Returns the generating function of the degree distribution of a network,     calculated for either a single argument x or a list or numpy array of arguments x</p> <p>Returns f(x) where f is the probability generating function for the degree distribution P(k) for a graph. The function is defined in the interval [0,1].  The value returned is from the range [0,1]. The following properties hold:</p> <p>[1/k! d^k/dx f]_{x=0} = P(k) with d^k/dx f being the k-th derivative of f by x</p> <p>f'(1) =  with f' being the first derivative and  the mean degree <p>[(x d/dx)^m f]_{x=1} =  with  being the m-th raw moment of P <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which the generating function shall be computed</p> required float, list, numpy.ndarray <p>The argument(s) for which value(s) f(x) shall be computed.</p> <p>Example: <pre><code>    # Generate simple network\n    import pathpyG as pp\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n    # Return single function value\n    val = pp.statistics.degreee_generating_func(n, 0.3)\n    print(val)\n    0.069\n\n    # Plot generating function of degree distribution\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func(n, x)\n    x = plt.plot(x, y)\n    # [Function plot]\n\n    # Plot generating function based on degree sequence\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func([1,2,1,2], x)\n    x = plt.plot(x, y)\n    # [Function plot]\n</code></pre></p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_generating_function(\n    graph: Graph, x: float | list[float] | _np.ndarray, mode: str = \"total\"\n) -&gt; float | _np.ndarray:\n    \"\"\"Returns the generating function of the degree distribution of a network,\n        calculated for either a single argument x or a list or numpy array of arguments x\n\n\n    Returns f(x) where f is the probability generating function for the degree\n    distribution P(k) for a graph. The function is defined in the interval\n    [0,1].  The value returned is from the range [0,1]. The following properties\n    hold:\n\n    [1/k! d^k/dx f]_{x=0} = P(k)\n    with d^k/dx f being the k-th derivative of f by x\n\n    f'(1) = &lt;k&gt;\n    with f' being the first derivative and &lt;k&gt; the mean degree\n\n    [(x d/dx)^m f]_{x=1} = &lt;k^m&gt;\n    with &lt;k^m&gt; being the m-th raw moment of P\n\n    Args:\n        graph: The graph for which the generating function shall be computed\n\n    x:  float, list, numpy.ndarray\n        The argument(s) for which value(s) f(x) shall be computed.\n\n    Example:\n    ```py\n        # Generate simple network\n        import pathpyG as pp\n        import numpy as np\n        import matplotlib.pyplot as plt\n\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                    ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n        # Return single function value\n        val = pp.statistics.degreee_generating_func(n, 0.3)\n        print(val)\n        0.069\n\n        # Plot generating function of degree distribution\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func(n, x)\n        x = plt.plot(x, y)\n        # [Function plot]\n\n        # Plot generating function based on degree sequence\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func([1,2,1,2], x)\n        x = plt.plot(x, y)\n        # [Function plot]\n    ```\n    \"\"\"\n\n    p_k = degree_distribution(graph, mode=mode)\n\n    if isinstance(x, float):\n        x_range = [x]\n    else:\n        x_range = x\n\n    values: defaultdict = defaultdict(float)\n    for k in p_k:\n        for v in x_range:\n            values[v] += p_k[k] * v**k\n\n    _values: float | _np.ndarray\n    if len(x_range) &gt; 1:\n        _values = _np.fromiter(values.values(), dtype=float)\n    else:\n        _values = values[x]\n    return _values\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_raw_moment","title":"<code>degree_raw_moment</code>","text":"<p>Calculates the k-th raw moment of the degree distribution of a network</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph in which to calculate the k-th raw moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_raw_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th raw moment of the degree distribution of a network\n\n    Args:\n        graph:  The graph in which to calculate the k-th raw moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mom = 0.0\n    for x in p_k:\n        mom += x**k * p_k[x]\n    return mom\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_sequence","title":"<code>degree_sequence</code>","text":"<p>Calculates the (unweighted) degree sequence of an undirected network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <p>The <code>Graph</code> object for which degrees are calculated</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_sequence(g: Graph, mode: str = \"total\") -&gt; _np.array:\n    \"\"\"Calculates the (unweighted) degree sequence of an undirected network.\n\n    Args:\n        graph: The `Graph` object for which degrees are calculated\n    \"\"\"\n    return g.degrees(mode, return_tensor=True).detach().numpy()\n</code></pre>"},{"location":"reference/pathpyG/statistics/clustering/","title":"clustering","text":""},{"location":"reference/pathpyG/statistics/clustering/#pathpyG.statistics.clustering.closed_triads","title":"<code>closed_triads</code>","text":"<p>Calculates the set of edges that represent a closed triad around a given node v.</p>"},{"location":"reference/pathpyG/statistics/clustering/#pathpyG.statistics.clustering.closed_triads--parameters","title":"Parameters","text":"<p>network : Network</p> <pre><code>The network in which to calculate the list of closed triads\n</code></pre> Source code in <code>src/pathpyG/statistics/clustering.py</code> <pre><code>def closed_triads(g: Graph, v: str) -&gt; Set:\n    \"\"\"Calculates the set of edges that represent a closed triad\n    around a given node v.\n\n    Parameters\n    ----------\n\n    network : Network\n\n        The network in which to calculate the list of closed triads\n\n    \"\"\"\n    c_triads: set = set()\n    edges = set()\n\n    # Collect all edges of successors\n    for x in g.successors(v):\n        for y in g.successors(x):\n            edges.add((x, y))\n\n    for x, y in edges:\n        if y in g.successors(v):\n            c_triads.add((x, y))\n    return c_triads\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/","title":"degrees","text":""},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_assortativity","title":"<code>degree_assortativity</code>","text":"<p>Calculate the degree assortativity</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_assortativity(g: Graph, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculate the degree assortativity\"\"\"\n\n    A = g.sparse_adj_matrix().todense()\n    m = _np.sum(A)\n\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n    elif not g.is_directed():\n        m = m / 2.0\n\n    cov = 0.0\n    var = 0.0\n    for i in g.nodes:\n        for j in g.nodes:\n            cov += (A[g.mapping.to_idx(i), g.mapping.to_idx(j)] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n            if i != j:\n                var -= (d[i] * d[j]) / (2 * m) * d[i] * d[j]\n            else:\n                var += (d[i] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n    return cov / var\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_central_moment","title":"<code>degree_central_moment</code>","text":"<p>Calculates the k-th central moment of the degree distribution.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which to calculate the k-th central moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_central_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th central moment of the degree distribution.\n\n    Args:\n        graph: The graph for which to calculate the k-th central moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mean = _np.mean(degree_sequence(graph, mode=mode))\n    m = 0.0\n    for x in p_k:\n        m += (x - mean) ** k * p_k[x]\n    return m\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_distribution","title":"<code>degree_distribution</code>","text":"<p>Calculates the (unweighted) degree distribution of a graph</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_distribution(g: Graph, mode: str = \"total\") -&gt; Dict[int, float]:\n    \"\"\"Calculates the (unweighted) degree distribution of a graph\"\"\"\n    d = g.degrees(mode, return_tensor=False)    \n\n    cnt: defaultdict = defaultdict(float)\n    for v in g.nodes:\n        cnt[d[v]] += 1.0 / g.n\n    return cnt\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_generating_function","title":"<code>degree_generating_function</code>","text":"<p>Returns the generating function of the degree distribution of a network,     calculated for either a single argument x or a list or numpy array of arguments x</p> <p>Returns f(x) where f is the probability generating function for the degree distribution P(k) for a graph. The function is defined in the interval [0,1].  The value returned is from the range [0,1]. The following properties hold:</p> <p>[1/k! d^k/dx f]_{x=0} = P(k) with d^k/dx f being the k-th derivative of f by x</p> <p>f'(1) =  with f' being the first derivative and  the mean degree <p>[(x d/dx)^m f]_{x=1} =  with  being the m-th raw moment of P <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which the generating function shall be computed</p> required float, list, numpy.ndarray <p>The argument(s) for which value(s) f(x) shall be computed.</p> <p>Example: <pre><code>    # Generate simple network\n    import pathpyG as pp\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n    # Return single function value\n    val = pp.statistics.degreee_generating_func(n, 0.3)\n    print(val)\n    0.069\n\n    # Plot generating function of degree distribution\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func(n, x)\n    x = plt.plot(x, y)\n    # [Function plot]\n\n    # Plot generating function based on degree sequence\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func([1,2,1,2], x)\n    x = plt.plot(x, y)\n    # [Function plot]\n</code></pre></p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_generating_function(\n    graph: Graph, x: float | list[float] | _np.ndarray, mode: str = \"total\"\n) -&gt; float | _np.ndarray:\n    \"\"\"Returns the generating function of the degree distribution of a network,\n        calculated for either a single argument x or a list or numpy array of arguments x\n\n\n    Returns f(x) where f is the probability generating function for the degree\n    distribution P(k) for a graph. The function is defined in the interval\n    [0,1].  The value returned is from the range [0,1]. The following properties\n    hold:\n\n    [1/k! d^k/dx f]_{x=0} = P(k)\n    with d^k/dx f being the k-th derivative of f by x\n\n    f'(1) = &lt;k&gt;\n    with f' being the first derivative and &lt;k&gt; the mean degree\n\n    [(x d/dx)^m f]_{x=1} = &lt;k^m&gt;\n    with &lt;k^m&gt; being the m-th raw moment of P\n\n    Args:\n        graph: The graph for which the generating function shall be computed\n\n    x:  float, list, numpy.ndarray\n        The argument(s) for which value(s) f(x) shall be computed.\n\n    Example:\n    ```py\n        # Generate simple network\n        import pathpyG as pp\n        import numpy as np\n        import matplotlib.pyplot as plt\n\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                    ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n        # Return single function value\n        val = pp.statistics.degreee_generating_func(n, 0.3)\n        print(val)\n        0.069\n\n        # Plot generating function of degree distribution\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func(n, x)\n        x = plt.plot(x, y)\n        # [Function plot]\n\n        # Plot generating function based on degree sequence\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func([1,2,1,2], x)\n        x = plt.plot(x, y)\n        # [Function plot]\n    ```\n    \"\"\"\n\n    p_k = degree_distribution(graph, mode=mode)\n\n    if isinstance(x, float):\n        x_range = [x]\n    else:\n        x_range = x\n\n    values: defaultdict = defaultdict(float)\n    for k in p_k:\n        for v in x_range:\n            values[v] += p_k[k] * v**k\n\n    _values: float | _np.ndarray\n    if len(x_range) &gt; 1:\n        _values = _np.fromiter(values.values(), dtype=float)\n    else:\n        _values = values[x]\n    return _values\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_raw_moment","title":"<code>degree_raw_moment</code>","text":"<p>Calculates the k-th raw moment of the degree distribution of a network</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph in which to calculate the k-th raw moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_raw_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th raw moment of the degree distribution of a network\n\n    Args:\n        graph:  The graph in which to calculate the k-th raw moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mom = 0.0\n    for x in p_k:\n        mom += x**k * p_k[x]\n    return mom\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_sequence","title":"<code>degree_sequence</code>","text":"<p>Calculates the (unweighted) degree sequence of an undirected network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <p>The <code>Graph</code> object for which degrees are calculated</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_sequence(g: Graph, mode: str = \"total\") -&gt; _np.array:\n    \"\"\"Calculates the (unweighted) degree sequence of an undirected network.\n\n    Args:\n        graph: The `Graph` object for which degrees are calculated\n    \"\"\"\n    return g.degrees(mode, return_tensor=True).detach().numpy()\n</code></pre>"},{"location":"reference/pathpyG/statistics/node_similarities/","title":"similarities","text":""},{"location":"reference/pathpyG/utils/","title":"utils","text":""},{"location":"reference/pathpyG/utils/config/","title":"config","text":"<p>Config reader.</p>"},{"location":"reference/pathpyG/utils/convert/","title":"convert","text":"<p>Utility functions for converting between different data types.</p>"},{"location":"reference/pathpyG/utils/convert/#pathpyG.utils.convert.to_numpy","title":"<code>to_numpy</code>","text":"<p>Convert an iterable (including a tensor or tensor subclasses like <code>torch_geometric.Edge_Index</code>) to numpy.</p> <p>Parameters:</p> Name Type Description Default <code>input_iterable</code> <code>torch.Tensor | numpy.ndarray | list</code> <p>Tensor, tensor subclass, numpy array or list.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Numpy array.</p> Source code in <code>src/pathpyG/utils/convert.py</code> <pre><code>def to_numpy(input_iterable: torch.Tensor | np.ndarray | list) -&gt; np.ndarray:\n    \"\"\"\n    Convert an iterable (including a tensor or tensor subclasses like `torch_geometric.Edge_Index`) to numpy.\n\n    Args:\n        input_iterable: Tensor, tensor subclass, numpy array or list.\n\n    Returns:\n        Numpy array.\n    \"\"\"\n    if isinstance(input_iterable, (EdgeIndex, Index)):\n        return input_iterable.as_tensor().cpu().numpy()\n    elif isinstance(input_iterable, torch.Tensor):\n        return input_iterable.cpu().numpy()\n    elif isinstance(input_iterable, (list, tuple)):\n        return np.array(input_iterable)\n    elif isinstance(input_iterable, np.ndarray):\n        return input_iterable\n</code></pre>"},{"location":"reference/pathpyG/utils/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/utils/dbgnn/#pathpyG.utils.dbgnn.generate_bipartite_edge_index","title":"<code>generate_bipartite_edge_index</code>","text":"<p>Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.</p> Source code in <code>src/pathpyG/utils/dbgnn.py</code> <pre><code>def generate_bipartite_edge_index(\n    g: Graph, g2: Graph, mapping: str = \"last\", device: Optional[torch.device] = None\n) -&gt; torch.Tensor:\n    \"\"\"Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.\"\"\"\n\n    if mapping == \"last\":\n        bipartide_edge_index = torch.tensor([list(range(g2.n)), [v[1] for v in g2.data.node_sequence]], device=device)\n\n    elif mapping == \"first\":\n        bipartide_edge_index = torch.tensor([list(range(g2.n)), [v[0] for v in g2.data.node_sequence]], device=device)\n    else:\n        bipartide_edge_index = torch.tensor(\n            [\n                list(range(g2.n)) + list(range(g2.n)),\n                [v[0] for v in g2.data.node_sequence] + [v[1] for v in g2.data.node_sequence],\n            ],\n            device=device,\n        )\n\n    return bipartide_edge_index\n</code></pre>"},{"location":"reference/pathpyG/utils/logger/","title":"logger","text":""},{"location":"reference/pathpyG/utils/progress/","title":"progress","text":"<p>Progressbar for pathpy.</p>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_console","title":"<code>tqdm_console</code>","text":"<p>Progressbar for a console environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_console(*args, **kwargs):\n    \"\"\"Progressbar for a console environment.\"\"\"\n    if len(args[0]) &gt; config[\"progress\"][\"min_iter\"]:\n        return tq(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_disabled","title":"<code>tqdm_disabled</code>","text":"<p>Disable the progress bar and return initial iterator.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_disabled(it, *args, **kwargs):\n    \"\"\"Disable the progress bar and return initial iterator.\"\"\"\n    return it\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_notebook","title":"<code>tqdm_notebook</code>","text":"<p>Progressbar for a notebook environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_notebook(*args, **kwargs):\n    \"\"\"Progressbar for a notebook environment.\"\"\"\n    if len(args[0]) &gt; config[\"progress\"][\"min_iter\"]:\n        return tqn(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/visualisations/","title":"visualisations","text":"<p>PathpyG visualizations.</p>"},{"location":"reference/pathpyG/visualisations/plot/","title":"PathpyG Visualisations","text":"<p>This page provides an overview of the available visualisations and the supported backends. It also describes which displaying and saving options are available as well as the supported keyword arguments for customized plot styling.</p> <p>Methods</p> <ul> <li><code>show(**kwargs)</code>: Show Visualisation</li> <li><code>save(filename: str, **kwargs)</code>: Save Visualisation to hard drive</li> </ul> <p>kwargs for saving Manim plots:</p> <ul> <li><code>filename</code> (<code>str</code>): Name to assign to the output file. This keyword is necessary for saving.</li> </ul> <p>For display use the <code>show()</code> method instead of <code>save()</code>.</p>"},{"location":"reference/pathpyG/visualisations/plot/#supported-features-by-backend","title":"Supported Features by Backend","text":"Backend Static Networks Temporal Networks Available File Formats d3.js \u2714\ufe0f \u2714\ufe0f <code>svg</code>, <code>html</code>, <code>json</code> (dynamic) manim \u274c \u2714\ufe0f <code>mp4</code>, <code>gif</code> matplotlib \u2714\ufe0f \u274c <code>png</code>, <code>svg</code>, <code>pdf</code>, etc. tikz \u2714\ufe0f \u274c <code>pdf</code>, <code>tex</code>"},{"location":"reference/pathpyG/visualisations/plot/#keyword-arguments-overview","title":"Keyword Arguments Overview","text":"Argument d3.js manim matplotlib tikz Short Description General <code>delta</code> \u2714\ufe0f \u2714\ufe0f \u274c Duration of timestep (ms) <code>start</code> \u2714\ufe0f \u2714\ufe0f \u274c Animation start timestep <code>end</code> \u2714\ufe0f \u2714\ufe0f \u274c Animation end timestep (last edge by default) <code>intervals</code> \u2714\ufe0f \u2714\ufe0f \u274c Number of animation intervals <code>dynamic_layout_interval</code> \u274c \u2714\ufe0f \u274c Steps between layout recalculations <code>background_color</code> \u274c \u2714\ufe0f \u274c Background color (name, hex, RGB) <code>width</code> \u2714\ufe0f \u274c \u274c Width of the output <code>height</code> \u2714\ufe0f \u274c \u274c Height of the output <code>lookahead</code> \u274c \u2714\ufe0f \u274c \u274c for layout computation <code>lookbehind</code> \u274c \u2714\ufe0f \u274c \u274c for layout computation Nodes <code>node_size</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Radius of nodes (uniform or per-node) <code>node_color</code> \ud83d\udfe8 \u2714\ufe0f \ud83d\udfe8 \ud83d\udfe8 Node fill color <code>node_cmap</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Colormap for scalar node values <code>node_opacity</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Node fill opacity (0 transparent, 1 solid) <code>node_label</code> \u2714\ufe0f \u2714\ufe0f \u274c Label text shown with nodes Edges <code>edge_size</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Edge width (uniform or per-edge) <code>edge_color</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Edge line color <code>edge_cmap</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Colormap for scalar edge values <code>edge_opacity</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Edge line opacity (0 transparent, 1 solid) <p>Legend: \u2714\ufe0f Supported\u2003\ud83d\udfe8 Partially Supported\u2003\u274c Not Supported </p>"},{"location":"reference/pathpyG/visualisations/plot/#detailed-description-of-keywords","title":"Detailed Description of Keywords","text":"<p>The default values may differ for each individual Backend.</p>"},{"location":"reference/pathpyG/visualisations/plot/#general","title":"General","text":"<ul> <li><code>delta</code> (int): Duration (in milliseconds) of each animation timestep.</li> <li><code>start</code> (int): Starting timestep of the animation sequence.</li> <li><code>end</code>(int or None): Ending timestep; defaults to the last timestamp of the input data.</li> <li><code>intervals</code>(int): Number of discrete animation steps.</li> <li><code>dynamic_layout_interval</code> (int): How often (in timesteps) the layout recomputes.</li> <li><code>background_color</code>(str or tuple): Background color of the plot, accepts color names, hex codes or RGB tuples.</li> <li><code>width</code>  (int): width of the output</li> <li><code>height</code> (int): height of the output</li> <li><code>look_ahead</code> (int): timesteps in the future to include while calculating layout</li> <li><code>look_behind</code> (int): timesteps into the past to include while calculating layout</li> </ul>"},{"location":"reference/pathpyG/visualisations/plot/#nodes","title":"Nodes","text":"<ul> <li><code>node_size</code>: Node radius; either a single float applied to all nodes or a dictionary with sizes per node ID.</li> <li><code>node_color</code>: Fill color(s) for nodes. Can be a single color string referred to by name (<code>\"blue\"</code>), HEX (<code>\"#ff0000\"</code>), RGB(<code>(255,0,0)</code>), float, a list of colors cycling through nodes or a dictionary with color per node in one of the given formats. Manim additionally supports timed node color changes in the format <code>{\"node_id-timestep\": color}</code> (i.e. <code>{a-2.0\" : \"yellow\"}</code>) </li> <li><code>node_cmap</code>: Colormap used when node colors are numeric.</li> <li><code>node_opacity</code>: Opacity level for nodes, either uniform or per node.</li> <li><code>node_label</code> (dict): Assign text labels to nodes</li> </ul>"},{"location":"reference/pathpyG/visualisations/plot/#edges","title":"Edges","text":"<ul> <li><code>edge_size</code>: Width of edges, can be uniform or specified per edge in a dictionary with size per edge ID.</li> <li><code>edge_color</code>: Color(s) of edges; supports single or multiple colors (see <code>node_color</code> above).</li> <li><code>edge_cmap</code>: Colormap used when edge colors are numeric.</li> <li><code>edge_opacity</code>: Opacity for edges, uniform or per edge.</li> </ul>"},{"location":"reference/pathpyG/visualisations/plot/#usage-examples","title":"Usage Examples","text":"<p>d3.js <pre><code>import pathpyG as pp\n\n# Example network data\ntedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot with custom settings and display inline\npp.plot(\n    t,\n    backend= 'd3js', \n    node_size = {\"a\": 15, \"b\": 5},\n    node_color = \"grey\",\n    edge_opacity = 0.7,\n)\n</code></pre></p> <p>manim <pre><code>import pathpyG as pp\n\n# Example network data\ntedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot with custom settings and display inline\npp.plot(\n    t,\n    backend=\"manim\",\n    dynamic_layout_interval=1,\n    edge_color={\"b-a-3.0\": \"red\", \"c-b-4.0\": (220,30,50)},\n    node_color = {\"c-3.0\" : \"yellow\"},\n    edge_size=6,\n    node_label={\"a\": \"a\", \"b\": \"b\", \"c\": \"c\", \"d\" : \"d\"},\n    font_size=20,\n)\n</code></pre></p> <p>matplotlib <pre><code>import pathpyG as pp\n\n# Example network data (static)\ng = Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]))\n\n# Create static plot with custom settings and display inline\npp.plot(\n    g,\n    backend= 'matplotlib', \n    edge_color= \"grey\",\n    node_color = \"blue\"\n)\n</code></pre> </p> <p>For more details and usage examples, see Manim Visualisation Tutorial,Visualisation Tutorial and Develop your own plot Functions</p>"},{"location":"reference/pathpyG/visualisations/_manim/","title":"Visualisation using Manim","text":"<p>The <code>_manim</code> submodule provides plotting tools for creating Manim-based visualisations of temporal networks. Designed for use in Jupyter notebooks or standalone rendering, it allows animated plots of temporal graphs while offering a wide range of customizable styling options.</p>"},{"location":"reference/pathpyG/visualisations/_manim/#classes","title":"Classes","text":""},{"location":"reference/pathpyG/visualisations/_manim/#manimplot","title":"<code>ManimPlot</code>","text":"<p>Base class for Manim visualisations integrated with Jupyter notebooks. Defines the interface for rendering and exporting animations from data.</p> <p>Methods</p> <ul> <li><code>show(**kwargs)</code>: Render and display inline in Jupyter Notebook</li> <li><code>save(filename: str, **kwargs)</code>: Save animation to disk </li> </ul> <p>kwargs for saving Manim plots:</p> <ul> <li><code>filename</code> (<code>str</code>): Name the rendered file should be given. This keyword is necessary for saving.</li> <li><code>save_as</code> {<code>gif</code>,<code>mp4</code>}: Saving format options. Default is <code>mp4</code></li> <li><code>save_dir</code> (<code>str</code>): Directory path to save the Output to. Default is current working directory.</li> </ul> <p>For rendering and inline display use the <code>show()</code> method instead of <code>save()</code>.</p>"},{"location":"reference/pathpyG/visualisations/_manim/#temporalnetworkplot","title":"<code>TemporalNetworkPlot</code>","text":"<p>Animation class for temporal graphs. Supports dynamic layout, time-based color changes, and further customized styling options.</p>"},{"location":"reference/pathpyG/visualisations/_manim/#keyword-arguments-overview","title":"Keyword Arguments Overview","text":"Argument Type Default Short Description General <code>delta</code> int 1000 Duration of timestep (ms) <code>start</code> int 0 Animation start timestep <code>end</code> int / None None Animation end timestep (last edge by default) <code>intervals</code> int None Number of animation intervals <code>dynamic_layout_interval</code> int None Steps between layout recalculations <code>background_color</code> str WHITE Background color (name, hex, RGB, or Manim) Nodes <code>node_size</code> float / dict 0.4 Radius of nodes (uniform or per-node) <code>node_color</code> str / list / dict / float / tuple BLUE Node fill color or list of colors <code>node_cmap</code> Colormap None Colormap for scalar node values <code>node_opacity</code> float / dict 1 Node fill opacity (0 transparent, 1 solid) <code>node_color_timed</code> list None Color Changes for Nodes at timestep Edges <code>edge_size</code> float / dict 0.4 Edge width (uniform or per-edge) <code>edge_color</code> str / list / dict / float / tuple GRAY Edge line color or list of colors <code>edge_cmap</code> Colormap None Colormap for scalar edge values <code>edge_opacity</code> float / dict 1 Edge line opacity (0 transparent, 1 solid)"},{"location":"reference/pathpyG/visualisations/_manim/#detailed-descriptions","title":"Detailed Descriptions","text":""},{"location":"reference/pathpyG/visualisations/_manim/#general","title":"General","text":"<ul> <li><code>delta</code>: Duration (in milliseconds) of each animation timestep.</li> <li><code>start</code>: Starting timestep of the animation sequence.</li> <li><code>end</code>: Ending timestep; defaults to the last timestamp of the input data.</li> <li><code>intervals</code>: Number of discrete animation steps.</li> <li><code>dynamic_layout_interval</code>: How often (in timesteps) the layout recomputes.</li> <li><code>background_color</code>: Background color of the plot, accepts color names, hex codes, RGB tuples, or Manim color constants.</li> </ul>"},{"location":"reference/pathpyG/visualisations/_manim/#nodes","title":"Nodes","text":"<ul> <li><code>node_size</code>: Node radius; either a single float applied to all nodes or a dictionary with sizes per node ID.</li> <li><code>node_color</code>: Fill color(s) for nodes. Can be a single color string referred to by name (<code>\"blue\"</code>), HEX (<code>\"#ff0000\"</code>), RGB(<code>(255,0,0)</code>), float, a list of colors cycling through nodes or a dictionary with color per node in one of the given formats</li> <li><code>node_cmap</code>: Colormap used when node colors are numeric.</li> <li><code>node_opacity</code>: Opacity level for nodes, either uniform or per node.</li> <li><code>node_color_timed</code>: List containing color changes at certain time steps for a certain node. Tuples in the list follow <code>('node_id',(t, color))</code> format to indicate for a node with node_id a change in color at time t. Color can be a single color string referred to by name, HEX, RGB or float.</li> </ul>"},{"location":"reference/pathpyG/visualisations/_manim/#edges","title":"Edges","text":"<ul> <li><code>edge_size</code>: Width of edges, can be uniform or specified per edge in a dictionary with size per edge ID.</li> <li><code>edge_color</code>: Color(s) of edges; supports single or multiple colors (see <code>node_color</code> above).</li> <li><code>edge_cmap</code>: Colormap used when edge colors are numeric.</li> <li><code>edge_opacity</code>: Opacity for edges, uniform or per edge.</li> </ul>"},{"location":"reference/pathpyG/visualisations/_manim/#notable-methods","title":"Notable Methods","text":"<ul> <li><code>construct</code>: Core method for generating the Manim animation</li> <li><code>get_layout()</code>: Computed node 3D positions based on temporal windows</li> <li><code>get_color_at_time()</code>: Determines a node\u00b4s color at a given timestep</li> <li><code>compute_edge_index()</code>: converts input data into <code>(source, target, time)</code> tuples</li> </ul>"},{"location":"reference/pathpyG/visualisations/_manim/#usage-example","title":"Usage Example","text":"<pre><code>import pathpyG as pp\n\n# Example network data\ntedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4)]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot with custom settings and display inline\npp.plot(\n    t,\n    backend= 'manim', \n    delta = 5,\n    start= 1,\n    end = 10,\n    background_color = '#f0f0f0',\n    node_size = {\"a\": 0.6, \"b\": 0.3},\n    node_color = [\"red\", \"blue\"],\n    edge_color = {'a-b-1.0':0.6, 'd-c-4.0':'green'},\n    edge_opacity = 0.7,\n    node_color_timed =  [('a', (1, 'yellow')), ('b', (2, 'blue')), ('c', (4, 0.1)), ('b', 4, (255,0,0))]\n)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/#notes","title":"Notes","text":"<ul> <li>The Manim config is adjusted internally for resolution, framerate and format</li> </ul>"},{"location":"tutorial/basic_concepts/","title":"Basic Concepts","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nimport torch_geometric as pyG\nfrom torch_geometric.data import Data\nimport pandas as pd\n\nimport pathpyG as pp\n</pre> import torch import torch_geometric as pyG from torch_geometric.data import Data import pandas as pd  import pathpyG as pp <pre>/opt/conda/lib/python3.11/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n  return torch._C._show_config()\n</pre> In\u00a0[2]: Copied! <pre>d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]]))\ng = pp.Graph(d)\nprint(g)\n</pre> d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]])) g = pp.Graph(d) print(g) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>If we do not need additional node or edge attributes, we can use the class function <code>Graph.from_edge_index</code> to directly create a graph based on an edge index:</p> In\u00a0[3]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]))\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]])) print(g) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>We may want to inlude isolated nodes that do not have an edge. We can do so by passing a <code>num_nodes</code> parameter. The following graph thus contains a fourth node (which we could name as <code>d</code>) that is not connected to any of the other nodes.</p> In\u00a0[4]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes=4)\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes=4) print(g) <pre>Directed graph with 4 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>In both cases, the <code>Graph</code> instance has a property <code>g.data</code> that stores a <code>pyG</code> <code>Data</code> object that includes the edge index as well as any further node-, edge- or graph-level attributes.</p> In\u00a0[5]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 3], num_nodes=4, node_sequence=[4, 1])\n</pre> In\u00a0[6]: Copied! <pre>print(g.data.edge_index)\n</pre> print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1],\n           [2, 1, 2]], sparse_size=(4, 4), nnz=3, sort_order=row)\n</pre> <p>Note that the <code>edge_index</code> is actually of type <code>pyG.EdgeIndex</code>, which is a subclass of <code>torch.Tensor</code>. Any tensor passed as an edge index in the constructor of <code>Graph</code> will automatically be converted to an <code>EdgeIndex</code> instance, as this internally allows us to provide efficient edge traveral routines based on sparse matrix operations. To support this, the edge index will be automatically sorted by row when the <code>Graph</code> object is created. To avoid this additional sort operation, you can pass an already sorted <code>EdgeIndex</code> object in the <code>Data</code> object in the constructor or using the <code>from_edge_index</code> class function.</p> <p>We can use the generators <code>nodes</code> and <code>edges</code> to iterate through the nodes and edges of a graph as follows:</p> In\u00a0[5]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>0\n1\n2\n3\n(0, 2)\n(0, 1)\n(1, 2)\n</pre> <p>While the index-based representation of nodes allows for efficient tensor-based operations, it is often convenient to use string identifiers to refer to nodes. To simplify the handling of graphs with such node identifiers, <code>pathpyG</code> provides a class <code>IndexMap</code> that transparently maps string identifiers to integer indices. For our small example graph, we can create an <code>IndexMap</code> that associates node indices with string IDs. For our example, we can create a mapping as follows:</p> In\u00a0[6]: Copied! <pre>m = pp.IndexMap(['a', 'b', 'c', 'd'])\nprint(m)\n</pre> m = pp.IndexMap(['a', 'b', 'c', 'd']) print(m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n</pre> <p>We can use the functions <code>IndexMap.to_id</code> or <code>IndexMap.to_idx</code> to map a node to an index or an ID:</p> In\u00a0[10]: Copied! <pre>print(m.to_id(0))\n</pre> print(m.to_id(0)) <pre>a\n</pre> In\u00a0[11]: Copied! <pre>print(m.to_idx('b'))\n</pre> print(m.to_idx('b')) <pre>1\n</pre> <p><code>pathpyG</code> can apply this mapping transparently for the user. For this, we can add a mapping to a <code>Graph</code> object, either by passing it in the constructor or by setting the <code>mapping</code> attribute of an existing <code>Graph</code> instance.</p> In\u00a0[12]: Copied! <pre>g.mapping = m\n</pre> g.mapping = m <p>If we now iterate through the nodes and edges of the graph, we get:</p> In\u00a0[7]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>0\n1\n2\n3\n(0, 2)\n(0, 1)\n(1, 2)\n</pre> <p>We can also pass an <code>IndexMap</code> object to the constructor of the <code>Graph</code> class. This transparently applies the mapping in all future operations on this graph instance.</p> In\u00a0[8]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes = 4, mapping=m)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes = 4, mapping=m) <p>Above, we have created a graph based on an edge index tensor and we then additionally applied a mapping that we manually defined. We often have data in the form on an edge list, where edges are given as tuples of non-numeric node identifiers. The class function <code>Graph.from_edge_list</code> simplifies the construction of a <code>Graph</code> from such edge lists. It automatically creates an internal integer-based representation of the edge index along with the associated <code>IndexMap</code>, where integer node indices are based on the lexicographic order of node IDs.</p> In\u00a0[9]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')])\nprint(g)\nprint(g.data.edge_index)\nprint(g.mapping)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')]) print(g) print(g.data.edge_index) print(g.mapping) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 0, 1],\n           [1, 2, 2]], sparse_size=(3, 3), nnz=3, sort_order=row)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n</pre> <p>We can also pass a custom index mapping, e.g. mapping node <code>c</code> to idex 1 and node <code>b</code> to index 2 (thus deviating from a lexicographic order):</p> In\u00a0[11]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('a','c'), ('b','c')], mapping = pp.IndexMap(['a', 'c', 'b']))\nprint(g.data.edge_index)\nprint(g.mapping)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('a','c'), ('b','c')], mapping = pp.IndexMap(['a', 'c', 'b'])) print(g.data.edge_index) print(g.mapping) <pre>EdgeIndex([[0, 0, 2],\n           [2, 1, 1]], sparse_size=(3, 3), nnz=3, sort_order=row)\na -&gt; 0\nc -&gt; 1\nb -&gt; 2\n\n</pre> In\u00a0[12]: Copied! <pre>g.get_successors(0)\n</pre> g.get_successors(0) Out[12]: <pre>tensor([2, 1])</pre> In\u00a0[23]: Copied! <pre>g.get_predecessors(0)\n</pre> g.get_predecessors(0) Out[23]: <pre>tensor([], dtype=torch.int64)</pre> <p>Note that, even if a mapping is defined, the <code>get_successors</code> and <code>get_predecessors</code> functions always return a tensor with node indices, rather than node IDs. This is useful to support fast tensor-based operations on the list of successors and predecessors. We can however manually map node indices using the <code>IndexMap</code> object stored in the <code>mapping</code> attribute.</p> <p>If we instead want to traverse graphs based on string node IDs, we can use the <code>successors</code> and <code>predecessors</code> generators of the <code>Graph</code> object, which -- if a mapping is defined - yield the string IDs of successor or predecessor nodes for a given node (also identified by its string identifier).</p> In\u00a0[24]: Copied! <pre>for v in g.successors('a'):\n    print(v)\n</pre> for v in g.successors('a'):     print(v) <pre>b\nc\n</pre> In\u00a0[25]: Copied! <pre>for v in g.predecessors('c'):\n    print(v)\n</pre> for v in g.predecessors('c'):     print(v) <pre>a\nb\n</pre> <p>To check (in constant time) whether an edge exists in the graph, we can call the <code>is_edge</code> function:</p> In\u00a0[26]: Copied! <pre>g.is_edge('a', 'b')\n</pre> g.is_edge('a', 'b') Out[26]: <pre>True</pre> <p>Alternatively, we can use the following function to check (in constant time) whether node <code>b</code> is a successor of <code>a</code></p> In\u00a0[27]: Copied! <pre>'b' in g.successors('a')\n</pre> 'b' in g.successors('a') Out[27]: <pre>True</pre> <p>By default, graph objects in <code>pathpyG</code> are directed, i.e. for the graph above, the edge <code>(b,a)</code> does not exist, which we can verify as follows:</p> In\u00a0[28]: Copied! <pre>print('a' in g.successors('b'))\nprint(g.is_edge('b', 'a'))\n</pre> print('a' in g.successors('b')) print(g.is_edge('b', 'a')) <pre>False\nFalse\n</pre> <p>To calculate (directed) in- and out-degrees of nodes, we can use the properties <code>in_degrees</code> and <code>out_degrees</code>, which return a dictionary that maps node IDs to their degrees:</p> In\u00a0[13]: Copied! <pre>for v in g.nodes:\n    print(f\"{v} -&gt; {g.in_degrees[v]}\")\n</pre> for v in g.nodes:     print(f\"{v} -&gt; {g.in_degrees[v]}\") <pre>a -&gt; 0\nc -&gt; 2\nb -&gt; 1\n</pre> <p>The <code>in_degree</code> and <code>out_degree</code> properties are shortcuts to a general <code>degree</code> function that can be used to calculate (weighted) in- and outdegrees.</p> In\u00a0[15]: Copied! <pre>g.degrees(mode='in')\n</pre> g.degrees(mode='in') Out[15]: <pre>{'a': 0, 'c': 2, 'b': 1}</pre> In\u00a0[16]: Copied! <pre>g.degrees(mode='out')\n</pre> g.degrees(mode='out') Out[16]: <pre>{'a': 2, 'c': 0, 'b': 1}</pre> <p>Degrees can be alternatively returned as torch.tensors.</p> In\u00a0[17]: Copied! <pre>g.degrees(mode='in', return_tensor=True)\n</pre> g.degrees(mode='in', return_tensor=True) Out[17]: <pre>tensor([0, 2, 1], dtype=torch.int32)</pre> <p>We can also use arbitrary numerical edge attributes that will be used for a weighted (in- or out) degree calculation.</p> In\u00a0[18]: Copied! <pre>g.data.edge_weight=torch.tensor([1.0, 2.0, 3.0])\n</pre> g.data.edge_weight=torch.tensor([1.0, 2.0, 3.0]) In\u00a0[19]: Copied! <pre>g.degrees(mode='in', edge_attr='edge_weight', return_tensor=True)\n</pre> g.degrees(mode='in', edge_attr='edge_weight', return_tensor=True) Out[19]: <pre>tensor([0., 5., 1.])</pre> In\u00a0[20]: Copied! <pre>g.degrees(mode='out', edge_attr='edge_weight', return_tensor=True)\n</pre> g.degrees(mode='out', edge_attr='edge_weight', return_tensor=True) Out[20]: <pre>tensor([3., 0., 3.])</pre> <p>Importantly, irrespective of how we have generated the graph object, the actual node and edge data are always stored as a <code>pyG</code> data object. This allows us to use the full power of <code>torch</code> and <code>pyG</code>, including the application of transforms, splits, or any easy migration between CPU and GPU-based computation.</p> In\u00a0[21]: Copied! <pre>g.data\n</pre> g.data Out[21]: <pre>Data(edge_index=[2, 3], num_nodes=3, node_sequence=[3, 1], edge_weight=[3])</pre> <p>In general, <code>pathpyG</code> handles device placement (i.e. if a tensor should be placed on CPU or GPU memory) similar to <code>pytorch</code>. By default, all tensors are created on the CPU, as we can see below:</p> In\u00a0[36]: Copied! <pre>g.data.is_cuda\n</pre> g.data.is_cuda Out[36]: <pre>False</pre> <p>If we instead want to create a graph on the GPU, we can specify the device during graph creation.</p> In\u00a0[16]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')], device='cuda')\ng.data.is_cuda\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')], device='cuda') g.data.is_cuda <pre>\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[16], line 1\n----&gt; 1 g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')], device='cuda')\n      2 g.data.is_cuda\n\nFile /workspaces/pathpyG/src/pathpyG/core/graph.py:179, in Graph.from_edge_list(edge_list, is_undirected, mapping, device)\n    174     mapping = IndexMap(node_ids)\n    176 num_nodes = mapping.num_ids()\n    178 edge_index = EdgeIndex(\n--&gt; 179     mapping.to_idxs(edge_list, device=device).T.contiguous(),\n    180     sparse_size=(num_nodes, num_nodes),\n    181     is_undirected=is_undirected,\n    182 )\n    183 return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\nFile /workspaces/pathpyG/src/pathpyG/core/index_map.py:361, in IndexMap.to_idxs(self, nodes, device)\n    359 shape = nodes.shape\n    360 if self.id_shape == (-1,):\n--&gt; 361     return torch.tensor([self.id_to_idx[node] for node in nodes.flatten()], device=device).reshape(shape)\n    362 else:\n    363     return torch.tensor([self.id_to_idx[tuple(node)] for node in nodes.reshape(self.id_shape)], device=device).reshape(\n    364         shape[: -len(self.id_shape) + 1]\n    365     )\n\nFile /opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:314, in _lazy_init()\n    312 if \"CUDA_MODULE_LOADING\" not in os.environ:\n    313     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n--&gt; 314 torch._C._cuda_init()\n    315 # Some of the queued calls may reentrantly call _lazy_init();\n    316 # we need to just return without initializing in that case.\n    317 # However, we must not let any *other* threads in!\n    318 _tls.is_initializing = True\n\nRuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found</pre> <p>We can move a graph that is stored on the GPU back to the CPU using the familiar <code>to</code> function:</p> In\u00a0[38]: Copied! <pre>g = g.to('cpu')\n</pre> g = g.to('cpu') In\u00a0[39]: Copied! <pre>g.data['node_class'] = torch.tensor([[0], [0], [1]])\ng.data['edge_weight'] = torch.tensor([[1], [2], [3]])\ng.data['feature'] = torch.tensor([3, 2])\n</pre> g.data['node_class'] = torch.tensor([[0], [0], [1]]) g.data['edge_weight'] = torch.tensor([[1], [2], [3]]) g.data['feature'] = torch.tensor([3, 2]) <p>Once we have added attributes to nodes, edges, or the graph, those attributes, along with their type and shape will be shown when you print a string representation of the graph object:</p> In\u00a0[40]: Copied! <pre>print(g)\n</pre> print(g) <pre>Directed graph with 3 nodes and 3 edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\"},\n    'Graph Attributes': {'feature': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {'node_class': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\"}}\n</pre> <p>To simplify access to attribute values, the <code>Graph</code> class provides getter and setter functions that allow to access attribute values based on node identifiers. To access the feature <code>node_feature</code> of node <code>a</code>, we can write:</p> In\u00a0[41]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[41]: <pre>tensor([0])</pre> <p>To access the weight of edge <code>(a, b)</code> we can write:</p> In\u00a0[42]: Copied! <pre>g['edge_weight', 'a', 'b']\n</pre> g['edge_weight', 'a', 'b'] Out[42]: <pre>tensor([1])</pre> <p>And finally, graph-based attributes can accessed as follows:</p> In\u00a0[43]: Copied! <pre>g['feature']\n</pre> g['feature'] Out[43]: <pre>tensor([3, 2])</pre> <p>We can also use the setter functions to change attributes:</p> In\u00a0[44]: Copied! <pre>g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda')\n</pre> g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda') <pre>\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[44], line 1\n----&gt; 1 g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda')\n\nFile /opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:314, in _lazy_init()\n    312 if \"CUDA_MODULE_LOADING\" not in os.environ:\n    313     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n--&gt; 314 torch._C._cuda_init()\n    315 # Some of the queued calls may reentrantly call _lazy_init();\n    316 # we need to just return without initializing in that case.\n    317 # However, we must not let any *other* threads in!\n    318 _tls.is_initializing = True\n\nRuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found</pre> In\u00a0[45]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[45]: <pre>tensor([0])</pre> <p>To create sparse adjacency matrix representations of graphs, we can use the following function:</p> In\u00a0[46]: Copied! <pre>print(g.sparse_adj_matrix())\n</pre> print(g.sparse_adj_matrix()) <pre>&lt;COOrdinate sparse matrix of dtype 'float32'\n\twith 3 stored elements and shape (3, 3)&gt;\n  Coords\tValues\n  (0, 2)\t1.0\n  (0, 1)\t1.0\n  (2, 1)\t1.0\n</pre> <p>This returns a <code>scipy.sparse.coo_matrix</code> object, which can be turned into a dense <code>numpy</code> matrix as follows:</p> In\u00a0[47]: Copied! <pre>print(g.sparse_adj_matrix().todense())\n</pre> print(g.sparse_adj_matrix().todense()) <pre>[[0. 1. 1.]\n [0. 0. 0.]\n [0. 1. 0.]]\n</pre> <p>By passing the name of the attribute, we can use edge attributes in the creation of the adjacency matrix. To create a sparse, weighted adjacency matrix that uses the <code>edge_weight</code> attribute of our graph object we can simply write:</p> In\u00a0[48]: Copied! <pre>print(g.sparse_adj_matrix(edge_attr='edge_weight').todense())\n</pre> print(g.sparse_adj_matrix(edge_attr='edge_weight').todense()) <pre>[[0 2 1]\n [0 0 0]\n [0 3 0]]\n</pre> <p>By default, graphs in <code>pathpyG</code> are directed. To represent undirected edges, we must add edges in both directions. We can use the <code>to_undirected()</code> function to make a directed graph undirected, which adds all (missing) edges that point in the opposite direction. This will also automatically duplicate and assign the corresponding edge attributes to the newly formed (directed) edges, i.e. edges are assumed to have the same attributes in both directions.</p> In\u00a0[49]: Copied! <pre>g_u = g.to_undirected()\nprint(g_u)\n</pre> g_u = g.to_undirected() print(g_u) <pre>Undirected graph with 3 nodes and 6 (directed) edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 1])\"},\n    'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {'node_class': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\"}}\n</pre> <p>By default, the <code>Graph</code> object can contain multiple identical edges, so the following is possible:</p> In\u00a0[17]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')])\nprint(g.data.edge_index)\n</pre> g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')]) print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1, 2],\n           [1, 1, 2, 0]], sparse_size=(3, 3), nnz=4, sort_order=row)\n</pre> <p>It is often convenient, to coalesce multi-edges into weighted single-edges, i.e. in the example above we may prefer a graph where each edge occurs once in the edge index, but the edge <code>a-&gt;b</code> has a weight attribute of two, while the two other edges have one.</p> <p>In <code>pathpyG</code> we can do this by turning a graph into a weighted graph, which will coalesce edges and add an edge weight attribute that counts multi-edges in the original istance.</p> In\u00a0[18]: Copied! <pre>g_w = g.to_weighted_graph()\nprint(g_w.data.edge_index)\nprint(g_w['edge_weight', 'a', 'b'])\nprint(g_w['edge_weight', 'b', 'c'])\nprint(g_w['edge_weight', 'c', 'a'])\n</pre> g_w = g.to_weighted_graph() print(g_w.data.edge_index) print(g_w['edge_weight', 'a', 'b']) print(g_w['edge_weight', 'b', 'c']) print(g_w['edge_weight', 'c', 'a']) <pre>EdgeIndex([[0, 1, 2],\n           [1, 2, 0]], sparse_size=(3, 3), nnz=3, sort_order=row)\ntensor(2.)\ntensor(1.)\ntensor(1.)\n</pre> <p>As we will see in a separate notebook focusing on the advanced (temporal) graph visualization features of <code>pathpyG</code>, it is easy to generate (interactive) HTML plots of graphs, that are embedded into jupyter notebooks. You can simply call the <code>pp.plot</code> function on the Graph object:</p> In\u00a0[19]: Copied! <pre>pp.plot(g, edge_color='gray', node_label=g.mapping.node_ids.tolist());\n</pre> pp.plot(g, edge_color='gray', node_label=g.mapping.node_ids.tolist()); In\u00a0[53]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('c','a')])\nprint(g)\n\ndf = pp.io.graph_to_df(g)\nprint(df)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('c','a')]) print(g)  df = pp.io.graph_to_df(g) print(df) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n   v  w\n0  a  b\n1  b  c\n2  c  a\n</pre> In\u00a0[54]: Copied! <pre>g.data.edge_weight = torch.tensor([1.0, 2.0, 3.0])\nprint(g)\n\ndf = pp.io.graph_to_df(g)\nprint(df)\n</pre> g.data.edge_weight = torch.tensor([1.0, 2.0, 3.0]) print(g)  df = pp.io.graph_to_df(g) print(df) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n   v  w  edge_weight\n0  a  b          1.0\n1  b  c          2.0\n2  c  a          3.0\n</pre> In\u00a0[55]: Copied! <pre>node_attr = pd.DataFrame({'v': ['b', 'a', 'c'], 'node_size': [5.0, 2.0, 1.0]})\nprint(node_attr)\n</pre> node_attr = pd.DataFrame({'v': ['b', 'a', 'c'], 'node_size': [5.0, 2.0, 1.0]}) print(node_attr) <pre>   v  node_size\n0  b        5.0\n1  a        2.0\n2  c        1.0\n</pre> In\u00a0[56]: Copied! <pre>pp.io.add_node_attributes(node_attr, g)\nprint(g.data.node_size)\n</pre> pp.io.add_node_attributes(node_attr, g) print(g.data.node_size) <pre>tensor([2., 5., 1.], dtype=torch.float64)\n</pre> In\u00a0[57]: Copied! <pre>edge_attr = pd.DataFrame({'v': ['c', 'a', 'b'], 'w': ['a', 'b', 'c'], 'edge_weight': [42.0, 43.0, 45.0]})\nprint(edge_attr)\n</pre> edge_attr = pd.DataFrame({'v': ['c', 'a', 'b'], 'w': ['a', 'b', 'c'], 'edge_weight': [42.0, 43.0, 45.0]}) print(edge_attr) <pre>   v  w  edge_weight\n0  c  a         42.0\n1  a  b         43.0\n2  b  c         45.0\n</pre> In\u00a0[58]: Copied! <pre>pp.io.add_edge_attributes(edge_attr, g)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> pp.io.add_edge_attributes(edge_attr, g) print(g.data.edge_index) print(g.data.edge_weight) <pre>EdgeIndex([[0, 1, 2],\n           [1, 2, 0]], sparse_size=(3, 3), nnz=3, sort_order=row)\ntensor([45., 42., 43.], dtype=torch.float64)\n</pre> In\u00a0[59]: Copied! <pre>df = pp.io.graph_to_df(g, node_indices=True)\nprint(df)\n</pre> df = pp.io.graph_to_df(g, node_indices=True) print(df) <pre>   v  w  edge_weight\n0  0  1         45.0\n1  1  2         42.0\n2  2  0         43.0\n</pre> In\u00a0[60]: Copied! <pre>edge_attr = pd.DataFrame([['c', 'a', 'b'], ['a', 'b', 'c'], [42.0, 43.0, 45.0]])\nprint(edge_attr)\n</pre> edge_attr = pd.DataFrame([['c', 'a', 'b'], ['a', 'b', 'c'], [42.0, 43.0, 45.0]]) print(edge_attr) <pre>      0     1     2\n0     c     a     b\n1     a     b     c\n2  42.0  43.0  45.0\n</pre> In\u00a0[70]: Copied! <pre>pp.io.write_csv(g, path_or_buf='../data/test_graph.csv')\n</pre> pp.io.write_csv(g, path_or_buf='../data/test_graph.csv') In\u00a0[65]: Copied! <pre>import os \nprint(os.getcwd())\n</pre> import os  print(os.getcwd()) <pre>/workspaces/pathpyG/docs/tutorial\n</pre> In\u00a0[71]: Copied! <pre>g = pp.io.read_csv_graph(filename='../data/test_graph.csv')\nprint(g)\nprint(g.data)\nprint(g.mapping)\n</pre> g = pp.io.read_csv_graph(filename='../data/test_graph.csv') print(g) print(g.data) print(g.mapping) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nData(edge_index=[2, 3], num_nodes=3, edge_weight=[3], node_sequence=[3, 1])\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n</pre> In\u00a0[72]: Copied! <pre>g.edge_attrs()\n</pre> g.edge_attrs() Out[72]: <pre>['edge_weight']</pre> In\u00a0[73]: Copied! <pre>g.data\n</pre> g.data Out[73]: <pre>Data(edge_index=[2, 3], num_nodes=3, edge_weight=[3], node_sequence=[3, 1])</pre> In\u00a0[74]: Copied! <pre>pp.algorithms.centrality.closeness_centrality(g)\n</pre> pp.algorithms.centrality.closeness_centrality(g) Out[74]: <pre>{np.str_('a'): 0.6666666666666666,\n np.str_('b'): 0.6666666666666666,\n np.str_('c'): 0.6666666666666666}</pre> In\u00a0[75]: Copied! <pre>pp.algorithms.centrality.eigenvector_centrality(g)\n</pre> pp.algorithms.centrality.eigenvector_centrality(g) Out[75]: <pre>{np.str_('a'): 0.5773502691896258,\n np.str_('b'): 0.5773502691896258,\n np.str_('c'): 0.5773502691896258}</pre> In\u00a0[76]: Copied! <pre>pp.algorithms.centrality.katz_centrality(g)\n</pre> pp.algorithms.centrality.katz_centrality(g) Out[76]: <pre>{np.str_('a'): 0.5773502691896258,\n np.str_('b'): 0.5773502691896258,\n np.str_('c'): 0.5773502691896258}</pre> In\u00a0[20]: Copied! <pre>import numpy as np\nimport seaborn as sns\n\nx = np.linspace(0, 1, 100)\ny = pp.statistics.degree_generating_function(g.to_undirected(), x)\nax = sns.lineplot(x=x, y=y)\nax.set_xlabel('$x$', fontsize=16)\nax.set_ylabel('$G_0(x)$', fontsize=16);\n</pre> import numpy as np import seaborn as sns  x = np.linspace(0, 1, 100) y = pp.statistics.degree_generating_function(g.to_undirected(), x) ax = sns.lineplot(x=x, y=y) ax.set_xlabel('$x$', fontsize=16) ax.set_ylabel('$G_0(x)$', fontsize=16); In\u00a0[21]: Copied! <pre>k_2 = pp.statistics.degree_raw_moment(g.to_undirected(), k=2)\nprint(k_2)\nk_1 = pp.statistics.degree_raw_moment(g.to_undirected(), k=1)\nprint(k_1)\nprint('Molloy-Reed Fraction &lt;k^2&gt;/&lt;k&gt;: ', k_2/k_1)\n</pre> k_2 = pp.statistics.degree_raw_moment(g.to_undirected(), k=2) print(k_2) k_1 = pp.statistics.degree_raw_moment(g.to_undirected(), k=1) print(k_1) print('Molloy-Reed Fraction /: ', k_2/k_1) <pre>4.0\n2.0\nMolloy-Reed Fraction &lt;k^2&gt;/&lt;k&gt;:  2.0\n</pre>"},{"location":"tutorial/basic_concepts/#basic-pathpyg-concepts","title":"Basic pathpyG Concepts\u00b6","text":""},{"location":"tutorial/basic_concepts/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/basic_concepts/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>This first step of our multi-stage introductory tutorial introduces key concepts of <code>pathpyG</code>. While <code>pathpyG</code> targets GPU-accelerated analysis and learning using higher-order graph models for time series data on graphs, it can also be used to represent, analyze and interactively visualize static graphs. For this, it provides a <code>Graph</code> class that is build around the <code>torch_geometric.data.Data</code> object, which has the advantage that we can directly apply <code>pyG</code> transforms and use the <code>Graph</code> object for deep graph learning.</p> <p>In this tutorial you will learn how we can use <code>pathpyG</code> to represent static graphs. We start with basic features to create directed and undirected graphs with node-, edge-, and graph-level attributes. We also show how we can read and write graph data and how we can implement graph algorithms that are based on a traversal of nodes and edges.</p> <p>We first import the modules <code>torch</code>, <code>torch_geometric</code> and <code>pathpyG</code>.</p>"},{"location":"tutorial/basic_concepts/#creating-graph-objects","title":"Creating Graph objects\u00b6","text":"<p>Let's start by generating a simple, directed graph with three nodes <code>a</code>, <code>b</code>, <code>c</code> and three edges <code>(a,b)</code>, <code>(b,c)</code> and <code>(a,b)</code>. The three nodes <code>a</code>, <code>b</code>, and <code>c</code> can be represented by integer indices $0, 1$ and $2$ respectively. Following the tensor-based representation in <code>pyG</code>, we use an <code>edge_index</code> tensor with shape <code>(2,m)</code> to represent the <code>m</code> edges of a graph. We can then add this to a <code>Data</code> object that can hold additional node and edge attributes. We finally pass the <code>Data</code> object to the constructor of the <code>Graph</code> class.</p> <p>Using the mapping of node names to indices specified above, the following code generates a directed <code>Graph</code> with three edges <code>(a,c)</code>, <code>(b,c)</code> and <code>(a,b)</code>.</p>"},{"location":"tutorial/basic_concepts/#traversing-graphs","title":"Traversing Graphs\u00b6","text":"<p>The <code>Graph</code> object provides <code>get_successors</code> and <code>get_predecessors</code> functions, which return the indices of nodes that are connected to a node with a given index. Based on cached CSR (compressed sparse row) and CSC (compressed sparse column) representations cached for the sorted <code>EdgeIndex</code>, access to the successors and predecessors of a node works in constant time, i.e. it does not require to enumerate the <code>edge_index</code> tensor.</p> <p>For node <code>a</code> with index $0$ in our directed network we obtain:</p>"},{"location":"tutorial/basic_concepts/#node-edge-or-graph-level-attributes","title":"Node-, Edge- or Graph-Level Attributes\u00b6","text":"<p>Real-world graphs often have node-, edge-, or graph-level attributes. In <code>pathpyG</code>, we can add attributes as tensors, either by directly assigning them to the <code>pyG</code> data object of an existing graph (or by adding them to the <code>Data</code> object passed to the constructor). Following the <code>pyG</code> semantics of attribute names, we use the prefixes <code>node_</code> and <code>edge_</code> to refer to node- and edge-level attributes. Attributes without those prefixes are assumed to refer to graph-level attributes.</p>"},{"location":"tutorial/basic_concepts/#reading-and-writing-graph-data","title":"Reading and writing graph data\u00b6","text":""},{"location":"tutorial/basic_concepts/#networkx-delegate-mechanism","title":"<code>networkx</code> Delegate Mechanism\u00b6","text":"<p>To calculate node centralities, we can use a <code>networkx</code> delegate mechanism implemented in the module <code>pathpyG.algorithms.centrality</code>. Simply speaking, you can call any function implented in the <code>networkx.centrality</code> module whose name ends with <code>_centrality</code>. The <code>pathpyG</code> graph object will be internally converted to a <code>networkx.DiGraph</code> object, the corresponding centrality function (with all of its parameters) will be called, and the result will be mapped back to nodes based on node IDs.</p> <p>In order to calculate the closeness centralities of all nodes for the graph above, we can call:</p>"},{"location":"tutorial/basic_concepts/#probability-generating-functions-for-degree-distributions","title":"Probability Generating functions for degree distributions\u00b6","text":""},{"location":"tutorial/dbgnn/","title":"Causality-Aware GNNs","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n!pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy as sp\n\nimport torch\nfrom torch_geometric.transforms import RandomNodeSplit\n\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.manifold import TSNE\n\nimport pathpyG as pp\nfrom pathpyG.nn.dbgnn import DBGNN\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n</pre> import numpy as np import matplotlib.pyplot as plt import scipy as sp  import torch from torch_geometric.transforms import RandomNodeSplit  from sklearn.metrics import balanced_accuracy_score from sklearn.manifold import TSNE  import pathpyG as pp from pathpyG.nn.dbgnn import DBGNN  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') In\u00a0[2]: Copied! <pre>t = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False)\nt = t.to(device)\n</pre> t = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False) t = t.to(device) <p>This example has created in such a way that the nodes naturally form three clusters, which are highlighted in the interactive visualization below:</p> In\u00a0[3]: Copied! <pre>style = {}\nstyle['node_color'] = ['green']*10+['red']*10+['blue']*10\npp.plot(t, **style, edge_size=4, edge_color='gray');\n</pre> style = {} style['node_color'] = ['green']*10+['red']*10+['blue']*10 pp.plot(t, **style, edge_size=4, edge_color='gray'); In\u00a0[4]: Copied! <pre>pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray');\n</pre> pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray'); <p>In fact, the topology of this graph corresponds to that of a random graph, i.e. there are not patterns whatsoever in the topology of links. Nevertheless, the temporal graph contains a cluster pattern in the topology of causal or time-respecting paths. In particular, the temporal ordering of time-stamped edges is such that nodes with the same cluster label are more frequently connected by time-respecting paths than nodes with different cluster labels. Hence, nodes within the same clusters can more strongly influence each other in a causal way, i.e. via multiple interactions that follow the arrow of time.</p> <p>Traditional (temporal) graph neural networks will not be able to learn from this pattern, as it is due to the specific microscopic temporal ordering of edges. Using higher-order De Bruijn graph models implemented in pathpyG, we can learn from temporal graph data that contains such patterns. Let us explain this step by step.</p> <p>Referring to the previous tutorial on causal paths in temporal graphs, we first create a node-time directed acyclic graph that captures the causal structure of the temporal graph. In this small example, we will only consider two time-stamped edges $(u,v;t)$ and $(v,w;t')$ to contribute to a causal path iff $0 &lt; t'-t \\leq 1$, i.e. we use a delta for the maximum time difference of one time step.</p> In\u00a0[5]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2)\nprint(m)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2) print(m) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [01:04&lt;00:00, 926.86it/s] \n</pre> <pre>MultiOrderModel with max. order 2\n</pre> <p>We can get the first and second order networks from the Multi Order Network object. The first order network is the network of nodes and edges, while the second order network is the network of first order edges as second order nodes and second order edges. The second order network is a De Bruijn graph that captures the temporal-topological patterns in the data.</p> In\u00a0[6]: Copied! <pre>g = m.layers[1]\ng2 = m.layers[2]\n</pre> g = m.layers[1] g2 = m.layers[2] In\u00a0[7]: Copied! <pre>pp.plot(g, edge_size=2);\n</pre> pp.plot(g, edge_size=2); <p>Since it does not consider patterns in the causal topology of the temporal graph, this is not a meaningful model. We can instead use a second-order De Bruijn graph model, which we can easily fit to the paths:</p> In\u00a0[8]: Copied! <pre>layout_style = {}\nlayout_style['layout'] = 'Fruchterman-Reingold'\nlayout_style['seed'] = 1\nlayout_style['force'] = 0.5\nlayout_style['iterations'] = 300\nlayout = pp.layout(g2, **layout_style)\npp.plot(g2, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib',layout=layout);\n</pre> layout_style = {} layout_style['layout'] = 'Fruchterman-Reingold' layout_style['seed'] = 1 layout_style['force'] = 0.5 layout_style['iterations'] = 300 layout = pp.layout(g2, **layout_style) pp.plot(g2, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib',layout=layout); <p>In this graph, every node is a link and links correspond to causal paths of length two, i.e. temporally ordered sequences consisting of two edges that overlap in the center node. In this graph, we clearly see a cluster pattern that is due to the way in which temporal edges are ordered in time. In particular, we see three clusters, where the edges in three of the clusters correspond to causal paths of length two that connect nodes within each of the three clusters. The edges in the fourth cluster (in the center of the visualization) represent causal paths that connect nodes in different clusters.</p> In\u00a0[9]: Copied! <pre>t_shuffled = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False).to(device)\nt_shuffled.shuffle_time()\n</pre> t_shuffled = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False).to(device) t_shuffled.shuffle_time() In\u00a0[10]: Copied! <pre>g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2]\nprint(g2_shuffled)\n</pre> g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2] print(g2_shuffled) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [00:53&lt;00:00, 1123.30it/s]\n</pre> <pre>Directed graph with 557 nodes and 1965 edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1965])\"},\n    'Graph Attributes': {'inverse_idx': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([60000])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {}}\n</pre> In\u00a0[11]: Copied! <pre>layout = pp.layout(g2_shuffled,**layout_style)\npp.plot(g2_shuffled, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib', layout=layout);\n</pre> layout = pp.layout(g2_shuffled,**layout_style) pp.plot(g2_shuffled, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib', layout=layout); <p>We now find that the cluster pattern in the second-order graph has vanished. In fact, there is no pattern whatsoever since the underlying (static) graph topology is random and the random shuffling of time stamps leads to random causal paths.</p> In\u00a0[12]: Copied! <pre>L = g2.laplacian(normalization='rw', edge_attr='edge_weight')\nL_shuffled= g2_shuffled.laplacian(normalization='rw',edge_attr='edge_weight')\n</pre> L = g2.laplacian(normalization='rw', edge_attr='edge_weight') L_shuffled= g2_shuffled.laplacian(normalization='rw',edge_attr='edge_weight') <p>We then calculate the eigenvalues and eigenvectors of the Laplacians, and compute the Fiedler vector, i.e. the eigenvector that corresponds to the second-smallest eigenvalue of the Laplacian.</p> In\u00a0[13]: Copied! <pre>w,v = sp.linalg.eig(L.todense(),left= False, right = True)\nw_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense())\n</pre> w,v = sp.linalg.eig(L.todense(),left= False, right = True) w_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense()) In\u00a0[14]: Copied! <pre>fiedler = v[:,np.argsort(w)[1]]\nfiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]]\n</pre> fiedler = v[:,np.argsort(w)[1]] fiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]] <p>Below, we show that the clusters in the causal topology of the temporal graph correspond to clusters in the distribution of entries in the Fiedler vector, while there is no such pattern for the Fiedler vector of the second-order graph constructed from the shuffled temporal graph:</p> In\u00a0[15]: Copied! <pre>c = []\na = []\nfor v in g2.nodes:\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c.append('green')\n        a.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c.append('red')\n        a.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c.append('blue')\n        a.append(1)\n    else:\n        c.append('black')\n        a.append(0.1)\n</pre> c = [] a = [] for v in g2.nodes:     if int(v[0])&lt;10 and int(v[1])&lt;10:         c.append('green')         a.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c.append('red')         a.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c.append('blue')         a.append(1)     else:         c.append('black')         a.append(0.1) In\u00a0[16]: Copied! <pre>c_shuffled = []\na_shuffled = []\nfor v in g2_shuffled.nodes: \n\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c_shuffled.append('green')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c_shuffled.append('red')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c_shuffled.append('blue')\n        a_shuffled.append(1)\n    else:\n        c_shuffled.append('black')\n        a_shuffled.append(0.1)\n</pre> c_shuffled = [] a_shuffled = [] for v in g2_shuffled.nodes:       if int(v[0])&lt;10 and int(v[1])&lt;10:         c_shuffled.append('green')         a_shuffled.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c_shuffled.append('red')         a_shuffled.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c_shuffled.append('blue')         a_shuffled.append(1)     else:         c_shuffled.append('black')         a_shuffled.append(0.1) <p>In the plots below, we have colored those entries of the Fiedler vectors that correspond to edges connecting nodes within one of the three clusters shown above. The Fiedler vector shows a clear pattern, which translates to the cluster pattern in the causal topology that we have planted into our synthetic temporal graph.</p> In\u00a0[17]: Copied! <pre>plt.ylim(-.2, .25)\nplt.scatter(range(g2.n), np.real(fiedler),c=c, alpha=a);\n</pre> plt.ylim(-.2, .25) plt.scatter(range(g2.n), np.real(fiedler),c=c, alpha=a); <p>No such pattern exists in the Fiedler vector of the second-order graph corresponding to the shuffled <code>TemporalGraph</code>.</p> In\u00a0[18]: Copied! <pre>plt.ylim(-.1, .1)\nplt.scatter(range(g2_shuffled.n), np.real(fiedler_shuffled), c=c_shuffled, alpha=a_shuffled);\n</pre> plt.ylim(-.1, .1) plt.scatter(range(g2_shuffled.n), np.real(fiedler_shuffled), c=c_shuffled, alpha=a_shuffled); <p>We now set up a <code>pytorch_geometric.Data</code> object that contains all of the information needed to train the DBGNN model. For this, we can use a convenience function of the <code>MultiOrderModel</code> class in <code>pathpyG</code>. Combining a first- and a second-order model, this uses the edge indices and the weight tensors for a message passing scheme. it further constructs an <code>edge_index</code> of a bipartite graph that uses the last node in a second-order node to map messages back to first-order nodes.</p> In\u00a0[19]: Copied! <pre>data = m.to_dbgnn_data(max_order=2, mapping='last')\ndata.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids], device=device)\n</pre> data = m.to_dbgnn_data(max_order=2, mapping='last') data.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids], device=device) In\u00a0[20]: Copied! <pre>data = RandomNodeSplit(num_val=0, num_test=0.3)(data)\n\nmodel = DBGNN(num_features=[g.n, g2.n], num_classes=len(data.y.unique()), hidden_dims=[16, 32, 8], p_dropout=0.4).to(\n    device\n)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)\nloss_function = torch.nn.CrossEntropyLoss()\n</pre> data = RandomNodeSplit(num_val=0, num_test=0.3)(data)  model = DBGNN(num_features=[g.n, g2.n], num_classes=len(data.y.unique()), hidden_dims=[16, 32, 8], p_dropout=0.4).to(     device )  optimizer = torch.optim.Adam(model.parameters(), lr=0.005) loss_function = torch.nn.CrossEntropyLoss() <p>The following function evaluates the prediction of our model based on the balanced accuracy score for categorical predictions.</p> In\u00a0[21]: Copied! <pre>def test(model, data):\n    model.eval()\n\n    _, pred = model(data).max(dim=1)\n\n    metrics_train = balanced_accuracy_score(\n        data.y[data.train_mask].cpu(),\n        pred[data.train_mask].cpu().numpy()\n        )\n\n    metrics_test = balanced_accuracy_score(\n        data.y[data.test_mask].cpu(),\n        pred[data.test_mask].cpu().numpy()\n        )\n\n    return metrics_train, metrics_test\n</pre> def test(model, data):     model.eval()      _, pred = model(data).max(dim=1)      metrics_train = balanced_accuracy_score(         data.y[data.train_mask].cpu(),         pred[data.train_mask].cpu().numpy()         )      metrics_test = balanced_accuracy_score(         data.y[data.test_mask].cpu(),         pred[data.test_mask].cpu().numpy()         )      return metrics_train, metrics_test In\u00a0[22]: Copied! <pre>losses = []\nfor epoch in range(100):\n        output = model(data)\n        loss = loss_function(output[data.train_mask], data.y[data.train_mask])\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        losses.append(loss)\n\n        if epoch % 10 == 0:\n                train_ba, test_ba = test(model, data)\n                print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}')\n</pre> losses = [] for epoch in range(100):         output = model(data)         loss = loss_function(output[data.train_mask], data.y[data.train_mask])         loss.backward()         optimizer.step()         optimizer.zero_grad()         losses.append(loss)          if epoch % 10 == 0:                 train_ba, test_ba = test(model, data)                 print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}') <pre>Epoch: 0, Loss: 1.5443899631500244, Train balanced accuracy: 0.3333333333333333, Test balanced accuracy: 0.3333333333333333\nEpoch: 10, Loss: 0.7875016331672668, Train balanced accuracy: 0.6666666666666666, Test balanced accuracy: 0.6666666666666666\nEpoch: 20, Loss: 0.061541132628917694, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 30, Loss: 0.0012057410785928369, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 40, Loss: 0.00011560289567569271, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 50, Loss: 4.159091258770786e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 60, Loss: 2.7213001885684207e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 70, Loss: 2.2796812118031085e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 80, Loss: 2.102010512317065e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 90, Loss: 2.0162973669357598e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\n</pre> In\u00a0[23]: Copied! <pre>model.eval()\nlatent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach()\nlatent = model.higher_order_layers[1].forward(latent, data.edge_index_higher_order).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())\n\ncolors = []\nfor v, w in g2.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g2.edges:\n    src = g2.mapping.to_idx(e[0])\n    tgt = g2.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach() latent = model.higher_order_layers[1].forward(latent, data.edge_index_higher_order).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())  colors = [] for v, w in g2.nodes:     if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g2.edges:     src = g2.mapping.to_idx(e[0])     tgt = g2.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show() <p>We can further generate latent space representations of the nodes generated by the last bipartite layer of our architecture:</p> In\u00a0[24]: Copied! <pre>model.eval()\nlatent = model.forward(data).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())\n\ncolors = []\nfor v in g.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g.edges:\n    src = g.mapping.to_idx(e[0])\n    tgt = g.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.forward(data).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())  colors = [] for v in g.nodes:     if data.y[g.mapping.to_idx(v)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g.edges:     src = g.mapping.to_idx(e[0])     tgt = g.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show()"},{"location":"tutorial/dbgnn/#causality-aware-graph-neural-networks","title":"Causality-Aware Graph Neural Networks\u00b6","text":""},{"location":"tutorial/dbgnn/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/dbgnn/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In previous tutorials, we have introduced causal paths in temporal graphs, and how we can use them to generate higher-order De Bruijn graph models that capture temporal-topological patterns in time series data. In this tutorial, we will show how we can use De Bruijn Graph Neural Networks, a causality-aware deep learning architecture for temporal graph data. The details of this approach are introduced in this paper. The architecture is implemented in pathpyG and can be readily applied to temporal graph data.</p> <p>Below we illustrate this mthod in a supervised node classification task, i.e. given a temporal graph we will use the temporal-topological patterns in the graph to classify nodes.</p> <p>We start by importing a few modules:</p>"},{"location":"tutorial/dbgnn/#temporal-topological-clusters-in-temporal-graphs","title":"Temporal-Topological Clusters in Temporal Graphs\u00b6","text":"<p>Let us load a small synthetic toy example for a temporal graph with 60.000 time-stamped interactions between 30 nodes. We use the <code>TemporalGraph</code> class to load this example from a file containing edges with discrete time-stamps.</p>"},{"location":"tutorial/dbgnn/#modelling-causal-structures-with-higher-order-de-bruijn-graphs","title":"Modelling Causal Structures with Higher-Order De Bruijn Graphs\u00b6","text":"<p>But what is the origin for the cluster pattern? In the visualization above, you will notice that the time-stamped edges randomly interconnect nodes within and across clusters, actually there is no correlation whatsoever between the topology of links and the cluster membership of the nodes. Hence, the notion of clusters does not correspond to the common idea of cluster patterns in static graphs, which we can highlight further by plotting the static time-aggregated network:</p>"},{"location":"tutorial/dbgnn/#comparison-to-temporal-graph-with-shuffled-time-stamps","title":"Comparison to Temporal Graph with Shuffled Time Stamps\u00b6","text":"<p>You may wonder whether this pattern is really due to the temporal ordering of time-stamped edges. It is easy to check this. We can simply randomly shuffle the time stamps of all edges, which will break any correlations in the temporal ordering that lead to patterns in the causal topology.</p> <p>We repeat the path calculation for this shuffled temporal graph and construct the second-order De Bruijn Graph model again:</p>"},{"location":"tutorial/dbgnn/#spectral-clustering-with-second-order-graph-laplacian","title":"Spectral clustering with second-order graph Laplacian\u00b6","text":"<p>To take a different perspective on cluster patterns, we can actually use <code>pathpyG</code> to apply a spectral analysis to the higher-order graph. We can simply calculate a generalization of the Laplacian matrix to the second-order graph both for the actual temporal graph and its shuffled counterpart:</p>"},{"location":"tutorial/dbgnn/#node-classification-with-causality-aware-graph-neural-networks","title":"Node Classification with Causality-Aware Graph Neural Networks\u00b6","text":"<p>Let us now explore how we can develop a causality-aware deep graph learning architecture that utilizes this pattern in the causal topology. We will follow the architecture introduced in this work. The architecture actually performs message passing in higher-order models with multiple orders at once. In a final message passing step, a bipartite graph is used to obtain vector-space representations of actual nodes in the temporal graph.</p>"},{"location":"tutorial/dbgnn/#training-the-model","title":"Training the model\u00b6","text":"<p>We are now ready to train and evaluate our causality-aware graph neural network. We will frist create a random split of the nodes, set the optimizer and the hyperparameters of our model.</p>"},{"location":"tutorial/dbgnn/#causality-aware-latent-space-representation-of-nodes","title":"Causality-aware latent space representation of nodes\u00b6","text":"<p>We can inspect the model by plotting a latent space representation of the edges generated by the second-order layer of our architecture.</p>"},{"location":"tutorial/generative_models/","title":"Generative Models for Random Graphs","text":"In\u00a0[53]: Copied! <pre>import pathpyG as pp\nimport string \nimport numpy as np\n</pre> import pathpyG as pp import string  import numpy as np <p><code>pathpyG</code> provides implementations for several basic generative models for random graphs, such as different variants of the Erd\u00f6s-Renyi model for random graphs, the Molloy-Reed configuration model for random graphs with given degree sequence or distribution, or the Watts-Strogatz models for small-world graphs.</p> <p>These models are implemented in the module <code>pathpyG.algorithms.generative_models</code>.</p> <p>To generate a random Erd\u00f6s-Renyi graph using the so-called $G(n,p)$ model where $n$ is the number of nodes and $p$ is the probability for each node pair to be connected, we can call:</p> In\u00a0[7]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, p=0.2)\npp.plot(g);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, p=0.2) pp.plot(g); <pre>{'edges': [{'uid': '0-12', 'source': '0', 'target': '12', 'weight': 1}, {'uid': '1-14', 'source': '1', 'target': '14', 'weight': 1}, {'uid': '1-17', 'source': '1', 'target': '17', 'weight': 1}, {'uid': '1-12', 'source': '1', 'target': '12', 'weight': 1}, {'uid': '1-5', 'source': '1', 'target': '5', 'weight': 1}, {'uid': '1-11', 'source': '1', 'target': '11', 'weight': 1}, {'uid': '1-7', 'source': '1', 'target': '7', 'weight': 1}, {'uid': '2-6', 'source': '2', 'target': '6', 'weight': 1}, {'uid': '2-12', 'source': '2', 'target': '12', 'weight': 1}, {'uid': '2-10', 'source': '2', 'target': '10', 'weight': 1}, {'uid': '2-13', 'source': '2', 'target': '13', 'weight': 1}, {'uid': '3-8', 'source': '3', 'target': '8', 'weight': 1}, {'uid': '3-14', 'source': '3', 'target': '14', 'weight': 1}, {'uid': '4-17', 'source': '4', 'target': '17', 'weight': 1}, {'uid': '4-19', 'source': '4', 'target': '19', 'weight': 1}, {'uid': '4-11', 'source': '4', 'target': '11', 'weight': 1}, {'uid': '5-8', 'source': '5', 'target': '8', 'weight': 1}, {'uid': '5-19', 'source': '5', 'target': '19', 'weight': 1}, {'uid': '5-1', 'source': '5', 'target': '1', 'weight': 1}, {'uid': '5-14', 'source': '5', 'target': '14', 'weight': 1}, {'uid': '5-18', 'source': '5', 'target': '18', 'weight': 1}, {'uid': '5-17', 'source': '5', 'target': '17', 'weight': 1}, {'uid': '5-15', 'source': '5', 'target': '15', 'weight': 1}, {'uid': '6-11', 'source': '6', 'target': '11', 'weight': 1}, {'uid': '6-15', 'source': '6', 'target': '15', 'weight': 1}, {'uid': '6-13', 'source': '6', 'target': '13', 'weight': 1}, {'uid': '6-2', 'source': '6', 'target': '2', 'weight': 1}, {'uid': '6-12', 'source': '6', 'target': '12', 'weight': 1}, {'uid': '6-14', 'source': '6', 'target': '14', 'weight': 1}, {'uid': '7-19', 'source': '7', 'target': '19', 'weight': 1}, {'uid': '7-8', 'source': '7', 'target': '8', 'weight': 1}, {'uid': '7-1', 'source': '7', 'target': '1', 'weight': 1}, {'uid': '7-17', 'source': '7', 'target': '17', 'weight': 1}, {'uid': '7-12', 'source': '7', 'target': '12', 'weight': 1}, {'uid': '7-15', 'source': '7', 'target': '15', 'weight': 1}, {'uid': '8-5', 'source': '8', 'target': '5', 'weight': 1}, {'uid': '8-7', 'source': '8', 'target': '7', 'weight': 1}, {'uid': '8-9', 'source': '8', 'target': '9', 'weight': 1}, {'uid': '8-3', 'source': '8', 'target': '3', 'weight': 1}, {'uid': '9-8', 'source': '9', 'target': '8', 'weight': 1}, {'uid': '10-17', 'source': '10', 'target': '17', 'weight': 1}, {'uid': '10-18', 'source': '10', 'target': '18', 'weight': 1}, {'uid': '10-2', 'source': '10', 'target': '2', 'weight': 1}, {'uid': '10-11', 'source': '10', 'target': '11', 'weight': 1}, {'uid': '11-1', 'source': '11', 'target': '1', 'weight': 1}, {'uid': '11-13', 'source': '11', 'target': '13', 'weight': 1}, {'uid': '11-4', 'source': '11', 'target': '4', 'weight': 1}, {'uid': '11-10', 'source': '11', 'target': '10', 'weight': 1}, {'uid': '11-6', 'source': '11', 'target': '6', 'weight': 1}, {'uid': '12-16', 'source': '12', 'target': '16', 'weight': 1}, {'uid': '12-2', 'source': '12', 'target': '2', 'weight': 1}, {'uid': '12-1', 'source': '12', 'target': '1', 'weight': 1}, {'uid': '12-7', 'source': '12', 'target': '7', 'weight': 1}, {'uid': '12-6', 'source': '12', 'target': '6', 'weight': 1}, {'uid': '12-0', 'source': '12', 'target': '0', 'weight': 1}, {'uid': '12-13', 'source': '12', 'target': '13', 'weight': 1}, {'uid': '13-16', 'source': '13', 'target': '16', 'weight': 1}, {'uid': '13-6', 'source': '13', 'target': '6', 'weight': 1}, {'uid': '13-11', 'source': '13', 'target': '11', 'weight': 1}, {'uid': '13-12', 'source': '13', 'target': '12', 'weight': 1}, {'uid': '13-2', 'source': '13', 'target': '2', 'weight': 1}, {'uid': '14-3', 'source': '14', 'target': '3', 'weight': 1}, {'uid': '14-1', 'source': '14', 'target': '1', 'weight': 1}, {'uid': '14-6', 'source': '14', 'target': '6', 'weight': 1}, {'uid': '14-5', 'source': '14', 'target': '5', 'weight': 1}, {'uid': '15-6', 'source': '15', 'target': '6', 'weight': 1}, {'uid': '15-5', 'source': '15', 'target': '5', 'weight': 1}, {'uid': '15-16', 'source': '15', 'target': '16', 'weight': 1}, {'uid': '15-7', 'source': '15', 'target': '7', 'weight': 1}, {'uid': '16-12', 'source': '16', 'target': '12', 'weight': 1}, {'uid': '16-15', 'source': '16', 'target': '15', 'weight': 1}, {'uid': '16-13', 'source': '16', 'target': '13', 'weight': 1}, {'uid': '17-1', 'source': '17', 'target': '1', 'weight': 1}, {'uid': '17-7', 'source': '17', 'target': '7', 'weight': 1}, {'uid': '17-5', 'source': '17', 'target': '5', 'weight': 1}, {'uid': '17-10', 'source': '17', 'target': '10', 'weight': 1}, {'uid': '17-4', 'source': '17', 'target': '4', 'weight': 1}, {'uid': '18-10', 'source': '18', 'target': '10', 'weight': 1}, {'uid': '18-5', 'source': '18', 'target': '5', 'weight': 1}, {'uid': '19-5', 'source': '19', 'target': '5', 'weight': 1}, {'uid': '19-4', 'source': '19', 'target': '4', 'weight': 1}, {'uid': '19-7', 'source': '19', 'target': '7', 'weight': 1}], 'nodes': [{'uid': '0'}, {'uid': '1'}, {'uid': '2'}, {'uid': '3'}, {'uid': '4'}, {'uid': '5'}, {'uid': '6'}, {'uid': '7'}, {'uid': '8'}, {'uid': '9'}, {'uid': '10'}, {'uid': '11'}, {'uid': '12'}, {'uid': '13'}, {'uid': '14'}, {'uid': '15'}, {'uid': '16'}, {'uid': '17'}, {'uid': '18'}, {'uid': '19'}]}\n</pre> <p>By default, no self-loops are added. If we want self-loops to be generated with probability $p$ we can do this as follows (note that self-loops are currently not plotted):</p> In\u00a0[10]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, p=0.2, self_loops=True)\npp.plot(g);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, p=0.2, self_loops=True) pp.plot(g); <pre>{'edges': [{'uid': '0-8', 'source': '0', 'target': '8', 'weight': 1}, {'uid': '0-17', 'source': '0', 'target': '17', 'weight': 1}, {'uid': '0-4', 'source': '0', 'target': '4', 'weight': 1}, {'uid': '1-1', 'source': '1', 'target': '1', 'weight': 1}, {'uid': '1-17', 'source': '1', 'target': '17', 'weight': 1}, {'uid': '1-9', 'source': '1', 'target': '9', 'weight': 1}, {'uid': '1-14', 'source': '1', 'target': '14', 'weight': 1}, {'uid': '2-14', 'source': '2', 'target': '14', 'weight': 1}, {'uid': '2-3', 'source': '2', 'target': '3', 'weight': 1}, {'uid': '2-8', 'source': '2', 'target': '8', 'weight': 1}, {'uid': '2-7', 'source': '2', 'target': '7', 'weight': 1}, {'uid': '3-9', 'source': '3', 'target': '9', 'weight': 1}, {'uid': '3-18', 'source': '3', 'target': '18', 'weight': 1}, {'uid': '3-8', 'source': '3', 'target': '8', 'weight': 1}, {'uid': '3-11', 'source': '3', 'target': '11', 'weight': 1}, {'uid': '3-2', 'source': '3', 'target': '2', 'weight': 1}, {'uid': '3-19', 'source': '3', 'target': '19', 'weight': 1}, {'uid': '3-16', 'source': '3', 'target': '16', 'weight': 1}, {'uid': '4-0', 'source': '4', 'target': '0', 'weight': 1}, {'uid': '4-7', 'source': '4', 'target': '7', 'weight': 1}, {'uid': '5-17', 'source': '5', 'target': '17', 'weight': 1}, {'uid': '5-7', 'source': '5', 'target': '7', 'weight': 1}, {'uid': '5-18', 'source': '5', 'target': '18', 'weight': 1}, {'uid': '6-16', 'source': '6', 'target': '16', 'weight': 1}, {'uid': '7-5', 'source': '7', 'target': '5', 'weight': 1}, {'uid': '7-16', 'source': '7', 'target': '16', 'weight': 1}, {'uid': '7-4', 'source': '7', 'target': '4', 'weight': 1}, {'uid': '7-2', 'source': '7', 'target': '2', 'weight': 1}, {'uid': '8-2', 'source': '8', 'target': '2', 'weight': 1}, {'uid': '8-14', 'source': '8', 'target': '14', 'weight': 1}, {'uid': '8-19', 'source': '8', 'target': '19', 'weight': 1}, {'uid': '8-0', 'source': '8', 'target': '0', 'weight': 1}, {'uid': '8-3', 'source': '8', 'target': '3', 'weight': 1}, {'uid': '9-17', 'source': '9', 'target': '17', 'weight': 1}, {'uid': '9-3', 'source': '9', 'target': '3', 'weight': 1}, {'uid': '9-19', 'source': '9', 'target': '19', 'weight': 1}, {'uid': '9-1', 'source': '9', 'target': '1', 'weight': 1}, {'uid': '9-15', 'source': '9', 'target': '15', 'weight': 1}, {'uid': '10-13', 'source': '10', 'target': '13', 'weight': 1}, {'uid': '10-10', 'source': '10', 'target': '10', 'weight': 1}, {'uid': '11-13', 'source': '11', 'target': '13', 'weight': 1}, {'uid': '11-12', 'source': '11', 'target': '12', 'weight': 1}, {'uid': '11-3', 'source': '11', 'target': '3', 'weight': 1}, {'uid': '12-11', 'source': '12', 'target': '11', 'weight': 1}, {'uid': '12-15', 'source': '12', 'target': '15', 'weight': 1}, {'uid': '12-17', 'source': '12', 'target': '17', 'weight': 1}, {'uid': '13-11', 'source': '13', 'target': '11', 'weight': 1}, {'uid': '13-18', 'source': '13', 'target': '18', 'weight': 1}, {'uid': '13-16', 'source': '13', 'target': '16', 'weight': 1}, {'uid': '13-15', 'source': '13', 'target': '15', 'weight': 1}, {'uid': '13-19', 'source': '13', 'target': '19', 'weight': 1}, {'uid': '13-10', 'source': '13', 'target': '10', 'weight': 1}, {'uid': '14-1', 'source': '14', 'target': '1', 'weight': 1}, {'uid': '14-2', 'source': '14', 'target': '2', 'weight': 1}, {'uid': '14-8', 'source': '14', 'target': '8', 'weight': 1}, {'uid': '15-13', 'source': '15', 'target': '13', 'weight': 1}, {'uid': '15-9', 'source': '15', 'target': '9', 'weight': 1}, {'uid': '15-19', 'source': '15', 'target': '19', 'weight': 1}, {'uid': '15-12', 'source': '15', 'target': '12', 'weight': 1}, {'uid': '16-7', 'source': '16', 'target': '7', 'weight': 1}, {'uid': '16-6', 'source': '16', 'target': '6', 'weight': 1}, {'uid': '16-3', 'source': '16', 'target': '3', 'weight': 1}, {'uid': '16-16', 'source': '16', 'target': '16', 'weight': 1}, {'uid': '16-13', 'source': '16', 'target': '13', 'weight': 1}, {'uid': '17-12', 'source': '17', 'target': '12', 'weight': 1}, {'uid': '17-5', 'source': '17', 'target': '5', 'weight': 1}, {'uid': '17-9', 'source': '17', 'target': '9', 'weight': 1}, {'uid': '17-1', 'source': '17', 'target': '1', 'weight': 1}, {'uid': '17-0', 'source': '17', 'target': '0', 'weight': 1}, {'uid': '18-5', 'source': '18', 'target': '5', 'weight': 1}, {'uid': '18-13', 'source': '18', 'target': '13', 'weight': 1}, {'uid': '18-3', 'source': '18', 'target': '3', 'weight': 1}, {'uid': '19-13', 'source': '19', 'target': '13', 'weight': 1}, {'uid': '19-3', 'source': '19', 'target': '3', 'weight': 1}, {'uid': '19-15', 'source': '19', 'target': '15', 'weight': 1}, {'uid': '19-9', 'source': '19', 'target': '9', 'weight': 1}, {'uid': '19-8', 'source': '19', 'target': '8', 'weight': 1}], 'nodes': [{'uid': '0'}, {'uid': '1'}, {'uid': '2'}, {'uid': '3'}, {'uid': '4'}, {'uid': '5'}, {'uid': '6'}, {'uid': '7'}, {'uid': '8'}, {'uid': '9'}, {'uid': '10'}, {'uid': '11'}, {'uid': '12'}, {'uid': '13'}, {'uid': '14'}, {'uid': '15'}, {'uid': '16'}, {'uid': '17'}, {'uid': '18'}, {'uid': '19'}]}\n</pre> <p>This also works for directed networks and we can specify a given node ID mapping:</p> In\u00a0[18]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, \n                                                    p=0.2, directed=True, mapping=pp.IndexMap([x for x in string.ascii_lowercase]))\npp.plot(g, node_label = g.nodes);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20,                                                      p=0.2, directed=True, mapping=pp.IndexMap([x for x in string.ascii_lowercase])) pp.plot(g, node_label = g.nodes); <pre>{'edges': [{'uid': 'a-d', 'source': 'a', 'target': 'd', 'weight': 1}, {'uid': 'a-n', 'source': 'a', 'target': 'n', 'weight': 1}, {'uid': 'a-e', 'source': 'a', 'target': 'e', 'weight': 1}, {'uid': 'b-g', 'source': 'b', 'target': 'g', 'weight': 1}, {'uid': 'b-n', 'source': 'b', 'target': 'n', 'weight': 1}, {'uid': 'c-n', 'source': 'c', 'target': 'n', 'weight': 1}, {'uid': 'c-o', 'source': 'c', 'target': 'o', 'weight': 1}, {'uid': 'c-t', 'source': 'c', 'target': 't', 'weight': 1}, {'uid': 'c-j', 'source': 'c', 'target': 'j', 'weight': 1}, {'uid': 'c-l', 'source': 'c', 'target': 'l', 'weight': 1}, {'uid': 'c-q', 'source': 'c', 'target': 'q', 'weight': 1}, {'uid': 'c-s', 'source': 'c', 'target': 's', 'weight': 1}, {'uid': 'c-m', 'source': 'c', 'target': 'm', 'weight': 1}, {'uid': 'd-b', 'source': 'd', 'target': 'b', 'weight': 1}, {'uid': 'd-j', 'source': 'd', 'target': 'j', 'weight': 1}, {'uid': 'd-l', 'source': 'd', 'target': 'l', 'weight': 1}, {'uid': 'd-t', 'source': 'd', 'target': 't', 'weight': 1}, {'uid': 'e-h', 'source': 'e', 'target': 'h', 'weight': 1}, {'uid': 'e-s', 'source': 'e', 'target': 's', 'weight': 1}, {'uid': 'e-l', 'source': 'e', 'target': 'l', 'weight': 1}, {'uid': 'e-i', 'source': 'e', 'target': 'i', 'weight': 1}, {'uid': 'e-m', 'source': 'e', 'target': 'm', 'weight': 1}, {'uid': 'e-q', 'source': 'e', 'target': 'q', 'weight': 1}, {'uid': 'f-t', 'source': 'f', 'target': 't', 'weight': 1}, {'uid': 'f-o', 'source': 'f', 'target': 'o', 'weight': 1}, {'uid': 'g-l', 'source': 'g', 'target': 'l', 'weight': 1}, {'uid': 'g-m', 'source': 'g', 'target': 'm', 'weight': 1}, {'uid': 'g-c', 'source': 'g', 'target': 'c', 'weight': 1}, {'uid': 'g-a', 'source': 'g', 'target': 'a', 'weight': 1}, {'uid': 'h-e', 'source': 'h', 'target': 'e', 'weight': 1}, {'uid': 'h-n', 'source': 'h', 'target': 'n', 'weight': 1}, {'uid': 'h-m', 'source': 'h', 'target': 'm', 'weight': 1}, {'uid': 'i-f', 'source': 'i', 'target': 'f', 'weight': 1}, {'uid': 'i-k', 'source': 'i', 'target': 'k', 'weight': 1}, {'uid': 'i-j', 'source': 'i', 'target': 'j', 'weight': 1}, {'uid': 'j-s', 'source': 'j', 'target': 's', 'weight': 1}, {'uid': 'j-r', 'source': 'j', 'target': 'r', 'weight': 1}, {'uid': 'j-l', 'source': 'j', 'target': 'l', 'weight': 1}, {'uid': 'k-r', 'source': 'k', 'target': 'r', 'weight': 1}, {'uid': 'k-l', 'source': 'k', 'target': 'l', 'weight': 1}, {'uid': 'k-h', 'source': 'k', 'target': 'h', 'weight': 1}, {'uid': 'k-c', 'source': 'k', 'target': 'c', 'weight': 1}, {'uid': 'k-n', 'source': 'k', 'target': 'n', 'weight': 1}, {'uid': 'k-t', 'source': 'k', 'target': 't', 'weight': 1}, {'uid': 'k-e', 'source': 'k', 'target': 'e', 'weight': 1}, {'uid': 'l-d', 'source': 'l', 'target': 'd', 'weight': 1}, {'uid': 'l-b', 'source': 'l', 'target': 'b', 'weight': 1}, {'uid': 'l-o', 'source': 'l', 'target': 'o', 'weight': 1}, {'uid': 'l-c', 'source': 'l', 'target': 'c', 'weight': 1}, {'uid': 'm-e', 'source': 'm', 'target': 'e', 'weight': 1}, {'uid': 'm-s', 'source': 'm', 'target': 's', 'weight': 1}, {'uid': 'm-a', 'source': 'm', 'target': 'a', 'weight': 1}, {'uid': 'm-i', 'source': 'm', 'target': 'i', 'weight': 1}, {'uid': 'n-e', 'source': 'n', 'target': 'e', 'weight': 1}, {'uid': 'n-i', 'source': 'n', 'target': 'i', 'weight': 1}, {'uid': 'o-a', 'source': 'o', 'target': 'a', 'weight': 1}, {'uid': 'o-p', 'source': 'o', 'target': 'p', 'weight': 1}, {'uid': 'p-r', 'source': 'p', 'target': 'r', 'weight': 1}, {'uid': 'p-q', 'source': 'p', 'target': 'q', 'weight': 1}, {'uid': 'p-h', 'source': 'p', 'target': 'h', 'weight': 1}, {'uid': 'p-d', 'source': 'p', 'target': 'd', 'weight': 1}, {'uid': 'p-s', 'source': 'p', 'target': 's', 'weight': 1}, {'uid': 'p-a', 'source': 'p', 'target': 'a', 'weight': 1}, {'uid': 'q-b', 'source': 'q', 'target': 'b', 'weight': 1}, {'uid': 'q-m', 'source': 'q', 'target': 'm', 'weight': 1}, {'uid': 'q-j', 'source': 'q', 'target': 'j', 'weight': 1}, {'uid': 'q-h', 'source': 'q', 'target': 'h', 'weight': 1}, {'uid': 'q-e', 'source': 'q', 'target': 'e', 'weight': 1}, {'uid': 'q-l', 'source': 'q', 'target': 'l', 'weight': 1}, {'uid': 'r-e', 'source': 'r', 'target': 'e', 'weight': 1}, {'uid': 'r-l', 'source': 'r', 'target': 'l', 'weight': 1}, {'uid': 's-m', 'source': 's', 'target': 'm', 'weight': 1}, {'uid': 's-o', 'source': 's', 'target': 'o', 'weight': 1}, {'uid': 's-f', 'source': 's', 'target': 'f', 'weight': 1}, {'uid': 's-h', 'source': 's', 'target': 'h', 'weight': 1}, {'uid': 't-l', 'source': 't', 'target': 'l', 'weight': 1}, {'uid': 't-b', 'source': 't', 'target': 'b', 'weight': 1}, {'uid': 't-i', 'source': 't', 'target': 'i', 'weight': 1}, {'uid': 't-g', 'source': 't', 'target': 'g', 'weight': 1}], 'nodes': [{'uid': 'a', 'label': 'a'}, {'uid': 'b', 'label': 'b'}, {'uid': 'c', 'label': 'c'}, {'uid': 'd', 'label': 'd'}, {'uid': 'e', 'label': 'e'}, {'uid': 'f', 'label': 'f'}, {'uid': 'g', 'label': 'g'}, {'uid': 'h', 'label': 'h'}, {'uid': 'i', 'label': 'i'}, {'uid': 'j', 'label': 'j'}, {'uid': 'k', 'label': 'k'}, {'uid': 'l', 'label': 'l'}, {'uid': 'm', 'label': 'm'}, {'uid': 'n', 'label': 'n'}, {'uid': 'o', 'label': 'o'}, {'uid': 'p', 'label': 'p'}, {'uid': 'q', 'label': 'q'}, {'uid': 'r', 'label': 'r'}, {'uid': 's', 'label': 's'}, {'uid': 't', 'label': 't'}]}\n</pre> <p>For the random realizations generated by the $G(n,p)$ model with connection probability $p$, we have an expected number of $p \\cdot \\binom{n}{2}$ edges, i.e. the number of edges in each realization varies.</p> <p>We can use the alternative $G(n,m)$ formulation of the Erd\u00f6s-Renyi model, which generates a fixed number of $m$ edges chosen uniformly at random:</p> In\u00a0[20]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20, \n                                                    m=40, mapping=pp.IndexMap([x for x in string.ascii_lowercase]))\nprint(g)\npp.plot(g, node_label = g.nodes);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20,                                                      m=40, mapping=pp.IndexMap([x for x in string.ascii_lowercase])) print(g) pp.plot(g, node_label = g.nodes); <pre>Undirected graph with 20 nodes and 80 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n{'edges': [{'uid': 'a-f', 'source': 'a', 'target': 'f', 'weight': 1}, {'uid': 'a-h', 'source': 'a', 'target': 'h', 'weight': 1}, {'uid': 'a-k', 'source': 'a', 'target': 'k', 'weight': 1}, {'uid': 'b-q', 'source': 'b', 'target': 'q', 'weight': 1}, {'uid': 'b-j', 'source': 'b', 'target': 'j', 'weight': 1}, {'uid': 'b-r', 'source': 'b', 'target': 'r', 'weight': 1}, {'uid': 'c-q', 'source': 'c', 'target': 'q', 'weight': 1}, {'uid': 'd-s', 'source': 'd', 'target': 's', 'weight': 1}, {'uid': 'd-j', 'source': 'd', 'target': 'j', 'weight': 1}, {'uid': 'd-k', 'source': 'd', 'target': 'k', 'weight': 1}, {'uid': 'd-q', 'source': 'd', 'target': 'q', 'weight': 1}, {'uid': 'd-n', 'source': 'd', 'target': 'n', 'weight': 1}, {'uid': 'd-i', 'source': 'd', 'target': 'i', 'weight': 1}, {'uid': 'd-e', 'source': 'd', 'target': 'e', 'weight': 1}, {'uid': 'e-m', 'source': 'e', 'target': 'm', 'weight': 1}, {'uid': 'e-t', 'source': 'e', 'target': 't', 'weight': 1}, {'uid': 'e-d', 'source': 'e', 'target': 'd', 'weight': 1}, {'uid': 'e-l', 'source': 'e', 'target': 'l', 'weight': 1}, {'uid': 'f-s', 'source': 'f', 'target': 's', 'weight': 1}, {'uid': 'f-g', 'source': 'f', 'target': 'g', 'weight': 1}, {'uid': 'f-r', 'source': 'f', 'target': 'r', 'weight': 1}, {'uid': 'f-a', 'source': 'f', 'target': 'a', 'weight': 1}, {'uid': 'g-s', 'source': 'g', 'target': 's', 'weight': 1}, {'uid': 'g-j', 'source': 'g', 'target': 'j', 'weight': 1}, {'uid': 'g-r', 'source': 'g', 'target': 'r', 'weight': 1}, {'uid': 'g-n', 'source': 'g', 'target': 'n', 'weight': 1}, {'uid': 'g-f', 'source': 'g', 'target': 'f', 'weight': 1}, {'uid': 'h-n', 'source': 'h', 'target': 'n', 'weight': 1}, {'uid': 'h-a', 'source': 'h', 'target': 'a', 'weight': 1}, {'uid': 'h-r', 'source': 'h', 'target': 'r', 'weight': 1}, {'uid': 'i-p', 'source': 'i', 'target': 'p', 'weight': 1}, {'uid': 'i-k', 'source': 'i', 'target': 'k', 'weight': 1}, {'uid': 'i-n', 'source': 'i', 'target': 'n', 'weight': 1}, {'uid': 'i-d', 'source': 'i', 'target': 'd', 'weight': 1}, {'uid': 'i-l', 'source': 'i', 'target': 'l', 'weight': 1}, {'uid': 'j-g', 'source': 'j', 'target': 'g', 'weight': 1}, {'uid': 'j-d', 'source': 'j', 'target': 'd', 'weight': 1}, {'uid': 'j-b', 'source': 'j', 'target': 'b', 'weight': 1}, {'uid': 'j-o', 'source': 'j', 'target': 'o', 'weight': 1}, {'uid': 'k-t', 'source': 'k', 'target': 't', 'weight': 1}, {'uid': 'k-r', 'source': 'k', 'target': 'r', 'weight': 1}, {'uid': 'k-a', 'source': 'k', 'target': 'a', 'weight': 1}, {'uid': 'k-i', 'source': 'k', 'target': 'i', 'weight': 1}, {'uid': 'k-d', 'source': 'k', 'target': 'd', 'weight': 1}, {'uid': 'l-e', 'source': 'l', 'target': 'e', 'weight': 1}, {'uid': 'l-o', 'source': 'l', 'target': 'o', 'weight': 1}, {'uid': 'l-n', 'source': 'l', 'target': 'n', 'weight': 1}, {'uid': 'l-i', 'source': 'l', 'target': 'i', 'weight': 1}, {'uid': 'l-p', 'source': 'l', 'target': 'p', 'weight': 1}, {'uid': 'm-o', 'source': 'm', 'target': 'o', 'weight': 1}, {'uid': 'm-e', 'source': 'm', 'target': 'e', 'weight': 1}, {'uid': 'm-p', 'source': 'm', 'target': 'p', 'weight': 1}, {'uid': 'n-r', 'source': 'n', 'target': 'r', 'weight': 1}, {'uid': 'n-i', 'source': 'n', 'target': 'i', 'weight': 1}, {'uid': 'n-d', 'source': 'n', 'target': 'd', 'weight': 1}, {'uid': 'n-g', 'source': 'n', 'target': 'g', 'weight': 1}, {'uid': 'n-l', 'source': 'n', 'target': 'l', 'weight': 1}, {'uid': 'n-h', 'source': 'n', 'target': 'h', 'weight': 1}, {'uid': 'o-j', 'source': 'o', 'target': 'j', 'weight': 1}, {'uid': 'o-m', 'source': 'o', 'target': 'm', 'weight': 1}, {'uid': 'o-l', 'source': 'o', 'target': 'l', 'weight': 1}, {'uid': 'p-l', 'source': 'p', 'target': 'l', 'weight': 1}, {'uid': 'p-i', 'source': 'p', 'target': 'i', 'weight': 1}, {'uid': 'p-m', 'source': 'p', 'target': 'm', 'weight': 1}, {'uid': 'q-r', 'source': 'q', 'target': 'r', 'weight': 1}, {'uid': 'q-c', 'source': 'q', 'target': 'c', 'weight': 1}, {'uid': 'q-d', 'source': 'q', 'target': 'd', 'weight': 1}, {'uid': 'q-b', 'source': 'q', 'target': 'b', 'weight': 1}, {'uid': 'r-f', 'source': 'r', 'target': 'f', 'weight': 1}, {'uid': 'r-h', 'source': 'r', 'target': 'h', 'weight': 1}, {'uid': 'r-g', 'source': 'r', 'target': 'g', 'weight': 1}, {'uid': 'r-q', 'source': 'r', 'target': 'q', 'weight': 1}, {'uid': 'r-n', 'source': 'r', 'target': 'n', 'weight': 1}, {'uid': 'r-k', 'source': 'r', 'target': 'k', 'weight': 1}, {'uid': 'r-b', 'source': 'r', 'target': 'b', 'weight': 1}, {'uid': 's-d', 'source': 's', 'target': 'd', 'weight': 1}, {'uid': 's-g', 'source': 's', 'target': 'g', 'weight': 1}, {'uid': 's-f', 'source': 's', 'target': 'f', 'weight': 1}, {'uid': 't-k', 'source': 't', 'target': 'k', 'weight': 1}, {'uid': 't-e', 'source': 't', 'target': 'e', 'weight': 1}], 'nodes': [{'uid': 'a', 'label': 'a'}, {'uid': 'b', 'label': 'b'}, {'uid': 'c', 'label': 'c'}, {'uid': 'd', 'label': 'd'}, {'uid': 'e', 'label': 'e'}, {'uid': 'f', 'label': 'f'}, {'uid': 'g', 'label': 'g'}, {'uid': 'h', 'label': 'h'}, {'uid': 'i', 'label': 'i'}, {'uid': 'j', 'label': 'j'}, {'uid': 'k', 'label': 'k'}, {'uid': 'l', 'label': 'l'}, {'uid': 'm', 'label': 'm'}, {'uid': 'n', 'label': 'n'}, {'uid': 'o', 'label': 'o'}, {'uid': 'p', 'label': 'p'}, {'uid': 'q', 'label': 'q'}, {'uid': 'r', 'label': 'r'}, {'uid': 's', 'label': 's'}, {'uid': 't', 'label': 't'}]}\n</pre> <p>Naturally, the maximum number of edges that we can create depends on the size of the graph (and whether edges are directed and whether we allow for self-loops). The following fails:</p> In\u00a0[24]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20, \n                                                    m=195, mapping=pp.IndexMap([x for x in string.ascii_lowercase]))\nprint(g)\npp.plot(g, node_label = g.nodes);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20,                                                      m=195, mapping=pp.IndexMap([x for x in string.ascii_lowercase])) print(g) pp.plot(g, node_label = g.nodes); <pre>\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\nCell In[24], line 1\n----&gt; 1 g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20, \n      2                                                     m=195, mapping=pp.IndexMap([x for x in string.ascii_lowercase]))\n      3 print(g)\n      4 pp.plot(g, node_label = g.nodes)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/generative_models.py:85, in erdos_renyi_gnm(n, m, mapping, self_loops, multi_edges, directed)\n     69 def erdos_renyi_gnm(n: int, m: int, mapping: IndexMap | None = None,\n     70                     self_loops: bool = False, multi_edges: bool = False,\n     71                     directed: bool = False) -&gt; Graph:\n     72     \"\"\"Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.\n     73 \n     74     Args:\n   (...)\n     83         Graph: graph object\n     84     \"\"\"\n---&gt; 85     assert m &lt;= max_edges(n, directed=directed, self_loops=self_loops, multi_edges=multi_edges)\n     87     edges = set()\n     88     edges_added: int = 0\n\nAssertionError: </pre> <p>To check how many edges a directed/undirected graph with/without self-loop can possibly have, you can use the <code>max_edges</code> function:</p> In\u00a0[25]: Copied! <pre>pp.algorithms.generative_models.max_edges(n=20, directed=False, self_loops=False)\n</pre> pp.algorithms.generative_models.max_edges(n=20, directed=False, self_loops=False) Out[25]: <pre>190</pre> <p>We often use random graph models to generate randomized versions of empirical networks. For this prupose, <code>pathpyG</code> provides <code>_randomize</code> variants for random graph models, which can be used to automatically fit the model parameters to an empirical graph, thus generating a randomized version that preserves the corresponding aggregate characteristics defined by the model.</p> <p>Let's try this for randomized versions of the Karate club network, which we can load from the netzschleuder database:</p> In\u00a0[11]: Copied! <pre>g_karate = pp.io.read_netzschleuder_graph('karate', '77')\nprint(g_karate)\n</pre> g_karate = pp.io.read_netzschleuder_graph('karate', '77') print(g_karate) <pre>Mapping node attributes based on node indices in column `index`\nUndirected graph with 34 nodes and 154 (directed) edges\n{   'Edge Attributes': {},\n    'Graph Attributes': {   'analyses_average_degree': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_assortativity': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_std_dev': \"&lt;class 'float'&gt;\",\n                            'analyses_diameter': \"&lt;class 'int'&gt;\",\n                            'analyses_edge_properties': \"&lt;class 'list'&gt;\",\n                            'analyses_edge_reciprocity': \"&lt;class 'float'&gt;\",\n                            'analyses_global_clustering': \"&lt;class 'float'&gt;\",\n                            'analyses_hashimoto_radius': \"&lt;class 'float'&gt;\",\n                            'analyses_is_bipartite': \"&lt;class 'bool'&gt;\",\n                            'analyses_is_directed': \"&lt;class 'bool'&gt;\",\n                            'analyses_knn_proj_1': \"&lt;class 'float'&gt;\",\n                            'analyses_knn_proj_2': \"&lt;class 'float'&gt;\",\n                            'analyses_largest_component_fraction': \"&lt;class 'float'&gt;\",\n                            'analyses_mixing_time': \"&lt;class 'float'&gt;\",\n                            'analyses_num_edges': \"&lt;class 'int'&gt;\",\n                            'analyses_num_vertices': \"&lt;class 'int'&gt;\",\n                            'analyses_transition_gap': \"&lt;class 'float'&gt;\",\n                            'analyses_vertex_properties': \"&lt;class 'list'&gt;\",\n                            'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {   'node__pos': \"&lt;class 'numpy.ndarray'&gt;\",\n                           'node_groups': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\",\n                           'node_name': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\"}}\n</pre> <p>Using <code>erdos_renyi_gnm_randomize</code>, we obtain a random graph with the same number of nodes and edges.</p> In\u00a0[29]: Copied! <pre>r_karate = pp.algorithms.generative_models.erdos_renyi_gnm_randomize(g_karate)\nprint(r_karate)\n</pre> r_karate = pp.algorithms.generative_models.erdos_renyi_gnm_randomize(g_karate) print(r_karate) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>Note that node, edge, and graph attributes are not preserved, but it is easy to add back those manually that you want to reassign.</p> In\u00a0[31]: Copied! <pre>r_karate.data.node_groups = g_karate.data.node_groups\nprint(r_karate)\n</pre> r_karate.data.node_groups = g_karate.data.node_groups print(r_karate) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {'node_groups': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\"}}\n</pre> <p>Using <code>erdos_renyi_gnp_randomize</code>, we obtain a random graph with the same number of nodes and where the expected number of edges matches the original graph, i.e. in each random realization the actual number of edges varies:</p> In\u00a0[33]: Copied! <pre>r_karate_1 = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate)\nr_karate_2 = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate)\nprint(r_karate_1)\nprint(r_karate_2)\n</pre> r_karate_1 = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate) r_karate_2 = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate) print(r_karate_1) print(r_karate_2) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nUndirected graph with 34 nodes and 196 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>Plotting the distribution of edges in the random realization confirms that we get a distribution that is centered around the edge count of our empirical graph.</p> In\u00a0[45]: Copied! <pre>from matplotlib import pyplot as plt\n\nedge_counts = []\nfor i in range(200):\n    r_karate = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate)\n    edge_counts.append(r_karate.m)\nax = plt.hist(edge_counts)\nplt.axvline(x=g_karate.m, color='red')\n</pre> from matplotlib import pyplot as plt  edge_counts = [] for i in range(200):     r_karate = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate)     edge_counts.append(r_karate.m) ax = plt.hist(edge_counts) plt.axvline(x=g_karate.m, color='red') Out[45]: <pre>&lt;matplotlib.lines.Line2D at 0x7f638bcf9ea0&gt;</pre> <p>We can finally use the Molloy-Reed configuration model to generate random graphs with a given degree sequence:</p> In\u00a0[\u00a0]: Copied! <pre>g = pp.algorithms.generative_models.molloy_reed([2,2,3,2,3])\nprint(pp.statistics.degree_sequence(g))\nprint(g)\npp.plot(g)\n</pre> g = pp.algorithms.generative_models.molloy_reed([2,2,3,2,3]) print(pp.statistics.degree_sequence(g)) print(g) pp.plot(g) <pre>[2. 2. 3. 2. 3.]\nUndirected graph with 5 nodes and 12 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n{'edges': [{'uid': '0-2', 'source': '0', 'target': '2', 'weight': 1}, {'uid': '0-3', 'source': '0', 'target': '3', 'weight': 1}, {'uid': '1-2', 'source': '1', 'target': '2', 'weight': 1}, {'uid': '1-4', 'source': '1', 'target': '4', 'weight': 1}, {'uid': '2-0', 'source': '2', 'target': '0', 'weight': 1}, {'uid': '2-1', 'source': '2', 'target': '1', 'weight': 1}, {'uid': '2-4', 'source': '2', 'target': '4', 'weight': 1}, {'uid': '3-0', 'source': '3', 'target': '0', 'weight': 1}, {'uid': '3-4', 'source': '3', 'target': '4', 'weight': 1}, {'uid': '4-1', 'source': '4', 'target': '1', 'weight': 1}, {'uid': '4-2', 'source': '4', 'target': '2', 'weight': 1}, {'uid': '4-3', 'source': '4', 'target': '3', 'weight': 1}], 'nodes': [{'uid': '0'}, {'uid': '1'}, {'uid': '2'}, {'uid': '3'}, {'uid': '4'}]}\n</pre> Out[\u00a0]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f0be060c460&gt;</pre> <p>Not every sequence of integers is the degree sequence of a corresponding graph, the following thus fails:</p> In\u00a0[8]: Copied! <pre>g = pp.algorithms.generative_models.molloy_reed([2,2,6,2,3])\n</pre> g = pp.algorithms.generative_models.molloy_reed([2,2,6,2,3]) <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 g = pp.algorithms.generative_models.molloy_reed([2,2,6,2,3])\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/generative_models.py:437, in molloy_reed(degree_sequence, multiedge, relax, node_ids)\n    435 # assume that we are given a graphical degree sequence\n    436 if not is_graphic_erdos_gallai(degree_sequence):\n--&gt; 437     raise AttributeError('degree sequence is not graphic')\n    439 # create empty network with n nodes\n    440 n = len(degree_sequence)\n\nAttributeError: degree sequence is not graphic</pre> <p>We can test whether a sequence of integers is graphic, i.e. whether we can use it to generate a Molloy-Reed random graph:</p> In\u00a0[10]: Copied! <pre>pp.algorithms.generative_models.is_graphic_erdos_gallai([2,2,6,2,3])\n</pre> pp.algorithms.generative_models.is_graphic_erdos_gallai([2,2,6,2,3]) Out[10]: <pre>False</pre> <p>We can use the Molloy-Reed model to randomize empirical networks, generating a random graph with the same degree sequence but a randomized topology:</p> In\u00a0[16]: Copied! <pre>r_karate = pp.algorithms.generative_models.molloy_reed_randomize(g_karate)\nprint(r_karate)\nprint(pp.statistics.degree_sequence(g_karate))\nprint(pp.statistics.degree_sequence(r_karate))\n</pre> r_karate = pp.algorithms.generative_models.molloy_reed_randomize(g_karate) print(r_karate) print(pp.statistics.degree_sequence(g_karate)) print(pp.statistics.degree_sequence(r_karate)) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n[16.  9. 10.  6.  3.  4.  4.  4.  5.  2.  3.  1.  2.  5.  2.  2.  2.  2.\n  2.  3.  2.  2.  1.  5.  3.  3.  2.  4.  3.  4.  4.  6. 12. 16.]\n[16.  9. 10.  6.  3.  4.  4.  4.  5.  2.  3.  1.  2.  5.  2.  2.  2.  2.\n  2.  3.  2.  2.  1.  5.  3.  3.  2.  4.  3.  4.  4.  6. 12. 16.]\n</pre> <p>Finally, the <code>generative_models</code> module also contains implementations of the Watts-Strogatz model as well as the stochastic block model. Different from the models above, those models cannot be used to randomize a graph though.</p> In\u00a0[18]: Copied! <pre>g = pp.algorithms.generative_models.watts_strogatz(n=100, s=2, p=0.1)\npp.plot(g);\n</pre> g = pp.algorithms.generative_models.watts_strogatz(n=100, s=2, p=0.1) pp.plot(g); <pre>{'edges': [{'uid': '0-2', 'source': '0', 'target': '2', 'weight': 1}, {'uid': '0-1', 'source': '0', 'target': '1', 'weight': 1}, {'uid': '0-99', 'source': '0', 'target': '99', 'weight': 1}, {'uid': '0-98', 'source': '0', 'target': '98', 'weight': 1}, {'uid': '1-0', 'source': '1', 'target': '0', 'weight': 1}, {'uid': '1-2', 'source': '1', 'target': '2', 'weight': 1}, {'uid': '1-3', 'source': '1', 'target': '3', 'weight': 1}, {'uid': '1-99', 'source': '1', 'target': '99', 'weight': 1}, {'uid': '2-0', 'source': '2', 'target': '0', 'weight': 1}, {'uid': '2-1', 'source': '2', 'target': '1', 'weight': 1}, {'uid': '2-3', 'source': '2', 'target': '3', 'weight': 1}, {'uid': '2-4', 'source': '2', 'target': '4', 'weight': 1}, {'uid': '3-5', 'source': '3', 'target': '5', 'weight': 1}, {'uid': '3-18', 'source': '3', 'target': '18', 'weight': 1}, {'uid': '3-4', 'source': '3', 'target': '4', 'weight': 1}, {'uid': '3-2', 'source': '3', 'target': '2', 'weight': 1}, {'uid': '3-1', 'source': '3', 'target': '1', 'weight': 1}, {'uid': '4-2', 'source': '4', 'target': '2', 'weight': 1}, {'uid': '4-3', 'source': '4', 'target': '3', 'weight': 1}, {'uid': '4-5', 'source': '4', 'target': '5', 'weight': 1}, {'uid': '4-6', 'source': '4', 'target': '6', 'weight': 1}, {'uid': '4-79', 'source': '4', 'target': '79', 'weight': 1}, {'uid': '5-3', 'source': '5', 'target': '3', 'weight': 1}, {'uid': '5-4', 'source': '5', 'target': '4', 'weight': 1}, {'uid': '5-6', 'source': '5', 'target': '6', 'weight': 1}, {'uid': '5-7', 'source': '5', 'target': '7', 'weight': 1}, {'uid': '6-7', 'source': '6', 'target': '7', 'weight': 1}, {'uid': '6-8', 'source': '6', 'target': '8', 'weight': 1}, {'uid': '6-5', 'source': '6', 'target': '5', 'weight': 1}, {'uid': '6-4', 'source': '6', 'target': '4', 'weight': 1}, {'uid': '7-5', 'source': '7', 'target': '5', 'weight': 1}, {'uid': '7-6', 'source': '7', 'target': '6', 'weight': 1}, {'uid': '7-9', 'source': '7', 'target': '9', 'weight': 1}, {'uid': '7-76', 'source': '7', 'target': '76', 'weight': 1}, {'uid': '8-6', 'source': '8', 'target': '6', 'weight': 1}, {'uid': '8-10', 'source': '8', 'target': '10', 'weight': 1}, {'uid': '8-96', 'source': '8', 'target': '96', 'weight': 1}, {'uid': '9-7', 'source': '9', 'target': '7', 'weight': 1}, {'uid': '9-10', 'source': '9', 'target': '10', 'weight': 1}, {'uid': '9-11', 'source': '9', 'target': '11', 'weight': 1}, {'uid': '10-9', 'source': '10', 'target': '9', 'weight': 1}, {'uid': '10-12', 'source': '10', 'target': '12', 'weight': 1}, {'uid': '10-11', 'source': '10', 'target': '11', 'weight': 1}, {'uid': '10-8', 'source': '10', 'target': '8', 'weight': 1}, {'uid': '11-9', 'source': '11', 'target': '9', 'weight': 1}, {'uid': '11-10', 'source': '11', 'target': '10', 'weight': 1}, {'uid': '11-12', 'source': '11', 'target': '12', 'weight': 1}, {'uid': '11-13', 'source': '11', 'target': '13', 'weight': 1}, {'uid': '12-10', 'source': '12', 'target': '10', 'weight': 1}, {'uid': '12-11', 'source': '12', 'target': '11', 'weight': 1}, {'uid': '12-13', 'source': '12', 'target': '13', 'weight': 1}, {'uid': '12-14', 'source': '12', 'target': '14', 'weight': 1}, {'uid': '13-12', 'source': '13', 'target': '12', 'weight': 1}, {'uid': '13-15', 'source': '13', 'target': '15', 'weight': 1}, {'uid': '13-14', 'source': '13', 'target': '14', 'weight': 1}, {'uid': '13-11', 'source': '13', 'target': '11', 'weight': 1}, {'uid': '14-13', 'source': '14', 'target': '13', 'weight': 1}, {'uid': '14-15', 'source': '14', 'target': '15', 'weight': 1}, {'uid': '14-16', 'source': '14', 'target': '16', 'weight': 1}, {'uid': '14-12', 'source': '14', 'target': '12', 'weight': 1}, {'uid': '15-13', 'source': '15', 'target': '13', 'weight': 1}, {'uid': '15-14', 'source': '15', 'target': '14', 'weight': 1}, {'uid': '15-16', 'source': '15', 'target': '16', 'weight': 1}, {'uid': '15-17', 'source': '15', 'target': '17', 'weight': 1}, {'uid': '16-18', 'source': '16', 'target': '18', 'weight': 1}, {'uid': '16-17', 'source': '16', 'target': '17', 'weight': 1}, {'uid': '16-15', 'source': '16', 'target': '15', 'weight': 1}, {'uid': '16-14', 'source': '16', 'target': '14', 'weight': 1}, {'uid': '17-15', 'source': '17', 'target': '15', 'weight': 1}, {'uid': '17-16', 'source': '17', 'target': '16', 'weight': 1}, {'uid': '17-18', 'source': '17', 'target': '18', 'weight': 1}, {'uid': '17-19', 'source': '17', 'target': '19', 'weight': 1}, {'uid': '18-3', 'source': '18', 'target': '3', 'weight': 1}, {'uid': '18-16', 'source': '18', 'target': '16', 'weight': 1}, {'uid': '18-17', 'source': '18', 'target': '17', 'weight': 1}, {'uid': '18-19', 'source': '18', 'target': '19', 'weight': 1}, {'uid': '19-53', 'source': '19', 'target': '53', 'weight': 1}, {'uid': '19-20', 'source': '19', 'target': '20', 'weight': 1}, {'uid': '19-17', 'source': '19', 'target': '17', 'weight': 1}, {'uid': '19-18', 'source': '19', 'target': '18', 'weight': 1}, {'uid': '20-19', 'source': '20', 'target': '19', 'weight': 1}, {'uid': '20-31', 'source': '20', 'target': '31', 'weight': 1}, {'uid': '20-70', 'source': '20', 'target': '70', 'weight': 1}, {'uid': '21-22', 'source': '21', 'target': '22', 'weight': 1}, {'uid': '21-23', 'source': '21', 'target': '23', 'weight': 1}, {'uid': '22-21', 'source': '22', 'target': '21', 'weight': 1}, {'uid': '22-23', 'source': '22', 'target': '23', 'weight': 1}, {'uid': '22-24', 'source': '22', 'target': '24', 'weight': 1}, {'uid': '22-77', 'source': '22', 'target': '77', 'weight': 1}, {'uid': '23-22', 'source': '23', 'target': '22', 'weight': 1}, {'uid': '23-25', 'source': '23', 'target': '25', 'weight': 1}, {'uid': '23-24', 'source': '23', 'target': '24', 'weight': 1}, {'uid': '23-21', 'source': '23', 'target': '21', 'weight': 1}, {'uid': '24-22', 'source': '24', 'target': '22', 'weight': 1}, {'uid': '24-23', 'source': '24', 'target': '23', 'weight': 1}, {'uid': '24-25', 'source': '24', 'target': '25', 'weight': 1}, {'uid': '24-26', 'source': '24', 'target': '26', 'weight': 1}, {'uid': '25-23', 'source': '25', 'target': '23', 'weight': 1}, {'uid': '25-24', 'source': '25', 'target': '24', 'weight': 1}, {'uid': '25-26', 'source': '25', 'target': '26', 'weight': 1}, {'uid': '25-27', 'source': '25', 'target': '27', 'weight': 1}, {'uid': '26-28', 'source': '26', 'target': '28', 'weight': 1}, {'uid': '26-24', 'source': '26', 'target': '24', 'weight': 1}, {'uid': '26-25', 'source': '26', 'target': '25', 'weight': 1}, {'uid': '26-27', 'source': '26', 'target': '27', 'weight': 1}, {'uid': '27-25', 'source': '27', 'target': '25', 'weight': 1}, {'uid': '27-26', 'source': '27', 'target': '26', 'weight': 1}, {'uid': '27-28', 'source': '27', 'target': '28', 'weight': 1}, {'uid': '27-29', 'source': '27', 'target': '29', 'weight': 1}, {'uid': '28-26', 'source': '28', 'target': '26', 'weight': 1}, {'uid': '28-27', 'source': '28', 'target': '27', 'weight': 1}, {'uid': '28-29', 'source': '28', 'target': '29', 'weight': 1}, {'uid': '28-45', 'source': '28', 'target': '45', 'weight': 1}, {'uid': '29-30', 'source': '29', 'target': '30', 'weight': 1}, {'uid': '29-31', 'source': '29', 'target': '31', 'weight': 1}, {'uid': '29-28', 'source': '29', 'target': '28', 'weight': 1}, {'uid': '29-27', 'source': '29', 'target': '27', 'weight': 1}, {'uid': '30-29', 'source': '30', 'target': '29', 'weight': 1}, {'uid': '30-31', 'source': '30', 'target': '31', 'weight': 1}, {'uid': '30-32', 'source': '30', 'target': '32', 'weight': 1}, {'uid': '31-20', 'source': '31', 'target': '20', 'weight': 1}, {'uid': '31-29', 'source': '31', 'target': '29', 'weight': 1}, {'uid': '31-30', 'source': '31', 'target': '30', 'weight': 1}, {'uid': '31-32', 'source': '31', 'target': '32', 'weight': 1}, {'uid': '31-33', 'source': '31', 'target': '33', 'weight': 1}, {'uid': '32-31', 'source': '32', 'target': '31', 'weight': 1}, {'uid': '32-34', 'source': '32', 'target': '34', 'weight': 1}, {'uid': '32-33', 'source': '32', 'target': '33', 'weight': 1}, {'uid': '32-30', 'source': '32', 'target': '30', 'weight': 1}, {'uid': '33-32', 'source': '33', 'target': '32', 'weight': 1}, {'uid': '33-34', 'source': '33', 'target': '34', 'weight': 1}, {'uid': '33-35', 'source': '33', 'target': '35', 'weight': 1}, {'uid': '33-31', 'source': '33', 'target': '31', 'weight': 1}, {'uid': '34-32', 'source': '34', 'target': '32', 'weight': 1}, {'uid': '34-33', 'source': '34', 'target': '33', 'weight': 1}, {'uid': '34-35', 'source': '34', 'target': '35', 'weight': 1}, {'uid': '34-71', 'source': '34', 'target': '71', 'weight': 1}, {'uid': '35-36', 'source': '35', 'target': '36', 'weight': 1}, {'uid': '35-37', 'source': '35', 'target': '37', 'weight': 1}, {'uid': '35-34', 'source': '35', 'target': '34', 'weight': 1}, {'uid': '35-33', 'source': '35', 'target': '33', 'weight': 1}, {'uid': '36-35', 'source': '36', 'target': '35', 'weight': 1}, {'uid': '36-37', 'source': '36', 'target': '37', 'weight': 1}, {'uid': '36-38', 'source': '36', 'target': '38', 'weight': 1}, {'uid': '37-35', 'source': '37', 'target': '35', 'weight': 1}, {'uid': '37-36', 'source': '37', 'target': '36', 'weight': 1}, {'uid': '37-38', 'source': '37', 'target': '38', 'weight': 1}, {'uid': '37-39', 'source': '37', 'target': '39', 'weight': 1}, {'uid': '38-39', 'source': '38', 'target': '39', 'weight': 1}, {'uid': '38-89', 'source': '38', 'target': '89', 'weight': 1}, {'uid': '38-36', 'source': '38', 'target': '36', 'weight': 1}, {'uid': '38-37', 'source': '38', 'target': '37', 'weight': 1}, {'uid': '39-38', 'source': '39', 'target': '38', 'weight': 1}, {'uid': '39-40', 'source': '39', 'target': '40', 'weight': 1}, {'uid': '39-41', 'source': '39', 'target': '41', 'weight': 1}, {'uid': '39-37', 'source': '39', 'target': '37', 'weight': 1}, {'uid': '40-39', 'source': '40', 'target': '39', 'weight': 1}, {'uid': '40-41', 'source': '40', 'target': '41', 'weight': 1}, {'uid': '40-42', 'source': '40', 'target': '42', 'weight': 1}, {'uid': '41-48', 'source': '41', 'target': '48', 'weight': 1}, {'uid': '41-43', 'source': '41', 'target': '43', 'weight': 1}, {'uid': '41-42', 'source': '41', 'target': '42', 'weight': 1}, {'uid': '41-40', 'source': '41', 'target': '40', 'weight': 1}, {'uid': '41-39', 'source': '41', 'target': '39', 'weight': 1}, {'uid': '42-40', 'source': '42', 'target': '40', 'weight': 1}, {'uid': '42-41', 'source': '42', 'target': '41', 'weight': 1}, {'uid': '42-44', 'source': '42', 'target': '44', 'weight': 1}, {'uid': '42-70', 'source': '42', 'target': '70', 'weight': 1}, {'uid': '43-41', 'source': '43', 'target': '41', 'weight': 1}, {'uid': '43-44', 'source': '43', 'target': '44', 'weight': 1}, {'uid': '43-45', 'source': '43', 'target': '45', 'weight': 1}, {'uid': '43-72', 'source': '43', 'target': '72', 'weight': 1}, {'uid': '44-46', 'source': '44', 'target': '46', 'weight': 1}, {'uid': '44-45', 'source': '44', 'target': '45', 'weight': 1}, {'uid': '44-42', 'source': '44', 'target': '42', 'weight': 1}, {'uid': '44-43', 'source': '44', 'target': '43', 'weight': 1}, {'uid': '45-28', 'source': '45', 'target': '28', 'weight': 1}, {'uid': '45-43', 'source': '45', 'target': '43', 'weight': 1}, {'uid': '45-44', 'source': '45', 'target': '44', 'weight': 1}, {'uid': '45-46', 'source': '45', 'target': '46', 'weight': 1}, {'uid': '45-47', 'source': '45', 'target': '47', 'weight': 1}, {'uid': '46-44', 'source': '46', 'target': '44', 'weight': 1}, {'uid': '46-45', 'source': '46', 'target': '45', 'weight': 1}, {'uid': '46-47', 'source': '46', 'target': '47', 'weight': 1}, {'uid': '46-48', 'source': '46', 'target': '48', 'weight': 1}, {'uid': '47-46', 'source': '47', 'target': '46', 'weight': 1}, {'uid': '47-49', 'source': '47', 'target': '49', 'weight': 1}, {'uid': '47-48', 'source': '47', 'target': '48', 'weight': 1}, {'uid': '47-45', 'source': '47', 'target': '45', 'weight': 1}, {'uid': '48-41', 'source': '48', 'target': '41', 'weight': 1}, {'uid': '48-46', 'source': '48', 'target': '46', 'weight': 1}, {'uid': '48-47', 'source': '48', 'target': '47', 'weight': 1}, {'uid': '48-49', 'source': '48', 'target': '49', 'weight': 1}, {'uid': '49-47', 'source': '49', 'target': '47', 'weight': 1}, {'uid': '49-48', 'source': '49', 'target': '48', 'weight': 1}, {'uid': '49-50', 'source': '49', 'target': '50', 'weight': 1}, {'uid': '49-51', 'source': '49', 'target': '51', 'weight': 1}, {'uid': '50-58', 'source': '50', 'target': '58', 'weight': 1}, {'uid': '50-52', 'source': '50', 'target': '52', 'weight': 1}, {'uid': '50-49', 'source': '50', 'target': '49', 'weight': 1}, {'uid': '50-51', 'source': '50', 'target': '51', 'weight': 1}, {'uid': '51-50', 'source': '51', 'target': '50', 'weight': 1}, {'uid': '51-52', 'source': '51', 'target': '52', 'weight': 1}, {'uid': '51-53', 'source': '51', 'target': '53', 'weight': 1}, {'uid': '51-49', 'source': '51', 'target': '49', 'weight': 1}, {'uid': '52-50', 'source': '52', 'target': '50', 'weight': 1}, {'uid': '52-51', 'source': '52', 'target': '51', 'weight': 1}, {'uid': '52-53', 'source': '52', 'target': '53', 'weight': 1}, {'uid': '52-54', 'source': '52', 'target': '54', 'weight': 1}, {'uid': '53-19', 'source': '53', 'target': '19', 'weight': 1}, {'uid': '53-51', 'source': '53', 'target': '51', 'weight': 1}, {'uid': '53-52', 'source': '53', 'target': '52', 'weight': 1}, {'uid': '53-54', 'source': '53', 'target': '54', 'weight': 1}, {'uid': '53-55', 'source': '53', 'target': '55', 'weight': 1}, {'uid': '54-52', 'source': '54', 'target': '52', 'weight': 1}, {'uid': '54-56', 'source': '54', 'target': '56', 'weight': 1}, {'uid': '54-55', 'source': '54', 'target': '55', 'weight': 1}, {'uid': '54-53', 'source': '54', 'target': '53', 'weight': 1}, {'uid': '55-53', 'source': '55', 'target': '53', 'weight': 1}, {'uid': '55-54', 'source': '55', 'target': '54', 'weight': 1}, {'uid': '55-56', 'source': '55', 'target': '56', 'weight': 1}, {'uid': '55-57', 'source': '55', 'target': '57', 'weight': 1}, {'uid': '56-54', 'source': '56', 'target': '54', 'weight': 1}, {'uid': '56-55', 'source': '56', 'target': '55', 'weight': 1}, {'uid': '56-57', 'source': '56', 'target': '57', 'weight': 1}, {'uid': '56-58', 'source': '56', 'target': '58', 'weight': 1}, {'uid': '57-55', 'source': '57', 'target': '55', 'weight': 1}, {'uid': '57-88', 'source': '57', 'target': '88', 'weight': 1}, {'uid': '57-56', 'source': '57', 'target': '56', 'weight': 1}, {'uid': '57-58', 'source': '57', 'target': '58', 'weight': 1}, {'uid': '58-50', 'source': '58', 'target': '50', 'weight': 1}, {'uid': '58-56', 'source': '58', 'target': '56', 'weight': 1}, {'uid': '58-57', 'source': '58', 'target': '57', 'weight': 1}, {'uid': '58-60', 'source': '58', 'target': '60', 'weight': 1}, {'uid': '59-60', 'source': '59', 'target': '60', 'weight': 1}, {'uid': '59-61', 'source': '59', 'target': '61', 'weight': 1}, {'uid': '60-62', 'source': '60', 'target': '62', 'weight': 1}, {'uid': '60-61', 'source': '60', 'target': '61', 'weight': 1}, {'uid': '60-59', 'source': '60', 'target': '59', 'weight': 1}, {'uid': '60-58', 'source': '60', 'target': '58', 'weight': 1}, {'uid': '61-59', 'source': '61', 'target': '59', 'weight': 1}, {'uid': '61-60', 'source': '61', 'target': '60', 'weight': 1}, {'uid': '61-62', 'source': '61', 'target': '62', 'weight': 1}, {'uid': '61-63', 'source': '61', 'target': '63', 'weight': 1}, {'uid': '61-73', 'source': '61', 'target': '73', 'weight': 1}, {'uid': '62-60', 'source': '62', 'target': '60', 'weight': 1}, {'uid': '62-61', 'source': '62', 'target': '61', 'weight': 1}, {'uid': '62-63', 'source': '62', 'target': '63', 'weight': 1}, {'uid': '62-64', 'source': '62', 'target': '64', 'weight': 1}, {'uid': '63-61', 'source': '63', 'target': '61', 'weight': 1}, {'uid': '63-65', 'source': '63', 'target': '65', 'weight': 1}, {'uid': '63-62', 'source': '63', 'target': '62', 'weight': 1}, {'uid': '63-64', 'source': '63', 'target': '64', 'weight': 1}, {'uid': '64-63', 'source': '64', 'target': '63', 'weight': 1}, {'uid': '64-65', 'source': '64', 'target': '65', 'weight': 1}, {'uid': '64-66', 'source': '64', 'target': '66', 'weight': 1}, {'uid': '64-62', 'source': '64', 'target': '62', 'weight': 1}, {'uid': '65-63', 'source': '65', 'target': '63', 'weight': 1}, {'uid': '65-64', 'source': '65', 'target': '64', 'weight': 1}, {'uid': '65-66', 'source': '65', 'target': '66', 'weight': 1}, {'uid': '65-67', 'source': '65', 'target': '67', 'weight': 1}, {'uid': '66-68', 'source': '66', 'target': '68', 'weight': 1}, {'uid': '66-67', 'source': '66', 'target': '67', 'weight': 1}, {'uid': '66-65', 'source': '66', 'target': '65', 'weight': 1}, {'uid': '66-64', 'source': '66', 'target': '64', 'weight': 1}, {'uid': '67-65', 'source': '67', 'target': '65', 'weight': 1}, {'uid': '67-66', 'source': '67', 'target': '66', 'weight': 1}, {'uid': '67-68', 'source': '67', 'target': '68', 'weight': 1}, {'uid': '67-69', 'source': '67', 'target': '69', 'weight': 1}, {'uid': '68-66', 'source': '68', 'target': '66', 'weight': 1}, {'uid': '68-67', 'source': '68', 'target': '67', 'weight': 1}, {'uid': '68-70', 'source': '68', 'target': '70', 'weight': 1}, {'uid': '68-97', 'source': '68', 'target': '97', 'weight': 1}, {'uid': '69-71', 'source': '69', 'target': '71', 'weight': 1}, {'uid': '69-70', 'source': '69', 'target': '70', 'weight': 1}, {'uid': '69-67', 'source': '69', 'target': '67', 'weight': 1}, {'uid': '70-20', 'source': '70', 'target': '20', 'weight': 1}, {'uid': '70-42', 'source': '70', 'target': '42', 'weight': 1}, {'uid': '70-68', 'source': '70', 'target': '68', 'weight': 1}, {'uid': '70-69', 'source': '70', 'target': '69', 'weight': 1}, {'uid': '70-71', 'source': '70', 'target': '71', 'weight': 1}, {'uid': '70-72', 'source': '70', 'target': '72', 'weight': 1}, {'uid': '71-73', 'source': '71', 'target': '73', 'weight': 1}, {'uid': '71-72', 'source': '71', 'target': '72', 'weight': 1}, {'uid': '71-70', 'source': '71', 'target': '70', 'weight': 1}, {'uid': '71-69', 'source': '71', 'target': '69', 'weight': 1}, {'uid': '71-34', 'source': '71', 'target': '34', 'weight': 1}, {'uid': '72-43', 'source': '72', 'target': '43', 'weight': 1}, {'uid': '72-70', 'source': '72', 'target': '70', 'weight': 1}, {'uid': '72-71', 'source': '72', 'target': '71', 'weight': 1}, {'uid': '72-73', 'source': '72', 'target': '73', 'weight': 1}, {'uid': '72-95', 'source': '72', 'target': '95', 'weight': 1}, {'uid': '73-61', 'source': '73', 'target': '61', 'weight': 1}, {'uid': '73-71', 'source': '73', 'target': '71', 'weight': 1}, {'uid': '73-72', 'source': '73', 'target': '72', 'weight': 1}, {'uid': '73-74', 'source': '73', 'target': '74', 'weight': 1}, {'uid': '74-76', 'source': '74', 'target': '76', 'weight': 1}, {'uid': '74-73', 'source': '74', 'target': '73', 'weight': 1}, {'uid': '74-75', 'source': '74', 'target': '75', 'weight': 1}, {'uid': '75-76', 'source': '75', 'target': '76', 'weight': 1}, {'uid': '75-74', 'source': '75', 'target': '74', 'weight': 1}, {'uid': '75-77', 'source': '75', 'target': '77', 'weight': 1}, {'uid': '76-7', 'source': '76', 'target': '7', 'weight': 1}, {'uid': '76-74', 'source': '76', 'target': '74', 'weight': 1}, {'uid': '76-75', 'source': '76', 'target': '75', 'weight': 1}, {'uid': '76-77', 'source': '76', 'target': '77', 'weight': 1}, {'uid': '76-78', 'source': '76', 'target': '78', 'weight': 1}, {'uid': '77-22', 'source': '77', 'target': '22', 'weight': 1}, {'uid': '77-75', 'source': '77', 'target': '75', 'weight': 1}, {'uid': '77-76', 'source': '77', 'target': '76', 'weight': 1}, {'uid': '77-78', 'source': '77', 'target': '78', 'weight': 1}, {'uid': '78-77', 'source': '78', 'target': '77', 'weight': 1}, {'uid': '78-80', 'source': '78', 'target': '80', 'weight': 1}, {'uid': '78-79', 'source': '78', 'target': '79', 'weight': 1}, {'uid': '78-76', 'source': '78', 'target': '76', 'weight': 1}, {'uid': '79-4', 'source': '79', 'target': '4', 'weight': 1}, {'uid': '79-78', 'source': '79', 'target': '78', 'weight': 1}, {'uid': '79-81', 'source': '79', 'target': '81', 'weight': 1}, {'uid': '80-78', 'source': '80', 'target': '78', 'weight': 1}, {'uid': '80-81', 'source': '80', 'target': '81', 'weight': 1}, {'uid': '80-82', 'source': '80', 'target': '82', 'weight': 1}, {'uid': '81-83', 'source': '81', 'target': '83', 'weight': 1}, {'uid': '81-82', 'source': '81', 'target': '82', 'weight': 1}, {'uid': '81-79', 'source': '81', 'target': '79', 'weight': 1}, {'uid': '81-80', 'source': '81', 'target': '80', 'weight': 1}, {'uid': '82-80', 'source': '82', 'target': '80', 'weight': 1}, {'uid': '82-81', 'source': '82', 'target': '81', 'weight': 1}, {'uid': '82-83', 'source': '82', 'target': '83', 'weight': 1}, {'uid': '82-84', 'source': '82', 'target': '84', 'weight': 1}, {'uid': '83-81', 'source': '83', 'target': '81', 'weight': 1}, {'uid': '83-82', 'source': '83', 'target': '82', 'weight': 1}, {'uid': '83-84', 'source': '83', 'target': '84', 'weight': 1}, {'uid': '83-85', 'source': '83', 'target': '85', 'weight': 1}, {'uid': '84-85', 'source': '84', 'target': '85', 'weight': 1}, {'uid': '84-86', 'source': '84', 'target': '86', 'weight': 1}, {'uid': '84-83', 'source': '84', 'target': '83', 'weight': 1}, {'uid': '84-82', 'source': '84', 'target': '82', 'weight': 1}, {'uid': '85-83', 'source': '85', 'target': '83', 'weight': 1}, {'uid': '85-84', 'source': '85', 'target': '84', 'weight': 1}, {'uid': '85-86', 'source': '85', 'target': '86', 'weight': 1}, {'uid': '85-87', 'source': '85', 'target': '87', 'weight': 1}, {'uid': '86-84', 'source': '86', 'target': '84', 'weight': 1}, {'uid': '86-85', 'source': '86', 'target': '85', 'weight': 1}, {'uid': '86-87', 'source': '86', 'target': '87', 'weight': 1}, {'uid': '86-88', 'source': '86', 'target': '88', 'weight': 1}, {'uid': '87-89', 'source': '87', 'target': '89', 'weight': 1}, {'uid': '87-88', 'source': '87', 'target': '88', 'weight': 1}, {'uid': '87-85', 'source': '87', 'target': '85', 'weight': 1}, {'uid': '87-86', 'source': '87', 'target': '86', 'weight': 1}, {'uid': '88-86', 'source': '88', 'target': '86', 'weight': 1}, {'uid': '88-87', 'source': '88', 'target': '87', 'weight': 1}, {'uid': '88-89', 'source': '88', 'target': '89', 'weight': 1}, {'uid': '88-90', 'source': '88', 'target': '90', 'weight': 1}, {'uid': '88-57', 'source': '88', 'target': '57', 'weight': 1}, {'uid': '89-38', 'source': '89', 'target': '38', 'weight': 1}, {'uid': '89-87', 'source': '89', 'target': '87', 'weight': 1}, {'uid': '89-88', 'source': '89', 'target': '88', 'weight': 1}, {'uid': '89-90', 'source': '89', 'target': '90', 'weight': 1}, {'uid': '89-91', 'source': '89', 'target': '91', 'weight': 1}, {'uid': '90-91', 'source': '90', 'target': '91', 'weight': 1}, {'uid': '90-92', 'source': '90', 'target': '92', 'weight': 1}, {'uid': '90-89', 'source': '90', 'target': '89', 'weight': 1}, {'uid': '90-88', 'source': '90', 'target': '88', 'weight': 1}, {'uid': '91-89', 'source': '91', 'target': '89', 'weight': 1}, {'uid': '91-90', 'source': '91', 'target': '90', 'weight': 1}, {'uid': '91-92', 'source': '91', 'target': '92', 'weight': 1}, {'uid': '91-93', 'source': '91', 'target': '93', 'weight': 1}, {'uid': '92-90', 'source': '92', 'target': '90', 'weight': 1}, {'uid': '92-91', 'source': '92', 'target': '91', 'weight': 1}, {'uid': '92-93', 'source': '92', 'target': '93', 'weight': 1}, {'uid': '92-94', 'source': '92', 'target': '94', 'weight': 1}, {'uid': '93-95', 'source': '93', 'target': '95', 'weight': 1}, {'uid': '93-92', 'source': '93', 'target': '92', 'weight': 1}, {'uid': '93-91', 'source': '93', 'target': '91', 'weight': 1}, {'uid': '93-94', 'source': '93', 'target': '94', 'weight': 1}, {'uid': '94-92', 'source': '94', 'target': '92', 'weight': 1}, {'uid': '94-93', 'source': '94', 'target': '93', 'weight': 1}, {'uid': '94-96', 'source': '94', 'target': '96', 'weight': 1}, {'uid': '95-72', 'source': '95', 'target': '72', 'weight': 1}, {'uid': '95-93', 'source': '95', 'target': '93', 'weight': 1}, {'uid': '95-97', 'source': '95', 'target': '97', 'weight': 1}, {'uid': '96-8', 'source': '96', 'target': '8', 'weight': 1}, {'uid': '96-94', 'source': '96', 'target': '94', 'weight': 1}, {'uid': '96-97', 'source': '96', 'target': '97', 'weight': 1}, {'uid': '96-98', 'source': '96', 'target': '98', 'weight': 1}, {'uid': '97-68', 'source': '97', 'target': '68', 'weight': 1}, {'uid': '97-99', 'source': '97', 'target': '99', 'weight': 1}, {'uid': '97-98', 'source': '97', 'target': '98', 'weight': 1}, {'uid': '97-96', 'source': '97', 'target': '96', 'weight': 1}, {'uid': '97-95', 'source': '97', 'target': '95', 'weight': 1}, {'uid': '98-0', 'source': '98', 'target': '0', 'weight': 1}, {'uid': '98-96', 'source': '98', 'target': '96', 'weight': 1}, {'uid': '98-97', 'source': '98', 'target': '97', 'weight': 1}, {'uid': '98-99', 'source': '98', 'target': '99', 'weight': 1}, {'uid': '99-0', 'source': '99', 'target': '0', 'weight': 1}, {'uid': '99-1', 'source': '99', 'target': '1', 'weight': 1}, {'uid': '99-97', 'source': '99', 'target': '97', 'weight': 1}, {'uid': '99-98', 'source': '99', 'target': '98', 'weight': 1}], 'nodes': [{'uid': '0'}, {'uid': '1'}, {'uid': '2'}, {'uid': '3'}, {'uid': '4'}, {'uid': '5'}, {'uid': '6'}, {'uid': '7'}, {'uid': '8'}, {'uid': '9'}, {'uid': '10'}, {'uid': '11'}, {'uid': '12'}, {'uid': '13'}, {'uid': '14'}, {'uid': '15'}, {'uid': '16'}, {'uid': '17'}, {'uid': '18'}, {'uid': '19'}, {'uid': '20'}, {'uid': '21'}, {'uid': '22'}, {'uid': '23'}, {'uid': '24'}, {'uid': '25'}, {'uid': '26'}, {'uid': '27'}, {'uid': '28'}, {'uid': '29'}, {'uid': '30'}, {'uid': '31'}, {'uid': '32'}, {'uid': '33'}, {'uid': '34'}, {'uid': '35'}, {'uid': '36'}, {'uid': '37'}, {'uid': '38'}, {'uid': '39'}, {'uid': '40'}, {'uid': '41'}, {'uid': '42'}, {'uid': '43'}, {'uid': '44'}, {'uid': '45'}, {'uid': '46'}, {'uid': '47'}, {'uid': '48'}, {'uid': '49'}, {'uid': '50'}, {'uid': '51'}, {'uid': '52'}, {'uid': '53'}, {'uid': '54'}, {'uid': '55'}, {'uid': '56'}, {'uid': '57'}, {'uid': '58'}, {'uid': '59'}, {'uid': '60'}, {'uid': '61'}, {'uid': '62'}, {'uid': '63'}, {'uid': '64'}, {'uid': '65'}, {'uid': '66'}, {'uid': '67'}, {'uid': '68'}, {'uid': '69'}, {'uid': '70'}, {'uid': '71'}, {'uid': '72'}, {'uid': '73'}, {'uid': '74'}, {'uid': '75'}, {'uid': '76'}, {'uid': '77'}, {'uid': '78'}, {'uid': '79'}, {'uid': '80'}, {'uid': '81'}, {'uid': '82'}, {'uid': '83'}, {'uid': '84'}, {'uid': '85'}, {'uid': '86'}, {'uid': '87'}, {'uid': '88'}, {'uid': '89'}, {'uid': '90'}, {'uid': '91'}, {'uid': '92'}, {'uid': '93'}, {'uid': '94'}, {'uid': '95'}, {'uid': '96'}, {'uid': '97'}, {'uid': '98'}, {'uid': '99'}]}\n</pre> <p>To generate an undirected random graph based on the stochastic block model, we must minimally specify two parameters:</p> <p>The stochastic block matrix $M$ contains edge probabilities for all pairs of nodes where the source and target belong to different blocks.</p> <p>The block assignment vector $z$ assigns nodes to blocks (based on their index). The length of this vector implicitly determined the number of nodes.</p> <p>In the example below, we generate a random graph with eight nodes, where the first four nodes <code>a</code> - <code>d</code> are assigned to block 0 and the last four nodes <code>e</code> - <code>h</code> are assigned to block 1. Edges between node pairs where both nodes are in block 0 are generated with probability $0.95$. If both nodes are in block 1 edges are generated with probability $0.85$. If the nodes are in different blocks, edges are generated with probability $0.1$.</p> In\u00a0[40]: Copied! <pre>M = np.matrix('0.95 0.15; 0.15 0.85')\nprint(M)\nz = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n\ng = pp.algorithms.generative_models.stochastic_block_model(M, z, pp.IndexMap(list('abcdefgh')))\npp.plot(g, node_label=g.nodes, node_color=z.tolist());\n</pre> M = np.matrix('0.95 0.15; 0.15 0.85') print(M) z = np.array([0, 0, 0, 0, 1, 1, 1, 1])  g = pp.algorithms.generative_models.stochastic_block_model(M, z, pp.IndexMap(list('abcdefgh'))) pp.plot(g, node_label=g.nodes, node_color=z.tolist()); <pre>[[0.95 0.15]\n [0.15 0.85]]\n{'edges': [{'uid': 'a-c', 'source': 'a', 'target': 'c', 'weight': 1}, {'uid': 'a-d', 'source': 'a', 'target': 'd', 'weight': 1}, {'uid': 'a-b', 'source': 'a', 'target': 'b', 'weight': 1}, {'uid': 'b-a', 'source': 'b', 'target': 'a', 'weight': 1}, {'uid': 'b-c', 'source': 'b', 'target': 'c', 'weight': 1}, {'uid': 'b-d', 'source': 'b', 'target': 'd', 'weight': 1}, {'uid': 'c-a', 'source': 'c', 'target': 'a', 'weight': 1}, {'uid': 'c-b', 'source': 'c', 'target': 'b', 'weight': 1}, {'uid': 'c-d', 'source': 'c', 'target': 'd', 'weight': 1}, {'uid': 'c-f', 'source': 'c', 'target': 'f', 'weight': 1}, {'uid': 'd-c', 'source': 'd', 'target': 'c', 'weight': 1}, {'uid': 'd-b', 'source': 'd', 'target': 'b', 'weight': 1}, {'uid': 'd-a', 'source': 'd', 'target': 'a', 'weight': 1}, {'uid': 'e-f', 'source': 'e', 'target': 'f', 'weight': 1}, {'uid': 'e-g', 'source': 'e', 'target': 'g', 'weight': 1}, {'uid': 'f-c', 'source': 'f', 'target': 'c', 'weight': 1}, {'uid': 'f-e', 'source': 'f', 'target': 'e', 'weight': 1}, {'uid': 'f-g', 'source': 'f', 'target': 'g', 'weight': 1}, {'uid': 'f-h', 'source': 'f', 'target': 'h', 'weight': 1}, {'uid': 'g-e', 'source': 'g', 'target': 'e', 'weight': 1}, {'uid': 'g-f', 'source': 'g', 'target': 'f', 'weight': 1}, {'uid': 'g-h', 'source': 'g', 'target': 'h', 'weight': 1}, {'uid': 'h-f', 'source': 'h', 'target': 'f', 'weight': 1}, {'uid': 'h-g', 'source': 'h', 'target': 'g', 'weight': 1}], 'nodes': [{'uid': 'a', 'label': 'a', 'color': '#00ff00'}, {'uid': 'b', 'label': 'b', 'color': '#00ff00'}, {'uid': 'c', 'label': 'c', 'color': '#00ff00'}, {'uid': 'd', 'label': 'd', 'color': '#00ff00'}, {'uid': 'e', 'label': 'e', 'color': '#ff0000'}, {'uid': 'f', 'label': 'f', 'color': '#ff0000'}, {'uid': 'g', 'label': 'g', 'color': '#ff0000'}, {'uid': 'h', 'label': 'h', 'color': '#ff0000'}]}\n</pre> <p>To generate a graph with three fully connected cliques, we can specify the parameters as follows:</p> In\u00a0[49]: Copied! <pre>M = np.matrix('1 0 0;0 1 0;0 0 1')\nprint(M)\nz = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\ng = pp.algorithms.generative_models.stochastic_block_model(M, z, pp.IndexMap(list('abcdefghi')))\nprint(g)\npp.plot(g, node_label=g.nodes, node_color=z.tolist());\n</pre> M = np.matrix('1 0 0;0 1 0;0 0 1') print(M) z = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2]) g = pp.algorithms.generative_models.stochastic_block_model(M, z, pp.IndexMap(list('abcdefghi'))) print(g) pp.plot(g, node_label=g.nodes, node_color=z.tolist()); <pre>[[1 0 0]\n [0 1 0]\n [0 0 1]]\nUndirected graph with 9 nodes and 18 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n{'edges': [{'uid': 'a-c', 'source': 'a', 'target': 'c', 'weight': 1}, {'uid': 'a-b', 'source': 'a', 'target': 'b', 'weight': 1}, {'uid': 'b-a', 'source': 'b', 'target': 'a', 'weight': 1}, {'uid': 'b-c', 'source': 'b', 'target': 'c', 'weight': 1}, {'uid': 'c-a', 'source': 'c', 'target': 'a', 'weight': 1}, {'uid': 'c-b', 'source': 'c', 'target': 'b', 'weight': 1}, {'uid': 'd-e', 'source': 'd', 'target': 'e', 'weight': 1}, {'uid': 'd-f', 'source': 'd', 'target': 'f', 'weight': 1}, {'uid': 'e-f', 'source': 'e', 'target': 'f', 'weight': 1}, {'uid': 'e-d', 'source': 'e', 'target': 'd', 'weight': 1}, {'uid': 'f-d', 'source': 'f', 'target': 'd', 'weight': 1}, {'uid': 'f-e', 'source': 'f', 'target': 'e', 'weight': 1}, {'uid': 'g-h', 'source': 'g', 'target': 'h', 'weight': 1}, {'uid': 'g-i', 'source': 'g', 'target': 'i', 'weight': 1}, {'uid': 'h-g', 'source': 'h', 'target': 'g', 'weight': 1}, {'uid': 'h-i', 'source': 'h', 'target': 'i', 'weight': 1}, {'uid': 'i-g', 'source': 'i', 'target': 'g', 'weight': 1}, {'uid': 'i-h', 'source': 'i', 'target': 'h', 'weight': 1}], 'nodes': [{'uid': 'a', 'label': 'a', 'color': '#00ff00'}, {'uid': 'b', 'label': 'b', 'color': '#00ff00'}, {'uid': 'c', 'label': 'c', 'color': '#00ff00'}, {'uid': 'd', 'label': 'd', 'color': '#7f7f00'}, {'uid': 'e', 'label': 'e', 'color': '#7f7f00'}, {'uid': 'f', 'label': 'f', 'color': '#7f7f00'}, {'uid': 'g', 'label': 'g', 'color': '#ff0000'}, {'uid': 'h', 'label': 'h', 'color': '#ff0000'}, {'uid': 'i', 'label': 'i', 'color': '#ff0000'}]}\n</pre> In\u00a0[55]: Copied! <pre>from pathpyG.algorithms import connected_components\n</pre> from pathpyG.algorithms import connected_components In\u00a0[56]: Copied! <pre>connected_components(g)\n</pre> connected_components(g) Out[56]: <pre>(3, array([0, 0, 0, 1, 1, 1, 2, 2, 2], dtype=int32))</pre>"},{"location":"tutorial/generative_models/#generative-models-for-random-graphs","title":"Generative Models for Random Graphs\u00b6","text":""},{"location":"tutorial/generative_models/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/implementation_concepts/","title":"Implementation Concepts","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n# !pip install torch_geometric\n# !pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch # !pip install torch_geometric # !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[2]: Copied! <pre>import torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.utils import cumsum, degree, sort_edge_index\n\nimport pathpyG as pp\n</pre> import torch from torch_geometric.data import Data from torch_geometric.utils import cumsum, degree, sort_edge_index  import pathpyG as pp In\u00a0[3]: Copied! <pre>mapping = pp.IndexMap(list(\"abcdef\"))\ngraph = pp.Graph.from_edge_index(\n    edge_index=torch.tensor([[0, 1, 3, 4, 2, 2, 5], [2, 2, 5, 5, 3, 4, 0]]), mapping=mapping\n)\npp.plot(graph, node_label=graph.nodes)\n</pre> mapping = pp.IndexMap(list(\"abcdef\")) graph = pp.Graph.from_edge_index(     edge_index=torch.tensor([[0, 1, 3, 4, 2, 2, 5], [2, 2, 5, 5, 3, 4, 0]]), mapping=mapping ) pp.plot(graph, node_label=graph.nodes) Out[3]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd5d0e990f0&gt;</pre> <p>We can create the line graph for this graph using the <code>lift_order_edge_index</code> function as follows:</p> In\u00a0[4]: Copied! <pre>second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=graph.data.edge_index, num_nodes=graph.n)\nsecond_order_mapping = pp.IndexMap(graph.edges)\nsecond_order_data = Data(edge_index=second_order_edge_index, node_sequence=graph.data.edge_index.t())\nline_graph = pp.Graph(data=second_order_data, mapping=second_order_mapping)\npp.plot(line_graph, node_label=line_graph.nodes)\n</pre> second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=graph.data.edge_index, num_nodes=graph.n) second_order_mapping = pp.IndexMap(graph.edges) second_order_data = Data(edge_index=second_order_edge_index, node_sequence=graph.data.edge_index.t()) line_graph = pp.Graph(data=second_order_data, mapping=second_order_mapping) pp.plot(line_graph, node_label=line_graph.nodes) Out[4]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee1930&gt;</pre> <p>To create the higher-order <code>PathpyG.Graph</code>, we needed to specify a <code>node_sequence</code> in the <code>Data</code> object. The node sequence above was given by the original edges of the graph. This <code>node_sequence</code> keeps track of which original nodes correspond to which higher-order nodes in the higher-order graph. In a second order graph, each higher-order node corresponds to an edge in the original graph. In a graph of order k, each higher-order node corresponds to a path of length k in the original graph. With this, we can always trace back which higher-order node corresponds to which original nodes.</p> <p>As long as we have this mapping from higher-order nodes to original nodes, we can always do an additional line graph transformation to create even higher order graphs. Below, we create a third-order graph:</p> In\u00a0[5]: Copied! <pre>third_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=line_graph.data.edge_index, num_nodes=line_graph.n)\nthird_order_data = Data(edge_index=third_order_edge_index, node_sequence=torch.cat([line_graph.data.node_sequence[line_graph.data.edge_index[0]], line_graph.data.node_sequence[line_graph.data.edge_index[1]][:, -1:]], dim=1))\nthird_order_mapping = pp.IndexMap([tuple(seq) for seq in graph.mapping.to_ids(third_order_data.node_sequence).tolist()])\nthird_order_graph = pp.Graph(data=third_order_data, mapping=third_order_mapping)\npp.plot(third_order_graph, node_label=third_order_graph.nodes)\n</pre> third_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=line_graph.data.edge_index, num_nodes=line_graph.n) third_order_data = Data(edge_index=third_order_edge_index, node_sequence=torch.cat([line_graph.data.node_sequence[line_graph.data.edge_index[0]], line_graph.data.node_sequence[line_graph.data.edge_index[1]][:, -1:]], dim=1)) third_order_mapping = pp.IndexMap([tuple(seq) for seq in graph.mapping.to_ids(third_order_data.node_sequence).tolist()]) third_order_graph = pp.Graph(data=third_order_data, mapping=third_order_mapping) pp.plot(third_order_graph, node_label=third_order_graph.nodes) Out[5]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee3070&gt;</pre> <p>Note that above, we constructed the <code>node_sequence</code> for the third-order graph by concatenating the sequences of the two nodes that form each edge in the second-order graph. However, only the first node in the sequence of the higher-order source and the last node in the sequence of the higher-order target node are different. The middle nodes are the same for both higher-order nodes since they represent the overlapping part of the paths.</p> In\u00a0[6]: Copied! <pre>def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int ) -&gt; torch.Tensor:\n    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n    outdegree_per_dst = outdegree[edge_index[1]]\n    num_new_edges = outdegree_per_dst.sum()\n    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n    ptrs = cumsum(outdegree, dim=0)[:-1]\n    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n    idx_correction = torch.arange(num_new_edges, dtype=torch.long)\n    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n    ho_edge_dsts += idx_correction\n    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</pre> def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int ) -&gt; torch.Tensor:     outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)     outdegree_per_dst = outdegree[edge_index[1]]     num_new_edges = outdegree_per_dst.sum()     ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)     ptrs = cumsum(outdegree, dim=0)[:-1]     ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)     idx_correction = torch.arange(num_new_edges, dtype=torch.long)     idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]     ho_edge_dsts += idx_correction     return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0) <p>However, what the function does exactly is obfuscated by the heavy use of tensor operations. Let us break down the function step-by-step to understand what is happening internally.</p> <p>Note</p> <p>         Due to the high complexity of the tensor operations, we will maintain to lines of explanations that try to explain the same concepts with different words. One explanation line will be added to the code snippets as comments and the other explanation line will be provided in the markdown cells between the code snippets.     </p> <p>Edge index must be sorted!</p> <p>     The <code>lift_order_edge_index</code> function assumes that the input <code>edge_index</code> is sorted by source nodes. This is not enforced by the function itself, because we ensure that the edge indices are sorted whenever we create a <code>PathpyG.Graph</code> object. This step is crucial for the correct functioning of the <code>lift_order_edge_index</code> function.     </p> <ol> <li>The function first computes the outdegree of each node in the graph using the <code>degree</code> function from <code>torch_geometric.utils</code>. This gives us a tensor containing the number of outgoing edges for each node.</li> </ol> In\u00a0[7]: Copied! <pre># Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge\noutdegree = degree(graph.data.edge_index[0], dtype=torch.long, num_nodes=graph.n)\nprint(\"Outdegree per node:\")\nfor node in graph.nodes:\n    print(f\"\\t{node}: {outdegree[graph.mapping.to_idx(node)].item()}\")\n</pre> # Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge outdegree = degree(graph.data.edge_index[0], dtype=torch.long, num_nodes=graph.n) print(\"Outdegree per node:\") for node in graph.nodes:     print(f\"\\t{node}: {outdegree[graph.mapping.to_idx(node)].item()}\") <pre>Outdegree per node:\n\ta: 1\n\tb: 1\n\tc: 2\n\td: 1\n\te: 1\n\tf: 1\n</pre> <ol> <li>Next, we map the outdegree values to the destination nodes of each edge in the edge index. This gives us a tensor where each entry corresponds to the outdegree of the target node of each edge.</li> </ol> <p>Note</p> <p>         This helps us because for the line graph transformation, we need to transform each edge into a node and then connect these nodes (previously edges) if a node in the original graph connects them. Therefore, we need to create a higher-order edge for each combination of incoming and outgoing edges for each node in the original graph. The outdegree of the target node tells us how many outgoing edges there are for each target node, which directly translates to how many higher-order edges we need to create for each incoming edge.     </p> In\u00a0[8]: Copied! <pre># For each center node, we need to combine each outgoing edge with each incoming edge\n# We achieve this by creating `outdegree` number of edges for each destination node \n# of the old edge index\noutdegree_per_dst = outdegree[graph.data.edge_index[1]]\nprint(\"\\nOutdegree per destination node of each edge:\")\nfor e, outdeg in zip(graph.edges, outdegree_per_dst.tolist()):\n    print(f\"\\t{e}: {outdeg}\")\n</pre> # For each center node, we need to combine each outgoing edge with each incoming edge # We achieve this by creating `outdegree` number of edges for each destination node  # of the old edge index outdegree_per_dst = outdegree[graph.data.edge_index[1]] print(\"\\nOutdegree per destination node of each edge:\") for e, outdeg in zip(graph.edges, outdegree_per_dst.tolist()):     print(f\"\\t{e}: {outdeg}\") <pre>\nOutdegree per destination node of each edge:\n\t('a', 'c'): 2\n\t('b', 'c'): 2\n\t('c', 'd'): 1\n\t('c', 'e'): 1\n\t('d', 'f'): 1\n\t('e', 'f'): 1\n\t('f', 'a'): 1\n</pre> <ol> <li>Next, we create the source nodes for the higher-order graph. For this, we create a new index that maps the original edges to its index as a higher-order node. This is done by creating a range from 0 to the number of edges in the original graph. We then repeat each index according to the outdegree of the corresponding target node. This way, we create a source node for each combination of incoming and outgoing edges for each target node, which will be the edges in the higher-order graph.</li> </ol> In\u00a0[9]: Copied! <pre># Use each edge from the edge index as node and assign the new indices in the order of the original edge index\n# Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n# Since we keep the ordering, we can just repeat each node using the `outdegree_per_dst` tensor\nho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\nprint(\"\\nHigher-order edge source indices:\\n\", ho_edge_srcs.tolist())\nprint(\"Higher-order edge sources:\\n\", graph.mapping.to_ids(graph.data.edge_index[:, ho_edge_srcs]).T)\n</pre> # Use each edge from the edge index as node and assign the new indices in the order of the original edge index # Each higher order node has one outgoing edge for each outgoing edge of the original destination node # Since we keep the ordering, we can just repeat each node using the `outdegree_per_dst` tensor ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst) print(\"\\nHigher-order edge source indices:\\n\", ho_edge_srcs.tolist()) print(\"Higher-order edge sources:\\n\", graph.mapping.to_ids(graph.data.edge_index[:, ho_edge_srcs]).T) <pre>\nHigher-order edge source indices:\n [0, 0, 1, 1, 2, 3, 4, 5, 6]\nHigher-order edge sources:\n [['a' 'c']\n ['a' 'c']\n ['b' 'c']\n ['b' 'c']\n ['c' 'd']\n ['c' 'e']\n ['d' 'f']\n ['e' 'f']\n ['f' 'a']]\n</pre> <ol> <li>Now, we need to create the target nodes for the higher-order edges. For this, we first need to know where the edges of each node start in the original edge index. We can compute this by calculating the cumulative sum of the outdegree values of all nodes. This gives us a tensor where each entry corresponds to the starting index of the edges for each node in the original edge index.</li> </ol> <p>Cumulative Sum</p> <p>         There is one <code>cumsum</code> implementation in PyTorch and one in PyTorch Geometric. The one in PyTorch Geometric starts with an initial zero value, while the one in PyTorch does not. This means that the <code>torch.cumsum</code> function will give us the end pointers of the edges for each node, while the <code>torch_geometric.utils.cumsum</code> function will give us the start pointers (including a last pointer that is equal to the total number of edges). Therefore, we use the <code>torch_geometric.utils.cumsum</code> function here and remove the last entry afterwards.     </p> In\u00a0[10]: Copied! <pre># For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges\n# (new higher-order nodes) that have the node as source node\nptrs = cumsum(outdegree, dim=0)[:-1]\nprint(\"Edge start pointers per node:\\n\", ptrs.tolist())\n</pre> # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges # (new higher-order nodes) that have the node as source node ptrs = cumsum(outdegree, dim=0)[:-1] print(\"Edge start pointers per node:\\n\", ptrs.tolist()) <pre>Edge start pointers per node:\n [0, 1, 2, 4, 5, 6]\n</pre> <ol> <li>With the starting pointers of the edges for each node, we can start with the creation of the target nodes for the higher-order edges. Remember that we assigned the node indices based on the order of edges in the original edge index and ordered the higher-order source nodes accordingly. Therefore, we are essentially going through each edge, and combine it with each outgoing edge of the edges target node to create the higher-order edges. Since the edges are ordered by source nodes, we are going through all nodes in the original graph in order by going through each outgoing edge of each node. This means that for each edge in the original graph, we can look up where the outgoing edges of its target node start in the original edge index using the <code>ptrs</code> tensor we created in the previous step. We then repeat these starting pointers according to the outdegree of the corresponding target node to create a target node for each combination of incoming and outgoing edges for each target node.</li> </ol> In\u00a0[11]: Copied! <pre># Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times\n# Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively\nho_edge_dsts = torch.repeat_interleave(ptrs[graph.data.edge_index[1]], outdegree_per_dst)\nprint(\"Higher-order edge destination indices (before correction):\\n\", ho_edge_dsts.tolist())\n</pre> # Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times # Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively ho_edge_dsts = torch.repeat_interleave(ptrs[graph.data.edge_index[1]], outdegree_per_dst) print(\"Higher-order edge destination indices (before correction):\\n\", ho_edge_dsts.tolist()) <pre>Higher-order edge destination indices (before correction):\n [2, 2, 2, 2, 4, 5, 6, 6, 0]\n</pre> <ol> <li>For now, we do not have the correct indices for the higher-order target nodes yet. Since we only repeated the starting pointers of the edges for each target node, we only have the correct offsets for each group of higher-order edges corresponding to each target node. However, within each group, we need to assign the correct indices to the higher-order target nodes. Luckily, we only need to count up from the starting pointer for each group corresponding to one incoming edge in the original graph due to the ordering of the edges. For this, we create a correction index that counts up from 0 to the total number of higher-order edges.</li> </ol> In\u00a0[12]: Copied! <pre># Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...)\n# for all `outdegree` number of edges consecutively to get the correct destination nodes\n# We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\nidx_correction = torch.arange(ho_edge_srcs.size(0), dtype=torch.long)\nprint(\"Index correction (before adjustment):\\n\", idx_correction.tolist())\n</pre> # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) # for all `outdegree` number of edges consecutively to get the correct destination nodes # We can achieve this by starting with a range from (0, 1, ..., num_new_edges) idx_correction = torch.arange(ho_edge_srcs.size(0), dtype=torch.long) print(\"Index correction (before adjustment):\\n\", idx_correction.tolist()) <pre>Index correction (before adjustment):\n [0, 1, 2, 3, 4, 5, 6, 7, 8]\n</pre> <ol> <li>We then subtract the cumulative sum of the outdegree values of the higher-order source nodes from this correction index. This effectively resets the counting for each group of higher-order edges corresponding to each target node.</li> </ol> In\u00a0[13]: Copied! <pre># Then, we subtract the cumulative sum of the outdegree for each destination node\nidx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\nprint(\"Index correction (after adjustment):\\n\", idx_correction.tolist())\n</pre> # Then, we subtract the cumulative sum of the outdegree for each destination node idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs] print(\"Index correction (after adjustment):\\n\", idx_correction.tolist()) <pre>Index correction (after adjustment):\n [0, 1, 0, 1, 0, 0, 0, 0, 0]\n</pre> <ol> <li>Finally, we add this correction index to the starting pointers of the edges for each target node to get the correct indices for the higher-order target nodes.</li> </ol> In\u00a0[14]: Copied! <pre># Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge        \nho_edge_dsts += idx_correction\nprint(\"Higher-order edge destination indices (after correction):\\n\", ho_edge_dsts.tolist())\nprint(\"Higher-order edge destinations:\\n\", graph.mapping.to_ids(graph.data.edge_index[:, ho_edge_dsts]).T)\n</pre> # Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge         ho_edge_dsts += idx_correction print(\"Higher-order edge destination indices (after correction):\\n\", ho_edge_dsts.tolist()) print(\"Higher-order edge destinations:\\n\", graph.mapping.to_ids(graph.data.edge_index[:, ho_edge_dsts]).T) <pre>Higher-order edge destination indices (after correction):\n [2, 3, 2, 3, 4, 5, 6, 6, 0]\nHigher-order edge destinations:\n [['c' 'd']\n ['c' 'e']\n ['c' 'd']\n ['c' 'e']\n ['d' 'f']\n ['e' 'f']\n ['f' 'a']\n ['f' 'a']\n ['a' 'c']]\n</pre> <p>This gives us the final higher-order edge index that we can return from the function.</p> In\u00a0[15]: Copied! <pre>tedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\npp.plot(t, node_label=t.nodes)\n</pre> tedges = [     (\"a\", \"b\", 1),     (\"a\", \"b\", 2),     (\"b\", \"a\", 3),     (\"b\", \"c\", 3),     (\"d\", \"c\", 4),     (\"a\", \"b\", 4),     (\"c\", \"b\", 4),     (\"c\", \"d\", 5),     (\"b\", \"a\", 5),     (\"c\", \"b\", 6), ] t = pp.TemporalGraph.from_edge_list(tedges) pp.plot(t, node_label=t.nodes) Out[15]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7fd5d0e98160&gt;</pre> <p>We can create a second-order graph from this temporal graph using the <code>lift_order_temporal</code> function. This second-order graph is typically referred to as an event graph. Each node in the graph is an event (edge) in the original temporal graph and two events are connected if they can follow each other in time respecting a maximum time difference <code>delta</code>. Here, we set <code>delta=2</code> which means that two events can be connected if the time difference between them is at most 2 time units.</p> In\u00a0[16]: Copied! <pre>event_edge_index = pp.algorithms.temporal.lift_order_temporal(t, delta=2)\nevent_mapping = pp.IndexMap(t.temporal_edges)\nevent_data = Data(edge_index=event_edge_index, node_sequence=graph.data.edge_index.t())\nevent_graph = pp.Graph(data=event_data, mapping=event_mapping)\npp.plot(event_graph, node_label=event_graph.nodes)\n</pre> event_edge_index = pp.algorithms.temporal.lift_order_temporal(t, delta=2) event_mapping = pp.IndexMap(t.temporal_edges) event_data = Data(edge_index=event_edge_index, node_sequence=graph.data.edge_index.t()) event_graph = pp.Graph(data=event_data, mapping=event_mapping) pp.plot(event_graph, node_label=event_graph.nodes) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 3495.74it/s]\n</pre> Out[16]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee3eb0&gt;</pre> <p>Starting with the event graph, we have a static higher-order representation of the temporal graph that we can use to create higher-order models. For each following lift-order transformations, we can use the same principles as described in the previous section on order-lifting and line graph transformations.</p> In\u00a0[17]: Copied! <pre>def filter_time_respecting_edges(event_edge_index: torch.Tensor, timestamps: torch.Tensor, delta: int) -&gt; torch.Tensor:\n    # Subtract timestamps of the two events to get the time difference\n    time_diff = timestamps[event_edge_index[1]] - timestamps[event_edge_index[0]]\n    # Create masks for filtering\n    # Remove non-time-respecting higher-order edges\n    non_negative_mask = time_diff &gt; 0\n    # Remove edges that are too far apart in time based on delta\n    delta_mask = time_diff &lt;= delta\n    # Combine masks to get the final time-respecting edges\n    time_respecting_mask = non_negative_mask &amp; delta_mask\n    # Filter the event_edge_index using the time_respecting_mask\n    return event_edge_index[:, time_respecting_mask]\n</pre> def filter_time_respecting_edges(event_edge_index: torch.Tensor, timestamps: torch.Tensor, delta: int) -&gt; torch.Tensor:     # Subtract timestamps of the two events to get the time difference     time_diff = timestamps[event_edge_index[1]] - timestamps[event_edge_index[0]]     # Create masks for filtering     # Remove non-time-respecting higher-order edges     non_negative_mask = time_diff &gt; 0     # Remove edges that are too far apart in time based on delta     delta_mask = time_diff &lt;= delta     # Combine masks to get the final time-respecting edges     time_respecting_mask = non_negative_mask &amp; delta_mask     # Filter the event_edge_index using the time_respecting_mask     return event_edge_index[:, time_respecting_mask] <p>We can combine the above filter function with the <code>lift_order_edge_index</code> function to create a lift-order function for temporal graphs as follows:</p> <p>Warning</p> <p>     If we use the standard <code>lift_order_edge_index</code> function, we need to ensure that the input edge index is sorted by source nodes because the <code>edge_index</code> of a <code>TemporalGraph</code> is sorted by time and not by source nodes.     </p> In\u00a0[18]: Copied! <pre># Sort by source node indices\nsorted_edge_index, time = sort_edge_index(t.data.edge_index.as_tensor(), t.data.time)\n# Lift the edge index to the second order\nsecond_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=sorted_edge_index, num_nodes=t.n)\n# Filter the edges based on the lifted edge index\nfiltered_edge_index = filter_time_respecting_edges(second_order_edge_index, timestamps=time, delta=2)\n# Create `pp.Graph` from the filtered edge index\nfiltered_event_mapping = pp.IndexMap([tuple([*t.mapping.to_ids(edge).tolist(), timestamp.item()]) for edge, timestamp in zip(sorted_edge_index.t(), time)])\nfiltered_event_data = Data(edge_index=filtered_edge_index, node_sequence=sorted_edge_index.t())\nfiltered_event_graph = pp.Graph(data=filtered_event_data, mapping=filtered_event_mapping)\npp.plot(filtered_event_graph, node_label=filtered_event_graph.nodes)\n</pre> # Sort by source node indices sorted_edge_index, time = sort_edge_index(t.data.edge_index.as_tensor(), t.data.time) # Lift the edge index to the second order second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=sorted_edge_index, num_nodes=t.n) # Filter the edges based on the lifted edge index filtered_edge_index = filter_time_respecting_edges(second_order_edge_index, timestamps=time, delta=2) # Create `pp.Graph` from the filtered edge index filtered_event_mapping = pp.IndexMap([tuple([*t.mapping.to_ids(edge).tolist(), timestamp.item()]) for edge, timestamp in zip(sorted_edge_index.t(), time)]) filtered_event_data = Data(edge_index=filtered_edge_index, node_sequence=sorted_edge_index.t()) filtered_event_graph = pp.Graph(data=filtered_event_data, mapping=filtered_event_mapping) pp.plot(filtered_event_graph, node_label=filtered_event_graph.nodes) Out[18]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee0400&gt;</pre> <p>Note</p> <p>         The indexing of the above implementation is different from the one currently implemented in PathpyG. So while the illustrations look identical, the actual indices of the higher-order nodes will differ.     </p> <p>However, the above implementation has a large memory consumption for graphs with many edges because the full higher-order edge index is created before filtering. Therefore, we implement a more memory-efficient version in PathpyG that constructs the higher-order edges from the temporal graph sequentially for each timestamp. This implementation looks as follows:</p> In\u00a0[19]: Copied! <pre>def lift_order_temporal(g: pp.TemporalGraph, delta: int = 1):\n    indices = torch.arange(0, g.data.edge_index.size(1))\n\n    unique_t = torch.unique(g.data.time)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for t in unique_t:\n\n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = g.data.time == t\n        src_edge_idx = indices[src_time_mask]\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (g.data.time &gt; t) &amp; (g.data.time &lt;= t + delta)\n        dst_edge_idx = indices[dst_time_mask]\n\n        if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n            # compute second-order edges between src and dst idx\n            # create all possible combinations of src and dst edges\n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx)\n            # filter combinations for real higher-order edges\n            # for all edges where dst in src_edges (g.data.edge_index[1, x[:, 0]]) matches src in dst_edges (g.data.edge_index[0, x[:, 1]])\n            ho_edge_index = x[g.data.edge_index[1, x[:, 0]] == g.data.edge_index[0, x[:, 1]]]\n            second_order.append(ho_edge_index)\n\n    ho_index = torch.cat(second_order, dim=0).t().contiguous()\n    return ho_index\n</pre> def lift_order_temporal(g: pp.TemporalGraph, delta: int = 1):     indices = torch.arange(0, g.data.edge_index.size(1))      unique_t = torch.unique(g.data.time)     second_order = []      # lift order: find possible continuations for edges in each time stamp     for t in unique_t:          # find indices of all source edges that occur at unique timestamp t         src_time_mask = g.data.time == t         src_edge_idx = indices[src_time_mask]          # find indices of all edges that can possibly continue edges occurring at time t for the given delta         dst_time_mask = (g.data.time &gt; t) &amp; (g.data.time &lt;= t + delta)         dst_edge_idx = indices[dst_time_mask]          if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:             # compute second-order edges between src and dst idx             # create all possible combinations of src and dst edges             x = torch.cartesian_prod(src_edge_idx, dst_edge_idx)             # filter combinations for real higher-order edges             # for all edges where dst in src_edges (g.data.edge_index[1, x[:, 0]]) matches src in dst_edges (g.data.edge_index[0, x[:, 1]])             ho_edge_index = x[g.data.edge_index[1, x[:, 0]] == g.data.edge_index[0, x[:, 1]]]             second_order.append(ho_edge_index)      ho_index = torch.cat(second_order, dim=0).t().contiguous()     return ho_index <p>Note that above we do not use the same indexing trick that is used in the standard <code>lift_order_edge_index</code> function. Instead, we create all possible combinations of incoming and outgoing edges for all incoming edges at each timestamp. Therefore, we need a filtering step afterwards to ensure that only valid higher-order edges are created. However, we can skip the sorting step beforehand because we create all possible edge combinations using the cartesian product.</p> <p>It is also possible to combine both approaches, i.e., we create the higher-order edges for each timestamp separately using the indexing trick from the standard <code>lift_order_edge_index</code> function. While it saves the filtering step, it again requires sorting the edges beforehand which has been shown to be similar in performance to the above method. The code would look as follows:</p> In\u00a0[20]: Copied! <pre>def lift_order_temporal_combined(g: pp.TemporalGraph, delta: int = 1):\n    indices = torch.arange(0, g.data.edge_index.size(1))\n\n    unique_t = torch.unique(g.data.time)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for i in range(unique_t.size(0)):\n        t = unique_t[i]\n\n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = g.data.time == t\n        src_edge_idx = indices[src_time_mask]\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (g.data.time &gt; t) &amp; (g.data.time &lt;= t + delta)\n        dst_node_mask = torch.isin(g.data.edge_index[0], g.data.edge_index[1, src_edge_idx])\n        dst_edge_idx = indices[dst_time_mask &amp; dst_node_mask]\n\n        if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n            # get sorted dst edges for efficient processing\n            src_edges = g.data.edge_index[:, src_edge_idx]\n            dst_edges = g.data.edge_index[:, dst_edge_idx]\n            sorted_idx = torch.argsort(dst_edges[0])\n            dst_edge_idx = dst_edge_idx[sorted_idx]\n            dst_edges = dst_edges[:, sorted_idx]\n\n            # Use indexing trick to create higher-order edges\n            outdegree = degree(dst_edges[0], dtype=torch.long, num_nodes=g.n)\n            outdegree_per_dst = outdegree[src_edges[1]]\n            num_new_edges = outdegree_per_dst.sum()\n            ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n            ptrs = cumsum(outdegree, dim=0)[:-1]\n            ho_edge_dsts = torch.repeat_interleave(ptrs[src_edges[1]], outdegree_per_dst)\n            idx_correction = torch.arange(num_new_edges, dtype=torch.long)\n            idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n            ho_edge_dsts += idx_correction\n            second_order.append(torch.stack([src_edge_idx[ho_edge_srcs], dst_edge_idx[ho_edge_dsts]], dim=0))\n\n    ho_index = torch.cat(second_order, dim=1)\n    return ho_index\n</pre> def lift_order_temporal_combined(g: pp.TemporalGraph, delta: int = 1):     indices = torch.arange(0, g.data.edge_index.size(1))      unique_t = torch.unique(g.data.time)     second_order = []      # lift order: find possible continuations for edges in each time stamp     for i in range(unique_t.size(0)):         t = unique_t[i]          # find indices of all source edges that occur at unique timestamp t         src_time_mask = g.data.time == t         src_edge_idx = indices[src_time_mask]          # find indices of all edges that can possibly continue edges occurring at time t for the given delta         dst_time_mask = (g.data.time &gt; t) &amp; (g.data.time &lt;= t + delta)         dst_node_mask = torch.isin(g.data.edge_index[0], g.data.edge_index[1, src_edge_idx])         dst_edge_idx = indices[dst_time_mask &amp; dst_node_mask]          if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:             # get sorted dst edges for efficient processing             src_edges = g.data.edge_index[:, src_edge_idx]             dst_edges = g.data.edge_index[:, dst_edge_idx]             sorted_idx = torch.argsort(dst_edges[0])             dst_edge_idx = dst_edge_idx[sorted_idx]             dst_edges = dst_edges[:, sorted_idx]              # Use indexing trick to create higher-order edges             outdegree = degree(dst_edges[0], dtype=torch.long, num_nodes=g.n)             outdegree_per_dst = outdegree[src_edges[1]]             num_new_edges = outdegree_per_dst.sum()             ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)             ptrs = cumsum(outdegree, dim=0)[:-1]             ho_edge_dsts = torch.repeat_interleave(ptrs[src_edges[1]], outdegree_per_dst)             idx_correction = torch.arange(num_new_edges, dtype=torch.long)             idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]             ho_edge_dsts += idx_correction             second_order.append(torch.stack([src_edge_idx[ho_edge_srcs], dst_edge_idx[ho_edge_dsts]], dim=0))      ho_index = torch.cat(second_order, dim=1)     return ho_index <p>In contrast to the <code>lift_order_edge_index</code> implementation, the temporal version splits the edges into source and destination edges based on timestamps. For each timestamp, we select the edges that occur at that timestamp as source edges and all edges that occur at later timestamps (within the delta time window) as destination edges. Then, instead of repeating the higher-order source nodes for all edges, we only repeat them for the destination edges.</p> In\u00a0[21]: Copied! <pre>path_mapping = pp.IndexMap(list(\"abcde\"))\npaths = pp.PathData(mapping=path_mapping)\npaths.append_walk(list(\"ab\"))\npaths.append_walk(list(\"abd\"))\npaths.append_walk(list(\"abec\"))\npaths.append_walk(list(\"dbecb\"))\npp.plot(\n    pp.Graph.from_edge_index(paths.data.edge_index), node_label=paths.mapping.to_ids(paths.data.node_sequence).tolist()\n)\n</pre> path_mapping = pp.IndexMap(list(\"abcde\")) paths = pp.PathData(mapping=path_mapping) paths.append_walk(list(\"ab\")) paths.append_walk(list(\"abd\")) paths.append_walk(list(\"abec\")) paths.append_walk(list(\"dbecb\")) pp.plot(     pp.Graph.from_edge_index(paths.data.edge_index), node_label=paths.mapping.to_ids(paths.data.node_sequence).tolist() ) Out[21]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee34c0&gt;</pre> <p><code>pp.PathData</code> is the core class for working with paths in PathpyG. It allows us to gather a collection of paths that are all walks on the same underlying graph. All paths are stored using one <code>edge_index</code> internally. Thus, two nodes in a path that both correspond to the same node in the underlying graph will not share the same index in the path graph. Instead, each occurrence of a node in a path is represented by a separate node in the path graph. This allows us to represent paths that visit the same node multiple times without ambiguity. The information about the underlying graph is stored in the internal <code>PathData.data.node_sequence</code> tensor, similar to higher-order graphs. Let us look at the example above to illustrate this:</p> In\u00a0[22]: Copied! <pre>print(\"The paths represented using edge index look as follows:\")\nfor edge in paths.data.edge_index.t():\n    print(\n        f\"\\tInternal {edge.tolist()}: Underlying graph edge {paths.mapping.to_ids(paths.data.node_sequence[edge].view(-1)).tolist()}\"\n    )\n</pre> print(\"The paths represented using edge index look as follows:\") for edge in paths.data.edge_index.t():     print(         f\"\\tInternal {edge.tolist()}: Underlying graph edge {paths.mapping.to_ids(paths.data.node_sequence[edge].view(-1)).tolist()}\"     ) <pre>The paths represented using edge index look as follows:\n\tInternal [0, 1]: Underlying graph edge ['a', 'b']\n\tInternal [2, 3]: Underlying graph edge ['a', 'b']\n\tInternal [3, 4]: Underlying graph edge ['b', 'd']\n\tInternal [5, 6]: Underlying graph edge ['a', 'b']\n\tInternal [6, 7]: Underlying graph edge ['b', 'e']\n\tInternal [7, 8]: Underlying graph edge ['e', 'c']\n\tInternal [9, 10]: Underlying graph edge ['d', 'b']\n\tInternal [10, 11]: Underlying graph edge ['b', 'e']\n\tInternal [11, 12]: Underlying graph edge ['e', 'c']\n\tInternal [12, 13]: Underlying graph edge ['c', 'b']\n</pre> <p><code>PathData</code> additionally stores some metadata about the paths so that you can easily access information about which nodes belong to which path. This includes</p> <ul> <li><code>dag_weight</code>: A tensor that stores the weight of each path (i.e., the number of times the path was observed).</li> <li><code>dag_num_edges</code>: A tensor that stores the number of edges in each path.</li> <li><code>dag_num_nodes</code>: A tensor that stores the number of nodes in each path.</li> </ul> <p>Using this information, you can, e.g., access the second path in the collection as follows:</p> In\u00a0[23]: Copied! <pre>start = paths.data.dag_num_nodes[:1].sum().item()\nend = start + paths.data.dag_num_nodes[1].item()\npaths.mapping.to_ids(paths.data.node_sequence[start:end].view(-1)).tolist()\n</pre> start = paths.data.dag_num_nodes[:1].sum().item() end = start + paths.data.dag_num_nodes[1].item() paths.mapping.to_ids(paths.data.node_sequence[start:end].view(-1)).tolist() Out[23]: <pre>['a', 'b', 'd']</pre> <p>Lastly, since we are using an <code>edge_index</code> internally, the <code>lift_order_edge_index</code> function works out-of-the-box for paths. A second-order representation of the paths can be created as follows:</p> In\u00a0[24]: Copied! <pre>second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(\n    edge_index=paths.data.edge_index, num_nodes=paths.data.num_nodes\n)\nsecond_order_paths = pp.Graph.from_edge_index(edge_index=second_order_edge_index)\npp.plot(\n    second_order_paths,\n    node_label=paths.mapping.to_ids(paths.data.node_sequence[paths.data.edge_index.t()].squeeze()).tolist(),\n)\n</pre> second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(     edge_index=paths.data.edge_index, num_nodes=paths.data.num_nodes ) second_order_paths = pp.Graph.from_edge_index(edge_index=second_order_edge_index) pp.plot(     second_order_paths,     node_label=paths.mapping.to_ids(paths.data.node_sequence[paths.data.edge_index.t()].squeeze()).tolist(), ) Out[24]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40ee8ff10&gt;</pre> <p>With the concepts above, we can now create multi-order models using the <code>MultiOrderModel</code> class. This class allows us to create higher-order models of arbitrary order from a given base temporal graph or paths. Let's look at an example of creating a multi-order model from a temporal graph:</p> In\u00a0[25]: Copied! <pre>m_t = pp.MultiOrderModel.from_temporal_graph(t, max_order=2)\npp.plot(m_t.layers[2], node_label=m_t.layers[2].nodes)\n</pre> m_t = pp.MultiOrderModel.from_temporal_graph(t, max_order=2) pp.plot(m_t.layers[2], node_label=m_t.layers[2].nodes) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 2312.82it/s]\n</pre> Out[25]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee32b0&gt;</pre> <p>We can see that the second-order graph created by the <code>MultiOrderModel</code> is different from the one created by the <code>lift_order_temporal</code> function directly. This is because the <code>MultiOrderModel</code> higher-order DeBruijn graph representation. This representation merges higher-order nodes that correspond to the same path in the original graph. This means that temporal edges that appear in the event graph as different nodes will be merged into one node in the DeBruijn graph if they correspond to the same path in the original graph. This results in a more compact representation of the higher-order graph.</p> <p>The same is true for paths. We can create a multi-order model from a collection of paths as follows:</p> In\u00a0[26]: Copied! <pre>m_p = pp.MultiOrderModel.from_path_data(paths, max_order=2)\npp.plot(m_p.layers[2], node_label=m_p.layers[2].nodes)\n</pre> m_p = pp.MultiOrderModel.from_path_data(paths, max_order=2) pp.plot(m_p.layers[2], node_label=m_p.layers[2].nodes) Out[26]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee2860&gt;</pre> <p>We can see that the higher-order node <code>a-&gt;b</code> which appeared thrice in the second-order graph created by the <code>lift_order_edge_index</code> function is now merged into one node in the DeBruijn graph representation.</p> In\u00a0[27]: Copied! <pre># We create the third-order representation of the paths\nthird_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(\n    edge_index=second_order_paths.data.edge_index, num_nodes=second_order_paths.n\n)\n</pre> # We create the third-order representation of the paths third_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(     edge_index=second_order_paths.data.edge_index, num_nodes=second_order_paths.n ) <ol> <li>Update Node Sequences: Next, we need to update the internal <code>node_sequence</code> tensor to reflect the new higher-order nodes. For this, we create a new <code>node_sequence</code> by concatenating the last node of the target node sequence to the source node sequence. This way, we create a new sequence that corresponds to the paths represented by the next order nodes.</li> </ol> In\u00a0[28]: Copied! <pre>second_order_node_sequence = paths.data.node_sequence[paths.data.edge_index.t()].squeeze()\nthird_order_node_sequence = torch.cat([\n    second_order_node_sequence[second_order_paths.data.edge_index[0]],\n    second_order_node_sequence[second_order_paths.data.edge_index[1]][:, -1:]\n], dim=1)\n</pre> second_order_node_sequence = paths.data.node_sequence[paths.data.edge_index.t()].squeeze() third_order_node_sequence = torch.cat([     second_order_node_sequence[second_order_paths.data.edge_index[0]],     second_order_node_sequence[second_order_paths.data.edge_index[1]][:, -1:] ], dim=1) <ol> <li>Merge Higher-Order Nodes: Finally, we need to merge the higher-order nodes that correspond to the same path in the original graph. For this, we create a unique mapping from the new <code>node_sequence</code> to unique indices. We can then use this mapping to update the higher-order edge index to reflect the merged nodes and then aggregate duplicate edges.</li> </ol> In\u00a0[29]: Copied! <pre>third_order_paths = pp.algorithms.lift_order.aggregate_edge_index(\n    edge_index=third_order_edge_index, node_sequence=third_order_node_sequence\n)\n</pre> third_order_paths = pp.algorithms.lift_order.aggregate_edge_index(     edge_index=third_order_edge_index, node_sequence=third_order_node_sequence ) <p>After performing these steps, we can again visualize the resulting higher-order graph:</p> In\u00a0[30]: Copied! <pre>third_order_paths.mapping = pp.IndexMap([tuple(mapping.to_ids(v).tolist()) for v in third_order_paths.data.node_sequence])\npp.plot(third_order_paths, node_label=third_order_paths.nodes)\n</pre> third_order_paths.mapping = pp.IndexMap([tuple(mapping.to_ids(v).tolist()) for v in third_order_paths.data.node_sequence]) pp.plot(third_order_paths, node_label=third_order_paths.nodes) Out[30]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40ed71e70&gt;</pre> <p>These steps can be repeated for each order until we reach the desired maximum order for the <code>MultiOrderModel</code>.</p> In\u00a0[31]: Copied! <pre>def get_all_paths_DAG(g: pp.Graph) -&gt; dict:\n    \"\"\"Calculate all existing paths from any root node to any leaf node in a directed acyclic graph (DAG).\"\"\"\n    paths_of_length = {}\n    edge_index = g.data.edge_index.as_tensor()\n\n    # calculate degrees\n    out_degree = degree(edge_index[0], num_nodes=g.n, dtype=torch.long)\n    in_degree = degree(edge_index[1], num_nodes=g.n, dtype=torch.long)\n\n    # identify root nodes with in-degree zero\n    roots = torch.where(in_degree == 0)[0]\n    leafs = out_degree == 0\n\n    # create path tensor that contains all paths that are not yet at a leaf node\n    paths = roots.unsqueeze(1)\n    # remove all paths that are already at a leaf node\n    paths_of_length[1] = paths[leafs[roots]].cpu().tolist()\n    # continue all paths that are not at a leaf node\n    paths = paths[~leafs[roots]]\n    # remember nodes that haven't been traversed yet\n    nodes = roots[~leafs[roots]]\n\n    ptrs = cumsum(out_degree, dim=0)\n\n    # count all longest paths in DAG\n    step = 1\n    while nodes.size(0) &gt; 0 or step &gt; g.n:\n        idx_repeat = torch.repeat_interleave(out_degree[nodes])\n        next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])\n        idx_correction = (\n            torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]\n        )\n        next_idx += idx_correction\n        next_nodes = edge_index[1][next_idx]\n        paths = torch.cat([paths[idx_repeat], next_nodes.unsqueeze(1)], dim=1)\n        paths_of_length[step] = paths[leafs[next_nodes]].tolist()\n        paths = paths[~leafs[next_nodes]]\n        nodes = next_nodes[~leafs[next_nodes]]\n        step += 1\n\n    return paths_of_length\n</pre> def get_all_paths_DAG(g: pp.Graph) -&gt; dict:     \"\"\"Calculate all existing paths from any root node to any leaf node in a directed acyclic graph (DAG).\"\"\"     paths_of_length = {}     edge_index = g.data.edge_index.as_tensor()      # calculate degrees     out_degree = degree(edge_index[0], num_nodes=g.n, dtype=torch.long)     in_degree = degree(edge_index[1], num_nodes=g.n, dtype=torch.long)      # identify root nodes with in-degree zero     roots = torch.where(in_degree == 0)[0]     leafs = out_degree == 0      # create path tensor that contains all paths that are not yet at a leaf node     paths = roots.unsqueeze(1)     # remove all paths that are already at a leaf node     paths_of_length[1] = paths[leafs[roots]].cpu().tolist()     # continue all paths that are not at a leaf node     paths = paths[~leafs[roots]]     # remember nodes that haven't been traversed yet     nodes = roots[~leafs[roots]]      ptrs = cumsum(out_degree, dim=0)      # count all longest paths in DAG     step = 1     while nodes.size(0) &gt; 0 or step &gt; g.n:         idx_repeat = torch.repeat_interleave(out_degree[nodes])         next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])         idx_correction = (             torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]         )         next_idx += idx_correction         next_nodes = edge_index[1][next_idx]         paths = torch.cat([paths[idx_repeat], next_nodes.unsqueeze(1)], dim=1)         paths_of_length[step] = paths[leafs[next_nodes]].tolist()         paths = paths[~leafs[next_nodes]]         nodes = next_nodes[~leafs[next_nodes]]         step += 1      return paths_of_length <p>The function above starts at all root nodes (nodes with no incoming edges) and iteratively traverses all possible next nodes while keeping track of all current paths. Whenever a path reaches a leaf node (a node with no outgoing edges), it is added to the list of longest paths and removed from the current paths. This continues until all paths have reached a leaf node.</p> <p>Tip</p> <p>     Getting the next nodes for all current paths is done using a similar indexing trick as in the <code>lift_order_edge_index</code> function. This allows us to efficiently get all next nodes for all current paths in one go using tensor operations.     </p>"},{"location":"tutorial/implementation_concepts/#general-concepts-of-the-tensor-based-implementations","title":"General Concepts of the Tensor-based Implementations\u00b6","text":""},{"location":"tutorial/implementation_concepts/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/implementation_concepts/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>The inner workings of the core classes of PathpyG are based on tensor operations provided by PyTorch and PyTorch Geometric. Especially the creation of higher-order structures using the lift-order functions and the <code>MultiOderModel</code> heavily rely on tensor operations for efficiency reasons. While these implementations are highly optimized, they are very hard to read and understand for newcomers. This tutorial aims to explain the general concepts and ideas behind these implementations in a more accessible way. Additionally, we will provide step-by-step explanations of the core functions in the following sections.</p>"},{"location":"tutorial/implementation_concepts/#order-lifting-and-line-graph-transformations","title":"Order-lifting and Line Graph Transformations\u00b6","text":"<p>At the core of creating higher-order models is the <code>lift_order_edge_index</code> function that is essentially a line graph transformation. Given an edge index of a graph and the number of nodes in the graph, this function creates the edge index for the corresponding line graph. Let's look at an example:</p>"},{"location":"tutorial/implementation_concepts/#under-the-hood-of-lift_order_edge_index","title":"Under the Hood of <code>lift_order_edge_index</code>\u00b6","text":"<p>Let us now take a closer look at how the <code>lift_order_edge_index</code> function works under the hood. The whole function essentially only needs 10 lines of code and looks as follows:</p>"},{"location":"tutorial/implementation_concepts/#temporal-order-lifting","title":"Temporal Order Lifting\u00b6","text":"<p>One of the core functionalities of PathpyG is the ability to create temporal higher-order models. For this, an extension of the <code>lift_order_edge_index</code> function to temporal graphs is needed. We implement this in the <code>lift_order_temporal</code> function. This function works similarly to the <code>lift_order_edge_index</code> function, but with some additional steps to account for the temporal aspect of the graph. The main difference is that we need to ensure that the higher-order edges respect the temporal ordering of the original edges. Let us take a look at an example:</p>"},{"location":"tutorial/implementation_concepts/#internals-of-the-lift_order_temporal-function","title":"Internals of the <code>lift_order_temporal</code> Function\u00b6","text":"<p>The simplest way to implement the <code>lift_order_temporal</code> function would be to first create the full higher-order edge index using the <code>lift_order_edge_index</code> function and then filter out the edges that do not respect the temporal ordering. The filter function could look as follows:</p>"},{"location":"tutorial/implementation_concepts/#paths-in-pathpyg","title":"Paths in PathpyG\u00b6","text":"<p>One other core functionality of PathpyG is the ability to work with paths. Paths are sequences of nodes that represent a walk through the graph. We show an example below:</p>"},{"location":"tutorial/implementation_concepts/#multi-order-models","title":"Multi-Order Models\u00b6","text":""},{"location":"tutorial/implementation_concepts/#internals-of-the-multiordermodel-class","title":"Internals of the <code>MultiOrderModel</code> Class\u00b6","text":"<p>Let us now take a closer look at how the <code>MultiOrderModel</code> class works under the hood. We already saw that the <code>MultiOrderModel</code> merges higher-order nodes from the line/event graph transformations.</p> <p>This is done in 3 distinct steps which we will go through using the paths example above:</p> <ol> <li>Order Lifting: First, we create the higher-order edge index using the appropriate lift-order function (<code>lift_order_edge_index</code> or <code>lift_order_temporal</code>) depending on whether we are working with paths or temporal graphs in the first order and <code>lift_order_edge_index</code> for the second order and beyond regardless of the input type.</li> </ol> <p>Note</p> <p>         While we merge the higher-order nodes and aggregate the higher-order edges for each order, we need to use the original higher-order edge index to create the next order. This is because the transitivity of paths is only preserved in the original higher-order edge index.     </p>"},{"location":"tutorial/implementation_concepts/#other-tensor-based-implementations","title":"Other Tensor-based Implementations\u00b6","text":"<p>The concepts from above can also be useful to implement other functionalities using tensor operations.</p>"},{"location":"tutorial/implementation_concepts/#longest-path-extraction","title":"Longest Path Extraction\u00b6","text":"<p>One example is the extraction of all longest paths from a directed acyclic graph (DAG). This can be done by iterating through all nodes in the DAG in topological order at the same time. We provide an example implementation below:</p>"},{"location":"tutorial/manim_tutorial/","title":"Temporal Graph Visualisation using Manim","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git <p>Note that using the <code>Manim</code>-backend in <code>PathpyG</code> requires the installation of <code>Manim</code>. It will not be automatically installed with <code>PathpyG</code> due to its additional dependencies. We recommend using the installation instructions in the <code>Manim</code> documentation or our provided DevContainer.</p> In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\n</pre> import pathpyG as pp <p>Next, we can create a temporal graph that we want to visualise:</p> In\u00a0[2]: Copied! <pre>t = pp.TemporalGraph.from_edge_list(\n    [\n        (\"a\", \"b\", 1),\n        (\"b\", \"c\", 5),\n        (\"c\", \"d\", 9),\n        (\"d\", \"a\", 9),\n        (\"a\", \"b\", 10),\n        (\"b\", \"c\", 10),\n        (\"a\", \"b\", 8),\n        (\"b\", \"c\", 13),\n        (\"c\", \"d\", 17),\n        (\"d\", \"a\", 19),\n        (\"a\", \"b\", 20),\n        (\"b\", \"c\", 18),\n    ]\n)\n</pre> t = pp.TemporalGraph.from_edge_list(     [         (\"a\", \"b\", 1),         (\"b\", \"c\", 5),         (\"c\", \"d\", 9),         (\"d\", \"a\", 9),         (\"a\", \"b\", 10),         (\"b\", \"c\", 10),         (\"a\", \"b\", 8),         (\"b\", \"c\", 13),         (\"c\", \"d\", 17),         (\"d\", \"a\", 19),         (\"a\", \"b\", 20),         (\"b\", \"c\", 18),     ] ) <p>The <code>plot</code> function using Manim as backend allows  to use a variety of customization options to visualize temporal graphs and outputs a video. Some examples are provided below, e.g. the <code>node_size</code> or the <code>edge_size</code>.</p> In\u00a0[3]: Copied! <pre>pp.plot(t, backend=\"manim\", node_size=0.3, edge_size=4, edge_color=[\"red\", \"blue\"], node_color=0.89, node_label=\"Node\")\n</pre> pp.plot(t, backend=\"manim\", node_size=0.3, edge_size=4, edge_color=[\"red\", \"blue\"], node_color=0.89, node_label=\"Node\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21/21 [00:29&lt;00:00,  1.39s/it]\n</pre>                      Your browser does not support the video tag.                  Out[3]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f3499c50950&gt;</pre> <p>The videos can be exported as <code>.mp4</code> or <code>.gif</code> if you provide a filename to the <code>plot</code> function.</p> In\u00a0[4]: Copied! <pre>pp.plot(\n    t,\n    backend=\"manim\",\n    node_size=0.3,\n    edge_size=4,\n    edge_color=[\"red\", \"blue\"],\n    node_color=0.89,\n    node_label=\"Node\",\n    filename=\"tutorial_plot.gif\",\n)\n</pre> pp.plot(     t,     backend=\"manim\",     node_size=0.3,     edge_size=4,     edge_color=[\"red\", \"blue\"],     node_color=0.89,     node_label=\"Node\",     filename=\"tutorial_plot.gif\", ) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21/21 [00:31&lt;00:00,  1.48s/it]\n</pre> Out[4]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f349995ccd0&gt;</pre> In\u00a0[5]: Copied! <pre>pp.plot(\n    t,\n    backend=\"manim\",\n    node_size=0.1,\n    edge_size=4,\n    edge_color={\"a-b-1.0\": \"purple\", \"b-c-10.0\": \"green\"},\n    node_color={\"a-1.0\": \"yellow\", \"a\": \"green\", \"b-3.0\": \"black\"},\n    node_label=t.mapping.node_ids.tolist(),\n    font_size=40,\n    dynamic_layout_interval=5,\n)\n</pre> pp.plot(     t,     backend=\"manim\",     node_size=0.1,     edge_size=4,     edge_color={\"a-b-1.0\": \"purple\", \"b-c-10.0\": \"green\"},     node_color={\"a-1.0\": \"yellow\", \"a\": \"green\", \"b-3.0\": \"black\"},     node_label=t.mapping.node_ids.tolist(),     font_size=40,     dynamic_layout_interval=5, ) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21/21 [00:28&lt;00:00,  1.36s/it]\n</pre>                      Your browser does not support the video tag.                  Out[5]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f3499a02250&gt;</pre> In\u00a0[6]: Copied! <pre>g = pp.io.read_netzschleuder_graph('sp_baboons', 'observational', time_attr='time')\n</pre> g = pp.io.read_netzschleuder_graph('sp_baboons', 'observational', time_attr='time') In\u00a0[7]: Copied! <pre>colors = []\nfor category in g.data['edge_category']:\n    match category:\n        case 'Affiliative': colors.append('red')\n        case 'Agonistic': colors.append('green')\n        case 'Other': colors.append('grey')\n</pre> colors = [] for category in g.data['edge_category']:     match category:         case 'Affiliative': colors.append('red')         case 'Agonistic': colors.append('green')         case 'Other': colors.append('grey') In\u00a0[\u00a0]: Copied! <pre>pp.plot(\n    g,\n    backend=\"manim\",\n    start=1560412200,\n    end=1560431041,\n    intervals=20,\n    dynamic_layout_interval=50,\n    edge_color=colors,\n    node_size=0.06,\n    edge_size=5,\n    node_label_size=20,\n)\n</pre> pp.plot(     g,     backend=\"manim\",     start=1560412200,     end=1560431041,     intervals=20,     dynamic_layout_interval=50,     edge_color=colors,     node_size=0.06,     edge_size=5,     node_label_size=20, ) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21/21 [00:38&lt;00:00,  1.83s/it]\n</pre>                      Your browser does not support the video tag.                  Out[\u00a0]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f3670144dd0&gt;</pre>"},{"location":"tutorial/manim_tutorial/#temporal-network-visualizations-with-manim","title":"Temporal Network Visualizations with Manim\u00b6","text":""},{"location":"tutorial/manim_tutorial/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/manim_tutorial/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>While you already learned how to visualise graphs with <code>PathpyG</code> in the interactive graph visualisation tutorial, those visualisations mostly considered static graphs. In this tutorial, you will learn how to use the <code>Manim</code> backend in <code>PathpyG</code> to generate videos (<code>.mp4</code>) or animations (<code>.gif</code>) of temporal graphs.</p>"},{"location":"tutorial/manim_tutorial/#lets-get-started","title":"Let's Get Started\u00b6","text":"<p>We need to import <code>PathpyG</code> first:</p>"},{"location":"tutorial/manim_tutorial/#dynamically-changing-customisations","title":"Dynamically Changing Customisations\u00b6","text":"<p>So far, we only used customisations that you were already familiar with from other plotting backends. Manim offers four additional customisations:</p> <ol> <li><p>Both node and edge colors can be specified for single time stamps with the <code>node_color</code> and <code>edge_color</code> keyword arguments.</p> <p>e.g. : <code>node_color = {'a-1.0': 'yellow', 'a': 'green', 'b-3.0':'black'}</code>, where the keys <code>node_id-time_stamp</code> specify the node and the time stamp and the values the colors. If no time stamp is specified the first time stamp of the temporal graph is used.</p> <p>e.g. : <code>edge_color = {'a-b-1.0':'purple', 'd-c-4.0':'green'}</code>, where the keys <code>node_id_1-node_id_2-time_stamp</code> specify the nodes and the time stamp and the values the colors</p> </li> <li><p>Additionally, the user can specify after how many time steps the layout is recalculated with the Fruchtermann Rheingold algorithm based on the edges that existed in the last interval with the <code>dynamic_layout_interval</code> keyword argument. Additionally the user can specify based on how many timesteps backwards and forwards the new layout is calculated with the keyword arguments <code>look_forward</code> and <code>look_behind</code></p> </li> <li><p>The background color can be changed with the <code>background_color</code> keyword argument</p> </li> <li><p>The font size of the node labels is adjustable with the <code>font_size</code> keyword argument.</p> </li> </ol> <p>The following shows an example where all of the customisations described above are used:</p>"},{"location":"tutorial/manim_tutorial/#real-world-example","title":"Real-World Example\u00b6","text":"<p>As a final example, we show how to visualise a real-world temporal graph with <code>Manim</code>. We use Netschleuder Online Repository (see our next tutorial our next tutorial Graph Learning in Netzschleuder Data for more information) to obtain a temporal interaction graph between baboons and color the types of interactions in different colors.</p>"},{"location":"tutorial/netzschleuder/","title":"Graph Learning in Netzschleuder Data","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[29]: Copied! <pre>from matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.decomposition import TruncatedSVD\n\nimport torch\nfrom torch.nn import ReLU, Sigmoid\n\nimport torch_geometric\nfrom torch_geometric.nn import Sequential, GCNConv\n\nimport pathpyG as pp\n</pre> from matplotlib import pyplot as plt  from sklearn import metrics from sklearn.decomposition import TruncatedSVD  import torch from torch.nn import ReLU, Sigmoid  import torch_geometric from torch_geometric.nn import Sequential, GCNConv  import pathpyG as pp In\u00a0[30]: Copied! <pre>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n</pre> device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') In\u00a0[31]: Copied! <pre>g = pp.io.read_netzschleuder_graph(name='polbooks')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_graph(name='polbooks') print(g) <pre>Undirected graph with 105 nodes and 441 edges\n{   'Edge Attributes': {},\n    'Graph Attributes': {   'analyses_average_degree': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_assortativity': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_std_dev': \"&lt;class 'float'&gt;\",\n                            'analyses_diameter': \"&lt;class 'int'&gt;\",\n                            'analyses_edge_properties': \"&lt;class 'list'&gt;\",\n                            'analyses_edge_reciprocity': \"&lt;class 'float'&gt;\",\n                            'analyses_global_clustering': \"&lt;class 'float'&gt;\",\n                            'analyses_hashimoto_radius': \"&lt;class 'float'&gt;\",\n                            'analyses_is_bipartite': \"&lt;class 'bool'&gt;\",\n                            'analyses_is_directed': \"&lt;class 'bool'&gt;\",\n                            'analyses_knn_proj_1': \"&lt;class 'float'&gt;\",\n                            'analyses_knn_proj_2': \"&lt;class 'float'&gt;\",\n                            'analyses_largest_component_fraction': \"&lt;class 'float'&gt;\",\n                            'analyses_mixing_time': \"&lt;class 'float'&gt;\",\n                            'analyses_num_edges': \"&lt;class 'int'&gt;\",\n                            'analyses_num_vertices': \"&lt;class 'int'&gt;\",\n                            'analyses_transition_gap': \"&lt;class 'float'&gt;\",\n                            'analyses_vertex_properties': \"&lt;class 'list'&gt;\",\n                            'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {'node__pos': \"&lt;class 'numpy.ndarray'&gt;\", 'node_label': \"&lt;class 'numpy.ndarray'&gt;\", 'node_value': \"&lt;class 'numpy.ndarray'&gt;\"}}\n</pre> <p>We can plot this temporal graph in an interactive way:</p> In\u00a0[33]: Copied! <pre>pp.plot(g, edge_color='lightgray', edge_size=5);\n</pre> pp.plot(g, edge_color='lightgray', edge_size=5); <p>To see how we can apply GNNs to attributed graphs, let us read the famous karate club network. The record <code>karate</code> actually contains two networks with labels <code>77</code> and <code>78</code>, which refer to two different versions of the data with different numbers of edges. If multiple graph data sets exist in the same record, we can specify the name of the network as second argument.</p> In\u00a0[34]: Copied! <pre>g = pp.io.read_netzschleuder_graph(name='karate', network='78').to(device)\nprint(g)\n</pre> g = pp.io.read_netzschleuder_graph(name='karate', network='78').to(device) print(g) <pre>Undirected graph with 34 nodes and 78 edges\n{   'Edge Attributes': {},\n    'Graph Attributes': {   'analyses_average_degree': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_assortativity': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_std_dev': \"&lt;class 'float'&gt;\",\n                            'analyses_diameter': \"&lt;class 'int'&gt;\",\n                            'analyses_edge_properties': \"&lt;class 'list'&gt;\",\n                            'analyses_edge_reciprocity': \"&lt;class 'float'&gt;\",\n                            'analyses_global_clustering': \"&lt;class 'float'&gt;\",\n                            'analyses_hashimoto_radius': \"&lt;class 'float'&gt;\",\n                            'analyses_is_bipartite': \"&lt;class 'bool'&gt;\",\n                            'analyses_is_directed': \"&lt;class 'bool'&gt;\",\n                            'analyses_knn_proj_1': \"&lt;class 'float'&gt;\",\n                            'analyses_knn_proj_2': \"&lt;class 'float'&gt;\",\n                            'analyses_largest_component_fraction': \"&lt;class 'float'&gt;\",\n                            'analyses_mixing_time': \"&lt;class 'float'&gt;\",\n                            'analyses_num_edges': \"&lt;class 'int'&gt;\",\n                            'analyses_num_vertices': \"&lt;class 'int'&gt;\",\n                            'analyses_transition_gap': \"&lt;class 'float'&gt;\",\n                            'analyses_vertex_properties': \"&lt;class 'list'&gt;\",\n                            'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {   'node__pos': \"&lt;class 'numpy.ndarray'&gt;\",\n                           'node_groups': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\",\n                           'node_name': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\"}}\n</pre> In\u00a0[35]: Copied! <pre>pp.plot(g, edge_color='gray');\n</pre> pp.plot(g, edge_color='gray'); <p>We see that the nodes actually have a <code>node_groups</code> property, which maps the nodes to two groups. Those groups are often used as <code>ground truth</code> for communities in this simple illustrative graph. We will instead use it as ground truth categorical node label for a node classification experiment based on a Graph Neural Network.</p> <p>Conveniently, numerical node attributes (either scalar or vector values) are automatically converted to torch tensors, so we can directly use them for a GNN.</p> In\u00a0[36]: Copied! <pre>print(g.data.node_groups)\n</pre> print(g.data.node_groups) <pre>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n</pre> <p>For convenience, let us shift the group labels to binary values 0 and 1:</p> In\u00a0[37]: Copied! <pre>g.data.node_groups -= 1\nprint(g.data.node_groups)\n</pre> g.data.node_groups -= 1 print(g.data.node_groups) <pre>tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n</pre> <p>We can plot categorical labels by passing node colors in the plot function.</p> In\u00a0[38]: Copied! <pre>pp.plot(g, node_color = [g['node_groups',v].item() for v in g.nodes])\n</pre> pp.plot(g, node_color = [g['node_groups',v].item() for v in g.nodes]) Out[38]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f36e006f1d0&gt;</pre> <p>For convenience, let us shift the group labels to binary values 0 and 1:</p> In\u00a0[39]: Copied! <pre>color_map = {0: 'red', 1: 'blue'}\ncolors = [ color_map[g['node_groups',v].item()] for v in g.nodes ]\npp.plot(g, node_color = colors);\n</pre> color_map = {0: 'red', 1: 'blue'} colors = [ color_map[g['node_groups',v].item()] for v in g.nodes ] pp.plot(g, node_color = colors); <p>To simplify the application of deep learning models, we can retrieve a data object that contains the graph and its attributes:</p> In\u00a0[40]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 156], num_nodes=34, node_sequence=[34, 1], node_name=[34], node_groups=[34], node__pos=[34], analyses_average_degree=4.588235294117647, analyses_degree_assortativity=-0.47561309768461424, analyses_degree_std_dev=3.820360677912828, analyses_diameter=5, analyses_edge_properties=[0], analyses_edge_reciprocity=1.0, analyses_global_clustering=0.2556818181818182, analyses_hashimoto_radius=5.292780644548693, analyses_is_bipartite=False, analyses_is_directed=False, analyses_knn_proj_1=3.6123615105719784, analyses_knn_proj_2=1.4566019942625823, analyses_largest_component_fraction=1.0, analyses_mixing_time=7.04834107126513, analyses_num_edges=78, analyses_num_vertices=34, analyses_transition_gap=0.8677276709836416, analyses_vertex_properties=[3])\n</pre> <p>Let's use a one-hot encoding of nodes as a simple additional node feature <code>x</code>, and let's use the node groups as target label <code>y</code>.</p> In\u00a0[41]: Copied! <pre>data = g.data\ng[\"node_feature\"] = torch.eye(g.n, device=device)\ndata['x'] = data['node_feature']\ndata['y'] = data['node_groups'].reshape(-1, 1).float()\n</pre> data = g.data g[\"node_feature\"] = torch.eye(g.n, device=device) data['x'] = data['node_feature'] data['y'] = data['node_groups'].reshape(-1, 1).float() <p>It is easy to define a Graph Convolutional Network that ues the one-hot-encodings of nodes and the topology to predict binary node labels:</p> In\u00a0[42]: Copied! <pre>model = Sequential('node_ohe, edge_index', [\n    (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),\n    ReLU(inplace=True),\n    (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),\n    Sigmoid(),\n])\nmodel.to(device)\n</pre> model = Sequential('node_ohe, edge_index', [     (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),     ReLU(inplace=True),     (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),     Sigmoid(), ]) model.to(device) Out[42]: <pre>Sequential(\n  (0) - GCNConv(34, 8): node_ohe, edge_index -&gt; hidden\n  (1) - ReLU(inplace=True): hidden -&gt; hidden\n  (2) - GCNConv(8, 1): hidden, edge_index -&gt; output\n  (3) - Sigmoid(): output -&gt; output\n)</pre> <p>We next apply a <code>RandomNodeSplit</code> transformation to split the nodes in a training and test set.</p> In\u00a0[25]: Copied! <pre>transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0)\ndata = transform(data)\n</pre> transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0) data = transform(data) <p>We then train our model for 1000 epochs on the training set.</p> In\u00a0[26]: Copied! <pre>epochs = 1000\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n    \nlosses = []\n\nmodel.train()\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)\n    loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n\n    losses.append(loss.cpu().detach().numpy())\n\nplt.plot(range(epochs), losses)\nplt.grid()\n</pre> epochs = 1000  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)      losses = []  model.train() for epoch in range(epochs):     optimizer.zero_grad()     out = model(data.x, data.edge_index)     loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])     loss.backward()     optimizer.step()      losses.append(loss.cpu().detach().numpy())  plt.plot(range(epochs), losses) plt.grid() <p>We evaluate the model in the test set and calculate the adjusted mutual information for the ground truth.</p> In\u00a0[27]: Copied! <pre>model.eval()\npredicted_groups = model(data.x, data.edge_index).round().long()\nmetrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy())\n</pre> model.eval() predicted_groups = model(data.x, data.edge_index).round().long() metrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy()) Out[27]: <pre>1.0</pre> <p>We visualize node representations learned by the model. The test nodes are colored, while training nodes are greyed out.</p> In\u00a0[28]: Copied! <pre># get activations in first-layer\nembedding = model[0].forward(data.x, data.edge_index)\n\n# dimensionality reduction\nsvd = TruncatedSVD()\nlow_dim = svd.fit_transform(embedding.cpu().detach().numpy())\n\n# plot with colors corresponding to groups in validation set\ncolors = {}\nfor v in range(g.n):\n    if not data.val_mask[v]:\n        colors[v] = 'grey'\n    else:\n        if data.y[v].item() == 0.0:\n            colors[v] = 'blue'\n        else:\n            colors[v] = 'orange'\n\nplt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values());\n</pre> # get activations in first-layer embedding = model[0].forward(data.x, data.edge_index)  # dimensionality reduction svd = TruncatedSVD() low_dim = svd.fit_transform(embedding.cpu().detach().numpy())  # plot with colors corresponding to groups in validation set colors = {} for v in range(g.n):     if not data.val_mask[v]:         colors[v] = 'grey'     else:         if data.y[v].item() == 0.0:             colors[v] = 'blue'         else:             colors[v] = 'orange'  plt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values()); <p>This simple code gives you thousands of networks with various meta information at your fingertips, to wich you can directly apply graph learning models provided in pyG, or deep graoh learning architectures defined by yourself.</p>"},{"location":"tutorial/netzschleuder/#learning-in-graphs-from-the-netzschleuder-repository","title":"Learning in Graphs from the Netzschleuder Repository\u00b6","text":""},{"location":"tutorial/netzschleuder/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/netzschleuder/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>Access to a large number of graphs with different topological characteristics and from different domains is crucial for the development and evaluation of graph learning methods. Tousands of graph data sets are available scattered throughout the web, possibly using different data formats and with missing information on their actual origin. Addressing this issue the Netschleuder Online Repository by Tiago Peixoto provides a single repository of graphs in a single format, including descriptions, citations, and node-/edge- or graph-level meta-data. To facilitate the development of graph learning techniques, pathpyG provides a feature that allows to directly read networks from the netzschleuder repository via an API.</p> <p>In this brief unit, we will learn how we can retrieve network records and graph data from the netzschleuder repository. We will further demonstrate how we can conveniently apply a Graph Neural Network to predict node-level categories contained in the meta-data.</p> <p>We first need to import a few modules.</p>"},{"location":"tutorial/netzschleuder/#reading-graphs-from-the-netzschleuder-repository","title":"Reading graphs from the netzschleuder repository\u00b6","text":"<p>In the <code>pathpy.io</code> module, there is a function that allows to read graph data from the API.</p> <p>We can read a given networks from the netzschleuder database using its record name. Just browse the Netschleuder Online Repository to find the record names. As an example, we use a graph capturing co-purchase relationships between political books.</p>"},{"location":"tutorial/netzschleuder/#applying-graph-neural-networks-to-netzschleuder-data","title":"Applying Graph Neural Networks to Netzschleuder Data\u00b6","text":""},{"location":"tutorial/paths_higher_order/","title":"Path Data and Higher-Order Models","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nimport pathpyG as pp\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n</pre> import torch import pathpyG as pp  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') <pre>/opt/conda/lib/python3.11/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n  return torch._C._show_config()\n</pre> <p>For the following examples, we consider a simple directed graph with five nodes <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>, <code>e</code> and four edges:</p> In\u00a0[2]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\npp.plot(g, node_label=g.nodes, edge_color='gray');\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c', 'e')]) pp.plot(g, node_label=g.nodes, edge_color='gray'); In\u00a0[3]: Copied! <pre>paths = pp.PathData(g.mapping)\n\npaths.append_walk(('a', 'c', 'd'), weight=4.0)\npaths.append_walk(('b', 'c', 'e'), weight=4.0)\nprint(paths)\n</pre> paths = pp.PathData(g.mapping)  paths.append_walk(('a', 'c', 'd'), weight=4.0) paths.append_walk(('b', 'c', 'e'), weight=4.0) print(paths) <pre>PathData with 2 paths with total weight 8.0\n</pre> <p>Let us inspect how those walks are internally stored in the <code>PathData</code> object. We find that the class internally stores a <code>pyG.Data</code> object, which contains the properties <code>edge_index</code>, <code>node_sequence</code>, <code>dag_weight</code>, <code>dag_num_edges</code> and <code>dag_num_nodes</code> that can be used to access all of the individual paths.</p> In\u00a0[4]: Copied! <pre>paths.data\n</pre> paths.data Out[4]: <pre>Data(edge_index=[2, 4], node_sequence=[6, 1], dag_weight=[2], dag_num_edges=[2], dag_num_nodes=[2], num_nodes=6)</pre> <p>The <code>edge_index</code> tensor represents an ordered sequence of edges traversed by the walk, where the indices of nodes map to the <code>node_sequence</code> tensor. This additional mapping is neccessary since walks can traverse the same edge multiple times. Moreover, it allows to internally concatenate multiple walks into a single <code>Data</code> object, which is needed for fast GPU-based operations on path data. We can access the first path as follows:</p> In\u00a0[5]: Copied! <pre>paths.data.edge_index[:, :paths.data.dag_num_edges[0]]\n</pre> paths.data.edge_index[:, :paths.data.dag_num_edges[0]] Out[5]: <pre>tensor([[0, 1],\n        [1, 2]])</pre> <p>The <code>node_sequence</code> tensor tells us that the node with index <code>1</code> in the <code>edge_index</code> maps to the node in the graph with index <code>2</code>, which is node <code>c</code>.</p> In\u00a0[6]: Copied! <pre>paths.data.node_sequence[:paths.data.dag_num_nodes[0]]\n</pre> paths.data.node_sequence[:paths.data.dag_num_nodes[0]] Out[6]: <pre>tensor([[0],\n        [2],\n        [3]])</pre> <p>We can index the second edge index accordingly and can see that the <code>node_sequence</code> tensor maps to the sequence <code>b -&gt; c -&gt; e</code>:</p> In\u00a0[7]: Copied! <pre>paths.data.node_sequence[paths.data.edge_index[:, paths.data.dag_num_edges[0]:]]\n</pre> paths.data.node_sequence[paths.data.edge_index[:, paths.data.dag_num_edges[0]:]] Out[7]: <pre>tensor([[[1],\n         [2]],\n\n        [[2],\n         [4]]])</pre> <p>We can actually see a collection of walks as a higher-order generalization of the usual way to define graphs as a collection of dyadic edges (which are simply walks of length one). From this point of view, a standard static (weighted) graph is simply a first-order model of node sequences, which only considers the frequency at which edges are traversed.</p> <p>To generate such a first-order model, we can use the class <code>MultiOderModel</code> and use the first-layer of the model, which is simply a weighted static graph where edge weights count the number of times each edge is traversed by a path. We will explain the class <code>MultiOrderModel</code>, which generalizes this concept to higher-order graph models for any order $k$ in a moment. For now, we can just use it to generate a first-order weighted graph as follows.</p> <p>The generated graph is again based on a <code>pyG.Data</code> object that contains an edge_index and edge weights. As we can see, for the example above the edge_index is just a concatenation of the edge indices of individual walks, where the node indices have been mapped to the correct nodes.</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths, max_order=1)\ng = m.layers[1]\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\npp.plot(g, node_label=paths.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_path_data(paths, max_order=1) g = m.layers[1] print(g.data.edge_index) print(g.data.edge_weight) pp.plot(g, node_label=paths.mapping.node_ids.tolist()); <pre>EdgeIndex([[0, 1, 2, 2],\n           [2, 2, 3, 4]], sparse_size=(5, 5), nnz=4, sort_order=row)\ntensor([4., 4., 4., 4.])\n</pre> <p>Why are data on paths and walks interesting in the first place. The answer is that they provide information on the causal topology of complex systems, i.e. which nodes can possibly causally influence each other via paths that follow the arrow of time. This information is lost if we were to split paths into an (unordered) collection of dyadyic interactions between pairs of nodes, i.e. if we were to only onsider links.</p> <p>To illustrate this, let us assume that the four walks above tell us which paths information (or whatever you may be interested in) can take in the simple graph above. That is, we observe something moving from <code>a</code> via <code>c</code> to <code>d</code> and from <code>b</code> via <code>c</code> to <code>e</code>, and each of those events occur four times. However, we never observed that something moving from <code>a</code> to <code>c</code> ended up in <code>d</code>. And neither did we observe that something moving from <code>b</code> to <code>c</code> ended up in <code>e</code>. This means that - assuming that we completely observed all walks or paths - there is no way that <code>a</code> can causally influence <code>e</code> or that <code>b</code> could causally influence <code>d</code> via the center node <code>c</code>. Note that this is not what we would assume if we consider possible paths in the topology of the underlying graph, where paths of length two exist between all four pairs of nodes (<code>a</code>, <code>d</code>), (<code>a</code>, <code>e</code>), (<code>b</code>, <code>d</code>), (<code>b</code>, <code>e</code>).</p> <p>Hence, we can use data capturing actually observed paths or walks ion a network in contrast to which paths or walks would theoretically be possible based on the topology.</p> <p>As a contrast, consider the following observations of walks in the same graph.</p> In\u00a0[9]: Copied! <pre>paths_2 = pp.PathData(g.mapping)\n\npaths_2.append_walk(('a', 'c', 'd'), weight=2)\npaths_2.append_walk(('a', 'c', 'e'), weight=2)\npaths_2.append_walk(('b', 'c', 'd'), weight=2)\npaths_2.append_walk(('b', 'c', 'e'), weight=2)\nprint(paths_2)\n</pre> paths_2 = pp.PathData(g.mapping)  paths_2.append_walk(('a', 'c', 'd'), weight=2) paths_2.append_walk(('a', 'c', 'e'), weight=2) paths_2.append_walk(('b', 'c', 'd'), weight=2) paths_2.append_walk(('b', 'c', 'e'), weight=2) print(paths_2) <pre>PathData with 4 paths with total weight 8.0\n</pre> <p>Here we have observed walks along all four possible paths of length two, each walk occurring only two times. Like in the example before, each edge was traversed exactly four times and thus the weighted edge index of a first-order graph model is identical to the one before:</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths_2, max_order=1)\ng = m.layers[1]\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_path_data(paths_2, max_order=1) g = m.layers[1] print(g.data.edge_index) print(g.data.edge_weight) pp.plot(g, node_label=g.mapping.node_ids.tolist()); <pre>EdgeIndex([[0, 1, 2, 2],\n           [2, 2, 3, 4]], sparse_size=(5, 5), nnz=4, sort_order=row)\ntensor([4., 4., 4., 4.])\n</pre> <p>This is a first-order graph representation, as it only captures the (weighted) edges in the underlying path data, i.e. we could say that we only count the frequency of paths (or walks) of length one. This naturally gives rise to an <code>edge_index</code> tensor with shape $(2,m)$, where $m$ is the number of unique edges in the graph that are traversed by the paths.</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths, max_order=2)\ng = m.layers[2]\npp.plot(g, node_label=g.nodes, edge_size=5);\n</pre> m = pp.MultiOrderModel.from_path_data(paths, max_order=2) g = m.layers[2] pp.plot(g, node_label=g.nodes, edge_size=5); <p>For $k=2$, we obtain a second-order De Bruijn graph where second-order nodes are first-order edges and second-order edges represent walks of length two in the original graph. Edge weights capture observation frequencies of those walks. In our example, we have two different walks of length two ($a$ -&gt; $c$ -&gt; $d$ and $b$ -&gt; $c$ -&gt; $e$), represented by two edges $(a-c, c-d)$ and $(b-c, c-e)$. Each of those walks appears four times so the weights of both edges are four.</p> In\u00a0[12]: Copied! <pre>print(g.mapping)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> print(g.mapping) print(g.data.edge_index) print(g.data.edge_weight) <pre>(np.str_('a'), np.str_('c')) -&gt; 0\n(np.str_('b'), np.str_('c')) -&gt; 1\n(np.str_('c'), np.str_('d')) -&gt; 2\n(np.str_('c'), np.str_('e')) -&gt; 3\n\nEdgeIndex([[0, 1],\n           [2, 3]], sparse_size=(4, 4), nnz=2, sort_order=row)\ntensor([4., 4.])\n</pre> <p>While this goes beyond the scope of this tutorial, thanks to the tensor-based representation of paths, the construction ofhigher-order De Bruijn graphs can be done based on efficient GPU operations, i.e. we can scale it up to large graphs.</p> <p>Let us have a closer look at our examples above. While the first-order edge indices of the two path objects <code>paths</code> and <code>paths_2</code> are the same, we find that the second-order edge indices are actually different. For <code>paths_2</code> we have four different paths of length two, each occurring twice. Hence, our second-order De Bruijn graph has four edges, each with weight two. These edges correspond to all possible paths of length two in the underlying graph.</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths_2, max_order=2)\ng = m.layers[2]\npp.plot(g, node_label=g.nodes);\n</pre> m = pp.MultiOrderModel.from_path_data(paths_2, max_order=2) g = m.layers[2] pp.plot(g, node_label=g.nodes); In\u00a0[14]: Copied! <pre>print(g.mapping)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> print(g.mapping) print(g.data.edge_index) print(g.data.edge_weight) <pre>(np.str_('a'), np.str_('c')) -&gt; 0\n(np.str_('b'), np.str_('c')) -&gt; 1\n(np.str_('c'), np.str_('d')) -&gt; 2\n(np.str_('c'), np.str_('e')) -&gt; 3\n\nEdgeIndex([[0, 0, 1, 1],\n           [2, 3, 2, 3]], sparse_size=(4, 4), nnz=4, sort_order=row)\ntensor([2., 2., 2., 2.])\n</pre> <p>We thus find that the second-order De Bruijn graph representation of paths is sensitive to the differences in the causal topology, while a first-order graph is not. This is the basis to generalize network analysis and graph learning to causality-aware graph models for various kinds of time series data on graphs. In particular, as we shall see in more detail in a later tutorial, we can use paths to generate k-th order graphs that can be used to generalize Graph Neural Networks to higher-order De Bruijn Graphs.</p> <p>Note that all higher-order graphs are simply <code>Graph</code> objects, which means that we can iterate through the nodes of a higher-order graph just like for normal graphs. Node indices are automatically mapped, yielding tuples of first-order node identifiers.</p> In\u00a0[15]: Copied! <pre>for n in g.nodes:\n    print(n)\n</pre> for n in g.nodes:     print(n) <pre>('a', 'c')\n('b', 'c')\n('c', 'd')\n('c', 'e')\n</pre> <p>Edges are tuples with two elements, where each element is a k-th order node, i.e. a tuple of node IDs of length $k$. I.e. for a second-order model the edges are tuples of length two, each entry containing s tuple of length two.</p> In\u00a0[16]: Copied! <pre>for e in g.edges:\n    print(e)\n</pre> for e in g.edges:     print(e) <pre>(('a', 'c'), ('c', 'd'))\n(('a', 'c'), ('c', 'e'))\n(('b', 'c'), ('c', 'd'))\n(('b', 'c'), ('c', 'e'))\n</pre> <p>The weight attribute stores a tensor whose entries capture the frequencies of edges, i.e. the frequencies of paths of length $k$.</p> In\u00a0[17]: Copied! <pre>for e in g.edges:\n    print(e, g['edge_weight', e[0], e[1]].item())\n</pre> for e in g.edges:     print(e, g['edge_weight', e[0], e[1]].item()) <pre>(('a', 'c'), ('c', 'd')) 2.0\n(('a', 'c'), ('c', 'e')) 2.0\n(('b', 'c'), ('c', 'd')) 2.0\n(('b', 'c'), ('c', 'e')) 2.0\n</pre> <p>We can finally plot a higher-order De Bruijn graph in the same way as a first-order graph.</p> In\u00a0[18]: Copied! <pre>pp.plot(g, node_label=g.nodes, edge_color='gray');\n</pre> pp.plot(g, node_label=g.nodes, edge_color='gray'); <p>Let us compare this to a second-order graph model of the second path data set <code>paths_2</code> from above, which corresponds to a network where all possible paths of length two actually occur. Hence, different from the data in <code>paths</code>, all pairs of nodes in this graph can causally influence each other via paths of length two.</p> In\u00a0[\u00a0]: Copied! <pre>m1 = pp.MultiOrderModel.from_path_data(paths, max_order=2)\nprint(m1.estimate_order(paths, significance_threshold=0.01))\n</pre> m1 = pp.MultiOrderModel.from_path_data(paths, max_order=2) print(m1.estimate_order(paths, significance_threshold=0.01)) <pre>2\n</pre> <pre>/opt/conda/lib/python3.11/site-packages/torch_geometric/edge_index.py:863: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n  return torch.sparse_csr_tensor(\n</pre> <p>For <code>paths_2</code> where the observed paths are in line what we would expect based on the weighted edges in the first-order graph model, we correctly find that we do not need to consider a second-order model</p> In\u00a0[\u00a0]: Copied! <pre>m2 = pp.MultiOrderModel.from_path_data(paths_2, max_order=2)\nprint(m2.estimate_order(paths_2, significance_threshold=0.01))\n</pre> m2 = pp.MultiOrderModel.from_path_data(paths_2, max_order=2) print(m2.estimate_order(paths_2, significance_threshold=0.01)) <pre>1\n</pre> <p>Admittedly, the situation in the <code>paths</code> data is extreme insofar as two of the possible paths of lengths two have not been observed at all. We can also have more subtle deviations from the expectation based on the first-order graph model. Consider the following case, where two of the paths are observed more often than two other paths. Note that we have assigned the path frequencies such that again all edges are traversed with exactly the same frequencies, i.e. all edge weights are again equal in the first-order graph.</p> In\u00a0[\u00a0]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\npaths_3 = pp.PathData(g.mapping)\n\npaths_3.append_walk(('a', 'c', 'd'), weight=6.0)\npaths_3.append_walk(('a', 'c', 'e'), weight=2.0)\n\npaths_3.append_walk(('b', 'c', 'e'), weight=6.0)\npaths_3.append_walk(('b', 'c', 'd'), weight=2.0)\n\nm3 = pp.MultiOrderModel.from_path_data(paths_3, max_order=2)\nprint(m3.layers[1].data.edge_weight)\nprint(m3.estimate_order(paths_3, significance_threshold=0.01))\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c', 'e')]) paths_3 = pp.PathData(g.mapping)  paths_3.append_walk(('a', 'c', 'd'), weight=6.0) paths_3.append_walk(('a', 'c', 'e'), weight=2.0)  paths_3.append_walk(('b', 'c', 'e'), weight=6.0) paths_3.append_walk(('b', 'c', 'd'), weight=2.0)  m3 = pp.MultiOrderModel.from_path_data(paths_3, max_order=2) print(m3.layers[1].data.edge_weight) print(m3.estimate_order(paths_3, significance_threshold=0.01)) <pre>tensor([8., 8., 8., 8.])\n1\n</pre> <p>In this example, due to the relatively small number of observations, the deviations from the expected baseline are still not strong enough to detect the optimal order of two (at least not for a significance threshold of $0.01$). We would need to raise the signififance threshold to $0.15$ to detect order two:</p> In\u00a0[22]: Copied! <pre>print(m3.estimate_order(paths_3, significance_threshold=0.15))\n</pre> print(m3.estimate_order(paths_3, significance_threshold=0.15)) <pre>2\n</pre> <p>Alternatively, we are able to detect a significant deviation from a first-order model for a significance threshold of $0.01$ if we make the deviations more extreme. If we observe two fo the paths seven times, while the other two are only observed once we find that order two is significant at a sigificance threshold of $0.01$.</p> In\u00a0[\u00a0]: Copied! <pre>paths_3 = pp.PathData(g.mapping)\n\npaths_3.append_walk(('a', 'c', 'd'), weight=7.0)\npaths_3.append_walk(('a', 'c', 'e'), weight=1.0)\n\npaths_3.append_walk(('b', 'c', 'e'), weight=7.0)\npaths_3.append_walk(('b', 'c', 'd'), weight=1.0)\n\nm3 = pp.MultiOrderModel.from_path_data(paths_3, max_order=2)\nprint(m3.layers[1].data.edge_weight)\nprint(m3.estimate_order(paths_3, significance_threshold=0.01))\n</pre> paths_3 = pp.PathData(g.mapping)  paths_3.append_walk(('a', 'c', 'd'), weight=7.0) paths_3.append_walk(('a', 'c', 'e'), weight=1.0)  paths_3.append_walk(('b', 'c', 'e'), weight=7.0) paths_3.append_walk(('b', 'c', 'd'), weight=1.0)  m3 = pp.MultiOrderModel.from_path_data(paths_3, max_order=2) print(m3.layers[1].data.edge_weight) print(m3.estimate_order(paths_3, significance_threshold=0.01)) <pre>tensor([8., 8., 8., 8.])\n2\n</pre> <p>The ability to detect the optimal higher-order for a given data set in a statistically principled way is a powerful feature of the modelling framework of higher-order De Bruijn Graphs. Admittedly, the likelihood-based model selection approach has its limitations especially for small data sets or partially observed graphs, where it can both over- or underfit. To address this, we have developed an alternative Bayesian model selection technique that is explained and evaluated in the following paper:</p> <p>L Petrovic, I Scholtes: Learning the Markov order of paths, In Proc. of the ACM Web Conference (WWW'22), April 2022</p> <p>Unfortunately, this method has not yet been implemented in <code>pathpyG</code> but we are planning to add it soon.</p> In\u00a0[11]: Copied! <pre>paths_tube = pp.io.read_csv_path_data(path_or_buf='../data/tube_paths_train.ngram', sep=',', weight=True)\nprint(paths_tube)\n</pre> paths_tube = pp.io.read_csv_path_data(path_or_buf='../data/tube_paths_train.ngram', sep=',', weight=True) print(paths_tube) <pre>PathData with 61748 paths with total weight 2147865.0\n</pre> <p>To plot a (first-order) graph representation of the London Tube metro network, we can use the following code:</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths_tube, max_order=1)\ng = m.layers[1]\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_path_data(paths_tube, max_order=1) g = m.layers[1] pp.plot(g, node_label=g.mapping.node_ids.tolist()); <p>In general, the maximum size of a higher-order model could grow exponentially with the number of nodes in the underlying graph. However, for most empirical data sets, higher-order models are actually sparse, which allows us to efficiently construct them using GPU-based operations. We demonstrate this in the London Tube data sets by constructing all higher-order De Bruijn graph models up to order 20, which takes approx. 25 seconds on a mobile GPU (RTX A2000) and yields reasonably sized higher-order models.</p> In\u00a0[\u00a0]: Copied! <pre>paths_tube.to(device)\nm = pp.MultiOrderModel.from_path_data(paths_tube, max_order=20)\nprint(m.layers[20])\n</pre> paths_tube.to(device) m = pp.MultiOrderModel.from_path_data(paths_tube, max_order=20) print(m.layers[20]) <pre>Directed graph with 5634 nodes and 4729 edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4729])\"},\n    'Graph Attributes': {'inverse_idx': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([18950])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {}}\n</pre> <p>As we shall see in the following two units, the <code>MultiOrderGraph</code> class is also the basis for the GPU-based analysis and modelling of causal structures in temporal graphs. In particular, the underlying generalization of first-order static graph models to higher-order De Bruijn graphs allows us to easily build causality-aware graph neural network architectures that consider both the topology and the temoral ordering of time-stamped edges in a temporal graph. We will</p>"},{"location":"tutorial/paths_higher_order/#path-data-and-higher-order-de-bruijn-graphs","title":"Path Data and Higher-Order De Bruijn Graphs\u00b6","text":""},{"location":"tutorial/paths_higher_order/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/paths_higher_order/#motivation-and-learning-objective","title":"Motivation and Learning Objective\u00b6","text":"<p>While <code>pathpyG</code> is useful to handle and visualize static graphs - as the name suggests - its main advantage is that it facilitates the analysis of time series data that can be used to calculate paths in a graph. As we shall see in the following tutorial, there are various situations in which naturally have access to data on paths, including data on (random) walks or trajectories, traces of dynamical processes giving rise to node sequences or directed acyclic graphs, or time-respecting paths in temporal graphs. ``pathpyG` can be used to model patterns in such data based on higher-order De Bruijn graph models.</p> <p>In this first unit, we will show how <code>pathpyG</code> supports to represent data on paths in graphs. Like graphs, such data are internally stored as tensors, which facilitates GPU-based operations to create higher-order De Bruijn graphs.</p> <p>We first import the modules <code>torch</code> and <code>pathpyG</code>. By setting the device used by <code>torch</code>, we can specify whether we want to run our code on the CPU or on the GPU.</p>"},{"location":"tutorial/paths_higher_order/#using-pathdata-to-store-walks-or-paths-in-a-graph","title":"Using <code>PathData</code> to store walks or paths in a graph\u00b6","text":"<p>Assume that we have time series data that captures observations of trajectories (i.e. walks or paths) in the graph above. For example, we could observe four walks of length two, four each of the following:</p> <ul> <li>4 x <code>a</code> -&gt; <code>c</code> -&gt; <code>d</code></li> <li>4 x <code>b</code> -&gt; <code>c</code> -&gt; <code>e</code></li> </ul> <p>Note that we define the length of a walk or path as the number of edges that are traversed, i.e. a sequence that consists of a single node, e.g. <code>a</code>, is considered a walk of length zero, while every edge in a graph is a walk of length one.</p> <p><code>pp.PathData</code> supports to store and model such sequential data. We first create an instance of the <code>PathData</code> class. To consistently map node IDs to indices across <code>Graph</code> and <code>PathData</code> objects, we can pass the <code>IndexMap</code> object from the <code>Graph</code> above in the constructor. We then use the <code>append_walk</code> function to add observations of our two walks, where the <code>weight</code> argument is used to indicate the number of times each path or walk has been observed.</p>"},{"location":"tutorial/paths_higher_order/#from-graphs-to-higher-order-de-bruijn-graph-models","title":"From Graphs to Higher-Order De Bruijn Graph Models\u00b6","text":"<p>As we have seen above, the use of a first-order graph model discards information in path data, which capture which nodes can possibly causally influence each other via paths. A key feature of <code>pathpyG</code> is it allows to generalize this first-order modelling perspective to $k$-th order De Bruijn graph models for paths, where the nodes in a $k$-th order De Bruijn graph model are sequences of $k$ nodes. Edges connect pairs of nodes that overlap in $k-1$ nodes and capture paths of length $k$.</p> <p>A De Bruijn graph of order $k=1$ is simply a normal (weighted) static graph consisting of nodes and edges. Pairs of nodes connected by edges overlap in $k-1=0$ nodes and capture paths of length $k=1$, i.e. simple dyadic edges in the underlying path data.</p> <p>For a De Bruijn graph with order $k=2$, in our example above, an edge connects a pair of nodes $(a,b)$ and $(b,c)$ that overlaps in the $k-1=1$ node $b$. Such an edge represents the path $a -&gt; b -&gt; c$ of length two. We can use the <code>MultiOderModel</code> class to generate a second-order De Bruijn graph representation of the path data above. We just have to set the <code>max_order</code> parameter to two and use the second layer of the resulting <code>MultiOrderModel</code> instance.</p>"},{"location":"tutorial/paths_higher_order/#detecting-the-optimal-order-of-higher-order-de-bruijn-graph-models","title":"Detecting the Optimal Order of Higher-Order De Bruijn Graph Models\u00b6","text":"<p>The fact that we can model the same set of paths with higher-order De Bruijn graph models with different orders $k$ raises an important question: What is the optimal order to model a given <code>PathData</code> instance. It is actually easy to answer this question in our example above.</p> <p>For the data contained in <code>paths</code>, we observe only two of the four possible paths, which is different from what we would expect based on a first-order graph model. To capture this pattern in the node sequenves, a first-order graph model is not sufficient and we need a second-order De Bruoijn graph model.</p> <p>For <code>paths_2</code> this is different: Here we observe all four paths of length two with the same frequency, which is exactly what we would expect based on the first-order weighted graph, where all edge weights are the same. Hence, for <code>paths_2</code> the second-order De Bruijn graph model contains no additional information compared to a first-order weighted graph, which means a first-order model is sufficient.</p> <p>While it is easy to see this in the toy example, for real data we need a principled method to automatically determine the optimal order of a higher-order De Bruijn graph model. Luckily, this can be achieved based on statistical model selection in a multi-order De Bruijn graph model. Here we cannot explain the details of this method, so we kindly refer you to the following paper:</p> <p>I Scholtes: When is a Network a Network?: Multi-Order Graphical Model Selection in Pathways and Temporal Networks, In Proc. of SIGKDD 2017, August 2017</p> <p>The method introduced in this paper is implemented in <code>pathpyG</code>. To determine the optimal order of a higher-order De Bruijn graph model for the node sequences contained in a given <code>PathData</code> instance, we can use the <code>MultiOderModel.estimate_order</code> method. Since the method is based on statistical hypothesis testing, we can also pass a significance threshold, which - in line with the interpretation of p-values - bounds the type I error rate of our test, i.e. the rate at which we wrongly reject the null hypothesis that the true optimal order of a data set is $k-1$ in favor of the alternative hypothesis that the order is $k$.</p> <p>Let us test this for our toy example. Using a significance threshold of $0.01$, we determine the optimal order for the data set <code>paths</code> that should actually warrant a second-order model:</p>"},{"location":"tutorial/paths_higher_order/#loading-empirical-path-data-from-n-gram-files","title":"Loading empirical path data from N-Gram Files\u00b6","text":"<p>For real data on walks in graphs it is not convenient to manually construct and add walks based on edge tensors. We can instead use the <code>from_ngram</code> function of class <code>PathData</code> to load such data from an n-gram file, i.e. a text file where each line corresponds to one observed walk consisting of comma-separated node IDs. If we set the argument <code>weight=True</code>, the last component of each line is considered to be the observation frequency of that particular walk.</p> <p>As an example, the file <code>data/tube_paths_train.ngram</code> contains observed passenger itineraries between nodes in a graph that representes the network of London Tube stations. Each of those itineraries is associated with an observation frequencies. The following is an excerpt from that file:</p> <pre><code>Southwark,Waterloo,212.0\nLiverpool Street,Bank / Monument,1271.0\nBarking,West Ham,283.0\nTufnell Park,Kentish Town,103.0\n...\n</code></pre> <p>Note that this will automatically create an internal mapping of node IDs to indices.</p>"},{"location":"tutorial/temporal_graphs/","title":"Temporal Graphs","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[3]: Copied! <pre>import torch\nfrom torch_geometric.data import Data\nimport pathpyG as pp\nimport pandas as pd\n</pre> import torch from torch_geometric.data import Data import pathpyG as pp import pandas as pd <p>We can create a temporal graph object from a list of time-stamped edges. Since <code>TemporalGraph</code> is a subclass of the <code>Graph</code> class, the internal structures are very similar:</p> In\u00a0[4]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nprint(t.mapping)\nprint(t.n)\nprint(t.m)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) print(t.mapping) print(t.n) print(t.m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n10\n</pre> <p>By default, all temporal graphs are directed. We can create an undirected version a temporal graph as follows:</p> In\u00a0[5]: Copied! <pre>x = t.to_undirected()\nprint(x.mapping)\nprint(x.n)\nprint(x.m)\n</pre> x = t.to_undirected() print(x.mapping) print(x.n) print(x.m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n20\n</pre> <p>We can also directly create a temporal graph from an instance of <code>pyG.TemporalData</code></p> In\u00a0[6]: Copied! <pre>td = Data(\n    edge_index = torch.Tensor([[0,1,2,0],[1,2,3,1]]).long(),\n    time = torch.Tensor([0,1,2,3])\n)\nprint(td)\nt2 = pp.TemporalGraph(td)\nprint(t2)\n</pre> td = Data(     edge_index = torch.Tensor([[0,1,2,0],[1,2,3,1]]).long(),     time = torch.Tensor([0,1,2,3]) ) print(td) t2 = pp.TemporalGraph(td) print(t2) <pre>Data(edge_index=[2, 4], time=[4])\nTemporal Graph with 4 nodes, 3 unique edges and 4 events in [0.0, 3.0]\n{'Edge Attributes': {}, 'Graph Attributes': {}, 'Node Attributes': {}}\n</pre> <pre>/opt/conda/lib/python3.11/site-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index', 'time'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> <p>We can restrict a temporal graph to a time window, which returns a temporal graph that only contains time-stamped edges in the given time interval.</p> In\u00a0[7]: Copied! <pre>t1 = t.get_window(0,4)\nprint(t1)\nprint(t1.m)\nprint(t1.start_time)\nprint(t1.end_time)\n</pre> t1 = t.get_window(0,4) print(t1) print(t1.m) print(t1.start_time) print(t1.end_time) <pre>Temporal Graph with 4 nodes, 5 unique edges and 7 events in [1, 4]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n7\n1\n4\n</pre> <p>We can also extract a TemporalGraph object for a batch of temporal edges, which is defined by the start and end index of the edges defining the batch.</p> In\u00a0[8]: Copied! <pre>t1 = t.get_batch(1,6)\nprint(t1)\nprint(t1.m)\nprint(t1.start_time)\nprint(t1.end_time)\n</pre> t1 = t.get_batch(1,6) print(t1) print(t1.m) print(t1.start_time) print(t1.end_time) <pre>Temporal Graph with 4 nodes, 4 unique edges and 5 events in [2, 4]\n{'Edge Attributes': {}, 'Graph Attributes': {}, 'Node Attributes': {}}\n5\n2\n4\n</pre> <p>We can easily convert a temporal graph into a weighted time-aggregated static graph, where edge weights count the number of occurrences of an edge across all timestamps.</p> In\u00a0[9]: Copied! <pre>g = t.to_static_graph(weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(weighted=True) print(g) <pre>Directed graph with 4 nodes and 6 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>We can also aggregate a temporal graph within a certain time window:</p> In\u00a0[10]: Copied! <pre>g = t.to_static_graph(time_window=(1, 3), weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(time_window=(1, 3), weighted=True) print(g) <pre>Directed graph with 2 nodes and 1 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>Finally, we can use the class <code>RollingTimeWindow</code> to perform a rolling window analysis. The class returns an iterable object, where each iteration yields a time-aggregated weighted graph object as well as the corresponding time window.</p> In\u00a0[11]: Copied! <pre>r = pp.algorithms.RollingTimeWindow(t, window_size=3, step_size=1, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</pre> r = pp.algorithms.RollingTimeWindow(t, window_size=3, step_size=1, return_window=True) for g, w in r:     print('Time window ', w)     print(g)     print(g.data.edge_index)     print('---') <pre>Time window  (1, 4)\nDirected graph with 3 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 1],\n           [1, 0, 2]], sparse_size=(3, 3), nnz=3, sort_order=row)\n---\nTime window  (2, 5)\nDirected graph with 4 nodes and 5 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 1, 2, 3],\n           [1, 0, 2, 1, 2]], sparse_size=(4, 4), nnz=5, sort_order=row)\n---\nTime window  (3, 6)\nDirected graph with 4 nodes and 6 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 1, 2, 2, 3],\n           [1, 0, 2, 1, 3, 2]], sparse_size=(4, 4), nnz=6, sort_order=row)\n---\nTime window  (4, 7)\nDirected graph with 4 nodes and 5 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 2, 2, 3],\n           [1, 0, 1, 3, 2]], sparse_size=(4, 4), nnz=5, sort_order=row)\n---\nTime window  (5, 8)\nDirected graph with 4 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[1, 2, 2],\n           [0, 1, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\n---\nTime window  (6, 9)\nDirected graph with 3 nodes and 1 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[2],\n           [1]], sparse_size=(3, 3), nnz=1, sort_order=row)\n---\n</pre> <p>We can visualize temporal graphs using the plot function just like static graphs:</p> In\u00a0[26]: Copied! <pre>pp.plot(t, node_label=t.nodes, edge_color='lightgray');\n</pre> pp.plot(t, node_label=t.nodes, edge_color='lightgray'); <p>The source nodes, destination nodes and timestamps of time-stamped edges are stored as a <code>pyG TemporalData</code> object, which we can access in the following way.</p> In\u00a0[13]: Copied! <pre>t.data\n</pre> t.data Out[13]: <pre>Data(edge_index=[2, 10], time=[10], num_nodes=4)</pre> In\u00a0[14]: Copied! <pre>print(t.data.edge_index)\n</pre> print(t.data.edge_index) <pre>EdgeIndex([[0, 0, 1, 1, 3, 0, 2, 2, 1, 2],\n           [1, 1, 0, 2, 2, 1, 1, 3, 0, 1]], sparse_size=(4, 4), nnz=10)\n</pre> In\u00a0[15]: Copied! <pre>print(t.data.time)\n</pre> print(t.data.time) <pre>tensor([1, 2, 3, 3, 4, 4, 4, 5, 5, 6])\n</pre> <p>With the generator functions <code>edges</code> and <code>temporal_edges</code> we can iterate through the time-ordered (temporal) multi-edges of a temporal graph.</p> In\u00a0[16]: Copied! <pre>for v, w in t.edges:\n    print(v, w)\n</pre> for v, w in t.edges:     print(v, w) <pre>a b\na b\nb a\nb c\nd c\na b\nc b\nc d\nb a\nc b\n</pre> In\u00a0[17]: Copied! <pre>for v, w, time in t.temporal_edges:\n    print(v, w, time)\n</pre> for v, w, time in t.temporal_edges:     print(v, w, time) <pre>a b 1\na b 2\nb a 3\nb c 3\nd c 4\na b 4\nc b 4\nc d 5\nb a 5\nc b 6\n</pre> <p>We are often interested in time-respecting paths in a temporal graph. A time-respecting path consists of a sequence of nodes $v_0,...,v_l$ where consecutive nodes are connected by time-stamped edges that occur (i) in the right temporal ordering, and (ii) within a maximum time difference of $\\delta\\in \\N$.</p> <p>To calculate time-respecting paths in a temporal graph, we can construct a directed acyclic graph (DAG), where each time-stamped edge $(u,v;t)$ in the temporal graph is represented by a node and two nodes representing time-stamped edges $(u,v;t_1)$ and $(v,w;t_2)$ are connected by an edge iff $0 &lt; t_2-t_1 \\leq \\delta$. This implies that (i) each edge in the resulting DAG represents a time-respecting path of length two, and (ii) time-respecting paths of any lenghts are represented by paths in this DAG.</p> <p>We can construct such a DAG using the function <code>pp.algorithms.lift_order_temporal</code>, which returns an edge_index. We can pass this to the constructor of a <code>Graph</code> object, which we can use to visualize the resulting DAG.</p> In\u00a0[18]: Copied! <pre>e_i = pp.algorithms.lift_order_temporal(t, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\npp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]);\n</pre> e_i = pp.algorithms.lift_order_temporal(t, delta=1) dag = pp.Graph.from_edge_index(e_i) pp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 1993.65it/s]\n</pre> <p>For $\\delta=1$, this DAG with three connected components tells us that the underlying temporal graph has  the following time-respecting paths (of different lengths):</p> <p>Length one: a -&gt; b b -&gt; a b -&gt; c c -&gt; b c -&gt; d d -&gt; c</p> <p>Length two: a -&gt; b -&gt; a (twice, starting at time 2 and time 4) b -&gt; a -&gt; b a -&gt; b -&gt; c b -&gt; c -&gt; b c -&gt; b -&gt; a d -&gt; c -&gt; d</p> <p>Length three: a -&gt; b -&gt; a -&gt; b b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b b -&gt; c -&gt; b -&gt; a</p> <p>Length four: a -&gt; b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b -&gt; a</p> <p>We can can use the function <code>pp.algorithms.temporal.temporal_shortest_paths</code> to calculate shortest time-respecting path distances between any pair of nodes. This also returns a predecessor matrix, which can be used to reconstruct all shortest time-respecting paths (in analogy to the Dijkstra algorithm for static graphs):</p> In\u00a0[27]: Copied! <pre>dist, pred = pp.algorithms.temporal_shortest_paths(t, delta=1)\nprint(t.mapping)\nprint(dist)\nprint(pred)\n</pre> dist, pred = pp.algorithms.temporal_shortest_paths(t, delta=1) print(t.mapping) print(dist) print(pred) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2171.34it/s]</pre> <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n[[ 0.  1.  1.]\n [inf  0.  1.]\n [inf inf  0.]]\n[[ 0  0  0]\n [-1  1  1]\n [-1 -1  2]]\n</pre> <pre>\n</pre> <p>In the example above, the four <code>inf</code> values indicate that there is no time-respecting paths between the four node pairs (a, d), (b, d), (d,a) and (d, b). This is not something we would expect based on the (strongly connected) topology of the time-aggregated graph, which is shown below:</p> In\u00a0[20]: Copied! <pre>g = t.to_static_graph(weighted=True)\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> g = t.to_static_graph(weighted=True) pp.plot(g, node_label=g.mapping.node_ids.tolist()); In\u00a0[21]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\ndf = pp.io.temporal_graph_to_df(t)\nprint(df)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) df = pp.io.temporal_graph_to_df(t) print(df) <pre>   v  w  t\n0  a  b  1\n1  a  b  2\n2  b  a  3\n3  b  c  3\n4  d  c  4\n5  a  b  4\n6  c  b  4\n7  c  d  5\n8  b  a  5\n9  c  b  6\n</pre> In\u00a0[22]: Copied! <pre>t = pp.io.df_to_temporal_graph(df)\nprint(t)\n</pre> t = pp.io.df_to_temporal_graph(df) print(t) <pre>Temporal Graph with 4 nodes, 6 unique edges and 10 events in [1, 6]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> In\u00a0[23]: Copied! <pre>df = pd.DataFrame([['a', 'b', 1], ['b', 'c', 2], ['a', 'c', 3]])\nprint(df)\nt = pp.io.df_to_temporal_graph(df)\nprint(t)\n</pre> df = pd.DataFrame([['a', 'b', 1], ['b', 'c', 2], ['a', 'c', 3]]) print(df) t = pp.io.df_to_temporal_graph(df) print(t) <pre>   0  1  2\n0  a  b  1\n1  b  c  2\n2  a  c  3\nTemporal Graph with 3 nodes, 3 unique edges and 3 events in [1, 3]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> In\u00a0[28]: Copied! <pre>pp.io.write_csv(t, path_or_buf='../data/test_temporal_graph.csv')\n</pre> pp.io.write_csv(t, path_or_buf='../data/test_temporal_graph.csv') In\u00a0[29]: Copied! <pre>t = pp.io.read_csv_temporal_graph('../data/test_temporal_graph.csv')\nprint(t)\n</pre> t = pp.io.read_csv_temporal_graph('../data/test_temporal_graph.csv') print(t) <pre>Temporal Graph with 3 nodes, 3 unique edges and 3 events in [1, 3]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> In\u00a0[30]: Copied! <pre>t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False)\nprint(t_ants)\n</pre> t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False) print(t_ants) <pre>Temporal Graph with 89 nodes, 947 unique edges and 1911 events in [0, 1438]\n{   'Edge Attributes': {'edge_attr_1': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\", 'edge_attr_2': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\"},\n    'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {}}\n</pre> <p>To calculate the temporal closeness centrality, which is defined based on the length of shortest time-respecting paths of a node to all other nodes, we can write the following:</p> In\u00a0[\u00a0]: Copied! <pre>cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60)\nprint(cl)\nmx = max(cl.values())\nmn = min(cl.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60) print(cl) mx = max(cl.values()) mn = min(cl.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3322.84it/s]\n</pre> <pre>{'GBGR': 3024.615873015872, 'GBGW': 2999.502564102565, 'GBG_': 2928.756043956045, 'GGGG': 2859.2000000000007, 'GGGR': 2811.4253968253956, 'GGRR': 4383.866666666668, 'GGRY': 3304.400000000001, 'GGWW': 3418.311111111112, 'GGWY': 5092.2666666666655, 'GGW_': 4230.076190476191, 'GGYW': 2556.571916971917, 'GG_W': 3788.4000000000015, 'GRBR': 2977.3714285714286, 'GRGY': 3039.911111111111, 'GRWG': 4162.714285714285, 'GRYY': 2736.625396825396, 'GR_Y': 3113.7333333333336, 'GR_Y2': 4416.133333333335, 'GR__': 3305.8666666666663, 'GWRG': 3379.2000000000003, 'GYGG': 3321.2977777777783, 'GYYY': 2301.3777777777777, 'GY__': 2260.066666666665, 'G_GW': 3525.866666666667, 'G_R_': 4034.800000000001, 'G_W_': 3010.4380952380957, 'G___': 3100.533333333335, 'G___big': 2068.308913308913, 'G___small': 2351.7999999999993, 'Q': 4177.311111111112, 'RWGY': 3708.5714285714307, 'RWWG': 3030.488888888889, 'WBGG': 3781.0666666666675, 'WBGW': 3166.742857142857, 'WBYG': 2668.5999999999995, 'WGBB': 3440.171428571429, 'WGGB': 3751.1047619047636, 'WGWB': 4185.7619047619055, 'WG_R': 4216.666666666668, 'WRBB': 4256.266666666667, 'WRRY': 3768.600000000001, 'WRR_': 2583.8825396825387, 'WRWR': 3951.200000000001, 'WR__': 3180.7111111111117, 'WWBG': 2788.5206349206346, 'WYGG': 3617.466666666668, 'W___': 3253.0666666666675, 'YGWW': 4867.866666666667, 'YGWY': 2735.542857142857, 'YWGW': 3273.5999999999995, 'YWWW': 2991.999999999999, 'YWW_': 3136.082539682539, 'YW__': 1220.9476986781337, 'YYGG': 4430.8, 'YYGGmid': 4461.6, 'YYGGright': 3284.565079365079, 'YYGW': 3462.844444444446, 'YYRB': 3366.0000000000005, 'YYRG': 2891.30862663906, 'YYWR': 3060.6888888888893, 'YYYY': 2510.339682539682, 'YYY_': 2561.692063492063, 'YY_R': 3472.926984126984, 'YY_W': 3874.9333333333357, 'YY__': 2901.5206349206346, 'Y_WY': 3572.800000000001, 'Y__W': 2301.933333333332, 'Y___': 3097.8444444444453, '_RYG': 1844.680341880342, '_R__': 4439.600000000002, '_WGG': 3781.0666666666684, '_WWW': 2961.6539682539687, '_WWY': 4007.771428571429, '_WYG': 3018.9199999999996, '_WYW': 4252.914285714287, '_W_Y': 3262.742857142857, '_W__': 4009.8666666666677, '_Y__': 2881.7179487179487, '__BB': 3040.9200000000005, '__W_': 3649.4158730158724, '____almost': 3127.809523809524, '____bm': 3655.6, '____bot': 2454.007326007325, '____brood': 3952.0380952380965, '____corner': 3856.638095238096, '____pale': 4692.7047619047635, '____right': 2577.243809523809, '____topleft': 3392.4, '____topright': 2641.047619047619}\n</pre> <p>The definition of time-respecting paths depends on our maximum time difference parameter $\\delta$, which implies that different values of this parameter also yield different centralities. This means that we can calculate temporal node centralities for different \"time scales\" of a temporal graph.</p> In\u00a0[\u00a0]: Copied! <pre>cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=20)\nprint(cl)\nmx = max(cl.values())\nmn = min(cl.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=20) print(cl) mx = max(cl.values()) mn = min(cl.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3573.09it/s]\n</pre> <pre>{'GBGR': 2207.0092796092795, 'GBGW': 1574.1780861656403, 'GBG_': 2245.6238095238077, 'GGGG': 2065.6316957552262, 'GGGR': 2052.219608851188, 'GGRR': 3774.042140822139, 'GGRY': 2541.641269841269, 'GGWW': 2203.5236655224166, 'GGWY': 4598.104761904761, 'GGW_': 3827.514285714286, 'GGYW': 1998.2796889101228, 'GG_W': 3159.310780722547, 'GRBR': 2252.3125606823146, 'GRGY': 1961.2073260073257, 'GRWG': 3434.115731505299, 'GRYY': 1769.6720992921016, 'GR_Y': 2458.6663362781, 'GR_Y2': 3750.974603174604, 'GR__': 2287.758730158729, 'GWRG': 2460.425432737198, 'GYGG': 2512.0908424908425, 'GYYY': 1082.0915750915751, 'GY__': 1348.5477329496612, 'G_GW': 2936.1425267542913, 'G_R_': 3429.2739926739923, 'G_W_': 2107.469050754098, 'G___': 2127.2349206349195, 'G___big': 440.0, 'G___small': 1357.2765347758534, 'Q': 3506.6336134453786, 'RWGY': 2859.332112332112, 'RWWG': 2268.550438842203, 'WBGG': 2896.1205924510273, 'WBGW': 2433.333613445378, 'WBYG': 1977.0355670473316, 'WGBB': 2559.064886091109, 'WGGB': 2960.0190476190473, 'WGWB': 3741.2707061969318, 'WG_R': 3544.1333333333337, 'WRBB': 3554.813675213675, 'WRRY': 3153.2702075702073, 'WRR_': 1459.0539682539682, 'WRWR': 3188.4784241901884, 'WR__': 2500.955555555555, 'WWBG': 2036.6218377769462, 'WYGG': 2725.1190476190477, 'W___': 2336.6073260073267, 'YGWW': 4164.021611721611, 'YGWY': 2041.505738705739, 'YWGW': 2504.1366234788234, 'YWWW': 2304.5686202686197, 'YWW_': 2371.849188204297, 'YW__': 176.0, 'YYGG': 3941.017740429505, 'YYGGmid': 3978.1587301587306, 'YYGGright': 2585.841391941392, 'YYGW': 2942.4609600925396, 'YYRB': 2324.445981469511, 'YYRG': 2314.7781799899453, 'YYWR': 2196.252000287295, 'YYYY': 1173.542857142857, 'YYY_': 1451.0821205745692, 'YY_R': 2608.8452541610436, 'YY_W': 3165.41684981685, 'YY__': 2165.776312576312, 'Y_WY': 3077.7333333333327, 'Y__W': 1355.0833598705335, 'Y___': 2157.622222222223, '_RYG': 885.6630036630038, '_R__': 3843.0485958485956, '_WGG': 3243.3761904761905, '_WWW': 1688.0676434676436, '_WWY': 3225.482539682539, '_WYG': 2279.3990591108236, '_WYW': 3684.37142857143, '_W_Y': 2395.1028197945843, '_W__': 3375.862184873949, '_Y__': 2151.667587957515, '__BB': 1831.7949074070343, '__W_': 2927.860263403607, '____almost': 2504.1190835308475, '____bm': 2888.322842445042, '____bot': 1918.2603174603173, '____brood': 3139.037484737485, '____corner': 3197.7706444286337, '____pale': 4135.756532356533, '____right': 1686.4830900989923, '____topleft': 2661.486524002313, '____topright': 1843.6328641362072}\n</pre> <p>We can also calculate the temporal betweenness centrality, which is based on the number of shortest time-respecting paths between pairs of nodes that pass through a given node. Again, this centrality score is sensitive to the time scale parameter $\\delta$.</p> In\u00a0[\u00a0]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=60)\nprint(bw)\nmx = max(bw.values())\nmn = min(bw.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=60) print(bw) mx = max(bw.values()) mn = min(bw.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3475.66it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 89/89 [00:03&lt;00:00, 27.00it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7fdf20a03640&gt;, {'GBGR': 20.192212842427075, 'WGBB': 194.79309833949083, 'WRBB': 365.05013895123216, 'G___': 57.80632230642795, '_WYW': 427.3675796732633, '____topright': 10.760025336141013, 'YYGGmid': 663.4450747248108, '__W_': 46.375038482274306, 'GG_W': 292.080282213412, '_W__': 428.33207844162627, 'WBGW': 71.89857589572318, 'GR__': 64.19763457586924, 'RWWG': 83.25286865190012, '____almost': 134.89554914241063, 'GGGG': 78.97281365765863, 'YYGW': 319.0275353843234, 'YWGW': 84.52883527311734, 'YYWR': 139.62781952597214, 'YYRG': 30.06998326775235, 'WRWR': 130.49639766193505, 'WYGG': 274.1787721126864, 'GGYW': 9.54474098670821, 'GYGG': 206.18561458924665, 'GGWY': 1080.0676471347801, 'G_W_': 30.258200815352502, '_W_Y': 88.46660448533098, '_R__': 724.7535183751095, 'WBGG': 184.56469995815524, 'Y___': 124.00746952439442, '____brood': 261.05135853722055, 'WRRY': 227.56794665132307, '_WWY': 258.17798469631225, 'Y_WY': 168.0214751986637, 'GGWW': 127.47912860736434, 'YYGG': 452.6097076570282, 'YY_W': 372.5488526120025, '____topleft': 72.04751294375436, 'GBG_': 156.55265249530558, 'G_GW': 322.43708957585955, 'YGWY': 17.697241798229907, 'GRBR': 71.17718734804407, 'GGGR': 106.77684001312716, 'GGW_': 756.8587346464093, '____bm': 155.14819522566728, 'WGWB': 353.62165711237867, 'WWBG': 210.3370212595935, 'GRYY': 63.34672574396869, '_WWW': 59.796937914791975, '____right': 6.536713311055403, '_WYG': 159.5168700848977, 'YY__': 48.63844749559088, 'GRGY': 45.365480292377676, 'G_R_': 90.00180925262697, 'Q': 554.8667166042984, 'YYGGright': 329.28472257372005, 'WR__': 38.99166576434191, '____corner': 502.8870906126399, 'WG_R': 269.7153804058385, 'GR_Y2': 337.26045226613337, 'GWRG': 218.44745266674752, 'G___small': 20.205088001429456, 'YGWW': 535.3204311320455, 'YY_R': 143.38496654670294, 'RWGY': 235.07340157680488, 'WGGB': 131.96062903943462, '_WGG': 318.5137155129991, '__BB': 79.02021455742683, 'WBYG': 26.79640022964187, 'GRWG': 385.8105700686363, 'W___': 115.05159194927882, 'GGRR': 487.43937337734934, 'Y__W': 1.0294117647058814, 'GY__': 35.364487473310994, 'GR_Y': 23.23800388929457, 'YWW_': 116.98999358694506, 'YYRB': 32.66941405832229, '_Y__': 25.129282093002608, 'GBGW': 49.133677074004986, 'YYY_': 86.25984566814704, 'GGRY': 269.8419665751779, 'YWWW': 39.83384050331751, '____pale': 591.7102550688354, '____bot': 7.010335960335962, 'GYYY': 9.375127968877965, '_RYG': 5.108461302211301, 'WRR_': 74.76533132490208, 'YYYY': 1.000000000000001, 'G___big': -1.7708057242771247e-14, 'YW__': 0.0})\n</pre> In\u00a0[\u00a0]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=20)\nprint(bw)\nmx = max(bw.values())\nmn = min(bw.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=20) print(bw) mx = max(bw.values()) mn = min(bw.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3813.91it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 89/89 [00:01&lt;00:00, 69.84it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7fdf20ed9b40&gt;, {'GBGR': 271.0549203258132, 'YY__': 260.787489965592, '_WYG': 394.1302318596431, '____right': 28.503246753246753, 'Q': 1457.263110413932, 'GGRR': 393.6459799032444, 'GGGR': 201.48208556149757, 'YYGGright': 534.66060053214, 'YY_R': 266.91765439796467, 'Y___': 172.67107899804276, '____corner': 551.646068862101, 'YGWW': 1201.1725191494913, 'WG_R': 512.4899073911774, '_WGG': 662.2060823813118, 'YWGW': 71.94722222222224, '____bm': 520.5037887625123, '__BB': 146.4024424420817, '_Y__': 116.65703669247497, 'WBYG': 337.50697274935305, 'YYWR': 346.0394146748694, '_W_Y': 126.7397860593513, 'WBGG': 100.16123039327377, 'Y_WY': 709.6990969778257, '_W__': 888.9702395101842, 'GGWW': 252.45108178976466, 'RWGY': 400.3435250525273, 'WR__': 324.7003673342413, 'G_R_': 74.0687563696638, '____bot': 18.876190476190477, '____pale': 1160.042127920021, '____almost': 586.5742800306991, '____topright': 6.242857142857144, 'YYGG': 900.9820998851815, '_WYW': 910.3151884148607, 'GGW_': 1229.7209102391769, 'G_GW': 411.33446741036244, 'YYGGmid': 941.7798494844893, 'GG_W': 893.2237821543014, 'WWBG': 82.09047619047621, 'GRWG': 765.7519205139172, 'WGGB': 562.7259479161665, 'WRWR': 79.9309806206866, '____topleft': 31.47539682539684, 'GGRY': 1009.5761263646133, 'GGWY': 2510.3962123782903, 'RWWG': 238.21048955595802, 'GBG_': 219.31044140486634, 'WGWB': 651.4299970278146, '_R__': 1516.87808629868, 'GGYW': 96.16713560885782, 'WGBB': 458.9464625746425, 'GRBR': 229.0634357985618, '____brood': 241.461111111111, 'G___small': 2.0000000000000027, 'GR_Y2': 782.0649724285778, 'W___': 307.82509532385853, 'YYGW': 851.6365545426578, 'GY__': 74.0, 'GBGW': 47.5015406162465, 'YYY_': 148.44444444444446, '__W_': 184.20506454409792, 'YYRB': 213.21211161607084, 'WYGG': 427.62927891499254, 'WRBB': 343.03298248682995, 'WRRY': 409.20603349701526, 'YWWW': 8.403968253968255, 'WBGW': 28.814786967418545, 'GR_Y': 24.047859363598853, 'YWW_': 32.92341269841275, '_WWY': 660.9893002248847, 'YGWY': 172.38878675703566, 'GWRG': 172.5340550134477, 'GYGG': 596.7332954372962, 'GRYY': 221.22555230251604, '_RYG': 16.17857142857143, 'YY_W': 444.00904725283243, 'GRGY': 140.32892318821007, 'G___': 111.45865644159763, 'GR__': 91.98653846153846, 'GGGG': 148.8203370642651, 'G_W_': 13.97619047619047, '_WWW': 49.37142857142858, 'YYRG': 13.01755106156194, 'WRR_': 67.70574974670724, 'Y__W': 0.9999999999999983, 'YYYY': 2.0, 'GYYY': 0.0, 'G___big': 1.5154544286133387e-14, 'YW__': -1.4210854715202004e-14})\n</pre>"},{"location":"tutorial/temporal_graphs/#temporal-graph-analysis","title":"Temporal Graph Analysis\u00b6","text":""},{"location":"tutorial/temporal_graphs/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/temporal_graphs/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In this tutorial we will introduce the representation of temporal graph data using the <code>TemporalGraph</code> class and how such data can be used to calculate shortest time respecting paths between nodes as well temporal node cemtralities.</p>"},{"location":"tutorial/temporal_graphs/#extracting-time-respecting-paths-in-temporal-networks","title":"Extracting Time-Respecting Paths in Temporal Networks\u00b6","text":""},{"location":"tutorial/temporal_graphs/#reading-and-writing-temporal-graph-data","title":"Reading and writing temporal graph data\u00b6","text":""},{"location":"tutorial/temporal_graphs/#temporal-centralities-in-empirical-temporal-networks","title":"Temporal Centralities in Empirical Temporal Networks\u00b6","text":"<p><code>pathpyG</code>'s ability to calculate (shortest) time-respecting paths enables us to calulate different notions of temporal centralities for nodes in empirial temporal networks. We can read an empirical temporal graph based on CSV data, where each line contains the source, target, and timestamp of an edge as comma-separated value:</p>"},{"location":"tutorial/trp_higher_order/","title":"Higher-Order Models for Time-Respecting Paths","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\n</pre> import pathpyG as pp In\u00a0[2]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nprint(t)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) print(t) <pre>Temporal Graph with 4 nodes, 6 unique edges and 10 events in [1.0, 6.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> <p>To better understand this temporal graph, we can again create a directed acyclic graph that represents the topology of time-respecting paths:</p> In\u00a0[3]: Copied! <pre>e_i = pp.algorithms.lift_order_temporal(t, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\npp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]);\n</pre> e_i = pp.algorithms.lift_order_temporal(t, delta=1) dag = pp.Graph.from_edge_index(e_i) pp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 930.41it/s]\n</pre> <p>For $\\delta=1$, we again have the following time-respecting paths:</p> <p>Length one: a -&gt; b b -&gt; a b -&gt; c c -&gt; b c -&gt; d d -&gt; c Length two: a -&gt; b -&gt; a (twice) b -&gt; a -&gt; b a -&gt; b -&gt; c b -&gt; c -&gt; b c -&gt; b -&gt; a d -&gt; c -&gt; d Length three: a -&gt; b -&gt; a -&gt; b b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b b -&gt; c -&gt; b -&gt; a Length four: a -&gt; b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b -&gt; a</p> <p>As you can see, these time-respecting paths are actually very similar to the paths data that we have previously represented using the <code>PathData</code> object. In fact, we could - in theory - first extract all time-respecting paths of all lengths, add them to a <code>PathData</code> object and then use the <code>MultiOderModel</code> class to generate higher-order De Bruijn graph models of all orders. In the example above, since we have paths of length one to four, we could create higher-order models with orders from one to four.</p> <p>However, this approach would not be efficient for large temporal graphs, as it is computationally expensive to calculate all possible time-respecting paths as well as subpaths of length $k$, especially for larger values of $\\delta$. To avoid this bottleneck, <code>pathpyG</code> uses a smarter, GPU-based algorithm to calculate time-respecting paths of length $k$ that are needed for a given order $k$.</p> <p>For the example above, we can generate all higher-order models up to order four as follows:</p> In\u00a0[4]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=4)\n\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=4)  print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 6 nodes and 4 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Remember that in a $k$-th order model nodes capture paths of length $k-1$, while edges capture paths of length $k$.</p> <p>This implies that the first-order model has four nodes and six edges, which simply corresponds to the time-aggregated weighted graph for our example temporal network.</p> In\u00a0[5]: Copied! <pre>print(m.layers[1])\npp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes]);\n</pre> print(m.layers[1]) pp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes]); <pre>Undirected graph with 4 nodes and 6 (directed) edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 1])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>For the second-order model, we have six nodes, which map to the six different edges (each edge trivially being a time-respecting path of length one) of the temporal graph. The six edges in the second-order model represent the six different time-respecting paths of length two (see above). Since the time-respecting path $a \\rightarrow b \\rightarrow a$  occurs twice at different times, we have one edge with weight two.</p> In\u00a0[6]: Copied! <pre>print(m.layers[2])\nprint(m.layers[2].data.edge_weight)\npp.plot(m.layers[2], node_label=m.layers[2].mapping.node_ids.tolist());\n</pre> print(m.layers[2]) print(m.layers[2].data.edge_weight) pp.plot(m.layers[2], node_label=m.layers[2].mapping.node_ids.tolist()); <pre>Directed graph with 6 nodes and 6 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\ntensor([2., 1., 1., 1., 1., 1.])\n</pre> <p>For the third-oder mode, we have four edges representing the four diffeerent time-respecting paths of length three in the temporal graph above:</p> In\u00a0[7]: Copied! <pre>print(m.layers[3])\npp.plot(m.layers[3], node_label=m.layers[3].mapping.node_ids.tolist());\n</pre> print(m.layers[3]) pp.plot(m.layers[3], node_label=m.layers[3].mapping.node_ids.tolist()); <pre>Directed graph with 6 nodes and 4 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>And finally, for the model with order $k=4$ we only have two edges, representing the two time-respecting paths $a \\rightarrow b \\rightarrow a \\rightarrow b \\rightarrow a$ and $a \\rightarrow b \\rightarrow c \\rightarrow b \\rightarrow a$:</p> In\u00a0[8]: Copied! <pre>print(m.layers[4])\npp.plot(m.layers[4], node_label=m.layers[4].mapping.node_ids.tolist());\n</pre> print(m.layers[4]) pp.plot(m.layers[4], node_label=m.layers[4].mapping.node_ids.tolist()); <pre>Directed graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Intuitively, since in our example there are no time-respecting paths longer than four, if we were to generate a multi-order model with De Bruijn graphs with orders larger than four, those graphs cannot contain any edges. We see this in the following example. The first-order graph is simply the time-aggregated weighted graph, i.e. the number of nodes is equal to the number of nodes in the temporal graph and the number of edges is equal to the number of different time-stamped edges. In each graph of order $k&gt;1$, the number of nodes corresponds to the number of edges in the graph with order $k-1$, since each of those nodes corresponds to a time-respecting path of length $k-1$, which are represented by edges in a $k-1$-th order gaph. This implies that the graph with order five has two nodes, which are the two time-respecting paths of length four. Those nodes are not connected since there is no time-respecting path with length five.</p> In\u00a0[9]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=5)\n\nprint(m.layers[4])\nprint(m.layers[5])\npp.plot(m.layers[5], node_label=m.layers[5].mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=5)  print(m.layers[4]) print(m.layers[5]) pp.plot(m.layers[5], node_label=m.layers[5].mapping.node_ids.tolist()); <pre>Directed graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nUndirected graph with 2 nodes and 0 (directed) edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2, 5])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([0])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[10]: Copied! <pre>t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False)\nprint(t_ants)\n</pre> t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False) print(t_ants) <pre>Temporal Graph with 89 nodes, 1298 unique edges and 3822 events in [0.0, 1438.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3822])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3822])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3822])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[11]: Copied! <pre>t_email = pp.io.read_csv_temporal_graph('../data/manufacturing_email.tedges', header=False)\nprint(t_email)\n</pre> t_email = pp.io.read_csv_temporal_graph('../data/manufacturing_email.tedges', header=False) print(t_email) <pre>Temporal Graph with 167 nodes, 6501 unique edges and 165854 events in [1262454016.0, 1285884544.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([165854])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([165854])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([165854])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[12]: Copied! <pre>t_sp = pp.io.read_csv_temporal_graph('../data/sociopatterns_highschool_2013.tedges', header=False)\nprint(t_sp)\n</pre> t_sp = pp.io.read_csv_temporal_graph('../data/sociopatterns_highschool_2013.tedges', header=False) print(t_sp) <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 t_sp = pp.io.read_csv_temporal_graph('../data/sociopatterns_highschool_2013.tedges', header=False)\n      2 print(t_sp)\n\nFile /workspaces/pathpyG/src/pathpyG/io/pandas.py:399, in read_csv_temporal_graph(filename, sep, header, is_undirected, timestamp_format, time_rescale, **kwargs)\n    397     df = pd.read_csv(filename, header=0, sep=sep)\n    398 else:\n--&gt; 399     df = pd.read_csv(filename, header=None, sep=sep)\n    400 return df_to_temporal_graph(df, is_undirected=is_undirected, timestamp_fromat=timestamp_format, time_rescale=time_rescale, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211, in deprecate_kwarg.&lt;locals&gt;._deprecate_kwarg.&lt;locals&gt;.wrapper(*args, **kwargs)\n    209     else:\n    210         kwargs[new_arg_name] = new_arg_value\n--&gt; 211 return func(*args, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper(*args, **kwargs)\n    325 if len(args) &gt; num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--&gt; 331 return func(*args, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\n    935 kwds_defaults = _refine_defaults_read(\n    936     dialect,\n    937     delimiter,\n   (...)\n    946     defaults={\"delimiter\": \",\"},\n    947 )\n    948 kwds.update(kwds_defaults)\n--&gt; 950 return _read(filepath_or_buffer, kwds)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605, in _read(filepath_or_buffer, kwds)\n    602 _validate_names(kwds.get(\"names\", None))\n    604 # Create the parser.\n--&gt; 605 parser = TextFileReader(filepath_or_buffer, **kwds)\n    607 if chunksize or iterator:\n    608     return parser\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442, in TextFileReader.__init__(self, f, engine, **kwds)\n   1439     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1441 self.handles: IOHandles | None = None\n-&gt; 1442 self._engine = self._make_engine(f, self.engine)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735, in TextFileReader._make_engine(self, f, engine)\n   1733     if \"b\" not in mode:\n   1734         mode += \"b\"\n-&gt; 1735 self.handles = get_handle(\n   1736     f,\n   1737     mode,\n   1738     encoding=self.options.get(\"encoding\", None),\n   1739     compression=self.options.get(\"compression\", None),\n   1740     memory_map=self.options.get(\"memory_map\", False),\n   1741     is_text=is_text,\n   1742     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1743     storage_options=self.options.get(\"storage_options\", None),\n   1744 )\n   1745 assert self.handles is not None\n   1746 f = self.handles.handle\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    851 elif isinstance(handle, str):\n    852     # Check whether the filename is to be opened in binary mode.\n    853     # Binary mode does not support 'encoding' and 'newline'.\n    854     if ioargs.encoding and \"b\" not in ioargs.mode:\n    855         # Encoding\n--&gt; 856         handle = open(\n    857             handle,\n    858             ioargs.mode,\n    859             encoding=ioargs.encoding,\n    860             errors=errors,\n    861             newline=\"\",\n    862         )\n    863     else:\n    864         # Binary mode\n    865         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '../data/sociopatterns_highschool_2013.tedges'</pre> <p>To generate a <code>MultiOderModel</code> consisting of multiple layers of higher-order De Bruijn graph models, we can use the <code>MultiOderModel.from_temporal_graph</code> method. We can further specify the maximum order of the highest-order layer, as well as the maximum time difference $\\delta$ for time-respecting paths.</p> <p>For the ants, we consider time-respecting paths with a maximum time difference of 30 seconds up to length four:</p> In\u00a0[6]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 89 nodes and 947 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([89, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 947 nodes and 1780 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 1780 nodes and 2410 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 2410 nodes and 3292 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3292])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>For the E-Mail communication network, we use time-respecting paths up to length four with a maximum time difference of one hour.</p> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_email, delta=3600, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_email, delta=3600, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 167 nodes and 5784 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([167, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 5784 nodes and 25596 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([25596])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 25596 nodes and 47326 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([25596, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([47326])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 47326 nodes and 67801 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([47326, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([67801])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>And finally, for the largest data set from the Sociopatterns collaboration, we use a maximum time difference of 15 minutes. As you can see below, we can efficiently generate a 5-th order model despite using a temporal graph with more than 188,000 time-stamped edges and considering all time-respecting paths up to length five with a large maximum time difference. Thanks to the use of GPU-accelerated operations, creating such a model takes less than 12 seconds on an (old) RTX 2090 GPU.</p> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=900, max_order=5)\nprint(m.layers[1])\nprint(m.layers[5])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=900, max_order=5) print(m.layers[1]) print(m.layers[5]) <pre>Directed graph with 327 nodes and 5818 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([327, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5818])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 16307 nodes and 8712 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([16307, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([8712])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>How can we use such higher-order graph models for graph learning tasks? We will demonstrate this in the next unit of our tutorial.</p>"},{"location":"tutorial/trp_higher_order/#higher-order-models-for-time-respecting-paths-in-temporal-graphs","title":"Higher-Order Models for Time-Respecting Paths in Temporal Graphs\u00b6","text":""},{"location":"tutorial/trp_higher_order/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/trp_higher_order/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In the previous tutorial, we have seen how we can use higher-order models to model paths in complex networks. In this example, paths were directly given in terms of sequences of nodes traversed by some process (like a random walk). We have further seen that higher-order De Bruijn graph models can be used to capture patterns that influence the causal topology of a complex network, i.e. which nodes can possibly influence each other via paths. The same is true for time-respecting paths in a temporal graph. Due to the fact that time-stamped edges need to occur in the correct temporal ordering (and within a given time interval based on the maximum time difference $\\delta$), the causal topology given by time-respecting paths can be very different from what we would expect from the (static) topology of links.</p> <p>In the following, we will show how we can easiy and efficiently construct higher-order models for time-respecting paths in a temporal graph. To illustrate this, we use the same toy example as before:</p>"},{"location":"tutorial/trp_higher_order/#constructing-higher-order-de-bruijn-graph-models-for-empirical-temporal-networks","title":"Constructing Higher-Order De Bruijn Graph Models for Empirical Temporal Networks\u00b6","text":"<p>Let us now use <code>pathpyG</code> to construcct higher-order De Bruijn graph models for time-respecting paths in empirical temporal network. For this, we first read a number of temporal graphs using <code>TemporalGraph.from_csv</code>. In the following, we use the following three publicly available data sets:</p> <ul> <li>Antenna interactions between ants in a colony (Blonder and Dornhaus, 2011)</li> <li>E-Mail exchanges in a manufacturing company (Nurek and Michalski, 2020)</li> <li>Face-to-face interactions in a highschool (Mastrandrea, Fournet, Barrat, 2015)</li> </ul>"},{"location":"tutorial/visualisation/","title":"Interactive Graph Visualisation","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\nimport torch\n</pre> import pathpyG as pp import torch <pre>Running on cpu\n</pre> <p>With these preparations complete, we are ready to construct our first graph. This is achieved through the <code>Graph.from_edge_list</code> constructor provided by <code>pathpyG</code>, a method that allows us to transform a list of edges into a basic graphical representation.</p> In\u00a0[\u00a0]: Copied! <pre>g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']])\npp.plot(g, node_label=list(g.mapping.node_ids), edge_color='gray')\n</pre> g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']]) pp.plot(g, node_label=list(g.mapping.node_ids), edge_color='gray') Out[\u00a0]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2c7432ca60&gt;</pre> <p>After successfully creating a simple graph using <code>pathpyG</code>, our next step is to examine its structure. This is a crucial part of the process as it gives us an initial understanding of the complexity and scale of our graph. By printing out the number of nodes and edges, we gain insight into the size and connectivity of the graph.</p> <p>Although it may seem unnecessary for this simple graph, it's good practice to gather information about the number of nodes and edges before attempting to visualize it. This preemptive step is crucial, especially when dealing with larger graphs. Visualizing extensive networks can be a time-consuming or even unfeasible task, depending on the sheer volume of elements that need to be represented. Therefore, understanding the graph's scale upfront helps in efficiently planning the visualization process and avoiding potential complications that could arise with larger datasets.</p> In\u00a0[3]: Copied! <pre>f'Our graph has {g.n} nodes and {g.m} edges.'\n</pre> f'Our graph has {g.n} nodes and {g.m} edges.' Out[3]: <pre>'Our graph has 3 nodes and 2 edges.'</pre> In\u00a0[4]: Copied! <pre>pp.plot(g)\n</pre> pp.plot(g) Out[4]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2c7432c3a0&gt;</pre> In\u00a0[5]: Copied! <pre>pp.plot(g,backend='matplotlib');\n</pre> pp.plot(g,backend='matplotlib'); In\u00a0[6]: Copied! <pre>pp.plot(g,backend='matplotlib',layout='fr')\n</pre> pp.plot(g,backend='matplotlib',layout='fr') Out[6]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b528eb550&gt;</pre> <p>Additionally, <code>pathpyG</code> offers the flexibility to incorporate custom layout algorithms. If you have developed your own method or have specific requirements for node positioning, you can directly provide the node coordinates to the visualization. This capability ensures that <code>pathpyG</code> can cater to a wide range of visualization needs, from simple and automatic layouts to highly customized and complex arrangements, making it a versatile tool in the field of data visualization.</p> In\u00a0[7]: Copied! <pre>layout = {'a':[0,0],'b':[1,1],\"c\":[2,2]}\npp.plot(g,backend='matplotlib',layout=layout)\n</pre> layout = {'a':[0,0],'b':[1,1],\"c\":[2,2]} pp.plot(g,backend='matplotlib',layout=layout) Out[7]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b52743af0&gt;</pre> In\u00a0[8]: Copied! <pre>style = {}\nstyle['node_color'] = (255,1,255) # RGB tuple\nstyle['edge_color'] = 'green'     # Color name as str\npp.plot(g,**style)\n</pre> style = {} style['node_color'] = (255,1,255) # RGB tuple style['edge_color'] = 'green'     # Color name as str pp.plot(g,**style) Out[8]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b52743880&gt;</pre> <p>In <code>pathpyG</code>, there are various methods for assigning styles to objects, each offering a different level of customization and control. A straightforward approach, as previously shown, involves using a single value, such as a color string (e.g., <code>'green'</code>) or an RGB tuple (e.g., <code>(255,1,255)</code>). Applying this single value uniformly alters the appearance of all elements within a specific category, providing a quick and easy way to set a general style. However, for more detailed styling, one can utilize a <code>list</code> of values. In this approach, each value in the <code>list</code> is associated with an element according to its index position. This method is particularly familiar and efficient when working with tensors, where the association of values to elements is often index-based.</p> <p>Additionally, a more tailored approach can be employed through the use of dictionaries. In this case, each element id is paired with a corresponding value in the <code>dict</code>. Elements not included in the dictionary are assigned default values, ensuring that every element is styled, albeit some with custom and others with default styles. The types of values that can be used in these styling methods are diverse, including strings, integers, floats, and tuples, each type depending on the specific styling parameter being adjusted. This flexibility in value types and assignment methods allows for a high degree of customization, enabling the creation of visually distinct and information-rich visualizations.</p> In\u00a0[9]: Copied! <pre>style = {}\nstyle['node_color'] = ['red', 'green','blue'] # list based approach\nstyle['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach\nstyle['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value\nstyle['edge_color'] = ['orange','#00FF00']    # hex based color\npp.plot(g,**style)\n</pre> style = {} style['node_color'] = ['red', 'green','blue'] # list based approach style['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach style['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value style['edge_color'] = ['orange','#00FF00']    # hex based color pp.plot(g,**style) Out[9]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b5279af20&gt;</pre> In\u00a0[10]: Copied! <pre>from matplotlib.pyplot import get_cmap\nmy_map = get_cmap()\nmy_map\n</pre> from matplotlib.pyplot import get_cmap my_map = get_cmap() my_map Out[10]: viridis  underbad over  In\u00a0[11]: Copied! <pre>style = {}\nstyle['edge_color'] = [1, 9]      # int values\n\nstyle['node_color'] = pp.algorithms.centrality.betweenness_centrality(g)\nstyle['node_cmap'] = my_map       # new color map from matplotlib for nodes\npp.plot(g,**style)\n</pre> style = {} style['edge_color'] = [1, 9]      # int values  style['node_color'] = pp.algorithms.centrality.betweenness_centrality(g) style['node_cmap'] = my_map       # new color map from matplotlib for nodes pp.plot(g,**style) Out[11]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b560a20b0&gt;</pre> In\u00a0[12]: Copied! <pre>pp.plot(g,filename='test_plot.html')\n</pre> pp.plot(g,filename='test_plot.html') Out[12]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b52743fa0&gt;</pre> In\u00a0[13]: Copied! <pre>n = pp.io.read_netzschleuder_graph('karate', '77')\n</pre> n = pp.io.read_netzschleuder_graph('karate', '77') <pre>Mapping node attributes based on node indices in column `index`\n</pre> In\u00a0[14]: Copied! <pre>pp.plot(n)\n</pre> pp.plot(n) Out[14]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b5279a5c0&gt;</pre> In\u00a0[15]: Copied! <pre>node_color = [n['node_groups',v].item() for v in n.nodes]\npp.plot(n, edge_color='gray',node_color=node_color)\n</pre> node_color = [n['node_groups',v].item() for v in n.nodes] pp.plot(n, edge_color='gray',node_color=node_color) Out[15]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f2b52743dc0&gt;</pre> In\u00a0[16]: Copied! <pre>t = pp.TemporalGraph.from_edge_list(\n        [\n            (\"a\", \"b\", 1),\n            (\"b\", \"c\", 5),\n            (\"c\", \"d\", 9),\n            (\"d\", \"a\", 9),\n            (\"a\", \"b\", 10),\n            (\"b\", \"c\", 10),\n        ]\n    )\n</pre> t = pp.TemporalGraph.from_edge_list(         [             (\"a\", \"b\", 1),             (\"b\", \"c\", 5),             (\"c\", \"d\", 9),             (\"d\", \"a\", 9),             (\"a\", \"b\", 10),             (\"b\", \"c\", 10),         ]     ) In\u00a0[17]: Copied! <pre>pp.plot(t)\n</pre> pp.plot(t) Out[17]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f2b5279afb0&gt;</pre> <p>Besides the standard formatting options available in <code>pathpyG</code>, temporal plots come with specific options tailored to their unique nature. These specialized settings allow for precise control over the time dimension of the visualization. With the <code>start</code> and <code>end</code> parameters, you can define the exact start time and end time of the simulation, effectively setting the temporal boundaries of your graph. This feature is crucial for focusing on a particular time frame within your dataset. Additionally, the <code>delta</code> option lets you adjust the progression speed through the time steps of your visualization. Here, a value of 1000 translates to a one-second interval, providing a way to calibrate the pace at which the temporal data unfolds. Moreover, the <code>interval</code> option offers the flexibility to either widen or narrow the time intervals considered in the visualization. This feature is particularly useful for either zooming in on finer time-scaled details or zooming out for a broader, more comprehensive view of the temporal dynamics in your network.</p> In\u00a0[18]: Copied! <pre>color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"}\npp.plot(t,node_color=color,start=-1,end=25,delta=1000)\n</pre> color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"} pp.plot(t,node_color=color,start=-1,end=25,delta=1000) Out[18]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7f2b527439d0&gt;</pre>"},{"location":"tutorial/visualisation/#interactive-graph-visualization","title":"Interactive Graph Visualization\u00b6","text":""},{"location":"tutorial/visualisation/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/visualisation/#motivation","title":"Motivation\u00b6","text":"<p>This tutorial is specifically designed to guide you through the process of visualizing your data using <code>pathpyG</code>, an advanced data visualization tool. Data visualization is a crucial aspect of data analysis and interpretation, allowing for the transformation of complex datasets into visually appealing and easy-to-understand formats. pathpyG excels in this area by providing a range of functionalities that cater to both beginners and advanced users. Throughout this tutorial, you will be introduced to the basic and advanced features of pathpyG, empowering you to effectively visualize your data. This will not only enhance your understanding of your data but also enable you to communicate your findings more effectively to others.</p> <p>Visualization is a core concept of <code>pathpyG</code> because it bridges the gap between raw data and meaningful visual representations. We, as humans, are wired to process visual information much more rapidly compared to text or audio. This innate ability enables us to quickly identify patterns, outliers, and trends in visual data. Data visualization leverages this capability by graphically representing data, thereby facilitating the swift interpretation of large and complex datasets. Interactive visualizations further this advantage by allowing users to directly engage with the data, exploring and analyzing it in an intuitive and insightful manner. Whether it's understanding the intricate details of microscopic structures or grasping the dynamics of global phenomena, visualizations are instrumental in helping researchers and analysts gain deeper insights and effectively communicate their findings.</p>"},{"location":"tutorial/visualisation/#learning-objectives","title":"Learning objectives\u00b6","text":"<p>In this tutorial, you will learn to master the art of creating simple yet powerful interactive visualizations using <code>pathpyG</code>. You will learn the nuances of customizing the style of your visualizations, enabling you to tailor them to your specific needs and preferences. This customization extends to the aesthetics, layout, and interactive elements, ensuring that your visualizations are not only informative but also engaging. Additionally, the tutorial covers the essential skills needed to save your visualizations in various formats, making it easier to share your work across different platforms and audiences. Lastly, a significant part of the tutorial is dedicated to creating temporal visualizations. These types of visualizations are particularly useful in understanding and presenting data that changes over time, offering dynamic insights into trends and patterns that static visualizations cannot capture. By the end of this tutorial, you will have a comprehensive understanding of how to effectively use pathpyG to create and customize a wide range of visualizations.</p>"},{"location":"tutorial/visualisation/#lets-get-started","title":"Let's Get Started\u00b6","text":"<p>To embark on our journey of visualizing data with <code>pathpyG</code>, the initial step involves initializing and loading the required modules, a crucial process that sets the foundation for our data visualization work. This preparation ensures that all necessary tools and functionalities from <code>pathpyG</code> are at our disposal.</p> <p>In anticipation of enhancing our graphs with additional attributes, we also include the <code>torch</code> package in our setup. <code>torch</code> is renowned for its robust capabilities in data processing and machine learning, and its inclusion allows us to enrich our graphs with more complex and informative attributes.</p>"},{"location":"tutorial/visualisation/#the-plot-function","title":"The <code>plot</code> Function\u00b6","text":"<p>The <code>plot</code> function in <code>pathpyG</code> stands out as the simplest and most direct method for creating visualizations. Designed to encapsulate all the plotting capabilities of <code>pathpyG</code> in a single command, it streamlines the process of generating quick and efficient plots. This functionality is particularly beneficial for users who seek immediate visual feedback from their data without delving into more complex coding. The only prerequisite for using this function is the <code>Graph</code> object, which serves as the foundation for the visualization. Moreover, when working within an interactive environment, such as a <code>Jupyter notebook</code>, the <code>plot</code> function is particularly powerful. In such settings, invoking the <code>plot</code> command will automatically generate and display an interactive visualization. This feature is particularly beneficial as it allows for immediate visual feedback, making it an ideal tool for exploratory data analysis where quick and efficient visualization is key.</p>"},{"location":"tutorial/visualisation/#kwargs-in-the-plot-function","title":"<code>kwargs</code> in the <code>plot</code> function\u00b6","text":"<p>In <code>pathpyG</code>, the customization of your plot is managed through keyword arguments (kwargs), where each customization is specified as a keyword followed by its corresponding value. This approach is what gives the <code>plot</code> function its remarkable flexibility, allowing it to adapt to a wide variety of plotting requirements. Whether you're aiming for a simple graph or a complex, multi-faceted visualization, the keyword arguments provide the tools to tailor your plot precisely to your needs.</p> <p>However, this wealth of options can be somewhat overwhelming for beginners, given the extensive range of available choices. But worry not, as we will guide you through the most essential and basic options, ensuring you have a solid foundation to start from. By mastering these fundamental aspects, you'll be well on your way to effectively utilizing <code>pathpyG</code>'s plot function, gradually building up to more advanced features as you gain confidence and expertise.</p>"},{"location":"tutorial/visualisation/#plotting-backends","title":"Plotting Backends\u00b6","text":"<p>In the diverse world of data visualization, there is no one-size-fits-all technique, as different scenarios demand different approaches. Recognizing this, <code>pathpyG</code> offers a variety of plotting backends, each tailored for specific use cases, ensuring that users have the right tools for their unique requirements.</p> <ul> <li><p>For instance, <code>pathpyG</code> facilitates interactive visualizations, as previously demonstrated, which are immensely useful for dynamic exploration of data. This feature is particularly beneficial in educational settings, exploratory data analysis, and communication, where interaction with the data can lead to deeper understanding and insights.</p> </li> <li><p>On the other hand, <code>pathpyG</code> also integrates with matplotlib, a widely recognized package for creating static plots. This is especially efficient for visualizing large graphs where interactivity might be less critical.</p> </li> <li><p>Additionally, <code>pathpyG</code> caters to the academic and publication community by offering tikz plots, which are highly valued in formal publications for their precision and quality. (Note that for generating tikz plots, currently, the installation of <code>latexmk</code> is necessary to produce the corresponding <code>.tex</code> and <code>.pdf</code> files.)</p> </li> </ul> <p>Let's generate a static png image using the <code>matplotlib</code> backend:</p>"},{"location":"tutorial/visualisation/#quick-introduction-to-layouts","title":"Quick Introduction to Layouts\u00b6","text":"<p>An important aspect to consider is the layout of your plot. The previous plot we generated is static, meaning the positions of the nodes are fixed and do not change. This fixed arrangement presents a unique challenge, as finding the optimal placement for nodes and edges to convey information effectively is not a straightforward task. To assist with this, <code>pathpyG</code> supports simple layout functions designed to create visually appealing and coherent graphs. By default, nodes are assigned random locations for computational efficiency. However, this arrangement can be significantly improved with the use of the <code>layout</code> keyword in the <code>plot</code> function, allowing for more structured and meaningful representations of your graph.</p> <p>For example, <code>pathpyG</code> includes support for sophisticated layout algorithms, such as the Fruchterman-Reingold algorithm for force-directed layouts. This can be activated using the <code>\"fr\"</code> option, which applies a physics-based approach to arrange nodes and edges in a way that visually represents their relational dynamics. Such force-directed layouts are particularly useful for highlighting the underlying structure and relationships within the data.</p>"},{"location":"tutorial/visualisation/#styling-your-plots","title":"Styling Your Plots\u00b6","text":"<p>To enhance the effectiveness and appeal of our visualizations in <code>pathpyG</code>, styling of our plots becomes a key aspect. The ability to style your plots is not just about aesthetic appeal; it is about effectively conveying more information through visual means. Depending on the type of plot you are working with, there are multiple styling options available to tailor your visualization to your specific needs. The fundamental principle here is that the styles applied to your plot should not be dependent on the data of your model. In other words, you should be able to present the same data in different styles, depending on the context or the information you wish to highlight. To facilitate this, styles are organized in dictionaries, which are then incorporated into the <code>plot</code> function.</p> <p>For network plots, where the focus is on the topology of the data, there are several basic styling options you can adjust, including the <code>size</code>, <code>color</code>, and <code>opacity</code> of each node and edge object. These options provide a foundational level of customization, allowing you to make your graph more readable and visually appealing. However, the styling possibilities extend further, varying according to the specific kind of plot you are creating. To distinguish between the styling of edges and nodes, a prefix corresponding to each element type is added to the keyword, such as <code>node_size</code>. This distinction ensures that your styling choices are accurately applied to the intended elements of the graph, further enhancing the clarity and effectiveness of your visualization.</p>"},{"location":"tutorial/visualisation/#colormaps","title":"Colormaps\u00b6","text":"<p>In many instances, particularly when visualizing numerical data, the use of color gradients to represent values can greatly enhance the clarity and effectiveness of a plot. <code>pathpyG</code> addresses this need through its native support for <code>colormaps</code>. When the colors of node or edge elements are defined using <code>int</code> or <code>float</code> values, <code>pathpyG</code> automatically assigns colors based on these colormaps, effectively interpolating the correct color value for each element. By default, <code>pathpyG</code> offers a simple colormap that transitions from red to green, sufficient for many basic visualization needs. However, for more customized or advanced styling, users have the option to utilize any colormap from the extensive color palettes provided by <code>matplotlib</code> or <code>seaborn</code>. These libraries offer a wide range of color schemes, enabling you to select the perfect palette to convey the nuances of your data.</p>"},{"location":"tutorial/visualisation/#saving-plots","title":"Saving Plots\u00b6","text":"<p>In <code>pathpyG</code>, sharing your plots or incorporating them into various mediums is facilitated by the ability to save them as files. This functionality is conveniently accessed by simply adding the <code>filename</code> keyword within the plot function. When you specify a filename, <code>pathpyG</code> assigns the appropriate backend to use based on the file extension provided. For instance, if you save your file with an <code>.html</code> extension, <code>pathpyG</code> generates a standalone interactive visualization, perfect for web applications or interactive presentations. On the other hand, if you choose to save your plot as a <code>.png</code> file, a static image is created using the <code>matplotlib</code> backend, ideal for including in documents, reports, or presentations where interactivity is not required. Additionally, for those seeking to incorporate plots into academic papers or publications, saving the file with a <code>.tex</code> extension activates the <code>tikz</code> backend. This feature is particularly beneficial for creating high-quality, publication-ready figures.</p>"},{"location":"tutorial/visualisation/#larger-network-visualizations","title":"Larger Network Visualizations\u00b6","text":"<p>Having covered the basics, we are now well-prepared to venture into the realm of larger network visualizations using <code>pathpyG</code>.</p>"},{"location":"tutorial/visualisation/#temporal-network-visualizations","title":"Temporal Network Visualizations\u00b6","text":"<p>In the realm of network analysis, <code>pathpyG</code> particularly excels in handling and visualizing temporal graphs, a domain where both nodes and edges can change their properties over time. This dynamic aspect of temporal graphs adds a layer of complexity and richness to data analysis, capturing the evolution of relationships and properties within the network. <code>pathpyG</code> supports this advanced functionality, allowing users to apply the same versatile <code>plot</code> function used for static graphs to <code>TemporalGraph</code> data structures. This integration means that all the customization options, styling features, and layout choices previously explored for static network visualizations are also applicable to temporal graphs. The ability to utilize these tools in the context of temporal data opens up a world of possibilities for in-depth analysis and insightful visualization of networks where time plays a crucial role. Whether you're tracking changes in social networks, analyzing traffic patterns, or studying dynamic biological systems, <code>pathpyG</code>'s capabilities in temporal network visualization provide a powerful tool to uncover and illustrate the temporal dynamics inherent in these complex systems.</p>"},{"location":"tutorial/archive/_higher_order_scalability/","title":"higher order scalability","text":"In\u00a0[\u00a0]: Copied! <pre>import time\nimport torch\n\nimport pathpy as pp2\nimport pathpyG as pp\nfrom matplotlib import pyplot as plt\n</pre> import time import torch  import pathpy as pp2 import pathpyG as pp from matplotlib import pyplot as plt <pre>Running on cuda\n</pre> In\u00a0[2]: Copied! <pre>p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\n</pre> p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') In\u00a0[3]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(p, max_order=2)\ng2 = m.layers[2]\nprint(g2.n)\nprint(g2.m)\nprint(g2['edge_weight'].sum().item())\n</pre> m = pp.MultiOrderModel.from_DAGs(p, max_order=2) g2 = m.layers[2] print(g2.n) print(g2.m) print(g2['edge_weight'].sum().item()) <pre>646\n1139\n634916.0\n</pre> In\u00a0[4]: Copied! <pre>for e in g2.edges:\n    print(e, g2['edge_weight', e[0], e[1]])\n</pre> for e in g2.edges:     print(e, g2['edge_weight', e[0], e[1]]) <pre>(('Acton Town', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(2399., device='cuda:0')\n(('Acton Town', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(155., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(398., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(96., device='cuda:0')\n(('Acton Town', 'South Ealing'), ('South Ealing', 'Northfields')) tensor(1149., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(481., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(113., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(8., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(117., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(9., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(173., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(24., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(112., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(5., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2121., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1453., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(135., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(2147., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(234., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(5062., device='cuda:0')\n(('Alperton', 'Park Royal'), ('Park Royal', 'North Ealing')) tensor(232., device='cuda:0')\n(('Alperton', 'Sudbury Town'), ('Sudbury Town', 'Sudbury Hill')) tensor(117., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(1., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(180., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(46., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(665., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1404., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(3., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(33., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(56., device='cuda:0')\n(('Angel', 'Old Street'), ('Old Street', 'Moorgate')) tensor(2150., device='cuda:0')\n(('Archway', 'Highgate'), ('Highgate', 'East Finchley')) tensor(818., device='cuda:0')\n(('Archway', 'Tufnell Park'), ('Tufnell Park', 'Kentish Town')) tensor(1248., device='cuda:0')\n(('Arnos Grove', 'Bounds Green'), ('Bounds Green', 'Wood Green')) tensor(503., device='cuda:0')\n(('Arnos Grove', 'Southgate'), ('Southgate', 'Oakwood')) tensor(207., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(71., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(20., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(78., device='cuda:0')\n(('Arsenal', 'Holloway Road'), ('Holloway Road', 'Caledonian Road')) tensor(87., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(2561., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(104., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(669., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(2627., device='cuda:0')\n(('Baker Street', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Paddington')) tensor(5427., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(1379., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(157., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(639., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(290., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(463., device='cuda:0')\n(('Baker Street', 'Great Portland Street'), ('Great Portland Street', 'Euston Square')) tensor(4311., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(126., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(1391., device='cuda:0')\n(('Baker Street', \"Regent's Park\"), (\"Regent's Park\", 'Oxford Circus')) tensor(662., device='cuda:0')\n(('Baker Street', \"St. John's Wood\"), (\"St. John's Wood\", 'Swiss Cottage')) tensor(159., device='cuda:0')\n(('Balham', 'Clapham South'), ('Clapham South', 'Clapham Common')) tensor(1132., device='cuda:0')\n(('Balham', 'Tooting Bec'), ('Tooting Bec', 'Tooting Broadway')) tensor(637., device='cuda:0')\n(('Bank / Monument', 'Cannon Street'), ('Cannon Street', 'Mansion House')) tensor(274., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(110., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(2194., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(2353., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(522., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(264., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Borough')) tensor(805., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(3545., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(279., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(301., device='cuda:0')\n(('Bank / Monument', \"St. Paul's\"), (\"St. Paul's\", 'Chancery Lane')) tensor(3344., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(116., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(2188., device='cuda:0')\n(('Barbican', 'Farringdon'), ('Farringdon', \"King's Cross St. Pancras\")) tensor(2027., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1800., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(2., device='cuda:0')\n(('Barking', 'East Ham'), ('East Ham', 'Upton Park')) tensor(9., device='cuda:0')\n(('Barking', 'Upminster'), ('Upminster', 'Upminster Bridge')) tensor(561., device='cuda:0')\n(('Barking', 'Upney'), ('Upney', 'Becontree')) tensor(684., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(20., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Canning Town')) tensor(288., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Plaistow')) tensor(7., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Stratford')) tensor(2122., device='cuda:0')\n(('Barkingside', 'Fairlop'), ('Fairlop', 'Hainault')) tensor(201., device='cuda:0')\n(('Barkingside', 'Newbury Park'), ('Newbury Park', 'Gants Hill')) tensor(448., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1088., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(94., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(6., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(150., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(340., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(182., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(316., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(634., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(114., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(23., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(101., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(113., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(414., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(40., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(82., device='cuda:0')\n(('Becontree', 'Dagenham Heathway'), ('Dagenham Heathway', 'Dagenham East')) tensor(169., device='cuda:0')\n(('Becontree', 'Upney'), ('Upney', 'Barking')) tensor(623., device='cuda:0')\n(('Belsize Park', 'Chalk Farm'), ('Chalk Farm', 'Camden Town')) tensor(1156., device='cuda:0')\n(('Belsize Park', 'Hampstead'), ('Hampstead', 'Golders Green')) tensor(771., device='cuda:0')\n(('Bermondsey', 'Canada Water'), ('Canada Water', 'Canary Wharf')) tensor(1026., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(320., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Borough')) tensor(110., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(1094., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(11., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2252., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1505., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(119., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(253., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(144., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(3210., device='cuda:0')\n(('Blackfriars', 'Mansion House'), ('Mansion House', 'Cannon Street')) tensor(255., device='cuda:0')\n(('Blackfriars', 'Temple'), ('Temple', 'Embankment')) tensor(384., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(224., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(152., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2570., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(1699., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(92., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(999., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(174., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(282., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(225., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Victoria')) tensor(858., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Westminster')) tensor(1524., device='cuda:0')\n(('Bond Street', 'Marble Arch'), ('Marble Arch', 'Lancaster Gate')) tensor(835., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(226., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(519., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(93., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(3138., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(283., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(679., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(86., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(845., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(103., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(38., device='cuda:0')\n(('Boston Manor', 'Northfields'), ('Northfields', 'South Ealing')) tensor(1179., device='cuda:0')\n(('Boston Manor', 'Osterley'), ('Osterley', 'Hounslow East')) tensor(819., device='cuda:0')\n(('Bounds Green', 'Arnos Grove'), ('Arnos Grove', 'Southgate')) tensor(350., device='cuda:0')\n(('Bounds Green', 'Wood Green'), ('Wood Green', 'Turnpike Lane')) tensor(630., device='cuda:0')\n(('Bow Road', 'BromleyByBow'), ('BromleyByBow', 'West Ham')) tensor(13., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(225., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(5., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stratford')) tensor(10., device='cuda:0')\n(('Brent Cross', 'Golders Green'), ('Golders Green', 'Hampstead')) tensor(680., device='cuda:0')\n(('Brent Cross', 'Hendon Central'), ('Hendon Central', 'Colindale')) tensor(382., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(9., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Oval')) tensor(167., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(147., device='cuda:0')\n(('BromleyByBow', 'Bow Road'), ('Bow Road', 'Mile End')) tensor(87., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Barking')) tensor(16., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(3., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Plaistow')) tensor(4., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Stratford')) tensor(9., device='cuda:0')\n(('Buckhurst Hill', 'Loughton'), ('Loughton', 'Debden')) tensor(468., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(6., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'South Woodford')) tensor(934., device='cuda:0')\n(('Burnt Oak', 'Colindale'), ('Colindale', 'Hendon Central')) tensor(218., device='cuda:0')\n(('Caledonian Road', 'Holloway Road'), ('Holloway Road', 'Arsenal')) tensor(93., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(36., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(139., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(155., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(34., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(14., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(39., device='cuda:0')\n(('Camden Town', 'Chalk Farm'), ('Chalk Farm', 'Belsize Park')) tensor(1083., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(1459., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', 'Warren Street')) tensor(1639., device='cuda:0')\n(('Camden Town', 'Kentish Town'), ('Kentish Town', 'Tufnell Park')) tensor(1335., device='cuda:0')\n(('Canada Water', 'Bermondsey'), ('Bermondsey', 'London Bridge')) tensor(1333., device='cuda:0')\n(('Canada Water', 'Canary Wharf'), ('Canary Wharf', 'North Greenwich')) tensor(765., device='cuda:0')\n(('Canary Wharf', 'Canada Water'), ('Canada Water', 'Bermondsey')) tensor(1104., device='cuda:0')\n(('Canary Wharf', 'North Greenwich'), ('North Greenwich', 'Canning Town')) tensor(600., device='cuda:0')\n(('Canning Town', 'North Greenwich'), ('North Greenwich', 'Canary Wharf')) tensor(598., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Barking')) tensor(304., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(5., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Plaistow')) tensor(79., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Stratford')) tensor(222., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(198., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(78., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(42., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(59., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(96., device='cuda:0')\n(('Cannon Street', 'Mansion House'), ('Mansion House', 'Blackfriars')) tensor(268., device='cuda:0')\n(('Canons Park', 'Queensbury'), ('Queensbury', 'Kingsbury')) tensor(218., device='cuda:0')\n(('Chalfont &amp; Latimer', 'Chorleywood'), ('Chorleywood', 'Rickmansworth')) tensor(395., device='cuda:0')\n(('Chalk Farm', 'Belsize Park'), ('Belsize Park', 'Hampstead')) tensor(910., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1248., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(43., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(9., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(220., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Russell Square')) tensor(115., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(3066., device='cuda:0')\n(('Chancery Lane', \"St. Paul's\"), (\"St. Paul's\", 'Bank / Monument')) tensor(3482., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Temple')) tensor(61., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Waterloo')) tensor(231., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Westminster')) tensor(5., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(59., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(159., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(122., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(304., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(1., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(85., device='cuda:0')\n(('Chigwell', 'Grange Hill'), ('Grange Hill', 'Hainault')) tensor(204., device='cuda:0')\n(('Chigwell', 'Roding Valley'), ('Roding Valley', 'Woodford')) tensor(320., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(90., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(6., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(1., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(146., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(62., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'HarrowOnTheHill')) tensor(496., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'Moor Park')) tensor(10., device='cuda:0')\n(('Clapham Common', 'Clapham North'), ('Clapham North', 'Stockwell')) tensor(1504., device='cuda:0')\n(('Clapham Common', 'Clapham South'), ('Clapham South', 'Balham')) tensor(969., device='cuda:0')\n(('Clapham North', 'Clapham Common'), ('Clapham Common', 'Clapham South')) tensor(1148., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(8., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Oval')) tensor(964., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(686., device='cuda:0')\n(('Clapham South', 'Balham'), ('Balham', 'Tooting Bec')) tensor(782., device='cuda:0')\n(('Clapham South', 'Clapham Common'), ('Clapham Common', 'Clapham North')) tensor(1297., device='cuda:0')\n(('Cockfosters', 'Oakwood'), ('Oakwood', 'Southgate')) tensor(120., device='cuda:0')\n(('Colindale', 'Burnt Oak'), ('Burnt Oak', 'Edgware')) tensor(139., device='cuda:0')\n(('Colindale', 'Hendon Central'), ('Hendon Central', 'Brent Cross')) tensor(370., device='cuda:0')\n(('Colliers Wood', 'South Wimbledon'), ('South Wimbledon', 'Morden')) tensor(152., device='cuda:0')\n(('Colliers Wood', 'Tooting Broadway'), ('Tooting Broadway', 'Tooting Bec')) tensor(477., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(239., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Russell Square')) tensor(90., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(52., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(129., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(238., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(6., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Dagenham East', 'Dagenham Heathway'), ('Dagenham Heathway', 'Becontree')) tensor(161., device='cuda:0')\n(('Dagenham East', 'Elm Park'), ('Elm Park', 'Hornchurch')) tensor(5., device='cuda:0')\n(('Dagenham Heathway', 'Becontree'), ('Becontree', 'Upney')) tensor(418., device='cuda:0')\n(('Dagenham Heathway', 'Dagenham East'), ('Dagenham East', 'Elm Park')) tensor(5., device='cuda:0')\n(('Debden', 'Loughton'), ('Loughton', 'Buckhurst Hill')) tensor(577., device='cuda:0')\n(('Debden', 'Theydon Bois'), ('Theydon Bois', 'Epping')) tensor(217., device='cuda:0')\n(('Dollis Hill', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(118., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(2., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(2315., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(113., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Bayswater')) tensor(117., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(132., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(3451., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(94., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(60., device='cuda:0')\n(('Ealing Broadway', 'West Acton'), ('West Acton', 'North Acton')) tensor(875., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(105., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(508., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(1068., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(699., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(2570., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(49., device='cuda:0')\n(('Ealing Common', 'North Ealing'), ('North Ealing', 'Park Royal')) tensor(232., device='cuda:0')\n((\"Earl's Court\", 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(1065., device='cuda:0')\n((\"Earl's Court\", 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(3117., device='cuda:0')\n((\"Earl's Court\", 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(504., device='cuda:0')\n((\"Earl's Court\", 'West Brompton'), ('West Brompton', 'Fulham Broadway')) tensor(1757., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(70., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'West Acton')) tensor(168., device='cuda:0')\n(('East Acton', 'White City'), ('White City', \"Shepherd's Bush (Cen)\")) tensor(103., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(69., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(427., device='cuda:0')\n(('East Finchley', 'Highgate'), ('Highgate', 'Archway')) tensor(844., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upminster')) tensor(8., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upney')) tensor(7., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'West Ham')) tensor(426., device='cuda:0')\n(('East Ham', 'Upton Park'), ('Upton Park', 'Plaistow')) tensor(1., device='cuda:0')\n(('East Putney', 'Putney Bridge'), ('Putney Bridge', 'Parsons Green')) tensor(969., device='cuda:0')\n(('East Putney', 'Southfields'), ('Southfields', 'Wimbledon Park')) tensor(375., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(66., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(918., device='cuda:0')\n(('Eastcote', 'Ruislip Manor'), ('Ruislip Manor', 'Ruislip')) tensor(619., device='cuda:0')\n(('Edgware', 'Burnt Oak'), ('Burnt Oak', 'Colindale')) tensor(118., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(122., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(326., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(153., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(135., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(50., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(44., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(2860., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(253., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(2439., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(13., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(425., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(57., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(475., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(3182., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(590., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(924., device='cuda:0')\n(('Elephant &amp; Castle', 'Borough'), ('Borough', 'London Bridge')) tensor(867., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Oval')) tensor(627., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Waterloo')) tensor(217., device='cuda:0')\n(('Elephant &amp; Castle', 'Lambeth North'), ('Lambeth North', 'Waterloo')) tensor(211., device='cuda:0')\n(('Elm Park', 'Dagenham East'), ('Dagenham East', 'Dagenham Heathway')) tensor(5., device='cuda:0')\n(('Elm Park', 'Hornchurch'), ('Hornchurch', 'Upminster Bridge')) tensor(238., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Leicester Square')) tensor(114., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Piccadilly Circus')) tensor(175., device='cuda:0')\n(('Embankment', 'Temple'), ('Temple', 'Blackfriars')) tensor(412., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(105., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(23., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(276., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', 'Green Park')) tensor(549., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(132., device='cuda:0')\n(('Epping', 'Theydon Bois'), ('Theydon Bois', 'Debden')) tensor(306., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(1176., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(1482., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(703., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(131., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(326., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(683., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(576., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(100., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(88., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(2579., device='cuda:0')\n(('Euston Square', 'Great Portland Street'), ('Great Portland Street', 'Baker Street')) tensor(4039., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(1503., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(154., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(315., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(1522., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(739., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(87., device='cuda:0')\n(('Fairlop', 'Barkingside'), ('Barkingside', 'Newbury Park')) tensor(301., device='cuda:0')\n(('Fairlop', 'Hainault'), ('Hainault', 'Grange Hill')) tensor(3., device='cuda:0')\n(('Farringdon', 'Barbican'), ('Barbican', 'Moorgate')) tensor(2110., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(3., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(45., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(626., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1384., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(32., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(45., device='cuda:0')\n(('Finchley Central', 'East Finchley'), ('East Finchley', 'Highgate')) tensor(687., device='cuda:0')\n(('Finchley Central', 'West Finchley'), ('West Finchley', 'Woodside Park')) tensor(345., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1763., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(214., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(1034., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(145., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(245., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(172., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(95., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(235., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(603., device='cuda:0')\n(('Finchley Road', 'Swiss Cottage'), ('Swiss Cottage', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(338., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(96., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(85., device='cuda:0')\n(('Finchley Road', 'West Hampstead'), ('West Hampstead', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(110., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(98., device='cuda:0')\n(('Finsbury Park', 'Arsenal'), ('Arsenal', 'Holloway Road')) tensor(65., device='cuda:0')\n(('Finsbury Park', 'Highbury &amp; Islington'), ('Highbury &amp; Islington', \"King's Cross St. Pancras\")) tensor(1377., device='cuda:0')\n(('Finsbury Park', 'Manor House'), ('Manor House', 'Turnpike Lane')) tensor(960., device='cuda:0')\n(('Finsbury Park', 'Seven Sisters'), ('Seven Sisters', 'Tottenham Hale')) tensor(708., device='cuda:0')\n(('Fulham Broadway', 'Parsons Green'), ('Parsons Green', 'Putney Bridge')) tensor(1095., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', \"Earl's Court\")) tensor(1813., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', 'Kensington (Olympia)')) tensor(4., device='cuda:0')\n(('Gants Hill', 'Newbury Park'), ('Newbury Park', 'Barkingside')) tensor(471., device='cuda:0')\n(('Gants Hill', 'Redbridge'), ('Redbridge', 'Wanstead')) tensor(1094., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(1135., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(98., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(1410., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(192., device='cuda:0')\n(('Gloucester Road', 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(158., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(1378., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(2449., device='cuda:0')\n(('Golders Green', 'Brent Cross'), ('Brent Cross', 'Hendon Central')) tensor(542., device='cuda:0')\n(('Golders Green', 'Hampstead'), ('Hampstead', 'Belsize Park')) tensor(846., device='cuda:0')\n(('Goldhawk Road', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Wood Lane')) tensor(201., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(73., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(59., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(38., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(41., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Euston')) tensor(79., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(42., device='cuda:0')\n(('Grange Hill', 'Chigwell'), ('Chigwell', 'Roding Valley')) tensor(256., device='cuda:0')\n(('Grange Hill', 'Hainault'), ('Hainault', 'Fairlop')) tensor(3., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(93., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2262., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(946., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(582., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(14., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(115., device='cuda:0')\n(('Great Portland Street', 'Euston Square'), ('Euston Square', \"King's Cross St. Pancras\")) tensor(4322., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2417., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(156., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(245., device='cuda:0')\n(('Green Park', 'Hyde Park Corner'), ('Hyde Park Corner', 'Knightsbridge')) tensor(1812., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(41., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(250., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(1507., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(131., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(101., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Pimlico')) tensor(1017., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1741., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(140., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Embankment')) tensor(595., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(136., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Waterloo')) tensor(3391., device='cuda:0')\n(('Greenford', 'Northolt'), ('Northolt', 'South Ruislip')) tensor(194., device='cuda:0')\n(('Greenford', 'Perivale'), ('Perivale', 'Hanger Lane')) tensor(544., device='cuda:0')\n(('Gunnersbury', 'Kew Gardens'), ('Kew Gardens', 'Richmond')) tensor(293., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(557., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(217., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(6., device='cuda:0')\n(('Hainault', 'Fairlop'), ('Fairlop', 'Barkingside')) tensor(189., device='cuda:0')\n(('Hainault', 'Grange Hill'), ('Grange Hill', 'Chigwell')) tensor(187., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(437., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(191., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', \"Earl's Court\")) tensor(1123., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', 'West Kensington')) tensor(25., device='cuda:0')\n(('Hammersmith (Dis)', 'Ravenscourt Park'), ('Ravenscourt Park', 'Stamford Brook')) tensor(54., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(177., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(58., device='cuda:0')\n(('Hammersmith (H&amp;C)', 'Goldhawk Road'), ('Goldhawk Road', \"Shepherd's Bush Market\")) tensor(108., device='cuda:0')\n(('Hampstead', 'Belsize Park'), ('Belsize Park', 'Chalk Farm')) tensor(982., device='cuda:0')\n(('Hampstead', 'Golders Green'), ('Golders Green', 'Brent Cross')) tensor(610., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'East Acton')) tensor(80., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'West Acton')) tensor(688., device='cuda:0')\n(('Hanger Lane', 'Perivale'), ('Perivale', 'Greenford')) tensor(454., device='cuda:0')\n(('Harlesden', 'Stonebridge Park'), ('Stonebridge Park', 'Wembley Central')) tensor(333., device='cuda:0')\n(('Harlesden', 'Willesden Junction'), ('Willesden Junction', 'Kensal Green')) tensor(545., device='cuda:0')\n(('Harrow &amp; Wealdstone', 'Kenton'), ('Kenton', 'South Kenton')) tensor(118., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(1461., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(29., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(33., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(36., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(1479., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(383., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(222., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'North Harrow'), ('North Harrow', 'Pinner')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'Northwick Park'), ('Northwick Park', 'Preston Road')) tensor(21., device='cuda:0')\n(('HarrowOnTheHill', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(389., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(59., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'West Harrow'), ('West Harrow', 'Rayners Lane')) tensor(1303., device='cuda:0')\n(('Hatton Cross', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Heathrow Terminal 5')) tensor(75., device='cuda:0')\n(('Hatton Cross', 'Hounslow West'), ('Hounslow West', 'Hounslow Central')) tensor(571., device='cuda:0')\n(('Heathrow Terminal 4', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(123., device='cuda:0')\n(('Heathrow Terminal 5', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Hatton Cross')) tensor(92., device='cuda:0')\n(('Heathrow Terminals 123', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(332., device='cuda:0')\n(('Hendon Central', 'Brent Cross'), ('Brent Cross', 'Golders Green')) tensor(568., device='cuda:0')\n(('Hendon Central', 'Colindale'), ('Colindale', 'Burnt Oak')) tensor(251., device='cuda:0')\n(('High Barnet', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'Woodside Park')) tensor(159., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(97., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(15., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(379., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(34., device='cuda:0')\n(('High Street Kensington', 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(452., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(518., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(110., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(172., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(80., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(768., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(392., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(32., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(13., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(617., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(725., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(33., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(144., device='cuda:0')\n(('Highgate', 'Archway'), ('Archway', 'Tufnell Park')) tensor(1030., device='cuda:0')\n(('Highgate', 'East Finchley'), ('East Finchley', 'Finchley Central')) tensor(639., device='cuda:0')\n(('Hillingdon', 'Ickenham'), ('Ickenham', 'Ruislip')) tensor(424., device='cuda:0')\n(('Holborn', 'Chancery Lane'), ('Chancery Lane', \"St. Paul's\")) tensor(3506., device='cuda:0')\n(('Holborn', 'Covent Garden'), ('Covent Garden', 'Leicester Square')) tensor(203., device='cuda:0')\n(('Holborn', 'Russell Square'), ('Russell Square', \"King's Cross St. Pancras\")) tensor(302., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(2909., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(63., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(215., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(404., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(96., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(127., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(328., device='cuda:0')\n(('Holland Park', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'White City')) tensor(277., device='cuda:0')\n(('Holloway Road', 'Arsenal'), ('Arsenal', 'Finsbury Park')) tensor(69., device='cuda:0')\n(('Holloway Road', 'Caledonian Road'), ('Caledonian Road', \"King's Cross St. Pancras\")) tensor(243., device='cuda:0')\n(('Hornchurch', 'Elm Park'), ('Elm Park', 'Dagenham East')) tensor(4., device='cuda:0')\n(('Hornchurch', 'Upminster Bridge'), ('Upminster Bridge', 'Upminster')) tensor(437., device='cuda:0')\n(('Hounslow Central', 'Hounslow East'), ('Hounslow East', 'Osterley')) tensor(828., device='cuda:0')\n(('Hounslow Central', 'Hounslow West'), ('Hounslow West', 'Hatton Cross')) tensor(433., device='cuda:0')\n(('Hounslow East', 'Hounslow Central'), ('Hounslow Central', 'Hounslow West')) tensor(554., device='cuda:0')\n(('Hounslow East', 'Osterley'), ('Osterley', 'Boston Manor')) tensor(959., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminal 4')) tensor(69., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminals 123')) tensor(277., device='cuda:0')\n(('Hounslow West', 'Hounslow Central'), ('Hounslow Central', 'Hounslow East')) tensor(667., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Bond Street')) tensor(234., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(492., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(73., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Victoria')) tensor(20., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Westminster')) tensor(1029., device='cuda:0')\n(('Hyde Park Corner', 'Knightsbridge'), ('Knightsbridge', 'South Kensington')) tensor(1581., device='cuda:0')\n(('Ickenham', 'Hillingdon'), ('Hillingdon', 'Uxbridge')) tensor(257., device='cuda:0')\n(('Ickenham', 'Ruislip'), ('Ruislip', 'Ruislip Manor')) tensor(541., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(774., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Oval'), ('Oval', 'Stockwell')) tensor(1245., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(113., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(715., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(378., device='cuda:0')\n(('Kensal Green', \"Queen's Park\"), (\"Queen's Park\", 'Kilburn Park')) tensor(754., device='cuda:0')\n(('Kensal Green', 'Willesden Junction'), ('Willesden Junction', 'Harlesden')) tensor(470., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(47., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1547., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(11., device='cuda:0')\n(('Kentish Town', 'Tufnell Park'), ('Tufnell Park', 'Archway')) tensor(1191., device='cuda:0')\n(('Kenton', 'South Kenton'), ('South Kenton', 'North Wembley')) tensor(150., device='cuda:0')\n(('Kew Gardens', 'Gunnersbury'), ('Gunnersbury', 'Turnham Green')) tensor(510., device='cuda:0')\n(('Kilburn', 'West Hampstead'), ('West Hampstead', 'Finchley Road')) tensor(140., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(1., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(145., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(8., device='cuda:0')\n(('Kilburn Park', 'Maida Vale'), ('Maida Vale', 'Warwick Avenue')) tensor(1048., device='cuda:0')\n(('Kilburn Park', \"Queen's Park\"), (\"Queen's Park\", 'Kensal Green')) tensor(622., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Angel'), ('Angel', 'Old Street')) tensor(2221., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Caledonian Road'), ('Caledonian Road', 'Holloway Road')) tensor(246., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Camden Town')) tensor(1406., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Mornington Crescent')) tensor(85., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Warren Street')) tensor(881., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston Square'), ('Euston Square', 'Great Portland Street')) tensor(4062., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Farringdon'), ('Farringdon', 'Barbican')) tensor(2195., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Highbury &amp; Islington'), ('Highbury &amp; Islington', 'Finsbury Park')) tensor(1352., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Russell Square'), ('Russell Square', 'Holborn')) tensor(299., device='cuda:0')\n(('Kingsbury', 'Queensbury'), ('Queensbury', 'Canons Park')) tensor(189., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(334., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(66., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(16., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(1., device='cuda:0')\n(('Knightsbridge', 'Hyde Park Corner'), ('Hyde Park Corner', 'Green Park')) tensor(1733., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(1409., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(14., device='cuda:0')\n(('Ladbroke Grove', 'Latimer Road'), ('Latimer Road', 'Wood Lane')) tensor(299., device='cuda:0')\n(('Ladbroke Grove', 'Westbourne Park'), ('Westbourne Park', 'Royal Oak')) tensor(607., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(83., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(19., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(45., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(287., device='cuda:0')\n(('Lancaster Gate', 'Marble Arch'), ('Marble Arch', 'Bond Street')) tensor(839., device='cuda:0')\n(('Lancaster Gate', 'Queensway'), ('Queensway', 'Notting Hill Gate')) tensor(616., device='cuda:0')\n(('Latimer Road', 'Ladbroke Grove'), ('Ladbroke Grove', 'Westbourne Park')) tensor(446., device='cuda:0')\n(('Latimer Road', 'Wood Lane'), ('Wood Lane', \"Shepherd's Bush Market\")) tensor(240., device='cuda:0')\n(('Leicester Square', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(103., device='cuda:0')\n(('Leicester Square', 'Covent Garden'), ('Covent Garden', 'Holborn')) tensor(222., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(101., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(277., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(39., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(212., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(1851., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(1449., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Mile End')) tensor(1671., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'West Ham')) tensor(95., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2639., device='cuda:0')\n(('Leytonstone', 'Leyton'), ('Leyton', 'Stratford')) tensor(3987., device='cuda:0')\n(('Leytonstone', 'Snaresbrook'), ('Snaresbrook', 'South Woodford')) tensor(1706., device='cuda:0')\n(('Leytonstone', 'Wanstead'), ('Wanstead', 'Redbridge')) tensor(1245., device='cuda:0')\n(('Liverpool Street', 'Aldgate'), ('Aldgate', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(3609., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(2842., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(2155., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Bethnal Green'), ('Bethnal Green', 'Mile End')) tensor(3900., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(1688., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(1701., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(546., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(73., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2915., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(495., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(107., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1264., device='cuda:0')\n(('London Bridge', 'Bermondsey'), ('Bermondsey', 'Canada Water')) tensor(1250., device='cuda:0')\n(('London Bridge', 'Borough'), ('Borough', 'Elephant &amp; Castle')) tensor(795., device='cuda:0')\n(('London Bridge', 'Southwark'), ('Southwark', 'Waterloo')) tensor(4797., device='cuda:0')\n(('Loughton', 'Buckhurst Hill'), ('Buckhurst Hill', 'Woodford')) tensor(773., device='cuda:0')\n(('Loughton', 'Debden'), ('Debden', 'Theydon Bois')) tensor(301., device='cuda:0')\n(('Maida Vale', 'Kilburn Park'), ('Kilburn Park', \"Queen's Park\")) tensor(736., device='cuda:0')\n(('Maida Vale', 'Warwick Avenue'), ('Warwick Avenue', 'Paddington')) tensor(1186., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(21., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(806., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(328., device='cuda:0')\n(('Manor House', 'Turnpike Lane'), ('Turnpike Lane', 'Wood Green')) tensor(794., device='cuda:0')\n(('Mansion House', 'Blackfriars'), ('Blackfriars', 'Temple')) tensor(286., device='cuda:0')\n(('Mansion House', 'Cannon Street'), ('Cannon Street', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(104., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(145., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(161., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(658., device='cuda:0')\n(('Marble Arch', 'Lancaster Gate'), ('Lancaster Gate', 'Queensway')) tensor(725., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1060., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(1., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(4., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(601., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(104., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(15., device='cuda:0')\n(('Marylebone', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Paddington')) tensor(393., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(5., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(262., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(185., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(115., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(265., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(69., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(699., device='cuda:0')\n(('Mile End', 'Bethnal Green'), ('Bethnal Green', 'Liverpool Street')) tensor(3726., device='cuda:0')\n(('Mile End', 'Bow Road'), ('Bow Road', 'BromleyByBow')) tensor(112., device='cuda:0')\n(('Mile End', 'Stepney Green'), ('Stepney Green', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Leyton')) tensor(1541., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'West Ham')) tensor(1383., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(94., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(3., device='cuda:0')\n(('Moor Park', 'Croxley'), ('Croxley', 'Watford')) tensor(124., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(255., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(284., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(9., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(13., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(20., device='cuda:0')\n(('Moor Park', 'Northwood'), ('Northwood', 'Northwood Hills')) tensor(113., device='cuda:0')\n(('Moor Park', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(9., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(55., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(455., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(15., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(54., device='cuda:0')\n(('Moorgate', 'Barbican'), ('Barbican', 'Farringdon')) tensor(1978., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(187., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(1525., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(1624., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(26., device='cuda:0')\n(('Moorgate', 'Old Street'), ('Old Street', 'Angel')) tensor(2014., device='cuda:0')\n(('Morden', 'South Wimbledon'), ('South Wimbledon', 'Colliers Wood')) tensor(199., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(9., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(10., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(82., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', 'Warren Street')) tensor(88., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(114., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(14., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(5., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(108., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(8., device='cuda:0')\n(('Newbury Park', 'Barkingside'), ('Barkingside', 'Fairlop')) tensor(335., device='cuda:0')\n(('Newbury Park', 'Gants Hill'), ('Gants Hill', 'Redbridge')) tensor(742., device='cuda:0')\n(('North Acton', 'East Acton'), ('East Acton', 'White City')) tensor(131., device='cuda:0')\n(('North Acton', 'Hanger Lane'), ('Hanger Lane', 'Perivale')) tensor(534., device='cuda:0')\n(('North Acton', 'West Acton'), ('West Acton', 'Ealing Broadway')) tensor(1035., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(189., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(152., device='cuda:0')\n(('North Ealing', 'Park Royal'), ('Park Royal', 'Alperton')) tensor(180., device='cuda:0')\n(('North Greenwich', 'Canary Wharf'), ('Canary Wharf', 'Canada Water')) tensor(806., device='cuda:0')\n(('North Greenwich', 'Canning Town'), ('Canning Town', 'West Ham')) tensor(513., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(190., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(196., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(3., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(7., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(10., device='cuda:0')\n(('North Harrow', 'Pinner'), ('Pinner', 'Northwood Hills')) tensor(104., device='cuda:0')\n(('North Wembley', 'South Kenton'), ('South Kenton', 'Kenton')) tensor(163., device='cuda:0')\n(('North Wembley', 'Wembley Central'), ('Wembley Central', 'Stonebridge Park')) tensor(272., device='cuda:0')\n(('Northfields', 'Boston Manor'), ('Boston Manor', 'Osterley')) tensor(924., device='cuda:0')\n(('Northfields', 'South Ealing'), ('South Ealing', 'Acton Town')) tensor(1308., device='cuda:0')\n(('Northolt', 'Greenford'), ('Greenford', 'Perivale')) tensor(382., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'Ruislip Gardens')) tensor(51., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'West Ruislip')) tensor(73., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(92., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(110., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(7., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(2., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(13., device='cuda:0')\n(('Northwick Park', 'Preston Road'), ('Preston Road', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(257., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Northwood', 'Northwood Hills'), ('Northwood Hills', 'Pinner')) tensor(5., device='cuda:0')\n(('Northwood Hills', 'Northwood'), ('Northwood', 'Moor Park')) tensor(124., device='cuda:0')\n(('Northwood Hills', 'Pinner'), ('Pinner', 'North Harrow')) tensor(107., device='cuda:0')\n(('Notting Hill Gate', 'Bayswater'), ('Bayswater', 'Paddington')) tensor(656., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', \"Earl's Court\")) tensor(581., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', 'Gloucester Road')) tensor(194., device='cuda:0')\n(('Notting Hill Gate', 'Holland Park'), ('Holland Park', \"Shepherd's Bush (Cen)\")) tensor(462., device='cuda:0')\n(('Notting Hill Gate', 'Queensway'), ('Queensway', 'Lancaster Gate')) tensor(611., device='cuda:0')\n(('Oakwood', 'Southgate'), ('Southgate', 'Arnos Grove')) tensor(229., device='cuda:0')\n(('Old Street', 'Angel'), ('Angel', \"King's Cross St. Pancras\")) tensor(2078., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(296., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(3., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1828., device='cuda:0')\n(('Osterley', 'Boston Manor'), ('Boston Manor', 'Northfields')) tensor(1091., device='cuda:0')\n(('Osterley', 'Hounslow East'), ('Hounslow East', 'Hounslow Central')) tensor(679., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(691., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Waterloo')) tensor(837., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(155., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(859., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(169., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(672., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(178., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(519., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(999., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(361., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(304., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', \"Regent's Park\"), (\"Regent's Park\", 'Baker Street')) tensor(674., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(47., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(376., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Euston')) tensor(2437., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(48., device='cuda:0')\n(('Paddington', 'Bayswater'), ('Bayswater', 'Notting Hill Gate')) tensor(811., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(2429., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(891., device='cuda:0')\n(('Paddington', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Marylebone')) tensor(353., device='cuda:0')\n(('Paddington', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Baker Street')) tensor(5928., device='cuda:0')\n(('Paddington', 'Royal Oak'), ('Royal Oak', 'Westbourne Park')) tensor(686., device='cuda:0')\n(('Paddington', 'Warwick Avenue'), ('Warwick Avenue', 'Maida Vale')) tensor(976., device='cuda:0')\n(('Park Royal', 'Alperton'), ('Alperton', 'Sudbury Town')) tensor(128., device='cuda:0')\n(('Park Royal', 'North Ealing'), ('North Ealing', 'Ealing Common')) tensor(305., device='cuda:0')\n(('Parsons Green', 'Fulham Broadway'), ('Fulham Broadway', 'West Brompton')) tensor(1506., device='cuda:0')\n(('Parsons Green', 'Putney Bridge'), ('Putney Bridge', 'East Putney')) tensor(828., device='cuda:0')\n(('Perivale', 'Greenford'), ('Greenford', 'Northolt')) tensor(321., device='cuda:0')\n(('Perivale', 'Hanger Lane'), ('Hanger Lane', 'North Acton')) tensor(621., device='cuda:0')\n(('Piccadilly Circus', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(180., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Bond Street')) tensor(220., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(74., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(109., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(106., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(138., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(82., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(218., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(215., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(80., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(174., device='cuda:0')\n(('Pimlico', 'Vauxhall'), ('Vauxhall', 'Stockwell')) tensor(940., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Green Park')) tensor(1025., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(258., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(89., device='cuda:0')\n(('Pinner', 'North Harrow'), ('North Harrow', 'HarrowOnTheHill')) tensor(261., device='cuda:0')\n(('Pinner', 'Northwood Hills'), ('Northwood Hills', 'Northwood')) tensor(5., device='cuda:0')\n(('Plaistow', 'Upton Park'), ('Upton Park', 'East Ham')) tensor(1., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Barking')) tensor(9., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(4., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(97., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Stratford')) tensor(770., device='cuda:0')\n(('Preston Road', 'Northwick Park'), ('Northwick Park', 'HarrowOnTheHill')) tensor(23., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(84., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(22., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(2., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(5., device='cuda:0')\n(('Putney Bridge', 'East Putney'), ('East Putney', 'Southfields')) tensor(577., device='cuda:0')\n(('Putney Bridge', 'Parsons Green'), ('Parsons Green', 'Fulham Broadway')) tensor(1250., device='cuda:0')\n((\"Queen's Park\", 'Kensal Green'), ('Kensal Green', 'Willesden Junction')) tensor(551., device='cuda:0')\n((\"Queen's Park\", 'Kilburn Park'), ('Kilburn Park', 'Maida Vale')) tensor(903., device='cuda:0')\n(('Queensbury', 'Canons Park'), ('Canons Park', 'Stanmore')) tensor(99., device='cuda:0')\n(('Queensbury', 'Kingsbury'), ('Kingsbury', 'Wembley Park')) tensor(312., device='cuda:0')\n(('Queensway', 'Lancaster Gate'), ('Lancaster Gate', 'Marble Arch')) tensor(723., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(18., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(165., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(333., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(76., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(173., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Ravenscourt Park', 'Stamford Brook'), ('Stamford Brook', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Rayners Lane', 'Eastcote'), ('Eastcote', 'Ruislip Manor')) tensor(743., device='cuda:0')\n(('Rayners Lane', 'South Harrow'), ('South Harrow', 'Sudbury Hill')) tensor(253., device='cuda:0')\n(('Rayners Lane', 'West Harrow'), ('West Harrow', 'HarrowOnTheHill')) tensor(1408., device='cuda:0')\n(('Redbridge', 'Gants Hill'), ('Gants Hill', 'Newbury Park')) tensor(701., device='cuda:0')\n(('Redbridge', 'Wanstead'), ('Wanstead', 'Leytonstone')) tensor(1302., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(426., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(150., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(6., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(106., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(12., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(40., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(211., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(26., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(347., device='cuda:0')\n(('Richmond', 'Kew Gardens'), ('Kew Gardens', 'Gunnersbury')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'Chorleywood'), ('Chorleywood', 'Chalfont &amp; Latimer')) tensor(312., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(276., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(9., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(11., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(7., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(3., device='cuda:0')\n(('Roding Valley', 'Chigwell'), ('Chigwell', 'Grange Hill')) tensor(261., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(8., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'South Woodford')) tensor(372., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Bayswater')) tensor(47., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(92., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(54., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(684., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(8., device='cuda:0')\n(('Royal Oak', 'Westbourne Park'), ('Westbourne Park', 'Ladbroke Grove')) tensor(569., device='cuda:0')\n(('Ruislip', 'Ickenham'), ('Ickenham', 'Hillingdon')) tensor(398., device='cuda:0')\n(('Ruislip', 'Ruislip Manor'), ('Ruislip Manor', 'Eastcote')) tensor(712., device='cuda:0')\n(('Ruislip Gardens', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(78., device='cuda:0')\n(('Ruislip Manor', 'Eastcote'), ('Eastcote', 'Rayners Lane')) tensor(825., device='cuda:0')\n(('Ruislip Manor', 'Ruislip'), ('Ruislip', 'Ickenham')) tensor(496., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(119., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(90., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(327., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(59., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(40., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(91., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(86., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(53., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(151., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(66., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(387., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(335., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(153., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(561., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'Holland Park'), ('Holland Park', 'Notting Hill Gate')) tensor(468., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'White City'), ('White City', 'East Acton')) tensor(93., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Goldhawk Road'), ('Goldhawk Road', 'Hammersmith (H&amp;C)')) tensor(77., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Wood Lane'), ('Wood Lane', 'Latimer Road')) tensor(279., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(2467., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(15., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Green Park')) tensor(1713., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Pimlico')) tensor(260., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(1042., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(2080., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(7., device='cuda:0')\n(('Snaresbrook', 'South Woodford'), ('South Woodford', 'Woodford')) tensor(1415., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(8., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(1168., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(212., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(25., device='cuda:0')\n(('South Ealing', 'Northfields'), ('Northfields', 'Boston Manor')) tensor(1019., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(62., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(316., device='cuda:0')\n(('South Harrow', 'Sudbury Hill'), ('Sudbury Hill', 'Sudbury Town')) tensor(183., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', \"Earl's Court\")) tensor(3171., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', 'High Street Kensington')) tensor(414., device='cuda:0')\n(('South Kensington', 'Knightsbridge'), ('Knightsbridge', 'Hyde Park Corner')) tensor(1538., device='cuda:0')\n(('South Kensington', 'Sloane Square'), ('Sloane Square', 'Victoria')) tensor(2746., device='cuda:0')\n(('South Kenton', 'Kenton'), ('Kenton', 'Harrow &amp; Wealdstone')) tensor(119., device='cuda:0')\n(('South Kenton', 'North Wembley'), ('North Wembley', 'Wembley Central')) tensor(207., device='cuda:0')\n(('South Ruislip', 'Northolt'), ('Northolt', 'Greenford')) tensor(252., device='cuda:0')\n(('South Wimbledon', 'Colliers Wood'), ('Colliers Wood', 'Tooting Broadway')) tensor(328., device='cuda:0')\n(('South Woodford', 'Snaresbrook'), ('Snaresbrook', 'Leytonstone')) tensor(1888., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(830., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(309., device='cuda:0')\n(('Southfields', 'East Putney'), ('East Putney', 'Putney Bridge')) tensor(677., device='cuda:0')\n(('Southfields', 'Wimbledon Park'), ('Wimbledon Park', 'Wimbledon')) tensor(255., device='cuda:0')\n(('Southgate', 'Arnos Grove'), ('Arnos Grove', 'Bounds Green')) tensor(390., device='cuda:0')\n(('Southgate', 'Oakwood'), ('Oakwood', 'Cockfosters')) tensor(101., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(3604., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(1002., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Borough')) tensor(52., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(279., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(640., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(45., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(3875., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Green Park')) tensor(132., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Pimlico')) tensor(84., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1027., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Embankment')) tensor(128., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Green Park')) tensor(135., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Waterloo')) tensor(1190., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(168., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(54., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(119., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(16., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(11., device='cuda:0')\n((\"St. John's Wood\", 'Swiss Cottage'), ('Swiss Cottage', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(49., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2220., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(86., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(13., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1106., device='cuda:0')\n((\"St. Paul's\", 'Chancery Lane'), ('Chancery Lane', 'Holborn')) tensor(3317., device='cuda:0')\n(('Stamford Brook', 'Ravenscourt Park'), ('Ravenscourt Park', 'Hammersmith (Dis)')) tensor(63., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(89., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(6., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(67., device='cuda:0')\n(('Stanmore', 'Canons Park'), ('Canons Park', 'Queensbury')) tensor(110., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(132., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(5., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(24., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(214., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(25., device='cuda:0')\n(('Stockwell', 'Clapham North'), ('Clapham North', 'Clapham Common')) tensor(1366., device='cuda:0')\n(('Stockwell', 'Oval'), ('Oval', 'Kennington')) tensor(1370., device='cuda:0')\n(('Stockwell', 'Vauxhall'), ('Vauxhall', 'Pimlico')) tensor(928., device='cuda:0')\n(('Stonebridge Park', 'Harlesden'), ('Harlesden', 'Willesden Junction')) tensor(443., device='cuda:0')\n(('Stonebridge Park', 'Wembley Central'), ('Wembley Central', 'North Wembley')) tensor(257., device='cuda:0')\n(('Stratford', 'Leyton'), ('Leyton', 'Leytonstone')) tensor(3711., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(3185., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bow Road')) tensor(8., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(27., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Barking')) tensor(2374., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(7., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Canning Town')) tensor(170., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Plaistow')) tensor(707., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(5039., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(26., device='cuda:0')\n(('Sudbury Hill', 'South Harrow'), ('South Harrow', 'Rayners Lane')) tensor(290., device='cuda:0')\n(('Sudbury Hill', 'Sudbury Town'), ('Sudbury Town', 'Alperton')) tensor(143., device='cuda:0')\n(('Sudbury Town', 'Alperton'), ('Alperton', 'Park Royal')) tensor(166., device='cuda:0')\n(('Sudbury Town', 'Sudbury Hill'), ('Sudbury Hill', 'South Harrow')) tensor(190., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(180., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(4., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(8., device='cuda:0')\n(('Swiss Cottage', \"St. John's Wood\"), (\"St. John's Wood\", 'Baker Street')) tensor(175., device='cuda:0')\n(('Temple', 'Blackfriars'), ('Blackfriars', 'Mansion House')) tensor(291., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(57., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Waterloo')) tensor(44., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Westminster')) tensor(487., device='cuda:0')\n(('Theydon Bois', 'Debden'), ('Debden', 'Loughton')) tensor(447., device='cuda:0')\n(('Tooting Bec', 'Balham'), ('Balham', 'Clapham South')) tensor(939., device='cuda:0')\n(('Tooting Bec', 'Tooting Broadway'), ('Tooting Broadway', 'Colliers Wood')) tensor(404., device='cuda:0')\n(('Tooting Broadway', 'Colliers Wood'), ('Colliers Wood', 'South Wimbledon')) tensor(264., device='cuda:0')\n(('Tooting Broadway', 'Tooting Bec'), ('Tooting Bec', 'Balham')) tensor(763., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2377., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(244., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(630., device='cuda:0')\n(('Tottenham Court Road', 'Goodge Street'), ('Goodge Street', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(3254., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(104., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Russell Square')) tensor(322., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(154., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(101., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(86., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(245., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(80., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(40., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Hale', 'Blackhorse Road'), ('Blackhorse Road', 'Walthamstow Central')) tensor(197., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(24., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(138., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(566., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(133., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(26., device='cuda:0')\n(('Tottenham Hale', 'Seven Sisters'), ('Seven Sisters', 'Finsbury Park')) tensor(690., device='cuda:0')\n(('Totteridge &amp; Whetstone', 'Woodside Park'), ('Woodside Park', 'West Finchley')) tensor(259., device='cuda:0')\n(('Tower Hill', 'Aldgate'), ('Aldgate', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(2085., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(96., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(17., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(1239., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(59., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(1078., device='cuda:0')\n(('Tufnell Park', 'Archway'), ('Archway', 'Highgate')) tensor(965., device='cuda:0')\n(('Tufnell Park', 'Kentish Town'), ('Kentish Town', 'Camden Town')) tensor(1387., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(769., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(21., device='cuda:0')\n(('Turnham Green', 'Gunnersbury'), ('Gunnersbury', 'Kew Gardens')) tensor(470., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(367., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnham Green', 'Stamford Brook'), ('Stamford Brook', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnpike Lane', 'Manor House'), ('Manor House', 'Finsbury Park')) tensor(1014., device='cuda:0')\n(('Turnpike Lane', 'Wood Green'), ('Wood Green', 'Bounds Green')) tensor(618., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'Upney')) tensor(5., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'West Ham')) tensor(735., device='cuda:0')\n(('Upminster', 'Upminster Bridge'), ('Upminster Bridge', 'Hornchurch')) tensor(468., device='cuda:0')\n(('Upminster Bridge', 'Hornchurch'), ('Hornchurch', 'Elm Park')) tensor(269., device='cuda:0')\n(('Upminster Bridge', 'Upminster'), ('Upminster', 'Barking')) tensor(571., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'Upminster')) tensor(4., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'West Ham')) tensor(779., device='cuda:0')\n(('Upney', 'Becontree'), ('Becontree', 'Dagenham Heathway')) tensor(478., device='cuda:0')\n(('Upton Park', 'East Ham'), ('East Ham', 'Barking')) tensor(8., device='cuda:0')\n(('Upton Park', 'Plaistow'), ('Plaistow', 'West Ham')) tensor(464., device='cuda:0')\n(('Uxbridge', 'Hillingdon'), ('Hillingdon', 'Ickenham')) tensor(256., device='cuda:0')\n(('Vauxhall', 'Pimlico'), ('Pimlico', 'Victoria')) tensor(1094., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(152., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(680., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Oval')) tensor(173., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Bond Street')) tensor(835., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(23., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(974., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(116., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Westminster')) tensor(1201., device='cuda:0')\n(('Victoria', 'Pimlico'), ('Pimlico', 'Vauxhall')) tensor(1093., device='cuda:0')\n(('Victoria', 'Sloane Square'), ('Sloane Square', 'South Kensington')) tensor(2745., device='cuda:0')\n(('Victoria', \"St. James's Park\"), (\"St. James's Park\", 'Westminster')) tensor(1214., device='cuda:0')\n(('Walthamstow Central', 'Blackhorse Road'), ('Blackhorse Road', 'Tottenham Hale')) tensor(221., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(1544., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(15., device='cuda:0')\n(('Wanstead', 'Redbridge'), ('Redbridge', 'Gants Hill')) tensor(1049., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Camden Town')) tensor(1550., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(881., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Mornington Crescent')) tensor(73., device='cuda:0')\n(('Warren Street', 'Goodge Street'), ('Goodge Street', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(553., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(1574., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(182., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(369., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warwick Avenue', 'Maida Vale'), ('Maida Vale', 'Kilburn Park')) tensor(836., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Bayswater')) tensor(103., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(58., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(43., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(1143., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(8., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(229., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Temple')) tensor(53., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(231., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Oval')) tensor(779., device='cuda:0')\n(('Waterloo', 'Lambeth North'), ('Lambeth North', 'Elephant &amp; Castle')) tensor(226., device='cuda:0')\n(('Waterloo', 'Southwark'), ('Southwark', 'London Bridge')) tensor(4777., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', 'Green Park')) tensor(3439., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(1183., device='cuda:0')\n(('Watford', 'Croxley'), ('Croxley', 'Moor Park')) tensor(122., device='cuda:0')\n(('Wembley Central', 'North Wembley'), ('North Wembley', 'South Kenton')) tensor(199., device='cuda:0')\n(('Wembley Central', 'Stonebridge Park'), ('Stonebridge Park', 'Harlesden')) tensor(356., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(657., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(13., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(68., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(14., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(4., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(7., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(36., device='cuda:0')\n(('Wembley Park', 'Kingsbury'), ('Kingsbury', 'Queensbury')) tensor(311., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Dollis Hill')) tensor(14., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Preston Road'), ('Preston Road', 'Northwick Park')) tensor(4., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(61., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(1040., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'East Acton')) tensor(149., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(600., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(144., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1519., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(344., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(7., device='cuda:0')\n(('West Brompton', 'Fulham Broadway'), ('Fulham Broadway', 'Parsons Green')) tensor(1357., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(468., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(2., device='cuda:0')\n(('West Finchley', 'Woodside Park'), ('Woodside Park', 'Totteridge &amp; Whetstone')) tensor(221., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'East Ham')) tensor(588., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upminster')) tensor(788., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upney')) tensor(857., device='cuda:0')\n(('West Ham', 'BromleyByBow'), ('BromleyByBow', 'Bow Road')) tensor(16., device='cuda:0')\n(('West Ham', 'Canning Town'), ('Canning Town', 'North Greenwich')) tensor(490., device='cuda:0')\n(('West Ham', 'Plaistow'), ('Plaistow', 'Upton Park')) tensor(482., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Leyton')) tensor(122., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Mile End')) tensor(1283., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2023., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(267., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(19., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(4., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(13., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Hampstead', 'Kilburn'), ('Kilburn', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(660., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(779., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(13., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(31., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(853., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(270., device='cuda:0')\n(('West Kensington', 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(205., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(40., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(5., device='cuda:0')\n(('West Ruislip', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(64., device='cuda:0')\n(('Westbourne Park', 'Ladbroke Grove'), ('Ladbroke Grove', 'Latimer Road')) tensor(405., device='cuda:0')\n(('Westbourne Park', 'Royal Oak'), ('Royal Oak', 'Paddington')) tensor(780., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(5., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Temple')) tensor(525., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Bond Street')) tensor(1478., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(1051., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(353., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(101., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Victoria')) tensor(1205., device='cuda:0')\n(('Westminster', \"St. James's Park\"), (\"St. James's Park\", 'Victoria')) tensor(1204., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(372., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(319., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(3784., device='cuda:0')\n(('White City', 'East Acton'), ('East Acton', 'North Acton')) tensor(127., device='cuda:0')\n(('White City', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'Holland Park')) tensor(279., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(3522., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(2077., device='cuda:0')\n(('Whitechapel', 'Stepney Green'), ('Stepney Green', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Leyton')) tensor(2499., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'West Ham')) tensor(2098., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(512., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(27., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(8., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Kilburn'), ('Kilburn', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Junction', 'Harlesden'), ('Harlesden', 'Stonebridge Park')) tensor(405., device='cuda:0')\n(('Willesden Junction', 'Kensal Green'), ('Kensal Green', \"Queen's Park\")) tensor(678., device='cuda:0')\n(('Wimbledon', 'Wimbledon Park'), ('Wimbledon Park', 'Southfields')) tensor(299., device='cuda:0')\n(('Wimbledon Park', 'Southfields'), ('Southfields', 'East Putney')) tensor(456., device='cuda:0')\n(('Wood Green', 'Bounds Green'), ('Bounds Green', 'Arnos Grove')) tensor(479., device='cuda:0')\n(('Wood Green', 'Turnpike Lane'), ('Turnpike Lane', 'Manor House')) tensor(831., device='cuda:0')\n(('Wood Lane', 'Latimer Road'), ('Latimer Road', 'Ladbroke Grove')) tensor(346., device='cuda:0')\n(('Wood Lane', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Goldhawk Road')) tensor(133., device='cuda:0')\n(('Woodford', 'Buckhurst Hill'), ('Buckhurst Hill', 'Loughton')) tensor(683., device='cuda:0')\n(('Woodford', 'Roding Valley'), ('Roding Valley', 'Chigwell')) tensor(294., device='cuda:0')\n(('Woodford', 'South Woodford'), ('South Woodford', 'Snaresbrook')) tensor(1601., device='cuda:0')\n(('Woodside Park', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'High Barnet')) tensor(132., device='cuda:0')\n(('Woodside Park', 'West Finchley'), ('West Finchley', 'Finchley Central')) tensor(384., device='cuda:0')\n</pre> In\u00a0[5]: Copied! <pre>g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')]\n</pre> g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')] Out[5]: <pre>tensor(279., device='cuda:0')</pre> In\u00a0[6]: Copied! <pre>paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2)\ng2 = pp2.HigherOrderNetwork(paths, k=2)\nprint(g2)\n</pre> paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2) g2 = pp2.HigherOrderNetwork(paths, k=2) print(g2) <pre>2024-03-27 11:21:58 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:58 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:58 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n</pre> In\u00a0[7]: Copied! <pre>ks = range(1,10)\ntimes = []\nfor k in ks:\n    start = time.time() \n    paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)\n    g2 = pp2.HigherOrderNetwork(paths, k=k)\n    print(g2)\n    elapsed_pp = time.time()-start\n    times.append(elapsed_pp)\nplt.plot(ks, times)\n</pre> ks = range(1,10) times = [] for k in ks:     start = time.time()      paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)     g2 = pp2.HigherOrderNetwork(paths, k=k)     print(g2)     elapsed_pp = time.time()-start     times.append(elapsed_pp) plt.plot(ks, times) <pre>2024-03-27 11:21:59 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:59 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished.\nHigher-order network of order k = 1\n\nNodes:\t\t\t\t268\nLinks:\t\t\t\t646\nTotal weight (subpaths/longest paths):\t14404381.0/99956.0\n\n2024-03-27 11:22:00 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:00 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n2024-03-27 11:22:01 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:01 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished.\nHigher-order network of order k = 3\n\nNodes:\t\t\t\t1889\nLinks:\t\t\t\t1869\nTotal weight (subpaths/longest paths):\t10078001.0/230562.0\n\n2024-03-27 11:22:02 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:02 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:03 [Severity.INFO]\tfinished.\nHigher-order network of order k = 4\n\nNodes:\t\t\t\t5770\nLinks:\t\t\t\t2730\nTotal weight (subpaths/longest paths):\t8198110.0/236412.0\n\n2024-03-27 11:22:04 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:04 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:04 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:05 [Severity.INFO]\tfinished.\nHigher-order network of order k = 5\n\nNodes:\t\t\t\t19424\nLinks:\t\t\t\t3683\nTotal weight (subpaths/longest paths):\t6547275.0/243768.0\n\n2024-03-27 11:22:06 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:06 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:06 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:08 [Severity.INFO]\tfinished.\nHigher-order network of order k = 6\n\nNodes:\t\t\t\t66882\nLinks:\t\t\t\t4748\nTotal weight (subpaths/longest paths):\t5174028.0/209948.0\n\n2024-03-27 11:22:09 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:09 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:09 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:11 [Severity.INFO]\tfinished.\nHigher-order network of order k = 7\n\nNodes:\t\t\t\t242779\nLinks:\t\t\t\t5745\nTotal weight (subpaths/longest paths):\t4044268.0/176409.0\n\n2024-03-27 11:22:14 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:15 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:15 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:17 [Severity.INFO]\tfinished.\nHigher-order network of order k = 8\n\nNodes:\t\t\t\t888479\nLinks:\t\t\t\t6463\nTotal weight (subpaths/longest paths):\t3116104.0/151222.0\n\n2024-03-27 11:22:29 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:29 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:29 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:31 [Severity.INFO]\tfinished.\nHigher-order network of order k = 9\n\nNodes:\t\t\t\t3348421\nLinks:\t\t\t\t7053\nTotal weight (subpaths/longest paths):\t2349934.0/140450.0\n\n</pre> Out[7]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f081d30d9c0&gt;]</pre> In\u00a0[\u00a0]: Copied! <pre>ks = range(1,10)\ntimes_new_gpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram').to('cuda')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_gpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_gpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram').to('cuda') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_gpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[18]: Copied! <pre>ks = range(1,10)\ntimes_new_cpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_cpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_cpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_cpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[19]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.grid()\nplt.ylabel('time [s]')\nplt.legend()\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.grid() plt.ylabel('time [s]') plt.legend() Out[19]: <pre>&lt;matplotlib.legend.Legend at 0x7f082668d9f0&gt;</pre> In\u00a0[20]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.ylabel('time [s]')\nplt.legend()\nplt.grid()\nplt.yscale('log')\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.ylabel('time [s]') plt.legend() plt.grid() plt.yscale('log') In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/archive/_higher_order_scalability/#pathpy-20","title":"Pathpy 2.0\u00b6","text":""},{"location":"tutorial/archive/_higher_order_scalability/#pathpyg-gpu","title":"pathpyG (GPU)\u00b6","text":""},{"location":"tutorial/archive/_higher_order_scalability/#pathpyg-cpu","title":"pathpyG (CPU)\u00b6","text":""},{"location":"tutorial/archive/_scalability_analysis/","title":"scalability analysis","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nimport torch\nimport copy\nimport time\nimport numpy as np\nfrom collections import defaultdict\nimport json\n\nimport pprint \nprinter = pprint.PrettyPrinter(indent=4)\npp.config['device'] = 'cpu'\nimport seaborn as sns\n</pre> import pathpyG as pp import torch import copy import time import numpy as np from collections import defaultdict import json  import pprint  printer = pprint.PrettyPrinter(indent=4) pp.config['device'] = 'cpu' import seaborn as sns In\u00a0[2]: Copied! <pre>def test_mo_scalability(g, exp):\n    res = copy.deepcopy(exp)\n    pp.config['device'] = exp['device']\n    g.data.to(exp['device'])\n    res['temp_net_nodes'] = g.n\n    res['temp_net_edges'] = g.m\n    res['temp_net_events'] = g.data.edge_index.size(1)\n\n    start_time = time.time()\n    eg = pp.algorithms.lift_order_temporal(g, delta=exp['delta'])\n    eg.to(exp['device'])\n    res['lift_event_graph_time'] = time.time() - start_time\n    res['event_graph_edges'] = eg.size(1)\n\n    start_time = time.time()\n    m = pp.MultiOrderModel.from_temporal_graph(g, delta=exp['delta'], max_order=exp['max_order'])\n    res['mo_time'] = time.time() - start_time\n    res['max_order_nodes'] = m.layers[exp['max_order']].n\n    res['max_order_edges'] = m.layers[exp['max_order']].m\n    return res\n</pre> def test_mo_scalability(g, exp):     res = copy.deepcopy(exp)     pp.config['device'] = exp['device']     g.data.to(exp['device'])     res['temp_net_nodes'] = g.n     res['temp_net_edges'] = g.m     res['temp_net_events'] = g.data.edge_index.size(1)      start_time = time.time()     eg = pp.algorithms.lift_order_temporal(g, delta=exp['delta'])     eg.to(exp['device'])     res['lift_event_graph_time'] = time.time() - start_time     res['event_graph_edges'] = eg.size(1)      start_time = time.time()     m = pp.MultiOrderModel.from_temporal_graph(g, delta=exp['delta'], max_order=exp['max_order'])     res['mo_time'] = time.time() - start_time     res['max_order_nodes'] = m.layers[exp['max_order']].n     res['max_order_edges'] = m.layers[exp['max_order']].m     return res  In\u00a0[3]: Copied! <pre>results = defaultdict(lambda: defaultdict())\nexp = {}\n\ng = pp.io.read_netzschleuder_graph('copenhagen', 'sms', time_attr='timestamp')\nprint(g)\nfor d in ['cuda', 'cpu']:\n    exp['device'] = d\n    for delta in np.linspace(30, 3600, 5):\n        exp['delta'] = delta\n        for k in range(2, 6):\n            exp['max_order'] = k\n            try:\n                res = test_mo_scalability(g, exp)\n                printer.pprint(res)\n                results[delta][k] = res\n            except Exception as e:\n                print(e)\n\nwith open('results_copenhagen.json', 'w') as f:\n    json.dump(results, f)\n</pre> results = defaultdict(lambda: defaultdict()) exp = {}  g = pp.io.read_netzschleuder_graph('copenhagen', 'sms', time_attr='timestamp') print(g) for d in ['cuda', 'cpu']:     exp['device'] = d     for delta in np.linspace(30, 3600, 5):         exp['delta'] = delta         for k in range(2, 6):             exp['max_order'] = k             try:                 res = test_mo_scalability(g, exp)                 printer.pprint(res)                 results[delta][k] = res             except Exception as e:                 print(e)  with open('results_copenhagen.json', 'w') as f:     json.dump(results, f) <pre>Mapping node attributes based on node indices in column `index`\nTemporal Graph with 568 nodes, 1303 unique edges and 24333 events in [18.0, 2418982.0]\n\nNode attributes\n\tnode_female\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([568])\n\tnode_id\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([568])\n\tnode__pos\t\t&lt;class 'numpy.ndarray'&gt;\n\nEdge attributes\n\ttime\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([24333])\n\tedge_index\t\t&lt;class 'torch_geometric.edge_index.EdgeIndex'&gt;\n\nGraph attributes\n\tanalyses_edge_properties\t\t&lt;class 'list'&gt;\n\tanalyses_num_edges\t\t&lt;class 'int'&gt;\n\tanalyses_degree_assortativity\t\t&lt;class 'float'&gt;\n\tanalyses_mixing_time\t\t&lt;class 'float'&gt;\n\tanalyses_diameter\t\t&lt;class 'int'&gt;\n\tanalyses_largest_component_fraction\t\t&lt;class 'float'&gt;\n\tanalyses_is_directed\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_2\t\t&lt;class 'float'&gt;\n\tanalyses_num_vertices\t\t&lt;class 'int'&gt;\n\tanalyses_vertex_properties\t\t&lt;class 'list'&gt;\n\tanalyses_edge_reciprocity\t\t&lt;class 'float'&gt;\n\tanalyses_is_bipartite\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_1\t\t&lt;class 'float'&gt;\n\tanalyses_transition_gap\t\t&lt;class 'float'&gt;\n\tanalyses_average_degree\t\t&lt;class 'float'&gt;\n\tanalyses_hashimoto_radius\t\t&lt;class 'float'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tanalyses_degree_std_dev\t\t&lt;class 'float'&gt;\n\tanalyses_global_clustering\t\t&lt;class 'float'&gt;\n\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2167.73it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2088.86it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.122706413269043,\n    'max_order': 2,\n    'max_order_edges': 557,\n    'max_order_nodes': 1303,\n    'mo_time': 12.025795459747314,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2038.99it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2069.14it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.795116186141968,\n    'max_order': 3,\n    'max_order_edges': 229,\n    'max_order_nodes': 557,\n    'mo_time': 11.878443956375122,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2042.28it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2011.84it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.777009963989258,\n    'max_order': 4,\n    'max_order_edges': 110,\n    'max_order_nodes': 229,\n    'mo_time': 12.220279693603516,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2074.25it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2061.54it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.595112562179565,\n    'max_order': 5,\n    'max_order_edges': 61,\n    'max_order_nodes': 110,\n    'mo_time': 12.093271017074585,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1082.67it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1130.39it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 22.232107639312744,\n    'max_order': 2,\n    'max_order_edges': 1236,\n    'max_order_nodes': 1303,\n    'mo_time': 21.630196571350098,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1095.26it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1120.23it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 21.974792957305908,\n    'max_order': 3,\n    'max_order_edges': 1122,\n    'max_order_nodes': 1236,\n    'mo_time': 22.22197437286377,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1107.00it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1109.25it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 21.74143648147583,\n    'max_order': 4,\n    'max_order_edges': 1008,\n    'max_order_nodes': 1122,\n    'mo_time': 22.65464735031128,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1091.36it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1142.30it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 22.076518774032593,\n    'max_order': 5,\n    'max_order_edges': 878,\n    'max_order_nodes': 1008,\n    'mo_time': 22.64402413368225,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1059.94it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:26&lt;00:00, 896.10it/s] \n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 22.712382793426514,\n    'max_order': 2,\n    'max_order_edges': 1344,\n    'max_order_nodes': 1303,\n    'mo_time': 27.22113013267517,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:28&lt;00:00, 844.85it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:27&lt;00:00, 889.93it/s] \n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 28.49084734916687,\n    'max_order': 3,\n    'max_order_edges': 1306,\n    'max_order_nodes': 1344,\n    'mo_time': 27.783222198486328,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:23&lt;00:00, 1003.20it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:24&lt;00:00, 966.13it/s] \n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 24.00903582572937,\n    'max_order': 4,\n    'max_order_edges': 1279,\n    'max_order_nodes': 1306,\n    'mo_time': 26.02214217185974,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:23&lt;00:00, 1032.85it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1111.71it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 23.30103063583374,\n    'max_order': 5,\n    'max_order_edges': 1232,\n    'max_order_nodes': 1279,\n    'mo_time': 32.56914210319519,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1102.31it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:18&lt;00:00, 1283.34it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 21.834106922149658,\n    'max_order': 2,\n    'max_order_edges': 1408,\n    'max_order_nodes': 1303,\n    'mo_time': 19.122129917144775,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:17&lt;00:00, 1371.76it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:23&lt;00:00, 1042.82it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 17.55621361732483,\n    'max_order': 3,\n    'max_order_edges': 1420,\n    'max_order_nodes': 1408,\n    'mo_time': 23.811742305755615,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1078.05it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1062.19it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 22.32985234260559,\n    'max_order': 4,\n    'max_order_edges': 1448,\n    'max_order_nodes': 1420,\n    'mo_time': 23.88112759590149,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:25&lt;00:00, 950.98it/s] \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:24&lt;00:00, 976.45it/s] \n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 25.302610397338867,\n    'max_order': 5,\n    'max_order_edges': 1452,\n    'max_order_nodes': 1448,\n    'mo_time': 58.79792809486389,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1140.34it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1482.82it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 21.1067316532135,\n    'max_order': 2,\n    'max_order_edges': 1453,\n    'max_order_nodes': 1303,\n    'mo_time': 16.5167076587677,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:15&lt;00:00, 1506.81it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:18&lt;00:00, 1323.43it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 15.98039698600769,\n    'max_order': 3,\n    'max_order_edges': 1506,\n    'max_order_nodes': 1453,\n    'mo_time': 18.9002103805542,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1448.36it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1452.72it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 16.622321605682373,\n    'max_order': 4,\n    'max_order_edges': 1594,\n    'max_order_nodes': 1506,\n    'mo_time': 17.679415464401245,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1473.71it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:15&lt;00:00, 1547.80it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 16.335521936416626,\n    'max_order': 5,\n    'max_order_edges': 1674,\n    'max_order_nodes': 1594,\n    'mo_time': 126.71205115318298,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2870.65it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2878.70it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.384625434875488,\n    'max_order': 2,\n    'max_order_edges': 557,\n    'max_order_nodes': 1303,\n    'mo_time': 8.44395112991333,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2934.42it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2889.33it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.201921463012695,\n    'max_order': 3,\n    'max_order_edges': 229,\n    'max_order_nodes': 557,\n    'mo_time': 8.436858654022217,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2906.52it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2908.75it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.282766819000244,\n    'max_order': 4,\n    'max_order_edges': 110,\n    'max_order_nodes': 229,\n    'mo_time': 8.383979320526123,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2896.13it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2940.09it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.31244707107544,\n    'max_order': 5,\n    'max_order_edges': 61,\n    'max_order_nodes': 110,\n    'mo_time': 8.297135353088379,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:09&lt;00:00, 2424.21it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2379.18it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 9.95227837562561,\n    'max_order': 2,\n    'max_order_edges': 1236,\n    'max_order_nodes': 1303,\n    'mo_time': 10.21712613105774,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2373.41it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2403.32it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 10.163817644119263,\n    'max_order': 3,\n    'max_order_edges': 1122,\n    'max_order_nodes': 1236,\n    'mo_time': 10.227073669433594,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:09&lt;00:00, 2415.48it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2388.56it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 9.988727569580078,\n    'max_order': 4,\n    'max_order_edges': 1008,\n    'max_order_nodes': 1122,\n    'mo_time': 10.93671178817749,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:09&lt;00:00, 2404.24it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2394.89it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 10.032788515090942,\n    'max_order': 5,\n    'max_order_edges': 878,\n    'max_order_nodes': 1008,\n    'mo_time': 16.719266414642334,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2240.81it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2338.14it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.765197515487671,\n    'max_order': 2,\n    'max_order_edges': 1344,\n    'max_order_nodes': 1303,\n    'mo_time': 10.433187007904053,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2329.00it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2352.14it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.362721920013428,\n    'max_order': 3,\n    'max_order_edges': 1306,\n    'max_order_nodes': 1344,\n    'mo_time': 10.513421058654785,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2353.53it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2286.25it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.253392696380615,\n    'max_order': 4,\n    'max_order_edges': 1279,\n    'max_order_nodes': 1306,\n    'mo_time': 12.241335153579712,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2351.43it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2389.42it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.25893259048462,\n    'max_order': 5,\n    'max_order_edges': 1232,\n    'max_order_nodes': 1279,\n    'mo_time': 24.42807126045227,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2166.44it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2259.16it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 11.133711338043213,\n    'max_order': 2,\n    'max_order_edges': 1408,\n    'max_order_nodes': 1303,\n    'mo_time': 10.760009765625,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2304.09it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2265.84it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 10.470611095428467,\n    'max_order': 3,\n    'max_order_edges': 1420,\n    'max_order_nodes': 1408,\n    'mo_time': 10.977295637130737,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2313.20it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2345.28it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 10.43064832687378,\n    'max_order': 4,\n    'max_order_edges': 1448,\n    'max_order_nodes': 1420,\n    'mo_time': 12.300642490386963,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2258.72it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2333.72it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 10.682463884353638,\n    'max_order': 5,\n    'max_order_edges': 1452,\n    'max_order_nodes': 1448,\n    'mo_time': 36.225979804992676,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:12&lt;00:00, 1882.08it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2125.78it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 12.819502115249634,\n    'max_order': 2,\n    'max_order_edges': 1453,\n    'max_order_nodes': 1303,\n    'mo_time': 11.431120872497559,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2244.69it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2262.04it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 10.74588942527771,\n    'max_order': 3,\n    'max_order_edges': 1506,\n    'max_order_nodes': 1453,\n    'mo_time': 10.993196725845337,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2252.99it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2266.47it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 10.709041357040405,\n    'max_order': 4,\n    'max_order_edges': 1594,\n    'max_order_nodes': 1506,\n    'mo_time': 13.24429202079773,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2223.72it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2248.93it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 10.85075306892395,\n    'max_order': 5,\n    'max_order_edges': 1674,\n    'max_order_nodes': 1594,\n    'mo_time': 63.68161463737488,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> In\u00a0[4]: Copied! <pre>results_rm = defaultdict(lambda: defaultdict())\nexp = {}\n\ng = pp.io.read_netzschleuder_graph('reality_mining', time_attr='time')\nprint(g)\nfor d in ['cuda', 'cpu']:\n    exp['device'] = d\n    for delta in np.linspace(300, 3600, 5):\n        exp['delta'] = delta\n        for k in range(2, 6):\n            exp['max_order'] = k\n            try:\n                res = test_mo_scalability(g, exp)\n                printer.pprint(res)\n                results_rm[delta][k] = res\n            except Exception as e:\n                print(e)\n\n            with open('results_rm_realitymining.json', 'w') as f:\n                json.dump(results_rm, f)\n</pre> results_rm = defaultdict(lambda: defaultdict()) exp = {}  g = pp.io.read_netzschleuder_graph('reality_mining', time_attr='time') print(g) for d in ['cuda', 'cpu']:     exp['device'] = d     for delta in np.linspace(300, 3600, 5):         exp['delta'] = delta         for k in range(2, 6):             exp['max_order'] = k             try:                 res = test_mo_scalability(g, exp)                 printer.pprint(res)                 results_rm[delta][k] = res             except Exception as e:                 print(e)              with open('results_rm_realitymining.json', 'w') as f:                 json.dump(results_rm, f) <pre>Mapping node attributes based on node indices in column `index`\nTemporal Graph with 96 nodes, 5078 unique edges and 2172808 events in [1095183104.0, 1115253760.0]\n\nNode attributes\n\tnode__pos\t\t&lt;class 'numpy.ndarray'&gt;\n\nEdge attributes\n\ttime\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2172808])\n\tedge_index\t\t&lt;class 'torch_geometric.edge_index.EdgeIndex'&gt;\n\nGraph attributes\n\tanalyses_edge_properties\t\t&lt;class 'list'&gt;\n\tanalyses_num_edges\t\t&lt;class 'int'&gt;\n\tanalyses_degree_assortativity\t\t&lt;class 'float'&gt;\n\tanalyses_mixing_time\t\t&lt;class 'float'&gt;\n\tanalyses_diameter\t\t&lt;class 'int'&gt;\n\tanalyses_largest_component_fraction\t\t&lt;class 'float'&gt;\n\tanalyses_is_directed\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_2\t\t&lt;class 'float'&gt;\n\tanalyses_num_vertices\t\t&lt;class 'int'&gt;\n\tanalyses_vertex_properties\t\t&lt;class 'list'&gt;\n\tanalyses_edge_reciprocity\t\t&lt;class 'float'&gt;\n\tanalyses_is_bipartite\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_1\t\t&lt;class 'float'&gt;\n\tanalyses_transition_gap\t\t&lt;class 'float'&gt;\n\tanalyses_average_degree\t\t&lt;class 'float'&gt;\n\tanalyses_hashimoto_radius\t\t&lt;class 'float'&gt;\n\tanalyses_degree_std_dev\t\t&lt;class 'float'&gt;\n\tanalyses_global_clustering\t\t&lt;class 'float'&gt;\n\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:05&lt;00:00, 267.26it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:04&lt;00:00, 268.49it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:04&lt;00:00, 268.28it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:03&lt;00:00, 270.22it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:37&lt;00:00, 153.98it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:35&lt;00:00, 155.29it/s]\n</pre> <pre>{   'delta': 1125.0,\n    'device': 'cuda',\n    'event_graph_edges': 55088257,\n    'lift_event_graph_time': 217.30356216430664,\n    'max_order': 2,\n    'max_order_edges': 68938,\n    'max_order_nodes': 5078,\n    'mo_time': 243.20855259895325,\n    'temp_net_edges': 2172808,\n    'temp_net_events': 2172808,\n    'temp_net_nodes': 96}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:36&lt;00:00, 154.75it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:34&lt;00:00, 155.62it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 13.03 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 16.23 GiB is allocated by PyTorch, and 576.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:02&lt;00:00, 138.14it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:04&lt;00:00, 137.04it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 13.03 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 16.23 GiB is allocated by PyTorch, and 576.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:01&lt;00:00, 138.29it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:04&lt;00:00, 136.87it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 13.03 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 16.23 GiB is allocated by PyTorch, and 576.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:10&lt;00:00, 133.29it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:10&lt;00:00, 133.48it/s]\n</pre> <pre>{   'delta': 1950.0,\n    'device': 'cuda',\n    'event_graph_edges': 96946987,\n    'lift_event_graph_time': 251.03341007232666,\n    'max_order': 2,\n    'max_order_edges': 74773,\n    'max_order_nodes': 5078,\n    'mo_time': 281.3313329219818,\n    'temp_net_edges': 2172808,\n    'temp_net_events': 2172808,\n    'temp_net_nodes': 96}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:10&lt;00:00, 133.66it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:11&lt;00:00, 133.02it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 41.73 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.80 GiB is allocated by PyTorch, and 11.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [40:51&lt;00:00, 13.65it/s]  \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [49:33&lt;00:00, 11.25it/s]  \n</pre> <pre>CUDA out of memory. Tried to allocate 41.73 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.80 GiB is allocated by PyTorch, and 11.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [40:54&lt;00:00, 13.63it/s]  \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [49:35&lt;00:00, 11.24it/s]  \n</pre> <pre>CUDA out of memory. Tried to allocate 41.73 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.80 GiB is allocated by PyTorch, and 11.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [51:22&lt;00:00, 10.85it/s]  \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [53:05&lt;00:00, 10.50it/s]  \n</pre> <pre>{   'delta': 2775.0,\n    'device': 'cuda',\n    'event_graph_edges': 124683153,\n    'lift_event_graph_time': 3082.5759828090668,\n    'max_order': 2,\n    'max_order_edges': 77875,\n    'max_order_nodes': 5078,\n    'mo_time': 3224.959701538086,\n    'temp_net_edges': 2172808,\n    'temp_net_events': 2172808,\n    'temp_net_nodes': 96}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [50:31&lt;00:00, 11.03it/s]  \n 44%|\u2588\u2588\u2588\u2588\u258e     | 14586/33452 [22:45&lt;29:25, 10.68it/s]  \n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[4], line 13\n     11 exp['max_order'] = k\n     12 try:\n---&gt; 13     res = test_mo_scalability(g, exp)\n     14     printer.pprint(res)\n     15     results_rm[delta][k] = res\n\nCell In[2], line 16, in test_mo_scalability(g, exp)\n     13 res['event_graph_edges'] = eg.size(1)\n     15 start_time = time.time()\n---&gt; 16 m = pp.MultiOrderModel.from_temporal_graph(g, delta=exp['delta'], max_order=exp['max_order'])\n     17 res['mo_time'] = time.time() - start_time\n     18 res['max_order_nodes'] = m.layers[exp['max_order']].N\n\nFile /workspaces/pathpyG/src/pathpyG/core/multi_order_model.py:108, in MultiOrderModel.from_temporal_graph(g, delta, max_order, weight, cached)\n    106 if max_order &gt; 1:\n    107     node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n--&gt; 108     edge_index = lift_order_temporal(g, delta)\n    109     edge_weight = aggregate_node_attributes(edge_index, edge_weight, \"src\")\n    111     # Aggregate\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/temporal.py:39, in lift_order_temporal(g, delta)\n     36 dst_node_mask = torch.isin(edge_index[0], edge_index[1, src_edge_idx])\n     37 dst_edge_idx = indices[dst_time_mask &amp; dst_node_mask]\n---&gt; 39 if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n     40 \n     41     # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges\n     42     x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n     43     # print(x.size(1))\n\nKeyboardInterrupt: </pre> In\u00a0[\u00a0]: Copied! <pre>order = [] \neg_time = []\nmo_time = []\ndelta = 3600.\n\nfor k in results[delta]:\n    order.append(k)\n    eg_time.append(results[delta][k]['lift_event_graph_time'])\n    mo_time.append(results[delta][k]['mo_time']-results[delta][k]['lift_event_graph_time'])\nsns.lineplot(x=order, y=eg_time, label='event graph')\nsns.lineplot(x=order, y=mo_time, label='order lifting')\n</pre> order = []  eg_time = [] mo_time = [] delta = 3600.  for k in results[delta]:     order.append(k)     eg_time.append(results[delta][k]['lift_event_graph_time'])     mo_time.append(results[delta][k]['mo_time']-results[delta][k]['lift_event_graph_time']) sns.lineplot(x=order, y=eg_time, label='event graph') sns.lineplot(x=order, y=mo_time, label='order lifting') Out[\u00a0]: <pre>&lt;Axes: &gt;</pre>"}]}