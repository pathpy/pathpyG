{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pathpyG","text":"<p>This is the index page of the pathpyG documentation.</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#what-is-pathpyg","title":"What is pathpyG?","text":"<p>pathpyG is an Open Source package facilitating GPU-accelerated next-generation network analytics and graph learning for time series data on graphs.</p> <p>pathpyG is tailored to analyse time-stamped network data as well as sequential data that capture multiple short walks or paths observed in a graph or network. Examples for data that can be analysed with pathpyG include high-resolution time-stamped network data, dynamic social networks, user click streams on the Web, biological pathway data, directed acyclic graphs like citation networks, passenger trajectories in transportation networks, or trajectories of information propagation in social networks.</p> <p>pathpyG is fully integrated with jupyter, providing rich interactive visualisations of networks, temporal networks, and higher-order models. Visualisations can be exported to HTML5 files that can be shared and published on the Web.</p>"},{"location":"about/#what-is-the-science-behind-pathpyg","title":"What is the science behind pathpyG?","text":"<p>The theoretical foundation of this package, higher- and multi-order network models, was developed in the following peer-reviewed research articles:</p> <ol> <li>L Qarkaxhija, V Perri, I Scholtes: De Bruijn goes Neural: Causality-Aware Graph Neural Networks for Time Series Data on Dynamic Graphs, In Proceedings of the First Learning on Graphs Conference, PMLR 198:51:1-51:21, December 2022</li> <li>L Petrovic, I Scholtes: Learning the Markov order of paths in graphs, In Proceedings of WWW '22: The Web Conference 2022, Lyon, France, April 2022</li> <li>V Perri, I Scholtes: HOTVis: Higher-Order Time-Aware Visualisation of Dynamic Graphs, In Proceedings of the 28<sup>th</sup> International Symposium on Graph Drawing and Network Visualization (GD 2020), Vancouver, BC, Canada, September 15-18, 2020</li> <li>I Scholtes: When is a network a network? Multi-Order Graphical Model Selection in Pathways and Temporal Networks, In KDD'17 - Proceedings of the 23<sup>rd</sup> ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, Nova Scotia, Canada, August 13-17, 2017</li> <li>I Scholtes, N Wider, A Garas: Higher-Order Aggregate Networks in the Analysis of Temporal Networks: Path structures and centralities, The European Physical Journal B, 89:61, March 2016</li> <li>I Scholtes, N Wider, R Pfitzner, A Garas, CJ Tessone, F Schweitzer: Causality-driven slow-down and speed-up of diffusion in non-Markovian temporal networks, Nature Communications, 5, September 2014</li> <li>R Pfitzner, I Scholtes, A Garas, CJ Tessone, F Schweitzer: Betweenness preference: Quantifying correlations in the topological dynamics of temporal networks, Phys Rev Lett, 110(19), 198701, May 2013</li> </ol> <p>A broader view on the importance of higher-order graph models for complex systems can be found in this overview article. </p>"},{"location":"contributing/","title":"Contributing","text":"<p>This project is open source and welcomes contributions. In the following sections, you will find information about how to contribute to this project, set up your environment correctly, how to document your code and more.</p>"},{"location":"contributing/#overview","title":"Overview","text":"<ul> <li>Setting up your environment</li> <li>Documentation</li> <li>Code Style</li> <li>Formatting</li> <li>Testing</li> <li>Benchmarking</li> </ul>"},{"location":"contributing/#setting-up-your-environment","title":"Setting up your environment","text":""},{"location":"contributing/#clone-the-repository","title":"Clone the Repository","text":"<p>The first step is to clone the repository. You can do this by running the following command: <pre><code>git clone https://github.com/pathpy/pathpyG\n</code></pre> If you do not have the rights to push to the repository, you can also fork the repository and clone your fork instead. From there you can create a pull request to the original repository.</p>"},{"location":"contributing/#installation","title":"Installation","text":"<p>To ensure version consistency, we use a Development Container for this project.   VSCode provides an easy-to-use extension for this. Check out their official documentation for more information. Once you've installed the extension successfully,   VSCode will recommend reopening the project in the Dev Container. You can also do this manually by clicking on the button in the bottom left corner of   VSCode and then selecting <code>Reopen in Container</code>.</p> Setup without Dev Containers <p>If you do not want to use Dev Containers, you can also install the dependencies into your virtual Python environment manually. We recommend that you follow the instructions provided on our getting started page. As last step, install the package in editable mode and include the dependencies necessary for testing, documentation and general development: <pre><code>pip install -e '.[dev,test,doc]'\n</code></pre></p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>This project uses <code>MkDocs</code> for documentation. It is a static site generator that creates the necessary <code>html</code>-files automatically from the <code>markdown</code>-files and  Group.svg Created using Figma 0.90  Jupyter notebooks in the <code>docs/</code>-directory and the <code>Python</code>-files in <code>src/</code>. The documentation is hosted on GitHub Pages.</p>"},{"location":"contributing/#hosting-the-documentation-locally","title":"Hosting the documentation locally","text":"<p>You can host the documentation locally with the following command: <pre><code>mkdocs serve\n</code></pre> The documentation is then available at <code>http://localhost:8000/</code>.</p> Actual Deployment <p>The development version of the documentation is deployed automatically to GitHub Pages when something is pushed to the <code>main</code>-branch. The workflow for deploying a new stable version needs to be triggered manually. You can find it in the <code>Actions</code>-tab of the repository. Both workflows use <code>mike</code> instead of <code>MkDocs</code> to enable versioning.</p>"},{"location":"contributing/#code-reference","title":"Code Reference","text":"<p>The <code>Code Reference</code> is generated automatically from the   Python source files using <code>docs/gen_ref_pages.py</code>. The docstrings should be formatted according to the Google Python Style Guide. Be sure to also use the advanced stuff like notes, tips and more. They can e.g. look as follows:</p> DocstringResult <pre><code>\"\"\"\nNote:\n    This is a note.\n\nTip: This is a heading\n    This is a tip.\n\"\"\"\n</code></pre> <p>Note</p> <p>This is a note.</p> <p>This is a heading</p> <p>This is a tip.</p> <p>See the documentation of the underlying griffe package for more details.</p> <p>To get an overview for each package, <code>mkdocstrings</code> automatically uses the docstrings from the <code>__init__.py</code> files in each package as description. Thus, do not forget to add a docstring to each <code>__init__.py</code> file. If a package starts with an underscore (<code>_</code>), the underscore will be removed from the name in the documentation. </p>"},{"location":"contributing/#replace-automatic-code-reference","title":"Replace Automatic Code Reference","text":"<p>While the docstrings include rich functionality, it is easier to write long and detailed descriptions using <code>.md</code>-files. Therefore, you can replace the automatically generated documentation for a module by adding a <code>.md</code>-file with the same name as the module in the <code>docs/reference/</code>-directory. The file will be rendered instead of the automatically generated documentation. You can find an example in <code>docs/reference/pathpyG/index.md</code>.</p> <p>Replacing package documentation in the <code>__init__.py</code>-file</p> <p>The Overview for each package can be provided in the <code>__init__.py</code>-file. If you want to replace the <code>__init__.py</code>-file to provide a better documentation using <code>markdown</code>, make sure to name the file <code>index.md</code> instead.</p>"},{"location":"contributing/#ignore-specific-py-files","title":"Ignore specific <code>.py</code>-files","text":"<p>If you want to ignore specific <code>.py</code>-files in the code reference, you can add them to <code>docs/reference/ignored_modules.yaml</code>. All files listed there will be ignored when generating the code reference. If you include all files in a package-directory, the whole package will not be shown in the documentation.</p>"},{"location":"contributing/#tutorials","title":"Tutorials","text":"<p>The tutorials are written in  Group.svg Created using Figma 0.90  Jupyter notebooks. They are located in the <code>docs/</code>-directory. You can add new tutorials by adding the notebook to the <code>docs/tutorial/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The tutorials are automatically converted to <code>html</code>-files when the documentation is built.</p>"},{"location":"contributing/#adding-new-pages","title":"Adding new pages","text":"<p>You can add more pages to the documentation by adding a <code>markdown</code>-file to the <code>docs/</code>-directory and adding the path to the <code>mkdocs.yml</code>-file under <code>nav:</code>. The pages are automatically converted to <code>html</code>-files when the documentation is built. We are using Material for MkDocs as a theme. It includes many great features like annotations, code blocks, diagrams, admonitions and more. Check out their documentation for more information.</p>"},{"location":"contributing/#code-style","title":"Code Style","text":"<p>We (soon) enforce code style guidelines with <code>ruff</code> and <code>mypy</code>. These packages are configured as defaults in the Dev Container setup via <code>VSCode</code> and the settings are saved in <code>pyproject.toml</code>. You can run them locally with the following commands:</p> <ul> <li><code>ruff</code>: A linter that checks for errors and code style violations.     <pre><code>ruff check . # (1)!\n</code></pre><ol> <li>This runs <code>ruff</code> as a linter on all files in the current directory. You can also run <code>ruff</code> on a single file by specifying the path to the file instead. If you want to automatically fix all issues that can be fixed automatically, you can use <code>ruff check . --fix</code>.</li> </ol> </li> <li><code>mypy</code>: A static type checker for Python.     <pre><code>mypy src/ # (1)!\n</code></pre><ol> <li>This runs <code>mypy</code> on all files in <code>src/</code>. You can also run <code>mypy</code> on a single file by specifying the path to the file instead.</li> </ol> </li> </ul>"},{"location":"contributing/#formatting","title":"Formatting","text":"<p>We use <code>ruff</code> for formatting. You can run it locally with the following command:</p> <pre><code>ruff format . # (1)!\n</code></pre> <ol> <li>This command will format all files in the current directory. You can also run <code>ruff</code> on a single file or a subdirectory by specifying the path accordingly.</li> </ol> <p>The default keyboard shortcut for formatting in <code>VSCode</code> is <code>Alt + Shift + F</code>.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>We are using <code>pytest</code> for testing. You can run the tests locally with the following command: <pre><code>pytest\n</code></pre> The tests are located in the <code>tests/</code>-directory. We use <code>pytest-cov</code> to measure the test coverage and are aiming for 100% coverage with a hard limit of 80%. Tests will fail if the coverage drops below 80%.</p> <p>Add tests</p> <p>We are currently only at 60% coverage. So the lines above are currently pure fiction.</p> <p>Test that use a GPU are located in the <code>tests/gpu</code>-directory. They are currently disabled for CI but can be manually executed with <pre><code>pytest -m gpu\n</code></pre></p>"},{"location":"contributing/#benchmarking","title":"Benchmarking","text":"<p>For optimal runtime, we continually measure the execution time of our core functions using pytest benchmarks. These benchmarks are located in <code>tests/benchmarks/</code> and are unit-tests that utilize the <code>benchmark</code> fixture from <code>pytest-benchmark</code>. All of them are marked with the benchmark decorator (<code>@pytest.mark.benchmark</code>) to exclude them from the normal unit-tests. You can run all benchmarks in the command line using <pre><code>pytest -m benchmark\n</code></pre> If you are working on runtime improvements, you can compare the runtime of your changes to the runtime of the main branch by saving the results of each run with <pre><code>pytest -m benchmark --benchmark-autosave\n</code></pre> or with a custom name <code>&lt;custom-name&gt;</code> <pre><code>pytest -m benchmark --benchmark-save=&lt;custom-name&gt;\n</code></pre> After running the benchmarks both in your current branch and in the main branch, you can compare them as follows: <pre><code>pytest-benchmark compare # (1)!\n</code></pre></p> <ol> <li>This will compare all runs that are currently saved in <code>.benchmarks/</code>. If you want to compare specific runs, you can add the number of the runs at the end of the command. The numbering usually starts with <code>0001</code>.</li> </ol> <p>Note</p> <p>Since the runtime is strongly dependent on the underlying machine, we do not keep any up-to-date results on <code>git</code> and recommend to do any comparisons locally.</p>"},{"location":"docker_installation/","title":"Docker Installation","text":"<p>  PyTorch provides a  Docker image with PyTorch preinstalled. Using this image, the Dockerfile below creates a Docker image with PathpyG installed.</p> GPUCPU <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cu121 --index-url https://download.pytorch.org/whl/cu121\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre> <pre><code>FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime\nWORKDIR /workspaces/pathpyG\nRUN apt-get update\nRUN apt-get -y install git\n\nRUN pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu # CPU only\n\nRUN pip install torch_geometric&gt;=2.4.0\nRUN pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html # CPU only\nRUN pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"Generate the code reference pages and navigation.\"\"\"\n# See for more detail: https://mkdocstrings.github.io/recipes/\n</pre> \"\"\"Generate the code reference pages and navigation.\"\"\" # See for more detail: https://mkdocstrings.github.io/recipes/ In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import yaml\nimport mkdocs_gen_files\n</pre> import yaml import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n# Load the ignored modules from the YAML file\nignored_modules_path = Path(\"docs\", \"reference\", \"ignored_modules.yaml\")\nignored_modules = yaml.safe_load(ignored_modules_path.read_text(\"utf-8\"))\n</pre> nav = mkdocs_gen_files.Nav() # Load the ignored modules from the YAML file ignored_modules_path = Path(\"docs\", \"reference\", \"ignored_modules.yaml\") ignored_modules = yaml.safe_load(ignored_modules_path.read_text(\"utf-8\")) In\u00a0[\u00a0]: Copied! <pre>for path in sorted(Path(\"src\").rglob(\"*.py\")):\n    if ignored_modules and str(path.relative_to(\".\")) in ignored_modules:\n        print(f\"Skipping {path} as it is in the ignored modules list.\")\n        continue\n    module_path = path.relative_to(\"src\").with_suffix(\"\")\n    doc_path = path.relative_to(\"src\").with_suffix(\".md\")\n    full_doc_path = Path(\"reference\", doc_path)\n\n    parts = tuple(module_path.parts)\n\n    if parts[-1] == \"__init__\":\n        parts = parts[:-1]\n        doc_path = doc_path.with_name(\"index.md\")\n        full_doc_path = full_doc_path.with_name(\"index.md\")\n    elif parts[-1] == \"__main__\":\n        continue\n\n    parts_list = []\n    for part in parts:\n        if part.startswith(\"_\"):\n            parts_list.append(part.split(\"_\")[-1])\n        else:\n            parts_list.append(part)\n    \n    nav[tuple(parts_list)] = doc_path.as_posix()\n\n    print(f\"Checking {full_doc_path}\")\n    if not (Path(\"docs\") / full_doc_path).exists():\n        with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n            ident = \".\".join(parts)\n            fd.write(f\"::: {ident}\")\n    else:\n        print(f\"File {full_doc_path} already exists, skipping.\")\n\n    mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path)\n</pre> for path in sorted(Path(\"src\").rglob(\"*.py\")):     if ignored_modules and str(path.relative_to(\".\")) in ignored_modules:         print(f\"Skipping {path} as it is in the ignored modules list.\")         continue     module_path = path.relative_to(\"src\").with_suffix(\"\")     doc_path = path.relative_to(\"src\").with_suffix(\".md\")     full_doc_path = Path(\"reference\", doc_path)      parts = tuple(module_path.parts)      if parts[-1] == \"__init__\":         parts = parts[:-1]         doc_path = doc_path.with_name(\"index.md\")         full_doc_path = full_doc_path.with_name(\"index.md\")     elif parts[-1] == \"__main__\":         continue      parts_list = []     for part in parts:         if part.startswith(\"_\"):             parts_list.append(part.split(\"_\")[-1])         else:             parts_list.append(part)          nav[tuple(parts_list)] = doc_path.as_posix()      print(f\"Checking {full_doc_path}\")     if not (Path(\"docs\") / full_doc_path).exists():         with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:             ident = \".\".join(parts)             fd.write(f\"::: {ident}\")     else:         print(f\"File {full_doc_path} already exists, skipping.\")      mkdocs_gen_files.set_edit_path(full_doc_path, Path(\"../\") / path) In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(\"reference/SUMMARY.md\", \"w\") as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"getting_started/","title":"Getting Started","text":"<p>The following will guide you through the installation of the package and the first steps to use it.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>PathpyG is available for   Python versions 3.10 and above. It is not recommended to install it on your system Python. Instead, we recommend using a virtual environment such as   conda or virtualenv. You can also set up a   Docker image as described in the next section.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<p>Once you have an environment up and running, you can install the package simply via pip. But first make sure that you installed the necessary dependencies.</p>"},{"location":"getting_started/#dependencies","title":"Dependencies","text":"<p>This package is based on   PyTorch and   PyTorch Geometric. Please install both libraries before installing PathpyG. You can follow the installation instructions in their respective documentation (  PyTorch and   PyG). Alternatively, you can install the correct versions of both libraries using <code>uv</code> to install the optional dependencies of PathpyG. You can choose between a CPU-only installation or a CUDA installation for a specific CUDA version. For example, to install the CPU-only version, run:</p> <p><pre><code>uv pip install pathpyg[cpu]\n</code></pre> Or, to install the CUDA 12.9 version, run:</p> <pre><code>uv pip install pathpyg[cu129]\n</code></pre> <p>Warning</p> <p>We currently only support PyG version 2.5.0 and above.</p>"},{"location":"getting_started/#install-stable-release","title":"Install Stable Release","text":"<p>You can install the latest stable release of PathpyG via pip:</p> <p>TODO</p> <p>This is not yet available. We will release the first stable version soon.</p> <pre><code>pip install pathpyg\n</code></pre>"},{"location":"getting_started/#install-latest-development-version","title":"Install Latest Development Version","text":"<p>If you want to install the latest development version, you can do so via pip directly from the GitHub repository:</p> <pre><code>pip install git+https://github.com/pathpy/pathpyG.git\n</code></pre>"},{"location":"getting_started/#optional-visualisation-backends","title":"Optional Visualisation Backends","text":"<p>We provide multiple visualisation backends for PathpyG. The default backend D3.js does not require any additional dependencies. We further provide a Matplotlib backend that is installed by default. Additionally, we implemented a tikz and a Manim backend that are not installed by default due to their dependencies that are required for installation. You can use the tikz backend if you have a LaTeX distribution installed on your system. </p> <p>To use the Manim backend, please refer to the Manim installation instructions for more information. Once installed, you can use the backends for visualisation by setting the <code>backend</code> in the <code>PathpyG.plot</code> function to <code>tikz</code> or <code>manim</code>:</p> Using the TikZ Backend <pre><code>import pathpyg as pp\n\ng = pp.Graph.from_edge_list([('a', 'b'),('b', 'c'),('c', 'a')])\npp.plot(g, backend='tikz')\n</code></pre> Using the Manim Backend <pre><code>import pathpyg as pp\n\nt_graph = TemporalGraph.from_edge_list([('a', 'b', 1),('b', 'a', 3), ('b', 'c', 3)])\npp.plot(t_graph, backend='manim')\n</code></pre>"},{"location":"plot_tutorial/","title":"Developing your own Plots","text":"<p>Overview</p> <p>Add a new histogram plot to pathpyG\u2019s visualisation stack, wire it into <code>pp.plot(...)</code>, and render it with Matplotlib. This guide explains the data-prep vs. rendering split and shows the minimal pieces to implement.</p> <p>This tutorial shows how to add a new plotting capability to pathpyG\u2019s visualisation backend by implementing a histogram plot. You\u2019ll learn how plot types, backends, and configuration work together, and how to add a new plot into the public <code>pp.plot(...)</code> entry point.</p> <p>What you\u2019ll do</p> <ul> <li> Understand the new visualisation architecture</li> <li> Implement a new <code>HistogramPlot</code> that prepares data</li> <li> Wire it into the plot orchestrator and select backends</li> <li> Add Matplotlib rendering support for the new type</li> <li> Use and (optionally) test your new plot</li> </ul> <p>Scope</p> <p>This guide focuses on Matplotlib for rendering histograms (a natural fit). You can add other backends later following the same pattern.</p>"},{"location":"plot_tutorial/#visualisation-architecture-at-a-glance","title":"Visualisation architecture at a glance","text":"<p>The visualisation module is built around two core abstractions and a single entry point:</p> <ul> <li> <code>PathPyPlot</code> prepares data/config for rendering. Subclass it for each plot type.</li> <li> <code>PlotBackend</code> renders a given <code>PathPyPlot</code> using a concrete engine (Matplotlib, TikZ, d3.js, Manim).</li> <li> <code>plot(...)</code> is the public API. It chooses a plot class (kind) and a backend (by argument or filename extension), instantiates both, then saves or shows.</li> </ul> <p>Reference</p> <p>See the module overview for supported backends, formats, and styling options. For existing plot types, see <code>NetworkPlot</code> (static) and <code>TemporalNetworkPlot</code> (temporal). For existing backends, see e.g. <code>MatplotlibBackend</code> which we will be using.</p>"},{"location":"plot_tutorial/#define-a-new-plot-type-histogramplot","title":"Define a new plot type: HistogramPlot","text":"<p>Start by creating a new subclass of <code>PathPyPlot</code> (e.g., in <code>src/pathpyG/visualisations/histogram_plot.py</code>). Its job is to:</p> <ul> <li>Accept the input object(s) (typically a <code>Graph</code>) and user options</li> <li>Compute or collect the values to be binned</li> <li>Populate <code>self.data</code> with a clean, backend-agnostic structure</li> <li>Update <code>self.config</code> with plot configuration (bins, labels, etc.)</li> </ul> <p>Minimal class attributes</p> <p>Inputs: <code>graph: Graph</code>, <code>key: str</code> (what to measure), <code>bins: int | sequence</code>, plus style options via <code>**kwargs</code>.</p> <p>Data format (suggested): - <code>self.data[\"hist_values\"]: list[float | int]</code> \u2014 the values to bin - optionally precomputed bins/edges (if you want backend-agnostic binning) - <code>self.config</code> should include <code>title</code>, <code>xlabel</code>, <code>ylabel</code>, and <code>bins</code></p>"},{"location":"plot_tutorial/#example-outline","title":"Example outline:","text":"<pre><code># src/pathpyG/visualisations/histogram_plot.py\nfrom __future__ import annotations\nimport logging\nfrom typing import Any\nfrom pathpyG.visualisations.pathpy_plot import PathPyPlot\nfrom pathpyG.core.graph import Graph\n\nlogger = logging.getLogger(\"root\")\n\n\nclass HistogramPlot(PathPyPlot):\n    \"\"\"Prepare data for histogram visualisation.\n\n    Collects values from a Graph according to `key` and exposes them in\n    `self.data[\"hist_values\"]` for backends to render.\n    \"\"\"\n\n    _kind = \"histogram\"\n\n    def __init__(self, graph: Graph, key: str = \"degree\", bins: int | list[int] = 10, **kwargs: Any) -&gt; None:\n        super().__init__()\n        self.graph = graph\n        # merge kwargs into config; ensure required fields are present\n        self.config.update({\n            \"bins\": bins,\n            \"title\": kwargs.pop(\"title\", f\"{key.title()} distribution\"),\n            \"xlabel\": kwargs.pop(\"xlabel\", key),\n            \"ylabel\": kwargs.pop(\"ylabel\", \"count\"),\n        })\n        self.key = key\n        self.config.update(kwargs)\n        self.generate()\n\n    def generate(self) -&gt; None:\n        # Compute values to bin based on `key`\n        if self.key in (\"degree\", \"degrees\"):\n            values = list(self.graph.degrees().values())\n        elif self.key in (\"in_degree\", \"indegree\", \"in-degrees\"):\n            values = list(self.graph.degrees(mode=\"in\").values())\n        elif self.key in (\"out_degree\", \"outdegree\", \"out-degrees\"):\n            values = list(self.graph.degrees(mode=\"out\").values())\n        else:\n            logger.error(f\"Histogram key '{self.key}' not supported.\")\n            raise KeyError(self.key)\n\n        self.data[\"hist_values\"] = values\n</code></pre> <p>Note</p> <ul> <li>Keep the class small: gather values and fill <code>self.data</code>/<code>self.config</code>.</li> <li>Choose names that are clear for backends (<code>hist_values</code>, <code>bins</code>, labels).</li> </ul>"},{"location":"plot_tutorial/#add-the-new-plot-to-the-public-api","title":"Add the new plot to the public API","text":"<p><code>plot(...)</code> uses the <code>PLOT_CLASSES</code> mapping to instantiate the right plot class for a given <code>kind</code>. Extend it with your new class:</p> <pre><code># src/pathpyG/visualisations/plot_function.py\nfrom pathpyG.visualisations.histogram_plot import HistogramPlot\n\nPLOT_CLASSES: dict = {\n    \"static\": NetworkPlot,\n    \"temporal\": TemporalNetworkPlot,\n    \"histogram\": HistogramPlot,  # add this line\n}\n</code></pre> Usage <pre><code>import pathpyG as pp\n\ng = pp.Graph.from_edge_list([(\"a\", \"b\"), (\"b\", \"c\"), (\"a\", \"c\")])\n# Matplotlib is the natural backend for histograms\npp.plot(g, kind=\"histogram\", backend=\"matplotlib\", key=\"degree\", bins=10, filename=\"degree_hist.png\")\n</code></pre> <p>Backend selection</p> <p><code>plot(...)</code> auto-selects a backend from the filename extension if you omit <code>backend</code>. For histograms, prefer PNG via Matplotlib by passing <code>filename=\"...png\"</code> or <code>backend=\"matplotlib\"</code>.</p>"},{"location":"plot_tutorial/#add-matplotlib-support-for-histogramplot","title":"Add Matplotlib support for HistogramPlot","text":"<p>Backends validate supported plot types. The Matplotlib backend currently supports <code>NetworkPlot</code> and renders nodes/edges. We\u2019ll extend it to also support <code>HistogramPlot</code>.</p> <p>Implementation approach:</p> <ol> <li>Add <code>HistogramPlot</code> to <code>SUPPORTED_KINDS</code> so the backend accepts the plot type.</li> <li>Branch in <code>to_fig()</code> (or factor out into a helper) to draw a histogram when the plot is a <code>HistogramPlot</code>.</li> </ol> <p>Sketch of the required changes (condensed for illustration):</p> <pre><code># src/pathpyG/visualisations/_matplotlib/backend.py\nfrom pathpyG.visualisations.histogram_plot import HistogramPlot\n\nSUPPORTED_KINDS = {\n    NetworkPlot: \"static\",\n    HistogramPlot: \"histogram\",  # add support\n}\n\nclass MatplotlibBackend(PlotBackend):\n    ...\n    def to_fig(self) -&gt; tuple[plt.Figure, plt.Axes]:\n        # If histogram: render using ax.hist\n        if self._kind == \"histogram\":\n            return self._to_fig_histogram()\n        # Else: existing network rendering\n        return self._to_fig_network()\n\n    def _to_fig_histogram(self) -&gt; tuple[plt.Figure, plt.Axes]:\n        fig, ax = plt.subplots(\n            figsize=(unit_str_to_float(self.config[\"width\"], \"in\"), unit_str_to_float(self.config[\"height\"], \"in\")),\n            dpi=150,\n        )\n        ax.set_axis_on()\n        ax.hist(self.data[\"hist_values\"], bins=self.config.get(\"bins\", 10), color=rgb_to_hex(self.config[\"node\"][\"color\"]), alpha=0.9)\n        ax.set_title(self.config.get(\"title\", \"Histogram\"))\n        ax.set_xlabel(self.config.get(\"xlabel\", \"value\"))\n        ax.set_ylabel(self.config.get(\"ylabel\", \"count\"))\n        return fig, ax\n\n    def _to_fig_network(self) -&gt; tuple[plt.Figure, plt.Axes]:\n        # move existing implementation of `to_fig` here\n        ...\n</code></pre> <p>Tips</p> <ul> <li>Reuse <code>unit_str_to_float</code> so sizing behaves like other plots.</li> <li>Use a default color from <code>self.config[\"node\"][\"color\"]</code> for consistency.</li> <li>Keep the new code path fully separate from the network drawing code to avoid regressions.</li> </ul> If you want web or LaTeX histograms <p>The current d3.js and TikZ backends are tailored to network visualisation (they expect <code>nodes</code>/<code>edges</code> in <code>self.data</code>). To add histogram support there, you would:</p> <ul> <li>Create a new JS or TeX template for histograms</li> <li>Extend the backend to accept <code>HistogramPlot</code> and dispatch to the new template</li> </ul> <p>Start with Matplotlib first \u2014 it's a good starting point.</p>"},{"location":"plot_tutorial/#try-it-out","title":"Try it out","text":"<p>Once you\u2019ve added the <code>HistogramPlot</code>, updated <code>PLOT_CLASSES</code>, and extended the Matplotlib backend as shown, you can create and save a histogram in a single call:</p> <pre><code>import pathpyG as pp\n\ng = pp.Graph.from_edge_list([(\"a\", \"b\"), (\"b\", \"c\"), (\"a\", \"c\"), (\"c\", \"d\")])\npp.plot(\n    g,\n    kind=\"histogram\",\n    backend=\"matplotlib\",  # or infer via filename extension\n    key=\"degree\",\n    bins=5,\n    title=\"Node Degree Distribution\",\n    filename=\"degree_hist.png\",\n)\n</code></pre> <p>In notebooks, omit <code>filename</code> to show inline.</p>"},{"location":"plot_tutorial/#testing-optional-but-recommended","title":"Testing (optional but recommended)","text":"<p>Create a small unit test to exercise the new path end-to-end:</p> <pre><code># tests/visualisations/test_histogram.py\nimport pathpyG as pp\n\ndef test_histogram_plot_matplotlib(tmp_path):\n    g = pp.Graph.from_edge_list([(\"a\", \"b\"), (\"b\", \"c\"), (\"a\", \"c\")])\n    out = tmp_path / \"deg_hist.png\"\n    pp.plot(g, kind=\"histogram\", backend=\"matplotlib\", key=\"degree\", bins=3, filename=str(out))\n    assert out.exists()\n</code></pre>"},{"location":"plot_tutorial/#where-to-look-for-guidance-and-consistency","title":"Where to look for guidance and consistency","text":"<ul> <li> Backends: see other backends like <code>Matplotlib</code> and <code>d3.js</code> for how plot instances are validated and rendered.</li> <li> Plot classes: study <code>NetworkPlot</code> and <code>TemporalNetworkPlot</code> to understand how <code>PathPyPlot</code> subclasses fill <code>self.data</code> and <code>self.config</code>.</li> <li> The module overview explains backend selection, saving, and common styling options.</li> </ul>"},{"location":"plot_tutorial/#recap","title":"Recap","text":"<ul> <li> New plots are <code>PathPyPlot</code> subclasses that prepare data and config.</li> <li> Register your plot in <code>PLOT_CLASSES</code> so <code>pp.plot(..., kind=...)</code> can instantiate it.</li> <li> Extend at least one backend to render your plot type. For histograms, Matplotlib is a clean first target.</li> <li> Keep a small, clear data contract between your plot class and backend rendering.</li> </ul> <p>With this, you have a clean, maintainable path to add new visualisations to pathpyG while leveraging the unified <code>pp.plot(...)</code> API and existing backend infrastructure.</p>"},{"location":"tutorial/","title":"Overview","text":"<p>In this tutorial, we will introduce basic concepts of pathpyG. pathpyG can be used as a wrapper around pytorch-geometric that facilitates network analysis, graph learning, and interactive data visualization. However, its real power comes into play when modelling causal path structures in time series data on networks, such as trajectories on graphs or temporal graphs with time-stamped interactions. pathpyG allows to compute causal paths in temporal graphs and model them based on higher-order De Bruijn graphs, a higher-dimensional generalization of standard graph models for relational data.</p> <p>The following introductory video explains the basic idea of higher-order De Bruijn graph models for causal path structures in time series data:</p> <p>The science behind pathpyG has been published in outlets like SIGKDD, WWW, Learning on Graphs, Nature Communications, Nature Physics, and Physical Review Letters. Please check here for more details on key scientific works that have laid the foundations for this package.</p> <p>Different from previous versions of pathpy, the latest version pathpyG fully utilizes the power of torch and tensor-based representations of sparse graph models to failitate the use of higher-order De Bruijn graph models. pathpyG's data structures naturally generalize the concepts of pytorch-geometric, which makes it easy to apply it in (temnporal) graph learning tasks.</p> <p>Finally, pathpyG comes with an implementation of De Bruijn Graph Neural Networks (DBGNN), a causality-aware deep learning architecture for temporal graph data. In the tutorial, we illustrate this temporal graph learning approach in a simple toy example.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>pathpyG<ul> <li>algorithms<ul> <li>centrality</li> <li>components</li> <li>generative_models</li> <li>lift_order</li> <li>rolling_time_window</li> <li>shortest_paths</li> <li>temporal</li> <li>weisfeiler_leman</li> </ul> </li> <li>core<ul> <li>graph</li> <li>index_map</li> <li>multi_order_model</li> <li>path_data</li> <li>temporal_graph</li> </ul> </li> <li>io<ul> <li>netzschleuder</li> <li>pandas</li> </ul> </li> <li>nn<ul> <li>dbgnn</li> </ul> </li> <li>statistics<ul> <li>clustering</li> <li>degrees</li> <li>node_similarities</li> </ul> </li> <li>utils<ul> <li>config</li> <li>convert</li> <li>dbgnn</li> <li>logger</li> <li>progress</li> </ul> </li> <li>visualisations<ul> <li>d3js<ul> <li>backend</li> </ul> </li> <li>manim<ul> <li>backend</li> <li>temporal_graph_scene</li> </ul> </li> <li>matplotlib<ul> <li>backend</li> </ul> </li> <li>tikz<ul> <li>backend</li> </ul> </li> <li>layout</li> <li>network_plot</li> <li>pathpy_plot</li> <li>plot_backend</li> <li>plot_function</li> <li>temporal_network_plot</li> <li>unfolded_network_plot</li> <li>utils</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/pathpyG/","title":"pathpyG","text":"<p>pathpyG is an Open Source package facilitating next-generation network analytics and graph learning for time series data on graphs.</p> <p>Building on the industry-proven data structures and concepts of <code>pytorch</code> and <code>torch_geometric</code>, pathpyG makes it easier than ever to apply machine learning to temporal graph data.</p> <p>pathpyG is jointly developed at University of Wuerzburg, Princeton University, and University of Zurich. The research behind pathpyG has been funded by the Swiss National Science Foundation via  grant 176938.</p>"},{"location":"reference/pathpyG/algorithms/","title":"algorithms","text":"<p>Algorithms for temporal path calculation and graph metrics.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG\nimport pathpyG as pp\n\n# Generate a toy example for a temporal graph.\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)\n])\n\n# Extract DAG capturing causal interaction sequences in temporal graph.\ne_i = pp.algorithms.lift_order_temporal(g, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\nprint(dag)\n\n# Calculate shortest time-respecting pathas\ndist, pred = pp.algorithms.temporal.temporal_shortest_paths(g, delta=1)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if \"num_nodes\" not in data and \"edge_index\" in data:            \n            data.num_nodes = data.edge_index.max().item() + 1\n            logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if (\n            data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n            or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n        ):\n            logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n            raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n        self.data = data\n\n        # sort EdgeIndex and validate\n        data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        data.edge_index.validate()\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n        # create node_sequence mapping for higher-order graphs\n        if \"node_sequence\" not in self.data:\n            self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n        Examples:\n            You can create a graph from an edge index tensor as follows:\n\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            &gt;&gt;&gt; print(g)\n            Directed graph with 3 nodes and 3 edges ...\n\n            You can also include a mapping of node IDs:\n\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n            &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n            &gt;&gt;&gt; print(g.mapping)\n            a -&gt; 0\n            b -&gt; 1\n            c -&gt; 2\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else:\n            if mapping is not None and mapping.num_ids() != num_nodes:\n                logger.error(\"Number of node IDs in mapping must match num_nodes\")\n                raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(d, mapping=mapping)\n\n    @staticmethod\n    def from_edge_list(\n        edge_list: Iterable[Tuple[str, str]],\n        is_undirected: bool = False,\n        mapping: Optional[IndexMap] = None,\n        device: Optional[torch.device] = None,\n    ) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            device: optional torch device where tensors shall be stored\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n            &gt;&gt;&gt; print(list(g.edges))\n            [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        \"\"\"\n\n        # handle empty graph\n        if len(edge_list) == 0:\n            return Graph(\n                Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n                mapping=IndexMap(),\n            )\n\n        if mapping is None:\n            edge_array = np.array(edge_list)\n            node_ids = np.unique(edge_array)\n            if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n                node_ids = np.sort(node_ids.astype(int)).astype(str)\n            mapping = IndexMap(node_ids)\n\n        num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex(\n            mapping.to_idxs(edge_list, device=device).T.contiguous(),\n            sparse_size=(num_nodes, num_nodes),\n            is_undirected=is_undirected,\n        )\n        return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"Return an undirected version of this directed graph.\n\n        This method creates a new undirected Graph from the current graph instance by\n        adding all directed edges in opposite direction.\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            &gt;&gt;&gt; g_u = g.to_undirected()\n            &gt;&gt;&gt; print(g_u)\n            Undirected graph with 3 nodes and 6 (directed) edges\n        \"\"\"\n        # create undirected edge index by coalescing the directed edges and keep\n        # track of the original edge index for the edge attributes\n        attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n        edge_index, attr_idx = to_undirected(\n            self.data.edge_index,\n            edge_attr=attr_idx,\n            num_nodes=self.data.num_nodes,\n            reduce=\"min\",\n        )\n\n        data = Data(\n            edge_index=EdgeIndex(\n                data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n            ),\n            num_nodes=self.data.num_nodes,\n        )\n        # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n        # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n        # make sure to copy all node and (undirected) edge attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        for edge_attr in self.edge_attrs():\n            if edge_attr != \"edge_index\":\n                data[edge_attr] = self.data[edge_attr][attr_idx]\n\n        return Graph(data, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n        If the graph contains multiple edges between the same nodes, this method will coalesce\n        them into a single edge with an additional weight attribute called `edge_weight` that\n        contains the number of coalesced edges. The method returns a new graph instance with\n        the coalesced edges.\n\n        Returns:\n            Graph: Graph with coalesced edges\n        \"\"\"\n        i, w = torch_geometric.utils.coalesce(\n            self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n\n    def to(self, device: torch.device) -&gt; Graph:\n        \"\"\"Move all tensors to the given device.\n\n        Args:\n            device: torch device to which all tensors shall be moved\n\n        Returns:\n            Graph: self\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.node_sequence = self.data.node_sequence.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n\n        self.row = self.row.to(device)\n        self.row_ptr = self.row_ptr.to(device)\n        self.col = self.col.to(device)\n        self.col_ptr = self.col_ptr.to(device)\n\n        return self\n\n    def node_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_sequence` attribute.\n\n        Returns:\n            list: list of node attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n\n        Returns:\n            list: list of edge attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; list:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a list object that contains all nodes.\n        If an IndexMap is used, nodes are returned as string IDs.\n        If no IndexMap is used, nodes are returned as integer indices.\n\n        Returns:\n            list: list of all nodes using IDs or indices (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(np.arange(self.n)).tolist()\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    @property\n    def edges(self) -&gt; list:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a list object that contains all edges, where each\n        edge is a tuple of two elements. If an IndexMap is used to map node\n        indices to string IDs, edges are returned as tuples of string IDs.\n        If no mapping is used, edges are returned as tuples of integer indices.\n\n        Returns:\n            list: list object yielding all edges using IDs or indices (if no mapping is used)\n        \"\"\"\n        edge_list = self.mapping.to_ids(self.data.edge_index.t()).tolist()\n        if self.order &gt; 1:\n            return [tuple(map(tuple, x)) for x in edge_list]\n        return list(map(tuple, edge_list))\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n        \"\"\"\n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def successors(self, node: Union[int, str] | tuple) -&gt; list:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n\n        Returns:\n            list: list with all successors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n\n        node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n\n        Returns:\n            list: list with all predecessors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID\n\n        Returns:\n            bool: True if edge exists, False otherwise\n        \"\"\"\n        row = self.mapping.to_idx(v)\n        row_start = self.row_ptr[row]\n        row_end = self.row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in self.col[row_start:row_end]\n\n    def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted in-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing in-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted out-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing out-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                     torch.tensor]:\n        \"\"\"\n        Return (weighted) degrees of nodes.\n\n        Args:\n            mode: `in` or `out` to calculate in- or out-degree for\n                directed networks.\n            edge_attr: Optional numerical edge attribute that will \n                be used to compute weighted degrees\n            return_tensor: if True the function returns a degree tensor, if False (default)\n                a dictionary will be returned that can be indexed by nodes\n        Returns:\n            dict: dictionary containing node degrees\n        \"\"\"\n        if mode == \"in\":\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        else:\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        if return_tensor:\n            return d\n        else:\n            return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n\n    def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n        \"\"\"\n        Compute transition probabilities based on (weighted) outdegrees.\n\n        Args:\n            edge_attr: Optional name of numerical edge attribute that will\n                        will be used to calculate weighted out-degrees for the\n                        visitation probabilities.\n\n        Returns:\n            tensor: Transition probabilities.\n        \"\"\"\n        weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n        source_ids = self.data.edge_index[0]        \n        edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n        if edge_attr:\n            edge_weight = getattr(self.data, edge_attr, None)\n        return edge_weight / weighted_outdegree[source_ids]\n\n    def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization: normalization parameter passed to pyG `get_laplacian`\n                function\n            edge_attr: optinal name of numerical edge attribute that shall\n                be passed to pyG `get_laplacian` function as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(), normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(),\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key.startswith(\"node_\"):\n                if val.size(0) != self.n:\n                    raise ValueError(\"Attribute must have same length as number of nodes\")\n                self.data[key] = val\n            elif key.startswith(\"edge_\"):\n                if val.size(0) != self.m:\n                    raise ValueError(\"Attribute must have same length as number of edges\")\n                self.data[key] = val\n            else:\n                self.data[key] = val\n        elif key[0].startswith(\"node_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif key[0].startswith(\"edge_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n\n    @property\n    def n(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns:\n            int: number of nodes in the graph\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def m(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the number of \n        undirected edges (accounting for self-loops) is returned, i.e. in an undirected\n        graph the directed edges (a,b) and (b,a) will be counted only once.\n\n        Returns:\n            int: number of edges in the graph\n        \"\"\"\n        if self.is_directed():\n            return self.data.num_edges  # type: ignore\n        else:\n            num_self_loops = (self.data.edge_index[0] == self.data.edge_index[1]).sum().item()\n            num_edges_wo_self_loops = self.data.edge_index.size(1) - int(num_self_loops)\n            return int(num_edges_wo_self_loops/2 + num_self_loops) # type: ignore\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"\n        Return order of graph.\n\n        Returns:\n            int: order of the (De Bruijn) graph\n        \"\"\"\n        return self.data.node_sequence.size(1)  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\n\n        Returns:\n            bool: True if graph is directed, False otherwise\n        \"\"\"\n        return not self.data.edge_index.is_undirected\n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\n\n        Returns:\n            bool: True if graph is undirected, False otherwise\n        \"\"\"\n        return self.data.edge_index.is_undirected\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\n\n        Returns:\n            bool: True if graph contains self-loops, False otherwise\n        \"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Args:\n            other: Other graph to be combined with this graph\n            reduce: Reduction method for node attributes of nodes that are present in both graphs.\n                Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n        Examples:\n            Adding two graphs without node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 6 edges\n\n            Adding two graphs with identical node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 4 edges\n\n            Adding two graphs with non-overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 6 nodes and 4 edges\n\n            Adding two graphs with partly overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 5 nodes and 4 edges\n        \"\"\"\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n        mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n        d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n        d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n        d = d1.concat(d2)\n        d.num_nodes = mapping.num_ids()\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n        # For higher-order graphs, we need to update the inverse_idx attribute\n        if \"inverse_idx\" in d:\n            d.inverse_idx = mapping.to_idxs(\n                np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n                device=d.inverse_idx.device,\n            )\n\n        # If both graphs contain node attributes, reduce them using the specified method\n        for k in d1.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                if isinstance(d[k], torch.Tensor):\n                    d[k] = torch_geometric.utils.scatter(\n                        d[k],\n                        mapping.to_idxs(\n                            np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                            device=d[k].device,\n                        ),\n                        dim_size=d.num_nodes,\n                        reduce=reduce,\n                    )\n                else:\n                    raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a list object that contains all edges, where each edge is a tuple of two elements. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of string IDs. If no mapping is used, edges are returned as tuples of integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list object yielding all edges using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.in_degrees","title":"<code>in_degrees</code>  <code>property</code>","text":"<p>Return unweighted in-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing in-degrees of nodes</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.m","title":"<code>m</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the number of  undirected edges (accounting for self-loops) is returned, i.e. in an undirected graph the directed edges (a,b) and (b,a) will be counted only once.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of edges in the graph</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.n","title":"<code>n</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of nodes in the graph</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a list object that contains all nodes. If an IndexMap is used, nodes are returned as string IDs. If no IndexMap is used, nodes are returned as integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list of all nodes using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order of graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>order of the (De Bruijn) graph</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.out_degrees","title":"<code>out_degrees</code>  <code>property</code>","text":"<p>Return unweighted out-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing out-degrees of nodes</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>pathpyG.core.graph.Graph</code> <p>Other graph to be combined with this graph</p> required <code>reduce</code> <code>str</code> <p>Reduction method for node attributes of nodes that are present in both graphs. Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".</p> <code>'sum'</code> <p>Examples:</p> <p>Adding two graphs without node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 6 edges\n</code></pre> <p>Adding two graphs with identical node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 4 edges\n</code></pre> <p>Adding two graphs with non-overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 6 nodes and 4 edges\n</code></pre> <p>Adding two graphs with partly overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 5 nodes and 4 edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Args:\n        other: Other graph to be combined with this graph\n        reduce: Reduction method for node attributes of nodes that are present in both graphs.\n            Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n    Examples:\n        Adding two graphs without node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 6 edges\n\n        Adding two graphs with identical node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 4 edges\n\n        Adding two graphs with non-overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 6 nodes and 4 edges\n\n        Adding two graphs with partly overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 5 nodes and 4 edges\n    \"\"\"\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n    mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n    d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n    d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n    d = d1.concat(d2)\n    d.num_nodes = mapping.num_ids()\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n    # For higher-order graphs, we need to update the inverse_idx attribute\n    if \"inverse_idx\" in d:\n        d.inverse_idx = mapping.to_idxs(\n            np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n            device=d.inverse_idx.device,\n        )\n\n    # If both graphs contain node attributes, reduce them using the specified method\n    for k in d1.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            if isinstance(d[k], torch.Tensor):\n                d[k] = torch_geometric.utils.scatter(\n                    d[k],\n                    mapping.to_idxs(\n                        np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                        device=d[k].device,\n                    ),\n                    dim_size=d.num_nodes,\n                    reduce=reduce,\n                )\n            else:\n                raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if \"num_nodes\" not in data and \"edge_index\" in data:            \n        data.num_nodes = data.edge_index.max().item() + 1\n        logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if (\n        data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n        or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n    ):\n        logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n        raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n    self.data = data\n\n    # sort EdgeIndex and validate\n    data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    data.edge_index.validate()\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    # create node_sequence mapping for higher-order graphs\n    if \"node_sequence\" not in self.data:\n        self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key.startswith(\"node_\"):\n            if val.size(0) != self.n:\n                raise ValueError(\"Attribute must have same length as number of nodes\")\n            self.data[key] = val\n        elif key.startswith(\"edge_\"):\n            if val.size(0) != self.m:\n                raise ValueError(\"Attribute must have same length as number of edges\")\n            self.data[key] = val\n        else:\n            self.data[key] = val\n    elif key[0].startswith(\"node_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif key[0].startswith(\"edge_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return (weighted) degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate in- or out-degree for directed networks.</p> <code>'in'</code> <code>edge_attr</code> <code>typing.Any</code> <p>Optional numerical edge attribute that will  be used to compute weighted degrees</p> <code>None</code> <code>return_tensor</code> <code>bool</code> <p>if True the function returns a degree tensor, if False (default) a dictionary will be returned that can be indexed by nodes</p> <code>False</code> <p>Returns:     dict: dictionary containing node degrees</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                 torch.tensor]:\n    \"\"\"\n    Return (weighted) degrees of nodes.\n\n    Args:\n        mode: `in` or `out` to calculate in- or out-degree for\n            directed networks.\n        edge_attr: Optional numerical edge attribute that will \n            be used to compute weighted degrees\n        return_tensor: if True the function returns a degree tensor, if False (default)\n            a dictionary will be returned that can be indexed by nodes\n    Returns:\n        dict: dictionary containing node degrees\n    \"\"\"\n    if mode == \"in\":\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    else:\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    if return_tensor:\n        return d\n    else:\n        return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of edge attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def edge_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n\n    Returns:\n        list: list of edge attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <code>int</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.</p> <code>None</code> <p>Examples:</p> <p>You can create a graph from an edge index tensor as follows:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n&gt;&gt;&gt; print(g)\nDirected graph with 3 nodes and 3 edges ...\n</code></pre> <p>You can also include a mapping of node IDs:</p> <pre><code>&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n&gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n&gt;&gt;&gt; print(g.mapping)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n    Examples:\n        You can create a graph from an edge index tensor as follows:\n\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        &gt;&gt;&gt; print(g)\n        Directed graph with 3 nodes and 3 edges ...\n\n        You can also include a mapping of node IDs:\n\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n        &gt;&gt;&gt; print(g.mapping)\n        a -&gt; 0\n        b -&gt; 1\n        c -&gt; 2\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else:\n        if mapping is not None and mapping.num_ids() != num_nodes:\n            logger.error(\"Number of node IDs in mapping must match num_nodes\")\n            raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>device</code> <code>typing.Optional[torch.device]</code> <p>optional torch device where tensors shall be stored</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n&gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n&gt;&gt;&gt; print(list(g.edges))\n[('a', 'b'), ('a', 'c'), ('b', 'c')]\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(\n    edge_list: Iterable[Tuple[str, str]],\n    is_undirected: bool = False,\n    mapping: Optional[IndexMap] = None,\n    device: Optional[torch.device] = None,\n) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        device: optional torch device where tensors shall be stored\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n        &gt;&gt;&gt; print(list(g.edges))\n        [('a', 'b'), ('a', 'c'), ('b', 'c')]\n    \"\"\"\n\n    # handle empty graph\n    if len(edge_list) == 0:\n        return Graph(\n            Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n            mapping=IndexMap(),\n        )\n\n    if mapping is None:\n        edge_array = np.array(edge_list)\n        node_ids = np.unique(edge_array)\n        if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n            node_ids = np.sort(node_ids.astype(int)).astype(str)\n        mapping = IndexMap(node_ids)\n\n    num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex(\n        mapping.to_idxs(edge_list, device=device).T.contiguous(),\n        sparse_size=(num_nodes, num_nodes),\n        is_undirected=is_undirected,\n    )\n    return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all predecessor nodes of the node indexed by <code>col_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n    \"\"\"\n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all successor nodes of the node indexed by <code>row_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph contains self-loops, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\n\n    Returns:\n        bool: True if graph contains self-loops, False otherwise\n    \"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is directed, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\n\n    Returns:\n        bool: True if graph is directed, False otherwise\n    \"\"\"\n    return not self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if edge exists, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID\n\n    Returns:\n        bool: True if edge exists, False otherwise\n    \"\"\"\n    row = self.mapping.to_idx(v)\n    row_start = self.row_ptr[row]\n    row_end = self.row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in self.col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is undirected, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\n\n    Returns:\n        bool: True if graph is undirected, False otherwise\n    \"\"\"\n    return self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.laplacian","title":"<code>laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code> function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: Laplacian matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization: normalization parameter passed to pyG `get_laplacian`\n            function\n        edge_attr: optinal name of numerical edge attribute that shall\n            be passed to pyG `get_laplacian` function as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(), normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(),\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_sequence</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of node attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def node_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_sequence` attribute.\n\n    Returns:\n        list: list of node attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all predecessors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n\n    Returns:\n        list: list with all predecessors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n    node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.sparse_adj_matrix","title":"<code>sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n        )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all successors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) -&gt; list:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n\n    Returns:\n        list: list with all successors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n\n    node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to","title":"<code>to</code>","text":"<p>Move all tensors to the given device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>torch device to which all tensors shall be moved</p> required <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>self</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; Graph:\n    \"\"\"Move all tensors to the given device.\n\n    Args:\n        device: torch device to which all tensors shall be moved\n\n    Returns:\n        Graph: self\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.node_sequence = self.data.node_sequence.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n\n    self.row = self.row.to(device)\n    self.row_ptr = self.row_ptr.to(device)\n    self.col = self.col.to(device)\n    self.col_ptr = self.col_ptr.to(device)\n\n    return self\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of this directed graph.</p> <p>This method creates a new undirected Graph from the current graph instance by adding all directed edges in opposite direction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n&gt;&gt;&gt; g_u = g.to_undirected()\n&gt;&gt;&gt; print(g_u)\nUndirected graph with 3 nodes and 6 (directed) edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"Return an undirected version of this directed graph.\n\n    This method creates a new undirected Graph from the current graph instance by\n    adding all directed edges in opposite direction.\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        &gt;&gt;&gt; g_u = g.to_undirected()\n        &gt;&gt;&gt; print(g_u)\n        Undirected graph with 3 nodes and 6 (directed) edges\n    \"\"\"\n    # create undirected edge index by coalescing the directed edges and keep\n    # track of the original edge index for the edge attributes\n    attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n    edge_index, attr_idx = to_undirected(\n        self.data.edge_index,\n        edge_attr=attr_idx,\n        num_nodes=self.data.num_nodes,\n        reduce=\"min\",\n    )\n\n    data = Data(\n        edge_index=EdgeIndex(\n            data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n        ),\n        num_nodes=self.data.num_nodes,\n    )\n    # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n    # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n    # make sure to copy all node and (undirected) edge attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    for edge_attr in self.edge_attrs():\n        if edge_attr != \"edge_index\":\n            data[edge_attr] = self.data[edge_attr][attr_idx]\n\n    return Graph(data, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> <p>If the graph contains multiple edges between the same nodes, this method will coalesce them into a single edge with an additional weight attribute called <code>edge_weight</code> that contains the number of coalesced edges. The method returns a new graph instance with the coalesced edges.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>Graph with coalesced edges</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n    If the graph contains multiple edges between the same nodes, this method will coalesce\n    them into a single edge with an additional weight attribute called `edge_weight` that\n    contains the number of coalesced edges. The method returns a new graph instance with\n    the coalesced edges.\n\n    Returns:\n        Graph: Graph with coalesced edges\n    \"\"\"\n    i, w = torch_geometric.utils.coalesce(\n        self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n    )\n    return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.Graph.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Compute transition probabilities based on (weighted) outdegrees.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>Optional name of numerical edge attribute that will         will be used to calculate weighted out-degrees for the         visitation probabilities.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Transition probabilities.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n    \"\"\"\n    Compute transition probabilities based on (weighted) outdegrees.\n\n    Args:\n        edge_attr: Optional name of numerical edge attribute that will\n                    will be used to calculate weighted out-degrees for the\n                    visitation probabilities.\n\n    Returns:\n        tensor: Transition probabilities.\n    \"\"\"\n    weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n    source_ids = self.data.edge_index[0]        \n    edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n    if edge_attr:\n        edge_weight = getattr(self.data, edge_attr, None)\n    return edge_weight / weighted_outdegree[source_ids]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph","title":"<code>TemporalGraph</code>","text":"<p>               Bases: <code>pathpyG.Graph</code></p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>class TemporalGraph(Graph):\n    def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n        \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n        Args:\n            data: PyG `Data` object containing edges saved in `edge_index` and timestamps in `time`.\n            mapping: Optional mapping from node IDs to indices.\n\n        Example:\n            ```py\n            from pytorch_geometric.data import TemporalData\n            import pathpyG as pp\n\n            d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n            t = pp.TemporalGraph(d, mapping)\n            print(t)\n            ```\n        \"\"\"\n        self.data = data\n        if not isinstance(self.data.edge_index, EdgeIndex):\n            self.data.edge_index = EdgeIndex(\n                data=self.data.edge_index.contiguous(), sparse_size=(self.data.num_nodes, self.data.num_nodes)\n            )\n\n        # reorder temporal data\n        # Note that we do not use `torch_geometric.self.data.Data.sort_by_time` because it cannot sort numpy arrays`\n        sorted_idx = torch.argsort(self.data.time)\n        for edge_attr in set(self.data.edge_attrs()).union(set([\"time\"])):\n            if edge_attr == \"edge_index\":\n                self.data.edge_index = self.data.edge_index[:, sorted_idx]\n            else:\n                self.data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        if mapping is not None:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n\n        # create mapping between edge index and edge tuples\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate(self.data.edge_index.t())\n        }\n        self.tedge_to_index = {\n            (e[0].item(), e[1].item(), t.item()): i for i, (e, t) in enumerate(zip([e for e in self.data.edge_index.t()], self.data.time))\n        }\n\n        if self.data.time.size(0) &gt; 0:\n            self.start_time = self.data.time[0].item()\n            self.end_time = self.data.time[-1].item()\n        else:\n            self.start_time = 0\n            self.end_time = 0\n\n    @staticmethod\n    def from_edge_list(edge_list, num_nodes: Optional[int] = None, device: Optional[torch.device] = None) -&gt; TemporalGraph:  # type: ignore\n        \"\"\"Create a temporal graph from a list of tuples containing edges with timestamps.\"\"\"\n        if len(edge_list) == 0:\n            return TemporalGraph(\n                data=Data(\n                    edge_index=torch.empty((2, 0), dtype=torch.long, device=device),\n                    time=torch.empty((0,), dtype=torch.long, device=device),\n                    num_nodes=num_nodes,\n                ),\n            )\n\n        edge_array = np.array(edge_list)\n\n        # Convert timestamps to tensor\n        if isinstance(edge_list[0][2], int):\n            ts = torch.tensor(edge_array[:, 2].astype(np.int_), device=device)\n        else:\n            ts = torch.tensor(edge_array[:, 2].astype(np.double), device=device)\n\n        index_map = IndexMap(np.unique(edge_array[:, :2]))\n        edge_index = index_map.to_idxs(edge_array[:, :2].T, device=device)\n\n        if not num_nodes:\n            num_nodes = index_map.num_ids()\n\n        return TemporalGraph(\n            data=Data(\n                edge_index=edge_index,\n                time=ts,\n                num_nodes=num_nodes,\n            ),\n            mapping=index_map,\n        )\n\n    @property\n    def temporal_edges(self) -&gt; list:\n        \"\"\"Return all temporal edges as a list of tuples (source, destination, timestamp).\n\n        Returns:\n            list: A list of tuples representing temporal edges in the format (source, destination, timestamp).\n\n        Examples:\n            Get the list of temporal edges:\n\n            &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            &gt;&gt;&gt; print(g.temporal_edges)\n            [('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)]\n\n            Iterate over temporal edges:\n            &gt;&gt;&gt; for edge in g.temporal_edges:\n            &gt;&gt;&gt;     print(edge)\n            ('a', 'b', 1)\n            ('b', 'c', 2)\n            ('c', 'a', 3)\n        \"\"\"\n        edge_ids = self.mapping.to_ids(self.data.edge_index)\n        times = to_numpy(self.data.time)\n        return list(zip(edge_ids[0], edge_ids[1], times))\n\n    def to(self, device: torch.device) -&gt; TemporalGraph:\n        \"\"\"Moves all graph data to the specified device (CPU or GPU).\n\n        Args:\n            device: The target device to move the graph data to.\n\n        Returns:\n            TemporalGraph: A new TemporalGraph instance with data on the specified device.\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.time = self.data.time.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        return self\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"Return order 1, since all temporal graphs must be order one.\"\"\"\n        return 1\n\n    def shuffle_time(self) -&gt; None:\n        \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n        self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n\n    def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n        \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n        Args:\n            weighted: whether or not to return a weighted time-aggregated graph\n            time_window: A tuple with start and end time of the aggregation window\n\n        Returns:\n            Graph: A static graph object\n        \"\"\"\n        if time_window is not None:\n            idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n            edge_index = self.data.edge_index[:, idx]\n        else:\n            edge_index = self.data.edge_index\n\n        n = edge_index.max().item() + 1\n\n        if weighted:\n            i, w = torch_geometric.utils.coalesce(\n                edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n            )\n            return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n        else:\n            return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n\n    def to_undirected(self) -&gt; TemporalGraph:\n        \"\"\"Return an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        rev_edge_index = self.data.edge_index.flip([0])\n        edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n        times = torch.cat([self.data.time, self.data.time])\n        return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n\n    def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n        \"\"\"Return a batch of temporal edges based on start and end indices.\n\n        Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given batch defined by start and (non-inclusive) end, where start\n        and end refer to the index of the first and last event in the time-ordered list of events.\n\n        Args:\n            start_idx: The starting index of the batch (inclusive).\n            end_idx: The ending index of the batch (exclusive).\n\n        Examples:\n            Get a batch of temporal edges:\n\n            &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            &gt;&gt;&gt; batch = g.get_batch(0, 2)\n            &gt;&gt;&gt; print(batch.temporal_edges)\n            [('a', 'b', 1), ('b', 'c', 2)]\n        \"\"\"\n        # Create new Data object with the selected batch of edges and times\n        data = Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx])\n\n        # Copy all node attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        # Copy only edge attributes for the selected batch\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][start_idx:end_idx]\n\n        return TemporalGraph(\n            data=data,\n            mapping=self.mapping,\n        )\n\n    def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n        \"\"\"Return a time window of temporal edges based on start and end timestamps.\n\n        Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given time window defined by start and (non-inclusive) end, where start\n        and end refer to the time stamps.\n\n        Args:\n            start_time: The starting timestamp of the window (inclusive).\n            end_time: The ending timestamp of the window (exclusive).\n\n        Examples:\n            Get a time window of temporal edges:\n\n            &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            &gt;&gt;&gt; window = g.get_window(0, 2)\n            &gt;&gt;&gt; print(window.temporal_edges)\n            [('a', 'b', 1)]\n        \"\"\"\n        # While there is a PyG function `Data.snapshot`,\n        # we do it manually since it cannot handle numpy arrays as edge attributes.\n        edge_mask = (self.data.time &gt;= start_time).logical_and(self.data.time &lt; end_time)\n        # Create a new Data object with the selected edges and times\n        data = Data(\n            edge_index=self.data.edge_index[:, edge_mask],\n            time=self.data.time[edge_mask],\n        )\n        # Copy all node attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        # Copy only edge attributes for the selected edges\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][edge_mask]\n\n        return TemporalGraph(data=data, mapping=self.mapping)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, temporal edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            # TODO: Get item for non-temporal edges will only return the last occurence of the edge\n            #       This is a limitation and should be fixed in the future.\n            if len(key) == 3:\n                return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n            else:\n                return self.data[key[0]][self.tedge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2]), key[3]]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the graph\n        \"\"\"\n        s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n            self.data.num_nodes,\n            self.data.edge_index.unique(dim=1).size(dim=1),\n            self.data.edge_index.size(1),\n            self.start_time,\n            self.end_time,\n        )\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order 1, since all temporal graphs must be order one.</p>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.temporal_edges","title":"<code>temporal_edges</code>  <code>property</code>","text":"<p>Return all temporal edges as a list of tuples (source, destination, timestamp).</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of tuples representing temporal edges in the format (source, destination, timestamp).</p> <p>Examples:</p> <p>Get the list of temporal edges:</p> <pre><code>&gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n&gt;&gt;&gt; print(g.temporal_edges)\n[('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)]\n</code></pre> <p>Iterate over temporal edges:</p> <pre><code>&gt;&gt;&gt; for edge in g.temporal_edges:\n&gt;&gt;&gt;     print(edge)\n('a', 'b', 1)\n('b', 'c', 2)\n('c', 'a', 3)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, temporal edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, temporal edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        # TODO: Get item for non-temporal edges will only return the last occurence of the edge\n        #       This is a limitation and should be fixed in the future.\n        if len(key) == 3:\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            return self.data[key[0]][self.tedge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2]), key[3]]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__init__","title":"<code>__init__</code>","text":"<p>Creates an instance of a temporal graph from a <code>TemporalData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>PyG <code>Data</code> object containing edges saved in <code>edge_index</code> and timestamps in <code>time</code>.</p> required <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>Optional mapping from node IDs to indices.</p> <code>None</code> Example <pre><code>from pytorch_geometric.data import TemporalData\nimport pathpyG as pp\n\nd = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\nt = pp.TemporalGraph(d, mapping)\nprint(t)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n    \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n    Args:\n        data: PyG `Data` object containing edges saved in `edge_index` and timestamps in `time`.\n        mapping: Optional mapping from node IDs to indices.\n\n    Example:\n        ```py\n        from pytorch_geometric.data import TemporalData\n        import pathpyG as pp\n\n        d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n        t = pp.TemporalGraph(d, mapping)\n        print(t)\n        ```\n    \"\"\"\n    self.data = data\n    if not isinstance(self.data.edge_index, EdgeIndex):\n        self.data.edge_index = EdgeIndex(\n            data=self.data.edge_index.contiguous(), sparse_size=(self.data.num_nodes, self.data.num_nodes)\n        )\n\n    # reorder temporal data\n    # Note that we do not use `torch_geometric.self.data.Data.sort_by_time` because it cannot sort numpy arrays`\n    sorted_idx = torch.argsort(self.data.time)\n    for edge_attr in set(self.data.edge_attrs()).union(set([\"time\"])):\n        if edge_attr == \"edge_index\":\n            self.data.edge_index = self.data.edge_index[:, sorted_idx]\n        else:\n            self.data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    if mapping is not None:\n        self.mapping = mapping\n    else:\n        self.mapping = IndexMap()\n\n    # create mapping between edge index and edge tuples\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate(self.data.edge_index.t())\n    }\n    self.tedge_to_index = {\n        (e[0].item(), e[1].item(), t.item()): i for i, (e, t) in enumerate(zip([e for e in self.data.edge_index.t()], self.data.time))\n    }\n\n    if self.data.time.size(0) &gt; 0:\n        self.start_time = self.data.time[0].item()\n        self.end_time = self.data.time[-1].item()\n    else:\n        self.start_time = 0\n        self.end_time = 0\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the graph\n    \"\"\"\n    s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n        self.data.num_nodes,\n        self.data.edge_index.unique(dim=1).size(dim=1),\n        self.data.edge_index.size(1),\n        self.start_time,\n        self.end_time,\n    )\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Create a temporal graph from a list of tuples containing edges with timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(edge_list, num_nodes: Optional[int] = None, device: Optional[torch.device] = None) -&gt; TemporalGraph:  # type: ignore\n    \"\"\"Create a temporal graph from a list of tuples containing edges with timestamps.\"\"\"\n    if len(edge_list) == 0:\n        return TemporalGraph(\n            data=Data(\n                edge_index=torch.empty((2, 0), dtype=torch.long, device=device),\n                time=torch.empty((0,), dtype=torch.long, device=device),\n                num_nodes=num_nodes,\n            ),\n        )\n\n    edge_array = np.array(edge_list)\n\n    # Convert timestamps to tensor\n    if isinstance(edge_list[0][2], int):\n        ts = torch.tensor(edge_array[:, 2].astype(np.int_), device=device)\n    else:\n        ts = torch.tensor(edge_array[:, 2].astype(np.double), device=device)\n\n    index_map = IndexMap(np.unique(edge_array[:, :2]))\n    edge_index = index_map.to_idxs(edge_array[:, :2].T, device=device)\n\n    if not num_nodes:\n        num_nodes = index_map.num_ids()\n\n    return TemporalGraph(\n        data=Data(\n            edge_index=edge_index,\n            time=ts,\n            num_nodes=num_nodes,\n        ),\n        mapping=index_map,\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.get_batch","title":"<code>get_batch</code>","text":"<p>Return a batch of temporal edges based on start and end indices.</p> <p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given batch defined by start and (non-inclusive) end, where start and end refer to the index of the first and last event in the time-ordered list of events.</p> <p>Parameters:</p> Name Type Description Default <code>start_idx</code> <code>int</code> <p>The starting index of the batch (inclusive).</p> required <code>end_idx</code> <code>int</code> <p>The ending index of the batch (exclusive).</p> required <p>Examples:</p> <p>Get a batch of temporal edges:</p> <pre><code>&gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n&gt;&gt;&gt; batch = g.get_batch(0, 2)\n&gt;&gt;&gt; print(batch.temporal_edges)\n[('a', 'b', 1), ('b', 'c', 2)]\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n    \"\"\"Return a batch of temporal edges based on start and end indices.\n\n    Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given batch defined by start and (non-inclusive) end, where start\n    and end refer to the index of the first and last event in the time-ordered list of events.\n\n    Args:\n        start_idx: The starting index of the batch (inclusive).\n        end_idx: The ending index of the batch (exclusive).\n\n    Examples:\n        Get a batch of temporal edges:\n\n        &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        &gt;&gt;&gt; batch = g.get_batch(0, 2)\n        &gt;&gt;&gt; print(batch.temporal_edges)\n        [('a', 'b', 1), ('b', 'c', 2)]\n    \"\"\"\n    # Create new Data object with the selected batch of edges and times\n    data = Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx])\n\n    # Copy all node attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    # Copy only edge attributes for the selected batch\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][start_idx:end_idx]\n\n    return TemporalGraph(\n        data=data,\n        mapping=self.mapping,\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.get_window","title":"<code>get_window</code>","text":"<p>Return a time window of temporal edges based on start and end timestamps.</p> <p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given time window defined by start and (non-inclusive) end, where start and end refer to the time stamps.</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>int</code> <p>The starting timestamp of the window (inclusive).</p> required <code>end_time</code> <code>int</code> <p>The ending timestamp of the window (exclusive).</p> required <p>Examples:</p> <p>Get a time window of temporal edges:</p> <pre><code>&gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n&gt;&gt;&gt; window = g.get_window(0, 2)\n&gt;&gt;&gt; print(window.temporal_edges)\n[('a', 'b', 1)]\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n    \"\"\"Return a time window of temporal edges based on start and end timestamps.\n\n    Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given time window defined by start and (non-inclusive) end, where start\n    and end refer to the time stamps.\n\n    Args:\n        start_time: The starting timestamp of the window (inclusive).\n        end_time: The ending timestamp of the window (exclusive).\n\n    Examples:\n        Get a time window of temporal edges:\n\n        &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        &gt;&gt;&gt; window = g.get_window(0, 2)\n        &gt;&gt;&gt; print(window.temporal_edges)\n        [('a', 'b', 1)]\n    \"\"\"\n    # While there is a PyG function `Data.snapshot`,\n    # we do it manually since it cannot handle numpy arrays as edge attributes.\n    edge_mask = (self.data.time &gt;= start_time).logical_and(self.data.time &lt; end_time)\n    # Create a new Data object with the selected edges and times\n    data = Data(\n        edge_index=self.data.edge_index[:, edge_mask],\n        time=self.data.time[edge_mask],\n    )\n    # Copy all node attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    # Copy only edge attributes for the selected edges\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][edge_mask]\n\n    return TemporalGraph(data=data, mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.shuffle_time","title":"<code>shuffle_time</code>","text":"<p>Randomly shuffle the temporal order of edges by randomly permuting timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def shuffle_time(self) -&gt; None:\n    \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n    self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to","title":"<code>to</code>","text":"<p>Moves all graph data to the specified device (CPU or GPU).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>The target device to move the graph data to.</p> required <p>Returns:</p> Name Type Description <code>TemporalGraph</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>A new TemporalGraph instance with data on the specified device.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; TemporalGraph:\n    \"\"\"Moves all graph data to the specified device (CPU or GPU).\n\n    Args:\n        device: The target device to move the graph data to.\n\n    Returns:\n        TemporalGraph: A new TemporalGraph instance with data on the specified device.\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.time = self.data.time.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    return self\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to_static_graph","title":"<code>to_static_graph</code>","text":"<p>Return weighted time-aggregated instance of <code>Graph</code> graph.</p> <p>Parameters:</p> Name Type Description Default <code>weighted</code> <code>bool</code> <p>whether or not to return a weighted time-aggregated graph</p> <code>False</code> <code>time_window</code> <code>typing.Optional[typing.Tuple[int, int]]</code> <p>A tuple with start and end time of the aggregation window</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.Graph</code> <p>A static graph object</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n    \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n    Args:\n        weighted: whether or not to return a weighted time-aggregated graph\n        time_window: A tuple with start and end time of the aggregation window\n\n    Returns:\n        Graph: A static graph object\n    \"\"\"\n    if time_window is not None:\n        idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n        edge_index = self.data.edge_index[:, idx]\n    else:\n        edge_index = self.data.edge_index\n\n    n = edge_index.max().item() + 1\n\n    if weighted:\n        i, w = torch_geometric.utils.coalesce(\n            edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n    else:\n        return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.TemporalGraph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_undirected(self) -&gt; TemporalGraph:\n    \"\"\"Return an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    rev_edge_index = self.data.edge_index.flip([0])\n    edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n    times = torch.cat([self.data.time, self.data.time])\n    return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.lift_order_temporal","title":"<code>lift_order_temporal</code>","text":"<p>Lift a temporal graph to a second-order temporal event graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to lift.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events to consider them connected.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>ho_index</code> <p>Edge index of the second-order temporal event graph.</p> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def lift_order_temporal(g: TemporalGraph, delta: int = 1):\n    \"\"\"Lift a temporal graph to a second-order temporal event graph.\n\n    Args:\n        g: Temporal graph to lift.\n        delta: Maximum time difference between events to consider them connected.\n\n    Returns:\n        ho_index: Edge index of the second-order temporal event graph.\n    \"\"\"\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.time\n\n    delta = torch.tensor(delta, device=edge_index.device)\n    indices = torch.arange(0, edge_index.size(1), device=edge_index.device)\n\n    unique_t = torch.unique(timestamps, sorted=True)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for t in tqdm(unique_t):\n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = timestamps == t\n        src_edge_idx = indices[src_time_mask]\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t + delta)\n        dst_edge_idx = indices[dst_time_mask]\n\n        if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n            # compute second-order edges between src and dst idx\n            # for all edges where dst in src_edges (edge_index[1, x[:, 0]]) matches src in dst_edges (edge_index[0, x[:, 1]])\n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx)\n            ho_edge_index = x[edge_index[1, x[:, 0]] == edge_index[0, x[:, 1]]]\n            second_order.append(ho_edge_index)\n\n    ho_index = torch.cat(second_order, dim=0).t().contiguous()\n    return ho_index\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.temporal_shortest_paths","title":"<code>temporal_shortest_paths</code>","text":"<p>Compute shortest time-respecting paths in a temporal graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to compute shortest paths on.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events in a path.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Tuple of two numpy arrays:</p> <code>numpy.ndarray</code> <ul> <li>dist: Shortest time-respecting path distances between all first-order nodes.</li> </ul> <code>typing.Tuple[numpy.ndarray, numpy.ndarray]</code> <ul> <li>pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.</li> </ul> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def temporal_shortest_paths(g: TemporalGraph, delta: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute shortest time-respecting paths in a temporal graph.\n\n    Args:\n        g: Temporal graph to compute shortest paths on.\n        delta: Maximum time difference between events in a path.\n\n    Returns:\n        Tuple of two numpy arrays:\n        - dist: Shortest time-respecting path distances between all first-order nodes.\n        - pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n    dst_edges_dst = g.data.edge_index[1] + g.m + g.n\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.m + 2 * g.n)\n    m = event_graph.sparse_adj_matrix()\n\n    # print(f\"Created temporal event DAG with {event_graph.n} nodes and {event_graph.m} edges\")\n\n    # run disjktra for all source nodes\n    dist, pred = dijkstra(\n        m, directed=True, indices=np.arange(g.m, g.m + g.n), return_predecessors=True, unweighted=True\n    )\n\n    # limit to first-order destinations and correct distances\n    dist_fo = dist[:, g.m + g.n :] - 1\n    np.fill_diagonal(dist_fo, 0)\n\n    # limit to first-order destinations and correct predecessors\n    pred_fo = pred[:, g.n + g.m :]\n    pred_fo[pred_fo == -9999] = -1\n    idx_map = np.concatenate([to_numpy(g.data.edge_index[0].cpu()), [-1]])\n    pred_fo = idx_map[pred_fo]\n    np.fill_diagonal(pred_fo, np.arange(g.n))\n\n    return dist_fo, pred_fo\n</code></pre>"},{"location":"reference/pathpyG/algorithms/#pathpyG.algorithms.to_numpy","title":"<code>to_numpy</code>","text":"<p>Convert an iterable (including a tensor or tensor subclasses like <code>torch_geometric.Edge_Index</code>) to numpy.</p> <p>Parameters:</p> Name Type Description Default <code>input_iterable</code> <code>torch.Tensor | numpy.ndarray | list</code> <p>Tensor, tensor subclass, numpy array or list.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Numpy array.</p> Source code in <code>src/pathpyG/utils/convert.py</code> <pre><code>def to_numpy(input_iterable: torch.Tensor | np.ndarray | list) -&gt; np.ndarray:\n    \"\"\"\n    Convert an iterable (including a tensor or tensor subclasses like `torch_geometric.Edge_Index`) to numpy.\n\n    Args:\n        input_iterable: Tensor, tensor subclass, numpy array or list.\n\n    Returns:\n        Numpy array.\n    \"\"\"\n    if isinstance(input_iterable, (EdgeIndex, Index)):\n        return input_iterable.as_tensor().cpu().numpy()\n    elif isinstance(input_iterable, torch.Tensor):\n        return input_iterable.cpu().numpy()\n    elif isinstance(input_iterable, (list, tuple)):\n        return np.array(input_iterable)\n    elif isinstance(input_iterable, np.ndarray):\n        return input_iterable\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/","title":"centrality","text":"<p>Algorithms to calculate centralities in (temporal) graphs.</p> <p>The functions and submodules in this module allow to compute  time-respecting or causal paths in temporal graphs and to calculate (temporal) and higher-order graph metrics like centralities.</p> Example <pre><code># Import pathpyG\nimport pathpyG as pp\n\n# Generate toy example for temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)\n])\n\nbw_t = pp.algorithms.temporal_betweenness_centrality(g, delta=1)\ncl_t = pp.algorithms.temporal_closeness_centrality(g, delta=1)\n\nstatic_graph = g.to_static_graph()\nbw_s = pp.algorithms.betweenness_centrality(static_graph)\nbw_s = pp.algorithms.closeness_centrality(static_graph)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.__getattr__","title":"<code>__getattr__</code>","text":"<p>Map to corresponding functions in centrality module of networkx.</p> <p>Any call to a function that is not implemented in the module centrality and whose first argument is of type Graph will be delegated to the corresponding function in the networkx module <code>centrality</code>. Please refer to the networkx documentation for a reference of available functions.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>the name of the function that shall be called</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def __getattr__(name: str) -&gt; Any:\n    \"\"\"Map to corresponding functions in centrality module of networkx.\n\n    Any call to a function that is not implemented in the module centrality\n    and whose first argument is of type Graph will be delegated to the\n    corresponding function in the networkx module `centrality`. Please\n    refer to the [networkx documentation](https://networkx.org/documentation/stable/reference/algorithms/centrality.html)\n    for a reference of available functions.\n\n    Args:\n        name: the name of the function that shall be called\n    \"\"\"\n\n    def wrapper(*args: Any, **kwargs: Any) -&gt; Any:\n        if len(args) == 0:\n            raise RuntimeError(f\"Did not find method {name} with no arguments\")\n        if isinstance(args[0], TemporalGraph):\n            raise NotImplementedError(f\"Missing implementation of {name} for temporal graphs\")\n        # if first argument is of type Graph, delegate to networkx function\n        if isinstance(args[0], Graph):\n            g = to_networkx(args[0].data)\n            r = getattr(centrality, name)(g, *args[1:], **kwargs)\n            if name.index(\"centrality\") &gt; 0 and isinstance(r, dict):\n                return map_to_nodes(args[0], r)\n            return r\n        else:\n            return wrapper(*args, **kwargs)\n            # raise RuntimeError(f'Did not find method {name} that accepts first argument of type {type(args[0])}')\n\n    return wrapper\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.betweenness_centrality","title":"<code>betweenness_centrality</code>","text":"<p>Calculate the betweenness centrality of nodes based on the fast algorithm proposed by Brandes:</p> <p>U. Brandes: A faster algorithm for betweenness centrality, The Journal of Mathematical Sociology, 2001</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.graph.Graph</code> <p><code>Graph</code> object for which betweenness centrality will be computed</p> required <code>sources</code> <p>optional list of source nodes for BFS-based shortest path calculation</p> <code>None</code> Example <pre><code>import pathpyG as pp\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                    ('b', 'd'), ('c', 'e'), ('d', 'e')])\nbw = pp.algorithms.betweenness_centrality(g)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def betweenness_centrality(g: Graph, sources=None) -&gt; dict[str, float]:\n    \"\"\"Calculate the betweenness centrality of nodes based on the fast algorithm\n    proposed by Brandes:\n\n    U. Brandes: A faster algorithm for betweenness centrality, The Journal of\n    Mathematical Sociology, 2001\n\n    Args:\n        g: `Graph` object for which betweenness centrality will be computed\n        sources: optional list of source nodes for BFS-based shortest path calculation\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'),\n                            ('b', 'd'), ('c', 'e'), ('d', 'e')])\n        bw = pp.algorithms.betweenness_centrality(g)\n        ```\n    \"\"\"\n    bw = defaultdict(lambda: 0.0)\n\n    if sources == None:\n        sources = [v for v in g.nodes]\n\n    for s in sources:\n        S = list()\n        P = defaultdict(list)\n\n        sigma = defaultdict(lambda: 0)\n        sigma[s] = 1\n\n        d = defaultdict(lambda: -1)\n        d[s] = 0\n\n        Q = [s]\n        while Q:\n            v = Q.pop(0)\n            S.append(v)\n            for w in g.successors(v):\n                if d[w] &lt; 0:\n                    Q.append(w)\n                    d[w] = d[v] + 1\n                if d[w] == d[v] + 1:\n                    # we found shortest path from s via v to w\n                    sigma[w] = sigma[w] + sigma[v]\n                    P[w].append(v)\n        delta = defaultdict(lambda: 0.0)\n        while S:\n            w = S.pop()\n            for v in P[w]:\n                delta[v] = delta[v] + sigma[v] / sigma[w] * (1 + delta[w])\n                if v != w:\n                    bw[w] = bw[w] + delta[w]\n    return bw\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.map_to_nodes","title":"<code>map_to_nodes</code>","text":"<p>Map node-level centralities in dictionary to node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.graph.Graph</code> <p>Graph object</p> required <code>c</code> <code>typing.Dict</code> <p>dictionary mapping node indices to metrics</p> required Example <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n...                               node_id=['a', 'b', 'c'])\n&gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n&gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n&gt;&gt;&gt; print(c_mapped)\n{'a': 0.5, 'b': 2.7, 'c': 0.3}\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def map_to_nodes(g: Graph, c: Dict) -&gt; Dict:\n    \"\"\"Map node-level centralities in dictionary to node IDs.\n\n    Args:\n        g: Graph object\n        c: dictionary mapping node indices to metrics\n\n    Example:\n        ```pycon\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        ...                               node_id=['a', 'b', 'c'])\n        &gt;&gt;&gt; c = {0: 0.5, 1: 2.7, 2: 0.3}\n        &gt;&gt;&gt; c_mapped = pp.algorithms.centrality.map_to_nodes(g, c)\n        &gt;&gt;&gt; print(c_mapped)\n        {'a': 0.5, 'b': 2.7, 'c': 0.3}\n        ```\n    \"\"\"\n    return {g.mapping.to_id(i): c[i] for i in c}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_node_traversals","title":"<code>path_node_traversals</code>","text":"<p>Calculate the number of times any path traverses each of the nodes.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>pathpyG.core.path_data.PathData</code> <p><code>PathData</code> object that contains observations of paths in a graph</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_node_traversals(paths: PathData) -&gt; dict:\n    \"\"\"Calculate the number of times any path traverses each of the nodes.\n\n    Args:\n        paths: `PathData` object that contains observations of paths in a graph\n    \"\"\"\n    unique_node_seq, traversal_counts = torch.unique(paths.data.node_sequence, return_counts=True)\n    return {paths.mapping.to_id(node): count.item() for node, count in zip(unique_node_seq, traversal_counts)}\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.path_visitation_probabilities","title":"<code>path_visitation_probabilities</code>","text":"<p>Calculate the probabilities that a randomly chosen path passes through each of the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be assigned a visitation probability of 0.05. This measure can be interpreted as ground truth for the notion of importance captured by PageRank applied to a graphical abstraction of the paths.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>pathpyG.core.path_data.PathData</code> <p>PathData object that contains path data</p> required Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def path_visitation_probabilities(paths: PathData) -&gt; dict:\n    \"\"\"Calculate the probabilities that a randomly chosen path passes through each of\n    the nodes. If 5 out of 100 paths (of any length) traverse node v, node v will be\n    assigned a visitation probability of 0.05. This measure can be interpreted as ground\n    truth for the notion of importance captured by PageRank applied to a graphical\n    abstraction of the paths.\n\n    Args:\n        paths: PathData object that contains path data\n    \"\"\"\n    # entries capture the probability that a given node is visited on an arbitrary path\n    # Note: this is identical to the subpath count of zero-length paths\n    # (i.e. the relative frequencies of nodes across all pathways)\n    visit_probabilities = path_node_traversals(paths)\n\n    # total number of visits\n    visits = 0.0\n    for v in visit_probabilities:\n        visits += visit_probabilities[v]\n\n    for v in visit_probabilities:\n        visit_probabilities[v] /= visits\n    return visit_probabilities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_betweenness_centrality","title":"<code>temporal_betweenness_centrality</code>","text":"<p>Calculate the temporal betweenness of nodes in a temporal graph.</p> <p>The temporal betweenness centrality definition is based on shortest time-respecting paths with a given maximum time difference delta, where the length of a path is given as the number of traversed edges (i.e. not the temporal duration of a path or the earliest arrival at a node).</p> <p>The algorithm is an adaptation of Brandes' fast algorithm for betweenness centrality based on the following work:</p> <p>S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal Betweenness, arXiv:2006.08668v2</p> <p>Different from the algorithm proposed above, the temporal betweenness centrality implemented in pathpyG is based on a directed acyclic event graph representation of a temporal graph and it considers a maximum waiting time of delta. The complexity is in O(nm) where n is the number of nodes in the temporal graph and m is the number of time-stamped edges.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> <code>1</code> Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\nbw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_betweenness_centrality(g: TemporalGraph, delta: int = 1) -&gt; dict[str, float]:\n    \"\"\"Calculate the temporal betweenness of nodes in a temporal graph.\n\n    The temporal betweenness centrality definition is based on shortest\n    time-respecting paths with a given maximum time difference delta, where\n    the length of a path is given as the number of traversed edges (i.e. not\n    the temporal duration of a path or the earliest arrival at a node).\n\n    The algorithm is an adaptation of Brandes' fast algorithm for betweenness\n    centrality based on the following work:\n\n    S. Buss, H. Molter, R. Niedermeier, M. Rymar: Algorithmic Aspects of Temporal\n    Betweenness, arXiv:2006.08668v2\n\n    Different from the algorithm proposed above, the temporal betweenness centrality\n    implemented in pathpyG is based on a directed acyclic event graph representation of\n    a temporal graph and it considers a maximum waiting time of delta. The complexity\n    is in O(nm) where n is the number of nodes in the temporal graph and m is the number\n    of time-stamped edges.\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        bw = pp.algorithms.temporal_betweenness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1))\n\n    # add edges from first-order source nodes to edge events\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges], dim=1)\n    src_indices = torch.unique(src_edges_src).tolist()\n\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.m + g.n)\n\n    e_i = to_numpy(g.data.edge_index)\n\n    fo_nodes = dict()\n    for v in range(g.m + g.n):\n        if v &lt; g.m:  # return first-order target node otherwise\n            fo_nodes[v] = e_i[1, v]\n        else:\n            fo_nodes[v] = v - g.m\n\n    bw: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n    # for all first-order nodes\n    for s in tqdm(src_indices):\n\n        # for any given s, d[v] is the shortest path distance from s to v\n        # Note that here we calculate topological distances from sources to events (i.e. time-stamped edges)\n        delta_: defaultdict[int, float] = defaultdict(lambda: 0.0)\n\n        # for any given s, sigma[v] counts shortest paths from s to v\n        sigma: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma[s] = 1.0\n\n        sigma_fo: defaultdict[int, float] = defaultdict(lambda: 0.0)\n        sigma_fo[fo_nodes[s]] = 1.0\n\n        dist: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist[s] = 0\n\n        dist_fo: defaultdict[int, int] = defaultdict(lambda: -1)\n        dist_fo[fo_nodes[s]] = 0\n\n        # for any given s, P[v] is the set of predecessors of v on shortest paths from s\n        P = defaultdict(set)\n\n        # Q is a queue, so we append at the right and pop from the left\n        Q: deque = deque()\n        Q.append(s)\n\n        # S is a stack, so we append at the end and pop from the end\n        S = list()\n\n        # dijkstra with path counting\n        while Q:\n            v = Q.popleft()\n            # for all successor events within delta\n            for w in event_graph.successors(v):\n\n                # we dicover w for the first time\n                if dist[w] == -1:\n                    dist[w] = dist[v] + 1\n                    if dist_fo[fo_nodes[w]] == -1:\n                        dist_fo[fo_nodes[w]] = dist[v] + 1\n                    S.append(w)\n                    Q.append(w)\n                # we found a shortest path to event w via event v\n                if dist[w] == dist[v] + 1:\n                    sigma[w] += sigma[v]\n                    P[w].add(v)\n                    # we found a shortest path to first-order node of event w\n                    if dist[w] == dist_fo[fo_nodes[w]]:\n                        sigma_fo[fo_nodes[w]] += sigma[v]\n\n        c = 0.0\n        for i in dist_fo:\n            if dist_fo[i] &gt;= 0:\n                c += 1.0\n        bw[fo_nodes[s]] = bw[fo_nodes[s]] - c + 1.0\n\n        while S:\n            w = S.pop()\n            # work backwards through paths to all targets and sum delta and sigma\n            if dist[w] == dist_fo[fo_nodes[w]]:\n                x = sigma[w] / sigma_fo[fo_nodes[w]]\n                if isnan(x):\n                    x = 0.0\n                delta_[w] += x\n            for v in P[w]:\n                x = sigma[v] / sigma[w]\n                if isnan(x):\n                    x = 0.0\n                delta_[v] += x * delta_[w]\n                bw[fo_nodes[v]] += delta_[w] * x\n\n    # map index-based centralities to node IDs\n    bw_id = defaultdict(lambda: 0.0)\n    for idx in bw:\n        bw_id[g.mapping.to_id(idx)] = bw[idx]\n    return bw_id\n</code></pre>"},{"location":"reference/pathpyG/algorithms/centrality/#pathpyG.algorithms.centrality.temporal_closeness_centrality","title":"<code>temporal_closeness_centrality</code>","text":"<p>Calculates the temporal closeness centrality of nodes based on observed shortest time-respecting paths between all nodes.</p> <p>Following the definition by M. A. Beauchamp 1965 (https://doi.org/10.1002/bs.3830100205).</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p><code>TemporalGraph</code> object for which temporal betweenness centrality will be computed</p> required <code>delta</code> <code>int</code> <p>maximum waiting time for time-respecting paths</p> required Example <pre><code>import pathpyG as pp\nt = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                    ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\ncl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n</code></pre> Source code in <code>src/pathpyG/algorithms/centrality.py</code> <pre><code>def temporal_closeness_centrality(g: TemporalGraph, delta: int) -&gt; dict[str, float]:\n    \"\"\"Calculates the temporal closeness centrality of nodes based on\n    observed shortest time-respecting paths between all nodes.\n\n    Following the definition by M. A. Beauchamp 1965\n    (https://doi.org/10.1002/bs.3830100205).\n\n    Args:\n        g: `TemporalGraph` object for which temporal betweenness centrality will be computed\n        delta: maximum waiting time for time-respecting paths\n\n    Example:\n        ```py\n        import pathpyG as pp\n        t = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2),\n                            ('b', 'd', 2), ('c', 'e', 3), ('d', 'e', 3)])\n        cl = pp.algorithms.temporal_closeness_centrality(t, delta=1)\n        ```\n    \"\"\"\n    centralities = dict()\n    dist, _ = temporal_shortest_paths(g, delta)\n    for x in g.nodes:\n        centralities[x] = sum((g.n - 1) / dist[_np.arange(g.n) != g.mapping.to_idx(x), g.mapping.to_idx(x)])\n\n    return centralities\n</code></pre>"},{"location":"reference/pathpyG/algorithms/components/","title":"components","text":"<p>Algorithms to calculate connected components</p>"},{"location":"reference/pathpyG/algorithms/generative_models/","title":"generative_models","text":"<p>Algorithms to generate random graphs</p> <p>The functions in this module allow to generate graphs based on different probabilistic generative models.</p> Example <pre><code>import pathpyG as pp\n\ng = pp.algorithms.generative_models.erdos_renyi_gnm(n=100, m=200)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnm","title":"<code>erdos_renyi_gnm</code>","text":"<p>Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>the number of nodes of the graph</p> required <code>m</code> <code>int</code> <p>the number of random directed or undirected edges to be generated</p> required <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>optional given mapping of n nodes to node IDs. If this is not given a mapping is created</p> <code>None</code> <code>self_loops</code> <code>bool</code> <p>whether or not to allow self-loops (v,v) to be generated</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>whether or not multiple identical edges are allowed</p> <code>False</code> <code>directed</code> <code>bool</code> <p>whether or not to generate a directed graph</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>graph object</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnm(n: int, m: int, mapping: IndexMap | None = None,\n                    self_loops: bool = False, multi_edges: bool = False,\n                    directed: bool = False) -&gt; Graph:\n    \"\"\"Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.\n\n    Args:\n        n: the number of nodes of the graph\n        m: the number of random directed or undirected edges to be generated\n        mapping: optional given mapping of n nodes to node IDs. If this is not given a mapping is created\n        self_loops: whether or not to allow self-loops (v,v) to be generated\n        multi_edges: whether or not multiple identical edges are allowed\n        directed: whether or not to generate a directed graph\n\n    Returns:\n        Graph: graph object\n    \"\"\"\n    if m &gt; max_edges(n, directed=directed, self_loops=self_loops, multi_edges=multi_edges):\n        logger.error(\"Given number of edges is larger than theoretical maximum\")\n        raise ValueError(\"Given number of edges is larger than theoretical maximum\")\n\n    edges = set()\n    edges_added: int = 0\n\n    if mapping is None:\n        # make sure that we have indices for all n nodes even if not all\n        # nodes have incident edges\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    # Add m edges at random\n    while edges_added &lt; m:\n\n        # Choose two random nodes (with replacement if self-loops are included)\n        v, w = _np.random.choice(n, size=2, replace=self_loops)\n\n        # avoid multi-edges\n        if multi_edges or (mapping.to_id(v), mapping.to_id(w)) not in edges:\n            edges.add((mapping.to_id(v), mapping.to_id(w)))\n            if not directed and v != w:\n                edges.add((mapping.to_id(w), mapping.to_id(v)))\n            edges_added += 1\n\n    return Graph.from_edge_list(list(edges), is_undirected=not directed, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnm_randomize","title":"<code>erdos_renyi_gnm_randomize</code>","text":"<p>Generate a random graph whose number of nodes, edges, edge directedness and node IDs match the corresponding values of a given network instance. Useful to generate a randomized version of a network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>A given network used to determine number of nodes, edges, node uids, and edge directedness</p> required <code>self_loops</code> <code>bool</code> <p>Whether or not the generated network can contain loops.</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>Whether or not multiple edges can be added to the same node pair</p> <code>False</code> <p>Example: <pre><code>    # Generate undirected network\n    import pathpyG as pp\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('d', 'e')])\n    r = pp.algorithms.generative_models.G_nm_randomize(g)\n</code></pre></p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnm_randomize(graph: Graph, self_loops: bool = False, multi_edges: bool = False) -&gt; Graph:\n    \"\"\"Generate a random graph whose number of nodes, edges, edge directedness and node IDs\n    match the corresponding values of a given network instance. Useful to generate a randomized\n    version of a network.\n\n    Args:\n        graph: A given network used to determine number of nodes, edges, node uids, and edge directedness\n        self_loops: Whether or not the generated network can contain loops.\n        multi_edges: Whether or not multiple edges can be added to the same node pair\n\n    Example:\n    ```py\n        # Generate undirected network\n        import pathpyG as pp\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('d', 'e')])\n        r = pp.algorithms.generative_models.G_nm_randomize(g)\n    ```\n    \"\"\"\n    return erdos_renyi_gnm(\n        graph.n, graph.m, directed=graph.is_directed(),\n        self_loops=self_loops,\n        multi_edges=multi_edges,\n        mapping=graph.mapping\n    )\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp","title":"<code>erdos_renyi_gnp</code>","text":"<p>Generate an Erd\u00f6s-Renyi random graph with n nodes and  link probability p, using the G(n,p) model by Edgar Nelson Gilbert.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>the number of nodes of the graph</p> required <code>p</code> <code>float</code> <p>the link probability</p> required <code>self_loops</code> <code>bool</code> <p>whether or not to allow self-loops (v,v) to be generated</p> <code>False</code> <code>directed</code> <code>bool</code> <p>whether or not to generate a directed graph</p> <code>False</code> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp(n: int, p: float, mapping: IndexMap | None = None,\n                    self_loops: bool = False, directed: bool = False) -&gt; Graph:\n    \"\"\"Generate an Erd\u00f6s-Renyi random graph with n nodes and \n    link probability p, using the G(n,p) model by Edgar Nelson Gilbert.\n\n    Args:\n        n: the number of nodes of the graph\n        p: the link probability\n        self_loops: whether or not to allow self-loops (v,v) to be generated\n        directed: whether or not to generate a directed graph\n    \"\"\"\n    edges = set()\n\n    if mapping is None:\n        # make sure that we have indices for all n nodes even if not all\n        # nodes have incident edges\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    # fast handling of special case p = 0\n    if p == 0.0:\n        return Graph.from_edge_list([], is_undirected=not directed)\n\n    # connect pairs of nodes with probability p\n    for s in range(n):\n        if directed:\n            x = n\n        else:\n            x = s + 1\n        for t in range(x):\n            if not self_loops and t == s:\n                continue\n            if _np.random.random() &lt;= p:\n                edges.add((mapping.to_id(s), mapping.to_id(t)))\n                if not directed and s != t:\n                    edges.add((mapping.to_id(t), mapping.to_id(s)))\n\n    return Graph.from_edge_list(list(edges), is_undirected=not directed, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_likelihood","title":"<code>erdos_renyi_gnp_likelihood</code>","text":"<p>Calculate the likelihood of parameter p for a G(n,p) model and a given undirected graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_likelihood(p: float, graph: Graph) -&gt; float:\n    \"\"\"Calculate the likelihood of parameter p for a G(n,p) model and a given undirected graph\"\"\"\n    if graph.is_directed():\n        logger.error(\"erdos_renyi_gnp_likelihood does not support directed graphs\")\n        raise NotImplementedError(\"erdos_renyi_gnp_likelihood does not support directed graphs\")\n    return p**graph.n * (1 - p) ** (scipy.special.binom(graph.n, 2) - graph.m)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_log_likelihood","title":"<code>erdos_renyi_gnp_log_likelihood</code>","text":"<p>Calculate the log-likelihood of parameter p for a G(n,p) model and a given undirected graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_log_likelihood(p: float, graph: Graph) -&gt; float:\n    \"\"\"Calculate the log-likelihood of parameter p for a G(n,p) model and a given undirected graph\"\"\"\n    if graph.is_directed():\n        logger.error(\"erdos_renyi_gnp_log_likelihood does not support directed graphs\")\n        raise NotImplementedError(\"erdos_renyi_gnp_log_likelihood does not support directed graphs\")\n    return graph.m * _np.log10(p) + (scipy.special.binom(graph.n, 2) - (graph.m)) * _np.log10(1 - p)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_mle","title":"<code>erdos_renyi_gnp_mle</code>","text":"<p>Calculate the maximum likelihood estimate of parameter p for a G(n,p) model and a given undirected graph</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_mle(graph: Graph) -&gt; float:\n    \"\"\"Calculate the maximum likelihood estimate of parameter p for a G(n,p) model and a given undirected graph\"\"\"\n    if graph.is_directed():\n        logger.error(\"erdos_renyi_gnp_mle does not support directed graphs\")\n        raise NotImplementedError(\"erdos_renyi_gnp_mle does not support directed graphs\")\n    return graph.m / scipy.special.binom(graph.n, 2)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.erdos_renyi_gnp_randomize","title":"<code>erdos_renyi_gnp_randomize</code>","text":"<p>Randomize a given graph based on the Erd\u00f6s-Renyi random graph G(n,p) model.</p> <p>The number of nodes, expected number of edges, edge directedness and node uids of the generated graph match the corresponding values of the graph given as parameter.</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def erdos_renyi_gnp_randomize(graph: Graph, self_loops: bool = False) -&gt; Graph:\n    \"\"\"Randomize a given graph based on the Erd\u00f6s-Renyi random graph G(n,p) model.\n\n    The number of nodes, expected number of edges, edge directedness and node uids of the\n    generated graph match the corresponding values of the graph given as parameter.\n    \"\"\"\n    M = max_edges(graph.n, directed=graph.is_directed(), self_loops=self_loops)\n    p = graph.m / M\n    return erdos_renyi_gnp(n=graph.n, p=p, directed=graph.is_directed(), \n                           self_loops=self_loops, mapping=graph.mapping)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.generate_degree_sequence","title":"<code>generate_degree_sequence</code>","text":"<p>Generates a random graphic degree sequence drawn from a given degree distribution</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def generate_degree_sequence(\n    n: int,\n    distribution: Dict[float, float] | scipy.stats.rv_continuous | scipy.stats.rv_discrete,\n    **distribution_args: Any,\n) -&gt; _np.ndarray:\n    \"\"\"Generates a random graphic degree sequence drawn from a given degree distribution\"\"\"\n    s = _np.array([1])\n    # create rv_discrete object with custom distribution and generate degree sequence\n    if isinstance(distribution, dict):\n        degrees = [k for k in distribution]\n        probs = [distribution[k] for k in degrees]\n\n        dist = scipy.stats.rv_discrete(name=\"custom\", values=(degrees, probs))\n\n        while not is_graphic_erdos_gallai(s):\n            s = dist.rvs(size=n, **distribution_args)\n        return s\n    # use scipy rv objects to generate graphic degree sequence\n    elif hasattr(distribution, \"rvs\"):\n        while not is_graphic_erdos_gallai(s):\n            s = distribution.rvs(size=n, **distribution_args)\n            # Check if the distribution is discrete\n            if s.dtype != int:\n                s = _np.rint(s)\n        return s\n    else:\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.is_graphic_erdos_gallai","title":"<code>is_graphic_erdos_gallai</code>","text":"<p>Check Erd\u00f6s and Gallai condition.</p> <p>Checks whether the condition by Erd\u00f6s and Gallai (1967) for a graphic degree sequence is fulfilled.</p> <p>Parameters:</p> Name Type Description Default <code>degrees</code> <code>list[int] | numpy.ndarray</code> <p>List of integer node degrees to be tested.</p> required Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def is_graphic_erdos_gallai(degrees: list[int] | _np.ndarray) -&gt; bool:\n    \"\"\"Check Erd\u00f6s and Gallai condition.\n\n    Checks whether the condition by Erd\u00f6s and Gallai (1967) for a graphic degree\n    sequence is fulfilled.\n\n    Args:\n        degrees: List of integer node degrees to be tested.\n    \"\"\"\n    degree_sequence = sorted(degrees, reverse=True)\n    S = sum(degree_sequence)\n    n = len(degree_sequence)\n    if S % 2 != 0:\n        return False\n    for r in range(1, n):\n        M = 0\n        S = 0\n        for i in range(1, r + 1):\n            S += degree_sequence[i - 1]\n        for i in range(r + 1, n + 1):\n            M += min(r, degree_sequence[i - 1])\n        if S &gt; r * (r - 1) + M:\n            return False\n    return True\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.k_regular_random","title":"<code>k_regular_random</code>","text":"<p>Generate a random graph in which all nodes have exactly degree k</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>degree of all nodes in the generated network.</p> required <code>node_ids</code> <code>typing.Optional[list]</code> <p>Optional list of node uids that will be used.</p> <code>None</code> <p>Examples:</p> <pre><code>Generate random undirected network with given degree sequence\n\n&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n&gt;&gt;&gt; print(random_network.summary())\n...\n\nNetwork generation fails for non-graphic sequences\n\n&gt;&gt;&gt; import pathpy as pp\n&gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n&gt;&gt;&gt; print(random_network)\nNone\n</code></pre> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def k_regular_random(k: int, n: Optional[int] = None, node_ids: Optional[list] = None) -&gt; Optional[Graph]:\n    \"\"\"Generate a random graph in which all nodes have exactly degree k\n\n    Args:\n        k: degree of all nodes in the generated network.\n        node_ids: Optional list of node uids that will be used.\n\n    Examples:\n\n        Generate random undirected network with given degree sequence\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n        &gt;&gt;&gt; print(random_network.summary())\n        ...\n\n        Network generation fails for non-graphic sequences\n\n        &gt;&gt;&gt; import pathpy as pp\n        &gt;&gt;&gt; random_network = pp.algorithms.random_graphs.Molloy_Reed([1,0])\n        &gt;&gt;&gt; print(random_network)\n        None\n    \"\"\"\n    if k &lt; 0:\n        msg = 'Degree parameter k must be non-negative'\n        raise ValueError(msg)\n    if n is None and node_ids is None:\n        msg = 'You must either pass a list of node ids or a number of nodes to generate'\n        raise ValueError(msg)\n\n    if n is None:\n        n = len(node_ids)\n\n    return molloy_reed([k]*n, multiedge=False, relax=False, node_ids=node_ids)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.max_edges","title":"<code>max_edges</code>","text":"<p>Returns the maximum number of edges that a directed or undirected network with n nodes can possible have (with or without loops).</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of nodes in the network</p> required <code>directed</code> <code>bool</code> <p>If True, return the maximum number of edges in a directed network.</p> <code>False</code> <code>multi_edges</code> <code>bool</code> <p>If True, multiple edges between each node pair are allowed. In this case np.inf is returned.</p> <code>False</code> <code>self_loops</code> <code>bool</code> <p>If True, include self-loops.</p> <code>False</code> <p>Examples:</p> <p>Compute maximum number of edges in undirected network without self-loops and 100 nodes</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100)\n4950\n</code></pre> <p>Directed networks without self-loops</p> <pre><code>&gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True)\n9900\n</code></pre> <p>Directed networks with self-loops </p> <pre><code>&gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True, loops=True)\n10000\n</code></pre> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def max_edges(n: int, directed: bool = False, multi_edges: bool = False, self_loops: bool = False) -&gt; int | float:\n    \"\"\"Returns the maximum number of edges that a directed or undirected network with n nodes can\n    possible have (with or without loops).\n\n    Args:\n        n: The number of nodes in the network\n        directed: If True, return the maximum number of edges in a directed network.\n        multi_edges: If True, multiple edges between each node pair are allowed. In this case np.inf is returned.\n        self_loops: If True, include self-loops.\n\n    Examples:\n        Compute maximum number of edges in undirected network without self-loops and 100 nodes\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100)\n        4950\n\n        Directed networks without self-loops\n\n        &gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True)\n        9900\n\n        Directed networks with self-loops \n\n        &gt;&gt;&gt; print(pp.algorithms.generative_models.max_edges(100, directed=True, loops=True)\n        10000\n    \"\"\"\n\n    if multi_edges:\n        return _np.inf\n    elif self_loops and directed:\n        return int(n**2)\n    elif self_loops and not directed:\n        return int(n * (n + 1) / 2)\n    elif not self_loops and not directed:\n        return int(n * (n - 1) / 2)\n    else:  # not loops and directed:\n        return int(n * (n - 1))\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.molloy_reed","title":"<code>molloy_reed</code>","text":"<p>Generate Molloy-Reed graph.</p> <p>Generates a random undirected network without self-loops, with given degree sequence based on the Molloy-Reed algorithm. The condition proposed by Erd\u00f6s and Gallai (1967) is used to test whether the degree sequence is graphic, i.e. whether a network with the given degree sequence exists.</p> <p>Parameters:</p> Name Type Description Default <code>degrees</code> <p>List of integer node degrees. The number of nodes of the generated</p> required <code>relax</code> <code>bool</code> <p>If True, we conceptually allow self-loops and multi-edges, but do not</p> <code>False</code> <code>node_ids </code> <p>Optional list of node IDs that will be used for Indexmapping.</p> required <p>Examples:</p> <p>Generate random undirected network with given degree sequence</p> <p>import pathpyG as pp random_network = pp.algorithms.generative_models.molloy_reed([1,0]) print(random_network) ...</p> <p>Network generation fails for non-graphic degree sequence</p> <p>import pathpyG as pp random_network = pp.algorithms.generative_models.molloy_reed([1,0]) raises AttributeError</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def molloy_reed(degree_sequence: _np.array | Dict[int, float],\n                multiedge: bool = False,\n                relax: bool = False,\n                node_ids: Optional[list] = None) -&gt; Graph:\n    \"\"\"Generate Molloy-Reed graph.\n\n    Generates a random undirected network without self-loops, with given degree sequence based on\n    the Molloy-Reed algorithm. The condition proposed by Erd\u00f6s and Gallai (1967)\n    is used to test whether the degree sequence is graphic, i.e. whether a network\n    with the given degree sequence exists.\n\n    Args:\n        degrees: List of integer node degrees. The number of nodes of the generated\n        network corresponds to len(degrees).\n\n        relax: If True, we conceptually allow self-loops and multi-edges, but do not\n        add them to the network. This implies that the generated graph may not\n        have exactly sum(degrees)/2 edges, but it ensures that the algorithm\n        always finishes.\n\n        node_ids : Optional list of node IDs that will be used for Indexmapping.\n\n    Examples:\n\n    Generate random undirected network with given degree sequence\n\n    &gt;&gt;&gt; import pathpyG as pp\n    &gt;&gt;&gt; random_network = pp.algorithms.generative_models.molloy_reed([1,0])\n    &gt;&gt;&gt; print(random_network)\n    ...\n\n    Network generation fails for non-graphic degree sequence\n\n    &gt;&gt;&gt; import pathpyG as pp\n    &gt;&gt;&gt; random_network = pp.algorithms.generative_models.molloy_reed([1,0])\n    raises AttributeError\n\n    \"\"\"\n\n    # assume that we are given a graphical degree sequence\n    if not is_graphic_erdos_gallai(degree_sequence):\n        logger.error(\"given degree sequence is not graphic\")\n        raise ValueError('gicen degree sequence is not graphic')\n\n    # create empty network with n nodes\n    n = len(degree_sequence)\n    edges: list = []\n\n    if node_ids is None or len(node_ids) != n:\n        node_ids: list = []\n        for i in range(n):\n            node_ids.append(i)\n\n    # generate edge stubs based on degree sequence\n    stubs: list = []\n    for i in range(n):\n        for _ in range(int(degree_sequence[i])):\n            stubs.append(node_ids[i])\n\n    # connect randomly chosen pairs of stubs\n    while len(stubs) &gt; 0:\n        # find candidate node pair to connect\n        v, w = _np.random.choice(stubs, 2, replace=False)\n\n        # we encountered candidate edge that we cannot add\n        if v == w or (((v, w) in edges or (w, v) in edges) and not multiedge and not relax):\n            # break up random edge and add back stubs to avoid\n            # infinite loop\n            if len(edges) &gt; 0:\n                e = random.choice(edges)\n                edges.remove(e)\n                stubs.append(e[0])\n                stubs.append(e[1])\n        elif v != w:\n            edges.append((v, w))\n            stubs.remove(v)\n            stubs.remove(w)\n\n    return Graph.from_edge_list(edges).to_undirected()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.molloy_reed_randomize","title":"<code>molloy_reed_randomize</code>","text":"<p>Generates a randomized realization of a given undirected network based on the observed degree sequence.</p> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def molloy_reed_randomize(g: Graph) -&gt; Optional[Graph]:\n    \"\"\"Generates a randomized realization of a given undirected network based on the observed degree sequence.\n    \"\"\"\n    if g.is_directed():\n        logger.error(\"molloy_reed_randomize is only implemented for undirected graphs\")\n        raise NotImplementedError('molloy_reed_randomize is only implemented for undirected graphs')\n    # degrees are listed in order of node indices\n    degrees = degree(g.data.edge_index[1], num_nodes=g.n, dtype=torch.int).tolist()\n\n    return molloy_reed(degrees, node_ids=g.nodes).to_undirected()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.stochastic_block_model","title":"<code>stochastic_block_model</code>","text":"<p>Generate a random undirected graph based on the stochastic block model</p> <p>Parameters:</p> Name Type Description Default <code>M</code> <code>numpy.matrix</code> <p>n x n stochastic block matrix, where entry M[i,j] gives probability of edge to be generated between nodes in blocks i and j</p> required <code>z</code> <code>numpy.array</code> <p>n-dimensional block assignment vector, where z[i] gives block assignment of i-th node</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of node IDs to indices. If not given, a standard mapping based on integer IDs will be created</p> <code>None</code> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def stochastic_block_model(M: _np.matrix, z: _np.array, mapping: Optional[IndexMap] = None) -&gt; Graph:\n    \"\"\"Generate a random undirected graph based on the stochastic block model\n\n    Args:\n        M: n x n stochastic block matrix, where entry M[i,j] gives probability of edge to be generated\n            between nodes in blocks i and j\n        z: n-dimensional block assignment vector, where z[i] gives block assignment of i-th node\n        mapping: optional mapping of node IDs to indices. If not given, a standard\n            mapping based on integer IDs will be created\n    \"\"\"\n    # the number of nodes is implicitly given by the length of block assignment vector z\n    n = len(z)\n\n    # we can use pre-defined node names, if not given, we use contiguous numbers\n    if mapping is None:\n        mapping = IndexMap([str(i) for i in range(n)])\n\n    edges = []\n\n    # randomly generate links with probabilities given by entries of the stochastic block matrix M\n    for u in range(n):\n        for v in range(u):\n            if _np.random.random() &lt;= M[z[u], z[v]]:\n                edges.append((mapping.to_id(u), mapping.to_id(v)))\n                edges.append((mapping.to_id(v), mapping.to_id(u)))\n\n    g = Graph.from_edge_list(edges, mapping=mapping).to_undirected()\n    return g\n</code></pre>"},{"location":"reference/pathpyG/algorithms/generative_models/#pathpyG.algorithms.generative_models.watts_strogatz","title":"<code>watts_strogatz</code>","text":"<p>Generate a Watts-Strogatz small-world graph.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>The number of nodes in the graph.</p> required <code>s</code> <code>int</code> <p>The number of edges to attach from a new node to existing nodes.</p> required <code>p</code> <code>float</code> <p>The probability of rewiring each edge.</p> <code>0.0</code> <code>undirected</code> <code>bool</code> <p>If True, the graph will be undirected.</p> <code>True</code> <code>allow_duplicate_edges</code> <code>bool</code> <p>If True, allow duplicate edges in the graph. This is faster but may result in fewer edges than requested in the undirected case or duplicates in the directed case.</p> <code>True</code> <code>allow_self_loops</code> <code>bool</code> <p>If True, allow self-loops in the graph. This is faster but may result in fewer edges than requested in the undirected case.</p> <code>True</code> <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>A mapping from the node indices to node names.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>A Watts-Strogatz small-world graph.</p> <p>Examples:</p> <pre><code>g = Watts_Strogatz(100, 4, 0.1, mapping=pp.IndexMap([f\"n_{i}\" for i in range(100)])\n</code></pre> Source code in <code>src/pathpyG/algorithms/generative_models.py</code> <pre><code>def watts_strogatz(\n    n: int,\n    s: int,\n    p: float = 0.0,\n    undirected: bool = True,\n    allow_duplicate_edges: bool = True,\n    allow_self_loops: bool = True,\n    mapping: IndexMap | None = None,\n) -&gt; Graph:\n    \"\"\"Generate a Watts-Strogatz small-world graph.\n\n    Args:\n        n: The number of nodes in the graph.\n        s: The number of edges to attach from a new node to existing nodes.\n        p: The probability of rewiring each edge.\n        undirected: If True, the graph will be undirected.\n        allow_duplicate_edges: If True, allow duplicate edges in the graph.\n            This is faster but may result in fewer edges than requested in the undirected case\n            or duplicates in the directed case.\n        allow_self_loops: If True, allow self-loops in the graph.\n            This is faster but may result in fewer edges than requested in the undirected case.\n        mapping: A mapping from the node indices to node names.\n\n    Returns:\n        Graph: A Watts-Strogatz small-world graph.\n\n    Examples:\n        ```py\n        g = Watts_Strogatz(100, 4, 0.1, mapping=pp.IndexMap([f\"n_{i}\" for i in range(100)])\n        ```\n    \"\"\"\n\n    nodes = torch.arange(n)\n\n    # construct a ring lattice (dimension 1)\n    edges = (\n        torch.stack([torch.stack((nodes, torch.roll(nodes, shifts=-i, dims=0))) for i in range(1, s + 1)], dim=0)\n        .permute(1, 0, 2)\n        .reshape(2, -1)\n    )\n\n    if not allow_duplicate_edges:\n        if n * (n - 1) &lt; edges.shape[1]:\n            logger.error(\"number of edges is greater than the number of possible edges in the graph. Set `allow_duplicate_edges=True` to allow this.\")\n            raise ValueError(\n                \"number of edges is greater than the number of possible edges in the graph. Set `allow_duplicate_edges=True` to allow this.\"\n            )\n        elif n * (n - 1) * 0.5 &lt; edges.shape[1] and p &gt; 0.3:\n            logger.info(\n                \"Avoding duplicate in graphs with high connectivity and high rewiring probability may be slow. Consider setting `allow_duplicate_edges=True`.\"\n            )\n\n    # Rewire each link with probability p\n    rand_vals = torch.rand(edges.shape[1])\n    rewire_mask = rand_vals &lt; p\n\n    # Generate random nodes excluding the current node for each edge that needs to be rewired, also avoid duplicate edges\n    edges[1, rewire_mask] = torch.randint(n, (rewire_mask.sum(),))\n\n    # In the undirected case, make sure the edges all point in the same direction\n    # to avoid duplicate edges pointing in opposite directions\n    if undirected:\n        edges = edges.sort(dim=0)[0]\n    final_edges = edges\n\n    if not allow_duplicate_edges:\n        # Remove duplicate edges\n        final_edges, counts = edges.unique(dim=1, return_counts=True)\n        if final_edges.shape[0] &lt; edges.shape[1]:\n            for i, edge in enumerate(final_edges[:, counts &gt; 1].T):\n                for _ in range(counts[counts &gt; 1][i] - 1):\n                    while True:\n                        new_edge = torch.tensor([edge[0], torch.randint(n, (1,))]).sort()[0].unsqueeze(1)\n                        # Check if the new edge is already in the final edges\n                        # and add it if not\n                        if (new_edge != final_edges).any(dim=0).all():\n                            final_edges = torch.cat((final_edges, new_edge), dim=1)\n                            break\n\n    if not allow_self_loops:\n        self_loop_edges = final_edges[:, final_edges[0] == final_edges[1]]\n        final_edges = final_edges[:, final_edges[0] != final_edges[1]]\n        for self_loop_edge in self_loop_edges.T:\n            while True:\n                new_edge = torch.tensor([self_loop_edge[0], torch.randint(n, (1,))]).sort()[0].unsqueeze(1)\n                # Check if the new edge is already in the final edges\n                # and add it if not\n                if (new_edge != final_edges).any(dim=0).all() and new_edge[0] != new_edge[1]:\n                    final_edges = torch.cat((final_edges, new_edge), dim=1)\n                    break\n\n    g = Graph.from_edge_index(final_edges, mapping=mapping)\n    if undirected:\n        g = g.to_undirected()\n    return g\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/","title":"lift_order","text":"<p>Utility functions for lifting the order of a graph (line-graph transformation).</p>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.aggregate_edge_index","title":"<code>aggregate_edge_index</code>","text":"<p>Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object containing the (higher-order) edge index without duplicates and the node sequences.</p> <p>This method can be seen as a higher-order generalization of the <code>torch_geometric.utils.coalesce</code> method. It is used for example to generate the DeBruijn graph of a given order from the corresponding line graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of a (higher-order) graph where each source and destination node corresponds to a node which is an edge in the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of first order nodes that each node in the edge index corresponds to.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights corresponding to the edge index.</p> <code>None</code> <p>Returns:</p> Type Description <code>pathpyG.core.graph.Graph</code> <p>A graph object containing the aggregated edge index, the node sequences, the edge weights and the inverse index.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def aggregate_edge_index(\n    edge_index: torch.Tensor, node_sequence: torch.Tensor, edge_weight: torch.Tensor | None = None, aggr: str = \"sum\"\n) -&gt; Graph:\n    \"\"\"\n    Aggregate the possibly duplicated edges in the (higher-order) edge index and return a graph object\n    containing the (higher-order) edge index without duplicates and the node sequences.\n\n    This method can be seen as a higher-order generalization of the `torch_geometric.utils.coalesce` method.\n    It is used for example to generate the DeBruijn graph of a given order from the corresponding line graph.\n\n    Args:\n        edge_index: The edge index of a (higher-order) graph where each source and destination node\n            corresponds to a node which is an edge in the (k-1)-th order graph.\n        node_sequence: The node sequences of first order nodes that each node in the edge index corresponds to.\n        edge_weight: The edge weights corresponding to the edge index.\n\n    Returns:\n        A graph object containing the aggregated edge index, the node sequences, the edge weights and the inverse index.\n    \"\"\"\n    if edge_weight is None:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n\n    unique_nodes, inverse_idx = torch.unique(node_sequence, dim=0, return_inverse=True)\n    # If first order, then the indices in the node sequence are the inverse idx we would need already\n    if node_sequence.size(1) == 1:\n        mapped_edge_index = node_sequence.squeeze()[edge_index]\n    else:\n        mapped_edge_index = inverse_idx[edge_index]\n    aggregated_edge_index, edge_weight = coalesce(\n        mapped_edge_index,\n        edge_attr=edge_weight,\n        num_nodes=unique_nodes.size(0),\n        reduce=aggr,\n    )\n    data = Data(\n        edge_index=aggregated_edge_index,\n        num_nodes=unique_nodes.size(0),\n        node_sequence=unique_nodes,\n        edge_weight=edge_weight,\n        inverse_idx=inverse_idx,\n    )\n    return Graph(data)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.aggregate_node_attributes","title":"<code>aggregate_node_attributes</code>","text":"<p>Aggregate the node attributes of each pair of nodes in the edge index</p> <p>This method aggregates the node attributes of each pair of nodes in the edge index using the aggregation method specified. The method returns an attribute for each edge. The aggregation methods are: - \"src\": Use the attribute of the source node for each edge. - \"dst\": Use the attribute of the destination node for each edge. - \"max\": Use the maximum of the attributes of the source and destination nodes for each edge. - \"mul\": Use the product of the attributes of the source and destination nodes for each edge. - \"add\": Use the sum of the attributes of the source and destination nodes for each edge.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of the graph.</p> required <code>node_attribute</code> <code>torch.Tensor</code> <p>The node attribute tensor.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".</p> <code>'src'</code> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>The aggregated node attributes for each edge.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def aggregate_node_attributes(\n    edge_index: torch.Tensor, node_attribute: torch.Tensor, aggr: str = \"src\"\n) -&gt; torch.Tensor:\n    \"\"\"\n    Aggregate the node attributes of each pair of nodes in the edge index\n\n    This method aggregates the node attributes of each pair of nodes in the edge index\n    using the aggregation method specified. The method returns an attribute for each edge.\n    The aggregation methods are:\n    - \"src\": Use the attribute of the source node for each edge.\n    - \"dst\": Use the attribute of the destination node for each edge.\n    - \"max\": Use the maximum of the attributes of the source and destination nodes for each edge.\n    - \"mul\": Use the product of the attributes of the source and destination nodes for each edge.\n    - \"add\": Use the sum of the attributes of the source and destination nodes for each edge.\n\n    Args:\n        edge_index: The edge index of the graph.\n        node_attribute: The node attribute tensor.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".\n\n    Returns:\n        The aggregated node attributes for each edge.\n    \"\"\"\n    if aggr == \"src\":\n        aggr_attributes = node_attribute[edge_index[0]]\n    elif aggr == \"dst\":\n        aggr_attributes = node_attribute[edge_index[1]]\n    elif aggr == \"max\":\n        aggr_attributes = torch.maximum(node_attribute[edge_index[0]], node_attribute[edge_index[1]])\n    elif aggr == \"mul\":\n        aggr_attributes = node_attribute[edge_index[0]] * node_attribute[edge_index[1]]\n    elif aggr == \"add\":\n        aggr_attributes = node_attribute[edge_index[0]] + node_attribute[edge_index[1]]\n    else:\n        raise ValueError(f\"Unknown aggregation method {aggr}\")\n    return aggr_attributes\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.lift_order_edge_index","title":"<code>lift_order_edge_index</code>","text":"<p>Line graph transformation.</p> <p>Do a line graph transformation on the edge index to lift the order of the graph by one. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>num_nodes</code> <code>int | None</code> <p>The number of nodes in the graph. If not given, it will be inferred from the edge index (maximum node index + 1).</p> <code>None</code> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>The edge index of the lifted (line) graph.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int | None = None) -&gt; torch.Tensor:\n    \"\"\"Line graph transformation.\n\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        num_nodes: The number of nodes in the graph. If not given,\n            it will be inferred from the edge index (maximum node index + 1).\n\n    Returns:\n        The edge index of the lifted (line) graph.\n    \"\"\"\n    if num_nodes is None:\n        num_nodes = int(edge_index.max()) + 1\n\n    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n    # Map outdegree to each destination node to create an edge for each combination\n    # of incoming and outgoing edges for each destination node\n    outdegree_per_dst = outdegree[edge_index[1]]\n    # Create sources of the new higher-order edges\n    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n\n    # Create destination nodes that start the indexing after the cumulative sum of the outdegree\n    # of all previous nodes in the ordered sequence of nodes\n    ptrs = cumsum(outdegree, dim=0)[:-1]\n    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n    idx_correction = torch.arange(ho_edge_srcs.size(0), dtype=torch.long, device=edge_index.device)\n    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n    ho_edge_dsts += idx_correction\n    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/lift_order/#pathpyG.algorithms.lift_order.lift_order_edge_index_weighted","title":"<code>lift_order_edge_index_weighted</code>","text":"<p>Weighted line graph transformation.</p> <p>Do a line graph transformation on the edge index to lift the order of the graph by one. Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph. Assumes that the edge index is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>A sorted edge index tensor of shape (2, num_edges).</p> required <code>edge_weight</code> <code>torch.Tensor</code> <p>The edge weights of the (k-1)th order graph.</p> required <code>num_nodes</code> <code>int | None</code> <p>The number of nodes in the graph.</p> <code>None</code> <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".</p> <code>'src'</code> <p>Returns:</p> Type Description <code>tuple[torch.Tensor, torch.Tensor]</code> <p>A tuple containing the edge index of the lifted (line) graph and the aggregated edge weights.</p> Source code in <code>src/pathpyG/algorithms/lift_order.py</code> <pre><code>def lift_order_edge_index_weighted(\n    edge_index: torch.Tensor, edge_weight: torch.Tensor, num_nodes: int | None = None, aggr: str = \"src\"\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Weighted line graph transformation.\n\n    Do a line graph transformation on the edge index to lift the order of the graph by one.\n    Additionally, aggregate the edge weights of the (k-1)-th order graph to the (k)-th order graph.\n    Assumes that the edge index is sorted.\n\n    Args:\n        edge_index: A **sorted** edge index tensor of shape (2, num_edges).\n        edge_weight: The edge weights of the (k-1)th order graph.\n        num_nodes: The number of nodes in the graph.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\" or \"add\".\n\n    Returns:\n        A tuple containing the edge index of the lifted (line) graph and the aggregated edge weights.\n    \"\"\"\n    if num_nodes is None:\n        num_nodes = int(edge_index.max()) + 1\n\n    ho_index = lift_order_edge_index(edge_index, num_nodes)\n    ho_edge_weight = aggregate_node_attributes(ho_index, edge_weight, aggr)\n\n    return ho_index, ho_edge_weight\n</code></pre>"},{"location":"reference/pathpyG/algorithms/rolling_time_window/","title":"rolling_time_window","text":"<p>Iterator interface for rolling time window analysis in temporal graphs.</p>"},{"location":"reference/pathpyG/algorithms/rolling_time_window/#pathpyG.algorithms.rolling_time_window.RollingTimeWindow","title":"<code>RollingTimeWindow</code>","text":"<p>An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.</p> Source code in <code>src/pathpyG/algorithms/rolling_time_window.py</code> <pre><code>class RollingTimeWindow:\n    \"\"\"An iterable rolling time window that can be used to perform time slice analysis of temporal graphs.\"\"\"\n\n    def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n        \"\"\"Initialize a RollingTimeWindow instance that can be used to\n        iterate through a sequence of time-slice networks for a given\n        TemporalNetwork instance.\n\n        Args:\n            temporal_graph: TemporalGraphinstance that will be used to generate the\n                sequence of time-slice networks.\n            window_size: The width of the rolling time window used to create time-slice networks.\n            step_size: The step size in time units by which the starting\n                time of the rolling window will be incremented on each iteration.\n            return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n            weighted: Whether or not to return a weighted graph\n\n        Example:\n            ```py\n            tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n              ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n              ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n              ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n              ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n            t = pp.TemporalGraph.from_edge_list(tedges)\n            r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n            for g, w in r:\n                print('Time window ', w)\n                print(g)\n                print(g.data.edge_index)\n                print('---')\n            ```\n        \"\"\"\n        self.g = temporal_graph\n        self.window_size = window_size\n        self.step_size = step_size\n        self.current_time = self.g.start_time\n        self.return_window = return_window\n        self.weighted = weighted\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.current_time &lt;= self.g.end_time:\n            time_window = (self.current_time, self.current_time + self.window_size)\n            s = self.g.to_static_graph(weighted=self.weighted, time_window=time_window)\n            self.current_time += self.step_size\n            if self.return_window:\n                return s, time_window\n            else:\n                return s\n        else:\n            raise StopIteration()\n</code></pre>"},{"location":"reference/pathpyG/algorithms/rolling_time_window/#pathpyG.algorithms.rolling_time_window.RollingTimeWindow.__init__","title":"<code>__init__</code>","text":"<p>Initialize a RollingTimeWindow instance that can be used to iterate through a sequence of time-slice networks for a given TemporalNetwork instance.</p> <p>Parameters:</p> Name Type Description Default <code>temporal_graph</code> <p>TemporalGraphinstance that will be used to generate the sequence of time-slice networks.</p> required <code>window_size</code> <p>The width of the rolling time window used to create time-slice networks.</p> required <code>step_size</code> <p>The step size in time units by which the starting time of the rolling window will be incremented on each iteration.</p> <code>1</code> <code>return_window</code> <p>Whether or not the iterator shall return the current time window as a second return value. Default is False.</p> <code>False</code> <code>weighted</code> <p>Whether or not to return a weighted graph</p> <code>True</code> Example <pre><code>tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n  ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n  ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n  ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n  ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nr = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</code></pre> Source code in <code>src/pathpyG/algorithms/rolling_time_window.py</code> <pre><code>def __init__(self, temporal_graph, window_size, step_size=1, return_window=False, weighted=True):\n    \"\"\"Initialize a RollingTimeWindow instance that can be used to\n    iterate through a sequence of time-slice networks for a given\n    TemporalNetwork instance.\n\n    Args:\n        temporal_graph: TemporalGraphinstance that will be used to generate the\n            sequence of time-slice networks.\n        window_size: The width of the rolling time window used to create time-slice networks.\n        step_size: The step size in time units by which the starting\n            time of the rolling window will be incremented on each iteration.\n        return_window: Whether or not the iterator shall return the current time window as a second return value. Default is False.\n        weighted: Whether or not to return a weighted graph\n\n    Example:\n        ```py\n        tedges = [('a', 'b', 1), ('b', 'c', 5), ('c', 'd', 9), ('c', 'e', 9),\n          ('c', 'f', 11), ('f', 'a', 13), ('a', 'g', 18), ('b', 'f', 21),\n          ('a', 'g', 26), ('c', 'f', 27), ('h', 'f', 27), ('g', 'h', 28),\n          ('a', 'c', 30), ('a', 'b', 31), ('c', 'h', 32), ('f', 'h', 33),\n          ('b', 'i', 42), ('i', 'b', 42), ('c', 'i', 47), ('h', 'i', 50)]\n        t = pp.TemporalGraph.from_edge_list(tedges)\n        r = pp.algorithms.RollingTimeWindow(t, 10, 10, return_window=True)\n        for g, w in r:\n            print('Time window ', w)\n            print(g)\n            print(g.data.edge_index)\n            print('---')\n        ```\n    \"\"\"\n    self.g = temporal_graph\n    self.window_size = window_size\n    self.step_size = step_size\n    self.current_time = self.g.start_time\n    self.return_window = return_window\n    self.weighted = weighted\n</code></pre>"},{"location":"reference/pathpyG/algorithms/shortest_paths/","title":"shortest_paths","text":"<p>Algorithms to calculate shortest paths in static networks</p> <p>The functions  in this module allow to compute shortest paths in static networks.</p>"},{"location":"reference/pathpyG/algorithms/shortest_paths/#pathpyG.algorithms.shortest_paths.avg_path_length","title":"<code>avg_path_length</code>","text":"<p>Compute the average path length of the graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>Input graph.</p> required <p>Returns:     float: The average path length of the graph.</p> Source code in <code>src/pathpyG/algorithms/shortest_paths.py</code> <pre><code>def avg_path_length(graph: Graph) -&gt; float:\n    \"\"\"Compute the average path length of the graph.\n\n    Args:\n        graph (Graph): Input graph.\n    Returns:\n        float: The average path length of the graph.\n    \"\"\"\n    m = graph.sparse_adj_matrix()\n    dist = dijkstra(m, directed=graph.is_directed(), return_predecessors=False, unweighted=True)\n    return _np.sum(dist) / (graph.n * (graph.n - 1))\n</code></pre>"},{"location":"reference/pathpyG/algorithms/shortest_paths/#pathpyG.algorithms.shortest_paths.diameter","title":"<code>diameter</code>","text":"<p>Compute the diameter of the graph.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>Input graph.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The diameter of the graph.</p> Source code in <code>src/pathpyG/algorithms/shortest_paths.py</code> <pre><code>def diameter(graph: Graph) -&gt; float:\n    \"\"\"Compute the diameter of the graph.\n\n    Args:\n        graph (Graph): Input graph.\n\n    Returns:\n        float: The diameter of the graph.\n    \"\"\"\n    m = graph.sparse_adj_matrix()\n    dist = dijkstra(m, directed=graph.is_directed(), return_predecessors=False, unweighted=True)\n    return _np.max(dist)\n</code></pre>"},{"location":"reference/pathpyG/algorithms/shortest_paths/#pathpyG.algorithms.shortest_paths.shortest_paths_dijkstra","title":"<code>shortest_paths_dijkstra</code>","text":"<p>Compute shortest paths using Dijkstra's algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>Input graph.</p> required <p>Returns:</p> Type Description <code>tuple[numpy.ndarray, numpy.ndarray]</code> <p>tuple[np.ndarray, np.ndarray]: A tuple containing the distance matrix and the predecessor matrix.</p> Source code in <code>src/pathpyG/algorithms/shortest_paths.py</code> <pre><code>def shortest_paths_dijkstra(graph: Graph) -&gt; tuple[_np.ndarray, _np.ndarray]:\n    \"\"\"Compute shortest paths using Dijkstra's algorithm.\n\n    Args:\n        graph (Graph): Input graph.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple containing the distance matrix and the predecessor matrix.\n    \"\"\"\n    m = graph.sparse_adj_matrix()\n    dist, pred = dijkstra(m, directed=graph.is_directed(), return_predecessors=True, unweighted=True)\n    return dist, pred\n</code></pre>"},{"location":"reference/pathpyG/algorithms/temporal/","title":"temporal","text":"<p>Algorithms for the analysis of time-respecting paths in temporal graphs.</p>"},{"location":"reference/pathpyG/algorithms/temporal/#pathpyG.algorithms.temporal.lift_order_temporal","title":"<code>lift_order_temporal</code>","text":"<p>Lift a temporal graph to a second-order temporal event graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to lift.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events to consider them connected.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>ho_index</code> <p>Edge index of the second-order temporal event graph.</p> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def lift_order_temporal(g: TemporalGraph, delta: int = 1):\n    \"\"\"Lift a temporal graph to a second-order temporal event graph.\n\n    Args:\n        g: Temporal graph to lift.\n        delta: Maximum time difference between events to consider them connected.\n\n    Returns:\n        ho_index: Edge index of the second-order temporal event graph.\n    \"\"\"\n    # first-order edge index\n    edge_index, timestamps = g.data.edge_index, g.data.time\n\n    delta = torch.tensor(delta, device=edge_index.device)\n    indices = torch.arange(0, edge_index.size(1), device=edge_index.device)\n\n    unique_t = torch.unique(timestamps, sorted=True)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for t in tqdm(unique_t):\n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = timestamps == t\n        src_edge_idx = indices[src_time_mask]\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (timestamps &gt; t) &amp; (timestamps &lt;= t + delta)\n        dst_edge_idx = indices[dst_time_mask]\n\n        if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n            # compute second-order edges between src and dst idx\n            # for all edges where dst in src_edges (edge_index[1, x[:, 0]]) matches src in dst_edges (edge_index[0, x[:, 1]])\n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx)\n            ho_edge_index = x[edge_index[1, x[:, 0]] == edge_index[0, x[:, 1]]]\n            second_order.append(ho_edge_index)\n\n    ho_index = torch.cat(second_order, dim=0).t().contiguous()\n    return ho_index\n</code></pre>"},{"location":"reference/pathpyG/algorithms/temporal/#pathpyG.algorithms.temporal.temporal_shortest_paths","title":"<code>temporal_shortest_paths</code>","text":"<p>Compute shortest time-respecting paths in a temporal graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>Temporal graph to compute shortest paths on.</p> required <code>delta</code> <code>int</code> <p>Maximum time difference between events in a path.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Tuple of two numpy arrays:</p> <code>numpy.ndarray</code> <ul> <li>dist: Shortest time-respecting path distances between all first-order nodes.</li> </ul> <code>typing.Tuple[numpy.ndarray, numpy.ndarray]</code> <ul> <li>pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.</li> </ul> Source code in <code>src/pathpyG/algorithms/temporal.py</code> <pre><code>def temporal_shortest_paths(g: TemporalGraph, delta: int) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute shortest time-respecting paths in a temporal graph.\n\n    Args:\n        g: Temporal graph to compute shortest paths on.\n        delta: Maximum time difference between events in a path.\n\n    Returns:\n        Tuple of two numpy arrays:\n        - dist: Shortest time-respecting path distances between all first-order nodes.\n        - pred: Predecessor matrix for shortest time-respecting paths between all first-order nodes.\n    \"\"\"\n    # generate temporal event DAG\n    edge_index = lift_order_temporal(g, delta)\n\n    # Add indices of first-order nodes as src and dst of paths in augmented\n    # temporal event DAG\n    src_edges_src = g.data.edge_index[0] + g.m\n    src_edges_dst = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n\n    dst_edges_src = torch.arange(0, g.data.edge_index.size(1), device=g.data.edge_index.device)\n    dst_edges_dst = g.data.edge_index[1] + g.m + g.n\n\n    # add edges from source to edges and from edges to destinations\n    src_edges = torch.stack([src_edges_src, src_edges_dst])\n    dst_edges = torch.stack([dst_edges_src, dst_edges_dst])\n    edge_index = torch.cat([edge_index, src_edges, dst_edges], dim=1)\n\n    # create sparse scipy matrix\n    event_graph = Graph.from_edge_index(edge_index, num_nodes=g.m + 2 * g.n)\n    m = event_graph.sparse_adj_matrix()\n\n    # print(f\"Created temporal event DAG with {event_graph.n} nodes and {event_graph.m} edges\")\n\n    # run disjktra for all source nodes\n    dist, pred = dijkstra(\n        m, directed=True, indices=np.arange(g.m, g.m + g.n), return_predecessors=True, unweighted=True\n    )\n\n    # limit to first-order destinations and correct distances\n    dist_fo = dist[:, g.m + g.n :] - 1\n    np.fill_diagonal(dist_fo, 0)\n\n    # limit to first-order destinations and correct predecessors\n    pred_fo = pred[:, g.n + g.m :]\n    pred_fo[pred_fo == -9999] = -1\n    idx_map = np.concatenate([to_numpy(g.data.edge_index[0].cpu()), [-1]])\n    pred_fo = idx_map[pred_fo]\n    np.fill_diagonal(pred_fo, np.arange(g.n))\n\n    return dist_fo, pred_fo\n</code></pre>"},{"location":"reference/pathpyG/algorithms/weisfeiler_leman/","title":"weisfeiler_leman","text":""},{"location":"reference/pathpyG/algorithms/weisfeiler_leman/#pathpyG.algorithms.weisfeiler_leman.WeisfeilerLeman_test","title":"<code>WeisfeilerLeman_test</code>","text":"<p>Run Weisfeiler-Leman isomorphism test on two graphs.</p> <p>The algorithm heuristically checks whether two graphs are isomorphic. If it returns False, we can be sure that the graphs are non-isomoprhic. If the test returns True we did not find conclusive evidence that they are not isomorphic, i.e. the graphs may or may not be isomophic.</p> <p>The two graphs must have IndexMap mappings that assign different node IDs to the nodes in both graphs. The function will raise an error if the node labels of both graphs overlap.</p> <p>The function returns a tuple (bool, list, list), where the first entry is the result of the test and the two lists represent the fingerprints of the two graphs. If the test yields true the fingerprints are identical. If the test fails, the fingerprints do not correspond.</p> <p>Parameters:</p> Name Type Description Default <code>g1</code> <code>pathpyG.core.graph.Graph</code> <p>pp.Graph</p> required <code>g2</code> <code>pathpyG.core.graph.Graph</code> <p>pp.Graph</p> required Source code in <code>src/pathpyG/algorithms/weisfeiler_leman.py</code> <pre><code>def WeisfeilerLeman_test(\n    g1: Graph, g2: Graph, features_g1: dict = None, features_g2: dict = None\n) -&gt; Tuple[bool, List[str], List[str]]:\n    \"\"\"Run Weisfeiler-Leman isomorphism test on two graphs.\n\n    The algorithm heuristically checks whether two graphs are isomorphic. If it returns False,\n    we can be sure that the graphs are non-isomoprhic. If the test returns True we did not find\n    conclusive evidence that they are not isomorphic, i.e. the graphs may or may not be isomophic.\n\n    The two graphs must have IndexMap mappings that assign different node IDs to the nodes\n    in both graphs. The function will raise an error if the node labels of both graphs overlap.\n\n    The function returns a tuple (bool, list, list), where the first entry is the result of the test\n    and the two lists represent the fingerprints of the two graphs. If the test yields true the fingerprints\n    are identical. If the test fails, the fingerprints do not correspond.\n\n    Args:\n        g1: pp.Graph\n        g2: pp.Graph\n    \"\"\"\n    if g1.mapping is None or g2.mapping is None:\n        raise Exception(\"Graphs must contain IndexMap that assigns node IDs\")\n    if len(set(g1.mapping.node_ids).intersection(g2.mapping.node_ids)) &gt; 0:\n        raise Exception(\"node identifiers of graphs must not overlap\")\n    g_combined = g1 + g2\n    # initialize labels of all nodes to zero\n    if features_g1 is None or features_g2 is None:\n        fingerprint: Dict[str | int, str] = {v: \"0\" for v in g_combined.nodes}\n    else:\n        fingerprint = features_g1.copy()\n        fingerprint.update(features_g2)\n    labels = {}\n    label_count = 1\n    stop = False\n    while not stop:\n        new_fingerprint = {}\n        for node in g_combined.nodes:\n            # create new label based on own label and sorted labels of all neighbors\n            n_label = [fingerprint[x] for x in g_combined.successors(node)]\n            n_label.sort()\n            label = str(fingerprint[node]) + str(n_label)\n            # previously unknown label\n            if label not in labels:\n                # create a new label based on next consecutive number\n                labels[label] = label_count\n                label_count += 1\n            new_fingerprint[node] = labels[label]\n        if len(set(fingerprint.values())) == len(set(new_fingerprint.values())):\n            # we processed all nodes in both graphs without encountering a new label, so we stop\n            stop = True\n        else:\n            # update fingerprint and continue\n            fingerprint = new_fingerprint.copy()\n\n    # Reduce fingerprints to nodes of g1 and g2 respectively\n    fingerprint_1 = [fingerprint[v] for v in g1.nodes]\n    fingerprint_1_sorted = fingerprint_1.copy()\n    fingerprint_1_sorted.sort()\n    fingerprint_2 = [fingerprint[v] for v in g2.nodes]\n    fingerprint_2_sorted = fingerprint_2.copy()\n    fingerprint_2_sorted.sort()\n\n    # perform WL-test\n    if fingerprint_1_sorted == fingerprint_2_sorted:\n        return True, fingerprint_1, fingerprint_2\n    return False, fingerprint_1, fingerprint_2\n</code></pre>"},{"location":"reference/pathpyG/core/","title":"core","text":"<p>Core classes for (temporal) graphs, paths, and higher-order De Bruijn graphs.</p> <p>The classes in the <code>core</code> module can be used to implement integrated pipelines to preprocess time-stamped network data, do inference and model selection of higher-order De Bruijn graph models and address temporal graph learning tasks based on time-aware graph neural networks.</p> Example <pre><code>import pathpyG as pp\n\n# Generate toy example temporal graph\ng = pp.TemporalGraph.from_edge_list([\n    ('b', 'c', 2),\n    ('a', 'b', 1),\n    ('c', 'd', 3),\n    ('d', 'a', 4),\n    ('b', 'd', 2),\n    ('d', 'a', 6),\n    ('a', 'b', 7)],\n    device='cuda'\n)\n\n# Create Multi-Order model that models time-respecting paths\nm = pp.MultiOrderModel.from_temporal_graph(g, delta=1, max_order=3)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\n</code></pre>"},{"location":"reference/pathpyG/core/graph/","title":"graph","text":""},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if \"num_nodes\" not in data and \"edge_index\" in data:            \n            data.num_nodes = data.edge_index.max().item() + 1\n            logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if (\n            data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n            or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n        ):\n            logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n            raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n        self.data = data\n\n        # sort EdgeIndex and validate\n        data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        data.edge_index.validate()\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n        # create node_sequence mapping for higher-order graphs\n        if \"node_sequence\" not in self.data:\n            self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n        Examples:\n            You can create a graph from an edge index tensor as follows:\n\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            &gt;&gt;&gt; print(g)\n            Directed graph with 3 nodes and 3 edges ...\n\n            You can also include a mapping of node IDs:\n\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n            &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n            &gt;&gt;&gt; print(g.mapping)\n            a -&gt; 0\n            b -&gt; 1\n            c -&gt; 2\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else:\n            if mapping is not None and mapping.num_ids() != num_nodes:\n                logger.error(\"Number of node IDs in mapping must match num_nodes\")\n                raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(d, mapping=mapping)\n\n    @staticmethod\n    def from_edge_list(\n        edge_list: Iterable[Tuple[str, str]],\n        is_undirected: bool = False,\n        mapping: Optional[IndexMap] = None,\n        device: Optional[torch.device] = None,\n    ) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            device: optional torch device where tensors shall be stored\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n            &gt;&gt;&gt; print(list(g.edges))\n            [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        \"\"\"\n\n        # handle empty graph\n        if len(edge_list) == 0:\n            return Graph(\n                Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n                mapping=IndexMap(),\n            )\n\n        if mapping is None:\n            edge_array = np.array(edge_list)\n            node_ids = np.unique(edge_array)\n            if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n                node_ids = np.sort(node_ids.astype(int)).astype(str)\n            mapping = IndexMap(node_ids)\n\n        num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex(\n            mapping.to_idxs(edge_list, device=device).T.contiguous(),\n            sparse_size=(num_nodes, num_nodes),\n            is_undirected=is_undirected,\n        )\n        return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"Return an undirected version of this directed graph.\n\n        This method creates a new undirected Graph from the current graph instance by\n        adding all directed edges in opposite direction.\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            &gt;&gt;&gt; g_u = g.to_undirected()\n            &gt;&gt;&gt; print(g_u)\n            Undirected graph with 3 nodes and 6 (directed) edges\n        \"\"\"\n        # create undirected edge index by coalescing the directed edges and keep\n        # track of the original edge index for the edge attributes\n        attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n        edge_index, attr_idx = to_undirected(\n            self.data.edge_index,\n            edge_attr=attr_idx,\n            num_nodes=self.data.num_nodes,\n            reduce=\"min\",\n        )\n\n        data = Data(\n            edge_index=EdgeIndex(\n                data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n            ),\n            num_nodes=self.data.num_nodes,\n        )\n        # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n        # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n        # make sure to copy all node and (undirected) edge attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        for edge_attr in self.edge_attrs():\n            if edge_attr != \"edge_index\":\n                data[edge_attr] = self.data[edge_attr][attr_idx]\n\n        return Graph(data, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n        If the graph contains multiple edges between the same nodes, this method will coalesce\n        them into a single edge with an additional weight attribute called `edge_weight` that\n        contains the number of coalesced edges. The method returns a new graph instance with\n        the coalesced edges.\n\n        Returns:\n            Graph: Graph with coalesced edges\n        \"\"\"\n        i, w = torch_geometric.utils.coalesce(\n            self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n\n    def to(self, device: torch.device) -&gt; Graph:\n        \"\"\"Move all tensors to the given device.\n\n        Args:\n            device: torch device to which all tensors shall be moved\n\n        Returns:\n            Graph: self\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.node_sequence = self.data.node_sequence.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n\n        self.row = self.row.to(device)\n        self.row_ptr = self.row_ptr.to(device)\n        self.col = self.col.to(device)\n        self.col_ptr = self.col_ptr.to(device)\n\n        return self\n\n    def node_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_sequence` attribute.\n\n        Returns:\n            list: list of node attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n\n        Returns:\n            list: list of edge attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; list:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a list object that contains all nodes.\n        If an IndexMap is used, nodes are returned as string IDs.\n        If no IndexMap is used, nodes are returned as integer indices.\n\n        Returns:\n            list: list of all nodes using IDs or indices (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(np.arange(self.n)).tolist()\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    @property\n    def edges(self) -&gt; list:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a list object that contains all edges, where each\n        edge is a tuple of two elements. If an IndexMap is used to map node\n        indices to string IDs, edges are returned as tuples of string IDs.\n        If no mapping is used, edges are returned as tuples of integer indices.\n\n        Returns:\n            list: list object yielding all edges using IDs or indices (if no mapping is used)\n        \"\"\"\n        edge_list = self.mapping.to_ids(self.data.edge_index.t()).tolist()\n        if self.order &gt; 1:\n            return [tuple(map(tuple, x)) for x in edge_list]\n        return list(map(tuple, edge_list))\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n        \"\"\"\n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def successors(self, node: Union[int, str] | tuple) -&gt; list:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n\n        Returns:\n            list: list with all successors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n\n        node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n\n        Returns:\n            list: list with all predecessors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID\n\n        Returns:\n            bool: True if edge exists, False otherwise\n        \"\"\"\n        row = self.mapping.to_idx(v)\n        row_start = self.row_ptr[row]\n        row_end = self.row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in self.col[row_start:row_end]\n\n    def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted in-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing in-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted out-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing out-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                     torch.tensor]:\n        \"\"\"\n        Return (weighted) degrees of nodes.\n\n        Args:\n            mode: `in` or `out` to calculate in- or out-degree for\n                directed networks.\n            edge_attr: Optional numerical edge attribute that will \n                be used to compute weighted degrees\n            return_tensor: if True the function returns a degree tensor, if False (default)\n                a dictionary will be returned that can be indexed by nodes\n        Returns:\n            dict: dictionary containing node degrees\n        \"\"\"\n        if mode == \"in\":\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        else:\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        if return_tensor:\n            return d\n        else:\n            return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n\n    def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n        \"\"\"\n        Compute transition probabilities based on (weighted) outdegrees.\n\n        Args:\n            edge_attr: Optional name of numerical edge attribute that will\n                        will be used to calculate weighted out-degrees for the\n                        visitation probabilities.\n\n        Returns:\n            tensor: Transition probabilities.\n        \"\"\"\n        weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n        source_ids = self.data.edge_index[0]        \n        edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n        if edge_attr:\n            edge_weight = getattr(self.data, edge_attr, None)\n        return edge_weight / weighted_outdegree[source_ids]\n\n    def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization: normalization parameter passed to pyG `get_laplacian`\n                function\n            edge_attr: optinal name of numerical edge attribute that shall\n                be passed to pyG `get_laplacian` function as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(), normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(),\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key.startswith(\"node_\"):\n                if val.size(0) != self.n:\n                    raise ValueError(\"Attribute must have same length as number of nodes\")\n                self.data[key] = val\n            elif key.startswith(\"edge_\"):\n                if val.size(0) != self.m:\n                    raise ValueError(\"Attribute must have same length as number of edges\")\n                self.data[key] = val\n            else:\n                self.data[key] = val\n        elif key[0].startswith(\"node_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif key[0].startswith(\"edge_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n\n    @property\n    def n(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns:\n            int: number of nodes in the graph\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def m(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the number of \n        undirected edges (accounting for self-loops) is returned, i.e. in an undirected\n        graph the directed edges (a,b) and (b,a) will be counted only once.\n\n        Returns:\n            int: number of edges in the graph\n        \"\"\"\n        if self.is_directed():\n            return self.data.num_edges  # type: ignore\n        else:\n            num_self_loops = (self.data.edge_index[0] == self.data.edge_index[1]).sum().item()\n            num_edges_wo_self_loops = self.data.edge_index.size(1) - int(num_self_loops)\n            return int(num_edges_wo_self_loops/2 + num_self_loops) # type: ignore\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"\n        Return order of graph.\n\n        Returns:\n            int: order of the (De Bruijn) graph\n        \"\"\"\n        return self.data.node_sequence.size(1)  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\n\n        Returns:\n            bool: True if graph is directed, False otherwise\n        \"\"\"\n        return not self.data.edge_index.is_undirected\n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\n\n        Returns:\n            bool: True if graph is undirected, False otherwise\n        \"\"\"\n        return self.data.edge_index.is_undirected\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\n\n        Returns:\n            bool: True if graph contains self-loops, False otherwise\n        \"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Args:\n            other: Other graph to be combined with this graph\n            reduce: Reduction method for node attributes of nodes that are present in both graphs.\n                Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n        Examples:\n            Adding two graphs without node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 6 edges\n\n            Adding two graphs with identical node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 4 edges\n\n            Adding two graphs with non-overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 6 nodes and 4 edges\n\n            Adding two graphs with partly overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 5 nodes and 4 edges\n        \"\"\"\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n        mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n        d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n        d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n        d = d1.concat(d2)\n        d.num_nodes = mapping.num_ids()\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n        # For higher-order graphs, we need to update the inverse_idx attribute\n        if \"inverse_idx\" in d:\n            d.inverse_idx = mapping.to_idxs(\n                np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n                device=d.inverse_idx.device,\n            )\n\n        # If both graphs contain node attributes, reduce them using the specified method\n        for k in d1.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                if isinstance(d[k], torch.Tensor):\n                    d[k] = torch_geometric.utils.scatter(\n                        d[k],\n                        mapping.to_idxs(\n                            np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                            device=d[k].device,\n                        ),\n                        dim_size=d.num_nodes,\n                        reduce=reduce,\n                    )\n                else:\n                    raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a list object that contains all edges, where each edge is a tuple of two elements. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of string IDs. If no mapping is used, edges are returned as tuples of integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list object yielding all edges using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.in_degrees","title":"<code>in_degrees</code>  <code>property</code>","text":"<p>Return unweighted in-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing in-degrees of nodes</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.m","title":"<code>m</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the number of  undirected edges (accounting for self-loops) is returned, i.e. in an undirected graph the directed edges (a,b) and (b,a) will be counted only once.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of edges in the graph</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.n","title":"<code>n</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of nodes in the graph</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a list object that contains all nodes. If an IndexMap is used, nodes are returned as string IDs. If no IndexMap is used, nodes are returned as integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list of all nodes using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order of graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>order of the (De Bruijn) graph</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.out_degrees","title":"<code>out_degrees</code>  <code>property</code>","text":"<p>Return unweighted out-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing out-degrees of nodes</p>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>pathpyG.core.graph.Graph</code> <p>Other graph to be combined with this graph</p> required <code>reduce</code> <code>str</code> <p>Reduction method for node attributes of nodes that are present in both graphs. Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".</p> <code>'sum'</code> <p>Examples:</p> <p>Adding two graphs without node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 6 edges\n</code></pre> <p>Adding two graphs with identical node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 4 edges\n</code></pre> <p>Adding two graphs with non-overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 6 nodes and 4 edges\n</code></pre> <p>Adding two graphs with partly overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 5 nodes and 4 edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Args:\n        other: Other graph to be combined with this graph\n        reduce: Reduction method for node attributes of nodes that are present in both graphs.\n            Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n    Examples:\n        Adding two graphs without node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 6 edges\n\n        Adding two graphs with identical node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 4 edges\n\n        Adding two graphs with non-overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 6 nodes and 4 edges\n\n        Adding two graphs with partly overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 5 nodes and 4 edges\n    \"\"\"\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n    mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n    d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n    d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n    d = d1.concat(d2)\n    d.num_nodes = mapping.num_ids()\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n    # For higher-order graphs, we need to update the inverse_idx attribute\n    if \"inverse_idx\" in d:\n        d.inverse_idx = mapping.to_idxs(\n            np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n            device=d.inverse_idx.device,\n        )\n\n    # If both graphs contain node attributes, reduce them using the specified method\n    for k in d1.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            if isinstance(d[k], torch.Tensor):\n                d[k] = torch_geometric.utils.scatter(\n                    d[k],\n                    mapping.to_idxs(\n                        np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                        device=d[k].device,\n                    ),\n                    dim_size=d.num_nodes,\n                    reduce=reduce,\n                )\n            else:\n                raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if \"num_nodes\" not in data and \"edge_index\" in data:            \n        data.num_nodes = data.edge_index.max().item() + 1\n        logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if (\n        data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n        or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n    ):\n        logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n        raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n    self.data = data\n\n    # sort EdgeIndex and validate\n    data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    data.edge_index.validate()\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    # create node_sequence mapping for higher-order graphs\n    if \"node_sequence\" not in self.data:\n        self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key.startswith(\"node_\"):\n            if val.size(0) != self.n:\n                raise ValueError(\"Attribute must have same length as number of nodes\")\n            self.data[key] = val\n        elif key.startswith(\"edge_\"):\n            if val.size(0) != self.m:\n                raise ValueError(\"Attribute must have same length as number of edges\")\n            self.data[key] = val\n        else:\n            self.data[key] = val\n    elif key[0].startswith(\"node_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif key[0].startswith(\"edge_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return (weighted) degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate in- or out-degree for directed networks.</p> <code>'in'</code> <code>edge_attr</code> <code>typing.Any</code> <p>Optional numerical edge attribute that will  be used to compute weighted degrees</p> <code>None</code> <code>return_tensor</code> <code>bool</code> <p>if True the function returns a degree tensor, if False (default) a dictionary will be returned that can be indexed by nodes</p> <code>False</code> <p>Returns:     dict: dictionary containing node degrees</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                 torch.tensor]:\n    \"\"\"\n    Return (weighted) degrees of nodes.\n\n    Args:\n        mode: `in` or `out` to calculate in- or out-degree for\n            directed networks.\n        edge_attr: Optional numerical edge attribute that will \n            be used to compute weighted degrees\n        return_tensor: if True the function returns a degree tensor, if False (default)\n            a dictionary will be returned that can be indexed by nodes\n    Returns:\n        dict: dictionary containing node degrees\n    \"\"\"\n    if mode == \"in\":\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    else:\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    if return_tensor:\n        return d\n    else:\n        return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of edge attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def edge_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n\n    Returns:\n        list: list of edge attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <code>int</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.</p> <code>None</code> <p>Examples:</p> <p>You can create a graph from an edge index tensor as follows:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n&gt;&gt;&gt; print(g)\nDirected graph with 3 nodes and 3 edges ...\n</code></pre> <p>You can also include a mapping of node IDs:</p> <pre><code>&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n&gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n&gt;&gt;&gt; print(g.mapping)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n    Examples:\n        You can create a graph from an edge index tensor as follows:\n\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        &gt;&gt;&gt; print(g)\n        Directed graph with 3 nodes and 3 edges ...\n\n        You can also include a mapping of node IDs:\n\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n        &gt;&gt;&gt; print(g.mapping)\n        a -&gt; 0\n        b -&gt; 1\n        c -&gt; 2\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else:\n        if mapping is not None and mapping.num_ids() != num_nodes:\n            logger.error(\"Number of node IDs in mapping must match num_nodes\")\n            raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>device</code> <code>typing.Optional[torch.device]</code> <p>optional torch device where tensors shall be stored</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n&gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n&gt;&gt;&gt; print(list(g.edges))\n[('a', 'b'), ('a', 'c'), ('b', 'c')]\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(\n    edge_list: Iterable[Tuple[str, str]],\n    is_undirected: bool = False,\n    mapping: Optional[IndexMap] = None,\n    device: Optional[torch.device] = None,\n) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        device: optional torch device where tensors shall be stored\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n        &gt;&gt;&gt; print(list(g.edges))\n        [('a', 'b'), ('a', 'c'), ('b', 'c')]\n    \"\"\"\n\n    # handle empty graph\n    if len(edge_list) == 0:\n        return Graph(\n            Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n            mapping=IndexMap(),\n        )\n\n    if mapping is None:\n        edge_array = np.array(edge_list)\n        node_ids = np.unique(edge_array)\n        if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n            node_ids = np.sort(node_ids.astype(int)).astype(str)\n        mapping = IndexMap(node_ids)\n\n    num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex(\n        mapping.to_idxs(edge_list, device=device).T.contiguous(),\n        sparse_size=(num_nodes, num_nodes),\n        is_undirected=is_undirected,\n    )\n    return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all predecessor nodes of the node indexed by <code>col_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n    \"\"\"\n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all successor nodes of the node indexed by <code>row_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph contains self-loops, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\n\n    Returns:\n        bool: True if graph contains self-loops, False otherwise\n    \"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is directed, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\n\n    Returns:\n        bool: True if graph is directed, False otherwise\n    \"\"\"\n    return not self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if edge exists, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID\n\n    Returns:\n        bool: True if edge exists, False otherwise\n    \"\"\"\n    row = self.mapping.to_idx(v)\n    row_start = self.row_ptr[row]\n    row_end = self.row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in self.col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is undirected, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\n\n    Returns:\n        bool: True if graph is undirected, False otherwise\n    \"\"\"\n    return self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.laplacian","title":"<code>laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code> function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: Laplacian matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization: normalization parameter passed to pyG `get_laplacian`\n            function\n        edge_attr: optinal name of numerical edge attribute that shall\n            be passed to pyG `get_laplacian` function as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(), normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(),\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_sequence</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of node attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def node_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_sequence` attribute.\n\n    Returns:\n        list: list of node attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all predecessors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n\n    Returns:\n        list: list with all predecessors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n    node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.sparse_adj_matrix","title":"<code>sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all successors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) -&gt; list:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n\n    Returns:\n        list: list with all successors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n\n    node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.to","title":"<code>to</code>","text":"<p>Move all tensors to the given device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>torch device to which all tensors shall be moved</p> required <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>self</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; Graph:\n    \"\"\"Move all tensors to the given device.\n\n    Args:\n        device: torch device to which all tensors shall be moved\n\n    Returns:\n        Graph: self\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.node_sequence = self.data.node_sequence.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n\n    self.row = self.row.to(device)\n    self.row_ptr = self.row_ptr.to(device)\n    self.col = self.col.to(device)\n    self.col_ptr = self.col_ptr.to(device)\n\n    return self\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of this directed graph.</p> <p>This method creates a new undirected Graph from the current graph instance by adding all directed edges in opposite direction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n&gt;&gt;&gt; g_u = g.to_undirected()\n&gt;&gt;&gt; print(g_u)\nUndirected graph with 3 nodes and 6 (directed) edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"Return an undirected version of this directed graph.\n\n    This method creates a new undirected Graph from the current graph instance by\n    adding all directed edges in opposite direction.\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        &gt;&gt;&gt; g_u = g.to_undirected()\n        &gt;&gt;&gt; print(g_u)\n        Undirected graph with 3 nodes and 6 (directed) edges\n    \"\"\"\n    # create undirected edge index by coalescing the directed edges and keep\n    # track of the original edge index for the edge attributes\n    attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n    edge_index, attr_idx = to_undirected(\n        self.data.edge_index,\n        edge_attr=attr_idx,\n        num_nodes=self.data.num_nodes,\n        reduce=\"min\",\n    )\n\n    data = Data(\n        edge_index=EdgeIndex(\n            data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n        ),\n        num_nodes=self.data.num_nodes,\n    )\n    # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n    # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n    # make sure to copy all node and (undirected) edge attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    for edge_attr in self.edge_attrs():\n        if edge_attr != \"edge_index\":\n            data[edge_attr] = self.data[edge_attr][attr_idx]\n\n    return Graph(data, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> <p>If the graph contains multiple edges between the same nodes, this method will coalesce them into a single edge with an additional weight attribute called <code>edge_weight</code> that contains the number of coalesced edges. The method returns a new graph instance with the coalesced edges.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>Graph with coalesced edges</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n    If the graph contains multiple edges between the same nodes, this method will coalesce\n    them into a single edge with an additional weight attribute called `edge_weight` that\n    contains the number of coalesced edges. The method returns a new graph instance with\n    the coalesced edges.\n\n    Returns:\n        Graph: Graph with coalesced edges\n    \"\"\"\n    i, w = torch_geometric.utils.coalesce(\n        self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n    )\n    return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/graph/#pathpyG.core.graph.Graph.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Compute transition probabilities based on (weighted) outdegrees.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>Optional name of numerical edge attribute that will         will be used to calculate weighted out-degrees for the         visitation probabilities.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Transition probabilities.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n    \"\"\"\n    Compute transition probabilities based on (weighted) outdegrees.\n\n    Args:\n        edge_attr: Optional name of numerical edge attribute that will\n                    will be used to calculate weighted out-degrees for the\n                    visitation probabilities.\n\n    Returns:\n        tensor: Transition probabilities.\n    \"\"\"\n    weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n    source_ids = self.data.edge_index[0]        \n    edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n    if edge_attr:\n        edge_weight = getattr(self.data, edge_attr, None)\n    return edge_weight / weighted_outdegree[source_ids]\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/","title":"index_map","text":"<p>IndexMap class for mapping node indices to IDs.</p>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap","title":"<code>IndexMap</code>","text":"<p>Maps node indices to IDs.</p> <p>This class keeps a mapping from any node ID, e.g. names (strings) or higher-order IDs (tuples), to an index of the corresponding node in the initial list of IDs, enabling fast lookup of node IDs from a <code>torch_geometric.data.Data</code> object.</p> <p>Attributes:</p> Name Type Description <code>node_ids</code> <code>numpy.ndarray | None</code> <p><code>numpy.ndarray</code> storing the node IDs, enabling fast lookup of multiple node IDs from indices.</p> <code>id_to_idx</code> <code>dict</code> <p><code>dict</code> mapping each node ID to its index.</p> <code>id_shape</code> <code>tuple</code> <p><code>tuple</code> storing the shape of the ID. The default shape is (-1,) for first-order IDs. For higher-order IDs, the shape will be <code>(-1, k)</code> with order <code>k</code>.</p> <p>Examples:</p> <p>Initialize an <code>IndexMap</code> object with a list of string IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\n</code></pre> <p>Add additional IDs to the mapping:</p> <pre><code>&gt;&gt;&gt; index_map.add_id(\"D\")\n&gt;&gt;&gt; print(index_map.to_idx(\"D\"))\n3\n</code></pre> <p>Map indices to IDs. Use <code>to_id</code> for single indices and <code>to_ids</code> for multiple indices. Note that the shape of the given index list will be preserved in the output:</p> <pre><code>&gt;&gt;&gt; print(index_map.to_id(1))\nB\n&gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n['A' 'C']\n</code></pre> <p>Map IDs to indices. Works analogously to the reversed mapping and can, e.g., be used to create an <code>edge_index</code> tensor from a list of edges given by source and destination node IDs:</p> <pre><code>&gt;&gt;&gt; edge_index = index_map.to_idxs([[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]).T\n</code></pre> <p>Create a higher-order ID mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n&gt;&gt;&gt; print(index_map)\n('A', 'B') -&gt; 0\n('A', 'C') -&gt; 1\n('B', 'C') -&gt; 2\n</code></pre> <p>The methods above work analogously for higher-order IDs:</p> <pre><code>&gt;&gt;&gt; print(index_map.to_id(1))\n('A', 'C')\n&gt;&gt;&gt; print(index_map.to_ids([[0], [2]]))\n[[('A', 'B')], [('B', 'C')]]\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>class IndexMap:\n    \"\"\"Maps node indices to IDs.\n\n    This class keeps a mapping from any node ID, e.g. names (strings) or higher-order IDs (tuples),\n    to an index of the corresponding node in the initial list of IDs, enabling fast lookup of node IDs\n    from a `torch_geometric.data.Data` object.\n\n    Attributes:\n        node_ids: `numpy.ndarray` storing the node IDs, enabling fast lookup of multiple node IDs from indices.\n        id_to_idx: `dict` mapping each node ID to its index.\n        id_shape: `tuple` storing the shape of the ID. The default shape is (-1,) for first-order IDs.\n            For higher-order IDs, the shape will be `(-1, k)` with order `k`.\n\n    Examples:\n        Initialize an `IndexMap` object with a list of string IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n\n        Add additional IDs to the mapping:\n\n        &gt;&gt;&gt; index_map.add_id(\"D\")\n        &gt;&gt;&gt; print(index_map.to_idx(\"D\"))\n        3\n\n        Map indices to IDs. Use `to_id` for single indices and `to_ids` for multiple indices.\n        Note that the shape of the given index list will be preserved in the output:\n\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        B\n        &gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n        ['A' 'C']\n\n        Map IDs to indices. Works analogously to the reversed mapping and can, e.g., be used to\n        create an `edge_index` tensor from a list of edges given by source and destination node IDs:\n\n        &gt;&gt;&gt; edge_index = index_map.to_idxs([[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]).T\n\n        Create a higher-order ID mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n        &gt;&gt;&gt; print(index_map)\n        ('A', 'B') -&gt; 0\n        ('A', 'C') -&gt; 1\n        ('B', 'C') -&gt; 2\n\n        The methods above work analogously for higher-order IDs:\n\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        ('A', 'C')\n        &gt;&gt;&gt; print(index_map.to_ids([[0], [2]]))\n        [[('A', 'B')], [('B', 'C')]]\n    \"\"\"\n\n    def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n        \"\"\"Initialize mapping from indices to node IDs.\n\n        The mapping will keep the ordering of the IDs as provided by `node_ids`. If the IDs are not unique,\n        an error will be raised.\n\n        Args:\n            node_ids: List of node IDs to initialize mapping.\n\n        Raises:\n            ValueError: If IDs are not unique.\n\n        Examples:\n            Initialize an `IndexMap` object with a list of string IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"C\", \"B\"])\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            C -&gt; 1\n            B -&gt; 2\n\n            Handle non-unique IDs and sort IDs lexicographically:\n\n            &gt;&gt;&gt; node_ids = [\"A\", \"C\", \"B\", \"A\"]\n            &gt;&gt;&gt; index_map = IndexMap(np.unique(node_ids))\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n        \"\"\"\n        self.node_ids: np.ndarray | None = None\n        self.id_to_idx: dict = {}\n        self.id_shape: tuple = (-1,)  # If the index map is higher order, this will be the shape of the ID\n        if node_ids is not None:\n            self.add_ids(node_ids)\n\n    @property\n    def has_ids(self) -&gt; bool:\n        \"\"\"Return whether mapping has IDs.\n\n        Returns:\n            Whether mapping has IDs.\n\n        Examples:\n            Check if mapping has IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.has_ids)\n            False\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.has_ids)\n            True\n        \"\"\"\n        return self.node_ids is not None\n\n    def num_ids(self) -&gt; int:\n        \"\"\"Return number of IDs. If mapping is not defined, return 0.\n\n        Returns:\n            Number of IDs.\n\n        Examples:\n            Get number of IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.num_ids())\n            0\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.num_ids())\n            3\n\n            &gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n            &gt;&gt;&gt; print(index_map.num_ids())\n            3\n        \"\"\"\n        if self.node_ids is None:\n            return 0\n        else:\n            return len(self.node_ids)\n\n    def add_id(self, node_id: Any) -&gt; None:\n        \"\"\"Assigns additional ID to the next consecutive index.\n\n        Args:\n            node_id: ID to assign.\n\n        Raises:\n            ValueError: If ID is already present in the mapping.\n\n        Examples:\n            Add an additional ID to the mapping:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; index_map.add_id(\"D\")\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n            D -&gt; 3\n        \"\"\"\n        if node_id not in self.id_to_idx:\n            idx = self.num_ids()\n            if isinstance(node_id, (list, tuple)):\n                node_id = to_numpy(node_id)\n                self.id_shape = (-1, *node_id.shape)\n            self.node_ids = (\n                np.concatenate((self.node_ids, to_numpy([node_id])))\n                if self.node_ids is not None\n                else to_numpy([node_id])\n            )\n            self.id_to_idx[node_id] = idx\n        else:\n            raise ValueError(\"ID already present in the mapping.\")\n\n    def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n        \"\"\"Assigns additional IDs to next consecutive indices. The order of IDs is preserved.\n\n        Args:\n            node_ids: IDs to assign\n\n        Raises:\n            ValueError: If IDs are not unique or already present in the mapping.\n\n        Examples:\n            Add additional IDs to the mapping:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; index_map.add_ids([\"E\", \"D\"])\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n            E -&gt; 3\n            D -&gt; 4\n        \"\"\"\n        cur_num_ids = self.num_ids()\n        if isinstance(node_ids, list) and isinstance(node_ids[0], (list, tuple)):\n            self.id_shape = (-1, *to_numpy(node_ids[0]).shape)\n\n        if not isinstance(node_ids, np.ndarray):\n            node_ids = to_numpy(node_ids)\n\n        all_ids = np.concatenate((self.node_ids, node_ids)) if self.node_ids is not None else node_ids\n        unique_ids = np.unique(all_ids, axis=0 if self.id_shape != (-1,) else None)\n\n        if len(unique_ids) != len(all_ids):\n            raise ValueError(\"IDs are not unique or already present in the mapping.\")\n\n        self.node_ids = all_ids\n        self.id_to_idx.update(\n            {tuple(v) if self.id_shape != (-1,) else v: i + cur_num_ids for i, v in enumerate(node_ids)}\n        )\n\n    def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n        \"\"\"Map index to ID if mapping is defined, return index otherwise.\n\n        Args:\n            idx: Index to map.\n\n        Returns:\n            ID if mapping is defined, index otherwise.\n\n        Examples:\n            Map index to ID:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_id(1))\n            B\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_id(1))\n            1\n        \"\"\"\n        if self.has_ids:\n            if self.id_shape == (-1,):\n                return self.node_ids[idx]  # type: ignore\n            else:\n                return tuple(self.node_ids[idx])  # type: ignore\n        else:\n            return idx\n\n    def to_ids(self, idxs: list | tuple | np.ndarray) -&gt; np.ndarray:\n        \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise. The shape of the given index\n        list will be preserved in the output.\n\n        Args:\n            idxs: Indices to map.\n\n        Returns:\n            IDs if mapping is defined, indices otherwise.\n\n        Examples:\n            Map list of indices to IDs:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n            ['A' 'C']\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_ids(torch.tensor([0, 2])))\n            tensor([0 2])\n\n            Map edge_index tensor to array of edges:\n\n            &gt;&gt;&gt; edge_index = torch.tensor([[0, 2, 2, 3], [1, 1, 3, 0]])\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\", \"D\"])\n            &gt;&gt;&gt; print(index_map.to_ids(edge_index.T))\n            [['A' 'B']\n             ['C' 'B']\n             ['C' 'D']\n             ['D' 'A']]\n        \"\"\"\n        if self.has_ids:\n            if not isinstance(idxs, np.ndarray):\n                idxs = to_numpy(idxs)\n            return self.node_ids[idxs]  # type: ignore\n        else:\n            return idxs  # type: ignore\n\n    def to_idx(self, node: str | int | tuple[str] | tuple[int]) -&gt; int | tuple[int]:\n        \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\n\n        Args:\n            node: ID or index to map.\n\n        Returns:\n            Index if mapping is defined, argument otherwise.\n\n        Examples:\n            Map ID to index:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_idx(\"B\"))\n            1\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_idx(1))\n            1\n        \"\"\"\n        n: str | int | tuple[str] | tuple[int] = node\n        if self.has_ids:\n            if self.id_shape != (-1,):\n                n = tuple(n)\n            return self.id_to_idx[n]\n        else:\n            return n\n\n    def to_idxs(self, nodes: list | tuple | np.ndarray, device: Optional[torch.device] = None) -&gt; torch.Tensor:\n        \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise. The shape\n        of the given argument list will be preserved in the output.\n\n        Args:\n            nodes: IDs or indices to map.\n\n        Returns:\n            Indices if mapping is defined, arguments otherwise.\n\n        Examples:\n            Map list of IDs to indices:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map.to_idxs([\"B\", \"A\"]))\n            tensor([1, 0])\n\n            No mapping defined:\n\n            &gt;&gt;&gt; index_map = IndexMap()\n            &gt;&gt;&gt; print(index_map.to_idxs(torch.tensor([1, 0])))\n            tensor([1, 0])\n\n            Map list of edges to edge_index tensor:\n\n            &gt;&gt;&gt; edges = [[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]\n            &gt;&gt;&gt; index_map = IndexMap(np.unique(edges))\n            &gt;&gt;&gt; print(index_map.to_idxs(edges).T)\n            tensor([[0, 1, 2],\n                    [1, 2, 3]])\n        \"\"\"\n        if self.has_ids:\n            if not isinstance(nodes, np.ndarray):\n                nodes = to_numpy(nodes)\n\n            shape = nodes.shape\n            if self.id_shape == (-1,):\n                return torch.tensor([self.id_to_idx[node] for node in nodes.flatten()], device=device).reshape(shape)\n            else:\n                return torch.tensor([self.id_to_idx[tuple(node)] for node in nodes.reshape(self.id_shape)], device=device).reshape(\n                    shape[: -len(self.id_shape) + 1]\n                )\n        else:\n            return torch.tensor(nodes, device=device)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of the mapping.\n\n        Returns:\n            String representation of the mapping.\n\n        Examples:\n            Print string representation of the mapping:\n\n            &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n            &gt;&gt;&gt; print(index_map)\n            A -&gt; 0\n            B -&gt; 1\n            C -&gt; 2\n        \"\"\"\n        s = \"\"\n        for v in self.id_to_idx:\n            s += str(v) + \" -&gt; \" + str(self.to_idx(v)) + \"\\n\"\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.has_ids","title":"<code>has_ids</code>  <code>property</code>","text":"<p>Return whether mapping has IDs.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether mapping has IDs.</p> <p>Examples:</p> <p>Check if mapping has IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.has_ids)\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.has_ids)\nTrue\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.__init__","title":"<code>__init__</code>","text":"<p>Initialize mapping from indices to node IDs.</p> <p>The mapping will keep the ordering of the IDs as provided by <code>node_ids</code>. If the IDs are not unique, an error will be raised.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>typing.Union[typing.List[str], None]</code> <p>List of node IDs to initialize mapping.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If IDs are not unique.</p> <p>Examples:</p> <p>Initialize an <code>IndexMap</code> object with a list of string IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"C\", \"B\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nC -&gt; 1\nB -&gt; 2\n</code></pre> <p>Handle non-unique IDs and sort IDs lexicographically:</p> <pre><code>&gt;&gt;&gt; node_ids = [\"A\", \"C\", \"B\", \"A\"]\n&gt;&gt;&gt; index_map = IndexMap(np.unique(node_ids))\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def __init__(self, node_ids: Union[List[str], None] = None) -&gt; None:\n    \"\"\"Initialize mapping from indices to node IDs.\n\n    The mapping will keep the ordering of the IDs as provided by `node_ids`. If the IDs are not unique,\n    an error will be raised.\n\n    Args:\n        node_ids: List of node IDs to initialize mapping.\n\n    Raises:\n        ValueError: If IDs are not unique.\n\n    Examples:\n        Initialize an `IndexMap` object with a list of string IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"C\", \"B\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        C -&gt; 1\n        B -&gt; 2\n\n        Handle non-unique IDs and sort IDs lexicographically:\n\n        &gt;&gt;&gt; node_ids = [\"A\", \"C\", \"B\", \"A\"]\n        &gt;&gt;&gt; index_map = IndexMap(np.unique(node_ids))\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n    \"\"\"\n    self.node_ids: np.ndarray | None = None\n    self.id_to_idx: dict = {}\n    self.id_shape: tuple = (-1,)  # If the index map is higher order, this will be the shape of the ID\n    if node_ids is not None:\n        self.add_ids(node_ids)\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.__str__","title":"<code>__str__</code>","text":"<p>Return string representation of the mapping.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the mapping.</p> <p>Examples:</p> <p>Print string representation of the mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of the mapping.\n\n    Returns:\n        String representation of the mapping.\n\n    Examples:\n        Print string representation of the mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n    \"\"\"\n    s = \"\"\n    for v in self.id_to_idx:\n        s += str(v) + \" -&gt; \" + str(self.to_idx(v)) + \"\\n\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.add_id","title":"<code>add_id</code>","text":"<p>Assigns additional ID to the next consecutive index.</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>typing.Any</code> <p>ID to assign.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If ID is already present in the mapping.</p> <p>Examples:</p> <p>Add an additional ID to the mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; index_map.add_id(\"D\")\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\nD -&gt; 3\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def add_id(self, node_id: Any) -&gt; None:\n    \"\"\"Assigns additional ID to the next consecutive index.\n\n    Args:\n        node_id: ID to assign.\n\n    Raises:\n        ValueError: If ID is already present in the mapping.\n\n    Examples:\n        Add an additional ID to the mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; index_map.add_id(\"D\")\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n        D -&gt; 3\n    \"\"\"\n    if node_id not in self.id_to_idx:\n        idx = self.num_ids()\n        if isinstance(node_id, (list, tuple)):\n            node_id = to_numpy(node_id)\n            self.id_shape = (-1, *node_id.shape)\n        self.node_ids = (\n            np.concatenate((self.node_ids, to_numpy([node_id])))\n            if self.node_ids is not None\n            else to_numpy([node_id])\n        )\n        self.id_to_idx[node_id] = idx\n    else:\n        raise ValueError(\"ID already present in the mapping.\")\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.add_ids","title":"<code>add_ids</code>","text":"<p>Assigns additional IDs to next consecutive indices. The order of IDs is preserved.</p> <p>Parameters:</p> Name Type Description Default <code>node_ids</code> <code>list | numpy.ndarray</code> <p>IDs to assign</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If IDs are not unique or already present in the mapping.</p> <p>Examples:</p> <p>Add additional IDs to the mapping:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; index_map.add_ids([\"E\", \"D\"])\n&gt;&gt;&gt; print(index_map)\nA -&gt; 0\nB -&gt; 1\nC -&gt; 2\nE -&gt; 3\nD -&gt; 4\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def add_ids(self, node_ids: list | np.ndarray) -&gt; None:\n    \"\"\"Assigns additional IDs to next consecutive indices. The order of IDs is preserved.\n\n    Args:\n        node_ids: IDs to assign\n\n    Raises:\n        ValueError: If IDs are not unique or already present in the mapping.\n\n    Examples:\n        Add additional IDs to the mapping:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; index_map.add_ids([\"E\", \"D\"])\n        &gt;&gt;&gt; print(index_map)\n        A -&gt; 0\n        B -&gt; 1\n        C -&gt; 2\n        E -&gt; 3\n        D -&gt; 4\n    \"\"\"\n    cur_num_ids = self.num_ids()\n    if isinstance(node_ids, list) and isinstance(node_ids[0], (list, tuple)):\n        self.id_shape = (-1, *to_numpy(node_ids[0]).shape)\n\n    if not isinstance(node_ids, np.ndarray):\n        node_ids = to_numpy(node_ids)\n\n    all_ids = np.concatenate((self.node_ids, node_ids)) if self.node_ids is not None else node_ids\n    unique_ids = np.unique(all_ids, axis=0 if self.id_shape != (-1,) else None)\n\n    if len(unique_ids) != len(all_ids):\n        raise ValueError(\"IDs are not unique or already present in the mapping.\")\n\n    self.node_ids = all_ids\n    self.id_to_idx.update(\n        {tuple(v) if self.id_shape != (-1,) else v: i + cur_num_ids for i, v in enumerate(node_ids)}\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.num_ids","title":"<code>num_ids</code>","text":"<p>Return number of IDs. If mapping is not defined, return 0.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of IDs.</p> <p>Examples:</p> <p>Get number of IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.num_ids())\n0\n</code></pre> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.num_ids())\n3\n</code></pre> <pre><code>&gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n&gt;&gt;&gt; print(index_map.num_ids())\n3\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def num_ids(self) -&gt; int:\n    \"\"\"Return number of IDs. If mapping is not defined, return 0.\n\n    Returns:\n        Number of IDs.\n\n    Examples:\n        Get number of IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.num_ids())\n        0\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.num_ids())\n        3\n\n        &gt;&gt;&gt; index_map = IndexMap([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"C\")])\n        &gt;&gt;&gt; print(index_map.num_ids())\n        3\n    \"\"\"\n    if self.node_ids is None:\n        return 0\n    else:\n        return len(self.node_ids)\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_id","title":"<code>to_id</code>","text":"<p>Map index to ID if mapping is defined, return index otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>Index to map.</p> required <p>Returns:</p> Type Description <code>typing.Union[int, str, tuple]</code> <p>ID if mapping is defined, index otherwise.</p> <p>Examples:</p> <p>Map index to ID:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_id(1))\nB\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_id(1))\n1\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_id(self, idx: int) -&gt; Union[int, str, tuple]:\n    \"\"\"Map index to ID if mapping is defined, return index otherwise.\n\n    Args:\n        idx: Index to map.\n\n    Returns:\n        ID if mapping is defined, index otherwise.\n\n    Examples:\n        Map index to ID:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        B\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_id(1))\n        1\n    \"\"\"\n    if self.has_ids:\n        if self.id_shape == (-1,):\n            return self.node_ids[idx]  # type: ignore\n        else:\n            return tuple(self.node_ids[idx])  # type: ignore\n    else:\n        return idx\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_ids","title":"<code>to_ids</code>","text":"<p>Map list of indices to IDs if mapping is defined, return indices otherwise. The shape of the given index list will be preserved in the output.</p> <p>Parameters:</p> Name Type Description Default <code>idxs</code> <code>list | tuple | numpy.ndarray</code> <p>Indices to map.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>IDs if mapping is defined, indices otherwise.</p> <p>Examples:</p> <p>Map list of indices to IDs:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n['A' 'C']\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_ids(torch.tensor([0, 2])))\ntensor([0 2])\n</code></pre> <p>Map edge_index tensor to array of edges:</p> <pre><code>&gt;&gt;&gt; edge_index = torch.tensor([[0, 2, 2, 3], [1, 1, 3, 0]])\n&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\", \"D\"])\n&gt;&gt;&gt; print(index_map.to_ids(edge_index.T))\n[['A' 'B']\n ['C' 'B']\n ['C' 'D']\n ['D' 'A']]\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_ids(self, idxs: list | tuple | np.ndarray) -&gt; np.ndarray:\n    \"\"\"Map list of indices to IDs if mapping is defined, return indices otherwise. The shape of the given index\n    list will be preserved in the output.\n\n    Args:\n        idxs: Indices to map.\n\n    Returns:\n        IDs if mapping is defined, indices otherwise.\n\n    Examples:\n        Map list of indices to IDs:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_ids([0, 2]))\n        ['A' 'C']\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_ids(torch.tensor([0, 2])))\n        tensor([0 2])\n\n        Map edge_index tensor to array of edges:\n\n        &gt;&gt;&gt; edge_index = torch.tensor([[0, 2, 2, 3], [1, 1, 3, 0]])\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\", \"D\"])\n        &gt;&gt;&gt; print(index_map.to_ids(edge_index.T))\n        [['A' 'B']\n         ['C' 'B']\n         ['C' 'D']\n         ['D' 'A']]\n    \"\"\"\n    if self.has_ids:\n        if not isinstance(idxs, np.ndarray):\n            idxs = to_numpy(idxs)\n        return self.node_ids[idxs]  # type: ignore\n    else:\n        return idxs  # type: ignore\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_idx","title":"<code>to_idx</code>","text":"<p>Map argument (ID or index) to index if mapping is defined, return argument otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str | int | tuple[str] | tuple[int]</code> <p>ID or index to map.</p> required <p>Returns:</p> Type Description <code>int | tuple[int]</code> <p>Index if mapping is defined, argument otherwise.</p> <p>Examples:</p> <p>Map ID to index:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_idx(\"B\"))\n1\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_idx(1))\n1\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_idx(self, node: str | int | tuple[str] | tuple[int]) -&gt; int | tuple[int]:\n    \"\"\"Map argument (ID or index) to index if mapping is defined, return argument otherwise.\n\n    Args:\n        node: ID or index to map.\n\n    Returns:\n        Index if mapping is defined, argument otherwise.\n\n    Examples:\n        Map ID to index:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_idx(\"B\"))\n        1\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_idx(1))\n        1\n    \"\"\"\n    n: str | int | tuple[str] | tuple[int] = node\n    if self.has_ids:\n        if self.id_shape != (-1,):\n            n = tuple(n)\n        return self.id_to_idx[n]\n    else:\n        return n\n</code></pre>"},{"location":"reference/pathpyG/core/index_map/#pathpyG.core.index_map.IndexMap.to_idxs","title":"<code>to_idxs</code>","text":"<p>Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise. The shape of the given argument list will be preserved in the output.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list | tuple | numpy.ndarray</code> <p>IDs or indices to map.</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>Indices if mapping is defined, arguments otherwise.</p> <p>Examples:</p> <p>Map list of IDs to indices:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n&gt;&gt;&gt; print(index_map.to_idxs([\"B\", \"A\"]))\ntensor([1, 0])\n</code></pre> <p>No mapping defined:</p> <pre><code>&gt;&gt;&gt; index_map = IndexMap()\n&gt;&gt;&gt; print(index_map.to_idxs(torch.tensor([1, 0])))\ntensor([1, 0])\n</code></pre> <p>Map list of edges to edge_index tensor:</p> <pre><code>&gt;&gt;&gt; edges = [[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]\n&gt;&gt;&gt; index_map = IndexMap(np.unique(edges))\n&gt;&gt;&gt; print(index_map.to_idxs(edges).T)\ntensor([[0, 1, 2],\n        [1, 2, 3]])\n</code></pre> Source code in <code>src/pathpyG/core/index_map.py</code> <pre><code>def to_idxs(self, nodes: list | tuple | np.ndarray, device: Optional[torch.device] = None) -&gt; torch.Tensor:\n    \"\"\"Map list of arguments (IDs or indices) to indices if mapping is defined, return argument otherwise. The shape\n    of the given argument list will be preserved in the output.\n\n    Args:\n        nodes: IDs or indices to map.\n\n    Returns:\n        Indices if mapping is defined, arguments otherwise.\n\n    Examples:\n        Map list of IDs to indices:\n\n        &gt;&gt;&gt; index_map = IndexMap([\"A\", \"B\", \"C\"])\n        &gt;&gt;&gt; print(index_map.to_idxs([\"B\", \"A\"]))\n        tensor([1, 0])\n\n        No mapping defined:\n\n        &gt;&gt;&gt; index_map = IndexMap()\n        &gt;&gt;&gt; print(index_map.to_idxs(torch.tensor([1, 0])))\n        tensor([1, 0])\n\n        Map list of edges to edge_index tensor:\n\n        &gt;&gt;&gt; edges = [[\"A\", \"B\"], [\"B\", \"C\"], [\"C\", \"D\"]]\n        &gt;&gt;&gt; index_map = IndexMap(np.unique(edges))\n        &gt;&gt;&gt; print(index_map.to_idxs(edges).T)\n        tensor([[0, 1, 2],\n                [1, 2, 3]])\n    \"\"\"\n    if self.has_ids:\n        if not isinstance(nodes, np.ndarray):\n            nodes = to_numpy(nodes)\n\n        shape = nodes.shape\n        if self.id_shape == (-1,):\n            return torch.tensor([self.id_to_idx[node] for node in nodes.flatten()], device=device).reshape(shape)\n        else:\n            return torch.tensor([self.id_to_idx[tuple(node)] for node in nodes.reshape(self.id_shape)], device=device).reshape(\n                shape[: -len(self.id_shape) + 1]\n            )\n    else:\n        return torch.tensor(nodes, device=device)\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/","title":"multi_order_model","text":""},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel","title":"<code>MultiOrderModel</code>","text":"<p>MultiOrderModel based on torch_geometric.Data.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>class MultiOrderModel:\n    \"\"\"MultiOrderModel based on torch_geometric.Data.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.layers: dict[int, Graph] = {}\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the higher-order graph.\"\"\"\n        max_order = max(list(self.layers.keys())) if self.layers else 0\n        s = f\"MultiOrderModel with max. order {max_order}\"\n        return s\n\n    def to(self, device: torch.device) -&gt; MultiOrderModel:\n        \"\"\"Convert the graph layers to the given device.\n\n        Args:\n            device: The device to convert the graph layers to.\n\n        Returns: The MultiOrderModel with graph layers on the given device.\n        \"\"\"\n        for g in self.layers.values():\n            g.to(device)\n        return self\n\n    @staticmethod\n    def iterate_lift_order(\n        edge_index: torch.Tensor,\n        node_sequence: torch.Tensor,\n        mapping: IndexMap,\n        edge_weight: torch.Tensor | None = None,\n        aggr: str = \"src\",\n        save: bool = True,\n    ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n        \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n        This is a helper function that should not be called directly.\n        Only use for edge_indices after the special cases have been handled e.g.\n        in the from_temporal_graph (filtering non-time-respecting paths of order 2).\n\n        Args:\n            edge_index: The edge index of the (k-1)-th order graph.\n            node_sequence: The node sequences of the (k-1)-th order graph.\n            edge_weight: The edge weights of the (k-1)-th order graph.\n            k: The order of the graph that should be computed.\n            aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n            save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n        \"\"\"\n        # Lift order\n        if edge_weight is None:\n            ho_index = lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n        else:\n            ho_index, edge_weight = lift_order_edge_index_weighted(\n                edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n            )\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n        # Aggregate\n        if save:\n            gk = aggregate_edge_index(ho_index, node_sequence, edge_weight)\n            gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n        else:\n            gk = None\n        return ho_index, node_sequence, edge_weight, gk\n\n    @staticmethod\n    def from_temporal_graph(\n        g: TemporalGraph,\n        delta: float | int = 1,\n        max_order: int = 1,\n        weight: str = \"edge_weight\",\n        cached: bool = True,\n        event_graph: Optional[torch.Tensor] = None,\n    ) -&gt; MultiOrderModel:\n        \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\n\n        Args:\n            g: The temporal graph.\n            delta: The maximum time difference between two consecutive edges in a path.\n            max_order: The maximum order of the MultiOrderModel that should be computed.\n            weight: The edge attribute to use as edge weight.\n            cached: Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.\n            event_graph: precomputed event graph edge index for given delta to be used for model generation. Useful to prevent the same event graph\n            from being computed twice.\n\n        Returns:\n            MultiOrderModel: A multi-order model where each layer is a De Bruijn graph with order k.\n        \"\"\"\n        m = MultiOrderModel()\n        if not g.data.is_sorted_by_time():\n            data = g.data.sort_by_time()\n        else:\n            data = g.data\n        edge_index = data.edge_index\n        node_sequence = torch.arange(data.num_nodes, device=edge_index.device).unsqueeze(1)\n        if weight in data:\n            edge_weight = data[weight]\n        else:\n            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n        if cached or max_order == 1:\n            m.layers[1] = aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[1].mapping = g.mapping\n\n        if max_order &gt; 1:\n            node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n            if event_graph is None:\n                edge_index = lift_order_temporal(g, delta)\n            else:\n                edge_index = event_graph\n            edge_weight = aggregate_node_attributes(edge_index, edge_weight, \"src\")\n\n            # Aggregate\n            if cached or max_order == 2:\n                m.layers[2] = aggregate_edge_index(\n                    edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n                )\n                m.layers[2].mapping = IndexMap(\n                    [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n                )\n\n            for k in range(3, max_order + 1):\n                edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                    edge_index=edge_index,\n                    node_sequence=node_sequence,\n                    mapping=g.mapping,\n                    edge_weight=edge_weight,\n                    aggr=\"src\",\n                    save=cached or k == max_order,\n                )\n                if cached or k == max_order:\n                    m.layers[k] = gk\n        return m\n\n    @staticmethod\n    def from_path_data(\n        path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n    ) -&gt; MultiOrderModel:\n        \"\"\"\n        Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n        Args:\n            path_data: `PathData` object containing paths as list of PyG Data objects\n                with sorted edge indices, node sequences and num_nodes.\n            max_order: The maximum order of the MultiOrderModel that should be computed\n            mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n            cached: Whether to save the aggregated higher-order graphs smaller than max order\n                in the MultiOrderModel.\n\n        Returns:\n            MultiOrderModel: The MultiOrderModel.\n        \"\"\"\n        m = MultiOrderModel()\n\n        # We assume that paths are sorted\n        path_graph = path_data.data\n        edge_index = path_graph.edge_index\n        node_sequence = path_graph.node_sequence\n        edge_weight = path_graph.dag_weight.repeat_interleave(path_graph.dag_num_edges)\n        if mode == \"diffusion\":\n            edge_weight = (\n                edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n            )\n            aggr = \"mul\"\n        elif mode == \"propagation\":\n            aggr = \"src\"\n\n        m.layers[1] = aggregate_edge_index(edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight)\n        m.layers[1].mapping = path_data.mapping\n\n        for k in range(2, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=m.layers[1].mapping,\n                edge_weight=edge_weight,\n                aggr=aggr,\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n\n        return m\n\n    def get_mon_dof(self, max_order: Optional[int] = None, assumption: str = \"paths\") -&gt; int:\n        \"\"\"\n        The degrees of freedom for the kth layer of a multi-order model. This depends on the number of different paths of exactly length `k` in the graph.\n        Therefore, we can obtain these values by summing the entries of the `k`-th power of the binary adjacency matrix of the graph.\n        Finally, we must consider that, due the conservation of probablility, all non-zero rows of the transition matrix of the higher-order network must sum to one.\n        This poses one additional constraint per row that respects the condition, which should be removed from the total count of degrees of freedom.\n\n        Args:\n            m (MultiOrderModel): The multi-order model.\n            max_order (int, optional): The maximum order up to which model layers\n                shall be taken into account. Defaults to None, meaning it considers\n                all available layers.\n            assumption (str, optional): If set to 'paths', only paths in the\n                first-order network topology will be considered for the degree of\n                freedom calculation. If set to 'ngrams', all possible n-grams will\n                be considered, independent of whether they are valid paths in the\n                first-order network or not. Defaults to 'paths'.\n\n        Returns:\n            int: The degrees of freedom for the multi-order model.\n\n        Raises:\n            ValueError: If max_order is larger than the maximum order of\n                the multi-order network.\n            ValueError: If the assumption is not 'paths' or 'ngrams'.\n        \"\"\"\n        if max_order is None:\n            max_order = max(self.layers)\n\n        if max_order &gt; max(self.layers):\n            logger.error(\"max_order cannot be larger than maximum order of multi-order network\")\n            raise ValueError(\"max_order cannot be larger than maximum order of multi-order network\")\n\n\n        dof = self.layers[1].data.num_nodes - 1  # Degrees of freedom for zeroth order\n\n        if assumption == \"paths\":\n            # COMPUTING CONTRIBUTION FROM NUM PATHS AND NONZERO OUTDEGREES SEPARATELY\n            # TODO: CAN IT BE DONE TOGETHER?\n\n            edge_index = self.layers[1].data.edge_index\n            # Adding dof from Number of paths of length k\n            for k in range(1, max_order + 1):\n                if k &gt; 1:\n                    num_nodes = 0 if edge_index.numel() == 0 else edge_index.max().item() + 1\n                    edge_index = lift_order_edge_index(edge_index, num_nodes)\n                # counting number of len k paths\n                num_len_k_paths = edge_index.shape[1]  # edge_index.max().item() +1  # Number of paths of length k\n                dof += num_len_k_paths\n\n            # removing dof from total probability of nonzero degree nodes\n            for k in range(1, max_order + 1):\n                if k == 1:\n                    # edge_index of temporal graph is sorted by time by default\n                    # For matrix multiplication, we need to sort it by row\n                    edge_index_adj = self.layers[1].data.edge_index.sort_by(\"row\")[0]\n                    edge_index = edge_index_adj\n                else:\n                    edge_index, _ = edge_index.matmul(edge_index_adj)\n                num_nonzero_outdegrees = torch.unique(edge_index[0]).size(0)\n                dof -= num_nonzero_outdegrees\n\n        elif assumption == \"ngrams\":\n            for order in range(1, max_order + 1):\n                dof += (self.layers[1].data.num_nodes**order) * (self.layers[1].data.num_nodes - 1)\n        else:\n            logger.error(\"Unknown assumption %s. Only 'path' and 'ngram' are accepted.\", assumption)\n            raise ValueError(\n                f\"Unknown assumption {assumption}. Only 'path' and 'ngram' are accepted.\"\n            )\n\n        return int(dof)\n\n    def get_zeroth_order_log_likelihood(self, dag_graph: Data) -&gt; float:\n        \"\"\"\n        Compute the zeroth order log likelihood.\n\n        Args:\n            dag_graph (Data): Input DAG graph data.\n\n        Returns:\n            float: Zeroth order log likelihood.\n        \"\"\"\n        # Get frequencies\n        # getting the index of the last edge of each path (to be used to extract weights)\n        frequencies = dag_graph.dag_weight\n\n        # Get ixs starting nodes\n        # Q: Is dag_graph.path_index[:-1] enough to get the start_ixs?\n        mask = torch.ones(dag_graph.num_nodes, dtype=bool)\n        mask[dag_graph.edge_index[1]] = False\n        start_ixs = dag_graph.node_sequence.squeeze()[mask]\n\n        # Compute node emission probabilities\n        # TODOL modify once we have zeroth order in mon\n        _, counts = torch.unique(dag_graph.node_sequence, return_counts=True)\n        # WARNING: Only works if all nodes in the first-order graph are also in `node_sequence`\n        # Otherwise the missing nodes will not be included in `counts` which can lead to elements at the wrong index.\n        node_emission_probabilities = counts / counts.sum()\n        return torch.mul(frequencies, torch.log(node_emission_probabilities[start_ixs])).sum().item()\n\n    def get_intermediate_order_log_likelihood(self, dag_graph: Data, order: int) -&gt; float:\n        \"\"\"\n        Compute the intermediate order log likelihood.\n\n        Args:\n            m (MultiOrderModel): Multi-order model.\n            dag_graph (Data): Input DAG graph data.\n            order (int): Order of the intermediate log likelihood.\n\n        Returns:\n            float: Intermediate order log likelihood.\n        \"\"\"\n        # Get frequencies\n        frequencies = dag_graph.dag_weight\n        path_lengths = dag_graph.dag_num_nodes\n        # paths shrink by 'order' if we encode them using higher-order nodes\n        paths_lenghts_ho = path_lengths - order\n        # selecting only path that didn t shrink to zero due to higher-order transformation\n        paths_lenghts_ho_filtered = paths_lenghts_ho[paths_lenghts_ho &gt; 0]\n        frequencies = frequencies[paths_lenghts_ho &gt; 0]\n        # start index of the path in the higher order space\n        ixs_start_paths_ho = cumsum(paths_lenghts_ho_filtered)[:-1]\n\n        transition_probabilities = self.layers[order].transition_probabilities()[\n            self.layers[order + 1].data.inverse_idx[ixs_start_paths_ho]\n        ]\n\n        log_transition_probabilities = torch.log(transition_probabilities)\n        llh_by_subpath = torch.mul(frequencies, log_transition_probabilities)\n        return llh_by_subpath.sum().item()\n\n    def get_mon_log_likelihood(self, dag_graph: Data, max_order: int = 1) -&gt; float:\n        \"\"\"\n        Compute the likelihood of the walks given a multi-order model.\n\n        Args:\n            m (MultiOrderModel): The multi-order model.\n            dag_graph (Data): Dataset containing the walks.\n            max_order (int, optional): The maximum order up to which model layers\n                shall be taken into account. Defaults to 1.\n\n        Returns:\n            float: The log likelihood of the walks given the multi-order model.\n        \"\"\"\n        llh = 0\n\n        # Adding likelihood of zeroth order\n        llh += self.get_zeroth_order_log_likelihood(dag_graph)\n\n        # Adding the likelihood for all the intermediate orders\n        for order in range(1, max_order):\n            llh += self.get_intermediate_order_log_likelihood(dag_graph, order)\n\n        # Adding the likelihood of highest/stationary order\n        if max_order &gt; 0:\n            transition_probabilities = self.layers[max_order].transition_probabilities(edge_attr=\"edge_weight\")\n            log_transition_probabilities = torch.log(transition_probabilities)\n            llh_by_subpath = log_transition_probabilities * self.layers[max_order].data.edge_weight\n            llh += llh_by_subpath.sum().item()\n        else:\n            # Compute likelihood for zeroth order (to be modified)\n            # TODO: modify once we have zeroth order in mon\n            # (then won t need to compute emission probs from dag_graph -- which also hinders us from computing the lh that a new set of paths was generated by the model)\n            frequencies = dag_graph.dag_weight\n            counts = torch.bincount(\n                dag_graph.node_sequence.squeeze(), frequencies.repeat_interleave(dag_graph.dag_num_nodes)\n            )\n            node_emission_probabilities = counts / counts.sum()\n            llh = torch.mul(torch.log(node_emission_probabilities), counts).sum().item()\n\n        return llh\n\n    def likelihood_ratio_test(\n        self,\n        dag_graph: Data,\n        max_order_null: int = 0,\n        max_order: int = 1,\n        assumption: str = \"paths\",\n        significance_threshold: float = 0.01,\n    ) -&gt; tuple:\n        \"\"\"\n        Perform a likelihood ratio test to compare two models of different order.\n\n        Args:\n            dag_graph (Data): The input DAG graph data.\n            max_order_null (int, optional): The maximum order of the null hypothesis model.\n                Defaults to 0.\n            max_order (int, optional): The maximum order of the alternative hypothesis model.\n                Defaults to 1.\n            assumption (str, optional): The assumption to use for the degrees of freedom calculation.\n                Can be 'paths' or 'ngrams'. Defaults to 'paths'.\n            significance_threshold (float, optional): The significance threshold for the test.\n                Defaults to 0.01.\n\n        Returns:\n            tuple: A tuple containing a boolean indicating whether the null hypothesis is rejected\n                and the p-value of the test.\n        \"\"\"\n        if max_order_null &gt;= max_order:\n            logger.error(\"order of null hypothesis must be smaller than order of alternative hypothesis\")\n            raise ValueError(\"order of null hypothesis must be smaller than order of alternative hypothesis\")\n        if max_order &gt; max(self.layers):\n            logger.error(\"order of hypotheses must be smaller than max. order of MultiOrderModel\")\n            raise ValueError(f\"order of hypotheses ({max_order_null} and {max_order}) must be smaller than max. order of MultiOrderModel {max(self.layers)}\")\n        # let L0 be the likelihood for the null model and L1 be the likelihood for the alternative model\n\n        # we first compute a test statistic x = -2 * log (L0/L1) = -2 * (log L0 - log L1)\n        x = -2 * (\n            self.get_mon_log_likelihood(dag_graph, max_order=max_order_null)\n            - self.get_mon_log_likelihood(dag_graph, max_order=max_order)\n        )\n\n        # we calculate the additional degrees of freedom in the alternative model\n        dof_diff = self.get_mon_dof(max_order, assumption=assumption) - self.get_mon_dof(\n            max_order_null, assumption=assumption\n        )\n\n        # if the p-value is *below* the significance threshold, we reject the null hypothesis\n        p = 1 - chi2.cdf(x, dof_diff)\n        return (p &lt; significance_threshold), p\n\n    def estimate_order(self, dag_data: PathData, max_order: Optional[int] = None, significance_threshold: float = 0.01) -&gt; int:\n        \"\"\"\n        Selects the optimal maximum order of a multi-order network model for the\n        observed paths, based on a likelihood ratio test with p-value threshold of p\n        By default, all orders up to the maximum order of the multi-order model will be tested.\n\n        Args:\n            dag_data (DAGData): The path statistics data for which to estimate the optimal order.\n            max_order (int, optional): The maximum order to consider during the estimation process.\n                If not provided, the maximum order of the multi-order model is used.\n            significance_threshold (float, optional): The p-value threshold for the likelihood ratio test.\n                An order is accepted if the improvement in likelihood is significant at this threshold.\n\n        Returns:\n            int: The estimated optimal maximum order for the multi-order network model.\n\n        Raises:\n            ValueError: If the provided max_order is larger than the maximum order of the multi-order model\n                or if the input DAGData does not have the same set of nodes as the multi-order network\n        \"\"\"\n        if max_order is None:\n            max_order = max(self.layers)\n        if max_order &gt; max(self.layers):\n            logger.error(\"max_order cannot be larger than maximum order of multi-order network\")\n            raise ValueError(\"max_order cannot be larger than maximum order of multi-order network\")\n        if max_order &lt;= 1:\n            logger.error(\"max_order must be larger than one\")\n            raise ValueError(\"max_order must be larger than one\")\n        if set(dag_data.mapping.node_ids).intersection(set(self.layers[1].mapping.node_ids)) != set(dag_data.mapping.node_ids):\n            logger.error(\"Input paths do not have same set of nodes as multi-order network\")\n            raise ValueError(\"Input paths do not have same set of nodes as multi-order network\")        \n\n        max_accepted_order = 1\n        dag_graph = dag_data.data\n\n        # Test for highest order that passes\n        # likelihood ratio test against null model\n        for k in range(2, max_order + 1):\n            if self.likelihood_ratio_test(\n                dag_graph, max_order_null=k - 1, max_order=k, significance_threshold=significance_threshold\n            )[0]:\n                max_accepted_order = k\n\n        return max_accepted_order\n\n    def to_dbgnn_data(self, max_order: int = 2, mapping: str = \"last\") -&gt; Data:\n        \"\"\"\n        Convert the MultiOrderModel to a De Bruijn graph for the given maximum order\n        that can be used in `pathpyG.nn.dbgnn.DBGNN`.\n\n        Args:\n            max_order: The maximum order of the De Bruijn graph to be computed.\n            mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n\n        Returns:\n            Data: The De Bruijn graph data.\n        \"\"\"\n        if max_order not in self.layers:\n            logger.error(\"Higher-order graph of specified order not found.\")\n            raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n        g = self.layers[1]\n        g_max_order = self.layers[max_order]\n        num_nodes = g.data.num_nodes\n        num_ho_nodes = g_max_order.data.num_nodes\n        if g.data.x is not None:\n            x = g.data.x\n        else:\n            x = torch.eye(num_nodes, num_nodes, device=g.data.edge_index.device)\n        x_max_order = torch.eye(num_ho_nodes, num_ho_nodes, device=g_max_order.data.edge_index.device)\n        edge_index = g.data.edge_index\n        edge_index_max_order = g_max_order.data.edge_index\n        edge_weight = g.data.edge_weight\n        edge_weight_max_order = g_max_order.data.edge_weight\n        bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping, device=edge_index.device)\n\n        if g.data.y is not None:\n            y = g.data.y\n\n        return Data(\n            num_nodes=num_nodes,\n            num_ho_nodes=num_ho_nodes,\n            x=x,\n            x_h=x_max_order,\n            edge_index=edge_index,\n            edge_index_higher_order=edge_index_max_order,\n            edge_weights=edge_weight.float(),\n            edge_weights_higher_order=edge_weight_max_order.float(),\n            bipartite_edge_index=bipartite_edge_index,\n            y=y if \"y\" in locals() else None,\n        )\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the higher-order graph.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the higher-order graph.\"\"\"\n    max_order = max(list(self.layers.keys())) if self.layers else 0\n    s = f\"MultiOrderModel with max. order {max_order}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.estimate_order","title":"<code>estimate_order</code>","text":"<p>Selects the optimal maximum order of a multi-order network model for the observed paths, based on a likelihood ratio test with p-value threshold of p By default, all orders up to the maximum order of the multi-order model will be tested.</p> <p>Parameters:</p> Name Type Description Default <code>dag_data</code> <code>DAGData</code> <p>The path statistics data for which to estimate the optimal order.</p> required <code>max_order</code> <code>int</code> <p>The maximum order to consider during the estimation process. If not provided, the maximum order of the multi-order model is used.</p> <code>None</code> <code>significance_threshold</code> <code>float</code> <p>The p-value threshold for the likelihood ratio test. An order is accepted if the improvement in likelihood is significant at this threshold.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The estimated optimal maximum order for the multi-order network model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided max_order is larger than the maximum order of the multi-order model or if the input DAGData does not have the same set of nodes as the multi-order network</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def estimate_order(self, dag_data: PathData, max_order: Optional[int] = None, significance_threshold: float = 0.01) -&gt; int:\n    \"\"\"\n    Selects the optimal maximum order of a multi-order network model for the\n    observed paths, based on a likelihood ratio test with p-value threshold of p\n    By default, all orders up to the maximum order of the multi-order model will be tested.\n\n    Args:\n        dag_data (DAGData): The path statistics data for which to estimate the optimal order.\n        max_order (int, optional): The maximum order to consider during the estimation process.\n            If not provided, the maximum order of the multi-order model is used.\n        significance_threshold (float, optional): The p-value threshold for the likelihood ratio test.\n            An order is accepted if the improvement in likelihood is significant at this threshold.\n\n    Returns:\n        int: The estimated optimal maximum order for the multi-order network model.\n\n    Raises:\n        ValueError: If the provided max_order is larger than the maximum order of the multi-order model\n            or if the input DAGData does not have the same set of nodes as the multi-order network\n    \"\"\"\n    if max_order is None:\n        max_order = max(self.layers)\n    if max_order &gt; max(self.layers):\n        logger.error(\"max_order cannot be larger than maximum order of multi-order network\")\n        raise ValueError(\"max_order cannot be larger than maximum order of multi-order network\")\n    if max_order &lt;= 1:\n        logger.error(\"max_order must be larger than one\")\n        raise ValueError(\"max_order must be larger than one\")\n    if set(dag_data.mapping.node_ids).intersection(set(self.layers[1].mapping.node_ids)) != set(dag_data.mapping.node_ids):\n        logger.error(\"Input paths do not have same set of nodes as multi-order network\")\n        raise ValueError(\"Input paths do not have same set of nodes as multi-order network\")        \n\n    max_accepted_order = 1\n    dag_graph = dag_data.data\n\n    # Test for highest order that passes\n    # likelihood ratio test against null model\n    for k in range(2, max_order + 1):\n        if self.likelihood_ratio_test(\n            dag_graph, max_order_null=k - 1, max_order=k, significance_threshold=significance_threshold\n        )[0]:\n            max_accepted_order = k\n\n    return max_accepted_order\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.from_path_data","title":"<code>from_path_data</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graphs modelling paths in PathData.</p> <p>Parameters:</p> Name Type Description Default <code>path_data</code> <code>pathpyG.core.path_data.PathData</code> <p><code>PathData</code> object containing paths as list of PyG Data objects with sorted edge indices, node sequences and num_nodes.</p> required <code>max_order</code> <code>int</code> <p>The maximum order of the MultiOrderModel that should be computed</p> <code>1</code> <code>mode</code> <code>str</code> <p>The process that we assume. Can be \"diffusion\" or \"propagation\".</p> <code>'propagation'</code> <code>cached</code> <code>bool</code> <p>Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>MultiOrderModel</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The MultiOrderModel.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>@staticmethod\ndef from_path_data(\n    path_data: PathData, max_order: int = 1, mode: str = \"propagation\", cached: bool = True\n) -&gt; MultiOrderModel:\n    \"\"\"\n    Creates multiple higher-order De Bruijn graphs modelling paths in PathData.\n\n    Args:\n        path_data: `PathData` object containing paths as list of PyG Data objects\n            with sorted edge indices, node sequences and num_nodes.\n        max_order: The maximum order of the MultiOrderModel that should be computed\n        mode: The process that we assume. Can be \"diffusion\" or \"propagation\".\n        cached: Whether to save the aggregated higher-order graphs smaller than max order\n            in the MultiOrderModel.\n\n    Returns:\n        MultiOrderModel: The MultiOrderModel.\n    \"\"\"\n    m = MultiOrderModel()\n\n    # We assume that paths are sorted\n    path_graph = path_data.data\n    edge_index = path_graph.edge_index\n    node_sequence = path_graph.node_sequence\n    edge_weight = path_graph.dag_weight.repeat_interleave(path_graph.dag_num_edges)\n    if mode == \"diffusion\":\n        edge_weight = (\n            edge_weight / degree(edge_index[0], dtype=torch.long, num_nodes=node_sequence.size(0))[edge_index[0]]\n        )\n        aggr = \"mul\"\n    elif mode == \"propagation\":\n        aggr = \"src\"\n\n    m.layers[1] = aggregate_edge_index(edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight)\n    m.layers[1].mapping = path_data.mapping\n\n    for k in range(2, max_order + 1):\n        edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n            edge_index=edge_index,\n            node_sequence=node_sequence,\n            mapping=m.layers[1].mapping,\n            edge_weight=edge_weight,\n            aggr=aggr,\n            save=cached or k == max_order,\n        )\n        if cached or k == max_order:\n            m.layers[k] = gk\n\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.from_temporal_graph","title":"<code>from_temporal_graph</code>  <code>staticmethod</code>","text":"<p>Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>The temporal graph.</p> required <code>delta</code> <code>float | int</code> <p>The maximum time difference between two consecutive edges in a path.</p> <code>1</code> <code>max_order</code> <code>int</code> <p>The maximum order of the MultiOrderModel that should be computed.</p> <code>1</code> <code>weight</code> <code>str</code> <p>The edge attribute to use as edge weight.</p> <code>'edge_weight'</code> <code>cached</code> <code>bool</code> <p>Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.</p> <code>True</code> <code>event_graph</code> <code>typing.Optional[torch.Tensor]</code> <p>precomputed event graph edge index for given delta to be used for model generation. Useful to prevent the same event graph</p> <code>None</code> <p>Returns:</p> Name Type Description <code>MultiOrderModel</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>A multi-order model where each layer is a De Bruijn graph with order k.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>@staticmethod\ndef from_temporal_graph(\n    g: TemporalGraph,\n    delta: float | int = 1,\n    max_order: int = 1,\n    weight: str = \"edge_weight\",\n    cached: bool = True,\n    event_graph: Optional[torch.Tensor] = None,\n) -&gt; MultiOrderModel:\n    \"\"\"Creates multiple higher-order De Bruijn graph models for paths in a temporal graph.\n\n    Args:\n        g: The temporal graph.\n        delta: The maximum time difference between two consecutive edges in a path.\n        max_order: The maximum order of the MultiOrderModel that should be computed.\n        weight: The edge attribute to use as edge weight.\n        cached: Whether to save the aggregated higher-order graphs smaller than max order in the MultiOrderModel.\n        event_graph: precomputed event graph edge index for given delta to be used for model generation. Useful to prevent the same event graph\n        from being computed twice.\n\n    Returns:\n        MultiOrderModel: A multi-order model where each layer is a De Bruijn graph with order k.\n    \"\"\"\n    m = MultiOrderModel()\n    if not g.data.is_sorted_by_time():\n        data = g.data.sort_by_time()\n    else:\n        data = g.data\n    edge_index = data.edge_index\n    node_sequence = torch.arange(data.num_nodes, device=edge_index.device).unsqueeze(1)\n    if weight in data:\n        edge_weight = data[weight]\n    else:\n        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n    if cached or max_order == 1:\n        m.layers[1] = aggregate_edge_index(\n            edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n        )\n        m.layers[1].mapping = g.mapping\n\n    if max_order &gt; 1:\n        node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n        if event_graph is None:\n            edge_index = lift_order_temporal(g, delta)\n        else:\n            edge_index = event_graph\n        edge_weight = aggregate_node_attributes(edge_index, edge_weight, \"src\")\n\n        # Aggregate\n        if cached or max_order == 2:\n            m.layers[2] = aggregate_edge_index(\n                edge_index=edge_index, node_sequence=node_sequence, edge_weight=edge_weight\n            )\n            m.layers[2].mapping = IndexMap(\n                [tuple(g.mapping.to_ids(v.cpu())) for v in m.layers[2].data.node_sequence]\n            )\n\n        for k in range(3, max_order + 1):\n            edge_index, node_sequence, edge_weight, gk = MultiOrderModel.iterate_lift_order(\n                edge_index=edge_index,\n                node_sequence=node_sequence,\n                mapping=g.mapping,\n                edge_weight=edge_weight,\n                aggr=\"src\",\n                save=cached or k == max_order,\n            )\n            if cached or k == max_order:\n                m.layers[k] = gk\n    return m\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_intermediate_order_log_likelihood","title":"<code>get_intermediate_order_log_likelihood</code>","text":"<p>Compute the intermediate order log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>Multi-order model.</p> required <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>Input DAG graph data.</p> required <code>order</code> <code>int</code> <p>Order of the intermediate log likelihood.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Intermediate order log likelihood.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_intermediate_order_log_likelihood(self, dag_graph: Data, order: int) -&gt; float:\n    \"\"\"\n    Compute the intermediate order log likelihood.\n\n    Args:\n        m (MultiOrderModel): Multi-order model.\n        dag_graph (Data): Input DAG graph data.\n        order (int): Order of the intermediate log likelihood.\n\n    Returns:\n        float: Intermediate order log likelihood.\n    \"\"\"\n    # Get frequencies\n    frequencies = dag_graph.dag_weight\n    path_lengths = dag_graph.dag_num_nodes\n    # paths shrink by 'order' if we encode them using higher-order nodes\n    paths_lenghts_ho = path_lengths - order\n    # selecting only path that didn t shrink to zero due to higher-order transformation\n    paths_lenghts_ho_filtered = paths_lenghts_ho[paths_lenghts_ho &gt; 0]\n    frequencies = frequencies[paths_lenghts_ho &gt; 0]\n    # start index of the path in the higher order space\n    ixs_start_paths_ho = cumsum(paths_lenghts_ho_filtered)[:-1]\n\n    transition_probabilities = self.layers[order].transition_probabilities()[\n        self.layers[order + 1].data.inverse_idx[ixs_start_paths_ho]\n    ]\n\n    log_transition_probabilities = torch.log(transition_probabilities)\n    llh_by_subpath = torch.mul(frequencies, log_transition_probabilities)\n    return llh_by_subpath.sum().item()\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_mon_dof","title":"<code>get_mon_dof</code>","text":"<p>The degrees of freedom for the kth layer of a multi-order model. This depends on the number of different paths of exactly length <code>k</code> in the graph. Therefore, we can obtain these values by summing the entries of the <code>k</code>-th power of the binary adjacency matrix of the graph. Finally, we must consider that, due the conservation of probablility, all non-zero rows of the transition matrix of the higher-order network must sum to one. This poses one additional constraint per row that respects the condition, which should be removed from the total count of degrees of freedom.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The multi-order model.</p> required <code>max_order</code> <code>int</code> <p>The maximum order up to which model layers shall be taken into account. Defaults to None, meaning it considers all available layers.</p> <code>None</code> <code>assumption</code> <code>str</code> <p>If set to 'paths', only paths in the first-order network topology will be considered for the degree of freedom calculation. If set to 'ngrams', all possible n-grams will be considered, independent of whether they are valid paths in the first-order network or not. Defaults to 'paths'.</p> <code>'paths'</code> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The degrees of freedom for the multi-order model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If max_order is larger than the maximum order of the multi-order network.</p> <code>ValueError</code> <p>If the assumption is not 'paths' or 'ngrams'.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_mon_dof(self, max_order: Optional[int] = None, assumption: str = \"paths\") -&gt; int:\n    \"\"\"\n    The degrees of freedom for the kth layer of a multi-order model. This depends on the number of different paths of exactly length `k` in the graph.\n    Therefore, we can obtain these values by summing the entries of the `k`-th power of the binary adjacency matrix of the graph.\n    Finally, we must consider that, due the conservation of probablility, all non-zero rows of the transition matrix of the higher-order network must sum to one.\n    This poses one additional constraint per row that respects the condition, which should be removed from the total count of degrees of freedom.\n\n    Args:\n        m (MultiOrderModel): The multi-order model.\n        max_order (int, optional): The maximum order up to which model layers\n            shall be taken into account. Defaults to None, meaning it considers\n            all available layers.\n        assumption (str, optional): If set to 'paths', only paths in the\n            first-order network topology will be considered for the degree of\n            freedom calculation. If set to 'ngrams', all possible n-grams will\n            be considered, independent of whether they are valid paths in the\n            first-order network or not. Defaults to 'paths'.\n\n    Returns:\n        int: The degrees of freedom for the multi-order model.\n\n    Raises:\n        ValueError: If max_order is larger than the maximum order of\n            the multi-order network.\n        ValueError: If the assumption is not 'paths' or 'ngrams'.\n    \"\"\"\n    if max_order is None:\n        max_order = max(self.layers)\n\n    if max_order &gt; max(self.layers):\n        logger.error(\"max_order cannot be larger than maximum order of multi-order network\")\n        raise ValueError(\"max_order cannot be larger than maximum order of multi-order network\")\n\n\n    dof = self.layers[1].data.num_nodes - 1  # Degrees of freedom for zeroth order\n\n    if assumption == \"paths\":\n        # COMPUTING CONTRIBUTION FROM NUM PATHS AND NONZERO OUTDEGREES SEPARATELY\n        # TODO: CAN IT BE DONE TOGETHER?\n\n        edge_index = self.layers[1].data.edge_index\n        # Adding dof from Number of paths of length k\n        for k in range(1, max_order + 1):\n            if k &gt; 1:\n                num_nodes = 0 if edge_index.numel() == 0 else edge_index.max().item() + 1\n                edge_index = lift_order_edge_index(edge_index, num_nodes)\n            # counting number of len k paths\n            num_len_k_paths = edge_index.shape[1]  # edge_index.max().item() +1  # Number of paths of length k\n            dof += num_len_k_paths\n\n        # removing dof from total probability of nonzero degree nodes\n        for k in range(1, max_order + 1):\n            if k == 1:\n                # edge_index of temporal graph is sorted by time by default\n                # For matrix multiplication, we need to sort it by row\n                edge_index_adj = self.layers[1].data.edge_index.sort_by(\"row\")[0]\n                edge_index = edge_index_adj\n            else:\n                edge_index, _ = edge_index.matmul(edge_index_adj)\n            num_nonzero_outdegrees = torch.unique(edge_index[0]).size(0)\n            dof -= num_nonzero_outdegrees\n\n    elif assumption == \"ngrams\":\n        for order in range(1, max_order + 1):\n            dof += (self.layers[1].data.num_nodes**order) * (self.layers[1].data.num_nodes - 1)\n    else:\n        logger.error(\"Unknown assumption %s. Only 'path' and 'ngram' are accepted.\", assumption)\n        raise ValueError(\n            f\"Unknown assumption {assumption}. Only 'path' and 'ngram' are accepted.\"\n        )\n\n    return int(dof)\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_mon_log_likelihood","title":"<code>get_mon_log_likelihood</code>","text":"<p>Compute the likelihood of the walks given a multi-order model.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>pathpyG.core.multi_order_model.MultiOrderModel</code> <p>The multi-order model.</p> required <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>Dataset containing the walks.</p> required <code>max_order</code> <code>int</code> <p>The maximum order up to which model layers shall be taken into account. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The log likelihood of the walks given the multi-order model.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_mon_log_likelihood(self, dag_graph: Data, max_order: int = 1) -&gt; float:\n    \"\"\"\n    Compute the likelihood of the walks given a multi-order model.\n\n    Args:\n        m (MultiOrderModel): The multi-order model.\n        dag_graph (Data): Dataset containing the walks.\n        max_order (int, optional): The maximum order up to which model layers\n            shall be taken into account. Defaults to 1.\n\n    Returns:\n        float: The log likelihood of the walks given the multi-order model.\n    \"\"\"\n    llh = 0\n\n    # Adding likelihood of zeroth order\n    llh += self.get_zeroth_order_log_likelihood(dag_graph)\n\n    # Adding the likelihood for all the intermediate orders\n    for order in range(1, max_order):\n        llh += self.get_intermediate_order_log_likelihood(dag_graph, order)\n\n    # Adding the likelihood of highest/stationary order\n    if max_order &gt; 0:\n        transition_probabilities = self.layers[max_order].transition_probabilities(edge_attr=\"edge_weight\")\n        log_transition_probabilities = torch.log(transition_probabilities)\n        llh_by_subpath = log_transition_probabilities * self.layers[max_order].data.edge_weight\n        llh += llh_by_subpath.sum().item()\n    else:\n        # Compute likelihood for zeroth order (to be modified)\n        # TODO: modify once we have zeroth order in mon\n        # (then won t need to compute emission probs from dag_graph -- which also hinders us from computing the lh that a new set of paths was generated by the model)\n        frequencies = dag_graph.dag_weight\n        counts = torch.bincount(\n            dag_graph.node_sequence.squeeze(), frequencies.repeat_interleave(dag_graph.dag_num_nodes)\n        )\n        node_emission_probabilities = counts / counts.sum()\n        llh = torch.mul(torch.log(node_emission_probabilities), counts).sum().item()\n\n    return llh\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.get_zeroth_order_log_likelihood","title":"<code>get_zeroth_order_log_likelihood</code>","text":"<p>Compute the zeroth order log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>Input DAG graph data.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Zeroth order log likelihood.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def get_zeroth_order_log_likelihood(self, dag_graph: Data) -&gt; float:\n    \"\"\"\n    Compute the zeroth order log likelihood.\n\n    Args:\n        dag_graph (Data): Input DAG graph data.\n\n    Returns:\n        float: Zeroth order log likelihood.\n    \"\"\"\n    # Get frequencies\n    # getting the index of the last edge of each path (to be used to extract weights)\n    frequencies = dag_graph.dag_weight\n\n    # Get ixs starting nodes\n    # Q: Is dag_graph.path_index[:-1] enough to get the start_ixs?\n    mask = torch.ones(dag_graph.num_nodes, dtype=bool)\n    mask[dag_graph.edge_index[1]] = False\n    start_ixs = dag_graph.node_sequence.squeeze()[mask]\n\n    # Compute node emission probabilities\n    # TODOL modify once we have zeroth order in mon\n    _, counts = torch.unique(dag_graph.node_sequence, return_counts=True)\n    # WARNING: Only works if all nodes in the first-order graph are also in `node_sequence`\n    # Otherwise the missing nodes will not be included in `counts` which can lead to elements at the wrong index.\n    node_emission_probabilities = counts / counts.sum()\n    return torch.mul(frequencies, torch.log(node_emission_probabilities[start_ixs])).sum().item()\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.iterate_lift_order","title":"<code>iterate_lift_order</code>  <code>staticmethod</code>","text":"<p>Lift order by one and save the result in the layers dictionary of the object. This is a helper function that should not be called directly. Only use for edge_indices after the special cases have been handled e.g. in the from_temporal_graph (filtering non-time-respecting paths of order 2).</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>The edge index of the (k-1)-th order graph.</p> required <code>node_sequence</code> <code>torch.Tensor</code> <p>The node sequences of the (k-1)-th order graph.</p> required <code>edge_weight</code> <code>torch.Tensor | None</code> <p>The edge weights of the (k-1)-th order graph.</p> <code>None</code> <code>k</code> <p>The order of the graph that should be computed.</p> required <code>aggr</code> <code>str</code> <p>The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".</p> <code>'src'</code> <code>save</code> <code>bool</code> <p>Whether to compute the aggregated graph and later save it in the layers dictionary.</p> <code>True</code> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>@staticmethod\ndef iterate_lift_order(\n    edge_index: torch.Tensor,\n    node_sequence: torch.Tensor,\n    mapping: IndexMap,\n    edge_weight: torch.Tensor | None = None,\n    aggr: str = \"src\",\n    save: bool = True,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor | None, Graph | None]:\n    \"\"\"Lift order by one and save the result in the layers dictionary of the object.\n    This is a helper function that should not be called directly.\n    Only use for edge_indices after the special cases have been handled e.g.\n    in the from_temporal_graph (filtering non-time-respecting paths of order 2).\n\n    Args:\n        edge_index: The edge index of the (k-1)-th order graph.\n        node_sequence: The node sequences of the (k-1)-th order graph.\n        edge_weight: The edge weights of the (k-1)-th order graph.\n        k: The order of the graph that should be computed.\n        aggr: The aggregation method to use. One of \"src\", \"dst\", \"max\", \"mul\".\n        save: Whether to compute the aggregated graph and later save it in the layers dictionary.\n    \"\"\"\n    # Lift order\n    if edge_weight is None:\n        ho_index = lift_order_edge_index(edge_index, num_nodes=node_sequence.size(0))\n    else:\n        ho_index, edge_weight = lift_order_edge_index_weighted(\n            edge_index, edge_weight=edge_weight, num_nodes=node_sequence.size(0), aggr=aggr\n        )\n    node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n\n    # Aggregate\n    if save:\n        gk = aggregate_edge_index(ho_index, node_sequence, edge_weight)\n        gk.mapping = IndexMap([tuple(mapping.to_ids(v.cpu())) for v in gk.data.node_sequence])\n    else:\n        gk = None\n    return ho_index, node_sequence, edge_weight, gk\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.likelihood_ratio_test","title":"<code>likelihood_ratio_test</code>","text":"<p>Perform a likelihood ratio test to compare two models of different order.</p> <p>Parameters:</p> Name Type Description Default <code>dag_graph</code> <code>torch_geometric.data.Data</code> <p>The input DAG graph data.</p> required <code>max_order_null</code> <code>int</code> <p>The maximum order of the null hypothesis model. Defaults to 0.</p> <code>0</code> <code>max_order</code> <code>int</code> <p>The maximum order of the alternative hypothesis model. Defaults to 1.</p> <code>1</code> <code>assumption</code> <code>str</code> <p>The assumption to use for the degrees of freedom calculation. Can be 'paths' or 'ngrams'. Defaults to 'paths'.</p> <code>'paths'</code> <code>significance_threshold</code> <code>float</code> <p>The significance threshold for the test. Defaults to 0.01.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>A tuple containing a boolean indicating whether the null hypothesis is rejected and the p-value of the test.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def likelihood_ratio_test(\n    self,\n    dag_graph: Data,\n    max_order_null: int = 0,\n    max_order: int = 1,\n    assumption: str = \"paths\",\n    significance_threshold: float = 0.01,\n) -&gt; tuple:\n    \"\"\"\n    Perform a likelihood ratio test to compare two models of different order.\n\n    Args:\n        dag_graph (Data): The input DAG graph data.\n        max_order_null (int, optional): The maximum order of the null hypothesis model.\n            Defaults to 0.\n        max_order (int, optional): The maximum order of the alternative hypothesis model.\n            Defaults to 1.\n        assumption (str, optional): The assumption to use for the degrees of freedom calculation.\n            Can be 'paths' or 'ngrams'. Defaults to 'paths'.\n        significance_threshold (float, optional): The significance threshold for the test.\n            Defaults to 0.01.\n\n    Returns:\n        tuple: A tuple containing a boolean indicating whether the null hypothesis is rejected\n            and the p-value of the test.\n    \"\"\"\n    if max_order_null &gt;= max_order:\n        logger.error(\"order of null hypothesis must be smaller than order of alternative hypothesis\")\n        raise ValueError(\"order of null hypothesis must be smaller than order of alternative hypothesis\")\n    if max_order &gt; max(self.layers):\n        logger.error(\"order of hypotheses must be smaller than max. order of MultiOrderModel\")\n        raise ValueError(f\"order of hypotheses ({max_order_null} and {max_order}) must be smaller than max. order of MultiOrderModel {max(self.layers)}\")\n    # let L0 be the likelihood for the null model and L1 be the likelihood for the alternative model\n\n    # we first compute a test statistic x = -2 * log (L0/L1) = -2 * (log L0 - log L1)\n    x = -2 * (\n        self.get_mon_log_likelihood(dag_graph, max_order=max_order_null)\n        - self.get_mon_log_likelihood(dag_graph, max_order=max_order)\n    )\n\n    # we calculate the additional degrees of freedom in the alternative model\n    dof_diff = self.get_mon_dof(max_order, assumption=assumption) - self.get_mon_dof(\n        max_order_null, assumption=assumption\n    )\n\n    # if the p-value is *below* the significance threshold, we reject the null hypothesis\n    p = 1 - chi2.cdf(x, dof_diff)\n    return (p &lt; significance_threshold), p\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.to","title":"<code>to</code>","text":"<p>Convert the graph layers to the given device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>The device to convert the graph layers to.</p> required <p>Returns: The MultiOrderModel with graph layers on the given device.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def to(self, device: torch.device) -&gt; MultiOrderModel:\n    \"\"\"Convert the graph layers to the given device.\n\n    Args:\n        device: The device to convert the graph layers to.\n\n    Returns: The MultiOrderModel with graph layers on the given device.\n    \"\"\"\n    for g in self.layers.values():\n        g.to(device)\n    return self\n</code></pre>"},{"location":"reference/pathpyG/core/multi_order_model/#pathpyG.core.multi_order_model.MultiOrderModel.to_dbgnn_data","title":"<code>to_dbgnn_data</code>","text":"<p>Convert the MultiOrderModel to a De Bruijn graph for the given maximum order that can be used in <code>pathpyG.nn.dbgnn.DBGNN</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_order</code> <code>int</code> <p>The maximum order of the De Bruijn graph to be computed.</p> <code>2</code> <code>mapping</code> <code>str</code> <p>The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".</p> <code>'last'</code> <p>Returns:</p> Name Type Description <code>Data</code> <code>torch_geometric.data.Data</code> <p>The De Bruijn graph data.</p> Source code in <code>src/pathpyG/core/multi_order_model.py</code> <pre><code>def to_dbgnn_data(self, max_order: int = 2, mapping: str = \"last\") -&gt; Data:\n    \"\"\"\n    Convert the MultiOrderModel to a De Bruijn graph for the given maximum order\n    that can be used in `pathpyG.nn.dbgnn.DBGNN`.\n\n    Args:\n        max_order: The maximum order of the De Bruijn graph to be computed.\n        mapping: The mapping to use for the bipartite edge index. One of \"last\", \"first\", or \"both\".\n\n    Returns:\n        Data: The De Bruijn graph data.\n    \"\"\"\n    if max_order not in self.layers:\n        logger.error(\"Higher-order graph of specified order not found.\")\n        raise ValueError(f\"Higher-order graph of order {max_order} not found.\")\n\n    g = self.layers[1]\n    g_max_order = self.layers[max_order]\n    num_nodes = g.data.num_nodes\n    num_ho_nodes = g_max_order.data.num_nodes\n    if g.data.x is not None:\n        x = g.data.x\n    else:\n        x = torch.eye(num_nodes, num_nodes, device=g.data.edge_index.device)\n    x_max_order = torch.eye(num_ho_nodes, num_ho_nodes, device=g_max_order.data.edge_index.device)\n    edge_index = g.data.edge_index\n    edge_index_max_order = g_max_order.data.edge_index\n    edge_weight = g.data.edge_weight\n    edge_weight_max_order = g_max_order.data.edge_weight\n    bipartite_edge_index = generate_bipartite_edge_index(g, g_max_order, mapping=mapping, device=edge_index.device)\n\n    if g.data.y is not None:\n        y = g.data.y\n\n    return Data(\n        num_nodes=num_nodes,\n        num_ho_nodes=num_ho_nodes,\n        x=x,\n        x_h=x_max_order,\n        edge_index=edge_index,\n        edge_index_higher_order=edge_index_max_order,\n        edge_weights=edge_weight.float(),\n        edge_weights_higher_order=edge_weight_max_order.float(),\n        bipartite_edge_index=bipartite_edge_index,\n        y=y if \"y\" in locals() else None,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/","title":"path_data","text":""},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData","title":"<code>PathData</code>","text":"<p>Class that can be used to store multiple observations of node sequences representing paths or walks</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; # Generate toy example graph\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'c'),\n&gt;&gt;&gt;                      ('b', 'c'),\n&gt;&gt;&gt;                      ('c', 'd'),\n&gt;&gt;&gt;                      ('c', 'e')])\n&gt;&gt;&gt; # Store observations of walks using the index mapping\n&gt;&gt;&gt; # from the graph above\n&gt;&gt;&gt; paths = pp.PathData(g.mapping)\n&gt;&gt;&gt; paths.append_walk(('a', 'c', 'd'), weight=2.0)\n&gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=2.0)\n&gt;&gt;&gt; print(paths)\nPathData with 2 paths with total weight 4.0\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>class PathData:\n    \"\"\"Class that can be used to store multiple observations of\n    node sequences representing paths or walks\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; # Generate toy example graph\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'c'),\n        &gt;&gt;&gt;                      ('b', 'c'),\n        &gt;&gt;&gt;                      ('c', 'd'),\n        &gt;&gt;&gt;                      ('c', 'e')])\n        &gt;&gt;&gt; # Store observations of walks using the index mapping\n        &gt;&gt;&gt; # from the graph above\n        &gt;&gt;&gt; paths = pp.PathData(g.mapping)\n        &gt;&gt;&gt; paths.append_walk(('a', 'c', 'd'), weight=2.0)\n        &gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=2.0)\n        &gt;&gt;&gt; print(paths)\n        PathData with 2 paths with total weight 4.0\n    \"\"\"\n\n    def __init__(self, mapping: IndexMap | None = None, device: torch.device | None = None) -&gt; None:\n        if mapping:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n        self.data: Data = Data(\n            edge_index=torch.empty((2, 0), dtype=torch.long, device=device),\n            node_sequence=torch.empty((0, 1), dtype=torch.long, device=device),\n            dag_weight=torch.empty(0, dtype=torch.float, device=device),\n            dag_num_edges=torch.empty(0, dtype=torch.long, device=device),\n            dag_num_nodes=torch.empty(0, dtype=torch.long, device=device),\n        )\n        self.data.num_nodes = 0\n\n    @property\n    def num_paths(self) -&gt; int:\n        \"\"\"Return the number of stored paths.\"\"\"\n        return len(self.data.dag_num_edges)\n\n    def _append_data(\n        self,\n        edge_index: torch.Tensor,\n        node_sequence: torch.Tensor,\n        weights: torch.Tensor,\n        num_edges: torch.Tensor,\n        num_nodes: torch.Tensor,\n    ) -&gt; None:\n        \"\"\"\n        Append a edge_index and node_sequence to the PathData object and\n        reassign the indices so that there is no overlap.\n\n        Args:\n            edge_index: Edge index of the new path(s)\n            node_sequence: Node sequence of the new path(s)\n            weights: Weights of the new path(s)\n            num_edges: Number of edges in the new path(s)\n            num_nodes: Number of nodes in the new path(s)\n        \"\"\"\n        new_edge_index = edge_index + self.data.num_nodes\n        self.data.edge_index = torch.cat([self.data.edge_index, new_edge_index], dim=1)\n        self.data.node_sequence = torch.cat([self.data.node_sequence, node_sequence])\n        self.data.dag_weight = torch.cat([self.data.dag_weight, weights])\n        self.data.dag_num_edges = torch.cat([self.data.dag_num_edges, num_edges])\n        self.data.dag_num_nodes = torch.cat([self.data.dag_num_nodes, num_nodes])\n        self.data.num_nodes += num_nodes.sum().item()\n\n    def to(self, device: torch.device) -&gt; PathData:\n        \"\"\"Moves all paths to the given device.\"\"\"\n        self.data = self.data.to(device)\n        return self\n\n    def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n        \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n        Args:\n            node_seq: List or tuple of node IDs\n            weight: Weight of the walk\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n            &gt;&gt;&gt; walks = pp.PathData(mapping)\n            &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n            &gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=1.0)\n        \"\"\"\n        idx_seq = self.mapping.to_idxs(node_seq, device=self.data.edge_index.device).unsqueeze(1)\n        idx = torch.arange(len(node_seq), device=self.data.edge_index.device)\n        edge_index = torch.stack([idx[:-1], idx[1:]])\n\n        self._append_data(\n            edge_index=edge_index,\n            node_sequence=idx_seq,\n            weights=torch.tensor([weight], device=self.data.edge_index.device),\n            num_edges=torch.tensor([edge_index.shape[1]], device=self.data.edge_index.device),\n            num_nodes=torch.tensor([len(node_seq)], device=self.data.edge_index.device),\n        )\n\n    def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n        \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\n\n        Args:\n            node_seqs: List or tuple of lists or tuples of node IDs\n            weights: List or tuple of weights for each walk\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n            &gt;&gt;&gt; walks = pp.PathData(mapping)\n            &gt;&gt;&gt; walks.append_walks([['a', 'c', 'd'], ['b', 'c', 'e']], [2.0, 1.0])\n        \"\"\"\n        idx_seqs = torch.cat([self.mapping.to_idxs(seq, device=self.data.edge_index.device) for seq in node_seqs]).unsqueeze(1)\n        dag_num_nodes = torch.tensor([len(seq) for seq in node_seqs], device=self.data.edge_index.device)\n\n        big_idx = torch.arange(dag_num_nodes.sum(), device=self.data.edge_index.device)\n        big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n\n        # remove the edges that connect different walks\n        mask = torch.ones(big_edge_index.size(1), dtype=torch.bool, device=self.data.edge_index.device)\n        cum_sum = cumsum(dag_num_nodes, 0)\n        mask[cum_sum[1:-1] - 1] = False\n        big_edge_index = big_edge_index[:, mask]\n\n        self._append_data(\n            edge_index=big_edge_index,\n            node_sequence=idx_seqs,\n            weights=torch.tensor(weights, device=self.data.edge_index.device),\n            num_edges=dag_num_nodes - 1,\n            num_nodes=dag_num_nodes,\n        )\n\n    def get_walk(self, i: int) -&gt; tuple:\n        \"\"\"Return the i-th walk (based on when it was appended) as a tuple of node IDs\n\n        Args:\n            i: Index of the walk to retrieve\n\n        Returns:\n            Tuple of node IDs representing the i-th walk\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n            &gt;&gt;&gt; walks = pp.PathData(mapping)\n            &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n            &gt;&gt;&gt; walks.get_walk(0)\n            ('a', 'c', 'd')\n        \"\"\"\n        start = self.data.dag_num_nodes[:i].sum().item()\n        end = start + self.data.dag_num_nodes[i].item()\n        return tuple(self.mapping.to_ids(self.data.node_sequence[start:end].squeeze()))\n\n    def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n        \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n        return self.mapping.to_ids(node_seq).tolist()\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the PathData object.\"\"\"\n        weight = self.data.dag_weight.sum().item()\n        s = f\"PathData with {self.num_paths} paths with total weight {weight}\"\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.num_paths","title":"<code>num_paths</code>  <code>property</code>","text":"<p>Return the number of stored paths.</p>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the PathData object.</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the PathData object.\"\"\"\n    weight = self.data.dag_weight.sum().item()\n    s = f\"PathData with {self.num_paths} paths with total weight {weight}\"\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.append_walk","title":"<code>append_walk</code>","text":"<p>Add an observation of a walk based on a list or tuple of node IDs or indices</p> <p>Parameters:</p> Name Type Description Default <code>node_seq</code> <code>list | tuple</code> <p>List or tuple of node IDs</p> required <code>weight</code> <code>float</code> <p>Weight of the walk</p> <code>1.0</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n&gt;&gt;&gt; walks = pp.PathData(mapping)\n&gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n&gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=1.0)\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def append_walk(self, node_seq: list | tuple, weight: float = 1.0) -&gt; None:\n    \"\"\"Add an observation of a walk based on a list or tuple of node IDs or indices\n\n    Args:\n        node_seq: List or tuple of node IDs\n        weight: Weight of the walk\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n        &gt;&gt;&gt; walks = pp.PathData(mapping)\n        &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n        &gt;&gt;&gt; paths.append_walk(('b', 'c', 'e'), weight=1.0)\n    \"\"\"\n    idx_seq = self.mapping.to_idxs(node_seq, device=self.data.edge_index.device).unsqueeze(1)\n    idx = torch.arange(len(node_seq), device=self.data.edge_index.device)\n    edge_index = torch.stack([idx[:-1], idx[1:]])\n\n    self._append_data(\n        edge_index=edge_index,\n        node_sequence=idx_seq,\n        weights=torch.tensor([weight], device=self.data.edge_index.device),\n        num_edges=torch.tensor([edge_index.shape[1]], device=self.data.edge_index.device),\n        num_nodes=torch.tensor([len(node_seq)], device=self.data.edge_index.device),\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.append_walks","title":"<code>append_walks</code>","text":"<p>Add multiple observations of walks based on lists or tuples of node IDs or indices</p> <p>Parameters:</p> Name Type Description Default <code>node_seqs</code> <code>list | tuple</code> <p>List or tuple of lists or tuples of node IDs</p> required <code>weights</code> <code>list | tuple</code> <p>List or tuple of weights for each walk</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n&gt;&gt;&gt; walks = pp.PathData(mapping)\n&gt;&gt;&gt; walks.append_walks([['a', 'c', 'd'], ['b', 'c', 'e']], [2.0, 1.0])\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def append_walks(self, node_seqs: list | tuple, weights: list | tuple) -&gt; None:\n    \"\"\"Add multiple observations of walks based on lists or tuples of node IDs or indices\n\n    Args:\n        node_seqs: List or tuple of lists or tuples of node IDs\n        weights: List or tuple of weights for each walk\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n        &gt;&gt;&gt; walks = pp.PathData(mapping)\n        &gt;&gt;&gt; walks.append_walks([['a', 'c', 'd'], ['b', 'c', 'e']], [2.0, 1.0])\n    \"\"\"\n    idx_seqs = torch.cat([self.mapping.to_idxs(seq, device=self.data.edge_index.device) for seq in node_seqs]).unsqueeze(1)\n    dag_num_nodes = torch.tensor([len(seq) for seq in node_seqs], device=self.data.edge_index.device)\n\n    big_idx = torch.arange(dag_num_nodes.sum(), device=self.data.edge_index.device)\n    big_edge_index = torch.stack([big_idx[:-1], big_idx[1:]])\n\n    # remove the edges that connect different walks\n    mask = torch.ones(big_edge_index.size(1), dtype=torch.bool, device=self.data.edge_index.device)\n    cum_sum = cumsum(dag_num_nodes, 0)\n    mask[cum_sum[1:-1] - 1] = False\n    big_edge_index = big_edge_index[:, mask]\n\n    self._append_data(\n        edge_index=big_edge_index,\n        node_sequence=idx_seqs,\n        weights=torch.tensor(weights, device=self.data.edge_index.device),\n        num_edges=dag_num_nodes - 1,\n        num_nodes=dag_num_nodes,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.get_walk","title":"<code>get_walk</code>","text":"<p>Return the i-th walk (based on when it was appended) as a tuple of node IDs</p> <p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>Index of the walk to retrieve</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple of node IDs representing the i-th walk</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n&gt;&gt;&gt; walks = pp.PathData(mapping)\n&gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n&gt;&gt;&gt; walks.get_walk(0)\n('a', 'c', 'd')\n</code></pre> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def get_walk(self, i: int) -&gt; tuple:\n    \"\"\"Return the i-th walk (based on when it was appended) as a tuple of node IDs\n\n    Args:\n        i: Index of the walk to retrieve\n\n    Returns:\n        Tuple of node IDs representing the i-th walk\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; mapping = pp.IndexMap(['a', 'b', 'c', 'd', 'e'])\n        &gt;&gt;&gt; walks = pp.PathData(mapping)\n        &gt;&gt;&gt; walks.append_walk(('a', 'c', 'd'), weight=2.0)\n        &gt;&gt;&gt; walks.get_walk(0)\n        ('a', 'c', 'd')\n    \"\"\"\n    start = self.data.dag_num_nodes[:i].sum().item()\n    end = start + self.data.dag_num_nodes[i].item()\n    return tuple(self.mapping.to_ids(self.data.node_sequence[start:end].squeeze()))\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.map_node_seq","title":"<code>map_node_seq</code>","text":"<p>Map a sequence of node indices (e.g. representing a higher-order node) to node IDs</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def map_node_seq(self, node_seq: list | tuple) -&gt; list:\n    \"\"\"Map a sequence of node indices (e.g. representing a higher-order node) to node IDs\"\"\"\n    return self.mapping.to_ids(node_seq).tolist()\n</code></pre>"},{"location":"reference/pathpyG/core/path_data/#pathpyG.core.path_data.PathData.to","title":"<code>to</code>","text":"<p>Moves all paths to the given device.</p> Source code in <code>src/pathpyG/core/path_data.py</code> <pre><code>def to(self, device: torch.device) -&gt; PathData:\n    \"\"\"Moves all paths to the given device.\"\"\"\n    self.data = self.data.to(device)\n    return self\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/","title":"temporal_graph","text":""},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph","title":"<code>TemporalGraph</code>","text":"<p>               Bases: <code>pathpyG.Graph</code></p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>class TemporalGraph(Graph):\n    def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n        \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n        Args:\n            data: PyG `Data` object containing edges saved in `edge_index` and timestamps in `time`.\n            mapping: Optional mapping from node IDs to indices.\n\n        Example:\n            ```py\n            from pytorch_geometric.data import TemporalData\n            import pathpyG as pp\n\n            d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n            t = pp.TemporalGraph(d, mapping)\n            print(t)\n            ```\n        \"\"\"\n        self.data = data\n        if not isinstance(self.data.edge_index, EdgeIndex):\n            self.data.edge_index = EdgeIndex(\n                data=self.data.edge_index.contiguous(), sparse_size=(self.data.num_nodes, self.data.num_nodes)\n            )\n\n        # reorder temporal data\n        # Note that we do not use `torch_geometric.self.data.Data.sort_by_time` because it cannot sort numpy arrays`\n        sorted_idx = torch.argsort(self.data.time)\n        for edge_attr in set(self.data.edge_attrs()).union(set([\"time\"])):\n            if edge_attr == \"edge_index\":\n                self.data.edge_index = self.data.edge_index[:, sorted_idx]\n            else:\n                self.data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        if mapping is not None:\n            self.mapping = mapping\n        else:\n            self.mapping = IndexMap()\n\n        # create mapping between edge index and edge tuples\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate(self.data.edge_index.t())\n        }\n        self.tedge_to_index = {\n            (e[0].item(), e[1].item(), t.item()): i for i, (e, t) in enumerate(zip([e for e in self.data.edge_index.t()], self.data.time))\n        }\n\n        if self.data.time.size(0) &gt; 0:\n            self.start_time = self.data.time[0].item()\n            self.end_time = self.data.time[-1].item()\n        else:\n            self.start_time = 0\n            self.end_time = 0\n\n    @staticmethod\n    def from_edge_list(edge_list, num_nodes: Optional[int] = None, device: Optional[torch.device] = None) -&gt; TemporalGraph:  # type: ignore\n        \"\"\"Create a temporal graph from a list of tuples containing edges with timestamps.\"\"\"\n        if len(edge_list) == 0:\n            return TemporalGraph(\n                data=Data(\n                    edge_index=torch.empty((2, 0), dtype=torch.long, device=device),\n                    time=torch.empty((0,), dtype=torch.long, device=device),\n                    num_nodes=num_nodes,\n                ),\n            )\n\n        edge_array = np.array(edge_list)\n\n        # Convert timestamps to tensor\n        if isinstance(edge_list[0][2], int):\n            ts = torch.tensor(edge_array[:, 2].astype(np.int_), device=device)\n        else:\n            ts = torch.tensor(edge_array[:, 2].astype(np.double), device=device)\n\n        index_map = IndexMap(np.unique(edge_array[:, :2]))\n        edge_index = index_map.to_idxs(edge_array[:, :2].T, device=device)\n\n        if not num_nodes:\n            num_nodes = index_map.num_ids()\n\n        return TemporalGraph(\n            data=Data(\n                edge_index=edge_index,\n                time=ts,\n                num_nodes=num_nodes,\n            ),\n            mapping=index_map,\n        )\n\n    @property\n    def temporal_edges(self) -&gt; list:\n        \"\"\"Return all temporal edges as a list of tuples (source, destination, timestamp).\n\n        Returns:\n            list: A list of tuples representing temporal edges in the format (source, destination, timestamp).\n\n        Examples:\n            Get the list of temporal edges:\n\n            &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            &gt;&gt;&gt; print(g.temporal_edges)\n            [('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)]\n\n            Iterate over temporal edges:\n            &gt;&gt;&gt; for edge in g.temporal_edges:\n            &gt;&gt;&gt;     print(edge)\n            ('a', 'b', 1)\n            ('b', 'c', 2)\n            ('c', 'a', 3)\n        \"\"\"\n        edge_ids = self.mapping.to_ids(self.data.edge_index)\n        times = to_numpy(self.data.time)\n        return list(zip(edge_ids[0], edge_ids[1], times))\n\n    def to(self, device: torch.device) -&gt; TemporalGraph:\n        \"\"\"Moves all graph data to the specified device (CPU or GPU).\n\n        Args:\n            device: The target device to move the graph data to.\n\n        Returns:\n            TemporalGraph: A new TemporalGraph instance with data on the specified device.\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.time = self.data.time.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        return self\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"Return order 1, since all temporal graphs must be order one.\"\"\"\n        return 1\n\n    def shuffle_time(self) -&gt; None:\n        \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n        self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n\n    def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n        \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n        Args:\n            weighted: whether or not to return a weighted time-aggregated graph\n            time_window: A tuple with start and end time of the aggregation window\n\n        Returns:\n            Graph: A static graph object\n        \"\"\"\n        if time_window is not None:\n            idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n            edge_index = self.data.edge_index[:, idx]\n        else:\n            edge_index = self.data.edge_index\n\n        n = edge_index.max().item() + 1\n\n        if weighted:\n            i, w = torch_geometric.utils.coalesce(\n                edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n            )\n            return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n        else:\n            return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n\n    def to_undirected(self) -&gt; TemporalGraph:\n        \"\"\"Return an undirected version of a directed graph.\n\n        This method transforms the current graph instance into an undirected graph by\n        adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n        transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n        duplicates edge attributes for newly created directed edges.\n\n        Example:\n            ```py\n            import pathpyG as pp\n            g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            g_u = g.to_undirected()\n            print(g_u)\n            ```\n        \"\"\"\n        rev_edge_index = self.data.edge_index.flip([0])\n        edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n        times = torch.cat([self.data.time, self.data.time])\n        return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n\n    def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n        \"\"\"Return a batch of temporal edges based on start and end indices.\n\n        Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given batch defined by start and (non-inclusive) end, where start\n        and end refer to the index of the first and last event in the time-ordered list of events.\n\n        Args:\n            start_idx: The starting index of the batch (inclusive).\n            end_idx: The ending index of the batch (exclusive).\n\n        Examples:\n            Get a batch of temporal edges:\n\n            &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            &gt;&gt;&gt; batch = g.get_batch(0, 2)\n            &gt;&gt;&gt; print(batch.temporal_edges)\n            [('a', 'b', 1), ('b', 'c', 2)]\n        \"\"\"\n        # Create new Data object with the selected batch of edges and times\n        data = Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx])\n\n        # Copy all node attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        # Copy only edge attributes for the selected batch\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][start_idx:end_idx]\n\n        return TemporalGraph(\n            data=data,\n            mapping=self.mapping,\n        )\n\n    def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n        \"\"\"Return a time window of temporal edges based on start and end timestamps.\n\n        Return an instance of the TemporalGraph that captures all time-stamped\n        edges in a given time window defined by start and (non-inclusive) end, where start\n        and end refer to the time stamps.\n\n        Args:\n            start_time: The starting timestamp of the window (inclusive).\n            end_time: The ending timestamp of the window (exclusive).\n\n        Examples:\n            Get a time window of temporal edges:\n\n            &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n            &gt;&gt;&gt; window = g.get_window(0, 2)\n            &gt;&gt;&gt; print(window.temporal_edges)\n            [('a', 'b', 1)]\n        \"\"\"\n        # While there is a PyG function `Data.snapshot`,\n        # we do it manually since it cannot handle numpy arrays as edge attributes.\n        edge_mask = (self.data.time &gt;= start_time).logical_and(self.data.time &lt; end_time)\n        # Create a new Data object with the selected edges and times\n        data = Data(\n            edge_index=self.data.edge_index[:, edge_mask],\n            time=self.data.time[edge_mask],\n        )\n        # Copy all node attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        # Copy only edge attributes for the selected edges\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][edge_mask]\n\n        return TemporalGraph(data=data, mapping=self.mapping)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, temporal edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            # TODO: Get item for non-temporal edges will only return the last occurence of the edge\n            #       This is a limitation and should be fixed in the future.\n            if len(key) == 3:\n                return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n            else:\n                return self.data[key[0]][self.tedge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2]), key[3]]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Return a string representation of the graph\n        \"\"\"\n        s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n            self.data.num_nodes,\n            self.data.edge_index.unique(dim=1).size(dim=1),\n            self.data.edge_index.size(1),\n            self.start_time,\n            self.end_time,\n        )\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order 1, since all temporal graphs must be order one.</p>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.temporal_edges","title":"<code>temporal_edges</code>  <code>property</code>","text":"<p>Return all temporal edges as a list of tuples (source, destination, timestamp).</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of tuples representing temporal edges in the format (source, destination, timestamp).</p> <p>Examples:</p> <p>Get the list of temporal edges:</p> <pre><code>&gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n&gt;&gt;&gt; print(g.temporal_edges)\n[('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)]\n</code></pre> <p>Iterate over temporal edges:</p> <pre><code>&gt;&gt;&gt; for edge in g.temporal_edges:\n&gt;&gt;&gt;     print(edge)\n('a', 'b', 1)\n('b', 'c', 2)\n('c', 'a', 3)\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, temporal edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, temporal edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        # TODO: Get item for non-temporal edges will only return the last occurence of the edge\n        #       This is a limitation and should be fixed in the future.\n        if len(key) == 3:\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            return self.data[key[0]][self.tedge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2]), key[3]]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.__init__","title":"<code>__init__</code>","text":"<p>Creates an instance of a temporal graph from a <code>TemporalData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>PyG <code>Data</code> object containing edges saved in <code>edge_index</code> and timestamps in <code>time</code>.</p> required <code>mapping</code> <code>pathpyG.core.index_map.IndexMap | None</code> <p>Optional mapping from node IDs to indices.</p> <code>None</code> Example <pre><code>from pytorch_geometric.data import TemporalData\nimport pathpyG as pp\n\nd = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\nt = pp.TemporalGraph(d, mapping)\nprint(t)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __init__(self, data: Data, mapping: IndexMap | None = None) -&gt; None:\n    \"\"\"Creates an instance of a temporal graph from a `TemporalData` object.\n\n    Args:\n        data: PyG `Data` object containing edges saved in `edge_index` and timestamps in `time`.\n        mapping: Optional mapping from node IDs to indices.\n\n    Example:\n        ```py\n        from pytorch_geometric.data import TemporalData\n        import pathpyG as pp\n\n        d = Data(edge_index=[[0,0,1], [1,2,2]], time=[0,1,2])\n        t = pp.TemporalGraph(d, mapping)\n        print(t)\n        ```\n    \"\"\"\n    self.data = data\n    if not isinstance(self.data.edge_index, EdgeIndex):\n        self.data.edge_index = EdgeIndex(\n            data=self.data.edge_index.contiguous(), sparse_size=(self.data.num_nodes, self.data.num_nodes)\n        )\n\n    # reorder temporal data\n    # Note that we do not use `torch_geometric.self.data.Data.sort_by_time` because it cannot sort numpy arrays`\n    sorted_idx = torch.argsort(self.data.time)\n    for edge_attr in set(self.data.edge_attrs()).union(set([\"time\"])):\n        if edge_attr == \"edge_index\":\n            self.data.edge_index = self.data.edge_index[:, sorted_idx]\n        else:\n            self.data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    if mapping is not None:\n        self.mapping = mapping\n    else:\n        self.mapping = IndexMap()\n\n    # create mapping between edge index and edge tuples\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate(self.data.edge_index.t())\n    }\n    self.tedge_to_index = {\n        (e[0].item(), e[1].item(), t.item()): i for i, (e, t) in enumerate(zip([e for e in self.data.edge_index.t()], self.data.time))\n    }\n\n    if self.data.time.size(0) &gt; 0:\n        self.start_time = self.data.time[0].item()\n        self.end_time = self.data.time[-1].item()\n    else:\n        self.start_time = 0\n        self.end_time = 0\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Return a string representation of the graph\n    \"\"\"\n    s = \"Temporal Graph with {0} nodes, {1} unique edges and {2} events in [{3}, {4}]\\n\".format(\n        self.data.num_nodes,\n        self.data.edge_index.unique(dim=1).size(dim=1),\n        self.data.edge_index.size(1),\n        self.start_time,\n        self.end_time,\n    )\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Create a temporal graph from a list of tuples containing edges with timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(edge_list, num_nodes: Optional[int] = None, device: Optional[torch.device] = None) -&gt; TemporalGraph:  # type: ignore\n    \"\"\"Create a temporal graph from a list of tuples containing edges with timestamps.\"\"\"\n    if len(edge_list) == 0:\n        return TemporalGraph(\n            data=Data(\n                edge_index=torch.empty((2, 0), dtype=torch.long, device=device),\n                time=torch.empty((0,), dtype=torch.long, device=device),\n                num_nodes=num_nodes,\n            ),\n        )\n\n    edge_array = np.array(edge_list)\n\n    # Convert timestamps to tensor\n    if isinstance(edge_list[0][2], int):\n        ts = torch.tensor(edge_array[:, 2].astype(np.int_), device=device)\n    else:\n        ts = torch.tensor(edge_array[:, 2].astype(np.double), device=device)\n\n    index_map = IndexMap(np.unique(edge_array[:, :2]))\n    edge_index = index_map.to_idxs(edge_array[:, :2].T, device=device)\n\n    if not num_nodes:\n        num_nodes = index_map.num_ids()\n\n    return TemporalGraph(\n        data=Data(\n            edge_index=edge_index,\n            time=ts,\n            num_nodes=num_nodes,\n        ),\n        mapping=index_map,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.get_batch","title":"<code>get_batch</code>","text":"<p>Return a batch of temporal edges based on start and end indices.</p> <p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given batch defined by start and (non-inclusive) end, where start and end refer to the index of the first and last event in the time-ordered list of events.</p> <p>Parameters:</p> Name Type Description Default <code>start_idx</code> <code>int</code> <p>The starting index of the batch (inclusive).</p> required <code>end_idx</code> <code>int</code> <p>The ending index of the batch (exclusive).</p> required <p>Examples:</p> <p>Get a batch of temporal edges:</p> <pre><code>&gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n&gt;&gt;&gt; batch = g.get_batch(0, 2)\n&gt;&gt;&gt; print(batch.temporal_edges)\n[('a', 'b', 1), ('b', 'c', 2)]\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_batch(self, start_idx: int, end_idx: int) -&gt; TemporalGraph:\n    \"\"\"Return a batch of temporal edges based on start and end indices.\n\n    Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given batch defined by start and (non-inclusive) end, where start\n    and end refer to the index of the first and last event in the time-ordered list of events.\n\n    Args:\n        start_idx: The starting index of the batch (inclusive).\n        end_idx: The ending index of the batch (exclusive).\n\n    Examples:\n        Get a batch of temporal edges:\n\n        &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        &gt;&gt;&gt; batch = g.get_batch(0, 2)\n        &gt;&gt;&gt; print(batch.temporal_edges)\n        [('a', 'b', 1), ('b', 'c', 2)]\n    \"\"\"\n    # Create new Data object with the selected batch of edges and times\n    data = Data(edge_index=self.data.edge_index[:, start_idx:end_idx], time=self.data.time[start_idx:end_idx])\n\n    # Copy all node attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    # Copy only edge attributes for the selected batch\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][start_idx:end_idx]\n\n    return TemporalGraph(\n        data=data,\n        mapping=self.mapping,\n    )\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.get_window","title":"<code>get_window</code>","text":"<p>Return a time window of temporal edges based on start and end timestamps.</p> <p>Return an instance of the TemporalGraph that captures all time-stamped edges in a given time window defined by start and (non-inclusive) end, where start and end refer to the time stamps.</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>int</code> <p>The starting timestamp of the window (inclusive).</p> required <code>end_time</code> <code>int</code> <p>The ending timestamp of the window (exclusive).</p> required <p>Examples:</p> <p>Get a time window of temporal edges:</p> <pre><code>&gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n&gt;&gt;&gt; window = g.get_window(0, 2)\n&gt;&gt;&gt; print(window.temporal_edges)\n[('a', 'b', 1)]\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def get_window(self, start_time: int, end_time: int) -&gt; TemporalGraph:\n    \"\"\"Return a time window of temporal edges based on start and end timestamps.\n\n    Return an instance of the TemporalGraph that captures all time-stamped\n    edges in a given time window defined by start and (non-inclusive) end, where start\n    and end refer to the time stamps.\n\n    Args:\n        start_time: The starting timestamp of the window (inclusive).\n        end_time: The ending timestamp of the window (exclusive).\n\n    Examples:\n        Get a time window of temporal edges:\n\n        &gt;&gt;&gt; g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        &gt;&gt;&gt; window = g.get_window(0, 2)\n        &gt;&gt;&gt; print(window.temporal_edges)\n        [('a', 'b', 1)]\n    \"\"\"\n    # While there is a PyG function `Data.snapshot`,\n    # we do it manually since it cannot handle numpy arrays as edge attributes.\n    edge_mask = (self.data.time &gt;= start_time).logical_and(self.data.time &lt; end_time)\n    # Create a new Data object with the selected edges and times\n    data = Data(\n        edge_index=self.data.edge_index[:, edge_mask],\n        time=self.data.time[edge_mask],\n    )\n    # Copy all node attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    # Copy only edge attributes for the selected edges\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][edge_mask]\n\n    return TemporalGraph(data=data, mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.shuffle_time","title":"<code>shuffle_time</code>","text":"<p>Randomly shuffle the temporal order of edges by randomly permuting timestamps.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def shuffle_time(self) -&gt; None:\n    \"\"\"Randomly shuffle the temporal order of edges by randomly permuting timestamps.\"\"\"\n    self.data.time = self.data.time[torch.randperm(len(self.data.time))]\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.to","title":"<code>to</code>","text":"<p>Moves all graph data to the specified device (CPU or GPU).</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>The target device to move the graph data to.</p> required <p>Returns:</p> Name Type Description <code>TemporalGraph</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>A new TemporalGraph instance with data on the specified device.</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; TemporalGraph:\n    \"\"\"Moves all graph data to the specified device (CPU or GPU).\n\n    Args:\n        device: The target device to move the graph data to.\n\n    Returns:\n        TemporalGraph: A new TemporalGraph instance with data on the specified device.\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.time = self.data.time.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    return self\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.to_static_graph","title":"<code>to_static_graph</code>","text":"<p>Return weighted time-aggregated instance of <code>Graph</code> graph.</p> <p>Parameters:</p> Name Type Description Default <code>weighted</code> <code>bool</code> <p>whether or not to return a weighted time-aggregated graph</p> <code>False</code> <code>time_window</code> <code>typing.Optional[typing.Tuple[int, int]]</code> <p>A tuple with start and end time of the aggregation window</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.Graph</code> <p>A static graph object</p> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_static_graph(self, weighted: bool = False, time_window: Optional[Tuple[int, int]] = None) -&gt; Graph:\n    \"\"\"Return weighted time-aggregated instance of [`Graph`][pathpyG.Graph] graph.\n\n    Args:\n        weighted: whether or not to return a weighted time-aggregated graph\n        time_window: A tuple with start and end time of the aggregation window\n\n    Returns:\n        Graph: A static graph object\n    \"\"\"\n    if time_window is not None:\n        idx = (self.data.time &gt;= time_window[0]).logical_and(self.data.time &lt; time_window[1]).nonzero().ravel()\n        edge_index = self.data.edge_index[:, idx]\n    else:\n        edge_index = self.data.edge_index\n\n    n = edge_index.max().item() + 1\n\n    if weighted:\n        i, w = torch_geometric.utils.coalesce(\n            edge_index.as_tensor(), torch.ones(edge_index.size(1), device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=EdgeIndex(data=i, sparse_size=(n, n)), edge_weight=w), self.mapping)\n    else:\n        return Graph.from_edge_index(EdgeIndex(data=edge_index, sparse_size=(n, n)), self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/core/temporal_graph/#pathpyG.core.temporal_graph.TemporalGraph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of a directed graph.</p> <p>This method transforms the current graph instance into an undirected graph by adding all directed edges in opposite direction. It applies <code>ToUndirected</code> transform to the underlying <code>torch_geometric.Data</code> object, which automatically duplicates edge attributes for newly created directed edges.</p> Example <pre><code>import pathpyG as pp\ng = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ng_u = g.to_undirected()\nprint(g_u)\n</code></pre> Source code in <code>src/pathpyG/core/temporal_graph.py</code> <pre><code>def to_undirected(self) -&gt; TemporalGraph:\n    \"\"\"Return an undirected version of a directed graph.\n\n    This method transforms the current graph instance into an undirected graph by\n    adding all directed edges in opposite direction. It applies [`ToUndirected`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.transforms.ToUndirected.html#torch_geometric.transforms.ToUndirected)\n    transform to the underlying [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) object, which automatically\n    duplicates edge attributes for newly created directed edges.\n\n    Example:\n        ```py\n        import pathpyG as pp\n        g = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        g_u = g.to_undirected()\n        print(g_u)\n        ```\n    \"\"\"\n    rev_edge_index = self.data.edge_index.flip([0])\n    edge_index = torch.cat([self.data.edge_index, rev_edge_index], dim=1)\n    times = torch.cat([self.data.time, self.data.time])\n    return TemporalGraph(data=Data(edge_index=edge_index, time=times), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/io/","title":"io","text":""},{"location":"reference/pathpyG/io/netzschleuder/","title":"netzschleuder","text":""},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.list_netzschleuder_records","title":"<code>list_netzschleuder_records</code>","text":"<p>Read a list of data sets available at the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <code>**kwargs</code> <code>typing.Any</code> <p>Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters. For supported parameters see https://networks.skewed.de/api</p> <code>{}</code> <p>Examples:</p> <p>Return a list of all data sets</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; pp.io.list_netzschleuder_records()\n['karate', 'reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a list of all data sets with a given tag</p> <pre><code>&gt;&gt;&gt; pp.io.list_netzschleuder_records(tags='temporal')\n['reality_mining', 'sp_hypertext', ...]\n</code></pre> <p>Return a dictionary containing all data set names (keys) as well as all network attributes</p> <pre><code>&gt;&gt;&gt; pp.io.list_netzschleuder_records(full=True)\n{ 'reality_mining': [...], 'karate': [...] }\n</code></pre> <p>Returns:</p> Type Description <code>typing.Union[list, dict]</code> <p>Either a list of data set names or a dictionary containing all data set names and network attributes.</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def list_netzschleuder_records(base_url: str = \"https://networks.skewed.de\", **kwargs: Any) -&gt; Union[list, dict]:\n    \"\"\"\n    Read a list of data sets available at the netzschleuder repository.\n\n    Args:\n        base_url: Base URL of netzschleuder repository\n        **kwargs: Keyword arguments that will be passed to the netzschleuder repository as HTTP GET parameters.\n            For supported parameters see https://networks.skewed.de/api\n\n\n    Examples:\n        Return a list of all data sets\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; pp.io.list_netzschleuder_records()\n        ['karate', 'reality_mining', 'sp_hypertext', ...]\n\n        Return a list of all data sets with a given tag\n\n        &gt;&gt;&gt; pp.io.list_netzschleuder_records(tags='temporal')\n        ['reality_mining', 'sp_hypertext', ...]\n\n        Return a dictionary containing all data set names (keys) as well as all network attributes\n\n        &gt;&gt;&gt; pp.io.list_netzschleuder_records(full=True)\n        { 'reality_mining': [...], 'karate': [...] }\n\n\n    Returns:\n        Either a list of data set names or a dictionary containing all data set names and network attributes.\n\n    \"\"\"\n    url = \"/api/nets\"\n    for k, v in kwargs.items():\n        url += \"?{0}={1}\".format(k, v)\n    try:\n        f = request.urlopen(base_url + url).read()\n        return json.loads(f)\n    except HTTPError:\n        msg = \"Could not connect to netzschleuder repository at {0}\".format(base_url)\n        # LOG.error(msg)\n        raise Exception(msg)\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_graph","title":"<code>read_netzschleuder_graph</code>","text":"<p>Read a graph or temporal graph from the netzschleuder repository.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the network data set to read from</p> required <code>network</code> <code>typing.Optional[str]</code> <p>Identifier of the network within the data set to read. For data sets containing a single network only, this can be set to None.</p> <code>None</code> <code>ignore_temporal</code> <p>If False, this function will return a static or temporal network depending on whether edges contain a time attribute. If True, pathpy will not interpret time attributes and thus always return a static network.</p> required <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <p>Examples:</p> <p>Read network '77' from karate club data set</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; n = pp.io.read_netzschleuder_network(name='karate', network='77')\n&gt;&gt;&gt; print(type(n))\n&gt;&gt;&gt; pp.plot(n)\npp.Graph\n</code></pre> <p>Returns:</p> Type Description <code>typing.Union[pathpyG.core.graph.Graph, pathpyG.core.temporal_graph.TemporalGraph]</code> <p>Graph or TemporalGraph object</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_graph(\n    name: str,\n    network: Optional[str] = None,\n    multiedges: bool = False,\n    time_attr: Optional[str] = None,\n    base_url: str = \"https://networks.skewed.de\"\n) -&gt; Union[Graph, TemporalGraph]:\n    \"\"\"Read a graph or temporal graph from the netzschleuder repository.\n\n    Args:\n        name: Name of the network data set to read from\n        network: Identifier of the network within the data set to read. For data sets\n            containing a single network only, this can be set to None.\n        ignore_temporal: If False, this function will return a static or temporal network depending\n            on whether edges contain a time attribute. If True, pathpy will not interpret\n            time attributes and thus always return a static network.\n        base_url: Base URL of netzschleuder repository\n\n    Examples:\n        Read network '77' from karate club data set\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; n = pp.io.read_netzschleuder_network(name='karate', network='77')\n        &gt;&gt;&gt; print(type(n))\n        &gt;&gt;&gt; pp.plot(n)\n        pp.Graph\n\n    Returns:\n        Graph or TemporalGraph object\n    \"\"\"\n    # build URL\n    try:\n        # retrieve properties of data record via API\n        properties = json.loads(request.urlopen(f\"{base_url}/api/net/{name}\").read())\n\n        timestamps = not (time_attr is None)\n\n        if not network:\n            analyses = properties[\"analyses\"]\n            network = name\n        else:\n            analyses = properties[\"analyses\"][network]\n\n        try:\n            is_directed = analyses[\"is_directed\"]\n            num_nodes = analyses[\"num_vertices\"]\n        except KeyError as exc:\n            raise Exception(f\"Record {name} contains multiple networks, please specify network name.\") from exc\n\n        # Retrieve CSV data\n        url = f\"{base_url}/net/{name}/files/{network}.csv.zip\"\n        try:\n            response = request.urlopen(url)\n\n            # decompress zip into temporary folder\n            data = BytesIO(response.read())\n\n            with zipfile.ZipFile(data, \"r\") as zip_ref:\n                with tempfile.TemporaryDirectory() as temp_dir:\n                    zip_ref.extractall(path=temp_dir)\n\n                    # the gprop file contains lines with property name/value pairs\n                    # gprops = pd.read_csv(f'{temp_dir}/gprops.csv', header=0, sep=',', \n                    #           skip_blank_lines=True, skipinitialspace=True)\n\n                    # nodes.csv contains node indices with node properties (like name)\n                    edges = pd.read_csv(\n                        f\"{temp_dir}/edges.csv\", header=0, sep=\",\", skip_blank_lines=True, skipinitialspace=True\n                    )\n\n                    # rename columns\n                    edges.rename(columns={\"# source\": \"v\", \"target\": \"w\"}, inplace=True)\n                    if timestamps and time_attr:\n                        edges.rename(columns={time_attr: \"t\"}, inplace=True)\n\n                    # construct graph and assign edge attributes\n                    if timestamps:\n                        g = df_to_temporal_graph(df=edges, multiedges=multiedges, num_nodes=num_nodes)\n                    else:\n                        g = df_to_graph(df=edges, multiedges=multiedges,\n                                        is_undirected=not is_directed, num_nodes=num_nodes)\n\n                    node_attrs = pd.read_csv(\n                        f\"{temp_dir}/nodes.csv\", header=0, sep=\",\", skip_blank_lines=True, skipinitialspace=True\n                    )\n                    node_attrs.rename(columns={\"# index\": \"index\"}, inplace=True)\n\n                    add_node_attributes(node_attrs, g)\n\n                    # add graph-level attributes\n                    for x in analyses:\n                        g.data[\"analyses_\" + x] = analyses[x]\n\n                    return g\n        except HTTPError as exc:\n            msg = f\"Could not retrieve netzschleuder record at {url}\"\n            raise Exception(msg) from exc\n    except HTTPError as exc:\n        msg = f\"Could not retrieve netzschleuder record at {base_url}/api/net/{name}\"\n        raise Exception(msg) from exc\n    return None\n</code></pre>"},{"location":"reference/pathpyG/io/netzschleuder/#pathpyG.io.netzschleuder.read_netzschleuder_record","title":"<code>read_netzschleuder_record</code>","text":"<p>Read metadata of a single data record with given name from the netzschleuder repository</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the data set for which to retrieve the metadata</p> required <code>base_url</code> <code>str</code> <p>Base URL of netzschleuder repository</p> <code>'https://networks.skewed.de'</code> <p>Examples:</p> <p>Retrieve metadata of karate club network</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; metdata = pp.io.read_netzschleuder_record('karate')\n&gt;&gt;&gt; print(metadata)\n{\n    'analyses': {'77': {'average_degree': 4.52... } }\n}\n</code></pre> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing key-value pairs of metadata</p> Source code in <code>src/pathpyG/io/netzschleuder.py</code> <pre><code>def read_netzschleuder_record(name: str, base_url: str = \"https://networks.skewed.de\") -&gt; dict:\n    \"\"\"\n    Read metadata of a single data record with given name from the netzschleuder repository\n\n    Args:\n        name: Name of the data set for which to retrieve the metadata\n        base_url: Base URL of netzschleuder repository\n\n    Examples:\n        Retrieve metadata of karate club network\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; metdata = pp.io.read_netzschleuder_record('karate')\n        &gt;&gt;&gt; print(metadata)\n        {\n            'analyses': {'77': {'average_degree': 4.52... } }\n        }\n\n    Returns:\n        Dictionary containing key-value pairs of metadata\n    \"\"\"\n    url = f\"/api/net/{name}\"\n    try:\n        return json.loads(request.urlopen(base_url + url).read())\n    except HTTPError as exc:\n        msg = f\"Could not connect to netzschleuder repository at {base_url}\"\n        # LOG.error(msg)\n        raise Exception(msg) from exc\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/","title":"pandas","text":""},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.add_edge_attributes","title":"<code>add_edge_attributes</code>","text":"<p>Add (temporal) edge attributes from pandas data frame to existing <code>Graph</code>.</p> <p>Add edge attributes from <code>pandas.DataFrame</code> to existing <code>Graph</code>, where source/target node IDs are given in columns <code>v</code> and <code>w</code>  and edge attributes x are given in columns <code>edge_x</code>. If <code>time_attr</code> is not None, the dataframe is expected to contain temporal data with a timestamp in a column named as specified in <code>time_attr</code>.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>A DataFrame with rows containing edges and optional edge attributes.</p> required <code>g</code> <code>pathpyG.core.graph.Graph</code> <p>The graph to which the edge attributes should be added.</p> required <code>time_attr</code> <code>str | None</code> <p>If not None, the name of the column containing time stamps for temporal edges.</p> <code>None</code> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def add_edge_attributes(df: pd.DataFrame, g: Graph, time_attr: str | None = None) -&gt; None:\n    \"\"\"Add (temporal) edge attributes from pandas data frame to existing `Graph`.\n\n    Add edge attributes from `pandas.DataFrame` to existing `Graph`, where source/target node\n    IDs are given in columns `v` and `w`  and edge attributes x are given in columns `edge_x`.\n    If `time_attr` is not None, the dataframe is expected to contain temporal data with a timestamp\n    in a column named as specified in `time_attr`.\n\n    Args:\n        df: A DataFrame with rows containing edges and optional edge attributes.\n        g: The graph to which the edge attributes should be added.\n        time_attr: If not None, the name of the column containing time stamps for temporal edges.\n    \"\"\"\n    if \"v\" not in df or \"w\" not in df:\n        logger.error(\"Data frame must have columns `v` and `w` for source and target nodes\")\n        raise ValueError(\"Data frame must have columns `v` and `w` for source and target nodes\")\n\n    # check for non-existent nodes\n    node_ids = set(df[\"v\"]).union(set(df[\"w\"]))\n    if not node_ids.issubset(set(g.nodes)):\n        raise ValueError(\n            f\"DataFrame contains nodes {node_ids - set(g.nodes)} that do not exist in the graph. \"\n            \"Please ensure all nodes in the DataFrame are present in the graph.\"\n        )\n\n    # check if the number of edges in the data frame is consistent with the graph\n    if g.m != len(df):\n        raise ValueError(\n            f\"DataFrame contains {len(df)} edges, but the graph has {g.m} edges. \"\n            \"Please ensure the DataFrame matches the number of edges in the graph.\"\n        )\n\n    # extract indices of source/target node of edges\n    src = g.mapping.to_idxs(df[\"v\"].tolist())\n    tgt = g.mapping.to_idxs(df[\"w\"].tolist())\n\n    edge_attrs = [attr for attr in df.columns if attr not in [\"v\", \"w\"]]\n\n    if time_attr is not None:\n        if time_attr not in df:\n            logger.error(\"Data frame must have column %s for time stamps\", time_attr)\n            raise ValueError(f\"Data frame must have column {time_attr} for time stamps\")\n\n        time = df[time_attr].values\n        edge_attrs.remove(time_attr)\n\n        # find indices of edges in temporal edge_index\n        edge_idx = []\n        for src_i, tgt_i, time_i in zip(src, tgt, time):\n            edge = g.tedge_to_index.get((src_i.item(), tgt_i.item(), time_i.item()), None)  # type: ignore\n            if edge is None:\n                logger.error(\"found non-existing edge in temporal graph\")\n                raise ValueError(\n                    f\"Edge ({src_i.item()}, {tgt_i.item()}) does not exist at time {time_i.item()} in the graph.\"\n                )\n            edge_idx.append(edge)\n    else:\n        # find indices of edges in edge_index\n        edge_idx = []\n        for src_i, tgt_i in zip(src, tgt):\n            edge = g.edge_to_index.get((src_i.item(), tgt_i.item()), None)\n            if edge is None:\n                logger.error(\"found non-existing edge in temporal graph\")\n                raise ValueError(f\"Edge ({src_i.item()}, {tgt_i.item()}) does not exist in the graph.\")\n            edge_idx.append(edge)\n\n    for attr in edge_attrs:\n        if attr.startswith(\"edge_\"):\n            prefix = \"\"\n        else:\n            prefix = \"edge_\"\n\n        # parse column and add to graph\n        _parse_df_column(\n            df=df.iloc[edge_idx],\n            data=g.data,\n            attr=attr,\n            prefix=prefix,\n        )\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.add_node_attributes","title":"<code>add_node_attributes</code>","text":"<p>Add node attributes from <code>DataFrame</code> to existing <code>Graph</code>.</p> <p>Add node attributes from <code>pandas.DataFrame</code> to existing graph, where node IDs or indices are given in column <code>v</code> and node attributes x are given in columns <code>node_x</code>.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>A DataFrame with rows containing nodes and optional node attributes.</p> required <code>g</code> <code>pathpyG.core.graph.Graph</code> <p>The graph to which the node attributes should be added.</p> required Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def add_node_attributes(df: pd.DataFrame, g: Graph):\n    \"\"\"Add node attributes from `DataFrame` to existing `Graph`.\n\n    Add node attributes from `pandas.DataFrame` to existing graph, where node\n    IDs or indices are given in column `v` and node attributes x are given in columns `node_x`.\n\n    Args:\n        df: A DataFrame with rows containing nodes and optional node attributes.\n        g: The graph to which the node attributes should be added.\n    \"\"\"\n    if \"v\" in df:\n        logger.debug(\"Mapping node attributes based on node names in column `v`\")\n        attributed_nodes = list(df[\"v\"])\n    elif \"index\" in df:\n        logger.debug(\"Mapping node attributes based on node indices in column `index`\")\n        attributed_nodes = list(df[\"index\"])\n    else:\n        raise ValueError(\"DataFrame must either have `index` or `v` column\")\n\n    # check for duplicated node attributes\n    if len(set(attributed_nodes)) &lt; len(attributed_nodes):\n        raise ValueError(\"DataFrame cannot contain multiple attribute values for single node\")\n\n    # check for difference between nodes in graph and nodes in attributes\n    if \"v\" in df:\n        if set(attributed_nodes) != set([v for v in g.nodes]):\n            raise ValueError(\"Mismatch between nodes in DataFrame and nodes in graph\")\n\n        # get indices of nodes in tensor\n        node_idx = g.mapping.to_idxs(attributed_nodes).tolist()\n    else:\n        if set(attributed_nodes) != set([i for i in range(g.n)]):\n            raise ValueError(\"Mismatch between nodes in DataFrame and nodes in graph\")\n\n        # get indices of nodes in tensor\n        node_idx = attributed_nodes\n\n    # assign node property tensors\n    cols = [attr for attr in df.columns if attr not in [\"v\", \"index\"]]\n    for attr in cols:\n        # prefix attribute names that are not already prefixed\n        if attr.startswith(\"node_\"):\n            prefix = \"\"\n        else:\n            prefix = \"node_\"\n\n        _parse_df_column(\n            df=df,\n            data=g.data,\n            idx=node_idx,\n            attr=attr,\n            prefix=prefix,\n        )\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.df_to_graph","title":"<code>df_to_graph</code>","text":"<p>Reads a network from a pandas data frame.</p> <p>The data frame is expected to have a minimum of two columns that give the source and target nodes of edges. Additional columns in the data frame will be mapped to edge attributes.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>A data frame with rows containing edges and optional edge attributes. If the data frame contains column names, the source and target columns must be called 'v' and 'w' respectively. If no column names are used the first two columns are interpreted as source and target.</p> required <code>is_undirected</code> <code>bool</code> <p>Whether or not to interpret edges as undirected.</p> <code>False</code> <code>multiedges</code> <code>bool</code> <p>Whether or not to allow multiple edges between the same node pair. By default multi edges are ignored.</p> <code>False</code> <code>num_nodes</code> <code>int | None</code> <p>The number of nodes in the graph. If None, the number of unique nodes in the data frame is used.</p> <code>None</code> Example <pre><code>import pathpyG as pp\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'v': ['a', 'b', 'c'],\n    'w': ['b', 'c', 'a'],\n    'edge_weight': [1.0, 5.0, 2.0]\n    })\ng = pp.io.df_to_graph(df)\nprint(n)\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def df_to_graph(\n    df: pd.DataFrame, is_undirected: bool = False, multiedges: bool = False, num_nodes: int | None = None\n) -&gt; Graph:\n    \"\"\"Reads a network from a pandas data frame.\n\n    The data frame is expected to have a minimum of two columns\n    that give the source and target nodes of edges. Additional columns in the\n    data frame will be mapped to edge attributes.\n\n    Args:\n        df: A data frame with rows containing edges and optional edge attributes. If the\n            data frame contains column names, the source and target columns must be called\n            'v' and 'w' respectively. If no column names are used the first two columns\n            are interpreted as source and target.\n        is_undirected: Whether or not to interpret edges as undirected.\n        multiedges: Whether or not to allow multiple edges between the same node pair. By\n            default multi edges are ignored.\n        num_nodes: The number of nodes in the graph. If None, the number of unique nodes\n            in the data frame is used.\n\n    Example:\n        ```py\n\n        import pathpyG as pp\n        import pandas as pd\n\n        df = pd.DataFrame({\n            'v': ['a', 'b', 'c'],\n            'w': ['b', 'c', 'a'],\n            'edge_weight': [1.0, 5.0, 2.0]\n            })\n        g = pp.io.df_to_graph(df)\n        print(n)\n        ```\n    \"\"\"\n    # assign column names if no header is present\n    no_header = all(isinstance(x, int) for x in df.columns.values.tolist())\n\n    if no_header:\n        # interpret first two columns as source and target\n        col_names = [\"v\", \"w\"]\n        # interpret remaining columns as edge attributes\n        for i in range(2, len(df.columns.values.tolist())):\n            col_names += [f\"edge_attr_{i - 2}\"]\n        df.columns = col_names\n\n    # optionally remove multiedges\n    if not multiedges and df[[\"v\", \"w\"]].duplicated().any():\n        logger.debug(\"Data frame contains multiple edges, but multiedges is set to False. Removing duplicates.\")\n        df = df.drop_duplicates(subset=[\"v\", \"w\"])\n\n    # Create index mapping and data object\n    mapping = IndexMap(node_ids=np.unique(df[[\"v\", \"w\"]].values).tolist())\n    data = Data(\n        edge_index=mapping.to_idxs(df[[\"v\", \"w\"]].values.T),\n        num_nodes=num_nodes if num_nodes is not None else mapping.node_ids.shape[0],  # type: ignore\n    )\n\n    # Parse all columns except 'v' and 'w' as edge attributes\n    cols = df.columns.tolist()\n    cols.remove(\"v\")\n    cols.remove(\"w\")\n    for col in cols:\n        if col.startswith(\"edge_\"):\n            prefix = \"\"\n        else:\n            prefix = \"edge_\"\n\n        _parse_df_column(df=df, data=data, attr=col, prefix=prefix)\n\n    # Create graph object\n    g = Graph(data=data, mapping=mapping)\n    # If the graph should be undirected, convert it to an undirected graph\n    if is_undirected:\n        g = g.to_undirected()\n\n    return g\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.df_to_temporal_graph","title":"<code>df_to_temporal_graph</code>","text":"<p>Read a temporal graph from a DataFrame.</p> <p>The DataFrame is expected to have a minimum of two columns <code>v</code> and <code>w</code> that give the source and target nodes of edges. Each row in the DataFrame is mapped to one temporal edge. Additional columns in the DataFrame will be mapped to edge attributes.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pandas.DataFrame</code> <p>pandas.DataFrame with rows containing time-stamped edges and optional edge attributes.</p> required <code>multiedges</code> <code>bool</code> <p>Whether or not to allow multiple edges between the same node pair. By default multi edges are ignored.</p> <code>False</code> <code>timestamp_format</code> <p>The format of the time stamps in the <code>t</code> column.</p> <code>'%Y-%m-%d %H:%M:%S'</code> <code>time_rescale</code> <p>The factor by which to rescale the time stamps. Defaults to 1, meaning no rescaling.</p> <code>1</code> <code>num_nodes</code> <code>int | None</code> <p>The number of nodes in the graph. If None, the number of unique nodes in the DataFrame is used.</p> <code>None</code> Example <pre><code>import pathpyG as pp\nimport pandas as pd\ndf = pd.DataFrame({\n    'v': ['a', 'b', 'c'],\n    'w': ['b', 'c', 'a'],\n    't': [1, 2, 3]})\ng = pp.io.df_to_temporal_graph(df)\nprint(g)\n\ndf = pd.DataFrame([\n    ['a', 'b', 'c'],\n    ['b', 'c', 'a'],\n    [1, 2, 3]\n    ])\ng = pp.io.df_to_temporal_graph(df)\nprint(g)\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def df_to_temporal_graph(\n    df: pd.DataFrame,\n    multiedges: bool = False,\n    timestamp_format=\"%Y-%m-%d %H:%M:%S\",\n    time_rescale=1,\n    num_nodes: int | None = None,\n) -&gt; TemporalGraph:\n    \"\"\"Read a temporal graph from a DataFrame.\n\n    The DataFrame is expected to have a minimum of two columns `v` and `w`\n    that give the source and target nodes of edges. Each row in the DataFrame is\n    mapped to one temporal edge. Additional columns in the DataFrame will be\n    mapped to edge attributes.\n\n    Args:\n        df: pandas.DataFrame with rows containing time-stamped edges and optional edge\n            attributes.\n        multiedges: Whether or not to allow multiple edges between the same node pair. By\n            default multi edges are ignored.\n        timestamp_format: The format of the time stamps in the `t` column.\n        time_rescale: The factor by which to rescale the time stamps. Defaults to 1, meaning no rescaling.\n        num_nodes: The number of nodes in the graph. If None, the number of unique nodes\n            in the DataFrame is used.\n\n    Example:\n        ```py\n\n        import pathpyG as pp\n        import pandas as pd\n        df = pd.DataFrame({\n            'v': ['a', 'b', 'c'],\n            'w': ['b', 'c', 'a'],\n            't': [1, 2, 3]})\n        g = pp.io.df_to_temporal_graph(df)\n        print(g)\n\n        df = pd.DataFrame([\n            ['a', 'b', 'c'],\n            ['b', 'c', 'a'],\n            [1, 2, 3]\n            ])\n        g = pp.io.df_to_temporal_graph(df)\n        print(g)\n        ```\n    \"\"\"\n    # assign column names if no header is present\n    no_header = all(isinstance(x, int) for x in df.columns.values.tolist())\n\n    if no_header:\n        # interpret first two columns as source and target\n        logger.info(\"Interpreting first three columns as v, w, t\")\n        col_names = [\"v\", \"w\", \"t\"]\n        # interpret remaining columns as edge attributes\n        for i in range(3, len(df.columns.values.tolist())):\n            col_names += [\"edge_attr_{0}\".format(i - 2)]\n        df.columns = col_names\n\n    # parse the time stamp column \"t\"\n    _parse_timestamp(df=df, timestamp_format=timestamp_format, time_rescale=time_rescale)\n\n    # optionally remove multiedges\n    if not multiedges:\n        df = df.drop_duplicates(subset=[\"v\", \"w\", \"t\"])\n\n    # Create index mapping and data object\n    mapping = IndexMap(node_ids=np.unique(df[[\"v\", \"w\"]].values))\n    data = Data(\n        edge_index=mapping.to_idxs(df[[\"v\", \"w\"]].values.T),\n        time=torch.tensor(df[\"t\"].values),\n        num_nodes=num_nodes if num_nodes is not None else mapping.node_ids.shape[0],  # type: ignore\n    )\n\n    # add edge attributes\n    cols = [col for col in df.columns if col not in [\"v\", \"w\", \"t\"]]\n    for col in cols:\n        if col.startswith(\"edge_\"):\n            prefix = \"\"\n        else:\n            prefix = \"edge_\"\n\n        _parse_df_column(df=df, data=data, attr=col, prefix=prefix)\n\n    # Create temporal graph object\n    g = TemporalGraph(data=data, mapping=mapping)\n\n    return g\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.graph_to_df","title":"<code>graph_to_df</code>","text":"<p>Return a DataFrame for a given graph.</p> <p>Returns a <code>pandas.DataFrame</code> that contains all edges including edge attributes. Node and network-level attributes are not included. To facilitate the import into network analysis tools that only support integer node identifiers, node uids can be replaced by a consecutive, zero-based index.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph to export as pandas DataFrame</p> required <code>node_indices</code> <code>typing.Optional[bool]</code> <p>whether nodes should be exported as integer indices</p> <code>False</code> Example <pre><code>import pathpyG as pp\n\nn = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\ndf = pp.io.to_dataframe(n)\nprint(df)\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def graph_to_df(graph: Graph, node_indices: Optional[bool] = False) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame for a given graph.\n\n    Returns a `pandas.DataFrame` that contains all edges including edge\n    attributes. Node and network-level attributes are not included. To\n    facilitate the import into network analysis tools that only support integer\n    node identifiers, node uids can be replaced by a consecutive, zero-based\n    index.\n\n    Args:\n        graph: The graph to export as pandas DataFrame\n        node_indices: whether nodes should be exported as integer indices\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        n = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        df = pp.io.to_dataframe(n)\n        print(df)\n        ```\n    \"\"\"\n    if node_indices:\n        vs = to_numpy(graph.data.edge_index[0])\n        ws = to_numpy(graph.data.edge_index[1])\n    else:\n        vs = graph.mapping.to_ids(to_numpy(graph.data.edge_index[0]))\n        ws = graph.mapping.to_ids(to_numpy(graph.data.edge_index[1]))\n    df = pd.DataFrame({**{\"v\": vs, \"w\": ws}, **{a: graph.data[a].tolist() for a in graph.edge_attrs()}})\n\n    return df\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.read_csv_graph","title":"<code>read_csv_graph</code>","text":"<p>Read a <code>Graph</code> from a csv file.</p> <p>This method reads a graph from a <code>.csv</code>-file and converts it to a <code>Graph</code> object. To read a temporal graph, the csv file must have a header with column <code>t</code> containing time stamps of edges</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to the csv file containing the graph data.</p> required <code>sep</code> <code>str</code> <p>character separating columns in the csv file</p> <code>','</code> <code>header</code> <code>bool</code> <p>whether or not the first line of the csv file is interpreted as header with column names</p> <code>True</code> <code>is_undirected</code> <code>bool</code> <p>whether or not to interpret edges as undirected</p> <code>False</code> <code>multiedges</code> <code>bool</code> <p>whether or not to allow multiple edges between the same node pair. By default multi edges are ignored.</p> <code>False</code> <code>**kwargs</code> <code>typing.Any</code> <p>Additional keyword arguments passed to the <code>df_to_graph</code> function.</p> <code>{}</code> Example <pre><code>import pathpyG as pp\n\ng = pp.io.read_csv('example_graph.csv')\ng = pp.io.read_csv('example_temporal_graph.csv')\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def read_csv_graph(\n    filename: str,\n    sep: str = \",\",\n    header: bool = True,\n    is_undirected: bool = False,\n    multiedges: bool = False,\n    **kwargs: Any,\n) -&gt; Graph:\n    \"\"\"Read a `Graph` from a csv file.\n\n    This method reads a graph from a `.csv`-file and converts it to a\n    `Graph` object. To read a temporal graph, the csv file must have\n    a header with column `t` containing time stamps of edges\n\n    Args:\n        filename: The path to the csv file containing the graph data.\n        sep: character separating columns in the csv file\n        header: whether or not the first line of the csv file is interpreted as header with column names\n        is_undirected: whether or not to interpret edges as undirected\n        multiedges: whether or not to allow multiple edges between the same node pair. By default multi edges are\n            ignored.\n        **kwargs: Additional keyword arguments passed to the `df_to_graph` function.\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.io.read_csv('example_graph.csv')\n        g = pp.io.read_csv('example_temporal_graph.csv')\n        ```\n    \"\"\"\n    if header:\n        df = pd.read_csv(filename, header=0, sep=sep)\n    else:\n        df = pd.read_csv(filename, header=None, sep=sep)\n\n    return df_to_graph(df, is_undirected=is_undirected, multiedges=multiedges, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.read_csv_path_data","title":"<code>read_csv_path_data</code>","text":"<p>Read multiple paths stored in an n-gram csv file</p> <p>Parameters:</p> Name Type Description Default <code>path_or_buf</code> <code>typing.Any</code> <p>File, path or file-like object that the <code>pandas.read_table</code> function will read from        </p> <code>None</code> <code>weight</code> <code>bool</code> <p>If True the last column of each row in the CSV file will be interpreted as a count or weight</p> <code>True</code> <code>sep</code> <p>character that separates the nodes (and weight) in each line of the input file</p> <code>','</code> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def read_csv_path_data(path_or_buf: Any = None, weight: bool = True, sep=',',\n                       device: Optional[torch.device] = None, **pdargs: Any) -&gt; PathData:\n    \"\"\"Read multiple paths stored in an n-gram csv file\n\n\n    Args:\n        path_or_buf: File, path or file-like object that the `pandas.read_table` function will read from        \n        weight: If True the last column of each row in the CSV file will be interpreted as a count or weight\n        sep: character that separates the nodes (and weight) in each line of the input file\n    \"\"\"\n\n    # Read raw data\n    df = pd.read_table(filepath_or_buffer=path_or_buf, header=None)\n    # split and expand non-uniform rows\n    df = df[0].str.split(sep, expand=True)\n\n    paths = []\n    weights = []\n\n    # extract node sequences and edges\n    for row in df.itertuples(index=False):\n        p = [x for x in row if x]\n        if weight:\n            weights.append(float(p[-1]))\n            p.pop()\n        else:\n            weights.append(1.0)\n        paths.append(p)\n\n    # create index mapping\n    mapping = IndexMap()\n    mapping.add_ids(np.unique(np.hstack(paths)))\n\n    # create path_data object\n    pathdata = PathData(mapping, device)\n    pathdata.append_walks(node_seqs=paths, weights=weights)\n    return pathdata\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.read_csv_temporal_graph","title":"<code>read_csv_temporal_graph</code>","text":"<p>Read a <code>TemporalGraph</code> from a csv file.</p> <p>This method reads a temporal graph from a <code>.csv</code>-file and converts it to a <code>TemporalGraph</code> object. The csv file is expected to have a header with columns <code>v</code>, <code>w</code>, and <code>t</code> containing source nodes, target nodes, and time stamps of edges, respectively. Additional columns in the csv file will be interpreted as edge attributes.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The path to the csv file containing the temporal graph data.</p> required <code>sep</code> <code>str</code> <p>character separating columns in the csv file</p> <code>','</code> <code>header</code> <code>bool</code> <p>whether or not the first line of the csv file is interpreted as header with column names</p> <code>True</code> <code>timestamp_format</code> <code>str</code> <p>The format of the time stamps in the <code>t</code> column.</p> <code>'%Y-%m-%d %H:%M:%S'</code> <code>time_rescale</code> <code>int</code> <p>The factor by which to rescale the time stamps. Defaults to 1, meaning no rescaling.</p> <code>1</code> <code>**kwargs</code> <code>typing.Any</code> <p>Additional keyword arguments passed to the <code>df_to_temporal_graph</code> function.</p> <code>{}</code> Example <pre><code>import pathpyG as pp\n\ng = pp.io.read_csv('example_temporal_graph.csv')\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def read_csv_temporal_graph(\n    filename: str,\n    sep: str = \",\",\n    header: bool = True,\n    timestamp_format: str = \"%Y-%m-%d %H:%M:%S\",\n    time_rescale: int = 1,\n    **kwargs: Any,\n) -&gt; TemporalGraph:\n    \"\"\"Read a `TemporalGraph` from a csv file.\n\n    This method reads a temporal graph from a `.csv`-file and converts it to a\n    `TemporalGraph` object. The csv file is expected to have a header with columns\n    `v`, `w`, and `t` containing source nodes, target nodes, and time stamps of edges,\n    respectively. Additional columns in the csv file will be interpreted as edge attributes.\n\n    Args:\n        filename: The path to the csv file containing the temporal graph data.\n        sep: character separating columns in the csv file\n        header: whether or not the first line of the csv file is interpreted as header with column names\n        timestamp_format: The format of the time stamps in the `t` column.\n        time_rescale: The factor by which to rescale the time stamps. Defaults to 1, meaning no rescaling.\n        **kwargs: Additional keyword arguments passed to the `df_to_temporal_graph` function.\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        g = pp.io.read_csv('example_temporal_graph.csv')\n        ```\n    \"\"\"\n    if header:\n        df = pd.read_csv(filename, header=0, sep=sep)\n    else:\n        df = pd.read_csv(filename, header=None, sep=sep)\n    return df_to_temporal_graph(df, timestamp_format=timestamp_format, time_rescale=time_rescale, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.temporal_graph_to_df","title":"<code>temporal_graph_to_df</code>","text":"<p>Return a DataFrame for a given temporal graph.</p> <p>Returns a <code>pandas.DataFrame</code> that contains all edges including edge attributes. Node and network-level attributes are not included. To facilitate the import into network analysis tools that only support integer node identifiers, node uids can be replaced by a consecutive, zero-based index.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>The graph to export as pandas DataFrame</p> required <code>node_indices</code> <code>typing.Optional[bool]</code> <p>whether nodes should be exported as integer indices</p> <code>False</code> Example <pre><code>import pathpyG as pp\n\nn = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\ndf = pp.io.to_df(n)\nprint(df)\n</code></pre> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def temporal_graph_to_df(graph: TemporalGraph, node_indices: Optional[bool] = False) -&gt; pd.DataFrame:\n    \"\"\"Return a DataFrame for a given temporal graph.\n\n    Returns a `pandas.DataFrame` that contains all edges including edge\n    attributes. Node and network-level attributes are not included. To\n    facilitate the import into network analysis tools that only support integer\n    node identifiers, node uids can be replaced by a consecutive, zero-based\n    index.\n\n    Args:\n        graph: The graph to export as pandas DataFrame\n        node_indices: whether nodes should be exported as integer indices\n\n    Example:\n        ```py\n        import pathpyG as pp\n\n        n = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('c', 'a', 3)])\n        df = pp.io.to_df(n)\n        print(df)\n        ```\n    \"\"\"\n    if node_indices:\n        vs = to_numpy(graph.data.edge_index[0])\n        ws = to_numpy(graph.data.edge_index[1])\n    else:\n        vs = graph.mapping.to_ids(to_numpy(graph.data.edge_index[0]))\n        ws = graph.mapping.to_ids(to_numpy(graph.data.edge_index[1]))\n    df = pd.DataFrame(\n        {\n            **{\"v\": vs, \"w\": ws, \"t\": graph.data.time.tolist()},\n            **{a: graph.data[a].tolist() for a in graph.edge_attrs()},\n        }\n    )\n\n    return df\n</code></pre>"},{"location":"reference/pathpyG/io/pandas/#pathpyG.io.pandas.write_csv","title":"<code>write_csv</code>","text":"<p>Store all edges of a graph or temporal graph in a csv file.</p> <p>This method stores a <code>Graph</code> or <code>TemporalGraph</code> as a <code>.csv</code> file. The csv file will contain all edges including edge attributes. Node and network-level attributes are not included. To facilitate the import into network analysis tools that only support integer node identifiers, node uids can be replaced by a consecutive, zero-based index.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>typing.Union[pathpyG.core.graph.Graph, pathpyG.core.temporal_graph.TemporalGraph]</code> <p>The graph to export as pandas DataFrame</p> required <code>node_indices</code> <code>bool</code> <p>whether nodes should be exported as integer indices</p> <code>False</code> <code>path_or_buf</code> <code>typing.Any</code> <p>String, path, or file-like object (see documentation of <code>pandas.DaatFrame.to_csv</code>)</p> <code>None</code> <code>**pdargs</code> <code>typing.Any</code> <p>Additional keyword arguments passed to <code>pandas.DataFrame.to_csv</code>.</p> <code>{}</code> Source code in <code>src/pathpyG/io/pandas.py</code> <pre><code>def write_csv(graph: Union[Graph, TemporalGraph], node_indices: bool = False, \n              path_or_buf: Any = None, **pdargs: Any) -&gt; None:\n    \"\"\"Store all edges of a graph or temporal graph in a csv file.\n\n    This method stores a `Graph` or `TemporalGraph` as a `.csv` file. The csv file\n    will contain all edges including edge attributes. Node and network-level attributes\n    are not included. To facilitate the import into network analysis tools that only\n    support integer node identifiers, node uids can be replaced by a consecutive,\n    zero-based index.\n\n    Args:\n        graph: The graph to export as pandas DataFrame\n        node_indices: whether nodes should be exported as integer indices\n        path_or_buf: String, path, or file-like object (see documentation of `pandas.DaatFrame.to_csv`)\n        **pdargs: Additional keyword arguments passed to `pandas.DataFrame.to_csv`.\n    \"\"\"\n    if isinstance(graph, TemporalGraph):\n        frame = temporal_graph_to_df(graph=graph, node_indices=node_indices)\n    else:\n        frame = graph_to_df(graph=graph, node_indices=node_indices)\n    frame.to_csv(index=False, path_or_buf=path_or_buf, **pdargs)\n</code></pre>"},{"location":"reference/pathpyG/nn/","title":"nn","text":""},{"location":"reference/pathpyG/nn/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/nn/dbgnn/#pathpyG.nn.dbgnn.DBGNN","title":"<code>DBGNN</code>","text":"<p>               Bases: <code>torch.nn.Module</code></p> <p>Implementation of time-aware graph neural network DBGNN (Reference paper).</p> <p>Parameters:</p> Name Type Description Default <code>num_classes</code> <code>int</code> <p>number of classes</p> required <code>num_features</code> <code>list[int]</code> <p>number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]</p> required <code>hidden_dims</code> <code>list[int]</code> <p>number of hidden dimensions per each layer in the first/higher order network</p> required <code>p_dropout</code> <code>float</code> <p>drop-out probability</p> <code>0.0</code> Source code in <code>src/pathpyG/nn/dbgnn.py</code> <pre><code>class DBGNN(Module):\n    \"\"\"Implementation of time-aware graph neural network DBGNN ([Reference paper](https://openreview.net/pdf?id=Dbkqs1EhTr)).\n\n    Args:\n        num_classes: number of classes\n        num_features: number of features for first order and higher order nodes, e.g. [first_order_num_features, second_order_num_features]\n        hidden_dims: number of hidden dimensions per each layer in the first/higher order network\n        p_dropout: drop-out probability\n    \"\"\"\n\n    def __init__(self, num_classes: int, num_features: list[int], hidden_dims: list[int], p_dropout: float = 0.0):\n        super().__init__()\n\n        self.num_features = num_features\n        self.num_classes = num_classes\n        self.hidden_dims = hidden_dims\n        self.p_dropout = p_dropout\n\n        # higher-order layers\n        self.higher_order_layers = ModuleList()\n        self.higher_order_layers.append(GCNConv(self.num_features[1], self.hidden_dims[0]))\n\n        # first-order layers\n        self.first_order_layers = ModuleList()\n        self.first_order_layers.append(GCNConv(self.num_features[0], self.hidden_dims[0]))\n\n        for dim in range(1, len(self.hidden_dims) - 1):\n            # higher-order layers\n            self.higher_order_layers.append(GCNConv(self.hidden_dims[dim - 1], self.hidden_dims[dim]))\n            # first-order layers\n            self.first_order_layers.append(GCNConv(self.hidden_dims[dim - 1], self.hidden_dims[dim]))\n\n        self.bipartite_layer = BipartiteGraphOperator(self.hidden_dims[-2], self.hidden_dims[-1])\n\n        # Linear layer\n        self.lin = torch.nn.Linear(self.hidden_dims[-1], num_classes)\n\n    def forward(self, data):\n\n        x = data.x\n        x_h = data.x_h\n\n        # First-order convolutions\n        for layer in self.first_order_layers:\n            x = F.dropout(x, p=self.p_dropout, training=self.training)\n            x = F.elu(layer(x, data.edge_index, data.edge_weights))\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Second-order convolutions\n        for layer in self.higher_order_layers:\n            x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n            x_h = F.elu(layer(x_h, data.edge_index_higher_order, data.edge_weights_higher_order))\n        x_h = F.dropout(x_h, p=self.p_dropout, training=self.training)\n\n        # Bipartite message passing\n        x = torch.nn.functional.elu(\n            self.bipartite_layer((x_h, x), data.bipartite_edge_index, N=data.num_ho_nodes, M=data.num_nodes)\n        )\n        x = F.dropout(x, p=self.p_dropout, training=self.training)\n\n        # Linear layer\n        x = self.lin(x)\n\n        return x\n</code></pre>"},{"location":"reference/pathpyG/statistics/","title":"statistics","text":"<p>Functions to compute various graph statistics.</p> <p>The functions in this module allow to compute  various statistics on graphs</p> Example <pre><code>import pathpyG as pp\n\n# Generate a toy example graph.\ng = pp.Graph.from_edge_list([\n    ('b', 'c'),\n    ('a', 'b'),\n    ('c', 'd'),\n    ('d', 'a'),\n    ('b', 'd')\n])\n\n# Calculate degree distribution and raw moments\nd_dist = pp.statistics.degree_distribution(g)\nk_1 = pp.statistics.degree_raw_moment(g, k=1)\nk_2 = pp.statistics.degree_raw_moment(g, k=2)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph","title":"<code>Graph</code>","text":"<p>A graph object storing nodes, edges, and attributes.</p> <p>An object than be be used to store directed or undirected graphs with node and edge attributes. Data on nodes and edges are stored in an underlying instance of <code>torch_geometric.Data</code>.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>class Graph:\n    \"\"\"\n    A graph object storing nodes, edges, and attributes.\n\n    An object than be be used to store directed or undirected graphs with node\n    and edge attributes. Data on nodes and edges are stored in an underlying instance of\n    [`torch_geometric.Data`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data).\n    \"\"\"\n\n    def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n        \"\"\"Generate graph instance from a pyG `Data` object.\n\n        Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n        optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n        node indices to string identifiers.\n\n        Args:\n            data: A pyG Data object containing an EdgeIndex and additional attributes\n            mapping: `IndexMap` object that maps node indices to string identifiers\n\n        Example:\n            ```py\n            import pathpyG as pp\n            from torch_geometric.data import Data\n            from torch_geometric import EdgeIndex\n\n            data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n            g = pp.Graph(data)\n\n            g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n            ```\n        \"\"\"\n        if mapping is None:\n            self.mapping = IndexMap()\n        else:\n            self.mapping = mapping\n\n        # set num_nodes property\n        if \"num_nodes\" not in data and \"edge_index\" in data:            \n            data.num_nodes = data.edge_index.max().item() + 1\n            logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n        # turn edge index tensor into EdgeIndex object\n        if not isinstance(data.edge_index, EdgeIndex):\n            data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n        if (\n            data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n            or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n        ):\n            logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n            raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n        self.data = data\n\n        # sort EdgeIndex and validate\n        data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n        for edge_attr in self.edge_attrs():\n            data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n        data.edge_index.validate()\n\n        # create mapping between edge tuples and edge indices\n        self.edge_to_index = {\n            (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n        }\n\n        ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n        ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n        # create node_sequence mapping for higher-order graphs\n        if \"node_sequence\" not in self.data:\n            self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n\n    @staticmethod\n    def from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n        \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n        be used to transparently map node indices to string identifiers.\n\n        Args:\n            edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n            mapping: `IndexMap` object that maps node indices to string identifiers\n            num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n                inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n        Examples:\n            You can create a graph from an edge index tensor as follows:\n\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n            &gt;&gt;&gt; print(g)\n            Directed graph with 3 nodes and 3 edges ...\n\n            You can also include a mapping of node IDs:\n\n            &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n            &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n            &gt;&gt;&gt; print(g.mapping)\n            a -&gt; 0\n            b -&gt; 1\n            c -&gt; 2\n        \"\"\"\n\n        if not num_nodes:\n            d = Data(edge_index=edge_index)\n        else:\n            if mapping is not None and mapping.num_ids() != num_nodes:\n                logger.error(\"Number of node IDs in mapping must match num_nodes\")\n                raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n            d = Data(edge_index=edge_index, num_nodes=num_nodes)\n        return Graph(d, mapping=mapping)\n\n    @staticmethod\n    def from_edge_list(\n        edge_list: Iterable[Tuple[str, str]],\n        is_undirected: bool = False,\n        mapping: Optional[IndexMap] = None,\n        device: Optional[torch.device] = None,\n    ) -&gt; Graph:\n        \"\"\"Generate a Graph based on an edge list.\n\n        Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n        a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n        node IDs.\n\n        Args:\n            edge_list: Iterable of edges represented as tuples\n            is_undirected: Whether the edge list contains all bidorectional edges\n            mapping: optional mapping of string IDs to node indices\n            device: optional torch device where tensors shall be stored\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n            &gt;&gt;&gt; print(list(g.edges))\n            [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        \"\"\"\n\n        # handle empty graph\n        if len(edge_list) == 0:\n            return Graph(\n                Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n                mapping=IndexMap(),\n            )\n\n        if mapping is None:\n            edge_array = np.array(edge_list)\n            node_ids = np.unique(edge_array)\n            if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n                node_ids = np.sort(node_ids.astype(int)).astype(str)\n            mapping = IndexMap(node_ids)\n\n        num_nodes = mapping.num_ids()\n\n        edge_index = EdgeIndex(\n            mapping.to_idxs(edge_list, device=device).T.contiguous(),\n            sparse_size=(num_nodes, num_nodes),\n            is_undirected=is_undirected,\n        )\n        return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\n    def to_undirected(self) -&gt; Graph:\n        \"\"\"Return an undirected version of this directed graph.\n\n        This method creates a new undirected Graph from the current graph instance by\n        adding all directed edges in opposite direction.\n\n        Examples:\n            &gt;&gt;&gt; import pathpyG as pp\n            &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n            &gt;&gt;&gt; g_u = g.to_undirected()\n            &gt;&gt;&gt; print(g_u)\n            Undirected graph with 3 nodes and 6 (directed) edges\n        \"\"\"\n        # create undirected edge index by coalescing the directed edges and keep\n        # track of the original edge index for the edge attributes\n        attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n        edge_index, attr_idx = to_undirected(\n            self.data.edge_index,\n            edge_attr=attr_idx,\n            num_nodes=self.data.num_nodes,\n            reduce=\"min\",\n        )\n\n        data = Data(\n            edge_index=EdgeIndex(\n                data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n            ),\n            num_nodes=self.data.num_nodes,\n        )\n        # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n        # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n        # make sure to copy all node and (undirected) edge attributes\n        for node_attr in self.node_attrs():\n            data[node_attr] = self.data[node_attr]\n        for edge_attr in self.edge_attrs():\n            if edge_attr != \"edge_index\":\n                data[edge_attr] = self.data[edge_attr][attr_idx]\n\n        return Graph(data, self.mapping)\n\n    def to_weighted_graph(self) -&gt; Graph:\n        \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n        If the graph contains multiple edges between the same nodes, this method will coalesce\n        them into a single edge with an additional weight attribute called `edge_weight` that\n        contains the number of coalesced edges. The method returns a new graph instance with\n        the coalesced edges.\n\n        Returns:\n            Graph: Graph with coalesced edges\n        \"\"\"\n        i, w = torch_geometric.utils.coalesce(\n            self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n        )\n        return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n\n    def to(self, device: torch.device) -&gt; Graph:\n        \"\"\"Move all tensors to the given device.\n\n        Args:\n            device: torch device to which all tensors shall be moved\n\n        Returns:\n            Graph: self\n        \"\"\"\n        self.data.edge_index = self.data.edge_index.to(device)\n        self.data.node_sequence = self.data.node_sequence.to(device)\n        for attr in self.node_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n        for attr in self.edge_attrs():\n            if isinstance(self.data[attr], torch.Tensor):\n                self.data[attr] = self.data[attr].to(device)\n\n        self.row = self.row.to(device)\n        self.row_ptr = self.row_ptr.to(device)\n        self.col = self.col.to(device)\n        self.col_ptr = self.col_ptr.to(device)\n\n        return self\n\n    def node_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of node attributes.\n\n        This method returns a list containing the names of all node-level attributes,\n        ignoring the special `node_sequence` attribute.\n\n        Returns:\n            list: list of node attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                attrs.append(k)\n        return attrs\n\n    def edge_attrs(self) -&gt; List[str]:\n        \"\"\"\n        Return a list of edge attributes.\n\n        This method returns a list containing the names of all edge-level attributes,\n        ignoring the special `edge_index` attribute.\n\n        Returns:\n            list: list of edge attributes\n        \"\"\"\n        attrs = []\n        for k in self.data.keys():\n            if k != \"edge_index\" and k.startswith(\"edge_\"):\n                attrs.append(k)\n        return attrs\n\n    @property\n    def nodes(self) -&gt; list:\n        \"\"\"\n        Return indices or IDs of all nodes in the graph.\n\n        This method returns a list object that contains all nodes.\n        If an IndexMap is used, nodes are returned as string IDs.\n        If no IndexMap is used, nodes are returned as integer indices.\n\n        Returns:\n            list: list of all nodes using IDs or indices (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(np.arange(self.n)).tolist()\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    @property\n    def edges(self) -&gt; list:\n        \"\"\"Return all edges in the graph.\n\n        This method returns a list object that contains all edges, where each\n        edge is a tuple of two elements. If an IndexMap is used to map node\n        indices to string IDs, edges are returned as tuples of string IDs.\n        If no mapping is used, edges are returned as tuples of integer indices.\n\n        Returns:\n            list: list object yielding all edges using IDs or indices (if no mapping is used)\n        \"\"\"\n        edge_list = self.mapping.to_ids(self.data.edge_index.t()).tolist()\n        if self.order &gt; 1:\n            return [tuple(map(tuple, x)) for x in edge_list]\n        return list(map(tuple, edge_list))\n\n    def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n        Args:\n            row_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n        \"\"\"\n\n        if row_idx + 1 &lt; self.row_ptr.size(0):\n            row_start = self.row_ptr[row_idx]\n            row_end = self.row_ptr[row_idx + 1]\n            return self.col[row_start:row_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n        \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n        Args:\n            col_idx:   Index of node for which predecessors shall be returned.\n\n        Returns:\n            tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n        \"\"\"\n        if col_idx + 1 &lt; self.col_ptr.size(0):\n            col_start = self.col_ptr[col_idx]\n            col_end = self.col_ptr[col_idx + 1]\n            return self.row[col_start:col_end]\n        else:\n            return torch.tensor([], device=self.data.edge_index.device)\n\n    def successors(self, node: Union[int, str] | tuple) -&gt; list:\n        \"\"\"Return all successors of a given node.\n\n        This method returns a generator object that yields all successors of a\n        given node. If an IndexMap is used, successors are returned\n        as string IDs. If no mapping is used, successors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which successors shall be returned.\n\n        Returns:\n            list: list with all successors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n\n        node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n        \"\"\"Return the predecessors of a given node.\n\n        This method returns a generator object that yields all predecessors of a\n        given node. If a `node_id` mapping is used, predecessors will be returned\n        as string IDs. If no mapping is used, predecessors are returned as indices.\n\n        Args:\n            node:   Index or string ID of node for which predecessors shall be returned.\n\n        Returns:\n            list: list with all predecessors of the node identified\n                by `node` using ID or index (if no mapping is used)\n        \"\"\"\n        node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n        if self.order &gt; 1:\n            return list(map(tuple, node_list))\n        return node_list\n\n    def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n        \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n        If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n        mapping is used, nodes are assumed to be integer indices.\n\n        Args:\n            v: source node of edge as integer index or string ID\n            w: target node of edge as integer index or string ID\n\n        Returns:\n            bool: True if edge exists, False otherwise\n        \"\"\"\n        row = self.mapping.to_idx(v)\n        row_start = self.row_ptr[row]\n        row_end = self.row_ptr[row + 1]\n\n        return self.mapping.to_idx(w) in self.col[row_start:row_end]\n\n    def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n        Args:\n            edge_attr: the edge attribute that shall be used as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n        else:\n            return torch_geometric.utils.to_scipy_sparse_matrix(\n                self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n            )\n\n    @property\n    def in_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted in-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing in-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"in\")\n\n    @property\n    def out_degrees(self) -&gt; Dict[str, float]:\n        \"\"\"Return unweighted out-degrees of nodes in directed network.\n\n        Returns:\n            dict: dictionary containing out-degrees of nodes\n        \"\"\"\n        return self.degrees(mode=\"out\")\n\n    def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                     torch.tensor]:\n        \"\"\"\n        Return (weighted) degrees of nodes.\n\n        Args:\n            mode: `in` or `out` to calculate in- or out-degree for\n                directed networks.\n            edge_attr: Optional numerical edge attribute that will \n                be used to compute weighted degrees\n            return_tensor: if True the function returns a degree tensor, if False (default)\n                a dictionary will be returned that can be indexed by nodes\n        Returns:\n            dict: dictionary containing node degrees\n        \"\"\"\n        if mode == \"in\":\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        else:\n            if not edge_attr:\n                d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n            else:\n                edge_weight = getattr(self.data, edge_attr, None)\n                d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n        if return_tensor:\n            return d\n        else:\n            return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n\n    def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n        \"\"\"\n        Compute transition probabilities based on (weighted) outdegrees.\n\n        Args:\n            edge_attr: Optional name of numerical edge attribute that will\n                        will be used to calculate weighted out-degrees for the\n                        visitation probabilities.\n\n        Returns:\n            tensor: Transition probabilities.\n        \"\"\"\n        weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n        source_ids = self.data.edge_index[0]        \n        edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n        if edge_attr:\n            edge_weight = getattr(self.data, edge_attr, None)\n        return edge_weight / weighted_outdegree[source_ids]\n\n    def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n        \"\"\"Return Laplacian matrix for a given graph.\n\n        This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n        to return a Laplcian matrix representation of a given graph.\n\n        Args:\n            normalization: normalization parameter passed to pyG `get_laplacian`\n                function\n            edge_attr: optinal name of numerical edge attribute that shall\n                be passed to pyG `get_laplacian` function as edge weight\n\n        Returns:\n            scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n        \"\"\"\n        if edge_attr is None:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(), normalization=normalization\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n        else:\n            index, weight = torch_geometric.utils.get_laplacian(\n                self.data.edge_index.as_tensor(),\n                normalization=normalization,\n                edge_weight=self.data[edge_attr],\n            )\n            return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n\n    def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n        \"\"\"Return node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be returned\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key in self.data.keys():\n                return self.data[key]\n            else:\n                raise KeyError(key + \" is not a graph attribute\")\n        elif key[0] in self.node_attrs():\n            return self.data[key[0]][self.mapping.to_idx(key[1])]\n        elif key[0] in self.edge_attrs():\n            return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n        else:\n            raise KeyError(key[0] + \" is not a node or edge attribute\")\n\n    def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n        \"\"\"Store node, edge, or graph attribute.\n\n        Args:\n            key: name of attribute to be stored\n            val: value of attribute\n        \"\"\"\n        if not isinstance(key, tuple):\n            if key.startswith(\"node_\"):\n                if val.size(0) != self.n:\n                    raise ValueError(\"Attribute must have same length as number of nodes\")\n                self.data[key] = val\n            elif key.startswith(\"edge_\"):\n                if val.size(0) != self.m:\n                    raise ValueError(\"Attribute must have same length as number of edges\")\n                self.data[key] = val\n            else:\n                self.data[key] = val\n        elif key[0].startswith(\"node_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.mapping.to_idx(key[1])] = val\n        elif key[0].startswith(\"edge_\"):  # type: ignore\n            if key[0] not in self.data.keys():\n                raise KeyError(\n                    \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                    + \"requires that the attribute already exists.\"\n                )\n            self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n        else:\n            raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n\n    @property\n    def n(self) -&gt; int:\n        \"\"\"\n        Return number of nodes.\n\n        Returns:\n            int: number of nodes in the graph\n        \"\"\"\n        return self.data.num_nodes  # type: ignore\n\n    @property\n    def m(self) -&gt; int:\n        \"\"\"\n        Return number of edges.\n\n        Returns the number of edges in the graph. For an undirected graph, the number of \n        undirected edges (accounting for self-loops) is returned, i.e. in an undirected\n        graph the directed edges (a,b) and (b,a) will be counted only once.\n\n        Returns:\n            int: number of edges in the graph\n        \"\"\"\n        if self.is_directed():\n            return self.data.num_edges  # type: ignore\n        else:\n            num_self_loops = (self.data.edge_index[0] == self.data.edge_index[1]).sum().item()\n            num_edges_wo_self_loops = self.data.edge_index.size(1) - int(num_self_loops)\n            return int(num_edges_wo_self_loops/2 + num_self_loops) # type: ignore\n\n    @property\n    def order(self) -&gt; int:\n        \"\"\"\n        Return order of graph.\n\n        Returns:\n            int: order of the (De Bruijn) graph\n        \"\"\"\n        return self.data.node_sequence.size(1)  # type: ignore\n\n    def is_directed(self) -&gt; bool:\n        \"\"\"Return whether graph is directed.\n\n        Returns:\n            bool: True if graph is directed, False otherwise\n        \"\"\"\n        return not self.data.edge_index.is_undirected\n\n    def is_undirected(self) -&gt; bool:\n        \"\"\"Return whether graph is undirected.\n\n        Returns:\n            bool: True if graph is undirected, False otherwise\n        \"\"\"\n        return self.data.edge_index.is_undirected\n\n    def has_self_loops(self) -&gt; bool:\n        \"\"\"Return whether graph contains self-loops.\n\n        Returns:\n            bool: True if graph contains self-loops, False otherwise\n        \"\"\"\n        return self.data.has_self_loops()\n\n    def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n        \"\"\"Combine Graph object with other Graph object.\n\n        The semantics of this operation depends on the optional IndexMap\n        of both graphs. If no IndexMap is included, the two underlying data objects\n        are concatenated, thus merging edges from both graphs while leaving node indices\n        unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n        indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n        Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n        Args:\n            other: Other graph to be combined with this graph\n            reduce: Reduction method for node attributes of nodes that are present in both graphs.\n                Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n        Examples:\n            Adding two graphs without node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 6 edges\n\n            Adding two graphs with identical node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 3 nodes and 4 edges\n\n            Adding two graphs with non-overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 6 nodes and 4 edges\n\n            Adding two graphs with partly overlapping node IDs:\n\n            &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n            &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n            &gt;&gt;&gt; print(g1 + g2)\n            Graph with 5 nodes and 4 edges\n        \"\"\"\n        d1 = self.data.clone()\n        m1 = self.mapping\n\n        d2 = other.data.clone()\n        m2 = other.mapping\n\n        nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n        mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n        d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n        d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n        d = d1.concat(d2)\n        d.num_nodes = mapping.num_ids()\n        d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n        # For higher-order graphs, we need to update the inverse_idx attribute\n        if \"inverse_idx\" in d:\n            d.inverse_idx = mapping.to_idxs(\n                np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n                device=d.inverse_idx.device,\n            )\n\n        # If both graphs contain node attributes, reduce them using the specified method\n        for k in d1.keys():\n            if k != \"node_sequence\" and k.startswith(\"node_\"):\n                if isinstance(d[k], torch.Tensor):\n                    d[k] = torch_geometric.utils.scatter(\n                        d[k],\n                        mapping.to_idxs(\n                            np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                            device=d[k].device,\n                        ),\n                        dim_size=d.num_nodes,\n                        reduce=reduce,\n                    )\n                else:\n                    raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n        return Graph(d, mapping=mapping)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a string representation of the graph.\"\"\"\n\n        attr = self.data.to_dict()\n        attr_types = {}\n        for k in attr:\n            t = type(attr[k])\n            if t == torch.Tensor:\n                attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n            else:\n                attr_types[k] = str(t)\n\n        from pprint import pformat\n\n        if self.is_undirected():\n            s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n        else:\n            s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n        attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n        for a in self.node_attrs():\n            attribute_info[\"Node Attributes\"][a] = attr_types[a]\n        for a in self.edge_attrs():\n            attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n        for a in self.data.keys():\n            if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n                attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n        s += pformat(attribute_info, indent=4, width=160)\n        return s\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.edges","title":"<code>edges</code>  <code>property</code>","text":"<p>Return all edges in the graph.</p> <p>This method returns a list object that contains all edges, where each edge is a tuple of two elements. If an IndexMap is used to map node indices to string IDs, edges are returned as tuples of string IDs. If no mapping is used, edges are returned as tuples of integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list object yielding all edges using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.in_degrees","title":"<code>in_degrees</code>  <code>property</code>","text":"<p>Return unweighted in-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing in-degrees of nodes</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.m","title":"<code>m</code>  <code>property</code>","text":"<p>Return number of edges.</p> <p>Returns the number of edges in the graph. For an undirected graph, the number of  undirected edges (accounting for self-loops) is returned, i.e. in an undirected graph the directed edges (a,b) and (b,a) will be counted only once.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of edges in the graph</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.n","title":"<code>n</code>  <code>property</code>","text":"<p>Return number of nodes.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of nodes in the graph</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.nodes","title":"<code>nodes</code>  <code>property</code>","text":"<p>Return indices or IDs of all nodes in the graph.</p> <p>This method returns a list object that contains all nodes. If an IndexMap is used, nodes are returned as string IDs. If no IndexMap is used, nodes are returned as integer indices.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list of all nodes using IDs or indices (if no mapping is used)</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.order","title":"<code>order</code>  <code>property</code>","text":"<p>Return order of graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>order of the (De Bruijn) graph</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.out_degrees","title":"<code>out_degrees</code>  <code>property</code>","text":"<p>Return unweighted out-degrees of nodes in directed network.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>typing.Dict[str, float]</code> <p>dictionary containing out-degrees of nodes</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__add__","title":"<code>__add__</code>","text":"<p>Combine Graph object with other Graph object.</p> <p>The semantics of this operation depends on the optional IndexMap of both graphs. If no IndexMap is included, the two underlying data objects are concatenated, thus merging edges from both graphs while leaving node indices unchanged. If both graphs include IndexMaps that assign node IDs to indices, indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.</p> <p>Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>pathpyG.core.graph.Graph</code> <p>Other graph to be combined with this graph</p> required <code>reduce</code> <code>str</code> <p>Reduction method for node attributes of nodes that are present in both graphs. Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".</p> <code>'sum'</code> <p>Examples:</p> <p>Adding two graphs without node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n&gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 6 edges\n</code></pre> <p>Adding two graphs with identical node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 3 nodes and 4 edges\n</code></pre> <p>Adding two graphs with non-overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 6 nodes and 4 edges\n</code></pre> <p>Adding two graphs with partly overlapping node IDs:</p> <pre><code>&gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n&gt;&gt;&gt; print(g1 + g2)\nGraph with 5 nodes and 4 edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __add__(self, other: Graph, reduce: str = \"sum\") -&gt; Graph:\n    \"\"\"Combine Graph object with other Graph object.\n\n    The semantics of this operation depends on the optional IndexMap\n    of both graphs. If no IndexMap is included, the two underlying data objects\n    are concatenated, thus merging edges from both graphs while leaving node indices\n    unchanged. If both graphs include IndexMaps that assign node IDs to indices,\n    indices will be adjusted, creating a new mapping for the union of node Ids in both graphs.\n\n    Node IDs of graphs to be combined can be disjoint, partly overlapping or non-overlapping.\n\n    Args:\n        other: Other graph to be combined with this graph\n        reduce: Reduction method for node attributes of nodes that are present in both graphs.\n            Can be one of \"sum\", \"mean\", \"mul\", \"min\", \"max\". Default is \"sum\".\n\n    Examples:\n        Adding two graphs without node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,1,1],[1,2,3]]))\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_index(torch.Tensor([[0,2,3],[3,2,1]]))\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 6 edges\n\n        Adding two graphs with identical node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('a', 'c'), ('c', 'b')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 3 nodes and 4 edges\n\n        Adding two graphs with non-overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('c', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 6 nodes and 4 edges\n\n        Adding two graphs with partly overlapping node IDs:\n\n        &gt;&gt;&gt; g1 = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n        &gt;&gt;&gt; g2 = pp.Graph.from_edge_list([('b', 'd'), ('d', 'e')])\n        &gt;&gt;&gt; print(g1 + g2)\n        Graph with 5 nodes and 4 edges\n    \"\"\"\n    d1 = self.data.clone()\n    m1 = self.mapping\n\n    d2 = other.data.clone()\n    m2 = other.mapping\n\n    nodes = np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))])\n    mapping = IndexMap(np.unique(nodes, axis=0).tolist())\n    d1.edge_index = mapping.to_idxs(m1.to_ids(d1.edge_index), device=d1.edge_index.device)\n    d2.edge_index = mapping.to_idxs(m2.to_ids(d2.edge_index), device=d2.edge_index.device)\n\n    d = d1.concat(d2)\n    d.num_nodes = mapping.num_ids()\n    d.edge_index = EdgeIndex(d.edge_index, sparse_size=(d.num_nodes, d.num_nodes))\n\n    # For higher-order graphs, we need to update the inverse_idx attribute\n    if \"inverse_idx\" in d:\n        d.inverse_idx = mapping.to_idxs(\n            np.concatenate([m1.to_ids(d1.inverse_idx), m2.to_ids(d2.inverse_idx)]),\n            device=d.inverse_idx.device,\n        )\n\n    # If both graphs contain node attributes, reduce them using the specified method\n    for k in d1.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            if isinstance(d[k], torch.Tensor):\n                d[k] = torch_geometric.utils.scatter(\n                    d[k],\n                    mapping.to_idxs(\n                        np.concatenate([m1.to_ids(np.arange(self.n)), m2.to_ids(np.arange(other.n))]),\n                        device=d[k].device,\n                    ),\n                    dim_size=d.num_nodes,\n                    reduce=reduce,\n                )\n            else:\n                raise ValueError(\"Node attribute \" + k + \" is not a tensor and cannot be reduced.\")\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__getitem__","title":"<code>__getitem__</code>","text":"<p>Return node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>typing.Union[tuple, str]</code> <p>name of attribute to be returned</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __getitem__(self, key: Union[tuple, str]) -&gt; Any:\n    \"\"\"Return node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be returned\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key in self.data.keys():\n            return self.data[key]\n        else:\n            raise KeyError(key + \" is not a graph attribute\")\n    elif key[0] in self.node_attrs():\n        return self.data[key[0]][self.mapping.to_idx(key[1])]\n    elif key[0] in self.edge_attrs():\n        return self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]]\n    else:\n        raise KeyError(key[0] + \" is not a node or edge attribute\")\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__init__","title":"<code>__init__</code>","text":"<p>Generate graph instance from a pyG <code>Data</code> object.</p> <p>Generate a Graph instance from a <code>torch_geometric.Data</code> object that contains an EdgeIndex as well as optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>torch_geometric.data.Data</code> <p>A pyG Data object containing an EdgeIndex and additional attributes</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> Example <pre><code>import pathpyG as pp\nfrom torch_geometric.data import Data\nfrom torch_geometric import EdgeIndex\n\ndata = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\ng = pp.Graph(data)\n\ng = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __init__(self, data: Data, mapping: Optional[IndexMap] = None):\n    \"\"\"Generate graph instance from a pyG `Data` object.\n\n    Generate a Graph instance from a `torch_geometric.Data` object that contains an EdgeIndex as well as\n    optional node-, edge- or graph-level attributes. An optional mapping can be used to transparently map\n    node indices to string identifiers.\n\n    Args:\n        data: A pyG Data object containing an EdgeIndex and additional attributes\n        mapping: `IndexMap` object that maps node indices to string identifiers\n\n    Example:\n        ```py\n        import pathpyG as pp\n        from torch_geometric.data import Data\n        from torch_geometric import EdgeIndex\n\n        data = Data(edge_index=EdgeIndex([[1,1,2],[0,2,1]], sparse_size=(3,3)))\n        g = pp.Graph(data)\n\n        g = pp.Graph(data, mapping=pp.IndexMap(['a', 'b', 'c']))\n        ```\n    \"\"\"\n    if mapping is None:\n        self.mapping = IndexMap()\n    else:\n        self.mapping = mapping\n\n    # set num_nodes property\n    if \"num_nodes\" not in data and \"edge_index\" in data:            \n        data.num_nodes = data.edge_index.max().item() + 1\n        logger.debug(\"Inferred number of nodes from edge_index, n = %s\", data.num_nodes)\n\n    # turn edge index tensor into EdgeIndex object\n    if not isinstance(data.edge_index, EdgeIndex):\n        data.edge_index = EdgeIndex(data=data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n\n    if (\n        data.edge_index.get_sparse_size(dim=0) != data.num_nodes\n        or data.edge_index.get_sparse_size(dim=1) != data.num_nodes\n    ):\n        logger.error(\"Sparse size of edge_index does not match number of nodes, n = %s\", data.num_nodes)\n        raise ValueError(\"sparse size of EdgeIndex must match number of nodes!\")\n\n    self.data = data\n\n    # sort EdgeIndex and validate\n    data.edge_index, sorted_idx = data.edge_index.sort_by(\"row\")\n    for edge_attr in self.edge_attrs():\n        data[edge_attr] = self.data[edge_attr][sorted_idx]\n\n    data.edge_index.validate()\n\n    # create mapping between edge tuples and edge indices\n    self.edge_to_index = {\n        (e[0].item(), e[1].item()): i for i, e in enumerate([e for e in self.data.edge_index.t()])\n    }\n\n    ((self.row_ptr, self.col), _) = self.data.edge_index.get_csr()\n    ((self.col_ptr, self.row), _) = self.data.edge_index.get_csc()\n\n    # create node_sequence mapping for higher-order graphs\n    if \"node_sequence\" not in self.data:\n        self.data.node_sequence = torch.arange(data.num_nodes).reshape(-1, 1)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__setitem__","title":"<code>__setitem__</code>","text":"<p>Store node, edge, or graph attribute.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>name of attribute to be stored</p> required <code>val</code> <code>torch.Tensor</code> <p>value of attribute</p> required Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __setitem__(self, key: str, val: torch.Tensor) -&gt; None:\n    \"\"\"Store node, edge, or graph attribute.\n\n    Args:\n        key: name of attribute to be stored\n        val: value of attribute\n    \"\"\"\n    if not isinstance(key, tuple):\n        if key.startswith(\"node_\"):\n            if val.size(0) != self.n:\n                raise ValueError(\"Attribute must have same length as number of nodes\")\n            self.data[key] = val\n        elif key.startswith(\"edge_\"):\n            if val.size(0) != self.m:\n                raise ValueError(\"Attribute must have same length as number of edges\")\n            self.data[key] = val\n        else:\n            self.data[key] = val\n    elif key[0].startswith(\"node_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.mapping.to_idx(key[1])] = val\n    elif key[0].startswith(\"edge_\"):  # type: ignore\n        if key[0] not in self.data.keys():\n            raise KeyError(\n                \"Attribute does not yet exist. Setting the value of a specific node attribute\"\n                + \"requires that the attribute already exists.\"\n            )\n        self.data[key[0]][self.edge_to_index[self.mapping.to_idx(key[1]), self.mapping.to_idx(key[2])]] = val\n    else:\n        raise KeyError(\"node and edge specific attributes should be prefixed with 'node_' or 'edge_'\")\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.__str__","title":"<code>__str__</code>","text":"<p>Return a string representation of the graph.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a string representation of the graph.\"\"\"\n\n    attr = self.data.to_dict()\n    attr_types = {}\n    for k in attr:\n        t = type(attr[k])\n        if t == torch.Tensor:\n            attr_types[k] = str(t) + \" -&gt; \" + str(attr[k].size())\n        else:\n            attr_types[k] = str(t)\n\n    from pprint import pformat\n\n    if self.is_undirected():\n        s = \"Undirected graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n    else:\n        s = \"Directed graph with {0} nodes and {1} edges\\n\".format(self.n, self.m)\n\n    attribute_info = {\"Node Attributes\": {}, \"Edge Attributes\": {}, \"Graph Attributes\": {}}\n    for a in self.node_attrs():\n        attribute_info[\"Node Attributes\"][a] = attr_types[a]\n    for a in self.edge_attrs():\n        attribute_info[\"Edge Attributes\"][a] = attr_types[a]\n    for a in self.data.keys():\n        if not self.data.is_node_attr(a) and not self.data.is_edge_attr(a):\n            attribute_info[\"Graph Attributes\"][a] = attr_types[a]\n    s += pformat(attribute_info, indent=4, width=160)\n    return s\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.degrees","title":"<code>degrees</code>","text":"<p>Return (weighted) degrees of nodes.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p><code>in</code> or <code>out</code> to calculate in- or out-degree for directed networks.</p> <code>'in'</code> <code>edge_attr</code> <code>typing.Any</code> <p>Optional numerical edge attribute that will  be used to compute weighted degrees</p> <code>None</code> <code>return_tensor</code> <code>bool</code> <p>if True the function returns a degree tensor, if False (default) a dictionary will be returned that can be indexed by nodes</p> <code>False</code> <p>Returns:     dict: dictionary containing node degrees</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def degrees(self, mode: str = \"in\", edge_attr: Any = None, return_tensor: bool = False) -&gt; Union[Dict[str, float],\n                                                                                                 torch.tensor]:\n    \"\"\"\n    Return (weighted) degrees of nodes.\n\n    Args:\n        mode: `in` or `out` to calculate in- or out-degree for\n            directed networks.\n        edge_attr: Optional numerical edge attribute that will \n            be used to compute weighted degrees\n        return_tensor: if True the function returns a degree tensor, if False (default)\n            a dictionary will be returned that can be indexed by nodes\n    Returns:\n        dict: dictionary containing node degrees\n    \"\"\"\n    if mode == \"in\":\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[1], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[1], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    else:\n        if not edge_attr:\n            d = torch_geometric.utils.degree(self.data.edge_index[0], num_nodes=self.n, dtype=torch.int)\n        else:\n            edge_weight = getattr(self.data, edge_attr, None)\n            d = scatter(edge_weight, self.data.edge_index[0], dim=0, dim_size=self.data.num_nodes, reduce=\"sum\")\n    if return_tensor:\n        return d\n    else:\n        return {str(self.mapping.to_id(i)): d[i].item() for i in range(self.n)}\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.edge_attrs","title":"<code>edge_attrs</code>","text":"<p>Return a list of edge attributes.</p> <p>This method returns a list containing the names of all edge-level attributes, ignoring the special <code>edge_index</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of edge attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def edge_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of edge attributes.\n\n    This method returns a list containing the names of all edge-level attributes,\n    ignoring the special `edge_index` attribute.\n\n    Returns:\n        list: list of edge attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"edge_index\" and k.startswith(\"edge_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.from_edge_index","title":"<code>from_edge_index</code>  <code>staticmethod</code>","text":"<p>Construct a graph from a torch Tensor containing an edge index. An optional mapping can be used to transparently map node indices to string identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>edge_index</code> <code>torch.Tensor</code> <p>torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index</p> required <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p><code>IndexMap</code> object that maps node indices to string identifiers</p> <code>None</code> <code>num_nodes</code> <code>int</code> <p>optional number of nodes (default: None). If None, the number of nodes will be inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.</p> <code>None</code> <p>Examples:</p> <p>You can create a graph from an edge index tensor as follows:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n&gt;&gt;&gt; print(g)\nDirected graph with 3 nodes and 3 edges ...\n</code></pre> <p>You can also include a mapping of node IDs:</p> <pre><code>&gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n&gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n&gt;&gt;&gt; print(g.mapping)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_index(edge_index: torch.Tensor, mapping: Optional[IndexMap] = None, num_nodes: int = None) -&gt; Graph:\n    \"\"\"Construct a graph from a torch Tensor containing an edge index. An optional mapping can\n    be used to transparently map node indices to string identifiers.\n\n    Args:\n        edge_index:  torch.Tensor or torch_geometric.EdgeIndex object containing an edge_index\n        mapping: `IndexMap` object that maps node indices to string identifiers\n        num_nodes: optional number of nodes (default: None). If None, the number of nodes will be\n            inferred based on the maximum node index in the edge index, i.e. there will be no isolated nodes.\n\n    Examples:\n        You can create a graph from an edge index tensor as follows:\n\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]))\n        &gt;&gt;&gt; print(g)\n        Directed graph with 3 nodes and 3 edges ...\n\n        You can also include a mapping of node IDs:\n\n        &gt;&gt;&gt; g = pp.Graph.from_edge_index(torch.LongTensor([[1, 1, 2], [0, 2, 1]]),\n        &gt;&gt;&gt;                              mapping=pp.IndexMap(['a', 'b', 'c']))\n        &gt;&gt;&gt; print(g.mapping)\n        a -&gt; 0\n        b -&gt; 1\n        c -&gt; 2\n    \"\"\"\n\n    if not num_nodes:\n        d = Data(edge_index=edge_index)\n    else:\n        if mapping is not None and mapping.num_ids() != num_nodes:\n            logger.error(\"Number of node IDs in mapping must match num_nodes\")\n            raise ValueError(\"Number of node IDs in mapping must match num_nodes\")\n        d = Data(edge_index=edge_index, num_nodes=num_nodes)\n    return Graph(d, mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.from_edge_list","title":"<code>from_edge_list</code>  <code>staticmethod</code>","text":"<p>Generate a Graph based on an edge list.</p> <p>Edges can be given as string or integer tuples. If strings are used and no mapping is given, a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of node IDs.</p> <p>Parameters:</p> Name Type Description Default <code>edge_list</code> <code>typing.Iterable[typing.Tuple[str, str]]</code> <p>Iterable of edges represented as tuples</p> required <code>is_undirected</code> <code>bool</code> <p>Whether the edge list contains all bidorectional edges</p> <code>False</code> <code>mapping</code> <code>typing.Optional[pathpyG.core.index_map.IndexMap]</code> <p>optional mapping of string IDs to node indices</p> <code>None</code> <code>device</code> <code>typing.Optional[torch.device]</code> <p>optional torch device where tensors shall be stored</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n&gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n&gt;&gt;&gt; print(list(g.edges))\n[('a', 'b'), ('a', 'c'), ('b', 'c')]\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>@staticmethod\ndef from_edge_list(\n    edge_list: Iterable[Tuple[str, str]],\n    is_undirected: bool = False,\n    mapping: Optional[IndexMap] = None,\n    device: Optional[torch.device] = None,\n) -&gt; Graph:\n    \"\"\"Generate a Graph based on an edge list.\n\n    Edges can be given as string or integer tuples. If strings are used and no mapping is given,\n    a mapping of node IDs to indices will be automatically created based on a lexicographic ordering of\n    node IDs.\n\n    Args:\n        edge_list: Iterable of edges represented as tuples\n        is_undirected: Whether the edge list contains all bidorectional edges\n        mapping: optional mapping of string IDs to node indices\n        device: optional torch device where tensors shall be stored\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; l = [('a', 'b'), ('a', 'c'), ('b', 'c')]\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list(l)\n        &gt;&gt;&gt; print(list(g.edges))\n        [('a', 'b'), ('a', 'c'), ('b', 'c')]\n    \"\"\"\n\n    # handle empty graph\n    if len(edge_list) == 0:\n        return Graph(\n            Data(edge_index=torch.tensor([[], []], dtype=torch.int32, device=device), num_nodes=0),\n            mapping=IndexMap(),\n        )\n\n    if mapping is None:\n        edge_array = np.array(edge_list)\n        node_ids = np.unique(edge_array)\n        if np.issubdtype(node_ids.dtype, str) and np.char.isnumeric(node_ids).all():\n            node_ids = np.sort(node_ids.astype(int)).astype(str)\n        mapping = IndexMap(node_ids)\n\n    num_nodes = mapping.num_ids()\n\n    edge_index = EdgeIndex(\n        mapping.to_idxs(edge_list, device=device).T.contiguous(),\n        sparse_size=(num_nodes, num_nodes),\n        is_undirected=is_undirected,\n    )\n    return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_predecessors","title":"<code>get_predecessors</code>","text":"<p>Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>col_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all predecessor nodes of the node indexed by <code>col_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_predecessors(self, col_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all predecessor nodes for a given node identified by an index.\n\n    Args:\n        col_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all predecessor nodes of the node indexed by `col_idx`\n    \"\"\"\n    if col_idx + 1 &lt; self.col_ptr.size(0):\n        col_start = self.col_ptr[col_idx]\n        col_end = self.col_ptr[col_idx + 1]\n        return self.row[col_start:col_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.get_successors","title":"<code>get_successors</code>","text":"<p>Return a tensor containing the indices of all successor nodes for a given node identified by an index.</p> <p>Parameters:</p> Name Type Description Default <code>row_idx</code> <code>int</code> <p>Index of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>tensor containing indices of all successor nodes of the node indexed by <code>row_idx</code></p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def get_successors(self, row_idx: int) -&gt; torch.Tensor:\n    \"\"\"Return a tensor containing the indices of all successor nodes for a given node identified by an index.\n\n    Args:\n        row_idx:   Index of node for which predecessors shall be returned.\n\n    Returns:\n        tensor: tensor containing indices of all successor nodes of the node indexed by `row_idx`\n    \"\"\"\n\n    if row_idx + 1 &lt; self.row_ptr.size(0):\n        row_start = self.row_ptr[row_idx]\n        row_end = self.row_ptr[row_idx + 1]\n        return self.col[row_start:row_end]\n    else:\n        return torch.tensor([], device=self.data.edge_index.device)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.has_self_loops","title":"<code>has_self_loops</code>","text":"<p>Return whether graph contains self-loops.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph contains self-loops, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def has_self_loops(self) -&gt; bool:\n    \"\"\"Return whether graph contains self-loops.\n\n    Returns:\n        bool: True if graph contains self-loops, False otherwise\n    \"\"\"\n    return self.data.has_self_loops()\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_directed","title":"<code>is_directed</code>","text":"<p>Return whether graph is directed.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is directed, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_directed(self) -&gt; bool:\n    \"\"\"Return whether graph is directed.\n\n    Returns:\n        bool: True if graph is directed, False otherwise\n    \"\"\"\n    return not self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_edge","title":"<code>is_edge</code>","text":"<p>Return whether edge \\((v,w)\\) exists in the graph.</p> <p>If an index to ID mapping is used, nodes are assumed to be string IDs. If no mapping is used, nodes are assumed to be integer indices.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>typing.Union[str, int]</code> <p>source node of edge as integer index or string ID</p> required <code>w</code> <code>typing.Union[str, int]</code> <p>target node of edge as integer index or string ID</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if edge exists, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_edge(self, v: Union[str, int], w: Union[str, int]) -&gt; bool:\n    \"\"\"Return whether edge $(v,w)$ exists in the graph.\n\n    If an index to ID mapping is used, nodes are assumed to be string IDs. If no\n    mapping is used, nodes are assumed to be integer indices.\n\n    Args:\n        v: source node of edge as integer index or string ID\n        w: target node of edge as integer index or string ID\n\n    Returns:\n        bool: True if edge exists, False otherwise\n    \"\"\"\n    row = self.mapping.to_idx(v)\n    row_start = self.row_ptr[row]\n    row_end = self.row_ptr[row + 1]\n\n    return self.mapping.to_idx(w) in self.col[row_start:row_end]\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.is_undirected","title":"<code>is_undirected</code>","text":"<p>Return whether graph is undirected.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if graph is undirected, False otherwise</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def is_undirected(self) -&gt; bool:\n    \"\"\"Return whether graph is undirected.\n\n    Returns:\n        bool: True if graph is undirected, False otherwise\n    \"\"\"\n    return self.data.edge_index.is_undirected\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.laplacian","title":"<code>laplacian</code>","text":"<p>Return Laplacian matrix for a given graph.</p> <p>This wrapper method will use <code>torch_geometric.utils.laplacian</code> to return a Laplcian matrix representation of a given graph.</p> <p>Parameters:</p> Name Type Description Default <code>normalization</code> <code>typing.Any</code> <p>normalization parameter passed to pyG <code>get_laplacian</code> function</p> <code>None</code> <code>edge_attr</code> <code>typing.Any</code> <p>optinal name of numerical edge attribute that shall be passed to pyG <code>get_laplacian</code> function as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: Laplacian matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def laplacian(self, normalization: Any = None, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return Laplacian matrix for a given graph.\n\n    This wrapper method will use [`torch_geometric.utils.laplacian`](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.laplacian)\n    to return a Laplcian matrix representation of a given graph.\n\n    Args:\n        normalization: normalization parameter passed to pyG `get_laplacian`\n            function\n        edge_attr: optinal name of numerical edge attribute that shall\n            be passed to pyG `get_laplacian` function as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: Laplacian matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(), normalization=normalization\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n    else:\n        index, weight = torch_geometric.utils.get_laplacian(\n            self.data.edge_index.as_tensor(),\n            normalization=normalization,\n            edge_weight=self.data[edge_attr],\n        )\n        return torch_geometric.utils.to_scipy_sparse_matrix(index, weight)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.node_attrs","title":"<code>node_attrs</code>","text":"<p>Return a list of node attributes.</p> <p>This method returns a list containing the names of all node-level attributes, ignoring the special <code>node_sequence</code> attribute.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>typing.List[str]</code> <p>list of node attributes</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def node_attrs(self) -&gt; List[str]:\n    \"\"\"\n    Return a list of node attributes.\n\n    This method returns a list containing the names of all node-level attributes,\n    ignoring the special `node_sequence` attribute.\n\n    Returns:\n        list: list of node attributes\n    \"\"\"\n    attrs = []\n    for k in self.data.keys():\n        if k != \"node_sequence\" and k.startswith(\"node_\"):\n            attrs.append(k)\n    return attrs\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.predecessors","title":"<code>predecessors</code>","text":"<p>Return the predecessors of a given node.</p> <p>This method returns a generator object that yields all predecessors of a given node. If a <code>node_id</code> mapping is used, predecessors will be returned as string IDs. If no mapping is used, predecessors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[str, int] | tuple</code> <p>Index or string ID of node for which predecessors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all predecessors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def predecessors(self, node: Union[str, int] | tuple) -&gt; list:\n    \"\"\"Return the predecessors of a given node.\n\n    This method returns a generator object that yields all predecessors of a\n    given node. If a `node_id` mapping is used, predecessors will be returned\n    as string IDs. If no mapping is used, predecessors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which predecessors shall be returned.\n\n    Returns:\n        list: list with all predecessors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n    node_list = self.mapping.to_ids(self.get_predecessors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.sparse_adj_matrix","title":"<code>sparse_adj_matrix</code>","text":"<p>Return sparse adjacency matrix representation of (weighted) graph.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>the edge attribute that shall be used as edge weight</p> <code>None</code> <p>Returns:</p> Type Description <code>typing.Any</code> <p>scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def sparse_adj_matrix(self, edge_attr: Any = None) -&gt; Any:\n    \"\"\"Return sparse adjacency matrix representation of (weighted) graph.\n\n    Args:\n        edge_attr: the edge attribute that shall be used as edge weight\n\n    Returns:\n        scipy.sparse.coo_matrix: sparse adjacency matrix representation of graph\n    \"\"\"\n    if edge_attr is None:\n        return torch_geometric.utils.to_scipy_sparse_matrix(self.data.edge_index.as_tensor(), num_nodes=self.n)\n    else:\n        return torch_geometric.utils.to_scipy_sparse_matrix(\n            self.data.edge_index.as_tensor(), edge_attr=self.data[edge_attr], num_nodes=self.n\n        )\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.successors","title":"<code>successors</code>","text":"<p>Return all successors of a given node.</p> <p>This method returns a generator object that yields all successors of a given node. If an IndexMap is used, successors are returned as string IDs. If no mapping is used, successors are returned as indices.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>typing.Union[int, str] | tuple</code> <p>Index or string ID of node for which successors shall be returned.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>list with all successors of the node identified by <code>node</code> using ID or index (if no mapping is used)</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def successors(self, node: Union[int, str] | tuple) -&gt; list:\n    \"\"\"Return all successors of a given node.\n\n    This method returns a generator object that yields all successors of a\n    given node. If an IndexMap is used, successors are returned\n    as string IDs. If no mapping is used, successors are returned as indices.\n\n    Args:\n        node:   Index or string ID of node for which successors shall be returned.\n\n    Returns:\n        list: list with all successors of the node identified\n            by `node` using ID or index (if no mapping is used)\n    \"\"\"\n\n    node_list = self.mapping.to_ids(self.get_successors(self.mapping.to_idx(node))).tolist()  # type: ignore\n\n    if self.order &gt; 1:\n        return list(map(tuple, node_list))\n    return node_list\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to","title":"<code>to</code>","text":"<p>Move all tensors to the given device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>torch device to which all tensors shall be moved</p> required <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>self</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to(self, device: torch.device) -&gt; Graph:\n    \"\"\"Move all tensors to the given device.\n\n    Args:\n        device: torch device to which all tensors shall be moved\n\n    Returns:\n        Graph: self\n    \"\"\"\n    self.data.edge_index = self.data.edge_index.to(device)\n    self.data.node_sequence = self.data.node_sequence.to(device)\n    for attr in self.node_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n    for attr in self.edge_attrs():\n        if isinstance(self.data[attr], torch.Tensor):\n            self.data[attr] = self.data[attr].to(device)\n\n    self.row = self.row.to(device)\n    self.row_ptr = self.row_ptr.to(device)\n    self.col = self.col.to(device)\n    self.col_ptr = self.col_ptr.to(device)\n\n    return self\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to_undirected","title":"<code>to_undirected</code>","text":"<p>Return an undirected version of this directed graph.</p> <p>This method creates a new undirected Graph from the current graph instance by adding all directed edges in opposite direction.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n&gt;&gt;&gt; g_u = g.to_undirected()\n&gt;&gt;&gt; print(g_u)\nUndirected graph with 3 nodes and 6 (directed) edges\n</code></pre> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_undirected(self) -&gt; Graph:\n    \"\"\"Return an undirected version of this directed graph.\n\n    This method creates a new undirected Graph from the current graph instance by\n    adding all directed edges in opposite direction.\n\n    Examples:\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a')])\n        &gt;&gt;&gt; g_u = g.to_undirected()\n        &gt;&gt;&gt; print(g_u)\n        Undirected graph with 3 nodes and 6 (directed) edges\n    \"\"\"\n    # create undirected edge index by coalescing the directed edges and keep\n    # track of the original edge index for the edge attributes\n    attr_idx = torch.arange(self.data.num_edges, device=self.data.edge_index.device)\n    edge_index, attr_idx = to_undirected(\n        self.data.edge_index,\n        edge_attr=attr_idx,\n        num_nodes=self.data.num_nodes,\n        reduce=\"min\",\n    )\n\n    data = Data(\n        edge_index=EdgeIndex(\n            data=edge_index, sparse_size=(self.data.num_nodes, self.data.num_nodes), is_undirected=True\n        ),\n        num_nodes=self.data.num_nodes,\n    )\n    # Note that while the torch_geometric.transforms.ToUndirected function would do this automatically,\n    # we do it manually since the transform cannot handle numpy arrays as edge attributes.\n    # make sure to copy all node and (undirected) edge attributes\n    for node_attr in self.node_attrs():\n        data[node_attr] = self.data[node_attr]\n    for edge_attr in self.edge_attrs():\n        if edge_attr != \"edge_index\":\n            data[edge_attr] = self.data[edge_attr][attr_idx]\n\n    return Graph(data, self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.to_weighted_graph","title":"<code>to_weighted_graph</code>","text":"<p>Coalesces multi-edges to single-edges with an additional weight attribute</p> <p>If the graph contains multiple edges between the same nodes, this method will coalesce them into a single edge with an additional weight attribute called <code>edge_weight</code> that contains the number of coalesced edges. The method returns a new graph instance with the coalesced edges.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>pathpyG.core.graph.Graph</code> <p>Graph with coalesced edges</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def to_weighted_graph(self) -&gt; Graph:\n    \"\"\"Coalesces multi-edges to single-edges with an additional weight attribute\n\n    If the graph contains multiple edges between the same nodes, this method will coalesce\n    them into a single edge with an additional weight attribute called `edge_weight` that\n    contains the number of coalesced edges. The method returns a new graph instance with\n    the coalesced edges.\n\n    Returns:\n        Graph: Graph with coalesced edges\n    \"\"\"\n    i, w = torch_geometric.utils.coalesce(\n        self.data.edge_index.as_tensor(), torch.ones(self.m, device=self.data.edge_index.device)\n    )\n    return Graph(Data(edge_index=i, edge_weight=w, num_nodes=self.data.num_nodes), mapping=self.mapping)\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.Graph.transition_probabilities","title":"<code>transition_probabilities</code>","text":"<p>Compute transition probabilities based on (weighted) outdegrees.</p> <p>Parameters:</p> Name Type Description Default <code>edge_attr</code> <code>typing.Any</code> <p>Optional name of numerical edge attribute that will         will be used to calculate weighted out-degrees for the         visitation probabilities.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tensor</code> <code>torch.Tensor</code> <p>Transition probabilities.</p> Source code in <code>src/pathpyG/core/graph.py</code> <pre><code>def transition_probabilities(self, edge_attr: Any = None) -&gt; torch.Tensor:\n    \"\"\"\n    Compute transition probabilities based on (weighted) outdegrees.\n\n    Args:\n        edge_attr: Optional name of numerical edge attribute that will\n                    will be used to calculate weighted out-degrees for the\n                    visitation probabilities.\n\n    Returns:\n        tensor: Transition probabilities.\n    \"\"\"\n    weighted_outdegree = self.degrees(mode=\"out\", edge_attr=edge_attr, return_tensor=True)\n    source_ids = self.data.edge_index[0]        \n    edge_weight = torch.ones(self.data.num_edges, device=self.data.edge_index.device)\n    if edge_attr:\n        edge_weight = getattr(self.data, edge_attr, None)\n    return edge_weight / weighted_outdegree[source_ids]\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.closed_triads","title":"<code>closed_triads</code>","text":"<p>Calculates the set of edges that represent a closed triad around a given node v.</p>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.closed_triads--parameters","title":"Parameters","text":"<p>network : Network</p> <pre><code>The network in which to calculate the list of closed triads\n</code></pre> Source code in <code>src/pathpyG/statistics/clustering.py</code> <pre><code>def closed_triads(g: Graph, v: str) -&gt; Set:\n    \"\"\"Calculates the set of edges that represent a closed triad\n    around a given node v.\n\n    Parameters\n    ----------\n\n    network : Network\n\n        The network in which to calculate the list of closed triads\n\n    \"\"\"\n    c_triads: set = set()\n    edges = set()\n\n    # Collect all edges of successors\n    for x in g.successors(v):\n        for y in g.successors(x):\n            edges.add((x, y))\n\n    for x, y in edges:\n        if y in g.successors(v):\n            c_triads.add((x, y))\n    return c_triads\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_assortativity","title":"<code>degree_assortativity</code>","text":"<p>Calculate the degree assortativity</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_assortativity(g: Graph, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculate the degree assortativity\"\"\"\n\n    A = g.sparse_adj_matrix().todense()\n    m = _np.sum(A)\n\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n    elif not g.is_directed():\n        m = m / 2.0\n\n    cov = 0.0\n    var = 0.0\n    for i in g.nodes:\n        for j in g.nodes:\n            cov += (A[g.mapping.to_idx(i), g.mapping.to_idx(j)] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n            if i != j:\n                var -= (d[i] * d[j]) / (2 * m) * d[i] * d[j]\n            else:\n                var += (d[i] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n    return cov / var\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_central_moment","title":"<code>degree_central_moment</code>","text":"<p>Calculates the k-th central moment of the degree distribution.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which to calculate the k-th central moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_central_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th central moment of the degree distribution.\n\n    Args:\n        graph: The graph for which to calculate the k-th central moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mean = _np.mean(degree_sequence(graph, mode=mode))\n    m = 0.0\n    for x in p_k:\n        m += (x - mean) ** k * p_k[x]\n    return m\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_distribution","title":"<code>degree_distribution</code>","text":"<p>Calculates the (unweighted) degree distribution of a graph</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_distribution(g: Graph, mode: str = \"total\") -&gt; Dict[int, float]:\n    \"\"\"Calculates the (unweighted) degree distribution of a graph\"\"\"\n    d = g.degrees(mode, return_tensor=False)    \n\n    cnt: defaultdict = defaultdict(float)\n    for v in g.nodes:\n        cnt[d[v]] += 1.0 / g.n\n    return cnt\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_generating_function","title":"<code>degree_generating_function</code>","text":"<p>Returns the generating function of the degree distribution of a network,     calculated for either a single argument x or a list or numpy array of arguments x</p> <p>Returns f(x) where f is the probability generating function for the degree distribution P(k) for a graph. The function is defined in the interval [0,1].  The value returned is from the range [0,1]. The following properties hold:</p> <p>[1/k! d^k/dx f]_{x=0} = P(k) with d^k/dx f being the k-th derivative of f by x</p> <p>f'(1) =  with f' being the first derivative and  the mean degree <p>[(x d/dx)^m f]_{x=1} =  with  being the m-th raw moment of P <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which the generating function shall be computed</p> required float, list, numpy.ndarray <p>The argument(s) for which value(s) f(x) shall be computed.</p> <p>Example: <pre><code>    # Generate simple network\n    import pathpyG as pp\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n    # Return single function value\n    val = pp.statistics.degreee_generating_func(n, 0.3)\n    print(val)\n    0.069\n\n    # Plot generating function of degree distribution\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func(n, x)\n    x = plt.plot(x, y)\n    # [Function plot]\n\n    # Plot generating function based on degree sequence\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func([1,2,1,2], x)\n    x = plt.plot(x, y)\n    # [Function plot]\n</code></pre></p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_generating_function(\n    graph: Graph, x: float | list[float] | _np.ndarray, mode: str = \"total\"\n) -&gt; float | _np.ndarray:\n    \"\"\"Returns the generating function of the degree distribution of a network,\n        calculated for either a single argument x or a list or numpy array of arguments x\n\n\n    Returns f(x) where f is the probability generating function for the degree\n    distribution P(k) for a graph. The function is defined in the interval\n    [0,1].  The value returned is from the range [0,1]. The following properties\n    hold:\n\n    [1/k! d^k/dx f]_{x=0} = P(k)\n    with d^k/dx f being the k-th derivative of f by x\n\n    f'(1) = &lt;k&gt;\n    with f' being the first derivative and &lt;k&gt; the mean degree\n\n    [(x d/dx)^m f]_{x=1} = &lt;k^m&gt;\n    with &lt;k^m&gt; being the m-th raw moment of P\n\n    Args:\n        graph: The graph for which the generating function shall be computed\n\n    x:  float, list, numpy.ndarray\n        The argument(s) for which value(s) f(x) shall be computed.\n\n    Example:\n    ```py\n        # Generate simple network\n        import pathpyG as pp\n        import numpy as np\n        import matplotlib.pyplot as plt\n\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                    ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n        # Return single function value\n        val = pp.statistics.degreee_generating_func(n, 0.3)\n        print(val)\n        0.069\n\n        # Plot generating function of degree distribution\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func(n, x)\n        x = plt.plot(x, y)\n        # [Function plot]\n\n        # Plot generating function based on degree sequence\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func([1,2,1,2], x)\n        x = plt.plot(x, y)\n        # [Function plot]\n    ```\n    \"\"\"\n\n    p_k = degree_distribution(graph, mode=mode)\n\n    if isinstance(x, float):\n        x_range = [x]\n    else:\n        x_range = x\n\n    values: defaultdict = defaultdict(float)\n    for k in p_k:\n        for v in x_range:\n            values[v] += p_k[k] * v**k\n\n    _values: float | _np.ndarray\n    if len(x_range) &gt; 1:\n        _values = _np.fromiter(values.values(), dtype=float)\n    else:\n        _values = values[x]\n    return _values\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_raw_moment","title":"<code>degree_raw_moment</code>","text":"<p>Calculates the k-th raw moment of the degree distribution of a network</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph in which to calculate the k-th raw moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_raw_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th raw moment of the degree distribution of a network\n\n    Args:\n        graph:  The graph in which to calculate the k-th raw moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mom = 0.0\n    for x in p_k:\n        mom += x**k * p_k[x]\n    return mom\n</code></pre>"},{"location":"reference/pathpyG/statistics/#pathpyG.statistics.degree_sequence","title":"<code>degree_sequence</code>","text":"<p>Calculates the (unweighted) degree sequence of an undirected network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <p>The <code>Graph</code> object for which degrees are calculated</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_sequence(g: Graph, mode: str = \"total\") -&gt; _np.array:\n    \"\"\"Calculates the (unweighted) degree sequence of an undirected network.\n\n    Args:\n        graph: The `Graph` object for which degrees are calculated\n    \"\"\"\n    return g.degrees(mode, return_tensor=True).detach().numpy()\n</code></pre>"},{"location":"reference/pathpyG/statistics/clustering/","title":"clustering","text":""},{"location":"reference/pathpyG/statistics/clustering/#pathpyG.statistics.clustering.closed_triads","title":"<code>closed_triads</code>","text":"<p>Calculates the set of edges that represent a closed triad around a given node v.</p>"},{"location":"reference/pathpyG/statistics/clustering/#pathpyG.statistics.clustering.closed_triads--parameters","title":"Parameters","text":"<p>network : Network</p> <pre><code>The network in which to calculate the list of closed triads\n</code></pre> Source code in <code>src/pathpyG/statistics/clustering.py</code> <pre><code>def closed_triads(g: Graph, v: str) -&gt; Set:\n    \"\"\"Calculates the set of edges that represent a closed triad\n    around a given node v.\n\n    Parameters\n    ----------\n\n    network : Network\n\n        The network in which to calculate the list of closed triads\n\n    \"\"\"\n    c_triads: set = set()\n    edges = set()\n\n    # Collect all edges of successors\n    for x in g.successors(v):\n        for y in g.successors(x):\n            edges.add((x, y))\n\n    for x, y in edges:\n        if y in g.successors(v):\n            c_triads.add((x, y))\n    return c_triads\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/","title":"degrees","text":""},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_assortativity","title":"<code>degree_assortativity</code>","text":"<p>Calculate the degree assortativity</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_assortativity(g: Graph, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculate the degree assortativity\"\"\"\n\n    A = g.sparse_adj_matrix().todense()\n    m = _np.sum(A)\n\n    d = g.degrees()\n    if g.is_directed() and mode == \"in\":\n        d = g.in_degrees\n    elif g.is_directed() and mode == \"out\":\n        d = g.out_degrees\n    elif g.is_directed() and mode == \"total\":\n        d = g.degrees()\n    elif not g.is_directed():\n        m = m / 2.0\n\n    cov = 0.0\n    var = 0.0\n    for i in g.nodes:\n        for j in g.nodes:\n            cov += (A[g.mapping.to_idx(i), g.mapping.to_idx(j)] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n            if i != j:\n                var -= (d[i] * d[j]) / (2 * m) * d[i] * d[j]\n            else:\n                var += (d[i] - (d[i] * d[j]) / (2 * m)) * d[i] * d[j]\n    return cov / var\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_central_moment","title":"<code>degree_central_moment</code>","text":"<p>Calculates the k-th central moment of the degree distribution.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which to calculate the k-th central moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_central_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th central moment of the degree distribution.\n\n    Args:\n        graph: The graph for which to calculate the k-th central moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mean = _np.mean(degree_sequence(graph, mode=mode))\n    m = 0.0\n    for x in p_k:\n        m += (x - mean) ** k * p_k[x]\n    return m\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_distribution","title":"<code>degree_distribution</code>","text":"<p>Calculates the (unweighted) degree distribution of a graph</p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_distribution(g: Graph, mode: str = \"total\") -&gt; Dict[int, float]:\n    \"\"\"Calculates the (unweighted) degree distribution of a graph\"\"\"\n    d = g.degrees(mode, return_tensor=False)    \n\n    cnt: defaultdict = defaultdict(float)\n    for v in g.nodes:\n        cnt[d[v]] += 1.0 / g.n\n    return cnt\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_generating_function","title":"<code>degree_generating_function</code>","text":"<p>Returns the generating function of the degree distribution of a network,     calculated for either a single argument x or a list or numpy array of arguments x</p> <p>Returns f(x) where f is the probability generating function for the degree distribution P(k) for a graph. The function is defined in the interval [0,1].  The value returned is from the range [0,1]. The following properties hold:</p> <p>[1/k! d^k/dx f]_{x=0} = P(k) with d^k/dx f being the k-th derivative of f by x</p> <p>f'(1) =  with f' being the first derivative and  the mean degree <p>[(x d/dx)^m f]_{x=1} =  with  being the m-th raw moment of P <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph for which the generating function shall be computed</p> required float, list, numpy.ndarray <p>The argument(s) for which value(s) f(x) shall be computed.</p> <p>Example: <pre><code>    # Generate simple network\n    import pathpyG as pp\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n    # Return single function value\n    val = pp.statistics.degreee_generating_func(n, 0.3)\n    print(val)\n    0.069\n\n    # Plot generating function of degree distribution\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func(n, x)\n    x = plt.plot(x, y)\n    # [Function plot]\n\n    # Plot generating function based on degree sequence\n\n    x = np.linspace(0, 1, 20)\n    y = pp.statistics.degree_generating_func([1,2,1,2], x)\n    x = plt.plot(x, y)\n    # [Function plot]\n</code></pre></p> Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_generating_function(\n    graph: Graph, x: float | list[float] | _np.ndarray, mode: str = \"total\"\n) -&gt; float | _np.ndarray:\n    \"\"\"Returns the generating function of the degree distribution of a network,\n        calculated for either a single argument x or a list or numpy array of arguments x\n\n\n    Returns f(x) where f is the probability generating function for the degree\n    distribution P(k) for a graph. The function is defined in the interval\n    [0,1].  The value returned is from the range [0,1]. The following properties\n    hold:\n\n    [1/k! d^k/dx f]_{x=0} = P(k)\n    with d^k/dx f being the k-th derivative of f by x\n\n    f'(1) = &lt;k&gt;\n    with f' being the first derivative and &lt;k&gt; the mean degree\n\n    [(x d/dx)^m f]_{x=1} = &lt;k^m&gt;\n    with &lt;k^m&gt; being the m-th raw moment of P\n\n    Args:\n        graph: The graph for which the generating function shall be computed\n\n    x:  float, list, numpy.ndarray\n        The argument(s) for which value(s) f(x) shall be computed.\n\n    Example:\n    ```py\n        # Generate simple network\n        import pathpyG as pp\n        import numpy as np\n        import matplotlib.pyplot as plt\n\n        g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('a', 'c'), ('c', 'd'),\n                                    ('d', 'e'), ('d', 'f'), ('e', 'f')]).to_undirected()\n\n        # Return single function value\n        val = pp.statistics.degreee_generating_func(n, 0.3)\n        print(val)\n        0.069\n\n        # Plot generating function of degree distribution\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func(n, x)\n        x = plt.plot(x, y)\n        # [Function plot]\n\n        # Plot generating function based on degree sequence\n\n        x = np.linspace(0, 1, 20)\n        y = pp.statistics.degree_generating_func([1,2,1,2], x)\n        x = plt.plot(x, y)\n        # [Function plot]\n    ```\n    \"\"\"\n\n    p_k = degree_distribution(graph, mode=mode)\n\n    if isinstance(x, float):\n        x_range = [x]\n    else:\n        x_range = x\n\n    values: defaultdict = defaultdict(float)\n    for k in p_k:\n        for v in x_range:\n            values[v] += p_k[k] * v**k\n\n    _values: float | _np.ndarray\n    if len(x_range) &gt; 1:\n        _values = _np.fromiter(values.values(), dtype=float)\n    else:\n        _values = values[x]\n    return _values\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_raw_moment","title":"<code>degree_raw_moment</code>","text":"<p>Calculates the k-th raw moment of the degree distribution of a network</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>The graph in which to calculate the k-th raw moment</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_raw_moment(graph: Graph, k: int = 1, mode: str = \"total\") -&gt; float:\n    \"\"\"Calculates the k-th raw moment of the degree distribution of a network\n\n    Args:\n        graph:  The graph in which to calculate the k-th raw moment\n\n    \"\"\"\n    p_k = degree_distribution(graph, mode=mode)\n    mom = 0.0\n    for x in p_k:\n        mom += x**k * p_k[x]\n    return mom\n</code></pre>"},{"location":"reference/pathpyG/statistics/degrees/#pathpyG.statistics.degrees.degree_sequence","title":"<code>degree_sequence</code>","text":"<p>Calculates the (unweighted) degree sequence of an undirected network.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <p>The <code>Graph</code> object for which degrees are calculated</p> required Source code in <code>src/pathpyG/statistics/degrees.py</code> <pre><code>def degree_sequence(g: Graph, mode: str = \"total\") -&gt; _np.array:\n    \"\"\"Calculates the (unweighted) degree sequence of an undirected network.\n\n    Args:\n        graph: The `Graph` object for which degrees are calculated\n    \"\"\"\n    return g.degrees(mode, return_tensor=True).detach().numpy()\n</code></pre>"},{"location":"reference/pathpyG/statistics/node_similarities/","title":"node_similarities","text":""},{"location":"reference/pathpyG/utils/","title":"utils","text":""},{"location":"reference/pathpyG/utils/config/","title":"config","text":"<p>Config reader.</p>"},{"location":"reference/pathpyG/utils/convert/","title":"convert","text":"<p>Utility functions for converting between different data types.</p>"},{"location":"reference/pathpyG/utils/convert/#pathpyG.utils.convert.to_numpy","title":"<code>to_numpy</code>","text":"<p>Convert an iterable (including a tensor or tensor subclasses like <code>torch_geometric.Edge_Index</code>) to numpy.</p> <p>Parameters:</p> Name Type Description Default <code>input_iterable</code> <code>torch.Tensor | numpy.ndarray | list</code> <p>Tensor, tensor subclass, numpy array or list.</p> required <p>Returns:</p> Type Description <code>numpy.ndarray</code> <p>Numpy array.</p> Source code in <code>src/pathpyG/utils/convert.py</code> <pre><code>def to_numpy(input_iterable: torch.Tensor | np.ndarray | list) -&gt; np.ndarray:\n    \"\"\"\n    Convert an iterable (including a tensor or tensor subclasses like `torch_geometric.Edge_Index`) to numpy.\n\n    Args:\n        input_iterable: Tensor, tensor subclass, numpy array or list.\n\n    Returns:\n        Numpy array.\n    \"\"\"\n    if isinstance(input_iterable, (EdgeIndex, Index)):\n        return input_iterable.as_tensor().cpu().numpy()\n    elif isinstance(input_iterable, torch.Tensor):\n        return input_iterable.cpu().numpy()\n    elif isinstance(input_iterable, (list, tuple)):\n        return np.array(input_iterable)\n    elif isinstance(input_iterable, np.ndarray):\n        return input_iterable\n</code></pre>"},{"location":"reference/pathpyG/utils/dbgnn/","title":"dbgnn","text":""},{"location":"reference/pathpyG/utils/dbgnn/#pathpyG.utils.dbgnn.generate_bipartite_edge_index","title":"<code>generate_bipartite_edge_index</code>","text":"<p>Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.</p> Source code in <code>src/pathpyG/utils/dbgnn.py</code> <pre><code>def generate_bipartite_edge_index(\n    g: Graph, g2: Graph, mapping: str = \"last\", device: Optional[torch.device] = None\n) -&gt; torch.Tensor:\n    \"\"\"Generate edge_index for bipartite graph connecting nodes of a second-order graph to first-order nodes.\"\"\"\n\n    if mapping == \"last\":\n        bipartide_edge_index = torch.tensor([list(range(g2.n)), [v[1] for v in g2.data.node_sequence]], device=device)\n\n    elif mapping == \"first\":\n        bipartide_edge_index = torch.tensor([list(range(g2.n)), [v[0] for v in g2.data.node_sequence]], device=device)\n    else:\n        bipartide_edge_index = torch.tensor(\n            [\n                list(range(g2.n)) + list(range(g2.n)),\n                [v[0] for v in g2.data.node_sequence] + [v[1] for v in g2.data.node_sequence],\n            ],\n            device=device,\n        )\n\n    return bipartide_edge_index\n</code></pre>"},{"location":"reference/pathpyG/utils/logger/","title":"logger","text":""},{"location":"reference/pathpyG/utils/progress/","title":"progress","text":"<p>Progressbar for pathpy.</p>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_console","title":"<code>tqdm_console</code>","text":"<p>Progressbar for a console environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_console(*args, **kwargs):\n    \"\"\"Progressbar for a console environment.\"\"\"\n    if len(args[0]) &gt; config[\"progress\"][\"min_iter\"]:\n        return tq(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_disabled","title":"<code>tqdm_disabled</code>","text":"<p>Disable the progress bar and return initial iterator.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_disabled(it, *args, **kwargs):\n    \"\"\"Disable the progress bar and return initial iterator.\"\"\"\n    return it\n</code></pre>"},{"location":"reference/pathpyG/utils/progress/#pathpyG.utils.progress.tqdm_notebook","title":"<code>tqdm_notebook</code>","text":"<p>Progressbar for a notebook environment.</p> Source code in <code>src/pathpyG/utils/progress.py</code> <pre><code>def tqdm_notebook(*args, **kwargs):\n    \"\"\"Progressbar for a notebook environment.\"\"\"\n    if len(args[0]) &gt; config[\"progress\"][\"min_iter\"]:\n        return tqn(*args, **kwargs)\n    else:\n        return args[0]\n</code></pre>"},{"location":"reference/pathpyG/visualisations/","title":"PathpyG Visualisations","text":"<p>This page provides an overview of the available visualisations and the supported backends. It also describes which displaying and saving options are available as well as the supported keyword arguments for customized plot styling.</p>"},{"location":"reference/pathpyG/visualisations/#overview","title":"Overview","text":"<p>The main plotting function is <code>pathpyG.plot()</code>, which can be used to create visualisations of both static and temporal networks. The function supports multiple backends, each with its own capabilities and output formats. The backend will be automatically chosen depending on the input data and the specified options.</p> <p>The default backend is <code>d3.js</code>, which is suitable for both static and temporal networks and produces interactive visualisations that can be viewed in a web browser.</p> <p>Interactive Temporal Graph Visualisation with d3.js</p> <p><pre><code>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\npp.plot(t)\n</code></pre> </p> Interactive Static Graph Visualisation with d3.js <p><pre><code>import pathpyG as pp\n\n# Example network data\nedges = [\n    (\"a\", \"b\"),\n    (\"a\", \"c\"),\n    (\"b\", \"c\"),\n    (\"c\", \"d\"),\n    (\"d\", \"e\"),\n    (\"e\", \"a\"),\n]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g)\n</code></pre> </p>"},{"location":"reference/pathpyG/visualisations/#backends","title":"Backends","text":"<p>We currently support a total of four plotting backends, each with different capabilities making them suitable for different use cases. The table below provides an overview of the supported backends and their available file formats:</p> Backend Static Networks Temporal Networks Time-Unfolded Networks Available File Formats d3.js \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f <code>html</code> manim \u274c \u2714\ufe0f \u274c <code>mp4</code>, <code>gif</code> matplotlib \u2714\ufe0f \u274c \u2714\ufe0f <code>png</code>, <code>jpg</code> tikz \u2714\ufe0f \u274c \u2714\ufe0f <code>svg</code>, <code>pdf</code>, <code>tex</code>"},{"location":"reference/pathpyG/visualisations/#details","title":"Details","text":"<ul> <li>d3.js: The default backend, suitable for both static and temporal networks. It produces interactive visualisations that can be viewed in a web browser.</li> <li>matplotlib: A widely used plotting library in Python. It is suitable for static networks and produces raster graphics files.</li> <li>manim: A backend specifically designed for creating animations of temporal graphs, producing high-quality video files.</li> <li>tikz: A backend for creating publication-quality vector graphics with LaTeX-compatible output or directly compiled output as PDF or SVG.</li> </ul> <p>Note</p> <p>The <code>manim</code> and the <code>tikz</code> backends require additional dependencies to be installed. Please refer to the respective sections in the Installation Guide for more information.</p>"},{"location":"reference/pathpyG/visualisations/#saving-a-plot","title":"Saving a Plot","text":"<p>You can save plots to files by specifying the <code>filename</code> argument in the <code>pp.plot()</code> function call. The file format will be automatically determined based on the file extension. If no filename is provided, the plot will be displayed inline (in a Jupyter notebook or similar environment).</p>"},{"location":"reference/pathpyG/visualisations/#customisation","title":"Customisation","text":"<p>For more advanced visualisations, <code>PathpyG</code> offers customisation options for node and edge properties (like <code>color</code>, <code>size</code>, and <code>opacity</code>), as well as support for additional backends, including <code>manim</code>, <code>matplotlib</code>, and <code>tikz</code>. We provide some usage examples below, and a detailed overview of the supported keyword arguments for each backend in section Customisation Options.</p>"},{"location":"reference/pathpyG/visualisations/#visualising-undirected-networks","title":"Visualising Undirected Networks","text":"<p>We provide support for directed and undirected static networks. Directed networks are visualised with arrows, while undirected networks use simple lines in all backends. We provide an example using <code>matplotlib</code> below.</p> <p>Undirected Static Graph Visualisation with <code>matplotlib</code></p> <p>You will see below that compared to the examples above, the nodes do not have arrows indicating directionality. <pre><code>import torch\nimport pathpyG as pp\n\n# Example undirected network data\nedge_index = torch.tensor([[0, 1, 3, 3], [1, 2, 1, 0]])\ng = pp.Graph.from_edge_index(edge_index).to_undirected()\n\n# Create static plot and display inline\npp.plot(g, backend=\"matplotlib\")\n</code></pre> </p> <p>Node Labels</p> <p>In the above picture, the nodes do not have labels. This is because labels are automatically generated based on the node IDs provided in <code>g.mapping.node_ids</code>. When we created the graph using the <code>from_edge_index()</code> method, we did not provide any specific node IDs, so no IDs were assigned and no labels were generated. You can override the default behaviour by specifying <code>show_labels=True</code> in the <code>pp.plot()</code> function call.</p>"},{"location":"reference/pathpyG/visualisations/#node-and-edge-customisation","title":"Node and Edge Customisation","text":"<p>You can customise the appearance of nodes and edges in both static and temporal networks. We describe the different options below.</p>"},{"location":"reference/pathpyG/visualisations/#static-networks","title":"Static Networks","text":"<p>In all backends, you can customise the <code>size</code>, <code>color</code>, and <code>opacity</code> of nodes and edges.  You can specify these properties either as attributes of the <code>PyG</code> graph object <code>PathpyG.Graph.data</code> (as <code>torch.Tensor</code> or <code>numpy.ndarray</code> with one value per node/edge) or as arguments in the <code>pp.plot()</code> function call in three different ways: (1)</p> <ul> <li>A single value (applied uniformly to all nodes/edges)</li> <li>A list of values with length equal to the number of nodes/edges (values are applied in order)</li> <li>A dictionary mapping node/edge IDs to values (values are applied based on the IDs)</li> </ul> <p>For <code>color</code>, you can use color names (e.g., <code>\"blue\"</code>), HEX codes (e.g., <code>\"#ff0000\"</code>), or RGB tuples (e.g., <code>(255, 0, 0)</code>). You can also pass numeric values, which will be mapped to colors using a <code>matplotlib</code> colormap (specified via <code>cmap</code>).</p> <ol> <li>If both the graph attribute and the function argument are provided, the function argument takes precedence.</li> </ol> <p>Custom Node and Edge Properties</p> <p>In the example below, we set custom properties for nodes and edges using all three methods. <pre><code>import torch\nimport pathpyG as pp\n\n# Example network data\nedges = [\n    (\"a\", \"b\"),\n    (\"a\", \"c\"),\n    (\"b\", \"d\"),\n    (\"c\", \"d\"),\n    (\"d\", \"a\"),\n]\ng = pp.Graph.from_edge_list(edges)\n\n# Add properties as attributes to the graph\ng.data[\"node_size\"] = torch.tensor([10, 15, 20, 15])\ng.data[\"edge_color\"] = torch.tensor([0, 1, 2, 1, 0])\ng.data[\"node_opacity\"] = torch.zeros(g.n)\n\n# Create static plot with custom settings and display inline\npp.plot(\n    g,\n    backend=\"tikz\",\n    node_color={\"a\": \"red\", \"b\": \"#00FF00\"},\n    edge_opacity={(\"a\", \"b\"): 0.1, (\"a\", \"c\"): 0.5, (\"b\", \"d\"): 1.0},\n    node_opacity=1.0,  # override graph attribute\n    edge_size=torch.tensor([1, 2, 3, 2, 1]),\n)\n</code></pre> </p> Display Images inside your Nodes <p><code>d3.js</code> additionally supports images as node representations. You can specify the image source using the <code>node_image</code> argument. The image source can be a URL or a local file path. <pre><code>import torch\nimport pathpyG as pp\n\n# Example network data\nedges = [\n    (\"b\", \"a\"),\n    (\"c\", \"a\"),\n]\nmapping = pp.IndexMap([\"a\", \"b\", \"c\", \"d\"])\ng = pp.Graph.from_edge_list(edges, mapping=mapping)\ng.data[\"node_size\"] = torch.tensor([25]*4)\npp.plot(\n    g,\n    node_size={\"d\": 50},\n    edge_size=5,\n    node_image={\n        \"a\": \"https://avatars.githubusercontent.com/u/52822508?s=48&amp;v=4\",\n        \"b\": \"https://raw.githubusercontent.com/pyg-team/pyg_sphinx_theme/master/pyg_sphinx_theme/static/img/pyg_logo.png\",\n        \"c\": \"https://pytorch-geometric.readthedocs.io/en/latest/_static/img/pytorch_logo.svg\",\n        \"d\": \"docs/img/pathpy_logo_new.png\",\n    },\n    show_labels=False,\n)\n</code></pre> </p>"},{"location":"reference/pathpyG/visualisations/#temporal-networks","title":"Temporal Networks","text":"<p>For temporal networks, you can also customise the <code>size</code>, <code>color</code>, and <code>opacity</code> of nodes and edges at each timestep. In our understanding, a temporal network has a fixed set of nodes, but edges appear at different timesteps. Thus, all nodes exist at all times, but edges may only exist at certain timesteps. Therefore, edge properties can be specified for each timestep where the edge exists. In contrast, node properties can change at specified points in time, but will remain the same for all subsequent timesteps until they are changed again.</p> <p>The customisation options work similarly to static networks, with the exception that passing a dictionary for node/edge properties requires adding the timestep to the key:</p> <p>Custom Node and Edge Properties in Temporal Networks</p> <p>In the example below, we set the starting <code>node_color</code> and <code>node_size</code> for all nodes using graph attributes. We further customise the <code>edge_color</code> for each edge at each timestep using a graph attribute. Next, we override the <code>node_color</code> for node <code>\"b\"</code> at timestep <code>2</code> and for node <code>\"a\"</code> from the start using function arguments. Finally, we use a dictionary with a tuple consisting of the source node, target node, and timestep to set the <code>edge_size</code> for two specific edges at specific timesteps.</p> <p><pre><code>import torch\nimport numpy as np\nimport pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\nt.data[\"node_size\"] = torch.tensor([15, 8, 19])\nt.data[\"node_color\"] = np.array([\"blue\", \"green\", \"orange\"])\nt.data[\"edge_color\"] = torch.tensor([0, 1, 2, 1])\n\n# Create temporal plot and display inline\npp.plot(\n    t,\n    backend=\"manim\",\n    node_opacity=0.5,\n    edge_size={(\"a\", \"b\", 1): 10, (\"a\", \"b\", 2): 1},\n    node_color={(\"b\", 2): \"red\", \"a\": \"purple\"}, # node_color for node 'a' is set to 'purple' from the start\n)\n</code></pre> </p>"},{"location":"reference/pathpyG/visualisations/#layouts","title":"Layouts","text":"<p>By default, <code>PathpyG</code> uses the Fruchterman-Reingold force-directed algorithm to compute node positions for static networks. For temporal networks, the layout is computed dynamically at each timestep using the <code>d3.js</code> backend, while the <code>manim</code> backend uses a Fruchterman-Reingold layout computed on the aggregated static network by default.</p>"},{"location":"reference/pathpyG/visualisations/#static-networks_1","title":"Static Networks","text":"<p>You can change the layout algorithm for static networks using the <code>layout</code> argument in the <code>pp.plot()</code> function call.</p> <p>networkx layouts:</p> <p>We currently support most layouts via the <code>networkx</code> library. See the examples below for usage.</p> RandomCircularShellSpectralKamada-KawaiFruchterman-ReingoldForceAtlas2 <p>Use <code>\"random\"</code>, <code>\"rand\"</code> or <code>None</code> to specify a random layout. <pre><code>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"random\")\n</code></pre> </p> <p>Use <code>\"circular\"</code>, <code>\"circle\"</code>, <code>\"ring\"</code>, <code>\"1d-lattice\"</code>, or <code>\"lattice-1d\"</code> to specify a circular layout. <pre><code>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"circular\")\n</code></pre> </p> <p>Use <code>\"shell\"</code>, <code>\"concentric\"</code>, <code>\"concentric-circles\"</code>, or <code>\"shell layout\"</code> to specify a shell layout. <pre><code>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"shell\")\n</code></pre> </p> <p>Use <code>\"spectral\"</code>, <code>\"eigen\"</code>, or <code>\"spectral layout\"</code> to specify a spectral layout. <pre><code>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"spectral\")\n</code></pre> </p> <p>Use <code>\"kamada-kawai\"</code>, <code>\"kamada_kawai\"</code>, <code>\"kk\"</code>, <code>\"kamada\"</code>, or <code>\"kamada layout\"</code> to specify a Kamada-Kawai layout. <pre><code>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"kamada-kawai\")\n</code></pre> </p> <p>Use <code>\"fruchterman-reingold\"</code>, <code>\"fruchterman_reingold\"</code>, <code>\"fr\"</code>, <code>\"spring_layout\"</code>, <code>\"spring layout\"</code>, or <code>\"spring\"</code> to specify a Fruchterman-Reingold layout. <pre><code>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"fruchterman-reingold\")\n</code></pre> </p> <p>Use <code>\"forceatlas2\"</code>, <code>\"fa2\"</code>, <code>\"forceatlas\"</code>, <code>\"force-atlas\"</code>, <code>\"force-atlas2\"</code>, or <code>\"fa 2\"</code> to specify a ForceAtlas2 layout. <pre><code>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"forceatlas2\")\n</code></pre> </p> <p>Other layouts: In addition to the <code>networkx</code> layouts, we also support:</p> <ul> <li> <p>Grid layout</p> Example <p><pre><code>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"grid\", filename=\"tikz_grid_layout.svg\")\n</code></pre> </p> </li> <li> <p>Custom layout (by providing a dictionary mapping node IDs to positions)</p> Example <p><pre><code>import pathpyG as pp\n\ng = pp.Graph.from_edge_list([(\"a\", \"b\"), (\"a\", \"c\"), (\"b\", \"d\"), (\"c\", \"d\"), (\"d\", \"a\")])\n# Provide custom x and y coordinates for a layout\nlayout = {\n    \"a\": (0, 0),\n    \"b\": (1, 0),\n    \"c\": (0, 1),\n    \"d\": (1, 1)\n}\npp.plot(g, backend=\"tikz\", layout=layout, filename=\"tikz_layout.svg\")\n</code></pre> </p> </li> </ul>"},{"location":"reference/pathpyG/visualisations/#temporal-networks_1","title":"Temporal Networks","text":"<p>We apply a sliding window approach to compute layouts for temporal networks. At each timestep, we consider a window of past and future timesteps (controlled via the <code>layout_window_size</code> argument) and aggregate all edges inside this window to a static graph to compute the layout. You can either pass a fixed integer value, which will then be split equally into past and future timesteps, or a tuple specifying the number of past and future timesteps separately. The layout algorithm can be any of the supported static layout algorithms described above.</p> <p>Custom Layout for Temporal Networks</p> <p>In the example below, we use a sliding window of <code>2</code>, meaning that we aggregate the current and one previous timestep to compute the layout at each timestep. <pre><code>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\npp.plot(t, backend=\"manim\", layout_window_size=2, layout=\"fa2\")\n</code></pre> </p>"},{"location":"reference/pathpyG/visualisations/#time-unfolded-networks","title":"Time-Unfolded Networks","text":"<p>For temporal networks, you can use the time-unfolded visualisation to show a static representation of the temporal network. In this representation, each node is duplicated for each timestep, and edges are drawn between nodes at different timesteps to represent temporal interactions. You can enable this visualisation by setting the \"kind\" argument to <code>\"unfolded\"</code> in the <code>pp.plot()</code> function call. This visualisation is supported by all backends that support static networks, i.e. D3.js, Matplotlib, and TikZ.</p> <p>Time-Unfolded Visualisation of Temporal Networks</p> <p>In the example below, we create a time-unfolded visualisation of a temporal network using the <code>tikz</code> backend. <pre><code>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\nnode_color = {\"a\": \"red\", (\"a\", 2): \"darkred\"}\nedge_color = {(\"a\", \"b\", 2): \"blue\"}\npp.plot(t, backend=\"tikz\", kind=\"unfolded\", node_size=12, node_color=node_color, edge_color=edge_color)\n</code></pre> </p> <p>Customising Time-Unfolded Visualisations</p> <p>In the time-unfolded visualisation, you can still customise node and edge properties as described in the Node and Edge Customisation section.</p>"},{"location":"reference/pathpyG/visualisations/#customisation-options","title":"Customisation Options","text":"<p>Below is full list of supported keyword arguments for each backend and their descriptions.</p> Argument d3.js manim matplotlib tikz Short Description General <code>default_backend</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Backend to use when none is specified <code>cmap</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Colormap (string that refers to matplotlib cmap) for scalar node/edge values <code>layout</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Layout algorithm for static networks (see Layouts) <code>width</code> \u2714\ufe0f \u274c \u2714\ufe0f \u2714\ufe0f Width of the output <code>height</code> \u2714\ufe0f \u274c \u2714\ufe0f \u2714\ufe0f Height of the output <code>latex_class_options</code> \u274c \u274c \u274c \u2714\ufe0f LaTeX document class options (e.g., <code>\"border=2mm\"</code>) for <code>tikz</code> backend <code>margin</code> \u2714\ufe0f \u274c \u2714\ufe0f \u2714\ufe0f Margin around the plot area (in pixels for <code>d3.js</code>, in points for <code>matplotlib</code> and <code>tikz</code>) <code>curvature</code> \u2714\ufe0f \u274c \u274c \u2714\ufe0f Curvature of edges (0: straight, &gt;0: curved) <code>layout_window_size</code> \u2714\ufe0f \u2714\ufe0f \u274c \u274c Size of sliding window for temporal network layouts (int or tuple of int) <code>delta</code> \u2714\ufe0f \u2714\ufe0f \u274c \u274c Duration of timestep in milliseconds (ms) <code>separator</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Separator for higher-order node labels <code>orientation</code> \u2714\ufe0f \u2714\ufe0f \u274c \u2714\ufe0f Orientation of the time-unfolded network plot (<code>\"up\"</code>, <code>\"down\"</code>, <code>\"left\"</code>, or <code>\"right\"</code>) Nodes <code>size</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Radius of nodes (uniform or per-node) <code>color</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Node fill color <code>opacity</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Node fill opacity (0 transparent, 1 solid) <code>image_padding</code> \u2714\ufe0f \u274c \u274c \u274c Padding around node images (in pixels) Edges <code>size</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Edge width (uniform or per-edge) <code>color</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Edge line color <code>opacity</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Edge line opacity (0 transparent, 1 solid) <p>Legend: \u2714\ufe0f Supported\u2003\u274c Not Supported </p> <p>You can find the default values for each argument in <code>pathpyG.toml</code> located in the <code>pathpyG</code> installation directory.</p> <p>Node and Edge Keyword Arguments</p> <p>The node and edge keyword arguments listed above represent the default options that are specified via the <code>pathpyG.toml</code> configuration file. You can change these defaults using keyword arguments in the <code>pp.plot()</code> function call as follows: <pre><code>import pathpyG as pp\n\n# Example network data\ng = pp.Graph.from_edge_list([(\"a\", \"b\"), (\"a\", \"c\")])\n\n# Create network plot and display inline\npp.plot(g, node={\"opacity\": 0.2}, filename=\"d3js_node_opacity.html\")\n</code></pre> </p> <p>However, if you want to change either <code>color</code>, <code>size</code>, or <code>opacity</code> for nodes or edges, the preferred way is to use the dedicated keyword arguments described in the previous sections.</p> <p>For more details and usage examples, see Manim Visualisation Tutorial,Visualisation Tutorial and Develop your own plot Functions</p>"},{"location":"reference/pathpyG/visualisations/layout/","title":"layout","text":"<p>Network layout algorithms for node positioning.</p> <p>Provides comprehensive layout computation for network visualization using various algorithms from NetworkX and custom implementations. Supports both weighted and  unweighted networks with flexible parameter configuration.</p> <p>Key Features</p> <ul> <li>NetworkX integration for proven algorithms</li> <li>Custom grid layout for regular structures  </li> <li>Weighted layout support for better positioning</li> <li>Automatic algorithm selection and validation</li> </ul> <p>Available Algorithms</p> <ul> <li>All layouts that are implemented in <code>networkx</code><ul> <li>Random layout</li> <li>Circular layout</li> <li>Shell layout</li> <li>Spectral layout</li> <li>Kamada-Kawai layout</li> <li>Fruchterman-Reingold force-directed algorithm</li> <li>ForceAtlas2 layout algorithm</li> </ul> </li> <li>Grid layout</li> </ul> <p>Examples:</p> <p>Compute a spring layout for a simple graph:</p> <pre><code>&gt;&gt;&gt; from pathpyG import Graph\n&gt;&gt;&gt; from pathpyG.visualisations import layout\n&gt;&gt;&gt; \n&gt;&gt;&gt; g = Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; positions = layout(g, layout='spring', k=0.5)\n&gt;&gt;&gt; print(positions)\n{'a': array([ 0.61899711, -1.        ]), 'b': array([-0.00132282,  0.00213747]), 'c': array([-0.61767429,  0.99786253])}\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout","title":"<code>Layout</code>","text":"<p>               Bases: <code>object</code></p> <p>Layout computation engine for network node positioning.</p> <p>Core class that handles algorithm selection, parameter management, and coordinate generation. Integrates with NetworkX for proven algorithms while providing custom implementations for specialized cases.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>List of unique node identifiers</p> required <code>edge_index</code> <code>typing.Optional[torch.Tensor]</code> <p>Tensor containing source/target indices for each edge</p> <code>None</code> <code>layout_type</code> <code>str</code> <p>Algorithm name for position computation</p> <code>'random'</code> <code>weight</code> <code>typing.Optional[torch.Tensor]</code> <p>Optional edge weights as tensor with shape [num_edges]</p> <code>None</code> <code>**kwargs</code> <p>Algorithm-specific parameters</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>nodes</code> <p>Node identifier list</p> <code>edge_index</code> <p>Edge connectivity tensor</p> <code>weight</code> <p>Edge weight tensor (optional)</p> <code>layout_type</code> <p>Selected algorithm name</p> <code>kwargs</code> <p>Algorithm parameters</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>class Layout(object):\n    \"\"\"Layout computation engine for network node positioning.\n\n    Core class that handles algorithm selection, parameter management, and\n    coordinate generation. Integrates with NetworkX for proven algorithms\n    while providing custom implementations for specialized cases.\n\n    Args:\n        nodes: List of unique node identifiers\n        edge_index: Tensor containing source/target indices for each edge\n        layout_type: Algorithm name for position computation\n        weight: Optional edge weights as tensor with shape [num_edges]\n        **kwargs: Algorithm-specific parameters\n\n    Attributes:\n        nodes: Node identifier list\n        edge_index: Edge connectivity tensor\n        weight: Edge weight tensor (optional)\n        layout_type: Selected algorithm name\n        kwargs: Algorithm parameters\n    \"\"\"\n\n    def __init__(self, nodes: list, edge_index: Optional[Tensor] = None, layout_type: str = \"random\", weight: Optional[Tensor] = None, **kwargs):\n        \"\"\"Initialize layout computation with network data and parameters.\n\n        Args:\n            nodes: List of unique node identifiers\n            edge_index: Edge connectivity tensor (creates empty if None)\n            layout_type: Algorithm name for position computation\n            weight: Optional edge weights tensor\n            **kwargs: Algorithm-specific parameters\n        \"\"\"\n        # initialize variables\n        self.nodes = nodes\n        if edge_index is None:\n            self.edge_index = EdgeIndex(torch.empty((2, 0), dtype=torch.long))\n        else:\n            self.edge_index = edge_index\n        self.weight = weight\n        self.layout_type = layout_type\n        self.kwargs = kwargs\n\n    def generate_layout(self):\n        \"\"\"Select and execute appropriate layout algorithm.\n\n        Routes computation to either custom grid implementation or \n        NetworkX-based algorithms based on layout_type specification.\n\n        Returns:\n            dict: Node positions as {node_id: (x, y)} coordinate mapping\n        \"\"\"\n        # method names\n        names_grid = [\"grid\", \"2d-lattice\", \"lattice-2d\"]\n        # check which layout should be plotted\n        if self.layout_type in names_grid:\n            self.layout = self.grid()\n        else:\n            self.layout = self.generate_nx_layout()\n\n        return self.layout\n\n    def generate_nx_layout(self):\n        \"\"\"Compute layout using NetworkX algorithms with weight support.\n\n        Converts pathpyG network to NetworkX format, applies selected algorithm\n        with proper weight handling, and returns position dictionary.\n\n        Returns:\n            dict: Node positions from NetworkX layout algorithm\n\n        Raises:\n            ValueError: If layout algorithm name not recognized\n\n        !!! note \"Algorithm Mapping\"\n            Multiple aliases map to the same underlying NetworkX function\n            for user convenience and compatibility with different naming conventions.\n        \"\"\"\n        import networkx as nx\n\n        sp_matrix = to_scipy_sparse_matrix(self.edge_index.as_tensor(), edge_attr=self.weight, num_nodes=len(self.nodes))\n        nx_network = nx.from_scipy_sparse_array(sp_matrix)\n        nx_network = nx.relabel_nodes(nx_network, {i: node for i, node in enumerate(self.nodes)})\n\n        names_rand = [\"random\", \"rand\", None]\n        names_circular = [\"circular\", \"circle\", \"ring\", \"1d-lattice\", \"lattice-1d\"]\n        names_shell = [\"shell\", \"concentric\", \"concentric-circles\", \"shell layout\"]\n        names_spectral = [\"spectral\", \"eigen\", \"spectral layout\"]\n        names_kk = [\"kamada-kawai\", \"kamada_kawai\", \"kk\", \"kamada\", \"kamada layout\"]\n        names_fr = [\"fruchterman-reingold\", \"fruchterman_reingold\", \"fr\", \"spring_layout\", \"spring layout\", \"spring\"]\n        names_forceatlas2 = [\"forceatlas2\", \"fa2\", \"forceatlas\", \"force-atlas\", \"force-atlas2\", \"fa 2\"]\n\n        if self.layout_type in names_rand:\n            layout = nx.random_layout(nx_network, **self.kwargs)\n        elif self.layout_type in names_circular:\n            layout = nx.circular_layout(nx_network, **self.kwargs)\n        elif self.layout_type in names_shell:\n            layout = nx.shell_layout(nx_network, **self.kwargs)\n        elif self.layout_type in names_spectral:\n            layout = nx.spectral_layout(nx_network, **self.kwargs)\n        elif self.layout_type in names_kk:\n            layout = nx.kamada_kawai_layout(\n                nx_network, weight=\"weight\" if self.weight is not None else None, **self.kwargs\n            )\n        elif self.layout_type in names_fr:\n            layout = nx.spring_layout(nx_network, weight=\"weight\" if self.weight is not None else None, **self.kwargs)\n        elif self.layout_type in names_forceatlas2:\n            layout = nx.forceatlas2_layout(\n                nx_network, weight=\"weight\" if self.weight is not None else None, **self.kwargs\n            )\n        else:\n            raise ValueError(f\"Layout '{self.layout_type}' not recognized.\")\n\n        return layout\n\n    def grid(self):\n        \"\"\"Position nodes on regular 2D grid for lattice-like structures.\n\n        Arranges nodes in a square grid pattern with uniform spacing.\n        Useful for regular networks, lattices.\n\n        Returns:\n            dict: Grid positions as {node_id: (x, y)} coordinates\n        \"\"\"\n        n = len(self.nodes)\n        width = 1.0\n\n        # number of nodes in horizontal/vertical direction\n        k = np.floor(np.sqrt(n))\n        dist = width / k\n\n        x = (np.arange(0, n) % k) * dist\n        y = -(np.floor(np.arange(0, n) / k)) * dist\n        coords = np.vstack((x, y)).T\n\n        return {node: coords[i] for i, node in enumerate(self.nodes)}\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.__init__","title":"<code>__init__</code>","text":"<p>Initialize layout computation with network data and parameters.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>List of unique node identifiers</p> required <code>edge_index</code> <code>typing.Optional[torch.Tensor]</code> <p>Edge connectivity tensor (creates empty if None)</p> <code>None</code> <code>layout_type</code> <code>str</code> <p>Algorithm name for position computation</p> <code>'random'</code> <code>weight</code> <code>typing.Optional[torch.Tensor]</code> <p>Optional edge weights tensor</p> <code>None</code> <code>**kwargs</code> <p>Algorithm-specific parameters</p> <code>{}</code> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def __init__(self, nodes: list, edge_index: Optional[Tensor] = None, layout_type: str = \"random\", weight: Optional[Tensor] = None, **kwargs):\n    \"\"\"Initialize layout computation with network data and parameters.\n\n    Args:\n        nodes: List of unique node identifiers\n        edge_index: Edge connectivity tensor (creates empty if None)\n        layout_type: Algorithm name for position computation\n        weight: Optional edge weights tensor\n        **kwargs: Algorithm-specific parameters\n    \"\"\"\n    # initialize variables\n    self.nodes = nodes\n    if edge_index is None:\n        self.edge_index = EdgeIndex(torch.empty((2, 0), dtype=torch.long))\n    else:\n        self.edge_index = edge_index\n    self.weight = weight\n    self.layout_type = layout_type\n    self.kwargs = kwargs\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.generate_layout","title":"<code>generate_layout</code>","text":"<p>Select and execute appropriate layout algorithm.</p> <p>Routes computation to either custom grid implementation or  NetworkX-based algorithms based on layout_type specification.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Node positions as {node_id: (x, y)} coordinate mapping</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def generate_layout(self):\n    \"\"\"Select and execute appropriate layout algorithm.\n\n    Routes computation to either custom grid implementation or \n    NetworkX-based algorithms based on layout_type specification.\n\n    Returns:\n        dict: Node positions as {node_id: (x, y)} coordinate mapping\n    \"\"\"\n    # method names\n    names_grid = [\"grid\", \"2d-lattice\", \"lattice-2d\"]\n    # check which layout should be plotted\n    if self.layout_type in names_grid:\n        self.layout = self.grid()\n    else:\n        self.layout = self.generate_nx_layout()\n\n    return self.layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.generate_nx_layout","title":"<code>generate_nx_layout</code>","text":"<p>Compute layout using NetworkX algorithms with weight support.</p> <p>Converts pathpyG network to NetworkX format, applies selected algorithm with proper weight handling, and returns position dictionary.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Node positions from NetworkX layout algorithm</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If layout algorithm name not recognized</p> <p>Algorithm Mapping</p> <p>Multiple aliases map to the same underlying NetworkX function for user convenience and compatibility with different naming conventions.</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def generate_nx_layout(self):\n    \"\"\"Compute layout using NetworkX algorithms with weight support.\n\n    Converts pathpyG network to NetworkX format, applies selected algorithm\n    with proper weight handling, and returns position dictionary.\n\n    Returns:\n        dict: Node positions from NetworkX layout algorithm\n\n    Raises:\n        ValueError: If layout algorithm name not recognized\n\n    !!! note \"Algorithm Mapping\"\n        Multiple aliases map to the same underlying NetworkX function\n        for user convenience and compatibility with different naming conventions.\n    \"\"\"\n    import networkx as nx\n\n    sp_matrix = to_scipy_sparse_matrix(self.edge_index.as_tensor(), edge_attr=self.weight, num_nodes=len(self.nodes))\n    nx_network = nx.from_scipy_sparse_array(sp_matrix)\n    nx_network = nx.relabel_nodes(nx_network, {i: node for i, node in enumerate(self.nodes)})\n\n    names_rand = [\"random\", \"rand\", None]\n    names_circular = [\"circular\", \"circle\", \"ring\", \"1d-lattice\", \"lattice-1d\"]\n    names_shell = [\"shell\", \"concentric\", \"concentric-circles\", \"shell layout\"]\n    names_spectral = [\"spectral\", \"eigen\", \"spectral layout\"]\n    names_kk = [\"kamada-kawai\", \"kamada_kawai\", \"kk\", \"kamada\", \"kamada layout\"]\n    names_fr = [\"fruchterman-reingold\", \"fruchterman_reingold\", \"fr\", \"spring_layout\", \"spring layout\", \"spring\"]\n    names_forceatlas2 = [\"forceatlas2\", \"fa2\", \"forceatlas\", \"force-atlas\", \"force-atlas2\", \"fa 2\"]\n\n    if self.layout_type in names_rand:\n        layout = nx.random_layout(nx_network, **self.kwargs)\n    elif self.layout_type in names_circular:\n        layout = nx.circular_layout(nx_network, **self.kwargs)\n    elif self.layout_type in names_shell:\n        layout = nx.shell_layout(nx_network, **self.kwargs)\n    elif self.layout_type in names_spectral:\n        layout = nx.spectral_layout(nx_network, **self.kwargs)\n    elif self.layout_type in names_kk:\n        layout = nx.kamada_kawai_layout(\n            nx_network, weight=\"weight\" if self.weight is not None else None, **self.kwargs\n        )\n    elif self.layout_type in names_fr:\n        layout = nx.spring_layout(nx_network, weight=\"weight\" if self.weight is not None else None, **self.kwargs)\n    elif self.layout_type in names_forceatlas2:\n        layout = nx.forceatlas2_layout(\n            nx_network, weight=\"weight\" if self.weight is not None else None, **self.kwargs\n        )\n    else:\n        raise ValueError(f\"Layout '{self.layout_type}' not recognized.\")\n\n    return layout\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.Layout.grid","title":"<code>grid</code>","text":"<p>Position nodes on regular 2D grid for lattice-like structures.</p> <p>Arranges nodes in a square grid pattern with uniform spacing. Useful for regular networks, lattices.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>Grid positions as {node_id: (x, y)} coordinates</p> Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def grid(self):\n    \"\"\"Position nodes on regular 2D grid for lattice-like structures.\n\n    Arranges nodes in a square grid pattern with uniform spacing.\n    Useful for regular networks, lattices.\n\n    Returns:\n        dict: Grid positions as {node_id: (x, y)} coordinates\n    \"\"\"\n    n = len(self.nodes)\n    width = 1.0\n\n    # number of nodes in horizontal/vertical direction\n    k = np.floor(np.sqrt(n))\n    dist = width / k\n\n    x = (np.arange(0, n) % k) * dist\n    y = -(np.floor(np.arange(0, n) / k)) * dist\n    coords = np.vstack((x, y)).T\n\n    return {node: coords[i] for i, node in enumerate(self.nodes)}\n</code></pre>"},{"location":"reference/pathpyG/visualisations/layout/#pathpyG.visualisations.layout.layout","title":"<code>layout</code>","text":"<p>Generate node positions using specified layout algorithm.</p> <p>Computes 2D coordinates for all nodes in the network using various layout algorithms. Supports edge weighting for physics-based layouts and provides flexible parameter passing to underlying algorithms.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.core.graph.Graph</code> <p>Graph instance to generate layout for</p> required <code>layout</code> <code>str</code> <p>Algorithm name (see supported algorithms below)</p> <code>'random'</code> <code>weight</code> <code>None | str | typing.Iterable</code> <p>Edge weights as attribute name, iterable, or None</p> <code>None</code> <code>**kwargs</code> <p>Algorithm-specific parameters passed to layout function</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Node positions as {node_id: (x, y)} coordinate mapping</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If weight attribute not found or weight length mismatch</p> <code>ValueError</code> <p>If layout algorithm not recognized</p> <p>Examples:</p> <pre><code># Basic spring layout\npos = layout(graph, 'spring')\n\n# Weighted layout with edge attribute\npos = layout(graph, 'kamada-kawai', weight='edge_weight')\n\n# Custom parameters\npos = layout(graph, 'spring', k=0.3, iterations=100)\n</code></pre> <p>Supported Algorithms</p> Algorithm Aliases Best For <code>spring</code> <code>fruchterman-reingold</code>, <code>fr</code> General networks <code>kamada-kawai</code> <code>kk</code>, <code>kamada</code> Small/medium networks <code>forceatlas2</code> <code>fa2</code>, <code>force-atlas2</code> Large networks <code>circular</code> <code>circle</code>, <code>ring</code> Cycle structures <code>shell</code> <code>concentric</code> Hierarchical data <code>grid</code> <code>lattice-2d</code> Regular structures <code>spectral</code> <code>eigen</code> Community detection <code>random</code> <code>rand</code> Testing/baseline Source code in <code>src/pathpyG/visualisations/layout.py</code> <pre><code>def layout(network: Graph, layout: str = \"random\", weight: None | str | Iterable = None, **kwargs):\n    \"\"\"Generate node positions using specified layout algorithm.\n\n    Computes 2D coordinates for all nodes in the network using various layout\n    algorithms. Supports edge weighting for physics-based layouts and provides\n    flexible parameter passing to underlying algorithms.\n\n    Args:\n        network: Graph instance to generate layout for\n        layout: Algorithm name (see supported algorithms below)\n        weight: Edge weights as attribute name, iterable, or None\n        **kwargs: Algorithm-specific parameters passed to layout function\n\n    Returns:\n        dict: Node positions as {node_id: (x, y)} coordinate mapping\n\n    Raises:\n        ValueError: If weight attribute not found or weight length mismatch\n        ValueError: If layout algorithm not recognized\n\n    Examples:\n        ```python\n        # Basic spring layout\n        pos = layout(graph, 'spring')\n\n        # Weighted layout with edge attribute\n        pos = layout(graph, 'kamada-kawai', weight='edge_weight')\n\n        # Custom parameters\n        pos = layout(graph, 'spring', k=0.3, iterations=100)\n        ```\n\n    !!! note \"Supported Algorithms\"\n\n        | Algorithm | Aliases | Best For |\n        |-----------|---------|----------|\n        | `spring` | `fruchterman-reingold`, `fr` | General networks |\n        | `kamada-kawai` | `kk`, `kamada` | Small/medium networks |\n        | `forceatlas2` | `fa2`, `force-atlas2` | Large networks |\n        | `circular` | `circle`, `ring` | Cycle structures |\n        | `shell` | `concentric` | Hierarchical data |\n        | `grid` | `lattice-2d` | Regular structures |\n        | `spectral` | `eigen` | Community detection |\n        | `random` | `rand` | Testing/baseline |\n    \"\"\"\n    # initialize variables\n    if isinstance(weight, str):\n        if weight in network.edge_attrs():\n            weight = network.data[weight]\n        else:\n            raise ValueError(f\"Weight attribute '{weight}' not found in edge attributes.\")\n    elif isinstance(weight, Iterable) and not isinstance(weight, torch.Tensor):\n        n_edges = network.m * 2 if network.is_undirected() else network.m\n        if len(weight) == n_edges:  # type: ignore[arg-type]\n            weight = torch.tensor(weight)\n        else:\n            raise ValueError(\"Length of weight iterable does not match number of edges in the network.\")\n\n    # create layout class\n    layout_cls = Layout(\n        nodes=network.nodes, edge_index=network.data.edge_index, layout_type=layout, weight=weight, **kwargs\n    )\n    # return the layout\n    return layout_cls.generate_layout()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plot/","title":"network_plot","text":"<p>Static network visualization classes.</p> <p>Provides comprehensive plotting functionality for static (non-temporal) networks. Handles data preparation, attribute assignment, layout computation, and backend integration for Graph objects.</p> <p>Key Features</p> <ul> <li>Automatic attribute extraction from network data</li> <li>Flexible node/edge styling (colors, sizes, images)</li> <li>Layout algorithm integration</li> <li>Multi-backend compatibility</li> </ul> <p>Attribute Sources</p> <p>Attributes are resolved in order (highest priority to the leftmost): user arguments \u2192 network attributes \u2192 config defaults</p>"},{"location":"reference/pathpyG/visualisations/network_plot/#pathpyG.visualisations.network_plot.NetworkPlot","title":"<code>NetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.pathpy_plot.PathPyPlot</code></p> <p>Static network visualization with comprehensive styling options.</p> <p>Prepares Graph objects for visualization by extracting node/edge data, computing layouts, and processing visual attributes. Supports both  simple and higher-order networks with flexible attribute assignment.</p> <p>Attributes:</p> Name Type Description <code>network</code> <p>Graph instance being visualized</p> <code>node_args</code> <p>Node-specific styling arguments</p> <code>edge_args</code> <p>Edge-specific styling arguments</p> <code>attributes</code> <p>Standard visual attributes (color, size, opacity, image)</p> <p>Attribute Assignment</p> <p>Use <code>node_color</code>, <code>edge_size</code> etc. for convenient styling. Attributes support constants, lists, or node/edge mappings.</p> Source code in <code>src/pathpyG/visualisations/network_plot.py</code> <pre><code>class NetworkPlot(PathPyPlot):\n    \"\"\"Static network visualization with comprehensive styling options.\n\n    Prepares Graph objects for visualization by extracting node/edge data,\n    computing layouts, and processing visual attributes. Supports both \n    simple and higher-order networks with flexible attribute assignment.\n\n    Attributes:\n        network: Graph instance being visualized\n        node_args: Node-specific styling arguments\n        edge_args: Edge-specific styling arguments\n        attributes: Standard visual attributes (color, size, opacity, image)\n\n    !!! tip \"Attribute Assignment\"\n        Use `node_color`, `edge_size` etc. for convenient styling.\n        Attributes support constants, lists, or node/edge mappings.\n    \"\"\"\n\n    _kind = \"network\"\n\n    def __init__(self, network: Graph, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize network plot with graph and styling options.\n\n        Processes node/edge arguments, updates configuration, and generates\n        plot data structures. Arguments prefixed with 'node_' or 'edge_'\n        are automatically assigned to respective components.\n\n        Args:\n            network: Graph instance to visualize\n            **kwargs: Styling options (node_color, edge_size, layout, etc.)\n        \"\"\"\n        super().__init__()\n        self.network = network\n        self.node_args = {}\n        self.edge_args = {}\n        self.attributes = [\"color\", \"size\", \"opacity\", \"image\"]\n        # extract node and edge specific arguments from kwargs\n        for key in kwargs.keys():\n            if key.startswith(\"node_\"):\n                self.node_args[key[5:]] = kwargs.get(key)\n            elif key.startswith(\"edge_\"):\n                self.edge_args[key[5:]] = kwargs.get(key)\n        # remove node_ and edge_ arguments from kwargs and update config with remaining kwargs\n        for node_arg in self.node_args.keys():\n            kwargs.pop(f\"node_{node_arg}\")\n        for edge_arg in self.edge_args.keys():\n            kwargs.pop(f\"edge_{edge_arg}\")\n        if \"node\" in kwargs:\n            self.config[\"node\"].update(kwargs[\"node\"])\n            kwargs.pop(\"node\")\n        if \"edge\" in kwargs:\n            self.config[\"edge\"].update(kwargs[\"edge\"])\n            kwargs.pop(\"edge\")\n        self.config.update(kwargs)\n        # generate plot data\n        self.generate()\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate complete plot data through processing pipeline.\n\n        Orchestrates data preparation: edges \u2192 nodes \u2192 layout \u2192 post-processing \u2192 config.\n        Creates final data structures ready for backend rendering.\n        \"\"\"\n        self._compute_edge_data()\n        self._compute_node_data()\n        self._compute_layout()\n        self._post_process_node_data()\n        self._compute_config()\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Build node DataFrame with visual attributes.\n\n        Creates indexed DataFrame for all nodes, handling higher-order networks\n        by converting tuple nodes to string representation. Assigns attributes\n        from config defaults, network data, and user arguments.\n        \"\"\"\n        # initialize values\n        nodes: pd.DataFrame = pd.DataFrame(index=self.network.nodes)\n        # if higher-order network, convert node tuples to string representation\n        if self.network.order &gt; 1:\n            nodes.index = nodes.index.map(lambda x: self.config[\"separator\"].join(map(str, x)))\n        for attribute in self.attributes:\n            # set default value for each attribute based on the pathpyG.toml config\n            if isinstance(self.config.get(\"node\").get(attribute, None), list | tuple):  # type: ignore[union-attr]\n                nodes[attribute] = [self.config.get(\"node\").get(attribute, None)] * len(nodes)  # type: ignore[union-attr]\n            else:\n                nodes[attribute] = self.config.get(\"node\").get(attribute, None)  # type: ignore[union-attr]\n            # check if attribute is given as node attribute\n            if f\"node_{attribute}\" in self.network.node_attrs():\n                nodes[attribute] = self.network.data[f\"node_{attribute}\"]\n            # check if attribute is given as argument\n            if attribute in self.node_args:\n                nodes = self._assign_argument(attribute, self.node_args[attribute], nodes)\n\n        # save node data\n        self.data[\"nodes\"] = nodes\n\n    def _post_process_node_data(self) -&gt; None:\n        \"\"\"Finalize node attributes for backend compatibility.\n\n        Converts colors to uniform hex format and loads local images\n        to base64 strings for embedding in output formats.\n        \"\"\"\n        # convert colors to uniform hex values\n        self.data[\"nodes\"][\"color\"] = self._convert_to_rgb_tuple(self.data[\"nodes\"][\"color\"])\n        self.data[\"nodes\"][\"color\"] = self.data[\"nodes\"][\"color\"].map(self._convert_color)\n\n        # load any local images to base64 strings\n        if self.data[\"nodes\"][\"image\"].notna().any():\n            self.data[\"nodes\"][\"image\"] = self.data[\"nodes\"][\"image\"].map(self._load_image)\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Build edge DataFrame with visual attributes and deduplication.\n\n        Creates MultiIndex DataFrame for edges, handles higher-order networks,\n        assigns attributes, and removes duplicates for undirected graphs.\n        Special handling for edge weights as size defaults.\n\n        !!! warning \"No support for networks with multiedges\"\n            For efficiency, duplicate edges are removed.\n        \"\"\"\n        # initialize values\n        edges: pd.DataFrame = pd.DataFrame(index=pd.MultiIndex.from_tuples(self.network.edges, names=[\"source\", \"target\"]))\n        # if higher-order network, convert node tuples to string representation\n        if self.network.order &gt; 1:\n            edges.index = edges.index.map(lambda x: (self.config[\"separator\"].join(map(str, x[0])), self.config[\"separator\"].join(map(str, x[1]))))\n        for attribute in self.attributes:\n            # set default value for each attribute based on the pathpyG.toml config\n            if isinstance(self.config.get(\"edge\").get(attribute, None), list | tuple):  # type: ignore[union-attr]\n                edges[attribute] = [self.config.get(\"edge\").get(attribute, None)] * len(edges)  # type: ignore[union-attr]\n            else:\n                edges[attribute] = self.config.get(\"edge\").get(attribute, None)  # type: ignore[union-attr]\n            # check if attribute is given as edge attribute\n            if f\"edge_{attribute}\" in self.network.edge_attrs():\n                edges[attribute] = self.network.data[f\"edge_{attribute}\"]\n            # special case for size: If no edge_size is given use edge_weight if available\n            elif attribute == \"size\" and \"edge_weight\" in self.network.edge_attrs():\n                edges[attribute] = self.network.data[\"edge_weight\"]\n            # check if attribute is given as argument\n            if attribute in self.edge_args:\n                edges = self._assign_argument(attribute, self.edge_args[attribute], edges)\n            elif attribute == \"size\" and \"weight\" in self.edge_args:\n                edges = self._assign_argument(\"size\", self.edge_args[\"weight\"], edges)\n\n        # convert attributes to useful values\n        edges[\"color\"] = self._convert_to_rgb_tuple(edges[\"color\"])\n        edges[\"color\"] = edges[\"color\"].map(self._convert_color)\n\n        # remove duplicate edges for better efficiency\n        if not self.network.is_directed():\n            # for undirected networks, sort source and target and drop duplicates\n            edges = edges.reset_index()\n            edges[\"sorted\"] = edges.apply(lambda row: tuple(sorted((row[\"source\"], row[\"target\"]))), axis=1)\n            edges = edges.drop_duplicates(subset=[\"sorted\"]).drop(columns=[\"sorted\"])\n            edges = edges.set_index([\"source\", \"target\"])\n        else:\n            # for directed networks, remove duplicates based on index\n            edges = edges[~edges.index.duplicated(keep=\"first\")]\n\n        # save edge data\n        self.data[\"edges\"] = edges\n\n    def _assign_argument(self, attr_key: str, attr_value: Any, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Assign user arguments to node/edge attributes flexibly.\n\n        Handles multiple value types: constants, lists/arrays, or dictionaries\n        mapping node/edge IDs to values. Special handling for RGB color tuples\n        and proper length validation for sequence types.\n\n        Args:\n            attr_key: Attribute name (color, size, opacity, image)\n            attr_value: Value to assign (constant, list, or dict mapping)\n            df: Target DataFrame (nodes or edges)\n\n        Returns:\n            Updated DataFrame with assigned attributes\n\n        Raises:\n            AttributeError: If list length doesn't match DataFrame size\n        \"\"\"\n        if isinstance(attr_value, dict):\n            # if dict does not contain values for all edges, only update those that are given\n            if attr_key == \"color\":\n                # convert color tuples to hex strings to avoid pandas sequence assignment\n                for key in attr_value.keys():\n                    value = attr_value[key]\n                    if isinstance(value, tuple) and len(value) == 3:\n                        attr_value[key] = rgb_to_hex(value)\n            new_attrs = df.index.map(attr_value)\n            # Check if all values are assigned\n            if (~new_attrs.isna()).sum() == df.shape[0]:\n                # If all values are assigned, directly set the column to make sure that dtype is correct\n                df[attr_key] = new_attrs\n            else:\n                # Otherwise, only update the values that are not NaN\n                df.loc[~new_attrs.isna(), attr_key] = new_attrs[~new_attrs.isna()]\n        elif isinstance(attr_value, Sized) and not isinstance(attr_value, str):\n            # check if attr_key=\"color\" and given values is an RGB tuple\n            if attr_key == \"color\":\n                if isinstance(attr_value, tuple) and len(attr_value) == 3:\n                    df[attr_key] = [attr_value] * len(df)\n                else:\n                    df[attr_key] = attr_value\n            elif len(attr_value) != len(df):\n                logger.error(f\"The provided list for {attr_key} has length {len(attr_value)}, but there are {len(df)} nodes/edges!\")\n                raise AttributeError\n            else:\n                df[attr_key] = attr_value\n        else:\n            df[attr_key] = attr_value\n        return df\n\n    def _convert_to_rgb_tuple(self, colors: pd.Series) -&gt; dict:\n        \"\"\"Convert numeric color values to RGB tuples via colormap.\n\n        Maps numerical values to colors using matplotlib colormap when\n        colors are provided as numeric data (for value-based coloring).\n\n        Args:\n            colors: Series containing color values (numeric or already processed)\n\n        Returns:\n            Series with RGB tuple colors or original non-numeric colors\n        \"\"\"\n        # check if colors are given as numerical values\n        if pd.api.types.is_numeric_dtype(colors):\n            # load colormap to map numerical values to color\n            cmap_name = self.config.get(\"cmap\")\n            cmap = plt.get_cmap(cmap_name)\n            # normalize values to [0,1]\n            norm = plt.Normalize(vmin=colors.min(), vmax=colors.max())\n            # map values to colors\n            colors = colors.map(lambda x: cmap(norm(x)))\n        return colors\n\n    def _convert_color(self, color: tuple[int, int, int]) -&gt; str:\n        \"\"\"Normalize colors to hex format for backend consistency.\n\n        Converts RGB tuples, color names, or existing hex values to\n        standardized hex format. Handles matplotlib color names via\n        automatic RGB conversion.\n\n        Args:\n            color: Color as RGB tuple, hex string, or named color\n\n        Returns:\n            Hex color string (e.g., \"#ff0000\")\n\n        Raises:\n            AttributeError: If color format is invalid or unrecognized\n        \"\"\"\n        if isinstance(color, tuple):\n            return rgb_to_hex(color[:3])\n        elif isinstance(color, str):\n            if color.startswith(\"#\"):\n                return color\n            else:\n                # try to convert color name to hex\n                try:\n                    rgb = to_rgb(color)\n                    return rgb_to_hex(rgb)\n                except ValueError:\n                    logger.error(f\"The provided color {color} is not valid!\")\n                    raise AttributeError\n        elif not isinstance(color, Sized) and (color is None or pd.isna(color)):\n            return pd.NA  # will be filled with self._fill_node_values()\n        else:\n            logger.error(f\"The provided color {color} is not valid!\")\n            raise AttributeError\n\n    def _load_image(self, image_path: str) -&gt; str:\n        \"\"\"Load local images to base64 or pass through URLs.\n\n        Converts local image files to base64 data URLs for embedding\n        while preserving existing URLs and data URLs unchanged.\n\n        Args:\n            image_path: Local file path, URL, or data URL\n\n        Returns:\n            Base64 data URL for local files, original string for URLs\n\n        Raises:\n            AttributeError: If local file path doesn't exist\n        \"\"\"\n        if image_path.startswith(\"http://\") or image_path.startswith(\"https://\") or image_path.startswith(\"data:\"):\n            return image_path  # already a URL or base64 string\n        else:\n            # check if file exists\n            if not os.path.isfile(image_path):\n                logger.error(f\"The provided image path {image_path} does not exist!\")\n                raise AttributeError\n            return image_to_base64(image_path)\n\n    def _compute_layout(self) -&gt; None:\n        \"\"\"Compute and normalize node positions using layout algorithms.\n\n        Applies layout algorithm from config, normalizes coordinates to [0,1]\n        range, and joins position data with node attributes. Handles both\n        string layout names and pre-computed position dictionaries.\n        \"\"\"\n        # get layout from the config\n        layout = self.config.get(\"layout\")\n\n        # if no layout is considered stop this process\n        if layout is None:\n            return\n\n        # get layout dict for each node\n        if isinstance(layout, str):\n            layout = network_layout(self.network, layout=layout)\n        elif not isinstance(layout, dict):\n            logger.error(\"The provided layout is not valid!\")\n            raise AttributeError\n\n        # update x,y position of the nodes\n        layout_df = pd.DataFrame.from_dict(layout, orient=\"index\", columns=[\"x\", \"y\"])\n        if self.network.order &gt; 1 and not isinstance(layout_df.index[0], str):\n            layout_df.index = layout_df.index.map(lambda x: self.config[\"separator\"].join(map(str, x)))\n        # scale x and y to [0,1]\n        layout_df[\"x\"] = (layout_df[\"x\"] - layout_df[\"x\"].min()) / (layout_df[\"x\"].max() - layout_df[\"x\"].min())\n        layout_df[\"y\"] = (layout_df[\"y\"] - layout_df[\"y\"].min()) / (layout_df[\"y\"].max() - layout_df[\"y\"].min())\n        # join layout with node data\n        self.data[\"nodes\"] = self.data[\"nodes\"].join(layout_df, how=\"left\")\n\n    def _compute_config(self) -&gt; None:\n        \"\"\"Set network-specific visualization configuration.\n\n        Configures directedness, edge curvature, and simulation mode (for `d3.js` backend)\n        based on network properties. Directed networks use curved edges,\n        simulation mode activates when no layout is specified.\n        \"\"\"\n        self.config[\"directed\"] = self.network.is_directed()\n        self.config[\"curved\"] = self.network.is_directed()\n        self.config[\"simulation\"] = self.config[\"layout\"] is None\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plot/#pathpyG.visualisations.network_plot.NetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize network plot with graph and styling options.</p> <p>Processes node/edge arguments, updates configuration, and generates plot data structures. Arguments prefixed with 'node_' or 'edge_' are automatically assigned to respective components.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.core.graph.Graph</code> <p>Graph instance to visualize</p> required <code>**kwargs</code> <code>typing.Any</code> <p>Styling options (node_color, edge_size, layout, etc.)</p> <code>{}</code> Source code in <code>src/pathpyG/visualisations/network_plot.py</code> <pre><code>def __init__(self, network: Graph, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize network plot with graph and styling options.\n\n    Processes node/edge arguments, updates configuration, and generates\n    plot data structures. Arguments prefixed with 'node_' or 'edge_'\n    are automatically assigned to respective components.\n\n    Args:\n        network: Graph instance to visualize\n        **kwargs: Styling options (node_color, edge_size, layout, etc.)\n    \"\"\"\n    super().__init__()\n    self.network = network\n    self.node_args = {}\n    self.edge_args = {}\n    self.attributes = [\"color\", \"size\", \"opacity\", \"image\"]\n    # extract node and edge specific arguments from kwargs\n    for key in kwargs.keys():\n        if key.startswith(\"node_\"):\n            self.node_args[key[5:]] = kwargs.get(key)\n        elif key.startswith(\"edge_\"):\n            self.edge_args[key[5:]] = kwargs.get(key)\n    # remove node_ and edge_ arguments from kwargs and update config with remaining kwargs\n    for node_arg in self.node_args.keys():\n        kwargs.pop(f\"node_{node_arg}\")\n    for edge_arg in self.edge_args.keys():\n        kwargs.pop(f\"edge_{edge_arg}\")\n    if \"node\" in kwargs:\n        self.config[\"node\"].update(kwargs[\"node\"])\n        kwargs.pop(\"node\")\n    if \"edge\" in kwargs:\n        self.config[\"edge\"].update(kwargs[\"edge\"])\n        kwargs.pop(\"edge\")\n    self.config.update(kwargs)\n    # generate plot data\n    self.generate()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/network_plot/#pathpyG.visualisations.network_plot.NetworkPlot.generate","title":"<code>generate</code>","text":"<p>Generate complete plot data through processing pipeline.</p> <p>Orchestrates data preparation: edges \u2192 nodes \u2192 layout \u2192 post-processing \u2192 config. Creates final data structures ready for backend rendering.</p> Source code in <code>src/pathpyG/visualisations/network_plot.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate complete plot data through processing pipeline.\n\n    Orchestrates data preparation: edges \u2192 nodes \u2192 layout \u2192 post-processing \u2192 config.\n    Creates final data structures ready for backend rendering.\n    \"\"\"\n    self._compute_edge_data()\n    self._compute_node_data()\n    self._compute_layout()\n    self._post_process_node_data()\n    self._compute_config()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/pathpy_plot/","title":"pathpy_plot","text":"<p>Abstract base class for plot data preparation.</p> <p>Provides common foundation for assembling plot data and configuration before backend-specific rendering. Handles configuration loading and data structure initialization.</p>"},{"location":"reference/pathpyG/visualisations/pathpy_plot/#pathpyG.visualisations.pathpy_plot.PathPyPlot","title":"<code>PathPyPlot</code>","text":"<p>Abstract base class for plot data assembly.</p> <p>Prepares network data and configuration for backend rendering. Subclasses implement specific plot types (static, temporal, histogram, etc.).</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>dict</code> <p>Dictionary containing processed plot data</p> <code>config</code> <code>dict</code> <p>Visualization configuration from pathpyG settings</p> Source code in <code>src/pathpyG/visualisations/pathpy_plot.py</code> <pre><code>class PathPyPlot:\n    \"\"\"Abstract base class for plot data assembly.\n\n    Prepares network data and configuration for backend rendering.\n    Subclasses implement specific plot types (static, temporal, histogram, etc.).\n\n    Attributes:\n        data: Dictionary containing processed plot data\n        config: Visualization configuration from pathpyG settings\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize plot with empty data and default configuration.\n\n        Loads visualization config and normalizes color settings from\n        lists to tuples for consistency across backends.\n        \"\"\"\n        self.data: dict = {}\n        self.config: dict = config.get(\"visualisation\", {}).copy()\n        if isinstance(self.config[\"node\"][\"color\"], list):\n            self.config[\"node\"][\"color\"] = tuple(self.config[\"node\"][\"color\"])\n        if isinstance(self.config[\"edge\"][\"color\"], list):\n            self.config[\"edge\"][\"color\"] = tuple(self.config[\"edge\"][\"color\"])\n        logger.debug(f\"Intialising PathpyPlot with config: {self.config}\")\n\n    def generate(self) -&gt; None:\n        \"\"\"Generate plot data structures.\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/pathpy_plot/#pathpyG.visualisations.pathpy_plot.PathPyPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize plot with empty data and default configuration.</p> <p>Loads visualization config and normalizes color settings from lists to tuples for consistency across backends.</p> Source code in <code>src/pathpyG/visualisations/pathpy_plot.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize plot with empty data and default configuration.\n\n    Loads visualization config and normalizes color settings from\n    lists to tuples for consistency across backends.\n    \"\"\"\n    self.data: dict = {}\n    self.config: dict = config.get(\"visualisation\", {}).copy()\n    if isinstance(self.config[\"node\"][\"color\"], list):\n        self.config[\"node\"][\"color\"] = tuple(self.config[\"node\"][\"color\"])\n    if isinstance(self.config[\"edge\"][\"color\"], list):\n        self.config[\"edge\"][\"color\"] = tuple(self.config[\"edge\"][\"color\"])\n    logger.debug(f\"Intialising PathpyPlot with config: {self.config}\")\n</code></pre>"},{"location":"reference/pathpyG/visualisations/pathpy_plot/#pathpyG.visualisations.pathpy_plot.PathPyPlot.generate","title":"<code>generate</code>","text":"<p>Generate plot data structures.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses</p> Source code in <code>src/pathpyG/visualisations/pathpy_plot.py</code> <pre><code>def generate(self) -&gt; None:\n    \"\"\"Generate plot data structures.\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot_backend/","title":"plot_backend","text":"<p>Abstract base class for visualization backends.</p> <p>Defines the common interface that all visualization backends (matplotlib, TikZ,  d3.js, manim) must implement. Handles plot data extraction and provides  standardized save/show methods.</p> Example <pre><code>class CustomBackend(PlotBackend):\n    def save(self, filename: str) -&gt; None:\n        # Implementation for saving\n        pass\n\n    def show(self) -&gt; None:\n        # Implementation for display\n        pass\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot_backend/#pathpyG.visualisations.plot_backend.PlotBackend","title":"<code>PlotBackend</code>","text":"<p>Abstract base class for all visualization backends.</p> <p>Provides common interface for matplotlib, TikZ, d3.js, and manim backends. Extracts plot data and configuration for backend-specific rendering.</p> Source code in <code>src/pathpyG/visualisations/plot_backend.py</code> <pre><code>class PlotBackend:\n    \"\"\"Abstract base class for all visualization backends.\n\n    Provides common interface for matplotlib, TikZ, d3.js, and manim backends.\n    Extracts plot data and configuration for backend-specific rendering.\n    \"\"\"\n    def __init__(self, plot: PathPyPlot, show_labels: bool) -&gt; None:\n        \"\"\"Initialize backend with plot data and configuration.\n\n        Args:\n            plot: PathPyPlot instance containing network data\n            show_labels: Whether to display node labels\n        \"\"\"\n        self.data = plot.data\n        self.config = plot.config\n        self.show_labels = show_labels\n\n    def save(self, filename: str) -&gt; None:\n        \"\"\"Save plot to file.\n\n        Args:\n            filename: Output file path\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses\n        \"\"\"\n        raise NotImplementedError(\"Subclasses should implement this method.\")\n\n    def show(self) -&gt; None:\n        \"\"\"Display plot on screen.\n\n        Raises:\n            NotImplementedError: Must be implemented by subclasses\n        \"\"\"\n        raise NotImplementedError(\"Subclasses should implement this method.\")\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot_backend/#pathpyG.visualisations.plot_backend.PlotBackend.__init__","title":"<code>__init__</code>","text":"<p>Initialize backend with plot data and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>plot</code> <code>pathpyG.visualisations.pathpy_plot.PathPyPlot</code> <p>PathPyPlot instance containing network data</p> required <code>show_labels</code> <code>bool</code> <p>Whether to display node labels</p> required Source code in <code>src/pathpyG/visualisations/plot_backend.py</code> <pre><code>def __init__(self, plot: PathPyPlot, show_labels: bool) -&gt; None:\n    \"\"\"Initialize backend with plot data and configuration.\n\n    Args:\n        plot: PathPyPlot instance containing network data\n        show_labels: Whether to display node labels\n    \"\"\"\n    self.data = plot.data\n    self.config = plot.config\n    self.show_labels = show_labels\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot_backend/#pathpyG.visualisations.plot_backend.PlotBackend.save","title":"<code>save</code>","text":"<p>Save plot to file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Output file path</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses</p> Source code in <code>src/pathpyG/visualisations/plot_backend.py</code> <pre><code>def save(self, filename: str) -&gt; None:\n    \"\"\"Save plot to file.\n\n    Args:\n        filename: Output file path\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses\n    \"\"\"\n    raise NotImplementedError(\"Subclasses should implement this method.\")\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot_backend/#pathpyG.visualisations.plot_backend.PlotBackend.show","title":"<code>show</code>","text":"<p>Display plot on screen.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Must be implemented by subclasses</p> Source code in <code>src/pathpyG/visualisations/plot_backend.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Display plot on screen.\n\n    Raises:\n        NotImplementedError: Must be implemented by subclasses\n    \"\"\"\n    raise NotImplementedError(\"Subclasses should implement this method.\")\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot_function/","title":"plot_function","text":"<p>Network visualization orchestration module.</p> <p>Provides the main plotting interface for pathpyG networks with automatic backend selection and plot type detection. Serves as the unified entry point for all  visualization functionality across different backends and graph types.</p> Key Features <ul> <li>Multi-backend support (matplotlib, TikZ, d3.js, manim)</li> <li>Automatic plot type detection (static vs temporal)</li> <li>File format-based backend inference</li> <li>Unified plotting interface for all graph types</li> </ul> Supported Backends <ul> <li>matplotlib: PNG, JPG plots for static visualization</li> <li>TikZ: PDF, SVG, TEX for publication-quality vector graphics</li> <li>d3.js: HTML for interactive web visualization</li> <li>manim: MP4, GIF for animated temporal networks</li> </ul> <p>Examples:</p> <p>Plot a static network with the matplotlib backend and save it as <code>network.png</code>:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\n&gt;&gt;&gt; pp.plot(g, filename='network.png')\n</code></pre> <p></p> <p>Plot a temporal network with the default d3.js backend:</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; tg = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('a', 'c', 3)])\n&gt;&gt;&gt; pp.plot(tg)\n</code></pre> <p>```</p> <p>Backend Selection</p> <p>Backends are auto-selected from file extensions or can be explicitly  specified via the <code>backend</code> parameter.</p>"},{"location":"reference/pathpyG/visualisations/plot_function/#pathpyG.visualisations.plot_function.Backends","title":"<code>Backends</code>","text":"<p>               Bases: <code>str</code>, <code>enum.Enum</code></p> <p>Enumeration of supported visualization backends.</p> <p>Defines the available backend engines for network visualization, each optimized for different output formats and use cases.</p> Source code in <code>src/pathpyG/visualisations/plot_function.py</code> <pre><code>class Backends(str, Enum):\n    \"\"\"Enumeration of supported visualization backends.\n\n    Defines the available backend engines for network visualization,\n    each optimized for different output formats and use cases.\n    \"\"\"\n    d3js = \"d3js\"\n    matplotlib = \"matplotlib\"\n    tikz = \"tikz\"\n    manim = \"manim\"\n\n    @staticmethod\n    def is_backend(backend: str) -&gt; bool:\n        \"\"\"Check if string is a valid backend identifier.\n\n        Args:\n            backend: Backend name to validate\n\n        Returns:\n            True if backend is supported, False otherwise\n        \"\"\"\n        return backend in Backends.__members__.values()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot_function/#pathpyG.visualisations.plot_function.Backends.is_backend","title":"<code>is_backend</code>  <code>staticmethod</code>","text":"<p>Check if string is a valid backend identifier.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str</code> <p>Backend name to validate</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if backend is supported, False otherwise</p> Source code in <code>src/pathpyG/visualisations/plot_function.py</code> <pre><code>@staticmethod\ndef is_backend(backend: str) -&gt; bool:\n    \"\"\"Check if string is a valid backend identifier.\n\n    Args:\n        backend: Backend name to validate\n\n    Returns:\n        True if backend is supported, False otherwise\n    \"\"\"\n    return backend in Backends.__members__.values()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot_function/#pathpyG.visualisations.plot_function.plot","title":"<code>plot</code>","text":"<p>Make plot of pathpyG objects.</p> <p>Creates and displays a plot for a given <code>pathpyG</code> object. This function can generate different types of network plots based on the nature of the input data and specified plot kind.</p> <p>The function dynamically determines the plot type if not explicitly provided, based on the input data type. It supports static network plots for <code>Graph</code> objects, temporal network plots for <code>TemporalGraph</code> objects, and potentially other types if specified in <code>kind</code>.</p> <p>Parameters:</p> Name Type Description Default <code>graph</code> <code>pathpyG.core.graph.Graph</code> <p>A <code>pathpyG</code> object representing the network data. This can be a <code>Graph</code> or <code>TemporalGraph</code> object, or other compatible types.</p> required <code>kind</code> <code>typing.Optional[str]</code> <p>A string keyword defining the type of plot to generate. Options include: 'static', and 'temporal'.</p> <code>None</code> <code>show_labels</code> <p>Whether to display node labels (None uses graph.mapping.has_ids)</p> <code>None</code> <code>**kwargs</code> <code>typing.Any</code> <p>Backend-specific plotting parameters including: filename: Output file path (triggers backend auto-selection); backend: Explicit backend choice; layout: Layout algorithm name; style: Various styling parameters (colors, sizes, etc.)</p> <code>{}</code> <p>Returns:</p> Type Description <code>pathpyG.visualisations.plot_backend.PlotBackend</code> <p>Configured backend instance ready for display or saving</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If graph type cannot be auto-detected for plotting</p> <code>KeyError</code> <p>If specified backend is not supported</p> <code>ImportError</code> <p>If required backend cannot be loaded</p> <p>Examples:</p> <p>This will create a static network plot of the <code>graph</code> and save it to 'graph.png'.</p> <pre><code>&gt;&gt;&gt; import pathpyG as pp\n&gt;&gt;&gt; graph = pp.Graph.from_edge_list([[\"a\", \"b\"], [\"b\", \"c\"], [\"a\", \"c\"]])\n&gt;&gt;&gt; pp.plot(graph, kind=\"static\", filename=\"graph.png\")\n</code></pre> <p></p> Note <ul> <li>If a 'filename' is provided in <code>kwargs</code>, the plot will be saved to   that file. Otherwise, it will be displayed using <code>plt.show()</code>.</li> <li>The function's behavior and the available options in <code>kwargs</code> might   change based on the type of plot being generated.</li> </ul> <p>Backend Auto-Selection</p> <p>When filename is provided, backend is inferred from extension:</p> Extension Backend Best For .png, .jpg matplotlib Quick visualization .pdf, .svg, .tex tikz Publication quality .html d3js Interactive exploration .mp4, .gif manim Animated sequences Source code in <code>src/pathpyG/visualisations/plot_function.py</code> <pre><code>def plot(graph: Graph, kind: Optional[str] = None, show_labels=None, **kwargs: Any) -&gt; PlotBackend:\n    \"\"\"Make plot of pathpyG objects.\n\n    Creates and displays a plot for a given `pathpyG` object. This function can\n    generate different types of network plots based on the nature of the input\n    data and specified plot kind.\n\n    The function dynamically determines the plot type if not explicitly\n    provided, based on the input data type. It supports static network plots\n    for `Graph` objects, temporal network plots for `TemporalGraph` objects,\n    and potentially other types if specified in `kind`.\n\n    Args:\n        graph: A `pathpyG` object representing the network data. This can\n            be a `Graph` or `TemporalGraph` object, or other compatible types.\n        kind: A string keyword defining the type of plot to generate. Options include:\n            **'static'**, and **'temporal'**.\n        show_labels: Whether to display node labels (None uses graph.mapping.has_ids)\n        **kwargs: Backend-specific plotting parameters including:\n            **filename**: Output file path (triggers backend auto-selection);\n            **backend**: Explicit backend choice;\n            **layout**: Layout algorithm name;\n            **style**: Various styling parameters (colors, sizes, etc.)\n\n    Returns:\n        Configured backend instance ready for display or saving\n\n    Raises:\n        NotImplementedError: If graph type cannot be auto-detected for plotting\n        KeyError: If specified backend is not supported\n        ImportError: If required backend cannot be loaded\n\n    Examples:\n        This will create a static network plot of the `graph` and save it to 'graph.png'.\n\n        &gt;&gt;&gt; import pathpyG as pp\n        &gt;&gt;&gt; graph = pp.Graph.from_edge_list([[\"a\", \"b\"], [\"b\", \"c\"], [\"a\", \"c\"]])\n        &gt;&gt;&gt; pp.plot(graph, kind=\"static\", filename=\"graph.png\")\n\n        &lt;img src=\"../plot/graph.png\" alt=\"Example static network plot\" width=\"550\"/&gt;\n\n    Note:\n        - If a 'filename' is provided in `kwargs`, the plot will be saved to\n          that file. Otherwise, it will be displayed using `plt.show()`.\n        - The function's behavior and the available options in `kwargs` might\n          change based on the type of plot being generated.\n\n    !!! abstract \"Backend Auto-Selection\"\n        When filename is provided, backend is inferred from extension:\n\n        | Extension | Backend | Best For |\n        |-----------|---------|----------|\n        | .png, .jpg | matplotlib | Quick visualization |\n        | .pdf, .svg, .tex | tikz | Publication quality |\n        | .html | d3js | Interactive exploration |\n        | .mp4, .gif | manim | Animated sequences |\n    \"\"\"\n    if kind is None:\n        if isinstance(graph, TemporalGraph):\n            kind = \"temporal\"\n        elif isinstance(graph, Graph):\n            kind = \"static\"\n        else:\n            raise NotImplementedError\n\n    if show_labels is None:\n        show_labels = graph.mapping.has_ids\n\n    filename = kwargs.pop(\"filename\", None)\n    _backend: str = kwargs.pop(\"backend\", None)\n\n    plot_backend_class = _get_plot_backend(\n        backend=_backend, filename=filename, default=config.get(\"visualisation\").get(\"default_backend\")  # type: ignore[union-attr]\n    )\n\n    # Check if backend is d3js and set layout to None if not specifically given as argument\n    if plot_backend_class == D3jsBackend:\n        if \"layout\" not in kwargs:\n            kwargs[\"layout\"] = None\n\n    plt = PLOT_CLASSES[kind](graph, **kwargs)\n    plot_backend = plot_backend_class(plt, show_labels=show_labels)\n    if filename:\n        plot_backend.save(filename)\n    else:\n        if config[\"environment\"][\"interactive\"]:\n            plot_backend.show()\n    return plot_backend\n</code></pre>"},{"location":"reference/pathpyG/visualisations/temporal_network_plot/","title":"temporal_network_plot","text":"<p>Temporal network visualization module.</p> <p>Prepares temporal graphs for visualization, handling time-based node and edge dynamics, windowed layout computation, and attribute interpolation.</p>"},{"location":"reference/pathpyG/visualisations/temporal_network_plot/#pathpyG.visualisations.temporal_network_plot.TemporalNetworkPlot","title":"<code>TemporalNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.network_plot.NetworkPlot</code></p> <p>Temporal network visualization with time-based node and edge dynamics.</p> <p>Extends NetworkPlot to handle temporal graphs where edges appear at fixed times. Provides windowed layout computation and time-aware attribute interpolation.</p> <p>Temporal Features</p> <ul> <li>Node lifetime tracking (start/end times)</li> <li>Windowed layout computation</li> <li>Time-based attribute interpolation</li> </ul> Source code in <code>src/pathpyG/visualisations/temporal_network_plot.py</code> <pre><code>class TemporalNetworkPlot(NetworkPlot):\n    \"\"\"Temporal network visualization with time-based node and edge dynamics.\n\n    Extends NetworkPlot to handle temporal graphs where edges appear at\n    fixed times. Provides windowed layout computation and\n    time-aware attribute interpolation.\n\n    !!! info \"Temporal Features\"\n        - Node lifetime tracking (start/end times)\n        - Windowed layout computation\n        - Time-based attribute interpolation\n    \"\"\"\n\n    _kind = \"temporal\"\n    network: TemporalGraph\n\n    def __init__(self, network: TemporalGraph, **kwargs: Any) -&gt; None:\n        \"\"\"Initialize temporal network plot.\n\n        Args:\n            network: TemporalGraph instance to visualize\n            **kwargs: Additional plotting parameters\n        \"\"\"\n        super().__init__(network, **kwargs)\n\n    def _compute_node_data(self) -&gt; None:\n        \"\"\"Generate temporal node data with time-based attributes.\n\n        Creates multi-index DataFrame with (node_id, time) structure.\n        Handles node appearance times and attribute assignment from\n        network data, config defaults, and user arguments.\n        \"\"\"\n        # initialize values with index `node-0` to indicate time step 0\n        start_nodes: pd.DataFrame = pd.DataFrame(\n            index=pd.MultiIndex.from_tuples([(node, 0) for node in self.network.nodes], names=[\"uid\", \"time\"])\n        )\n        new_nodes: pd.DataFrame = pd.DataFrame(index=pd.MultiIndex.from_tuples([], names=[\"uid\", \"time\"]))\n        # add attributes to start nodes and new nodes if given as dictionary\n        for attribute in self.attributes:\n            # set default value for each attribute based on the pathpyG.toml config\n            if isinstance(self.config.get(\"node\").get(attribute, None), list | tuple):  # type: ignore[union-attr]\n                start_nodes[attribute] = [self.config.get(\"node\").get(attribute, None)] * len(start_nodes)  # type: ignore[union-attr]\n            else:\n                start_nodes[attribute] = self.config.get(\"node\").get(attribute, None)  # type: ignore[union-attr]\n            # check if attribute is given as node attribute\n            if f\"node_{attribute}\" in self.network.node_attrs():\n                start_nodes[attribute] = self.network.data[f\"node_{attribute}\"]\n            # check if attribute is given as argument\n            if attribute in self.node_args:\n                if isinstance(self.node_args[attribute], dict):\n                    # check if entry is tuple or string\n                    for key in self.node_args[attribute].keys():  # type: ignore[union-attr]\n                        if isinstance(key, tuple):\n                            # add node attribute according to node-time keys\n                            value = self.node_args[attribute][key]  # type: ignore[index]\n                            # convert color tuples to hex strings to avoid pandas sequence assignment\n                            if attribute == \"color\" and isinstance(value, tuple) and len(value) == 3:\n                                value = rgb_to_hex(value)\n                            new_nodes.loc[key, attribute] = value\n                        else:\n                            # add node attributes to start nodes according to node keys\n                            start_nodes.loc[(key, 0), attribute] = self.node_args[attribute][key]  # type: ignore[index]\n                else:\n                    start_nodes[attribute] = self.node_args[attribute]\n\n        # save node data and combine start nodes with new nodes by making sure start nodes are overwritten\n        self.data[\"nodes\"] = new_nodes.combine_first(start_nodes)\n\n    def _post_process_node_data(self) -&gt; None:\n        \"\"\"Add node lifetime information and forward-fill attributes.\n\n        Computes start/end times for each node appearance and fills\n        missing attribute values using forward-fill within node groups.\n\n        Returns:\n            Processed DataFrame with start/end time columns\n        \"\"\"\n        # Post-processing from parent class\n        super()._post_process_node_data()\n\n        # Fill all NaN/None values with the previous value and add start/end time columns.\n        nodes = self.data[\"nodes\"]\n        nodes = nodes.sort_values(by=[\"uid\", \"time\"]).groupby(\"uid\", sort=False).ffill()\n        nodes[\"start\"] = nodes.index.get_level_values(\"time\")\n        nodes = nodes.droplevel(\"time\")\n        # add end time step with the start the node appears the next time or max time step + 1\n        nodes[\"end\"] = nodes.groupby(\"uid\")[\"start\"].shift(-1)\n        max_node_time = nodes[\"start\"].max() + 1\n        if self.network.data.time.size(0) &gt; 0 and max_node_time &lt; self.network.data.time[-1].item() + 1:\n            max_node_time = self.network.data.time[-1].item() + 1\n        nodes[\"end\"] = nodes[\"end\"].fillna(max_node_time).astype(int)\n        self.data[\"nodes\"] = nodes\n\n    def _compute_edge_data(self) -&gt; None:\n        \"\"\"Generate temporal edge data with time-based attributes.\n\n        Creates edge DataFrame with temporal index (source, target, time).\n        Handles edge attributes from network data, config defaults, and\n        user arguments. Adds start/end time columns for edge lifetime.\n        \"\"\"\n        # initialize values\n        edges: pd.DataFrame = pd.DataFrame(\n            index=pd.MultiIndex.from_tuples(self.network.temporal_edges, names=[\"source\", \"target\", \"time\"])\n        )\n        for attribute in self.attributes:\n            # set default value for each attribute based on the pathpyG.toml config\n            if isinstance(self.config.get(\"edge\").get(attribute, None), list | tuple):  # type: ignore[union-attr]\n                edges[attribute] = [self.config.get(\"edge\").get(attribute, None)] * len(edges)  # type: ignore[union-attr]\n            else:\n                edges[attribute] = self.config.get(\"edge\").get(attribute, None)  # type: ignore[union-attr]\n            # check if attribute is given as edge attribute\n            if f\"edge_{attribute}\" in self.network.edge_attrs():\n                edges[attribute] = self.network.data[f\"edge_{attribute}\"]\n            # special case for size: If no edge_size is given use edge_weight if available\n            elif attribute == \"size\" and \"edge_weight\" in self.network.edge_attrs():\n                edges[attribute] = self.network.data[\"edge_weight\"]\n            # check if attribute is given as argument\n            if attribute in self.edge_args:\n                edges = self._assign_argument(attribute, self.edge_args[attribute], edges)\n            elif attribute == \"size\" and \"weight\" in self.edge_args:\n                edges = self._assign_argument(\"size\", self.edge_args[\"weight\"], edges)\n\n        # convert needed attributes to useful values\n        edges[\"color\"] = self._convert_to_rgb_tuple(edges[\"color\"])\n        edges[\"color\"] = edges[\"color\"].map(self._convert_color)\n        edges[\"start\"] = edges.index.get_level_values(\"time\").astype(int)\n        edges[\"end\"] = edges[\"start\"] + 1  # assume all edges last for one time step\n        edges.index = edges.index.droplevel(\"time\")\n\n        # save edge data\n        self.data[\"edges\"] = edges\n\n    def _compute_layout(self) -&gt; None:\n        \"\"\"Compute time-aware node layout using sliding window approach.\n\n        Uses configurable time windows to create smooth layout transitions.\n        For each time step, considers edges from surrounding time steps\n        based on layout_window_size configuration.\n\n        !!! tip \"Window Configuration\"\n            - Integer: symmetric window around current time\n            - [past, future]: asymmetric window sizes\n            - Negative values: use all past/future time steps\n        \"\"\"\n        # get layout from the config\n        layout_type = self.config.get(\"layout\")\n\n        # if no layout is considered or the graph is empty stop this process\n        if layout_type is None or len(self.data[\"nodes\"]) == 0:\n            return\n\n        max_time = int(\n            max(self.data[\"nodes\"].index.get_level_values(\"time\").max() + 1, self.data[\"edges\"][\"end\"].max())\n        )\n        window_size = self.config.get(\"layout_window_size\")\n        if isinstance(window_size, int):\n            # if uneven window size, add one to the future time steps since the end time step is exclusive\n            window_size = [window_size // 2, ceil(window_size / 2)]\n        elif isinstance(window_size, list | tuple):\n            if window_size[0] &lt; 0:\n                # use all previous time steps\n                window_size[0] = max_time  # type: ignore[index]\n            if window_size[1] &lt; 0:\n                # use all following time steps\n                window_size[1] = max_time  # type: ignore[index]\n        elif not isinstance(window_size, (list, tuple)):\n            logger.error(\"The provided layout_window_size is not valid!\")\n            raise AttributeError\n\n        pos = network_layout(self.network, layout=\"random\")  # initial layout\n        num_steps = max(max_time - window_size[1], 0)\n        layout_df = pd.DataFrame()\n        for step in range(num_steps + 1):\n            start_time = max(0, step - window_size[0])\n            end_time = step + window_size[1] + 1\n            # only compute layout if there are edges in the current window, otherwise use the previous layout\n            if ((start_time &lt;= self.network.data.time) &amp; (self.network.data.time &lt;= end_time)).sum() &gt; 0:\n                # get subgraph for the current time step\n                sub_graph = self.network.get_window(start_time=start_time, end_time=end_time)\n\n                # get layout dict for each node\n                if isinstance(layout_type, str):\n                    pos = network_layout(sub_graph, layout=layout_type, pos=pos)\n                elif not isinstance(layout_type, dict):\n                    logger.error(\"The provided layout is not valid!\")\n                    raise AttributeError\n\n            # update x,y position of the nodes\n            new_layout_df = pd.DataFrame.from_dict(pos, orient=\"index\", columns=[\"x\", \"y\"])\n            if self.network.order &gt; 1 and not isinstance(new_layout_df.index[0], str):\n                new_layout_df.index = new_layout_df.index.map(lambda x: self.config[\"separator\"].join(map(str, x)))\n            # scale x and y to [0,1]\n            new_layout_df[\"x\"] = (new_layout_df[\"x\"] - new_layout_df[\"x\"].min()) / (\n                new_layout_df[\"x\"].max() - new_layout_df[\"x\"].min()\n            )\n            new_layout_df[\"y\"] = (new_layout_df[\"y\"] - new_layout_df[\"y\"].min()) / (\n                new_layout_df[\"y\"].max() - new_layout_df[\"y\"].min()\n            )\n            # add time for the layout\n            new_layout_df[\"time\"] = step\n            # append to layout df\n            layout_df = pd.concat([layout_df, new_layout_df])\n        # join layout with node data\n        layout_df = layout_df.reset_index().rename(columns={\"index\": \"uid\"}).set_index([\"uid\", \"time\"])\n        self.data[\"nodes\"] = self.data[\"nodes\"].join(layout_df, how=\"outer\")\n\n    def _compute_config(self) -&gt; None:\n        \"\"\"Set temporal-specific visualization configuration.\n\n        Forces directed=True and curved=False for temporal networks.\n        Enables simulation mode (for `d3js` backend) when no layout algorithm is specified.\n        \"\"\"\n        self.config[\"directed\"] = True\n        self.config[\"curved\"] = False\n        self.config[\"simulation\"] = self.config[\"layout\"] is None\n</code></pre>"},{"location":"reference/pathpyG/visualisations/temporal_network_plot/#pathpyG.visualisations.temporal_network_plot.TemporalNetworkPlot.__init__","title":"<code>__init__</code>","text":"<p>Initialize temporal network plot.</p> <p>Parameters:</p> Name Type Description Default <code>network</code> <code>pathpyG.core.temporal_graph.TemporalGraph</code> <p>TemporalGraph instance to visualize</p> required <code>**kwargs</code> <code>typing.Any</code> <p>Additional plotting parameters</p> <code>{}</code> Source code in <code>src/pathpyG/visualisations/temporal_network_plot.py</code> <pre><code>def __init__(self, network: TemporalGraph, **kwargs: Any) -&gt; None:\n    \"\"\"Initialize temporal network plot.\n\n    Args:\n        network: TemporalGraph instance to visualize\n        **kwargs: Additional plotting parameters\n    \"\"\"\n    super().__init__(network, **kwargs)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/unfolded_network_plot/","title":"unfolded_network_plot","text":"<p>Time-unfolded temporal network visualisation module.</p> <p>Prepares temporal graphs for visualization as time-unfolded networks by assigning the node positions in a grid.</p>"},{"location":"reference/pathpyG/visualisations/unfolded_network_plot/#pathpyG.visualisations.unfolded_network_plot.TimeUnfoldedNetworkPlot","title":"<code>TimeUnfoldedNetworkPlot</code>","text":"<p>               Bases: <code>pathpyG.visualisations.temporal_network_plot.TemporalNetworkPlot</code></p> <p>Time-unfolded temporal network visualisation class.</p> <p>Prepares temporal graphs for visualization as time-unfolded networks by assigning the node positions in a grid.</p> <p>Inherits from TemporalNetworkPlot.</p> Source code in <code>src/pathpyG/visualisations/unfolded_network_plot.py</code> <pre><code>class TimeUnfoldedNetworkPlot(TemporalNetworkPlot):\n    \"\"\"Time-unfolded temporal network visualisation class.\n\n    Prepares temporal graphs for visualization as time-unfolded networks\n    by assigning the node positions in a grid.\n\n    Inherits from TemporalNetworkPlot.\n    \"\"\"\n\n    _kind = \"unfolded\"\n    network: TemporalGraph\n\n    def _compute_edge_data(self):\n        super()._compute_edge_data()\n        self.data[\"edges\"].index = pd.MultiIndex.from_arrays(\n            [\n                list(zip(self.data[\"edges\"].index.get_level_values(\"source\"), self.data[\"edges\"][\"start\"])),\n                list(zip(self.data[\"edges\"].index.get_level_values(\"target\"), self.data[\"edges\"][\"end\"])),\n            ],\n            names=[\"source\", \"target\"],\n        )\n\n    def _post_process_node_data(self):\n        super()._post_process_node_data()\n\n        self.data[\"nodes\"].index = pd.Index(\n            list(zip(self.data[\"nodes\"].index, self.data[\"nodes\"][\"start\"])),\n            name=\"uid\",\n            tupleize_cols=False\n        )\n\n    def _compute_layout(self) -&gt; None:\n        \"\"\"Compute time-unfolded node layout.\n\n        For each node, assign positions in a grid based on time steps.\n        Depending on orientation, x (left/right) or y (up/down) coordinates represent time steps\n        and the other coordinate represents node identity.\n        \"\"\"\n        num_nodes = self.network.n\n        max_time = int(\n            max(self.data[\"nodes\"].index.get_level_values(\"time\").max() + 1, self.data[\"edges\"][\"end\"].max() + 1)\n        )\n        orientation = self.config.get(\"orientation\")\n\n        # Determine coordinate assignment based on orientation\n        if orientation in [\"left\", \"right\"]:\n            time_coord = \"x\"\n            node_coord = \"y\"\n            if orientation == \"left\":\n                sign = -1\n            else:\n                sign = 1\n        elif orientation in [\"up\", \"down\"]:\n            time_coord = \"y\"\n            node_coord = \"x\"\n            if orientation == \"down\":\n                sign = -1\n            else:\n                sign = 1\n        else:\n            raise ValueError(\"Invalid orientation option. Choose from 'left', 'right', 'up', or 'down'.\")\n\n        # Create a DataFrame for the grid layout\n        node_ids = np.repeat(self.data[\"nodes\"].index.get_level_values(\"uid\").unique(), max_time)\n        node_values = np.repeat(np.arange(num_nodes), max_time)\n        time_values = np.tile(np.arange(max_time), num_nodes)\n        layout_df = pd.DataFrame(\n            {\n                \"uid\": node_ids,\n                \"time\": time_values,\n                time_coord: (sign * time_values).astype(float),\n                node_coord: node_values.astype(float),\n            }\n        ).set_index([\"uid\", \"time\"])\n\n        # Scale coordinates between 0 and 1\n        layout_df[time_coord] = (layout_df[time_coord] - layout_df[time_coord].min()) / (\n            layout_df[time_coord].max() - layout_df[time_coord].min()\n        )\n        layout_df[node_coord] = (layout_df[node_coord] - layout_df[node_coord].min()) / (\n            layout_df[node_coord].max() - layout_df[node_coord].min()\n        )\n\n        # Join the layout DataFrame with the existing node data\n        self.data[\"nodes\"] = self.data[\"nodes\"].join(layout_df, how=\"outer\")\n\n    def _compute_config(self) -&gt; None:\n        \"\"\"Set temporal-specific visualization configuration.\n\n        Forces directed=True and curved=False for temporal networks.\n        Enables simulation mode (for `d3js` backend) when no layout algorithm is specified.\n        \"\"\"\n        self.config[\"directed\"] = True\n        self.config[\"curved\"] = False\n        self.config[\"simulation\"] = False\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/","title":"utils","text":"<p>Visualization Utilities for PathpyG.</p> <p>Essential helper functions for network visualization backends. This module provides utilities for file management, color conversion, unit conversion, and image processing to support the various visualization backends in PathpyG.</p> <p>Key Utilities</p> <ul> <li> File Management - Temporary directory handling for compilation</li> <li> Color Conversion - RGB/Hex color format transformations</li> <li> Unit Conversion - Between cm, inches, and pixels</li> <li> Image Processing - Base64 encoding for web compatibility</li> </ul> <p>These utilities are primarily used internally by visualization backends but can also be useful for custom visualization development and data preprocessing.</p>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils--usage-examples","title":"Usage Examples","text":"<p>Color Format Conversion</p> <pre><code>from pathpyG.visualisations.utils import rgb_to_hex, hex_to_rgb\n\n# Convert RGB to hex\nhex_color = rgb_to_hex((255, 0, 0))  # \"#ff0000\"\nhex_color = rgb_to_hex((1.0, 0.0, 0.0))  # Also \"#ff0000\"\n\n# Convert hex to RGB\nrgb_color = hex_to_rgb(\"#ff0000\")  # (255, 0, 0)\n</code></pre> <p>Unit Conversions for Layout</p> <pre><code>from pathpyG.visualisations.utils import unit_str_to_float\n\n# Convert between different units\nwidth_px = unit_str_to_float(\"12cm\", \"px\")  # Converts 12cm to pixels\nheight_in = unit_str_to_float(\"800px\", \"in\")  # Converts 800px to inches\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.cm_to_inch","title":"<code>cm_to_inch</code>","text":"<p>Convert centimeters to inches.</p> <p>Converts metric length measurements to imperial inches for compatibility with systems that use imperial units.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>Length in centimeters</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Equivalent length in inches (1 cm = 0.393701 in)</p> <p>Examples:</p> <pre><code># Convert A4 width to inches\nwidth_in = cm_to_inch(21.0)  # 8.268 inches\n\n# Convert small measurement\nthickness_in = cm_to_inch(0.1)  # 0.039 inches\n</code></pre> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def cm_to_inch(value: float) -&gt; float:\n    \"\"\"Convert centimeters to inches.\n\n    Converts metric length measurements to imperial inches for compatibility\n    with systems that use imperial units.\n\n    Args:\n        value: Length in centimeters\n\n    Returns:\n        float: Equivalent length in inches (1 cm = 0.393701 in)\n\n    Examples:\n        ```python\n        # Convert A4 width to inches\n        width_in = cm_to_inch(21.0)  # 8.268 inches\n\n        # Convert small measurement\n        thickness_in = cm_to_inch(0.1)  # 0.039 inches\n        ```\n    \"\"\"\n    return value / 2.54\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.hex_to_rgb","title":"<code>hex_to_rgb</code>","text":"<p>Convert hexadecimal color string to RGB color tuple.</p> <p>Parses standard hex color strings (with or without '#' prefix) and returns RGB values in 0-255 integer range suitable for most graphics libraries.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Hexadecimal color string (e.g., \"#ff0000\" or \"ff0000\")</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>RGB color tuple with values in range 0-255</p> <p>Examples:</p> <pre><code># Standard hex with hash\nrgb = hex_to_rgb(\"#ff0000\")  # (255, 0, 0) - red\n\n# Hex without hash\nrgb = hex_to_rgb(\"00ff00\")  # (0, 255, 0) - green\n\n# Short hex notation\nrgb = hex_to_rgb(\"#f0f\")  # (255, 0, 255) - magenta\n</code></pre> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def hex_to_rgb(value: str) -&gt; tuple:\n    \"\"\"Convert hexadecimal color string to RGB color tuple.\n\n    Parses standard hex color strings (with or without '#' prefix) and\n    returns RGB values in 0-255 integer range suitable for most graphics libraries.\n\n    Args:\n        value: Hexadecimal color string (e.g., \"#ff0000\" or \"ff0000\")\n\n    Returns:\n        tuple: RGB color tuple with values in range 0-255\n\n    Examples:\n        ```python\n        # Standard hex with hash\n        rgb = hex_to_rgb(\"#ff0000\")  # (255, 0, 0) - red\n\n        # Hex without hash\n        rgb = hex_to_rgb(\"00ff00\")  # (0, 255, 0) - green\n\n        # Short hex notation\n        rgb = hex_to_rgb(\"#f0f\")  # (255, 0, 255) - magenta\n        ```\n    \"\"\"\n    value = value.lstrip(\"#\")\n    _l = len(value)\n    return tuple((int(value[i : i + _l // 3], 16) + 1)**(6 // _l) - 1 for i in range(0, _l, _l // 3))\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.image_to_base64","title":"<code>image_to_base64</code>","text":"<p>Convert local image file to base64 data URL for embedding.</p> <p>Reads an image file from disk and converts it to a base64-encoded data URL that can be embedded directly in HTML, SVG, or other formats without requiring external file references.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <p>Path to the image file (str or Path object)</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Base64 data URL (e.g., \"data:image/png;base64,iVBORw0KGgoAAAA...\")</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified image file does not exist</p> <p>Examples:</p> <pre><code># Convert PNG logo to data URL\nlogo_data = image_to_base64(\"logo.png\")\n# Returns: \"data:image/png;base64,iVBORw0KGgoAAAA...\"\n\n# Use in HTML template\nhtml = f'&lt;img src=\"{logo_data}\" alt=\"Logo\"&gt;'\n\n# Use in SVG embedding\nsvg_image = f'&lt;image href=\"{logo_data}\" x=\"10\" y=\"10\"/&gt;'\n</code></pre> <p>Supported Formats</p> <p>Automatically detects MIME types for PNG, JPEG, GIF, and SVG files based on file extension. Defaults to PNG for unknown extensions.</p> <p>Use Cases</p> <ul> <li>Embedding images in standalone HTML/SVG files</li> <li>Creating self-contained visualizations</li> <li>Avoiding external file dependencies in templates</li> <li>Allows visualizations in VSCode Jupyter notebook- and browser-environments where local file access is restricted</li> </ul> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def image_to_base64(image_path):\n    \"\"\"Convert local image file to base64 data URL for embedding.\n\n    Reads an image file from disk and converts it to a base64-encoded data URL\n    that can be embedded directly in HTML, SVG, or other formats without\n    requiring external file references.\n\n    Args:\n        image_path: Path to the image file (str or Path object)\n\n    Returns:\n        str: Base64 data URL (e.g., \"data:image/png;base64,iVBORw0KGgoAAAA...\")\n\n    Raises:\n        FileNotFoundError: If the specified image file does not exist\n\n    Examples:\n        ```python\n        # Convert PNG logo to data URL\n        logo_data = image_to_base64(\"logo.png\")\n        # Returns: \"data:image/png;base64,iVBORw0KGgoAAAA...\"\n\n        # Use in HTML template\n        html = f'&lt;img src=\"{logo_data}\" alt=\"Logo\"&gt;'\n\n        # Use in SVG embedding\n        svg_image = f'&lt;image href=\"{logo_data}\" x=\"10\" y=\"10\"/&gt;'\n        ```\n\n    !!! info \"Supported Formats\"\n        Automatically detects MIME types for PNG, JPEG, GIF, and SVG files\n        based on file extension. Defaults to PNG for unknown extensions.\n\n    !!! tip \"Use Cases\"\n        - Embedding images in standalone HTML/SVG files\n        - Creating self-contained visualizations\n        - Avoiding external file dependencies in templates\n        - Allows visualizations in VSCode Jupyter notebook- and browser-environments where local file access is restricted\n    \"\"\"\n    path = Path(image_path)\n    if not path.exists():\n        raise FileNotFoundError(f\"Image not found: {image_path}\")\n\n    # Detect image type\n    suffix = path.suffix.lower()\n    mime_types = {\n        \".png\": \"image/png\",\n        \".jpg\": \"image/jpeg\",\n        \".jpeg\": \"image/jpeg\",\n        \".gif\": \"image/gif\",\n        \".svg\": \"image/svg+xml\",\n    }\n    mime_type = mime_types.get(suffix, \"image/png\")\n\n    # Read and encode\n    with open(image_path, \"rb\") as f:\n        encoded = base64.b64encode(f.read()).decode()\n\n    return f\"data:{mime_type};base64,{encoded}\"\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.in_jupyter_notebook","title":"<code>in_jupyter_notebook</code>","text":"<p>Detects whether the current Python session is running inside a Jupyter Notebook.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if running inside a Jupyter notebook, False otherwise</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def in_jupyter_notebook() -&gt; bool:\n    \"\"\"Detects whether the current Python session is running inside a Jupyter Notebook.\n\n    Returns:\n        bool: True if running inside a Jupyter notebook, False otherwise\n    \"\"\"\n    try:\n        return \"IPKernelApp\" in get_ipython().config\n    except NameError:\n        return False\n    except AttributeError:\n        return False\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.inch_to_cm","title":"<code>inch_to_cm</code>","text":"<p>Convert inches to centimeters.</p> <p>Converts imperial length measurements to metric centimeters for standardization and international compatibility.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>Length in inches</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Equivalent length in centimeters (1 in = 2.54 cm)</p> <p>Examples:</p> <pre><code># Convert US letter width to cm\nwidth_cm = inch_to_cm(8.5)  # 21.59 cm\n\n# Convert screen size\nscreen_cm = inch_to_cm(15.6)  # 39.624 cm\n</code></pre> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def inch_to_cm(value: float) -&gt; float:\n    \"\"\"Convert inches to centimeters.\n\n    Converts imperial length measurements to metric centimeters for\n    standardization and international compatibility.\n\n    Args:\n        value: Length in inches\n\n    Returns:\n        float: Equivalent length in centimeters (1 in = 2.54 cm)\n\n    Examples:\n        ```python\n        # Convert US letter width to cm\n        width_cm = inch_to_cm(8.5)  # 21.59 cm\n\n        # Convert screen size\n        screen_cm = inch_to_cm(15.6)  # 39.624 cm\n        ```\n    \"\"\"\n    return value * 2.54\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.inch_to_px","title":"<code>inch_to_px</code>","text":"<p>Convert inches to pixels based on DPI resolution.</p> <p>Converts physical measurements to screen pixels using dots-per-inch resolution for accurate display sizing across different screens.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>Length in inches</p> required <code>dpi</code> <code>int</code> <p>Resolution in dots per inch (default: 96 - standard web DPI)</p> <code>96</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Equivalent length in pixels</p> <p>Examples:</p> <pre><code># Standard web resolution\nwidth_px = inch_to_px(8.5)  # 816.0 pixels (96 DPI)\n\n# High-resolution display\nwidth_px = inch_to_px(8.5, 300)  # 2550.0 pixels (300 DPI)\n</code></pre> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def inch_to_px(value: float, dpi: int = 96) -&gt; float:\n    \"\"\"Convert inches to pixels based on DPI resolution.\n\n    Converts physical measurements to screen pixels using dots-per-inch\n    resolution for accurate display sizing across different screens.\n\n    Args:\n        value: Length in inches\n        dpi: Resolution in dots per inch (default: 96 - standard web DPI)\n\n    Returns:\n        float: Equivalent length in pixels\n\n    Examples:\n        ```python\n        # Standard web resolution\n        width_px = inch_to_px(8.5)  # 816.0 pixels (96 DPI)\n\n        # High-resolution display\n        width_px = inch_to_px(8.5, 300)  # 2550.0 pixels (300 DPI)\n        ```\n    \"\"\"\n    return value * dpi\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.prepare_tempfile","title":"<code>prepare_tempfile</code>","text":"<p>Prepare temporary directory for backend compilation processes.</p> <p>Creates a secure temporary directory and changes the working directory to it. This is essential for LaTeX compilation and other backends that generate intermediate files during the rendering process.</p> <p>Returns:</p> Type Description <code>tuple[str, str]</code> <p>tuple[str, str]: (temp_directory_path, original_directory_path)</p> <p>Directory Management</p> <p>The caller is responsible for:</p> <ul> <li>Restoring the original working directory</li> <li>Cleaning up the temporary directory when done</li> </ul> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def prepare_tempfile() -&gt; tuple[str, str]:\n    \"\"\"Prepare temporary directory for backend compilation processes.\n\n    Creates a secure temporary directory and changes the working directory\n    to it. This is essential for LaTeX compilation and other backends that\n    generate intermediate files during the rendering process.\n\n    Returns:\n        tuple[str, str]: (temp_directory_path, original_directory_path)\n\n    !!! warning \"Directory Management\"\n        The caller is responsible for:\n\n        - Restoring the original working directory\n        - Cleaning up the temporary directory when done\n    \"\"\"\n    # get current directory\n    current_dir = os.getcwd()\n\n    # get temporal directory\n    temp_dir = tempfile.mkdtemp()\n\n    # change to output dir\n    os.chdir(temp_dir)\n\n    return temp_dir, current_dir\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.px_to_inch","title":"<code>px_to_inch</code>","text":"<p>Convert pixels to inches based on DPI resolution.</p> <p>Converts screen pixels to physical measurements using dots-per-inch resolution for print layout and physical sizing calculations.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>Length in pixels</p> required <code>dpi</code> <code>int</code> <p>Resolution in dots per inch (default: 96 - standard web DPI)</p> <code>96</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Equivalent length in inches</p> <p>Examples:</p> <pre><code># Standard web resolution\nwidth_in = px_to_inch(800)  # 8.333 inches (96 DPI)\n\n# Print resolution conversion\nwidth_in = px_to_inch(2400, 300)  # 8.0 inches (300 DPI)\n</code></pre> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def px_to_inch(value: float, dpi: int = 96) -&gt; float:\n    \"\"\"Convert pixels to inches based on DPI resolution.\n\n    Converts screen pixels to physical measurements using dots-per-inch\n    resolution for print layout and physical sizing calculations.\n\n    Args:\n        value: Length in pixels\n        dpi: Resolution in dots per inch (default: 96 - standard web DPI)\n\n    Returns:\n        float: Equivalent length in inches\n\n    Examples:\n        ```python\n        # Standard web resolution\n        width_in = px_to_inch(800)  # 8.333 inches (96 DPI)\n\n        # Print resolution conversion\n        width_in = px_to_inch(2400, 300)  # 8.0 inches (300 DPI)\n        ```\n    \"\"\"\n    return value / dpi\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.rgb_to_hex","title":"<code>rgb_to_hex</code>","text":"<p>Convert RGB color tuple to hexadecimal color string.</p> <p>Accepts RGB values in either 0-1 float range (matplotlib style) or 0-255 integer range (web/PIL style) and converts to standard hex format.</p> <p>Parameters:</p> Name Type Description Default <code>rgb</code> <code>tuple</code> <p>RGB color tuple - either (r, g, b) with values 0-1 or 0-255</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Hexadecimal color string (e.g., \"#ff0000\" for red)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If RGB values are outside valid ranges</p> <p>Examples:</p> <pre><code># Float values (matplotlib/numpy style)\nhex_color = rgb_to_hex((1.0, 0.0, 0.0))  # \"#ff0000\" (red)\n\n# Integer values (web/PIL style)\nhex_color = rgb_to_hex((255, 128, 0))  # \"#ff8000\" (orange)\n</code></pre> <p>Format Detection</p> <p>The function automatically detects whether input values are in 0-1 or 0-255 range and converts appropriately.</p> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def rgb_to_hex(rgb: tuple) -&gt; str:\n    \"\"\"Convert RGB color tuple to hexadecimal color string.\n\n    Accepts RGB values in either 0-1 float range (matplotlib style) or\n    0-255 integer range (web/PIL style) and converts to standard hex format.\n\n    Args:\n        rgb: RGB color tuple - either (r, g, b) with values 0-1 or 0-255\n\n    Returns:\n        str: Hexadecimal color string (e.g., \"#ff0000\" for red)\n\n    Raises:\n        ValueError: If RGB values are outside valid ranges\n\n    Examples:\n        ```python\n        # Float values (matplotlib/numpy style)\n        hex_color = rgb_to_hex((1.0, 0.0, 0.0))  # \"#ff0000\" (red)\n\n        # Integer values (web/PIL style)\n        hex_color = rgb_to_hex((255, 128, 0))  # \"#ff8000\" (orange)\n        ```\n\n    !!! tip \"Format Detection\"\n        The function automatically detects whether input values are in 0-1\n        or 0-255 range and converts appropriately.\n    \"\"\"\n    if all(0.0 &lt;= val &lt;= 1.0 for val in rgb):\n        rgb = tuple(int(val * 255) for val in rgb)\n    elif not all(0 &lt;= val &lt;= 255 for val in rgb) or any(not isinstance(val, int) for val in rgb):\n        raise ValueError(\"RGB values must be in range 0-1 or 0-255.\")\n    return \"#%02x%02x%02x\" % rgb\n</code></pre>"},{"location":"reference/pathpyG/visualisations/utils/#pathpyG.visualisations.utils.unit_str_to_float","title":"<code>unit_str_to_float</code>","text":"<p>Convert string with unit suffix to float in target unit.</p> <p>Parses strings containing numeric values with unit suffixes (e.g., \"10px\", \"5cm\") and converts to the specified target unit using appropriate conversion functions.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>String with numeric value and 2-character unit suffix</p> required <code>unit</code> <code>str</code> <p>Target unit for conversion (\"px\", \"cm\", \"in\")</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Converted numeric value in target unit</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If conversion between units is not supported</p> <p>Examples:</p> <pre><code># Convert pixel string to centimeters\ncm_value = unit_str_to_float(\"800px\", \"cm\")  # 21.17 cm (96 DPI)\n\n# Convert cm string to inches\nin_value = unit_str_to_float(\"21cm\", \"in\")  # 8.268 inches\n\n# Same unit (no conversion needed)\npx_value = unit_str_to_float(\"100px\", \"px\")  # 100.0\n</code></pre> <p>Supported Conversions</p> <p>Only supports conversions between \"px\", \"cm\", and \"in\" units. Pixel conversions assume 96 DPI by default.</p> <p>Supported conversion patterns:</p> From To Function cm in <code>cm_to_inch()</code> in cm <code>inch_to_cm()</code> in px <code>inch_to_px()</code> px in <code>px_to_inch()</code> cm px <code>cm_to_inch() + inch_to_px()</code> px cm <code>px_to_inch() + inch_to_cm()</code> Source code in <code>src/pathpyG/visualisations/utils.py</code> <pre><code>def unit_str_to_float(value: str, unit: str) -&gt; float:\n    \"\"\"Convert string with unit suffix to float in target unit.\n\n    Parses strings containing numeric values with unit suffixes (e.g., \"10px\", \"5cm\")\n    and converts to the specified target unit using appropriate conversion functions.\n\n    Args:\n        value: String with numeric value and 2-character unit suffix\n        unit: Target unit for conversion (\"px\", \"cm\", \"in\")\n\n    Returns:\n        float: Converted numeric value in target unit\n\n    Raises:\n        ValueError: If conversion between units is not supported\n\n    Examples:\n        ```python\n        # Convert pixel string to centimeters\n        cm_value = unit_str_to_float(\"800px\", \"cm\")  # 21.17 cm (96 DPI)\n\n        # Convert cm string to inches\n        in_value = unit_str_to_float(\"21cm\", \"in\")  # 8.268 inches\n\n        # Same unit (no conversion needed)\n        px_value = unit_str_to_float(\"100px\", \"px\")  # 100.0\n        ```\n\n    !!! warning \"Supported Conversions\"\n        Only supports conversions between \"px\", \"cm\", and \"in\" units.\n        Pixel conversions assume 96 DPI by default.\n\n    Supported conversion patterns:\n\n    | From | To | Function |\n    |------|----| ---------|\n    | cm   | in | `cm_to_inch()` |\n    | in   | cm | `inch_to_cm()` |\n    | in   | px | `inch_to_px()` |\n    | px   | in | `px_to_inch()` |\n    | cm   | px | `cm_to_inch() + inch_to_px()` |\n    | px   | cm | `px_to_inch() + inch_to_cm()` |\n    \"\"\"\n    conversion_functions: dict[str, Callable[[float], float]] = {\n        \"cm_to_in\": cm_to_inch,\n        \"in_to_cm\": inch_to_cm,\n        \"in_to_px\": inch_to_px,\n        \"px_to_in\": px_to_inch,\n        \"cm_to_px\": lambda x: inch_to_px(cm_to_inch(x)),\n        \"px_to_cm\": lambda x: inch_to_cm(px_to_inch(x)),\n    }\n    conversion_key = f\"{value[-2:]}_to_{unit}\"\n    if conversion_key in conversion_functions:\n        return conversion_functions[conversion_key](float(value[:-2]))\n    elif value[-2:] == unit:\n        return float(value[:-2])\n    else:\n        raise ValueError(f\"The provided conversion '{conversion_key}' is not supported.\")\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/","title":"d3js","text":"<p>D3.js Backend for PathpyG Visualizations.</p> <p>Interactive web-based visualization backend using D3.js for both static and temporal networks. Default backend providing rich interactivity, real-time exploration, and web-compatible output.</p> <p>Output Formats</p> <ul> <li>HTML: Interactive web visualizations where nodes can be dragged around and temporal graphs can be paused/played.</li> </ul> <p>Default Backend</p> <p>D3.js is the default visualization backend for PathpyG, automatically selected when no specific backend is specified. No additional dependencies required beyond web browser.</p>"},{"location":"reference/pathpyG/visualisations/_d3js/#pathpyG.visualisations._d3js--basic-usage","title":"Basic Usage","text":"<pre><code>import pathpyG as pp\n\n# Simple network visualization\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g)  # Uses d3.js backend by default\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/#pathpyG.visualisations._d3js--advanced-temporal-network-example","title":"Advanced Temporal Network Example","text":"<pre><code>import torch\nimport pathpyG as pp\n\n# Temporal network with evolving properties\ntedges = [\n    (\"a\", \"b\", 1), (\"b\", \"c\", 1),\n    (\"c\", \"d\", 2), (\"d\", \"a\", 2), \n    (\"a\", \"c\", 3), (\"b\", \"d\", 3)\n]\ntg = pp.TemporalGraph.from_edge_list(tedges)\ntg.data[\"edge_color\"] = torch.arange(tg.m)  # Assign a unique color index to each edge\n\npp.plot(\n    tg,\n    delta=750,  # 0.75 seconds per timestep\n    node_size={(\"a\", 1): 20, (\"b\", 2): 7},\n    node_color=[\"red\", \"blue\", \"green\", \"orange\"],\n    edge_opacity=0.7,\n    filename=\"dynamic_network.html\"\n)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/#pathpyG.visualisations._d3js--network-visualization-with-custom-images","title":"Network Visualization with custom Images","text":"<p>With D3.js, you can easily use custom images for nodes by providing URLs or local paths.</p> <pre><code>import torch\nimport pathpyG as pp\n\n# Example network data\nedges = [\n    (\"b\", \"a\"),\n    (\"c\", \"a\"),\n]\nmapping = pp.IndexMap([\"a\", \"b\", \"c\", \"d\"])\ng = pp.Graph.from_edge_list(edges, mapping=mapping)\ng.data[\"node_size\"] = torch.tensor([25]*4)\npp.plot(\n    g,\n    node_size={\"d\": 50},\n    edge_size=5,\n    node_image={\n        \"a\": \"https://avatars.githubusercontent.com/u/52822508?s=48&amp;v=4\",\n        \"b\": \"https://raw.githubusercontent.com/pyg-team/pyg_sphinx_theme/master/pyg_sphinx_theme/static/img/pyg_logo.png\",\n        \"c\": \"https://pytorch-geometric.readthedocs.io/en/latest/_static/img/pytorch_logo.svg\",\n        \"d\": \"docs/img/pathpy_logo_new.png\",\n    },\n    show_labels=False,\n)\n</code></pre> <p>Deployment Options</p> <ul> <li>Standalone: Self-contained HTML with embedded resources</li> <li>Jupyter: Direct display in notebook cells</li> <li>Web Apps: Easy integration into existing websites</li> </ul>"},{"location":"reference/pathpyG/visualisations/_d3js/#pathpyG.visualisations._d3js--time-unfolded-network","title":"Time-Unfolded Network","text":"<p>Below is an example of a time-unfolded network visualization using the D3.js backend.</p> <pre><code>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"d\", 1),\n    (\"b\", \"c\", 2),\n    (\"b\", \"c\", 3),\n    (\"b\", \"a\", 3),\n    (\"d\", \"b\", 4),\n\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\npp.plot(t, kind=\"unfolded\", show_labels=False)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/#pathpyG.visualisations._d3js--templates","title":"Templates","text":"<p>PathpyG uses HTML templates to generate D3.js visualizations located in the <code>templates</code> directory. Templates define the overall structure and include placeholders for dynamic content. Currently used templates:</p> <ul> <li><code>network.js</code>: A basic template for static and temporal networks</li> <li><code>setup.js</code>: Loads requireJS and D3.js libraries</li> <li><code>styles.css</code>: Basic CSS styling for the visualizations</li> <li><code>static.js</code>: Template for static networks that initializes the network from <code>network.js</code></li> <li><code>temporal.js</code>: Template for temporal networks that initializes the network from <code>network.js</code> with temporal controls</li> <li><code>d3.v7.min.js</code>: D3.js library (version 7) for using D3.js functionalities without internet connection</li> </ul>"},{"location":"reference/pathpyG/visualisations/_d3js/backend/","title":"backend","text":"<p>D3.js backend for interactive web-based network visualization.</p> <p>Template-driven HTML generation using D3.js library for rich interactive visualizations. Supports both static and temporal networks with embedded JavaScript, and CSS styling.</p> <p>!!! abstract \"Features\":     - Interactive HTML output with drag-and-drop node movement     - Template-based architecture for extensibility     - Both static and temporal network support     - Jupyter notebook integration with inline display</p>"},{"location":"reference/pathpyG/visualisations/_d3js/backend/#pathpyG.visualisations._d3js.backend.D3jsBackend","title":"<code>D3jsBackend</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot_backend.PlotBackend</code></p> <p>D3.js backend for interactive web visualization with template system.</p> <p>Generates self-contained HTML files with embedded D3.js visualizations using modular template architecture. Supports both static and temporal networks with rich interactivity and web-standard compatibility.</p> Features <ul> <li>Template-driven HTML generation (CSS + JavaScript + data)</li> <li>Multiple output modes: standalone HTML, Jupyter display, browser</li> <li>JSON data serialization with proper type conversion</li> </ul> Example <pre><code>import pathpyG as pp\n\n# Simple network visualization\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g)  # Uses d3.js backend by default\n</code></pre> <p>Template Architecture</p> <p>Uses modular templates for extensibility:</p> <ul> <li><code>styles.css</code>: Visual styling and responsive design</li> <li><code>setup.js</code>: Environment detection and D3.js loading</li> <li><code>network.js</code>: Core network visualization logic</li> <li><code>static.js</code> / <code>temporal.js</code>: Plot-type specific functionality</li> </ul> <p>Web Standards</p> <p>Generates standards-compliant HTML5 with SVG graphics, compatible with all modern browsers without plugins.</p> Source code in <code>src/pathpyG/visualisations/_d3js/backend.py</code> <pre><code>class D3jsBackend(PlotBackend):\n    \"\"\"D3.js backend for interactive web visualization with template system.\n\n    Generates self-contained HTML files with embedded D3.js visualizations\n    using modular template architecture. Supports both static and temporal\n    networks with rich interactivity and web-standard compatibility.\n\n    Features:\n        - Template-driven HTML generation (CSS + JavaScript + data)\n        - Multiple output modes: standalone HTML, Jupyter display, browser\n        - JSON data serialization with proper type conversion\n\n    Example:\n        ```python\n        import pathpyG as pp\n\n        # Simple network visualization\n        edges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\n        g = pp.Graph.from_edge_list(edges)\n        pp.plot(g)  # Uses d3.js backend by default\n        ```\n        &lt;iframe src=\"../../plot/simple_network.html\" width=\"650\" height=\"520\"&gt;&lt;/iframe&gt;\n\n    !!! info \"Template Architecture\"\n        Uses modular templates for extensibility:\n\n        - `styles.css`: Visual styling and responsive design\n        - `setup.js`: Environment detection and D3.js loading\n        - `network.js`: Core network visualization logic\n        - `static.js` / `temporal.js`: Plot-type specific functionality\n\n    !!! note \"Web Standards\"\n        Generates standards-compliant HTML5 with SVG graphics,\n        compatible with all modern browsers without plugins.\n    \"\"\"\n\n    def __init__(self, plot: PathPyPlot, show_labels: bool):\n        \"\"\"Initialize D3.js backend with plot validation and configuration.\n\n        Args:\n            plot: PathPyPlot instance (NetworkPlot or TemporalNetworkPlot)\n            show_labels: Whether to display node labels in visualization\n\n        Raises:\n            ValueError: If plot type not supported by D3.js backend\n\n        !!! tip \"Supported Plot Types\"\n            - **NetworkPlot**: Static network visualization\n            - **TemporalNetworkPlot**: Animated temporal network evolution\n        \"\"\"\n        super().__init__(plot, show_labels)\n        self._kind = SUPPORTED_KINDS.get(type(plot), None)\n        if self._kind is None:\n            logger.error(f\"Plot of type {type(plot)} not supported by D3js backend.\")\n            raise ValueError(f\"Plot of type {type(plot)} not supported.\")\n\n    def save(self, filename: str) -&gt; None:\n        \"\"\"Save interactive visualization as standalone HTML file.\n\n        Creates self-contained HTML file with embedded D3.js visualization,\n        complete with styling, JavaScript, and data. File can be opened\n        in any web browser or served from web servers.\n\n        Args:\n            filename: Output HTML file path\n\n        !!! tip \"Deployment Ready\"\n            Generated HTML files are standalone and can be:\n\n            - Opened directly in browsers\n            - Served from web servers\n            - Embedded in websites or documentation\n            - Shared without additional dependencies\n        \"\"\"\n        # Default to the CDN version of d3js since browsers may block local scripts\n        self.config[\"d3js_local\"] = self.config.get(\"d3js_local\", False)\n        with open(filename, \"w+\") as new:\n            new.write(self.to_html())\n\n    def show(self) -&gt; None:\n        \"\"\"Display visualization in appropriate environment.\n\n        Automatically detects environment and displays visualization:\n        - Jupyter notebooks: Inline HTML display with IPython widgets\n        - Scripts/terminals: Opens temporary HTML file in system browser\n\n        !!! info \"Environment Detection\"\n            Uses pathpyG config to detect interactive environment\n            and choose appropriate display method automatically.\n        \"\"\"\n        # Default to local d3js in Jupyter notebooks for offline use\n        self.config[\"d3js_local\"] = self.config.get(\"d3js_local\", False or in_jupyter_notebook())\n        if config[\"environment\"][\"interactive\"]:\n            from IPython.display import display_html, HTML  # noqa I001\n\n            display_html(HTML(self.to_html()))\n        else:\n            # create temporal file\n            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n                # save html\n                self.save(filename=temp_file.name)\n                # open the file\n                webbrowser.open(r\"file:///\" + temp_file.name)\n\n    def _prepare_data(self) -&gt; dict:\n        \"\"\"Transform network data for JSON serialization and D3.js consumption.\n\n        Converts pandas DataFrames to D3.js-compatible format with proper\n        node/edge structure. Handles coordinate renaming and unique ID generation\n        for JavaScript processing.\n\n        Returns:\n            dict: Structured data with 'nodes' and 'edges' arrays\n\n        !!! note \"Data Structure\"\n            **Nodes**: Include uid, coordinates (xpos/ypos), and all attributes\n\n            **Edges**: Include uid, source/target references, and styling\n        \"\"\"\n        node_data = self.data[\"nodes\"].copy()\n        node_data[\"uid\"] = self.data[\"nodes\"].index.map(lambda x: f\"({x[0]},{x[1]})\" if isinstance(x, tuple) else str(x))\n        node_data = node_data.rename(columns={\"x\": \"xpos\", \"y\": \"ypos\"})\n        if self._kind == \"unfolded\":\n            node_data[\"ypos\"] = 1 - node_data[\"ypos\"]  # Invert y-axis for unfolded layout\n        edge_data = self.data[\"edges\"].copy()\n        edge_data[\"uid\"] = self.data[\"edges\"].index.map(lambda x: f\"{x[0]}-{x[1]}\")\n        edge_data[\"source\"] = edge_data.index.to_frame()[\"source\"].map(lambda x: f\"({x[0]},{x[1]})\" if isinstance(x, tuple) else str(x))\n        edge_data[\"target\"] = edge_data.index.to_frame()[\"target\"].map(lambda x: f\"({x[0]},{x[1]})\" if isinstance(x, tuple) else str(x))\n        data_dict = {\n            \"nodes\": node_data.to_dict(orient=\"records\"),\n            \"edges\": edge_data.to_dict(orient=\"records\"),\n        }\n        return data_dict\n\n    def _prepare_config(self) -&gt; dict:\n        \"\"\"Transform configuration for JavaScript compatibility.\n\n        Converts pathpyG configuration to web-compatible format with proper\n        color conversion, unit normalization, and JavaScript-friendly types.\n\n        Returns:\n            dict: Web-compatible configuration object\n\n        !!! info \"Configuration Processing\"\n            - **Colors**: Convert to hex format for CSS compatibility\n            - **Units**: Convert to pixels for SVG rendering\n            - **Types**: Ensure JSON-serializable data types\n        \"\"\"\n        config = deepcopy(self.config)\n        config[\"node\"][\"color\"] = rgb_to_hex(self.config[\"node\"][\"color\"])\n        config[\"edge\"][\"color\"] = rgb_to_hex(self.config[\"edge\"][\"color\"])\n        config[\"width\"] = unit_str_to_float(self.config[\"width\"], \"px\")\n        config[\"height\"] = unit_str_to_float(self.config[\"height\"], \"px\")\n        config[\"show_labels\"] = self.show_labels\n        return config\n\n    def to_json(self) -&gt; tuple[str, str]:\n        \"\"\"Serialize network data and configuration to JSON strings.\n\n        Processes both data and configuration through preparation methods\n        and converts to JSON format suitable for JavaScript consumption.\n\n        Returns:\n            tuple: (data_json, config_json) string pair for template injection\n\n        !!! tip \"Template Integration\"\n            JSON strings are injected directly into JavaScript templates\n            as `const data = {...}` and `const config = {...}` declarations.\n        \"\"\"\n        data_dict = self._prepare_data()\n        config_dict = self._prepare_config()\n        return json.dumps(data_dict), json.dumps(config_dict)\n\n    def to_html(self) -&gt; str:\n        \"\"\"Generate complete standalone HTML visualization.\n\n        Assembles full HTML document using template system with embedded CSS,\n        JavaScript, and data. Creates unique DOM IDs to prevent conflicts\n        when multiple visualizations exist on same page.\n\n        Returns:\n            str: Complete HTML document with embedded visualization\n\n        !!! info \"HTML Structure\"\n            1. **CSS Styles**: Embedded styling\n            2. **DOM Container**: Unique div element for visualization\n            3. **D3.js Library**: CDN or local library loading\n            4. **Setup Code**: Environment detection and module loading\n            5. **Data/Config**: JSON-serialized network and configuration\n            6. **Visualization**: Plot-specific JavaScript execution\n\n        !!! note \"Library Loading\"\n            Supports both CDN and local (default) D3.js library embedding\n            based on `d3js_local` configuration parameter.\n        \"\"\"\n        # generate unique dom uids\n        dom_id = \"#x\" + uuid.uuid4().hex\n\n        # get path to the pathpy templates\n        template_dir = os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"_d3js/templates\"),\n        )\n\n        # get d3js library path\n        if self.config.get(\"d3js_local\", False):\n            d3js = os.path.join(template_dir, \"d3.v7.min.js\")\n        else:\n            d3js = \"https://d3js.org/d3.v7.min.js\"\n\n        js_template = self.get_template(template_dir)\n\n        with open(os.path.join(template_dir, \"setup.js\")) as template:\n            setup_template = template.read()\n\n        with open(os.path.join(template_dir, \"styles.css\")) as template:\n            css_template = template.read()\n\n        # update config\n        self.config[\"selector\"] = dom_id\n        data_json, config_json = self.to_json()\n\n        # generate html file\n        html = \"&lt;style&gt;\\n\" + css_template + \"\\n&lt;/style&gt;\\n\"\n\n        # div environment for the plot object\n        html += f'\\n&lt;div id = \"{dom_id[1:]}\"&gt; &lt;/div&gt;\\n'\n\n        # add d3js library\n        html += f'&lt;script charset=\"utf-8\" src=\"{d3js}\"&gt;&lt;/script&gt;\\n'\n\n        # start JavaScript\n        html += '&lt;script charset=\"utf-8\"&gt;\\n'\n\n        # add setup code to run d3js in multiple environments\n        html += Template(setup_template).substitute(d3js=d3js)\n\n        # start d3 environment\n        html += \"require(['d3'], function(d3){ //START\\n\"\n\n        # add data and config\n        html += f\"const data = {data_json}\\n\"\n        html += f\"const config = {config_json}\\n\"\n\n        # add log print\n        html += f\"console.log('{self._kind} Network Template');\\n\"\n\n        # add JavaScript\n        html += js_template\n\n        # end d3 environment\n        html += \"\\n}); //END\\n\"\n\n        # end JavaScript\n        html += \"\\n&lt;/script&gt;\"\n\n        return html\n\n    def get_template(self, template_dir: str) -&gt; str:\n        \"\"\"Load and combine JavaScript templates for visualization.\n\n        Assembles modular JavaScript code by combining core network\n        functionality with plot-type specific features. Enables clean\n        separation of concerns and extensible template architecture.\n\n        Args:\n            template_dir: Directory containing JavaScript template files\n\n        Returns:\n            str: Combined JavaScript code for visualization\n\n        !!! info \"Template Composition\"\n            **Core Template** (`network.js`): Base network visualization logic\n\n            **Plot Templates**: Type-specific functionality:\n\n            - `static.js`: Force simulation and interaction for static networks\n            - `temporal.js`: Timeline controls and animation for temporal networks\n\n        !!! tip \"Extensibility\"\n            New plot types can be added by creating additional\n            JavaScript templates following the established patterns.\n        \"\"\"\n        js_template = \"\"\n        with open(os.path.join(template_dir, \"network.js\")) as template:\n            js_template += template.read()\n\n        with open(\n            os.path.join(template_dir, \"static.js\" if self._kind == \"unfolded\" else f\"{self._kind}.js\")\n        ) as template:\n            js_template += template.read()\n\n        return js_template\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/backend/#pathpyG.visualisations._d3js.backend.D3jsBackend.__init__","title":"<code>__init__</code>","text":"<p>Initialize D3.js backend with plot validation and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>plot</code> <code>pathpyG.visualisations.pathpy_plot.PathPyPlot</code> <p>PathPyPlot instance (NetworkPlot or TemporalNetworkPlot)</p> required <code>show_labels</code> <code>bool</code> <p>Whether to display node labels in visualization</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If plot type not supported by D3.js backend</p> <p>Supported Plot Types</p> <ul> <li>NetworkPlot: Static network visualization</li> <li>TemporalNetworkPlot: Animated temporal network evolution</li> </ul> Source code in <code>src/pathpyG/visualisations/_d3js/backend.py</code> <pre><code>def __init__(self, plot: PathPyPlot, show_labels: bool):\n    \"\"\"Initialize D3.js backend with plot validation and configuration.\n\n    Args:\n        plot: PathPyPlot instance (NetworkPlot or TemporalNetworkPlot)\n        show_labels: Whether to display node labels in visualization\n\n    Raises:\n        ValueError: If plot type not supported by D3.js backend\n\n    !!! tip \"Supported Plot Types\"\n        - **NetworkPlot**: Static network visualization\n        - **TemporalNetworkPlot**: Animated temporal network evolution\n    \"\"\"\n    super().__init__(plot, show_labels)\n    self._kind = SUPPORTED_KINDS.get(type(plot), None)\n    if self._kind is None:\n        logger.error(f\"Plot of type {type(plot)} not supported by D3js backend.\")\n        raise ValueError(f\"Plot of type {type(plot)} not supported.\")\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/backend/#pathpyG.visualisations._d3js.backend.D3jsBackend.get_template","title":"<code>get_template</code>","text":"<p>Load and combine JavaScript templates for visualization.</p> <p>Assembles modular JavaScript code by combining core network functionality with plot-type specific features. Enables clean separation of concerns and extensible template architecture.</p> <p>Parameters:</p> Name Type Description Default <code>template_dir</code> <code>str</code> <p>Directory containing JavaScript template files</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Combined JavaScript code for visualization</p> <p>Template Composition</p> <p>Core Template (<code>network.js</code>): Base network visualization logic</p> <p>Plot Templates: Type-specific functionality:</p> <ul> <li><code>static.js</code>: Force simulation and interaction for static networks</li> <li><code>temporal.js</code>: Timeline controls and animation for temporal networks</li> </ul> <p>Extensibility</p> <p>New plot types can be added by creating additional JavaScript templates following the established patterns.</p> Source code in <code>src/pathpyG/visualisations/_d3js/backend.py</code> <pre><code>def get_template(self, template_dir: str) -&gt; str:\n    \"\"\"Load and combine JavaScript templates for visualization.\n\n    Assembles modular JavaScript code by combining core network\n    functionality with plot-type specific features. Enables clean\n    separation of concerns and extensible template architecture.\n\n    Args:\n        template_dir: Directory containing JavaScript template files\n\n    Returns:\n        str: Combined JavaScript code for visualization\n\n    !!! info \"Template Composition\"\n        **Core Template** (`network.js`): Base network visualization logic\n\n        **Plot Templates**: Type-specific functionality:\n\n        - `static.js`: Force simulation and interaction for static networks\n        - `temporal.js`: Timeline controls and animation for temporal networks\n\n    !!! tip \"Extensibility\"\n        New plot types can be added by creating additional\n        JavaScript templates following the established patterns.\n    \"\"\"\n    js_template = \"\"\n    with open(os.path.join(template_dir, \"network.js\")) as template:\n        js_template += template.read()\n\n    with open(\n        os.path.join(template_dir, \"static.js\" if self._kind == \"unfolded\" else f\"{self._kind}.js\")\n    ) as template:\n        js_template += template.read()\n\n    return js_template\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/backend/#pathpyG.visualisations._d3js.backend.D3jsBackend.save","title":"<code>save</code>","text":"<p>Save interactive visualization as standalone HTML file.</p> <p>Creates self-contained HTML file with embedded D3.js visualization, complete with styling, JavaScript, and data. File can be opened in any web browser or served from web servers.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Output HTML file path</p> required <p>Deployment Ready</p> <p>Generated HTML files are standalone and can be:</p> <ul> <li>Opened directly in browsers</li> <li>Served from web servers</li> <li>Embedded in websites or documentation</li> <li>Shared without additional dependencies</li> </ul> Source code in <code>src/pathpyG/visualisations/_d3js/backend.py</code> <pre><code>def save(self, filename: str) -&gt; None:\n    \"\"\"Save interactive visualization as standalone HTML file.\n\n    Creates self-contained HTML file with embedded D3.js visualization,\n    complete with styling, JavaScript, and data. File can be opened\n    in any web browser or served from web servers.\n\n    Args:\n        filename: Output HTML file path\n\n    !!! tip \"Deployment Ready\"\n        Generated HTML files are standalone and can be:\n\n        - Opened directly in browsers\n        - Served from web servers\n        - Embedded in websites or documentation\n        - Shared without additional dependencies\n    \"\"\"\n    # Default to the CDN version of d3js since browsers may block local scripts\n    self.config[\"d3js_local\"] = self.config.get(\"d3js_local\", False)\n    with open(filename, \"w+\") as new:\n        new.write(self.to_html())\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/backend/#pathpyG.visualisations._d3js.backend.D3jsBackend.show","title":"<code>show</code>","text":"<p>Display visualization in appropriate environment.</p> <p>Automatically detects environment and displays visualization: - Jupyter notebooks: Inline HTML display with IPython widgets - Scripts/terminals: Opens temporary HTML file in system browser</p> <p>Environment Detection</p> <p>Uses pathpyG config to detect interactive environment and choose appropriate display method automatically.</p> Source code in <code>src/pathpyG/visualisations/_d3js/backend.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Display visualization in appropriate environment.\n\n    Automatically detects environment and displays visualization:\n    - Jupyter notebooks: Inline HTML display with IPython widgets\n    - Scripts/terminals: Opens temporary HTML file in system browser\n\n    !!! info \"Environment Detection\"\n        Uses pathpyG config to detect interactive environment\n        and choose appropriate display method automatically.\n    \"\"\"\n    # Default to local d3js in Jupyter notebooks for offline use\n    self.config[\"d3js_local\"] = self.config.get(\"d3js_local\", False or in_jupyter_notebook())\n    if config[\"environment\"][\"interactive\"]:\n        from IPython.display import display_html, HTML  # noqa I001\n\n        display_html(HTML(self.to_html()))\n    else:\n        # create temporal file\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            # save html\n            self.save(filename=temp_file.name)\n            # open the file\n            webbrowser.open(r\"file:///\" + temp_file.name)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/backend/#pathpyG.visualisations._d3js.backend.D3jsBackend.to_html","title":"<code>to_html</code>","text":"<p>Generate complete standalone HTML visualization.</p> <p>Assembles full HTML document using template system with embedded CSS, JavaScript, and data. Creates unique DOM IDs to prevent conflicts when multiple visualizations exist on same page.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Complete HTML document with embedded visualization</p> <p>HTML Structure</p> <ol> <li>CSS Styles: Embedded styling</li> <li>DOM Container: Unique div element for visualization</li> <li>D3.js Library: CDN or local library loading</li> <li>Setup Code: Environment detection and module loading</li> <li>Data/Config: JSON-serialized network and configuration</li> <li>Visualization: Plot-specific JavaScript execution</li> </ol> <p>Library Loading</p> <p>Supports both CDN and local (default) D3.js library embedding based on <code>d3js_local</code> configuration parameter.</p> Source code in <code>src/pathpyG/visualisations/_d3js/backend.py</code> <pre><code>def to_html(self) -&gt; str:\n    \"\"\"Generate complete standalone HTML visualization.\n\n    Assembles full HTML document using template system with embedded CSS,\n    JavaScript, and data. Creates unique DOM IDs to prevent conflicts\n    when multiple visualizations exist on same page.\n\n    Returns:\n        str: Complete HTML document with embedded visualization\n\n    !!! info \"HTML Structure\"\n        1. **CSS Styles**: Embedded styling\n        2. **DOM Container**: Unique div element for visualization\n        3. **D3.js Library**: CDN or local library loading\n        4. **Setup Code**: Environment detection and module loading\n        5. **Data/Config**: JSON-serialized network and configuration\n        6. **Visualization**: Plot-specific JavaScript execution\n\n    !!! note \"Library Loading\"\n        Supports both CDN and local (default) D3.js library embedding\n        based on `d3js_local` configuration parameter.\n    \"\"\"\n    # generate unique dom uids\n    dom_id = \"#x\" + uuid.uuid4().hex\n\n    # get path to the pathpy templates\n    template_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)),\n        os.path.normpath(\"_d3js/templates\"),\n    )\n\n    # get d3js library path\n    if self.config.get(\"d3js_local\", False):\n        d3js = os.path.join(template_dir, \"d3.v7.min.js\")\n    else:\n        d3js = \"https://d3js.org/d3.v7.min.js\"\n\n    js_template = self.get_template(template_dir)\n\n    with open(os.path.join(template_dir, \"setup.js\")) as template:\n        setup_template = template.read()\n\n    with open(os.path.join(template_dir, \"styles.css\")) as template:\n        css_template = template.read()\n\n    # update config\n    self.config[\"selector\"] = dom_id\n    data_json, config_json = self.to_json()\n\n    # generate html file\n    html = \"&lt;style&gt;\\n\" + css_template + \"\\n&lt;/style&gt;\\n\"\n\n    # div environment for the plot object\n    html += f'\\n&lt;div id = \"{dom_id[1:]}\"&gt; &lt;/div&gt;\\n'\n\n    # add d3js library\n    html += f'&lt;script charset=\"utf-8\" src=\"{d3js}\"&gt;&lt;/script&gt;\\n'\n\n    # start JavaScript\n    html += '&lt;script charset=\"utf-8\"&gt;\\n'\n\n    # add setup code to run d3js in multiple environments\n    html += Template(setup_template).substitute(d3js=d3js)\n\n    # start d3 environment\n    html += \"require(['d3'], function(d3){ //START\\n\"\n\n    # add data and config\n    html += f\"const data = {data_json}\\n\"\n    html += f\"const config = {config_json}\\n\"\n\n    # add log print\n    html += f\"console.log('{self._kind} Network Template');\\n\"\n\n    # add JavaScript\n    html += js_template\n\n    # end d3 environment\n    html += \"\\n}); //END\\n\"\n\n    # end JavaScript\n    html += \"\\n&lt;/script&gt;\"\n\n    return html\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_d3js/backend/#pathpyG.visualisations._d3js.backend.D3jsBackend.to_json","title":"<code>to_json</code>","text":"<p>Serialize network data and configuration to JSON strings.</p> <p>Processes both data and configuration through preparation methods and converts to JSON format suitable for JavaScript consumption.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[str, str]</code> <p>(data_json, config_json) string pair for template injection</p> <p>Template Integration</p> <p>JSON strings are injected directly into JavaScript templates as <code>const data = {...}</code> and <code>const config = {...}</code> declarations.</p> Source code in <code>src/pathpyG/visualisations/_d3js/backend.py</code> <pre><code>def to_json(self) -&gt; tuple[str, str]:\n    \"\"\"Serialize network data and configuration to JSON strings.\n\n    Processes both data and configuration through preparation methods\n    and converts to JSON format suitable for JavaScript consumption.\n\n    Returns:\n        tuple: (data_json, config_json) string pair for template injection\n\n    !!! tip \"Template Integration\"\n        JSON strings are injected directly into JavaScript templates\n        as `const data = {...}` and `const config = {...}` declarations.\n    \"\"\"\n    data_dict = self._prepare_data()\n    config_dict = self._prepare_config()\n    return json.dumps(data_dict), json.dumps(config_dict)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/","title":"manim","text":"<p>Manim Backend for PathpyG Visualizations.</p> <p>High-quality animation backend using Manim for temporal networks and dynamic visualizations. Perfect for creating engaging presentations, educational content, and scientific animations.</p> <p>Output Formats</p> <ul> <li>MP4: High-quality video animations for presentations</li> <li>GIF: Animated graphics for web and social media</li> </ul> <p>Requirements</p> <ul> <li>Manim Community Edition (<code>pip install manim</code>)</li> <li>FFmpeg for video rendering</li> <li>LaTeX distribution for mathematical text</li> </ul>"},{"location":"reference/pathpyG/visualisations/_manim/#pathpyG.visualisations._manim--basic-usage","title":"Basic Usage","text":"<pre><code>import pathpyG as pp\n\n# Simple temporal network animation\ntedges = [(\"a\", \"b\", 1), (\"b\", \"c\", 2), (\"c\", \"a\", 3)]\ntg = pp.TemporalGraph.from_edge_list(tedges)\npp.plot(tg, backend=\"manim\", filename=\"temporal_network.mp4\")\n</code></pre>    Your browser does not support the video tag."},{"location":"reference/pathpyG/visualisations/_manim/#pathpyG.visualisations._manim--advanced-example","title":"Advanced Example","text":"<pre><code>import pathpyG as pp\n\n# Temporal network with evolving properties\ntedges = [\n    (\"a\", \"b\", 1), (\"b\", \"c\", 1),\n    (\"c\", \"d\", 2), (\"d\", \"a\", 2), \n    (\"a\", \"c\", 3), (\"b\", \"d\", 3)\n]\ntg = pp.TemporalGraph.from_edge_list(tedges)\n\npp.plot(\n    tg,\n    backend=\"manim\",\n    delta=2000,                    # 2 seconds per timestep\n    node_size={(\"a\", 1): 20, (\"b\", 2): 7},\n    node_color=[\"red\", \"blue\", \"green\", \"orange\"],\n    edge_opacity=0.7,\n    edge_color={(\"a\", \"b\", 1): \"purple\", (\"c\", \"d\", 2): \"orange\"},\n    filename=\"dynamic_network.mp4\"\n)\n</code></pre>    Your browser does not support the video tag.  <p>Rendering Time</p> <p>High-quality animations can take significant time to render. A 60-second animation of a medium-sized network at high quality  may take 5-30 minutes depending on the hardware specifications.</p>"},{"location":"reference/pathpyG/visualisations/_manim/backend/","title":"backend","text":"<p>Manim backend for high-quality temporal network animations.</p> <p>Professional animation backend using Manim Community Edition for creating high-quality temporal network visualizations. Optimized for temporal graphs with smooth transitions and customizable animation parameters.</p> Features <ul> <li>High-quality video output (MP4, GIF)</li> <li>Temporal network animation with smooth transitions</li> <li>Jupyter notebook integration with inline video display</li> <li>FFmpeg integration for format conversion</li> </ul>"},{"location":"reference/pathpyG/visualisations/_manim/backend/#pathpyG.visualisations._manim.backend--workflow-overview","title":"Workflow Overview","text":"<pre><code>graph LR\n    A[Graph Data] --&gt; B[Manim Scene Creation]\n    B --&gt; C[Rendering]\n    C --&gt; D[MP4 Output]\n    D --&gt; E[Conversion]\n    E --&gt; F[GIF Output]</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/backend/#pathpyG.visualisations._manim.backend.ManimBackend","title":"<code>ManimBackend</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot_backend.PlotBackend</code></p> <p>Manim backend for temporal network animation.</p> <p>Integrates Manim Community Edition for creating smooth temporal network animations. Supports both MP4 and GIF output formats with Jupyter notebook integration for inline display.</p> Features <ul> <li>Temporal network animation with smooth node/edge transitions</li> <li>Multiple output formats (MP4, GIF via FFmpeg)</li> <li>Jupyter integration with base64 video embedding</li> </ul> Example <p>Create and display a simple temporal network animation: <pre><code>import pathpyG as pp\n\ntedges = [(\"a\", \"b\", 1), (\"b\", \"c\", 2), (\"c\", \"a\", 3)]\ntg = pp.TemporalGraph.from_edge_list(tedges)\npp.plot(tg, backend=\"manim\", filename=\"temporal_network.gif\")\n</code></pre> </p> <p>Temporal Networks Only</p> <p>This backend is specifically designed for TemporalNetworkPlot objects and does not support static network visualization.</p> <p>Performance Requirements</p> <p>High-quality animations require significant computational resources. Rendering time scales with network size, animation duration, and quality settings.</p> Source code in <code>src/pathpyG/visualisations/_manim/backend.py</code> <pre><code>class ManimBackend(PlotBackend):\n    \"\"\"Manim backend for temporal network animation.\n\n    Integrates Manim Community Edition for creating smooth temporal network\n    animations. Supports both MP4 and GIF output formats with Jupyter notebook\n    integration for inline display.\n\n    Features:\n        - Temporal network animation with smooth node/edge transitions\n        - Multiple output formats (MP4, GIF via FFmpeg)\n        - Jupyter integration with base64 video embedding\n\n    Example:\n        Create and display a simple temporal network animation:\n        ```python\n        import pathpyG as pp\n\n        tedges = [(\"a\", \"b\", 1), (\"b\", \"c\", 2), (\"c\", \"a\", 3)]\n        tg = pp.TemporalGraph.from_edge_list(tedges)\n        pp.plot(tg, backend=\"manim\", filename=\"temporal_network.gif\")\n        ```\n        &lt;img src=\"../../plot/temporal_network.gif\" alt=\"Example Matplotlib Backend Output\" width=\"550\"/&gt;\n\n    !!! note \"Temporal Networks Only\"\n        This backend is specifically designed for TemporalNetworkPlot\n        objects and does not support static network visualization.\n\n    !!! warning \"Performance Requirements\"\n        High-quality animations require significant computational resources.\n        Rendering time scales with network size, animation duration, and quality settings.\n    \"\"\"\n\n    def __init__(self, plot: PathPyPlot, show_labels: bool):\n        \"\"\"Initialize Manim backend with temporal network validation and configuration.\n\n        Sets up Manim configuration parameters including resolution, frame rate,\n        quality settings, and background color. Validates that the plot type\n        is supported (currently only TemporalNetworkPlot).\n\n        Args:\n            plot: PathPyPlot instance (must be TemporalNetworkPlot)\n            show_labels: Whether to display node labels in animation\n\n        Raises:\n            ValueError: If plot type is not supported by Manim backend\n\n        !!! info \"Manim Configuration\"\n            Automatically configures Manim settings using pathpyG config and fixed defaults:\n\n            - **Resolution**: From width/height config parameters\n            - **Frame Rate**: Default 15 fps for smooth playback\n            - **Quality**: High quality\n            - **Background**: White background for clarity\n        \"\"\"\n        super().__init__(plot, show_labels=show_labels)\n        self._kind = SUPPORTED_KINDS.get(type(plot), None)\n        if self._kind is None:\n            logger.error(f\"Plot of type {type(plot)} not supported by Matplotlib backend.\")\n            raise ValueError(f\"Plot of type {type(plot)} not supported.\")\n\n        # Optional config settings\n        manim_config.pixel_height = int(unit_str_to_float(self.config.get(\"height\"), \"px\"))  # type: ignore[arg-type]\n        manim_config.pixel_width = int(unit_str_to_float(self.config.get(\"width\"), \"px\"))  # type: ignore[arg-type]\n        manim_config.quality = \"high_quality\"\n        manim_config.background_color = WHITE\n\n    def render_video(self) -&gt; tuple[Path, str]:\n        \"\"\"Render temporal network animation using Manim engine.\n\n        Creates temporary directory, configures Manim settings, instantiates\n        TemporalGraphScene, and renders the complete animation sequence.\n        Handles all Manim-specific setup and teardown.\n\n        Returns:\n            tuple: (video_file_path, temp_directory_path) for post-processing\n\n        !!! info \"Rendering Pipeline\"\n            1. **Setup**: Create temporary directory for Manim output\n            2. **Configuration**: Set output path and filename\n            3. **Scene Creation**: Instantiate TemporalGraphScene with data\n            4. **Rendering**: Execute Manim rendering process\n            5. **Cleanup**: Return paths for further processing and returns to original directory\n        \"\"\"\n        temp_dir, current_dir = prepare_tempfile()\n        manim_config.media_dir = temp_dir\n        manim_config.output_file = \"default.mp4\"\n        self.scene = TemporalGraphScene(data=self.data, config=self.config, show_labels=self.show_labels)\n        self.scene.render()\n        os.chdir(current_dir)\n        return Path(temp_dir) / \"videos\" / \"1080p60\" / \"default.mp4\", temp_dir\n\n    def save(self, filename: str) -&gt; None:\n        \"\"\"Render and save temporal network animation to specified file.\n\n        Creates high-quality animation video and saves to disk. Supports both\n        MP4 and GIF formats with automatic format detection from filename\n        extension. GIF conversion uses FFmpeg.\n\n        Args:\n            filename: Output file path with extension (.mp4 or .gif)\n\n        !!! warning \"GIF Conversion\"\n            GIF creation requires FFmpeg to be installed and available in PATH.\n            Conversion may take additional time for long animations.\n        \"\"\"\n        # render temporary .mp4\n        temp_file, temp_dir = self.render_video()\n        if filename.endswith(\".gif\"):\n            self.convert_to_gif(temp_file)\n            temp_file = temp_file.with_suffix(\".gif\")\n        shutil.copy(temp_file, filename)\n        shutil.rmtree(temp_dir)\n\n    def convert_to_gif(self, filename: Path) -&gt; None:\n        \"\"\"Convert rendered MP4 video to animated GIF using FFmpeg.\n\n        Uses FFmpeg with optimized settings for web-friendly GIF output:\n        30 fps for smooth animation, Lanczos scaling for quality preservation,\n        and 1080p resolution maintenance.\n\n        Args:\n            filename: Path to source MP4 file (output GIF uses same path with .gif extension)\n\n        Raises:\n            Exception: If FFmpeg conversion fails (logged as error)\n        \"\"\"\n        try:\n            subprocess.run(\n                [\n                    \"ffmpeg\",\n                    \"-i\",\n                    filename,\n                    \"-vf\",\n                    \"fps=30,scale=1080:-1:flags=lanczos\",\n                    \"-y\",\n                    \"-hide_banner\",\n                    \"-loglevel\",\n                    \"error\",\n                    filename.with_suffix(\".gif\"),\n                ],\n                check=True,\n            )\n        except Exception as e:\n            logger.error(f\"GIF conversion failed: {e}\")\n\n    def show(self) -&gt; None:\n        \"\"\"Display temporal network animation in interactive environment.\n\n        Renders animation and displays inline in Jupyter notebooks using base64\n        video embedding, or opens in system browser for non-interactive environments.\n        Automatically cleans up temporary files after display.\n        \"\"\"\n        temp_file, temp_dir = self.render_video()\n\n        if config[\"environment\"][\"interactive\"]:\n            from IPython.display import HTML, display\n\n            video_bytes = temp_file.read_bytes()\n            video_b64 = base64.b64encode(video_bytes).decode()\n            video_html = f\"\"\"\n            &lt;video width=\"580\" height=\"340\" controls&gt;\n                &lt;source src=\"data:video/mp4;base64,{video_b64}\" type=\"video/mp4\"&gt;\n                Your browser does not support the video tag.\n            &lt;/video&gt;\n            \"\"\"\n            display(HTML(video_html))\n        else:\n            # open the file in the webbrowser\n            webbrowser.open(r\"file:///\" + temp_file.as_posix())\n        shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/backend/#pathpyG.visualisations._manim.backend.ManimBackend.__init__","title":"<code>__init__</code>","text":"<p>Initialize Manim backend with temporal network validation and configuration.</p> <p>Sets up Manim configuration parameters including resolution, frame rate, quality settings, and background color. Validates that the plot type is supported (currently only TemporalNetworkPlot).</p> <p>Parameters:</p> Name Type Description Default <code>plot</code> <code>pathpyG.visualisations.pathpy_plot.PathPyPlot</code> <p>PathPyPlot instance (must be TemporalNetworkPlot)</p> required <code>show_labels</code> <code>bool</code> <p>Whether to display node labels in animation</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If plot type is not supported by Manim backend</p> <p>Manim Configuration</p> <p>Automatically configures Manim settings using pathpyG config and fixed defaults:</p> <ul> <li>Resolution: From width/height config parameters</li> <li>Frame Rate: Default 15 fps for smooth playback</li> <li>Quality: High quality</li> <li>Background: White background for clarity</li> </ul> Source code in <code>src/pathpyG/visualisations/_manim/backend.py</code> <pre><code>def __init__(self, plot: PathPyPlot, show_labels: bool):\n    \"\"\"Initialize Manim backend with temporal network validation and configuration.\n\n    Sets up Manim configuration parameters including resolution, frame rate,\n    quality settings, and background color. Validates that the plot type\n    is supported (currently only TemporalNetworkPlot).\n\n    Args:\n        plot: PathPyPlot instance (must be TemporalNetworkPlot)\n        show_labels: Whether to display node labels in animation\n\n    Raises:\n        ValueError: If plot type is not supported by Manim backend\n\n    !!! info \"Manim Configuration\"\n        Automatically configures Manim settings using pathpyG config and fixed defaults:\n\n        - **Resolution**: From width/height config parameters\n        - **Frame Rate**: Default 15 fps for smooth playback\n        - **Quality**: High quality\n        - **Background**: White background for clarity\n    \"\"\"\n    super().__init__(plot, show_labels=show_labels)\n    self._kind = SUPPORTED_KINDS.get(type(plot), None)\n    if self._kind is None:\n        logger.error(f\"Plot of type {type(plot)} not supported by Matplotlib backend.\")\n        raise ValueError(f\"Plot of type {type(plot)} not supported.\")\n\n    # Optional config settings\n    manim_config.pixel_height = int(unit_str_to_float(self.config.get(\"height\"), \"px\"))  # type: ignore[arg-type]\n    manim_config.pixel_width = int(unit_str_to_float(self.config.get(\"width\"), \"px\"))  # type: ignore[arg-type]\n    manim_config.quality = \"high_quality\"\n    manim_config.background_color = WHITE\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/backend/#pathpyG.visualisations._manim.backend.ManimBackend.convert_to_gif","title":"<code>convert_to_gif</code>","text":"<p>Convert rendered MP4 video to animated GIF using FFmpeg.</p> <p>Uses FFmpeg with optimized settings for web-friendly GIF output: 30 fps for smooth animation, Lanczos scaling for quality preservation, and 1080p resolution maintenance.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>pathlib.Path</code> <p>Path to source MP4 file (output GIF uses same path with .gif extension)</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>If FFmpeg conversion fails (logged as error)</p> Source code in <code>src/pathpyG/visualisations/_manim/backend.py</code> <pre><code>def convert_to_gif(self, filename: Path) -&gt; None:\n    \"\"\"Convert rendered MP4 video to animated GIF using FFmpeg.\n\n    Uses FFmpeg with optimized settings for web-friendly GIF output:\n    30 fps for smooth animation, Lanczos scaling for quality preservation,\n    and 1080p resolution maintenance.\n\n    Args:\n        filename: Path to source MP4 file (output GIF uses same path with .gif extension)\n\n    Raises:\n        Exception: If FFmpeg conversion fails (logged as error)\n    \"\"\"\n    try:\n        subprocess.run(\n            [\n                \"ffmpeg\",\n                \"-i\",\n                filename,\n                \"-vf\",\n                \"fps=30,scale=1080:-1:flags=lanczos\",\n                \"-y\",\n                \"-hide_banner\",\n                \"-loglevel\",\n                \"error\",\n                filename.with_suffix(\".gif\"),\n            ],\n            check=True,\n        )\n    except Exception as e:\n        logger.error(f\"GIF conversion failed: {e}\")\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/backend/#pathpyG.visualisations._manim.backend.ManimBackend.render_video","title":"<code>render_video</code>","text":"<p>Render temporal network animation using Manim engine.</p> <p>Creates temporary directory, configures Manim settings, instantiates TemporalGraphScene, and renders the complete animation sequence. Handles all Manim-specific setup and teardown.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[pathlib.Path, str]</code> <p>(video_file_path, temp_directory_path) for post-processing</p> <p>Rendering Pipeline</p> <ol> <li>Setup: Create temporary directory for Manim output</li> <li>Configuration: Set output path and filename</li> <li>Scene Creation: Instantiate TemporalGraphScene with data</li> <li>Rendering: Execute Manim rendering process</li> <li>Cleanup: Return paths for further processing and returns to original directory</li> </ol> Source code in <code>src/pathpyG/visualisations/_manim/backend.py</code> <pre><code>def render_video(self) -&gt; tuple[Path, str]:\n    \"\"\"Render temporal network animation using Manim engine.\n\n    Creates temporary directory, configures Manim settings, instantiates\n    TemporalGraphScene, and renders the complete animation sequence.\n    Handles all Manim-specific setup and teardown.\n\n    Returns:\n        tuple: (video_file_path, temp_directory_path) for post-processing\n\n    !!! info \"Rendering Pipeline\"\n        1. **Setup**: Create temporary directory for Manim output\n        2. **Configuration**: Set output path and filename\n        3. **Scene Creation**: Instantiate TemporalGraphScene with data\n        4. **Rendering**: Execute Manim rendering process\n        5. **Cleanup**: Return paths for further processing and returns to original directory\n    \"\"\"\n    temp_dir, current_dir = prepare_tempfile()\n    manim_config.media_dir = temp_dir\n    manim_config.output_file = \"default.mp4\"\n    self.scene = TemporalGraphScene(data=self.data, config=self.config, show_labels=self.show_labels)\n    self.scene.render()\n    os.chdir(current_dir)\n    return Path(temp_dir) / \"videos\" / \"1080p60\" / \"default.mp4\", temp_dir\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/backend/#pathpyG.visualisations._manim.backend.ManimBackend.save","title":"<code>save</code>","text":"<p>Render and save temporal network animation to specified file.</p> <p>Creates high-quality animation video and saves to disk. Supports both MP4 and GIF formats with automatic format detection from filename extension. GIF conversion uses FFmpeg.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Output file path with extension (.mp4 or .gif)</p> required <p>GIF Conversion</p> <p>GIF creation requires FFmpeg to be installed and available in PATH. Conversion may take additional time for long animations.</p> Source code in <code>src/pathpyG/visualisations/_manim/backend.py</code> <pre><code>def save(self, filename: str) -&gt; None:\n    \"\"\"Render and save temporal network animation to specified file.\n\n    Creates high-quality animation video and saves to disk. Supports both\n    MP4 and GIF formats with automatic format detection from filename\n    extension. GIF conversion uses FFmpeg.\n\n    Args:\n        filename: Output file path with extension (.mp4 or .gif)\n\n    !!! warning \"GIF Conversion\"\n        GIF creation requires FFmpeg to be installed and available in PATH.\n        Conversion may take additional time for long animations.\n    \"\"\"\n    # render temporary .mp4\n    temp_file, temp_dir = self.render_video()\n    if filename.endswith(\".gif\"):\n        self.convert_to_gif(temp_file)\n        temp_file = temp_file.with_suffix(\".gif\")\n    shutil.copy(temp_file, filename)\n    shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/backend/#pathpyG.visualisations._manim.backend.ManimBackend.show","title":"<code>show</code>","text":"<p>Display temporal network animation in interactive environment.</p> <p>Renders animation and displays inline in Jupyter notebooks using base64 video embedding, or opens in system browser for non-interactive environments. Automatically cleans up temporary files after display.</p> Source code in <code>src/pathpyG/visualisations/_manim/backend.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Display temporal network animation in interactive environment.\n\n    Renders animation and displays inline in Jupyter notebooks using base64\n    video embedding, or opens in system browser for non-interactive environments.\n    Automatically cleans up temporary files after display.\n    \"\"\"\n    temp_file, temp_dir = self.render_video()\n\n    if config[\"environment\"][\"interactive\"]:\n        from IPython.display import HTML, display\n\n        video_bytes = temp_file.read_bytes()\n        video_b64 = base64.b64encode(video_bytes).decode()\n        video_html = f\"\"\"\n        &lt;video width=\"580\" height=\"340\" controls&gt;\n            &lt;source src=\"data:video/mp4;base64,{video_b64}\" type=\"video/mp4\"&gt;\n            Your browser does not support the video tag.\n        &lt;/video&gt;\n        \"\"\"\n        display(HTML(video_html))\n    else:\n        # open the file in the webbrowser\n        webbrowser.open(r\"file:///\" + temp_file.as_posix())\n    shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/temporal_graph_scene/","title":"temporal_graph_scene","text":"<p>Manim scene implementation for temporal graph animation.</p> <p>Core animation scene that renders temporal networks with time-based node/edge evolution. Handles smooth transitions, proper edge-node boundary calculations, and time indicator display.</p>"},{"location":"reference/pathpyG/visualisations/_manim/temporal_graph_scene/#pathpyG.visualisations._manim.temporal_graph_scene.TemporalGraphScene","title":"<code>TemporalGraphScene</code>","text":"<p>               Bases: <code>manim.Scene</code></p> <p>Manim scene for animated temporal network visualization.</p> <p>Creates time-based animations showing network evolution with nodes appearing/moving and edges being added/removed over time. Handles proper scaling, positioning, and smooth transitions between timesteps.</p> Source code in <code>src/pathpyG/visualisations/_manim/temporal_graph_scene.py</code> <pre><code>class TemporalGraphScene(Scene):\n    \"\"\"Manim scene for animated temporal network visualization.\n\n    Creates time-based animations showing network evolution with nodes\n    appearing/moving and edges being added/removed over time. Handles\n    proper scaling, positioning, and smooth transitions between timesteps.\n    \"\"\"\n    def __init__(self, data: dict, config: dict, show_labels: bool):\n        \"\"\"Initialize temporal graph scene with network data and configuration.\n\n        Args:\n            data: Network data with nodes/edges DataFrames in a dictionary\n            config: Animation configuration (timing, colors, etc.)\n            show_labels: Whether to display node labels\n        \"\"\"\n        super().__init__()\n        self.data = deepcopy(data)\n        self.data[\"nodes\"][\"size\"] *= 0.025  # scale sizes down\n        self.data[\"nodes\"] = self.data[\"nodes\"].rename(\n            columns={\"size\": \"radius\", \"color\": \"fill_color\", \"opacity\": \"fill_opacity\"}\n        )\n        if \"x\" in self.data[\"nodes\"] and \"y\" in self.data[\"nodes\"]:\n            self.data[\"nodes\"][[\"x\", \"y\"]] = (self.data[\"nodes\"][[\"x\", \"y\"]] - 0.5) * 5  # scale layout\n        self.data[\"edges\"] = self.data[\"edges\"].rename(\n            columns={\"color\": \"stroke_color\", \"opacity\": \"stroke_opacity\", \"size\": \"stroke_width\"}\n        )\n        self.config = config\n        self.show_labels = show_labels\n\n    def construct(self):\n        \"\"\"Create temporal network animation with time-based evolution.\n\n        Main animation sequence:\n        1. Initialize nodes at t=0 with layout positioning\n        2. For each timestep: update time display, add new edges, \n           transform node positions, remove old edges\n        3. Clean up final frame\n\n        Uses smooth transitions and proper edge-node boundary calculations\n        for professional animation quality.\n        \"\"\"\n        # Add initial nodes\n        start_node_df = self.data[\"nodes\"][self.data[\"nodes\"][\"start\"] == 0]\n        if \"x\" in self.data[\"nodes\"] and \"y\" in self.data[\"nodes\"]:\n            layout = {node: np.concatenate([pos.values, [0]]) for node, pos in start_node_df[[\"x\", \"y\"]].iterrows()}\n        else:\n            # Use random layout if no positions are given\n            layout = Layout(nodes=start_node_df.index.tolist()).generate_layout()\n            # add z coordinate for manim and scale layout\n            layout = {node: (np.concatenate([pos, [0]]) - 0.5) * 5 for node, pos in layout.items()}\n        vertex_config = start_node_df[[\"radius\", \"fill_color\", \"fill_opacity\"]].to_dict(orient=\"index\")\n        if self.show_labels:\n            nodes = {node: LabeledDot(label=str(node), point=layout[node], **vertex_config[node]) for node in vertex_config}\n        else:\n            nodes = {node: Dot(point=layout[node], **vertex_config[node]) for node in vertex_config}\n        self.play(*[Create(node) for node in nodes.values()])\n\n        # Iterate over time steps and update nodes and edges\n        time_text = Text(f\"Time: {0}\", font_size=24, color=BLACK).to_corner(UP + RIGHT)\n        for t in range(self.data[\"edges\"][\"end\"].max() + 1):\n            # Add time step text\n            self.play(Transform(time_text, Text(f\"Time: {t}\", font_size=24, color=BLACK).to_corner(UP + RIGHT)), run_time=0.02)\n\n            # Add edges for current time step\n            new_edge_df = self.data[\"edges\"][(self.data[\"edges\"][\"start\"] == t)]\n            # drop duplicate edges\n            if new_edge_df.index.duplicated().any():\n                logger.warning(f\"Dropping duplicate edges at time {t}.\")\n                new_edge_df = new_edge_df[~new_edge_df.index.duplicated(keep='first')]\n            new_edge_config = new_edge_df[[\"stroke_color\", \"stroke_opacity\", \"stroke_width\"]].to_dict(orient=\"index\")\n            if not new_edge_df.empty:\n                arrows = {\n                    (source, target): Arrow(\n                        start=self.get_boundary_point(\n                            center=layout[source],\n                            direction=layout[target] - layout[source],\n                            radius=nodes[source].radius/2,\n                        ),\n                        end=self.get_boundary_point(\n                            center=layout[target],\n                            direction=layout[source] - layout[target],\n                            radius=nodes[target].radius/2,\n                        ),\n                        **new_edge_config[(source, target)],\n                    )\n                    for source, target in new_edge_df.index\n                }\n                self.play(*[GrowArrow(arrow) for arrow in arrows.values()], run_time=self.config[\"delta\"]/(4*1000))\n            else:\n                self.wait(self.config[\"delta\"]/(4*1000))\n\n            # Update node positions for the next time step\n            new_nodes = self.data[\"nodes\"][self.data[\"nodes\"][\"start\"] == (t + 1)]\n            if not new_nodes.empty:\n                new_vertex_config = new_nodes[[\"radius\", \"fill_color\", \"fill_opacity\"]].to_dict(orient=\"index\")\n                if \"x\" in new_nodes and \"y\" in new_nodes:\n                    layout.update({node: np.concatenate([pos.values, [0]]) for node, pos in new_nodes[[\"x\", \"y\"]].iterrows()})\n                if self.show_labels:\n                    new_nodes = {\n                        node: LabeledDot(label=str(node), point=layout[node], **new_vertex_config[node])\n                        for node in new_vertex_config\n                    }\n                else:\n                    new_nodes = {node: Dot(point=layout[node], **new_vertex_config[node]) for node in new_vertex_config}\n                movement_animations = [Transform(nodes[node], new_nodes[node]) for node in new_nodes]\n\n                # Update edge positions with moving nodes\n                if not new_edge_df.empty:\n                    new_arrows = {\n                        (source, target): Arrow(\n                            start=self.get_boundary_point(\n                                center=layout[source],\n                                direction=layout[target] - layout[source],\n                                radius=(nodes | new_nodes)[source].radius/2,\n                            ),\n                            end=self.get_boundary_point(\n                                center=layout[target],\n                                direction=layout[source] - layout[target],\n                                radius=(nodes | new_nodes)[target].radius/2,\n                            ),\n                            **new_edge_config[(source, target)],\n                        )\n                        for source, target in new_edge_df.index\n                        if (source, target) in arrows\n                    }\n                    movement_animations.extend([Transform(arrows[index], new_arrows[index]) for index in new_arrows])\n                self.play(*movement_animations, run_time=self.config[\"delta\"]/(2*1000) - 0.02) # 0.02 for time text update\n            else:\n                self.wait(self.config[\"delta\"]/(2*1000) - 0.02) # 0.02 for time text update\n\n            # Gather all old edges to be removed\n            if not new_edge_df.empty:\n                self.play(\n                    *[arrow.animate.scale(0, scale_tips=True, about_point=arrow.get_end()) for arrow in arrows.values()],\n                    run_time=self.config[\"delta\"]/(4*1000)\n                )\n            else:\n                self.wait(self.config[\"delta\"]/(4*1000))\n\n        self.play(Uncreate(node) for node in nodes.values())\n\n    def get_boundary_point(self, center, direction, radius):\n        \"\"\"Calculate edge attachment point on node boundary.\n\n        Computes where edges should connect to nodes to avoid visual\n        overlap with node circles. Uses vector normalization to find\n        the intersection point on the node's circumference.\n\n        Args:\n            center: Node center coordinates (x, y, z)\n            direction: Direction vector to target node\n            radius: Node radius for boundary calculation\n\n        Returns:\n            Boundary point coordinates for clean edge attachment\n        \"\"\"\n        distance = np.linalg.norm(direction)\n        if distance == 0:\n            return center  # Avoid division by zero\n        direction = direction / distance\n        return center + direction * radius\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/temporal_graph_scene/#pathpyG.visualisations._manim.temporal_graph_scene.TemporalGraphScene.__init__","title":"<code>__init__</code>","text":"<p>Initialize temporal graph scene with network data and configuration.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Network data with nodes/edges DataFrames in a dictionary</p> required <code>config</code> <code>dict</code> <p>Animation configuration (timing, colors, etc.)</p> required <code>show_labels</code> <code>bool</code> <p>Whether to display node labels</p> required Source code in <code>src/pathpyG/visualisations/_manim/temporal_graph_scene.py</code> <pre><code>def __init__(self, data: dict, config: dict, show_labels: bool):\n    \"\"\"Initialize temporal graph scene with network data and configuration.\n\n    Args:\n        data: Network data with nodes/edges DataFrames in a dictionary\n        config: Animation configuration (timing, colors, etc.)\n        show_labels: Whether to display node labels\n    \"\"\"\n    super().__init__()\n    self.data = deepcopy(data)\n    self.data[\"nodes\"][\"size\"] *= 0.025  # scale sizes down\n    self.data[\"nodes\"] = self.data[\"nodes\"].rename(\n        columns={\"size\": \"radius\", \"color\": \"fill_color\", \"opacity\": \"fill_opacity\"}\n    )\n    if \"x\" in self.data[\"nodes\"] and \"y\" in self.data[\"nodes\"]:\n        self.data[\"nodes\"][[\"x\", \"y\"]] = (self.data[\"nodes\"][[\"x\", \"y\"]] - 0.5) * 5  # scale layout\n    self.data[\"edges\"] = self.data[\"edges\"].rename(\n        columns={\"color\": \"stroke_color\", \"opacity\": \"stroke_opacity\", \"size\": \"stroke_width\"}\n    )\n    self.config = config\n    self.show_labels = show_labels\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/temporal_graph_scene/#pathpyG.visualisations._manim.temporal_graph_scene.TemporalGraphScene.construct","title":"<code>construct</code>","text":"<p>Create temporal network animation with time-based evolution.</p> <p>Main animation sequence: 1. Initialize nodes at t=0 with layout positioning 2. For each timestep: update time display, add new edges,     transform node positions, remove old edges 3. Clean up final frame</p> <p>Uses smooth transitions and proper edge-node boundary calculations for professional animation quality.</p> Source code in <code>src/pathpyG/visualisations/_manim/temporal_graph_scene.py</code> <pre><code>def construct(self):\n    \"\"\"Create temporal network animation with time-based evolution.\n\n    Main animation sequence:\n    1. Initialize nodes at t=0 with layout positioning\n    2. For each timestep: update time display, add new edges, \n       transform node positions, remove old edges\n    3. Clean up final frame\n\n    Uses smooth transitions and proper edge-node boundary calculations\n    for professional animation quality.\n    \"\"\"\n    # Add initial nodes\n    start_node_df = self.data[\"nodes\"][self.data[\"nodes\"][\"start\"] == 0]\n    if \"x\" in self.data[\"nodes\"] and \"y\" in self.data[\"nodes\"]:\n        layout = {node: np.concatenate([pos.values, [0]]) for node, pos in start_node_df[[\"x\", \"y\"]].iterrows()}\n    else:\n        # Use random layout if no positions are given\n        layout = Layout(nodes=start_node_df.index.tolist()).generate_layout()\n        # add z coordinate for manim and scale layout\n        layout = {node: (np.concatenate([pos, [0]]) - 0.5) * 5 for node, pos in layout.items()}\n    vertex_config = start_node_df[[\"radius\", \"fill_color\", \"fill_opacity\"]].to_dict(orient=\"index\")\n    if self.show_labels:\n        nodes = {node: LabeledDot(label=str(node), point=layout[node], **vertex_config[node]) for node in vertex_config}\n    else:\n        nodes = {node: Dot(point=layout[node], **vertex_config[node]) for node in vertex_config}\n    self.play(*[Create(node) for node in nodes.values()])\n\n    # Iterate over time steps and update nodes and edges\n    time_text = Text(f\"Time: {0}\", font_size=24, color=BLACK).to_corner(UP + RIGHT)\n    for t in range(self.data[\"edges\"][\"end\"].max() + 1):\n        # Add time step text\n        self.play(Transform(time_text, Text(f\"Time: {t}\", font_size=24, color=BLACK).to_corner(UP + RIGHT)), run_time=0.02)\n\n        # Add edges for current time step\n        new_edge_df = self.data[\"edges\"][(self.data[\"edges\"][\"start\"] == t)]\n        # drop duplicate edges\n        if new_edge_df.index.duplicated().any():\n            logger.warning(f\"Dropping duplicate edges at time {t}.\")\n            new_edge_df = new_edge_df[~new_edge_df.index.duplicated(keep='first')]\n        new_edge_config = new_edge_df[[\"stroke_color\", \"stroke_opacity\", \"stroke_width\"]].to_dict(orient=\"index\")\n        if not new_edge_df.empty:\n            arrows = {\n                (source, target): Arrow(\n                    start=self.get_boundary_point(\n                        center=layout[source],\n                        direction=layout[target] - layout[source],\n                        radius=nodes[source].radius/2,\n                    ),\n                    end=self.get_boundary_point(\n                        center=layout[target],\n                        direction=layout[source] - layout[target],\n                        radius=nodes[target].radius/2,\n                    ),\n                    **new_edge_config[(source, target)],\n                )\n                for source, target in new_edge_df.index\n            }\n            self.play(*[GrowArrow(arrow) for arrow in arrows.values()], run_time=self.config[\"delta\"]/(4*1000))\n        else:\n            self.wait(self.config[\"delta\"]/(4*1000))\n\n        # Update node positions for the next time step\n        new_nodes = self.data[\"nodes\"][self.data[\"nodes\"][\"start\"] == (t + 1)]\n        if not new_nodes.empty:\n            new_vertex_config = new_nodes[[\"radius\", \"fill_color\", \"fill_opacity\"]].to_dict(orient=\"index\")\n            if \"x\" in new_nodes and \"y\" in new_nodes:\n                layout.update({node: np.concatenate([pos.values, [0]]) for node, pos in new_nodes[[\"x\", \"y\"]].iterrows()})\n            if self.show_labels:\n                new_nodes = {\n                    node: LabeledDot(label=str(node), point=layout[node], **new_vertex_config[node])\n                    for node in new_vertex_config\n                }\n            else:\n                new_nodes = {node: Dot(point=layout[node], **new_vertex_config[node]) for node in new_vertex_config}\n            movement_animations = [Transform(nodes[node], new_nodes[node]) for node in new_nodes]\n\n            # Update edge positions with moving nodes\n            if not new_edge_df.empty:\n                new_arrows = {\n                    (source, target): Arrow(\n                        start=self.get_boundary_point(\n                            center=layout[source],\n                            direction=layout[target] - layout[source],\n                            radius=(nodes | new_nodes)[source].radius/2,\n                        ),\n                        end=self.get_boundary_point(\n                            center=layout[target],\n                            direction=layout[source] - layout[target],\n                            radius=(nodes | new_nodes)[target].radius/2,\n                        ),\n                        **new_edge_config[(source, target)],\n                    )\n                    for source, target in new_edge_df.index\n                    if (source, target) in arrows\n                }\n                movement_animations.extend([Transform(arrows[index], new_arrows[index]) for index in new_arrows])\n            self.play(*movement_animations, run_time=self.config[\"delta\"]/(2*1000) - 0.02) # 0.02 for time text update\n        else:\n            self.wait(self.config[\"delta\"]/(2*1000) - 0.02) # 0.02 for time text update\n\n        # Gather all old edges to be removed\n        if not new_edge_df.empty:\n            self.play(\n                *[arrow.animate.scale(0, scale_tips=True, about_point=arrow.get_end()) for arrow in arrows.values()],\n                run_time=self.config[\"delta\"]/(4*1000)\n            )\n        else:\n            self.wait(self.config[\"delta\"]/(4*1000))\n\n    self.play(Uncreate(node) for node in nodes.values())\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_manim/temporal_graph_scene/#pathpyG.visualisations._manim.temporal_graph_scene.TemporalGraphScene.get_boundary_point","title":"<code>get_boundary_point</code>","text":"<p>Calculate edge attachment point on node boundary.</p> <p>Computes where edges should connect to nodes to avoid visual overlap with node circles. Uses vector normalization to find the intersection point on the node's circumference.</p> <p>Parameters:</p> Name Type Description Default <code>center</code> <p>Node center coordinates (x, y, z)</p> required <code>direction</code> <p>Direction vector to target node</p> required <code>radius</code> <p>Node radius for boundary calculation</p> required <p>Returns:</p> Type Description <p>Boundary point coordinates for clean edge attachment</p> Source code in <code>src/pathpyG/visualisations/_manim/temporal_graph_scene.py</code> <pre><code>def get_boundary_point(self, center, direction, radius):\n    \"\"\"Calculate edge attachment point on node boundary.\n\n    Computes where edges should connect to nodes to avoid visual\n    overlap with node circles. Uses vector normalization to find\n    the intersection point on the node's circumference.\n\n    Args:\n        center: Node center coordinates (x, y, z)\n        direction: Direction vector to target node\n        radius: Node radius for boundary calculation\n\n    Returns:\n        Boundary point coordinates for clean edge attachment\n    \"\"\"\n    distance = np.linalg.norm(direction)\n    if distance == 0:\n        return center  # Avoid division by zero\n    direction = direction / distance\n    return center + direction * radius\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/","title":"matplotlib","text":"<p>Matplotlib Backend for PathpyG Visualizations.</p> <p>Raster graphics backend using matplotlib for static network images.</p> <p>Output Formats</p> <ul> <li>PNG: High-quality raster images for presentations</li> <li>JPG: Compressed raster images for web usage</li> </ul>"},{"location":"reference/pathpyG/visualisations/_matplotlib/#pathpyG.visualisations._matplotlib--basic-usage","title":"Basic Usage","text":"<p><pre><code>import pathpyG as pp\n\n# Simple network visualization\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g, backend=\"matplotlib\")\n</code></pre> </p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/#pathpyG.visualisations._matplotlib--time-unfolded-network","title":"Time-Unfolded Network","text":"<p>We also support time-unfolded static visualizations of temporal networks using the matplotlib backend. The example uses the <code>node_opacity</code> parameter to highlight active nodes and edges at each time step.</p> <p><pre><code>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\nnode_opacity = {(node_id, time): 0.1 for node_id in t.nodes for time in range(t.data.time.max().item() + 2)}\nnode_opacity.update({(source_id, time): 1.0 for source_id, target_id, time in t.temporal_edges})\nnode_opacity.update({(target_id, time+1): 1.0 for source_id, target_id, time in t.temporal_edges})\npp.plot(t, backend=\"matplotlib\", kind=\"unfolded\", node_size=12, node_opacity=node_opacity)\n</code></pre> </p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/","title":"backend","text":"<p>Matplotlib backend for raster graphics network visualization.</p> <p>High-performance matplotlib implementation with optimized collections for efficient rendering. Supports both directed and undirected networks with curved edges, proper arrowheads, and comprehensive styling options.</p>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/#pathpyG.visualisations._matplotlib.backend.MatplotlibBackend","title":"<code>MatplotlibBackend</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot_backend.PlotBackend</code></p> <p>Matplotlib backend for network visualization with optimized rendering.</p> <p>Uses matplotlib collections (EllipseCollection, LineCollection, PathCollection) for efficient batch rendering of network elements. Provides high-quality output with proper edge-node intersection handling and curved edge support.</p> Features <ul> <li>Batch rendering via matplotlib collections</li> <li>Bezier curves for directed edges</li> <li>Automatic edge shortening to avoid node overlap</li> </ul> Example <p>Plot a simple directed network with curved edges: <pre><code>import pathpyG as pp\n\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g, backend=\"matplotlib\")\n</code></pre> </p> <p>Performance Optimization</p> <p>Uses collections instead of individual plot calls for 10-100x faster rendering on networks with many edges.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/backend.py</code> <pre><code>class MatplotlibBackend(PlotBackend):\n    \"\"\"Matplotlib backend for network visualization with optimized rendering.\n\n    Uses matplotlib collections (EllipseCollection, LineCollection, PathCollection)\n    for efficient batch rendering of network elements. Provides high-quality\n    output with proper edge-node intersection handling and curved edge support.\n\n    Features:\n        - Batch rendering via matplotlib collections\n        - Bezier curves for directed edges\n        - Automatic edge shortening to avoid node overlap\n\n    Example:\n        Plot a simple directed network with curved edges:\n        ```python\n        import pathpyG as pp\n\n        edges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\n        g = pp.Graph.from_edge_list(edges)\n        pp.plot(g, backend=\"matplotlib\")\n        ```\n        &lt;img src=\"../../plot/network.png\" alt=\"Example Matplotlib Backend Output\" width=\"550\"/&gt;\n\n    !!! note \"Performance Optimization\"\n        Uses collections instead of individual plot calls for 10-100x\n        faster rendering on networks with many edges.\n    \"\"\"\n\n    def __init__(self, plot: PathPyPlot, show_labels: bool):\n        \"\"\"Initialize matplotlib backend with plot validation.\n\n        Args:\n            plot: PathPyPlot instance containing network data\n            show_labels: Whether to display node labels\n\n        Raises:\n            ValueError: If plot type not supported by matplotlib backend\n        \"\"\"\n        super().__init__(plot, show_labels=show_labels)\n        self._kind = SUPPORTED_KINDS.get(type(plot), None)  # type: ignore[arg-type]\n        if self._kind is None:\n            logger.error(f\"Plot of type {type(plot)} not supported by Matplotlib backend.\")\n            raise ValueError(f\"Plot of type {type(plot)} not supported.\")\n\n    def save(self, filename: str) -&gt; None:\n        \"\"\"Save plot to file with automatic format detection.\n\n        Args:\n            filename: Output file path (format inferred from extension)\n        \"\"\"\n        fig, ax = self.to_fig()\n        fig.savefig(filename)\n\n    def show(self) -&gt; None:\n        \"\"\"Display plot in interactive matplotlib window.\n\n        Opens plot in default matplotlib backend for interactive exploration.\n        \"\"\"\n        fig, ax = self.to_fig()\n        plt.show()\n\n    def to_fig(self) -&gt; tuple[plt.Figure, plt.Axes]:\n        \"\"\"Generate complete matplotlib figure with network visualization.\n\n        Creates figure with proper sizing, renders edges and nodes using optimized\n        collections, adds labels if enabled, and sets appropriate axis limits.\n\n        Returns:\n            tuple: (Figure, Axes) matplotlib objects ready for display/saving\n\n        !!! info \"Rendering Pipeline\"\n            1. **Setup**: Create figure with configured dimensions and DPI\n            2. **Edges**: Render using LineCollection (undirected) or PathCollection (directed)\n            3. **Nodes**: Render using EllipseCollection for precise sizing\n            4. **Labels**: Add text annotations at node centers\n            5. **Layout**: Set axis limits with margin configuration\n        \"\"\"\n        size_factor = 1 / 200  # scale node size to reasonable values\n        fig, ax = plt.subplots(\n            figsize=(unit_str_to_float(self.config[\"width\"], \"in\"), unit_str_to_float(self.config[\"height\"], \"in\")),\n            dpi=150,\n        )\n        ax.set_axis_off()\n\n        # get source and target coordinates for edges\n        source_coords = self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"source\"), [\"x\", \"y\"]].values\n        target_coords = self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"target\"), [\"x\", \"y\"]].values\n\n        if self.config[\"directed\"]:\n            self.add_directed_edges(source_coords, target_coords, ax, size_factor)\n        else:\n            self.add_undirected_edges(source_coords, target_coords, ax, size_factor)\n\n        # plot nodes\n        # We use EllipseCollection instead of scatter because there you can specify the radius of each circle in the unit of the data coordinates\n        # https://stackoverflow.com/a/33095224\n        ax.add_collection(\n            EllipseCollection(\n                widths=self.data[\"nodes\"][\"size\"] * size_factor,\n                heights=self.data[\"nodes\"][\"size\"] * size_factor,\n                angles=0,\n                units=\"xy\",\n                offsets=self.data[\"nodes\"][[\"x\", \"y\"]].values,\n                transOffset=ax.transData,\n                facecolors=self.data[\"nodes\"][\"color\"],\n                edgecolors=\"black\",\n                linewidths=0.5,\n                alpha=self.data[\"nodes\"][\"opacity\"],\n                zorder=2,\n            )\n        )\n\n        # add node labels\n        if self.show_labels:\n            if self._kind == \"static\":\n                for label in self.data[\"nodes\"].index:\n                    x, y = self.data[\"nodes\"].loc[[label], [\"x\", \"y\"]].values.flatten()\n                    # Annotate the node label with text in the center of the node\n                    ax.annotate(\n                        label,\n                        (x, y),\n                        fontsize=0.4 * self.data[\"nodes\"][\"size\"].mean(),\n                        ha=\"center\",\n                        va=\"center\",\n                    )\n            elif self._kind == \"unfolded\":\n                # add labels at the starting nodes only\n                min_time = self.data[\"nodes\"][\"start\"].min()\n                offset = 0.005 * self.data[\"nodes\"][\"size\"].mean()\n                sign = 1 if self.config[\"orientation\"] in [\"down\", \"left\"] else -1\n                label_df = self.data[\"nodes\"][self.data[\"nodes\"][\"start\"] == min_time]\n                for label in label_df.index:\n                    x, y = label_df.loc[[label], [\"x\", \"y\"]].values.flatten()\n                    ax.annotate(\n                        label[0],\n                        (x, y + offset * sign) if self.config[\"orientation\"] in [\"down\", \"up\"] else (x + offset * sign, y),\n                        fontsize=0.5 * self.data[\"nodes\"][\"size\"].mean(),\n                        ha=\"center\",\n                        va=\"center\",\n                    )\n\n                # add timestamps at the border\n                times = self.data[\"nodes\"][\"start\"].unique()\n                for time in times[:-1]:  # skip last time as it would be outside the plot\n                    x, y = self.data[\"nodes\"].iloc[time:time+2, :][[\"x\", \"y\"]].values.mean(axis=0)\n                    ax.annotate(\n                        str(time),\n                        (x - offset, y) if self.config[\"orientation\"] in [\"down\", \"up\"] else (x, y - offset),\n                        fontsize=0.5 * self.data[\"nodes\"][\"size\"].mean(),\n                        ha=\"center\",\n                        va=\"center\",\n                    )\n\n        # set limits\n        ax.set_xlim(-1 * self.config[\"margin\"], 1 + (1*self.config[\"margin\"]))\n        ax.set_ylim(-1 * self.config[\"margin\"], 1 + (1*self.config[\"margin\"]))\n        return fig, ax\n\n    def add_undirected_edges(self, source_coords, target_coords, ax, size_factor):\n        \"\"\"Render undirected edges using LineCollection for efficiency.\n\n        Computes edge shortening to prevent overlap with nodes and renders\n        all edges in a single matplotlib LineCollection for optimal performance.\n\n        Args:\n            source_coords: Source node coordinates array\n            target_coords: Target node coordinates array  \n            ax: Matplotlib axes for rendering\n            size_factor: Scaling factor for node size calculations\n\n        !!! tip \"Edge Shortening\"\n            Automatically shortens edges by node radius to create clean\n            visual separation between edges and node boundaries.\n        \"\"\"\n        # shorten edges so they don't overlap with nodes\n        vec = target_coords - source_coords\n        dist = np.linalg.norm(vec, axis=1, keepdims=True)\n        direction = vec / dist\n        source_coords += direction * (self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"source\"), [\"size\"]].values * (size_factor / 2))  # /2 because we use radius instead of diameter\n        target_coords -= direction * (self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"target\"), [\"size\"]].values * (size_factor / 2))\n\n        # create and add lines\n        edge_lines = list(zip(source_coords, target_coords))\n        ax.add_collection(\n            LineCollection(\n                edge_lines,\n                colors=self.data[\"edges\"][\"color\"],\n                alpha=self.data[\"edges\"][\"opacity\"],\n                linewidths=self.data[\"edges\"][\"size\"],\n                zorder=1,\n            )\n        )\n\n    def add_directed_edges(self, source_coords, target_coords, ax, size_factor):\n        \"\"\"Render directed edges using Bezier curves with arrowheads.\n\n        Creates curved edges using quadratic Bezier curves and adds proportional\n        arrowheads. Handles edge shortening and automatic fallback to straight\n        edges when curves would be too short.\n\n        Args:\n            source_coords: Source node coordinates array\n            target_coords: Target node coordinates array\n            ax: Matplotlib axes for rendering  \n            size_factor: Scaling factor for node size calculations\n\n        !!! warning \"Curve Limitations\"\n            Falls back to straight edges when arrowheads would be too large\n            relative to edge length to maintain visual clarity.\n        \"\"\"\n        # get bezier curve vertices and codes\n        head_length = 0.02\n        vertices, codes = self.get_bezier_curve(\n            source_coords,\n            target_coords,\n            source_node_size=self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"source\"), [\"size\"]].values\n            * (size_factor / 2),  # /2 because we use radius instead of diameter\n            target_node_size=self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"target\"), [\"size\"]].values\n            * (size_factor / 2),\n            head_length=head_length,\n        )\n        ax.add_collection(\n            PathCollection(\n                [\n                    Path(\n                        v,\n                        codes,\n                    )\n                    for v in zip(*vertices)\n                ],\n                facecolor=\"none\",\n                edgecolor=self.data[\"edges\"][\"color\"],\n                alpha=self.data[\"edges\"][\"opacity\"],\n                linewidth=self.data[\"edges\"][\"size\"],\n                zorder=1,\n            )\n        )\n\n        # add arrowheads\n        arrow_vertices, arrow_codes = self.get_arrowhead(vertices, head_length=head_length)\n        ax.add_collection(\n            PathCollection(\n                [Path(v, arrow_codes) for v in zip(*arrow_vertices)],\n                facecolor=self.data[\"edges\"][\"color\"],\n                edgecolor=self.data[\"edges\"][\"color\"],\n                alpha=self.data[\"edges\"][\"opacity\"],\n                zorder=1,\n            )\n        )\n\n    def get_bezier_curve(\n        self,\n        source_coords,\n        target_coords,\n        source_node_size,\n        target_node_size,\n        head_length,\n        shorten=0.005,\n    ):\n        \"\"\"Generate quadratic Bezier curve paths for directed edges.\n\n        Computes control points for smooth curved edges with automatic shortening\n        to accommodate node sizes and arrowheads. Uses perpendicular offset for\n        curve control points based on curvature configuration.\n\n        Args:\n            source_coords: Start points (x, y) for all edges\n            target_coords: End points (x, y) for all edges  \n            source_node_size: Source node radii for edge shortening\n            target_node_size: Target node radii for edge shortening\n            head_length: Arrowhead length for target-end shortening\n            shorten: Additional shortening amount to prevent visual overlap\n\n        Returns:\n            tuple: (vertices, codes) for matplotlib Path objects\n\n        !!! info \"Bezier Curve Mathematics\"\n            Uses quadratic Bezier curves with control point positioned\n            perpendicular to edge midpoint. Curvature parameter controls\n            the distance of control point from edge midpoint.\n\n        !!! note \"Fallback Behavior\" \n            Returns straight line paths when curves would be too short\n            for proper arrowhead placement.\n        \"\"\"\n        # Start and end points for the B\u00e9zier curve\n        P0 = source_coords\n        P2 = target_coords\n\n        # Calculate distance and direction vector\n        mid_point = (P0 + P2) / 2\n        vec = P2 - P0\n        dist = np.linalg.norm(vec, axis=1, keepdims=True)\n        # Avoid division by zero\n        dist[dist == 0] = 1e-6\n\n        # Perpendicular vector\n        perp_vec = np.array([-vec[:, 1], vec[:, 0]]).T / dist\n\n        # Calculate control points\n        P1 = mid_point + perp_vec * dist * self.config[\"curvature\"]\n\n        # Shorten the curve to avoid overlap with nodes\n        distance_P0_P1 = np.linalg.norm(P1 - P0, axis=1, keepdims=True)\n        distance_P0_P1[distance_P0_P1 == 0] = 1e-6\n        distance_P2_P1 = np.linalg.norm(P1 - P2, axis=1, keepdims=True)\n        distance_P2_P1[distance_P2_P1 == 0] = 1e-6\n        direction_P0_P1 = (P1 - P0) / distance_P0_P1\n        direction_P2_P1 = (P1 - P2) / distance_P2_P1\n        P0_offset_dist = shorten + source_node_size\n        P2_offset_dist = shorten + target_node_size + (head_length * self.data[\"edges\"][\"size\"].values[:, np.newaxis])\n        if (not self.config[\"curved\"]) or np.any(distance_P2_P1/2 &lt; P2_offset_dist):\n            logger.warning(\"Arrowhead length is too long for some edges. Please reduce the edge size. Using non-curved edges instead.\")\n            direction_P0_P2 = vec / dist\n            P0 += direction_P0_P2 * P0_offset_dist\n            P2 -= direction_P0_P2 * P2_offset_dist\n            return [P0, P2], [Path.MOVETO, Path.LINETO]\n\n        P0 += direction_P0_P1 * P0_offset_dist\n        P2 += direction_P2_P1 * P2_offset_dist\n\n        vertices = [P0, P1, P2]\n        codes = [\n            Path.MOVETO,\n            Path.CURVE3,\n            Path.MOVETO,\n        ]\n        return vertices, codes\n\n    def get_arrowhead(self, vertices, head_length, head_width=0.02):\n        \"\"\"Generate triangular arrowhead paths for directed edges.\n\n        Creates proportional arrowheads at curve endpoints using tangent vectors\n        for proper orientation. Arrowhead size scales with edge width for\n        consistent visual appearance across different edge weights.\n\n        Args:\n            vertices: Bezier curve vertices list for tangent calculation\n            head_length: Base arrowhead length (scaled by edge size)\n            head_width: Base arrowhead width (scaled by edge size)\n\n        Returns:\n            tuple: (vertices, codes) for matplotlib Path objects\n\n        !!! tip \"Proportional Scaling\"\n            Arrowhead dimensions automatically scale with edge width\n            to maintain consistent visual proportions across different\n            edge weights in the same network.\n        \"\"\"\n        # Extract the last segment of the B\u00e9zier curve\n        P1, P2 = vertices[-2], vertices[-1]\n        # 1. Calculate the tangent vector (direction of the curve at the end)\n        # For a quadratic curve, this is the vector from the control point to the end point.\n        tangent = P2 - P1\n        tangent /= np.linalg.norm(tangent, axis=1, keepdims=True)\n        # Avoid division by zero\n        tangent[tangent == 0] = 1e-6\n\n        # 2. Calculate the perpendicular vector for the width\n        perp = np.array([-tangent[:, 1], tangent[:, 0]]).T\n\n        # 3. Define the three points of the arrowhead triangle\n        base_center = P2\n        tip = P2 + tangent * head_length * self.data[\"edges\"][\"size\"].values[:, np.newaxis]\n        wing1 = base_center + perp * head_width / 2 * self.data[\"edges\"][\"size\"].values[:, np.newaxis]\n        wing2 = base_center - perp * head_width / 2 * self.data[\"edges\"][\"size\"].values[:, np.newaxis]\n\n        vertices = [wing1, tip, wing2, wing1]\n        codes = [\n            Path.MOVETO,\n            Path.LINETO,\n            Path.LINETO,\n            Path.CLOSEPOLY,  # Close the shape to make it fillable\n        ]\n        return vertices, codes\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/#pathpyG.visualisations._matplotlib.backend.MatplotlibBackend.__init__","title":"<code>__init__</code>","text":"<p>Initialize matplotlib backend with plot validation.</p> <p>Parameters:</p> Name Type Description Default <code>plot</code> <code>pathpyG.visualisations.pathpy_plot.PathPyPlot</code> <p>PathPyPlot instance containing network data</p> required <code>show_labels</code> <code>bool</code> <p>Whether to display node labels</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If plot type not supported by matplotlib backend</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/backend.py</code> <pre><code>def __init__(self, plot: PathPyPlot, show_labels: bool):\n    \"\"\"Initialize matplotlib backend with plot validation.\n\n    Args:\n        plot: PathPyPlot instance containing network data\n        show_labels: Whether to display node labels\n\n    Raises:\n        ValueError: If plot type not supported by matplotlib backend\n    \"\"\"\n    super().__init__(plot, show_labels=show_labels)\n    self._kind = SUPPORTED_KINDS.get(type(plot), None)  # type: ignore[arg-type]\n    if self._kind is None:\n        logger.error(f\"Plot of type {type(plot)} not supported by Matplotlib backend.\")\n        raise ValueError(f\"Plot of type {type(plot)} not supported.\")\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/#pathpyG.visualisations._matplotlib.backend.MatplotlibBackend.add_directed_edges","title":"<code>add_directed_edges</code>","text":"<p>Render directed edges using Bezier curves with arrowheads.</p> <p>Creates curved edges using quadratic Bezier curves and adds proportional arrowheads. Handles edge shortening and automatic fallback to straight edges when curves would be too short.</p> <p>Parameters:</p> Name Type Description Default <code>source_coords</code> <p>Source node coordinates array</p> required <code>target_coords</code> <p>Target node coordinates array</p> required <code>ax</code> <p>Matplotlib axes for rendering  </p> required <code>size_factor</code> <p>Scaling factor for node size calculations</p> required <p>Curve Limitations</p> <p>Falls back to straight edges when arrowheads would be too large relative to edge length to maintain visual clarity.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/backend.py</code> <pre><code>def add_directed_edges(self, source_coords, target_coords, ax, size_factor):\n    \"\"\"Render directed edges using Bezier curves with arrowheads.\n\n    Creates curved edges using quadratic Bezier curves and adds proportional\n    arrowheads. Handles edge shortening and automatic fallback to straight\n    edges when curves would be too short.\n\n    Args:\n        source_coords: Source node coordinates array\n        target_coords: Target node coordinates array\n        ax: Matplotlib axes for rendering  \n        size_factor: Scaling factor for node size calculations\n\n    !!! warning \"Curve Limitations\"\n        Falls back to straight edges when arrowheads would be too large\n        relative to edge length to maintain visual clarity.\n    \"\"\"\n    # get bezier curve vertices and codes\n    head_length = 0.02\n    vertices, codes = self.get_bezier_curve(\n        source_coords,\n        target_coords,\n        source_node_size=self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"source\"), [\"size\"]].values\n        * (size_factor / 2),  # /2 because we use radius instead of diameter\n        target_node_size=self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"target\"), [\"size\"]].values\n        * (size_factor / 2),\n        head_length=head_length,\n    )\n    ax.add_collection(\n        PathCollection(\n            [\n                Path(\n                    v,\n                    codes,\n                )\n                for v in zip(*vertices)\n            ],\n            facecolor=\"none\",\n            edgecolor=self.data[\"edges\"][\"color\"],\n            alpha=self.data[\"edges\"][\"opacity\"],\n            linewidth=self.data[\"edges\"][\"size\"],\n            zorder=1,\n        )\n    )\n\n    # add arrowheads\n    arrow_vertices, arrow_codes = self.get_arrowhead(vertices, head_length=head_length)\n    ax.add_collection(\n        PathCollection(\n            [Path(v, arrow_codes) for v in zip(*arrow_vertices)],\n            facecolor=self.data[\"edges\"][\"color\"],\n            edgecolor=self.data[\"edges\"][\"color\"],\n            alpha=self.data[\"edges\"][\"opacity\"],\n            zorder=1,\n        )\n    )\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/#pathpyG.visualisations._matplotlib.backend.MatplotlibBackend.add_undirected_edges","title":"<code>add_undirected_edges</code>","text":"<p>Render undirected edges using LineCollection for efficiency.</p> <p>Computes edge shortening to prevent overlap with nodes and renders all edges in a single matplotlib LineCollection for optimal performance.</p> <p>Parameters:</p> Name Type Description Default <code>source_coords</code> <p>Source node coordinates array</p> required <code>target_coords</code> <p>Target node coordinates array  </p> required <code>ax</code> <p>Matplotlib axes for rendering</p> required <code>size_factor</code> <p>Scaling factor for node size calculations</p> required <p>Edge Shortening</p> <p>Automatically shortens edges by node radius to create clean visual separation between edges and node boundaries.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/backend.py</code> <pre><code>def add_undirected_edges(self, source_coords, target_coords, ax, size_factor):\n    \"\"\"Render undirected edges using LineCollection for efficiency.\n\n    Computes edge shortening to prevent overlap with nodes and renders\n    all edges in a single matplotlib LineCollection for optimal performance.\n\n    Args:\n        source_coords: Source node coordinates array\n        target_coords: Target node coordinates array  \n        ax: Matplotlib axes for rendering\n        size_factor: Scaling factor for node size calculations\n\n    !!! tip \"Edge Shortening\"\n        Automatically shortens edges by node radius to create clean\n        visual separation between edges and node boundaries.\n    \"\"\"\n    # shorten edges so they don't overlap with nodes\n    vec = target_coords - source_coords\n    dist = np.linalg.norm(vec, axis=1, keepdims=True)\n    direction = vec / dist\n    source_coords += direction * (self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"source\"), [\"size\"]].values * (size_factor / 2))  # /2 because we use radius instead of diameter\n    target_coords -= direction * (self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"target\"), [\"size\"]].values * (size_factor / 2))\n\n    # create and add lines\n    edge_lines = list(zip(source_coords, target_coords))\n    ax.add_collection(\n        LineCollection(\n            edge_lines,\n            colors=self.data[\"edges\"][\"color\"],\n            alpha=self.data[\"edges\"][\"opacity\"],\n            linewidths=self.data[\"edges\"][\"size\"],\n            zorder=1,\n        )\n    )\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/#pathpyG.visualisations._matplotlib.backend.MatplotlibBackend.get_arrowhead","title":"<code>get_arrowhead</code>","text":"<p>Generate triangular arrowhead paths for directed edges.</p> <p>Creates proportional arrowheads at curve endpoints using tangent vectors for proper orientation. Arrowhead size scales with edge width for consistent visual appearance across different edge weights.</p> <p>Parameters:</p> Name Type Description Default <code>vertices</code> <p>Bezier curve vertices list for tangent calculation</p> required <code>head_length</code> <p>Base arrowhead length (scaled by edge size)</p> required <code>head_width</code> <p>Base arrowhead width (scaled by edge size)</p> <code>0.02</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>(vertices, codes) for matplotlib Path objects</p> <p>Proportional Scaling</p> <p>Arrowhead dimensions automatically scale with edge width to maintain consistent visual proportions across different edge weights in the same network.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/backend.py</code> <pre><code>def get_arrowhead(self, vertices, head_length, head_width=0.02):\n    \"\"\"Generate triangular arrowhead paths for directed edges.\n\n    Creates proportional arrowheads at curve endpoints using tangent vectors\n    for proper orientation. Arrowhead size scales with edge width for\n    consistent visual appearance across different edge weights.\n\n    Args:\n        vertices: Bezier curve vertices list for tangent calculation\n        head_length: Base arrowhead length (scaled by edge size)\n        head_width: Base arrowhead width (scaled by edge size)\n\n    Returns:\n        tuple: (vertices, codes) for matplotlib Path objects\n\n    !!! tip \"Proportional Scaling\"\n        Arrowhead dimensions automatically scale with edge width\n        to maintain consistent visual proportions across different\n        edge weights in the same network.\n    \"\"\"\n    # Extract the last segment of the B\u00e9zier curve\n    P1, P2 = vertices[-2], vertices[-1]\n    # 1. Calculate the tangent vector (direction of the curve at the end)\n    # For a quadratic curve, this is the vector from the control point to the end point.\n    tangent = P2 - P1\n    tangent /= np.linalg.norm(tangent, axis=1, keepdims=True)\n    # Avoid division by zero\n    tangent[tangent == 0] = 1e-6\n\n    # 2. Calculate the perpendicular vector for the width\n    perp = np.array([-tangent[:, 1], tangent[:, 0]]).T\n\n    # 3. Define the three points of the arrowhead triangle\n    base_center = P2\n    tip = P2 + tangent * head_length * self.data[\"edges\"][\"size\"].values[:, np.newaxis]\n    wing1 = base_center + perp * head_width / 2 * self.data[\"edges\"][\"size\"].values[:, np.newaxis]\n    wing2 = base_center - perp * head_width / 2 * self.data[\"edges\"][\"size\"].values[:, np.newaxis]\n\n    vertices = [wing1, tip, wing2, wing1]\n    codes = [\n        Path.MOVETO,\n        Path.LINETO,\n        Path.LINETO,\n        Path.CLOSEPOLY,  # Close the shape to make it fillable\n    ]\n    return vertices, codes\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/#pathpyG.visualisations._matplotlib.backend.MatplotlibBackend.get_bezier_curve","title":"<code>get_bezier_curve</code>","text":"<p>Generate quadratic Bezier curve paths for directed edges.</p> <p>Computes control points for smooth curved edges with automatic shortening to accommodate node sizes and arrowheads. Uses perpendicular offset for curve control points based on curvature configuration.</p> <p>Parameters:</p> Name Type Description Default <code>source_coords</code> <p>Start points (x, y) for all edges</p> required <code>target_coords</code> <p>End points (x, y) for all edges  </p> required <code>source_node_size</code> <p>Source node radii for edge shortening</p> required <code>target_node_size</code> <p>Target node radii for edge shortening</p> required <code>head_length</code> <p>Arrowhead length for target-end shortening</p> required <code>shorten</code> <p>Additional shortening amount to prevent visual overlap</p> <code>0.005</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>(vertices, codes) for matplotlib Path objects</p> <p>Bezier Curve Mathematics</p> <p>Uses quadratic Bezier curves with control point positioned perpendicular to edge midpoint. Curvature parameter controls the distance of control point from edge midpoint.</p> <p>Fallback Behavior</p> <p>Returns straight line paths when curves would be too short for proper arrowhead placement.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/backend.py</code> <pre><code>def get_bezier_curve(\n    self,\n    source_coords,\n    target_coords,\n    source_node_size,\n    target_node_size,\n    head_length,\n    shorten=0.005,\n):\n    \"\"\"Generate quadratic Bezier curve paths for directed edges.\n\n    Computes control points for smooth curved edges with automatic shortening\n    to accommodate node sizes and arrowheads. Uses perpendicular offset for\n    curve control points based on curvature configuration.\n\n    Args:\n        source_coords: Start points (x, y) for all edges\n        target_coords: End points (x, y) for all edges  \n        source_node_size: Source node radii for edge shortening\n        target_node_size: Target node radii for edge shortening\n        head_length: Arrowhead length for target-end shortening\n        shorten: Additional shortening amount to prevent visual overlap\n\n    Returns:\n        tuple: (vertices, codes) for matplotlib Path objects\n\n    !!! info \"Bezier Curve Mathematics\"\n        Uses quadratic Bezier curves with control point positioned\n        perpendicular to edge midpoint. Curvature parameter controls\n        the distance of control point from edge midpoint.\n\n    !!! note \"Fallback Behavior\" \n        Returns straight line paths when curves would be too short\n        for proper arrowhead placement.\n    \"\"\"\n    # Start and end points for the B\u00e9zier curve\n    P0 = source_coords\n    P2 = target_coords\n\n    # Calculate distance and direction vector\n    mid_point = (P0 + P2) / 2\n    vec = P2 - P0\n    dist = np.linalg.norm(vec, axis=1, keepdims=True)\n    # Avoid division by zero\n    dist[dist == 0] = 1e-6\n\n    # Perpendicular vector\n    perp_vec = np.array([-vec[:, 1], vec[:, 0]]).T / dist\n\n    # Calculate control points\n    P1 = mid_point + perp_vec * dist * self.config[\"curvature\"]\n\n    # Shorten the curve to avoid overlap with nodes\n    distance_P0_P1 = np.linalg.norm(P1 - P0, axis=1, keepdims=True)\n    distance_P0_P1[distance_P0_P1 == 0] = 1e-6\n    distance_P2_P1 = np.linalg.norm(P1 - P2, axis=1, keepdims=True)\n    distance_P2_P1[distance_P2_P1 == 0] = 1e-6\n    direction_P0_P1 = (P1 - P0) / distance_P0_P1\n    direction_P2_P1 = (P1 - P2) / distance_P2_P1\n    P0_offset_dist = shorten + source_node_size\n    P2_offset_dist = shorten + target_node_size + (head_length * self.data[\"edges\"][\"size\"].values[:, np.newaxis])\n    if (not self.config[\"curved\"]) or np.any(distance_P2_P1/2 &lt; P2_offset_dist):\n        logger.warning(\"Arrowhead length is too long for some edges. Please reduce the edge size. Using non-curved edges instead.\")\n        direction_P0_P2 = vec / dist\n        P0 += direction_P0_P2 * P0_offset_dist\n        P2 -= direction_P0_P2 * P2_offset_dist\n        return [P0, P2], [Path.MOVETO, Path.LINETO]\n\n    P0 += direction_P0_P1 * P0_offset_dist\n    P2 += direction_P2_P1 * P2_offset_dist\n\n    vertices = [P0, P1, P2]\n    codes = [\n        Path.MOVETO,\n        Path.CURVE3,\n        Path.MOVETO,\n    ]\n    return vertices, codes\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/#pathpyG.visualisations._matplotlib.backend.MatplotlibBackend.save","title":"<code>save</code>","text":"<p>Save plot to file with automatic format detection.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Output file path (format inferred from extension)</p> required Source code in <code>src/pathpyG/visualisations/_matplotlib/backend.py</code> <pre><code>def save(self, filename: str) -&gt; None:\n    \"\"\"Save plot to file with automatic format detection.\n\n    Args:\n        filename: Output file path (format inferred from extension)\n    \"\"\"\n    fig, ax = self.to_fig()\n    fig.savefig(filename)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/#pathpyG.visualisations._matplotlib.backend.MatplotlibBackend.show","title":"<code>show</code>","text":"<p>Display plot in interactive matplotlib window.</p> <p>Opens plot in default matplotlib backend for interactive exploration.</p> Source code in <code>src/pathpyG/visualisations/_matplotlib/backend.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Display plot in interactive matplotlib window.\n\n    Opens plot in default matplotlib backend for interactive exploration.\n    \"\"\"\n    fig, ax = self.to_fig()\n    plt.show()\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_matplotlib/backend/#pathpyG.visualisations._matplotlib.backend.MatplotlibBackend.to_fig","title":"<code>to_fig</code>","text":"<p>Generate complete matplotlib figure with network visualization.</p> <p>Creates figure with proper sizing, renders edges and nodes using optimized collections, adds labels if enabled, and sets appropriate axis limits.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[matplotlib.pyplot.Figure, matplotlib.pyplot.Axes]</code> <p>(Figure, Axes) matplotlib objects ready for display/saving</p> <p>Rendering Pipeline</p> <ol> <li>Setup: Create figure with configured dimensions and DPI</li> <li>Edges: Render using LineCollection (undirected) or PathCollection (directed)</li> <li>Nodes: Render using EllipseCollection for precise sizing</li> <li>Labels: Add text annotations at node centers</li> <li>Layout: Set axis limits with margin configuration</li> </ol> Source code in <code>src/pathpyG/visualisations/_matplotlib/backend.py</code> <pre><code>def to_fig(self) -&gt; tuple[plt.Figure, plt.Axes]:\n    \"\"\"Generate complete matplotlib figure with network visualization.\n\n    Creates figure with proper sizing, renders edges and nodes using optimized\n    collections, adds labels if enabled, and sets appropriate axis limits.\n\n    Returns:\n        tuple: (Figure, Axes) matplotlib objects ready for display/saving\n\n    !!! info \"Rendering Pipeline\"\n        1. **Setup**: Create figure with configured dimensions and DPI\n        2. **Edges**: Render using LineCollection (undirected) or PathCollection (directed)\n        3. **Nodes**: Render using EllipseCollection for precise sizing\n        4. **Labels**: Add text annotations at node centers\n        5. **Layout**: Set axis limits with margin configuration\n    \"\"\"\n    size_factor = 1 / 200  # scale node size to reasonable values\n    fig, ax = plt.subplots(\n        figsize=(unit_str_to_float(self.config[\"width\"], \"in\"), unit_str_to_float(self.config[\"height\"], \"in\")),\n        dpi=150,\n    )\n    ax.set_axis_off()\n\n    # get source and target coordinates for edges\n    source_coords = self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"source\"), [\"x\", \"y\"]].values\n    target_coords = self.data[\"nodes\"].loc[self.data[\"edges\"].index.get_level_values(\"target\"), [\"x\", \"y\"]].values\n\n    if self.config[\"directed\"]:\n        self.add_directed_edges(source_coords, target_coords, ax, size_factor)\n    else:\n        self.add_undirected_edges(source_coords, target_coords, ax, size_factor)\n\n    # plot nodes\n    # We use EllipseCollection instead of scatter because there you can specify the radius of each circle in the unit of the data coordinates\n    # https://stackoverflow.com/a/33095224\n    ax.add_collection(\n        EllipseCollection(\n            widths=self.data[\"nodes\"][\"size\"] * size_factor,\n            heights=self.data[\"nodes\"][\"size\"] * size_factor,\n            angles=0,\n            units=\"xy\",\n            offsets=self.data[\"nodes\"][[\"x\", \"y\"]].values,\n            transOffset=ax.transData,\n            facecolors=self.data[\"nodes\"][\"color\"],\n            edgecolors=\"black\",\n            linewidths=0.5,\n            alpha=self.data[\"nodes\"][\"opacity\"],\n            zorder=2,\n        )\n    )\n\n    # add node labels\n    if self.show_labels:\n        if self._kind == \"static\":\n            for label in self.data[\"nodes\"].index:\n                x, y = self.data[\"nodes\"].loc[[label], [\"x\", \"y\"]].values.flatten()\n                # Annotate the node label with text in the center of the node\n                ax.annotate(\n                    label,\n                    (x, y),\n                    fontsize=0.4 * self.data[\"nodes\"][\"size\"].mean(),\n                    ha=\"center\",\n                    va=\"center\",\n                )\n        elif self._kind == \"unfolded\":\n            # add labels at the starting nodes only\n            min_time = self.data[\"nodes\"][\"start\"].min()\n            offset = 0.005 * self.data[\"nodes\"][\"size\"].mean()\n            sign = 1 if self.config[\"orientation\"] in [\"down\", \"left\"] else -1\n            label_df = self.data[\"nodes\"][self.data[\"nodes\"][\"start\"] == min_time]\n            for label in label_df.index:\n                x, y = label_df.loc[[label], [\"x\", \"y\"]].values.flatten()\n                ax.annotate(\n                    label[0],\n                    (x, y + offset * sign) if self.config[\"orientation\"] in [\"down\", \"up\"] else (x + offset * sign, y),\n                    fontsize=0.5 * self.data[\"nodes\"][\"size\"].mean(),\n                    ha=\"center\",\n                    va=\"center\",\n                )\n\n            # add timestamps at the border\n            times = self.data[\"nodes\"][\"start\"].unique()\n            for time in times[:-1]:  # skip last time as it would be outside the plot\n                x, y = self.data[\"nodes\"].iloc[time:time+2, :][[\"x\", \"y\"]].values.mean(axis=0)\n                ax.annotate(\n                    str(time),\n                    (x - offset, y) if self.config[\"orientation\"] in [\"down\", \"up\"] else (x, y - offset),\n                    fontsize=0.5 * self.data[\"nodes\"][\"size\"].mean(),\n                    ha=\"center\",\n                    va=\"center\",\n                )\n\n    # set limits\n    ax.set_xlim(-1 * self.config[\"margin\"], 1 + (1*self.config[\"margin\"]))\n    ax.set_ylim(-1 * self.config[\"margin\"], 1 + (1*self.config[\"margin\"]))\n    return fig, ax\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/","title":"tikz","text":"<p>TikZ Backend for PathpyG Visualizations.</p> <p>Publication-quality vector graphics backend using LaTeX's TikZ package for static networks. Ideal for academic publications and high-quality print materials.</p> <p>Output Formats</p> <ul> <li>SVG: Scalable vector graphics for web and presentations</li> <li>PDF: Print-ready documents with embedded fonts  </li> <li>TeX: Raw LaTeX code for document integration</li> </ul> <p>Requirements</p> <ul> <li>LaTeX distribution with TikZ package</li> <li><code>dvisvgm</code> for SVG output (included with TeX Live)</li> <li><code>pdflatex</code> for PDF output</li> </ul>"},{"location":"reference/pathpyG/visualisations/_tikz/#pathpyG.visualisations._tikz--basic-usage","title":"Basic Usage","text":"<p><pre><code>import pathpyG as pp\n\n# Simple network visualization\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g, backend=\"tikz\")\n</code></pre> </p>"},{"location":"reference/pathpyG/visualisations/_tikz/#pathpyG.visualisations._tikz--advanced-example","title":"Advanced Example","text":"<p><pre><code>import pathpyG as pp\nimport torch\n\n# Graph with custom styling\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"D\"), (\"D\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\ng.data[\"node_size\"] = torch.tensor([15, 20, 25, 20])\n\npp.plot(\n    g,\n    backend=\"tikz\",\n    node_color={\"A\": \"red\", \"B\": \"#00FF00\"},\n    edge_opacity=0.7,\n    curvature=0.2,\n    width=\"8cm\",\n    height=\"6cm\",\n    filename=\"custom_network.svg\"\n)\n</code></pre> </p>"},{"location":"reference/pathpyG/visualisations/_tikz/#pathpyG.visualisations._tikz--time-unfolded-network-example","title":"Time-Unfolded Network Example","text":"<p>You can also create time-unfolded visualizations of temporal networks using the TikZ backend with all customization options from the temporal animations. With the <code>orientation</code> parameter, you can control the layout direction of the time-unfolded graph.</p> <p><pre><code>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\nnode_color = {\"a\": \"red\", (\"a\", 2): \"darkred\"}\nedge_color = {(\"a\", \"b\", 2): \"blue\"}\npp.plot(t, backend=\"tikz\", kind=\"unfolded\", node_size=12, node_color=node_color, edge_color=edge_color, orientation=\"right\")\n</code></pre> </p>"},{"location":"reference/pathpyG/visualisations/_tikz/#pathpyG.visualisations._tikz--templates","title":"Templates","text":"<p>PathpyG uses LaTeX templates to generate TikZ visualizations. Templates define standalone LaTeX documents with placeholders for dynamic content. Templates are located in the <code>pathpyG/visualisations/_tikz/templates/</code> directory. Currently supported templates: - <code>static.tex</code>: For static networks without time dynamics.</p>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/","title":"backend","text":"<p>TikZ/LaTeX Backend for High-Quality Network Visualizations.</p> <p>This backend generates publication-ready vector graphics using LaTeX's TikZ package. It provides precise control over visual elements and produces scalable output suitable for academic papers, presentations, and professional documentation.</p> <p>Backend Capabilities</p> <ul> <li>Static networks only - Temporal networks not supported</li> <li>Vector output - SVG, PDF, and raw TeX formats</li> <li>LaTeX compilation - Automatic document generation and compilation</li> <li>Custom styling - Full control over colors, sizes, and layouts</li> </ul> <p>The backend handles the complete workflow from graph data to compiled output, including template processing, LaTeX compilation, and format conversion.</p>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/#pathpyG.visualisations._tikz.backend--workflow-overview","title":"Workflow Overview","text":"<pre><code>graph LR\n    A[Graph Data] --&gt; B[TikZ Template]\n    B --&gt; C[LaTeX Document]\n    C --&gt; D[Compilation]\n    D --&gt; E[PDF Output]\n    D --&gt; F[DVI Output]\n    F --&gt; H[Conversion]\n    H --&gt; I[SVG Output]\n    C --&gt; G[TeX Output]</code></pre> <p>Performance Considerations</p> <ul> <li>Compilation time scales with network complexity</li> <li>Large networks (&gt;500 nodes) may require significant processing time</li> <li>Consider <code>matplotlib</code> backend for rapid prototyping of complex networks</li> </ul>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/#pathpyG.visualisations._tikz.backend.TikzBackend","title":"<code>TikzBackend</code>","text":"<p>               Bases: <code>pathpyG.visualisations.plot_backend.PlotBackend</code></p> <p>TikZ/LaTeX Backend for Publication-Quality Network Graphics.</p> <p>Generates high-quality vector graphics using LaTeX's TikZ package. The backend mainly uses the <code>tikz-network</code> package to create detailed and customizable visualizations. This backend is optimized for static networks and provides publication-ready output with precise control over visual elements.</p> <p>Supported Operations</p> <ul> <li>Formats: SVG, PDF, TeX</li> <li>Networks: Static graphs only</li> <li>Styling: Full customization support</li> <li>Layouts: All pathpyG layout algorithms</li> </ul> <p>The backend automatically handles LaTeX compilation, temporary file management, and format conversion to deliver clean, scalable graphics suitable for academic publications and professional presentations.</p> <p>Attributes:</p> Name Type Description <code>plot</code> <p>The PathPyPlot instance containing graph data and configuration</p> <code>show_labels</code> <p>Whether to display node labels in the output</p> <code>_kind</code> <p>Type of plot being processed (for now only \"static\" supported)</p> Example <p><pre><code># The backend is typically used via pp.plot()\nimport pathpyG as pp\n\ng = pp.Graph.from_edge_list([(\"A\", \"B\"), (\"B\", \"C\")])\npp.plot(g, backend=\"tikz\")\n</code></pre> </p> Source code in <code>src/pathpyG/visualisations/_tikz/backend.py</code> <pre><code>class TikzBackend(PlotBackend):\n    \"\"\"TikZ/LaTeX Backend for Publication-Quality Network Graphics.\n\n    Generates high-quality vector graphics using LaTeX's TikZ package.\n    The backend mainly uses the [`tikz-network`](https://github.com/hackl/tikz-network)\n    package to create detailed and customizable visualizations. This backend\n    is optimized for static networks and provides publication-ready output with\n    precise control over visual elements.\n\n    !!! info \"Supported Operations\"\n        - **Formats**: SVG, PDF, TeX\n        - **Networks**: Static graphs only\n        - **Styling**: Full customization support\n        - **Layouts**: All pathpyG layout algorithms\n\n    The backend automatically handles LaTeX compilation, temporary file management,\n    and format conversion to deliver clean, scalable graphics suitable for\n    academic publications and professional presentations.\n\n    Attributes:\n        plot: The PathPyPlot instance containing graph data and configuration\n        show_labels: Whether to display node labels in the output\n        _kind: Type of plot being processed (for now only \"static\" supported)\n\n    Example:\n        ```python\n        # The backend is typically used via pp.plot()\n        import pathpyG as pp\n\n        g = pp.Graph.from_edge_list([(\"A\", \"B\"), (\"B\", \"C\")])\n        pp.plot(g, backend=\"tikz\")\n        ```\n        &lt;img src=\"../../plot/tikz_backend_example.svg\" alt=\"Example TikZ Backend Output\" width=\"550\"/&gt;\n    \"\"\"\n\n    def __init__(self, plot: PathPyPlot, show_labels: bool):\n        \"\"\"Initialize the TikZ backend with plot data and configuration.\n\n        Sets up the backend to process the provided plot data and validates\n        that the plot type is supported by the TikZ backend.\n\n        Args:\n            plot: PathPyPlot instance containing graph data, layout, and styling\n            show_labels: Whether to display node labels in the generated output\n\n        Raises:\n            ValueError: If the plot type is not supported by the TikZ backend\n\n        Note:\n            Currently only static NetworkPlot instances are supported.\n            Temporal networks require, e.g. the manim backend instead.\n        \"\"\"\n        super().__init__(plot, show_labels=show_labels)\n        self._kind = SUPPORTED_KINDS.get(type(plot), None)  # type: ignore[arg-type]\n        if self._kind is None:\n            logger.error(f\"Plot of type {type(plot)} not supported by Tikz backend.\")\n            raise ValueError(f\"Plot of type {type(plot)} not supported.\")\n\n    def save(self, filename: str) -&gt; None:\n        \"\"\"Save the network visualization to a file in the specified format.\n\n        Automatically detects the output format from the file extension and\n        performs the necessary compilation steps. Supports TeX (raw LaTeX),\n        PDF (compiled document), and SVG (vector graphics) formats.\n\n        Args:\n            filename: Output file path with extension (.tex, .pdf, or .svg)\n\n        Raises:\n            NotImplementedError: If the file extension is not supported\n\n        Note:\n            PDF and SVG compilation requires LaTeX toolchain installation.\n            The method handles temporary file creation and cleanup automatically.\n        \"\"\"\n        if filename.endswith(\"tex\"):\n            with open(filename, \"w+\") as new:\n                new.write(self.to_tex())\n        elif filename.endswith(\"pdf\"):\n            # compile temporary pdf\n            temp_file, temp_dir = self.compile_pdf()\n            # Copy a file with new name\n            shutil.copy(temp_file, filename)\n            # remove the temporal directory\n            shutil.rmtree(temp_dir)\n        elif filename.endswith(\"svg\"):\n            # compile temporary svg\n            temp_file, temp_dir = self.compile_svg()\n            # Copy a file with new name\n            shutil.copy(temp_file, filename)\n            # remove the temporal directory\n            shutil.rmtree(temp_dir)\n        else:\n            raise NotImplementedError\n\n    def show(self) -&gt; None:\n        \"\"\"Display the network visualization in the current environment.\n\n        Compiles the network to SVG format and displays it either inline\n        (in Jupyter notebooks) or opens it in the default web browser.\n        The display method is automatically chosen based on the environment.\n\n        The method creates temporary files for compilation and cleans them\n        up automatically after display.\n\n        Environment Detection:\n            - **Interactive (Jupyter)**: Displays SVG inline using IPython.display\n            - **Non-interactive**: Opens SVG file in default web browser\n\n        Note:\n            Requires LaTeX toolchain with TikZ and dvisvgm for SVG compilation.\n            Temporary files are automatically cleaned up after a brief delay.\n        \"\"\"\n        # compile temporary pdf\n        temp_file, temp_dir = self.compile_svg()\n\n        if config[\"environment\"][\"interactive\"]:\n            from IPython.display import SVG, display\n\n            # open the file, read the content and display it\n            # workaround because it is not possible to embed files in vs code\n            # https://github.com/microsoft/vscode-jupyter/discussions/13769\n            with open(temp_file, \"r\") as svg_file:\n                svg = SVG(svg_file.read())\n            display(svg)\n        else:\n            # open the file in the webbrowser\n            webbrowser.open(r\"file:///\" + temp_file)\n\n        # Wait for .1 second before temp file is deleted\n        time.sleep(0.1)\n\n        # remove the temporal directory\n        shutil.rmtree(temp_dir)\n\n    def compile_svg(self) -&gt; tuple:\n        \"\"\"Compile LaTeX source to SVG format using the LaTeX toolchain.\n\n        Performs a complete compilation workflow: TeX \u2192 DVI \u2192 SVG conversion.\n        Uses latexmk for robust LaTeX compilation and dvisvgm for high-quality\n        SVG conversion with proper text rendering.\n\n        Returns:\n            tuple: (svg_file_path, temp_directory_path) for the compiled SVG\n\n        Raises:\n            AttributeError: If LaTeX compilation fails or required tools are missing\n\n        Compilation Steps:\n            1. Generate temporary directory and save TeX source\n            2. Run latexmk to compile TeX \u2192 DVI\n            3. Use dvisvgm to convert DVI \u2192 SVG\n            4. Return paths for file access and cleanup\n\n        Note:\n            Both latexmk and dvisvgm must be available in the system PATH.\n        \"\"\"\n        temp_dir, current_dir = prepare_tempfile()\n        # save the tex file\n        self.save(\"default.tex\")\n\n        # latex compiler\n        command = [\n            \"latexmk\",\n            \"--interaction=nonstopmode\",\n            \"default.tex\",\n        ]\n        try:\n            subprocess.check_output(command, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            logger.error(\"latexmk compiler failed with output:\\n%s\", e.output.decode())\n            raise AttributeError from e\n\n        # dvisvgm command\n        command = [\n            \"dvisvgm\",\n            \"default.dvi\",\n            \"-o\",\n            \"default.svg\",\n        ]\n        try:\n            subprocess.check_output(command, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            logger.error(\"dvisvgm command failed with output:\\n%s\", e.output.decode())\n            raise AttributeError from e\n        finally:\n            # change back to the current directory\n            os.chdir(current_dir)\n\n        # return the name of the folder and temp svg file\n        return os.path.join(temp_dir, \"default.svg\"), temp_dir\n\n    def compile_pdf(self) -&gt; tuple:\n        \"\"\"Compile LaTeX source to PDF format using pdflatex.\n\n        Generates a high-quality PDF document suitable for printing and\n        publication. Uses latexmk with PDF mode for robust compilation\n        and automatic dependency handling.\n\n        Returns:\n            tuple: (pdf_file_path, temp_directory_path) for the compiled PDF\n\n        Raises:\n            AttributeError: If LaTeX compilation fails or pdflatex is not available\n\n        Note:\n            Requires latexmk and a PDF-capable LaTeX engine (pdflatex, xelatex, etc.).\n        \"\"\"\n        temp_dir, current_dir = prepare_tempfile()\n        # save the tex file\n        self.save(\"default.tex\")\n\n        # latex compiler\n        command = [\n            \"latexmk\",\n            \"--pdf\",\n            \"-shell-escape\",\n            \"--interaction=nonstopmode\",\n            \"default.tex\",\n        ]\n\n        try:\n            subprocess.check_output(command, stderr=subprocess.STDOUT)\n        except subprocess.CalledProcessError as e:\n            logger.error(\"latexmk compiler failed with output:\\n%s\", e.output.decode())\n            raise AttributeError from e\n        finally:\n            # change back to the current directory\n            os.chdir(current_dir)\n\n        # return the name of the folder and temp pdf file\n        return os.path.join(temp_dir, \"default.pdf\"), temp_dir\n\n    def to_tex(self) -&gt; str:\n        \"\"\"Generate complete LaTeX document with TikZ network visualization.\n\n        Combines the network data with a LaTeX template to create a complete\n        document ready for compilation. The template includes all necessary\n        packages, document setup, and TikZ drawing commands.\n\n        Returns:\n            str: Complete LaTeX document source code\n\n        Process:\n            1. **Load template** - Retrieves the appropriate template for the plot type\n            2. **Generate TikZ** - Converts network data to TikZ drawing commands\n            3. **Template substitution** - Fills template variables with graph data\n            4. **Return final string** - Complete LaTeX document ready for compilation\n\n        Template Variables:\n            - `$classoptions`: LaTeX class options\n            - `$width`, `$height`: Document dimensions\n            - `$margin`: Margin around the drawing area\n            - `$tikz`: TikZ drawing commands for nodes and edges\n\n        Note:\n            The generated document is self-contained and includes all necessary\n            TikZ packages and configuration for network visualization.\n        \"\"\"\n        # get path to the pathpy templates\n        template_dir = os.path.join(\n            os.path.dirname(os.path.dirname(__file__)),\n            os.path.normpath(\"_tikz/templates\"),\n        )\n\n        # get template files\n        with open(os.path.join(template_dir, f\"static.tex\")) as template:\n            tex_template = template.read()\n\n        # generate data\n        data = self.to_tikz()\n\n        # fill template with data\n        tex = Template(tex_template).substitute(\n            classoptions=self.config.get(\"latex_class_options\"),\n            width=unit_str_to_float(self.config.get(\"width\"), \"cm\"),  # type: ignore[arg-type]\n            height=unit_str_to_float(self.config.get(\"height\"), \"cm\"),  # type: ignore[arg-type]\n            margin=self.config.get(\"margin\"),\n            tikz=data,\n        )\n\n        return tex\n\n    def to_tikz(self) -&gt; str:\n        r\"\"\"Generate TikZ drawing commands for the network visualization.\n\n        Converts the processed graph data (nodes, edges, layout) into TikZ-specific\n        drawing commands. Handles node positioning, styling, edge routing, and\n        label placement according to the configured visualization parameters.\n\n        Returns:\n            str: TikZ drawing commands ready for inclusion in LaTeX document\n\n        Generated Elements:\n            - **Node commands** - `\\Vertex` with labels, positions, colors, and sizes\n            - **Edge commands** - `\\Edge` with styling and optional curvature\n\n        Note:\n            The output assumes the tikz-network package is loaded in the template.\n            Coordinates are assumed to be normalized to [0, 1] range and scaled\n            according to the specified document dimensions.\n        \"\"\"\n        tikz = \"\"\n        # generate node strings\n        if not self.data[\"nodes\"].empty:\n            node_strings: pd.Series = \"\\\\Vertex[\"\n            # show labels if specified\n            if self.show_labels and self._kind == \"static\":\n                node_strings += (\n                    \"label=$\" + self.data[\"nodes\"].index.astype(str).map(self._replace_with_LaTeX_math_symbol) + \"$,\"\n                )\n                node_strings += (\n                    \"fontsize=\\\\fontsize{\" + str(int(0.6 * self.data[\"nodes\"][\"size\"].mean())) + \"}{10}\\selectfont,\"\n                )\n            # Convert hex colors to rgb if necessary\n            if self.data[\"nodes\"][\"color\"].str.startswith(\"#\").all():\n                self.data[\"nodes\"][\"color\"] = self.data[\"nodes\"][\"color\"].map(hex_to_rgb)\n                node_strings += \"RGB,color={\" + self.data[\"nodes\"][\"color\"].astype(str).str.strip(\"()\") + \"},\"\n            else:\n                node_strings += \"color=\" + self.data[\"nodes\"][\"color\"] + \",\"\n            # add other options\n            node_strings += \"size=\" + (self.data[\"nodes\"][\"size\"] * 0.075).astype(str) + \",\"\n            node_strings += \"opacity=\" + self.data[\"nodes\"][\"opacity\"].astype(str) + \",style={draw opacity=\" + self.data[\"nodes\"][\"opacity\"].astype(str) + \"},\" \n            # add position\n            node_strings += (\n                \"x=\"\n                + ((self.data[\"nodes\"][\"x\"] - 0.5) * unit_str_to_float(self.config[\"width\"], \"cm\")).astype(str)\n                + \",\"\n            )\n            node_strings += (\n                \"y=\"\n                + ((self.data[\"nodes\"][\"y\"] - 0.5) * unit_str_to_float(self.config[\"height\"], \"cm\")).astype(str)\n                + \"]\"\n            )\n            # add node name\n            node_strings += (\n                \"{\"\n                + self.data[\"nodes\"].index.map(lambda x: f\"{x[0]}{x[1]}\" if isinstance(x, tuple) else str(x))\n                + \"};\\n\"\n            )\n            tikz += node_strings.str.cat()\n\n            if self.show_labels and self._kind == \"unfolded\":\n                # add labels at the starting nodes only\n                min_time = self.data[\"nodes\"][\"start\"].min()\n                offset = 0.06 * self.data[\"nodes\"][\"size\"].mean()\n                sign = 1 if self.config[\"orientation\"] in [\"down\", \"left\"] else -1\n                label_df = self.data[\"nodes\"][self.data[\"nodes\"][\"start\"] == min_time]\n                label_strings: pd.Series = \"\\\\Vertex[\"\n                label_strings += \"label=$\" + label_df.index.map(lambda x: str(x[0])) + \"$,\"\n                label_strings += \"fontsize=\\\\fontsize{\" + str(int(label_df[\"size\"].mean())) + \"}{10}\\\\selectfont,\"\n                label_strings += \"opacity=0.0,style={draw=none},\"\n                label_strings += (\n                    \"x=\"\n                    + (\n                        (label_df[\"x\"] - 0.5) * unit_str_to_float(self.config[\"width\"], \"cm\")\n                        + (sign * offset if self.config[\"orientation\"] in [\"left\", \"right\"] else 0)\n                    ).astype(str)\n                    + \",\"\n                )\n                label_strings += (\n                    \"y=\"\n                    + (\n                        (label_df[\"y\"] - 0.5) * unit_str_to_float(self.config[\"height\"], \"cm\")\n                        + (sign * offset if self.config[\"orientation\"] in [\"down\", \"up\"] else 0)\n                    ).astype(str)\n                    + \"]\"\n                )\n                label_strings += \"{\" + label_df.index.map(lambda x: \"label_\" + str(x[0])) + \"};\\n\"\n                tikz += label_strings.str.cat()\n\n                # add timestamps at the border\n                time_df = self.data[\"nodes\"].iloc[: self.data[\"nodes\"][\"end\"].max()]\n                time_df.loc[:, [\"x\", \"y\"]] = (time_df[[\"x\", \"y\"]] + time_df[[\"x\", \"y\"]].shift(-1)) / 2\n                time_df = time_df.iloc[:-1]\n                time_strings: pd.Series = \"\\\\Vertex[\"\n                time_strings += \"label=$\" + time_df[\"start\"].astype(str) + \"$,\"\n                time_strings += \"fontsize=\\\\fontsize{\" + str(int(time_df[\"size\"].mean())) + \"}{10}\\\\selectfont,\"\n                time_strings += \"opacity=0.0,style={draw=none},\"\n                time_strings += (\n                    \"x=\"\n                    + (\n                        (time_df[\"x\"] - 0.5) * unit_str_to_float(self.config[\"width\"], \"cm\")\n                        - (offset if self.config[\"orientation\"] in [\"up\", \"down\"] else 0)\n                    ).astype(str)\n                    + \",\"\n                )\n                time_strings += (\n                    \"y=\"\n                    + (\n                        (time_df[\"y\"] - 0.5) * unit_str_to_float(self.config[\"height\"], \"cm\")\n                        - (offset if self.config[\"orientation\"] in [\"left\", \"right\"] else 0)\n                    ).astype(str)\n                    + \"]\"\n                )\n                time_strings += \"{\" + time_df.index.map(lambda x: \"time_\" + str(x[0])) + \"};\\n\"\n                tikz += time_strings.str.cat()\n\n        # generate edge strings\n        if not self.data[\"edges\"].empty:\n            edge_strings: pd.Series = \"\\\\Edge[\"\n            if self.config[\"curved\"]:\n                edge_strings += \"bend=15,\"\n            if self.config[\"directed\"]:\n                edge_strings += \"Direct,\"\n            if self.data[\"edges\"][\"color\"].str.startswith(\"#\").all():\n                self.data[\"edges\"][\"color\"] = self.data[\"edges\"][\"color\"].map(hex_to_rgb)\n                edge_strings += \"RGB,color={\" + self.data[\"edges\"][\"color\"].astype(str).str.strip(\"()\") + \"},\"\n            else:\n                edge_strings += \"color=\" + self.data[\"edges\"][\"color\"] + \",\"\n            edge_strings += \"lw=\" + self.data[\"edges\"][\"size\"].astype(str) + \",\"\n            edge_strings += \"opacity=\" + self.data[\"edges\"][\"opacity\"].astype(str) + \"]\"\n            edge_strings += (\n                \"(\"\n                + self.data[\"edges\"]\n                .index.to_frame()[\"source\"]\n                .map(lambda x: f\"{x[0]}{x[1]}\" if isinstance(x, tuple) else str(x))\n                + \")(\"\n                + self.data[\"edges\"]\n                .index.to_frame()[\"target\"]\n                .map(lambda x: f\"{x[0]}{x[1]}\" if isinstance(x, tuple) else str(x))\n                + \");\\n\"\n            )\n            tikz += edge_strings.str.cat()\n\n        return tikz\n\n    def _replace_with_LaTeX_math_symbol(self, node_label: str) -&gt; str:\n        \"\"\"Replace certain symbols with LaTeX math symbols.\"\"\"\n        replacements = {\n            \"-&gt;\": r\"\\to \",\n            \"&lt;-\": r\"\\gets \",\n            \"&lt;-&gt;\": r\"\\leftrightarrow \",\n            \"=&gt;\": r\"\\Rightarrow \",\n            \"&lt;=\": r\"\\Leftarrow \",\n            \"&lt;=&gt;\": r\"\\Leftrightarrow \",\n            \"!=\": r\"\\neq \",\n        }\n        if self.config[\"separator\"].strip() in replacements:\n            node_label = node_label.replace(\n                self.config[\"separator\"],\n                replacements[self.config[\"separator\"].strip()],\n            )\n        return node_label\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/#pathpyG.visualisations._tikz.backend.TikzBackend.__init__","title":"<code>__init__</code>","text":"<p>Initialize the TikZ backend with plot data and configuration.</p> <p>Sets up the backend to process the provided plot data and validates that the plot type is supported by the TikZ backend.</p> <p>Parameters:</p> Name Type Description Default <code>plot</code> <code>pathpyG.visualisations.pathpy_plot.PathPyPlot</code> <p>PathPyPlot instance containing graph data, layout, and styling</p> required <code>show_labels</code> <code>bool</code> <p>Whether to display node labels in the generated output</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the plot type is not supported by the TikZ backend</p> Note <p>Currently only static NetworkPlot instances are supported. Temporal networks require, e.g. the manim backend instead.</p> Source code in <code>src/pathpyG/visualisations/_tikz/backend.py</code> <pre><code>def __init__(self, plot: PathPyPlot, show_labels: bool):\n    \"\"\"Initialize the TikZ backend with plot data and configuration.\n\n    Sets up the backend to process the provided plot data and validates\n    that the plot type is supported by the TikZ backend.\n\n    Args:\n        plot: PathPyPlot instance containing graph data, layout, and styling\n        show_labels: Whether to display node labels in the generated output\n\n    Raises:\n        ValueError: If the plot type is not supported by the TikZ backend\n\n    Note:\n        Currently only static NetworkPlot instances are supported.\n        Temporal networks require, e.g. the manim backend instead.\n    \"\"\"\n    super().__init__(plot, show_labels=show_labels)\n    self._kind = SUPPORTED_KINDS.get(type(plot), None)  # type: ignore[arg-type]\n    if self._kind is None:\n        logger.error(f\"Plot of type {type(plot)} not supported by Tikz backend.\")\n        raise ValueError(f\"Plot of type {type(plot)} not supported.\")\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/#pathpyG.visualisations._tikz.backend.TikzBackend.compile_pdf","title":"<code>compile_pdf</code>","text":"<p>Compile LaTeX source to PDF format using pdflatex.</p> <p>Generates a high-quality PDF document suitable for printing and publication. Uses latexmk with PDF mode for robust compilation and automatic dependency handling.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>(pdf_file_path, temp_directory_path) for the compiled PDF</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If LaTeX compilation fails or pdflatex is not available</p> Note <p>Requires latexmk and a PDF-capable LaTeX engine (pdflatex, xelatex, etc.).</p> Source code in <code>src/pathpyG/visualisations/_tikz/backend.py</code> <pre><code>def compile_pdf(self) -&gt; tuple:\n    \"\"\"Compile LaTeX source to PDF format using pdflatex.\n\n    Generates a high-quality PDF document suitable for printing and\n    publication. Uses latexmk with PDF mode for robust compilation\n    and automatic dependency handling.\n\n    Returns:\n        tuple: (pdf_file_path, temp_directory_path) for the compiled PDF\n\n    Raises:\n        AttributeError: If LaTeX compilation fails or pdflatex is not available\n\n    Note:\n        Requires latexmk and a PDF-capable LaTeX engine (pdflatex, xelatex, etc.).\n    \"\"\"\n    temp_dir, current_dir = prepare_tempfile()\n    # save the tex file\n    self.save(\"default.tex\")\n\n    # latex compiler\n    command = [\n        \"latexmk\",\n        \"--pdf\",\n        \"-shell-escape\",\n        \"--interaction=nonstopmode\",\n        \"default.tex\",\n    ]\n\n    try:\n        subprocess.check_output(command, stderr=subprocess.STDOUT)\n    except subprocess.CalledProcessError as e:\n        logger.error(\"latexmk compiler failed with output:\\n%s\", e.output.decode())\n        raise AttributeError from e\n    finally:\n        # change back to the current directory\n        os.chdir(current_dir)\n\n    # return the name of the folder and temp pdf file\n    return os.path.join(temp_dir, \"default.pdf\"), temp_dir\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/#pathpyG.visualisations._tikz.backend.TikzBackend.compile_svg","title":"<code>compile_svg</code>","text":"<p>Compile LaTeX source to SVG format using the LaTeX toolchain.</p> <p>Performs a complete compilation workflow: TeX \u2192 DVI \u2192 SVG conversion. Uses latexmk for robust LaTeX compilation and dvisvgm for high-quality SVG conversion with proper text rendering.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>(svg_file_path, temp_directory_path) for the compiled SVG</p> <p>Raises:</p> Type Description <code>AttributeError</code> <p>If LaTeX compilation fails or required tools are missing</p> Compilation Steps <ol> <li>Generate temporary directory and save TeX source</li> <li>Run latexmk to compile TeX \u2192 DVI</li> <li>Use dvisvgm to convert DVI \u2192 SVG</li> <li>Return paths for file access and cleanup</li> </ol> Note <p>Both latexmk and dvisvgm must be available in the system PATH.</p> Source code in <code>src/pathpyG/visualisations/_tikz/backend.py</code> <pre><code>def compile_svg(self) -&gt; tuple:\n    \"\"\"Compile LaTeX source to SVG format using the LaTeX toolchain.\n\n    Performs a complete compilation workflow: TeX \u2192 DVI \u2192 SVG conversion.\n    Uses latexmk for robust LaTeX compilation and dvisvgm for high-quality\n    SVG conversion with proper text rendering.\n\n    Returns:\n        tuple: (svg_file_path, temp_directory_path) for the compiled SVG\n\n    Raises:\n        AttributeError: If LaTeX compilation fails or required tools are missing\n\n    Compilation Steps:\n        1. Generate temporary directory and save TeX source\n        2. Run latexmk to compile TeX \u2192 DVI\n        3. Use dvisvgm to convert DVI \u2192 SVG\n        4. Return paths for file access and cleanup\n\n    Note:\n        Both latexmk and dvisvgm must be available in the system PATH.\n    \"\"\"\n    temp_dir, current_dir = prepare_tempfile()\n    # save the tex file\n    self.save(\"default.tex\")\n\n    # latex compiler\n    command = [\n        \"latexmk\",\n        \"--interaction=nonstopmode\",\n        \"default.tex\",\n    ]\n    try:\n        subprocess.check_output(command, stderr=subprocess.STDOUT)\n    except subprocess.CalledProcessError as e:\n        logger.error(\"latexmk compiler failed with output:\\n%s\", e.output.decode())\n        raise AttributeError from e\n\n    # dvisvgm command\n    command = [\n        \"dvisvgm\",\n        \"default.dvi\",\n        \"-o\",\n        \"default.svg\",\n    ]\n    try:\n        subprocess.check_output(command, stderr=subprocess.STDOUT)\n    except subprocess.CalledProcessError as e:\n        logger.error(\"dvisvgm command failed with output:\\n%s\", e.output.decode())\n        raise AttributeError from e\n    finally:\n        # change back to the current directory\n        os.chdir(current_dir)\n\n    # return the name of the folder and temp svg file\n    return os.path.join(temp_dir, \"default.svg\"), temp_dir\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/#pathpyG.visualisations._tikz.backend.TikzBackend.save","title":"<code>save</code>","text":"<p>Save the network visualization to a file in the specified format.</p> <p>Automatically detects the output format from the file extension and performs the necessary compilation steps. Supports TeX (raw LaTeX), PDF (compiled document), and SVG (vector graphics) formats.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Output file path with extension (.tex, .pdf, or .svg)</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the file extension is not supported</p> Note <p>PDF and SVG compilation requires LaTeX toolchain installation. The method handles temporary file creation and cleanup automatically.</p> Source code in <code>src/pathpyG/visualisations/_tikz/backend.py</code> <pre><code>def save(self, filename: str) -&gt; None:\n    \"\"\"Save the network visualization to a file in the specified format.\n\n    Automatically detects the output format from the file extension and\n    performs the necessary compilation steps. Supports TeX (raw LaTeX),\n    PDF (compiled document), and SVG (vector graphics) formats.\n\n    Args:\n        filename: Output file path with extension (.tex, .pdf, or .svg)\n\n    Raises:\n        NotImplementedError: If the file extension is not supported\n\n    Note:\n        PDF and SVG compilation requires LaTeX toolchain installation.\n        The method handles temporary file creation and cleanup automatically.\n    \"\"\"\n    if filename.endswith(\"tex\"):\n        with open(filename, \"w+\") as new:\n            new.write(self.to_tex())\n    elif filename.endswith(\"pdf\"):\n        # compile temporary pdf\n        temp_file, temp_dir = self.compile_pdf()\n        # Copy a file with new name\n        shutil.copy(temp_file, filename)\n        # remove the temporal directory\n        shutil.rmtree(temp_dir)\n    elif filename.endswith(\"svg\"):\n        # compile temporary svg\n        temp_file, temp_dir = self.compile_svg()\n        # Copy a file with new name\n        shutil.copy(temp_file, filename)\n        # remove the temporal directory\n        shutil.rmtree(temp_dir)\n    else:\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/#pathpyG.visualisations._tikz.backend.TikzBackend.show","title":"<code>show</code>","text":"<p>Display the network visualization in the current environment.</p> <p>Compiles the network to SVG format and displays it either inline (in Jupyter notebooks) or opens it in the default web browser. The display method is automatically chosen based on the environment.</p> <p>The method creates temporary files for compilation and cleans them up automatically after display.</p> Environment Detection <ul> <li>Interactive (Jupyter): Displays SVG inline using IPython.display</li> <li>Non-interactive: Opens SVG file in default web browser</li> </ul> Note <p>Requires LaTeX toolchain with TikZ and dvisvgm for SVG compilation. Temporary files are automatically cleaned up after a brief delay.</p> Source code in <code>src/pathpyG/visualisations/_tikz/backend.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Display the network visualization in the current environment.\n\n    Compiles the network to SVG format and displays it either inline\n    (in Jupyter notebooks) or opens it in the default web browser.\n    The display method is automatically chosen based on the environment.\n\n    The method creates temporary files for compilation and cleans them\n    up automatically after display.\n\n    Environment Detection:\n        - **Interactive (Jupyter)**: Displays SVG inline using IPython.display\n        - **Non-interactive**: Opens SVG file in default web browser\n\n    Note:\n        Requires LaTeX toolchain with TikZ and dvisvgm for SVG compilation.\n        Temporary files are automatically cleaned up after a brief delay.\n    \"\"\"\n    # compile temporary pdf\n    temp_file, temp_dir = self.compile_svg()\n\n    if config[\"environment\"][\"interactive\"]:\n        from IPython.display import SVG, display\n\n        # open the file, read the content and display it\n        # workaround because it is not possible to embed files in vs code\n        # https://github.com/microsoft/vscode-jupyter/discussions/13769\n        with open(temp_file, \"r\") as svg_file:\n            svg = SVG(svg_file.read())\n        display(svg)\n    else:\n        # open the file in the webbrowser\n        webbrowser.open(r\"file:///\" + temp_file)\n\n    # Wait for .1 second before temp file is deleted\n    time.sleep(0.1)\n\n    # remove the temporal directory\n    shutil.rmtree(temp_dir)\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/#pathpyG.visualisations._tikz.backend.TikzBackend.to_tex","title":"<code>to_tex</code>","text":"<p>Generate complete LaTeX document with TikZ network visualization.</p> <p>Combines the network data with a LaTeX template to create a complete document ready for compilation. The template includes all necessary packages, document setup, and TikZ drawing commands.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Complete LaTeX document source code</p> Process <ol> <li>Load template - Retrieves the appropriate template for the plot type</li> <li>Generate TikZ - Converts network data to TikZ drawing commands</li> <li>Template substitution - Fills template variables with graph data</li> <li>Return final string - Complete LaTeX document ready for compilation</li> </ol> Template Variables <ul> <li><code>$classoptions</code>: LaTeX class options</li> <li><code>$width</code>, <code>$height</code>: Document dimensions</li> <li><code>$margin</code>: Margin around the drawing area</li> <li><code>$tikz</code>: TikZ drawing commands for nodes and edges</li> </ul> Note <p>The generated document is self-contained and includes all necessary TikZ packages and configuration for network visualization.</p> Source code in <code>src/pathpyG/visualisations/_tikz/backend.py</code> <pre><code>def to_tex(self) -&gt; str:\n    \"\"\"Generate complete LaTeX document with TikZ network visualization.\n\n    Combines the network data with a LaTeX template to create a complete\n    document ready for compilation. The template includes all necessary\n    packages, document setup, and TikZ drawing commands.\n\n    Returns:\n        str: Complete LaTeX document source code\n\n    Process:\n        1. **Load template** - Retrieves the appropriate template for the plot type\n        2. **Generate TikZ** - Converts network data to TikZ drawing commands\n        3. **Template substitution** - Fills template variables with graph data\n        4. **Return final string** - Complete LaTeX document ready for compilation\n\n    Template Variables:\n        - `$classoptions`: LaTeX class options\n        - `$width`, `$height`: Document dimensions\n        - `$margin`: Margin around the drawing area\n        - `$tikz`: TikZ drawing commands for nodes and edges\n\n    Note:\n        The generated document is self-contained and includes all necessary\n        TikZ packages and configuration for network visualization.\n    \"\"\"\n    # get path to the pathpy templates\n    template_dir = os.path.join(\n        os.path.dirname(os.path.dirname(__file__)),\n        os.path.normpath(\"_tikz/templates\"),\n    )\n\n    # get template files\n    with open(os.path.join(template_dir, f\"static.tex\")) as template:\n        tex_template = template.read()\n\n    # generate data\n    data = self.to_tikz()\n\n    # fill template with data\n    tex = Template(tex_template).substitute(\n        classoptions=self.config.get(\"latex_class_options\"),\n        width=unit_str_to_float(self.config.get(\"width\"), \"cm\"),  # type: ignore[arg-type]\n        height=unit_str_to_float(self.config.get(\"height\"), \"cm\"),  # type: ignore[arg-type]\n        margin=self.config.get(\"margin\"),\n        tikz=data,\n    )\n\n    return tex\n</code></pre>"},{"location":"reference/pathpyG/visualisations/_tikz/backend/#pathpyG.visualisations._tikz.backend.TikzBackend.to_tikz","title":"<code>to_tikz</code>","text":"<p>Generate TikZ drawing commands for the network visualization.</p> <p>Converts the processed graph data (nodes, edges, layout) into TikZ-specific drawing commands. Handles node positioning, styling, edge routing, and label placement according to the configured visualization parameters.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>TikZ drawing commands ready for inclusion in LaTeX document</p> Generated Elements <ul> <li>Node commands - <code>\\Vertex</code> with labels, positions, colors, and sizes</li> <li>Edge commands - <code>\\Edge</code> with styling and optional curvature</li> </ul> Note <p>The output assumes the tikz-network package is loaded in the template. Coordinates are assumed to be normalized to [0, 1] range and scaled according to the specified document dimensions.</p> Source code in <code>src/pathpyG/visualisations/_tikz/backend.py</code> <pre><code>def to_tikz(self) -&gt; str:\n    r\"\"\"Generate TikZ drawing commands for the network visualization.\n\n    Converts the processed graph data (nodes, edges, layout) into TikZ-specific\n    drawing commands. Handles node positioning, styling, edge routing, and\n    label placement according to the configured visualization parameters.\n\n    Returns:\n        str: TikZ drawing commands ready for inclusion in LaTeX document\n\n    Generated Elements:\n        - **Node commands** - `\\Vertex` with labels, positions, colors, and sizes\n        - **Edge commands** - `\\Edge` with styling and optional curvature\n\n    Note:\n        The output assumes the tikz-network package is loaded in the template.\n        Coordinates are assumed to be normalized to [0, 1] range and scaled\n        according to the specified document dimensions.\n    \"\"\"\n    tikz = \"\"\n    # generate node strings\n    if not self.data[\"nodes\"].empty:\n        node_strings: pd.Series = \"\\\\Vertex[\"\n        # show labels if specified\n        if self.show_labels and self._kind == \"static\":\n            node_strings += (\n                \"label=$\" + self.data[\"nodes\"].index.astype(str).map(self._replace_with_LaTeX_math_symbol) + \"$,\"\n            )\n            node_strings += (\n                \"fontsize=\\\\fontsize{\" + str(int(0.6 * self.data[\"nodes\"][\"size\"].mean())) + \"}{10}\\selectfont,\"\n            )\n        # Convert hex colors to rgb if necessary\n        if self.data[\"nodes\"][\"color\"].str.startswith(\"#\").all():\n            self.data[\"nodes\"][\"color\"] = self.data[\"nodes\"][\"color\"].map(hex_to_rgb)\n            node_strings += \"RGB,color={\" + self.data[\"nodes\"][\"color\"].astype(str).str.strip(\"()\") + \"},\"\n        else:\n            node_strings += \"color=\" + self.data[\"nodes\"][\"color\"] + \",\"\n        # add other options\n        node_strings += \"size=\" + (self.data[\"nodes\"][\"size\"] * 0.075).astype(str) + \",\"\n        node_strings += \"opacity=\" + self.data[\"nodes\"][\"opacity\"].astype(str) + \",style={draw opacity=\" + self.data[\"nodes\"][\"opacity\"].astype(str) + \"},\" \n        # add position\n        node_strings += (\n            \"x=\"\n            + ((self.data[\"nodes\"][\"x\"] - 0.5) * unit_str_to_float(self.config[\"width\"], \"cm\")).astype(str)\n            + \",\"\n        )\n        node_strings += (\n            \"y=\"\n            + ((self.data[\"nodes\"][\"y\"] - 0.5) * unit_str_to_float(self.config[\"height\"], \"cm\")).astype(str)\n            + \"]\"\n        )\n        # add node name\n        node_strings += (\n            \"{\"\n            + self.data[\"nodes\"].index.map(lambda x: f\"{x[0]}{x[1]}\" if isinstance(x, tuple) else str(x))\n            + \"};\\n\"\n        )\n        tikz += node_strings.str.cat()\n\n        if self.show_labels and self._kind == \"unfolded\":\n            # add labels at the starting nodes only\n            min_time = self.data[\"nodes\"][\"start\"].min()\n            offset = 0.06 * self.data[\"nodes\"][\"size\"].mean()\n            sign = 1 if self.config[\"orientation\"] in [\"down\", \"left\"] else -1\n            label_df = self.data[\"nodes\"][self.data[\"nodes\"][\"start\"] == min_time]\n            label_strings: pd.Series = \"\\\\Vertex[\"\n            label_strings += \"label=$\" + label_df.index.map(lambda x: str(x[0])) + \"$,\"\n            label_strings += \"fontsize=\\\\fontsize{\" + str(int(label_df[\"size\"].mean())) + \"}{10}\\\\selectfont,\"\n            label_strings += \"opacity=0.0,style={draw=none},\"\n            label_strings += (\n                \"x=\"\n                + (\n                    (label_df[\"x\"] - 0.5) * unit_str_to_float(self.config[\"width\"], \"cm\")\n                    + (sign * offset if self.config[\"orientation\"] in [\"left\", \"right\"] else 0)\n                ).astype(str)\n                + \",\"\n            )\n            label_strings += (\n                \"y=\"\n                + (\n                    (label_df[\"y\"] - 0.5) * unit_str_to_float(self.config[\"height\"], \"cm\")\n                    + (sign * offset if self.config[\"orientation\"] in [\"down\", \"up\"] else 0)\n                ).astype(str)\n                + \"]\"\n            )\n            label_strings += \"{\" + label_df.index.map(lambda x: \"label_\" + str(x[0])) + \"};\\n\"\n            tikz += label_strings.str.cat()\n\n            # add timestamps at the border\n            time_df = self.data[\"nodes\"].iloc[: self.data[\"nodes\"][\"end\"].max()]\n            time_df.loc[:, [\"x\", \"y\"]] = (time_df[[\"x\", \"y\"]] + time_df[[\"x\", \"y\"]].shift(-1)) / 2\n            time_df = time_df.iloc[:-1]\n            time_strings: pd.Series = \"\\\\Vertex[\"\n            time_strings += \"label=$\" + time_df[\"start\"].astype(str) + \"$,\"\n            time_strings += \"fontsize=\\\\fontsize{\" + str(int(time_df[\"size\"].mean())) + \"}{10}\\\\selectfont,\"\n            time_strings += \"opacity=0.0,style={draw=none},\"\n            time_strings += (\n                \"x=\"\n                + (\n                    (time_df[\"x\"] - 0.5) * unit_str_to_float(self.config[\"width\"], \"cm\")\n                    - (offset if self.config[\"orientation\"] in [\"up\", \"down\"] else 0)\n                ).astype(str)\n                + \",\"\n            )\n            time_strings += (\n                \"y=\"\n                + (\n                    (time_df[\"y\"] - 0.5) * unit_str_to_float(self.config[\"height\"], \"cm\")\n                    - (offset if self.config[\"orientation\"] in [\"left\", \"right\"] else 0)\n                ).astype(str)\n                + \"]\"\n            )\n            time_strings += \"{\" + time_df.index.map(lambda x: \"time_\" + str(x[0])) + \"};\\n\"\n            tikz += time_strings.str.cat()\n\n    # generate edge strings\n    if not self.data[\"edges\"].empty:\n        edge_strings: pd.Series = \"\\\\Edge[\"\n        if self.config[\"curved\"]:\n            edge_strings += \"bend=15,\"\n        if self.config[\"directed\"]:\n            edge_strings += \"Direct,\"\n        if self.data[\"edges\"][\"color\"].str.startswith(\"#\").all():\n            self.data[\"edges\"][\"color\"] = self.data[\"edges\"][\"color\"].map(hex_to_rgb)\n            edge_strings += \"RGB,color={\" + self.data[\"edges\"][\"color\"].astype(str).str.strip(\"()\") + \"},\"\n        else:\n            edge_strings += \"color=\" + self.data[\"edges\"][\"color\"] + \",\"\n        edge_strings += \"lw=\" + self.data[\"edges\"][\"size\"].astype(str) + \",\"\n        edge_strings += \"opacity=\" + self.data[\"edges\"][\"opacity\"].astype(str) + \"]\"\n        edge_strings += (\n            \"(\"\n            + self.data[\"edges\"]\n            .index.to_frame()[\"source\"]\n            .map(lambda x: f\"{x[0]}{x[1]}\" if isinstance(x, tuple) else str(x))\n            + \")(\"\n            + self.data[\"edges\"]\n            .index.to_frame()[\"target\"]\n            .map(lambda x: f\"{x[0]}{x[1]}\" if isinstance(x, tuple) else str(x))\n            + \");\\n\"\n        )\n        tikz += edge_strings.str.cat()\n\n    return tikz\n</code></pre>"},{"location":"reference/pathpyG/visualisations/plot/documentation_plots/","title":"Documentation plots","text":"In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\npp.plot(t, filename=\"d3js_temporal.html\")\n</pre> import pathpyG as pp  # Example temporal network data tedges = [     (\"a\", \"b\", 1),     (\"a\", \"b\", 2),     (\"b\", \"a\", 3),     (\"b\", \"c\", 3),     (\"d\", \"c\", 4),     (\"a\", \"b\", 4),     (\"c\", \"b\", 4),     (\"c\", \"d\", 5),     (\"b\", \"a\", 5),     (\"c\", \"b\", 6), ] t = pp.TemporalGraph.from_edge_list(tedges)  # Create temporal plot and display inline pp.plot(t, filename=\"d3js_temporal.html\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\n\n# Example network data\nedges = [\n    (\"a\", \"b\"),\n    (\"a\", \"c\"),\n    (\"b\", \"c\"),\n    (\"c\", \"d\"),\n    (\"d\", \"e\"),\n    (\"e\", \"a\"),\n]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g, filename=\"d3js_static.html\")\n</pre> import pathpyG as pp  # Example network data edges = [     (\"a\", \"b\"),     (\"a\", \"c\"),     (\"b\", \"c\"),     (\"c\", \"d\"),     (\"d\", \"e\"),     (\"e\", \"a\"), ] g = pp.Graph.from_edge_list(edges) pp.plot(g, filename=\"d3js_static.html\") In\u00a0[\u00a0]: Copied! <pre>import torch\nimport pathpyG as pp\n\n# Example undirected network data\nedge_index = torch.tensor([[0, 1, 3, 3], [1, 2, 1, 0]])\ng = pp.Graph.from_edge_index(edge_index).to_undirected()\n\n# Create static plot and display inline\npp.plot(g, backend=\"matplotlib\", filename=\"matplotlib_undirected.png\")\n</pre> import torch import pathpyG as pp  # Example undirected network data edge_index = torch.tensor([[0, 1, 3, 3], [1, 2, 1, 0]]) g = pp.Graph.from_edge_index(edge_index).to_undirected()  # Create static plot and display inline pp.plot(g, backend=\"matplotlib\", filename=\"matplotlib_undirected.png\") In\u00a0[\u00a0]: Copied! <pre>import torch\nimport pathpyG as pp\n\n# Example network data\nedges = [\n    (\"a\", \"b\"),\n    (\"a\", \"c\"),\n    (\"b\", \"d\"),\n    (\"c\", \"d\"),\n    (\"d\", \"a\"),\n]\ng = pp.Graph.from_edge_list(edges)\n\n# Add properties as attributes to the graph\ng.data[\"node_size\"] = torch.tensor([10, 15, 20, 15])\ng.data[\"edge_color\"] = torch.tensor([0, 1, 2, 1, 0])\ng.data[\"node_opacity\"] = torch.zeros(g.n)\n\n# Create static plot with custom settings and display inline\npp.plot(\n    g,\n    backend=\"tikz\",\n    node_color={\"a\": \"red\", \"b\": \"#00FF00\"},\n    edge_opacity={(\"a\", \"b\"): 0.1, (\"a\", \"c\"): 0.5, (\"b\", \"d\"): 1.0},\n    node_opacity=1.0,  # override graph attribute\n    edge_size=torch.tensor([1, 2, 3, 2, 1]),\n    filename=\"tikz_custom_properties.svg\"\n)\n</pre> import torch import pathpyG as pp  # Example network data edges = [     (\"a\", \"b\"),     (\"a\", \"c\"),     (\"b\", \"d\"),     (\"c\", \"d\"),     (\"d\", \"a\"), ] g = pp.Graph.from_edge_list(edges)  # Add properties as attributes to the graph g.data[\"node_size\"] = torch.tensor([10, 15, 20, 15]) g.data[\"edge_color\"] = torch.tensor([0, 1, 2, 1, 0]) g.data[\"node_opacity\"] = torch.zeros(g.n)  # Create static plot with custom settings and display inline pp.plot(     g,     backend=\"tikz\",     node_color={\"a\": \"red\", \"b\": \"#00FF00\"},     edge_opacity={(\"a\", \"b\"): 0.1, (\"a\", \"c\"): 0.5, (\"b\", \"d\"): 1.0},     node_opacity=1.0,  # override graph attribute     edge_size=torch.tensor([1, 2, 3, 2, 1]),     filename=\"tikz_custom_properties.svg\" ) In\u00a0[\u00a0]: Copied! <pre>import torch\nimport pathpyG as pp\n\n# Example network data\nedges = [\n    (\"b\", \"a\"),\n    (\"c\", \"a\"),\n]\nmapping = pp.IndexMap([\"a\", \"b\", \"c\", \"d\"])\ng = pp.Graph.from_edge_list(edges, mapping=mapping)\ng.data[\"node_size\"] = torch.tensor([25]*4)\npp.plot(\n    g,\n    node_size={\"d\": 50},\n    edge_size=5,\n    node_image={\n        \"a\": \"https://avatars.githubusercontent.com/u/52822508?s=48&amp;v=4\",\n        \"b\": \"https://raw.githubusercontent.com/pyg-team/pyg_sphinx_theme/master/pyg_sphinx_theme/static/img/pyg_logo.png\",\n        \"c\": \"https://pytorch-geometric.readthedocs.io/en/latest/_static/img/pytorch_logo.svg\",\n        \"d\": \"/workspaces/pathpyG/docs/img/pathpy_logo_new.png\",\n    },\n    show_labels=False,\n    filename=\"d3js_custom_node_images.html\",\n)\n</pre> import torch import pathpyG as pp  # Example network data edges = [     (\"b\", \"a\"),     (\"c\", \"a\"), ] mapping = pp.IndexMap([\"a\", \"b\", \"c\", \"d\"]) g = pp.Graph.from_edge_list(edges, mapping=mapping) g.data[\"node_size\"] = torch.tensor([25]*4) pp.plot(     g,     node_size={\"d\": 50},     edge_size=5,     node_image={         \"a\": \"https://avatars.githubusercontent.com/u/52822508?s=48&amp;v=4\",         \"b\": \"https://raw.githubusercontent.com/pyg-team/pyg_sphinx_theme/master/pyg_sphinx_theme/static/img/pyg_logo.png\",         \"c\": \"https://pytorch-geometric.readthedocs.io/en/latest/_static/img/pytorch_logo.svg\",         \"d\": \"/workspaces/pathpyG/docs/img/pathpy_logo_new.png\",     },     show_labels=False,     filename=\"d3js_custom_node_images.html\", ) In\u00a0[\u00a0]: Copied! <pre>import torch\nimport numpy as np\nimport pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\nt.data[\"node_size\"] = torch.tensor([15, 8, 19])\nt.data[\"node_color\"] = np.array([\"blue\", \"green\", \"orange\"])\nt.data[\"edge_color\"] = torch.tensor([0, 1, 2, 1])\n\n# Create temporal plot and display inline\npp.plot(\n    t,\n    backend=\"manim\",\n    node_opacity=0.5,\n    edge_size={(\"a\", \"b\", 1): 10, (\"a\", \"b\", 2): 1},\n    node_color={(\"b\", 2): \"red\", \"a\": \"purple\"}, # node_color for node 'a' is set to 'purple' from the start\n    filename=\"manim_custom_properties.gif\"\n)\n</pre> import torch import numpy as np import pathpyG as pp  # Example temporal network data tedges = [     (\"a\", \"b\", 1),     (\"a\", \"b\", 2),     (\"b\", \"a\", 3),     (\"b\", \"c\", 3), ] t = pp.TemporalGraph.from_edge_list(tedges) t.data[\"node_size\"] = torch.tensor([15, 8, 19]) t.data[\"node_color\"] = np.array([\"blue\", \"green\", \"orange\"]) t.data[\"edge_color\"] = torch.tensor([0, 1, 2, 1])  # Create temporal plot and display inline pp.plot(     t,     backend=\"manim\",     node_opacity=0.5,     edge_size={(\"a\", \"b\", 1): 10, (\"a\", \"b\", 2): 1},     node_color={(\"b\", 2): \"red\", \"a\": \"purple\"}, # node_color for node 'a' is set to 'purple' from the start     filename=\"manim_custom_properties.gif\" ) In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"random\", filename=\"tikz_random_layout.svg\")\n</pre> import pathpyG as pp from torch_geometric import seed_everything seed_everything(42)  g = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25) pp.plot(g, backend=\"tikz\", layout=\"random\", filename=\"tikz_random_layout.svg\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"circle\", filename=\"tikz_circle_layout.svg\")\n</pre> import pathpyG as pp from torch_geometric import seed_everything seed_everything(42)  g = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25) pp.plot(g, backend=\"tikz\", layout=\"circle\", filename=\"tikz_circle_layout.svg\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"shell\", filename=\"tikz_shell_layout.svg\")\n</pre> import pathpyG as pp from torch_geometric import seed_everything seed_everything(42)  g = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25) pp.plot(g, backend=\"tikz\", layout=\"shell\", filename=\"tikz_shell_layout.svg\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"spectral\", filename=\"tikz_spectral_layout.svg\")\n</pre> import pathpyG as pp from torch_geometric import seed_everything seed_everything(42)  g = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25) pp.plot(g, backend=\"tikz\", layout=\"spectral\", filename=\"tikz_spectral_layout.svg\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"kk\", filename=\"tikz_kk_layout.svg\")\n</pre> import pathpyG as pp from torch_geometric import seed_everything seed_everything(42)  g = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25) pp.plot(g, backend=\"tikz\", layout=\"kk\", filename=\"tikz_kk_layout.svg\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"spring\", filename=\"tikz_spring_layout.svg\")\n</pre> import pathpyG as pp from torch_geometric import seed_everything seed_everything(42)  g = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25) pp.plot(g, backend=\"tikz\", layout=\"spring\", filename=\"tikz_spring_layout.svg\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"fa2\", filename=\"tikz_fa2_layout.svg\")\n</pre> import pathpyG as pp from torch_geometric import seed_everything seed_everything(42)  g = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25) pp.plot(g, backend=\"tikz\", layout=\"fa2\", filename=\"tikz_fa2_layout.svg\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\nfrom torch_geometric import seed_everything\nseed_everything(42)\n\ng = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25)\npp.plot(g, backend=\"tikz\", layout=\"grid\", filename=\"tikz_grid_layout.svg\")\n</pre> import pathpyG as pp from torch_geometric import seed_everything seed_everything(42)  g = pp.algorithms.generative_models.watts_strogatz(30, 2, 0.25) pp.plot(g, backend=\"tikz\", layout=\"grid\", filename=\"tikz_grid_layout.svg\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\n\ng = pp.Graph.from_edge_list([(\"a\", \"b\"), (\"a\", \"c\"), (\"b\", \"d\"), (\"c\", \"d\"), (\"d\", \"a\")])\n# Provide custom x and y coordinates for a layout\nlayout = {\n    \"a\": (0, 0),\n    \"b\": (1, 0),\n    \"c\": (0, 1),\n    \"d\": (1, 1)\n}\npp.plot(g, backend=\"tikz\", layout=layout, filename=\"tikz_layout.svg\")\n</pre> import pathpyG as pp  g = pp.Graph.from_edge_list([(\"a\", \"b\"), (\"a\", \"c\"), (\"b\", \"d\"), (\"c\", \"d\"), (\"d\", \"a\")]) # Provide custom x and y coordinates for a layout layout = {     \"a\": (0, 0),     \"b\": (1, 0),     \"c\": (0, 1),     \"d\": (1, 1) } pp.plot(g, backend=\"tikz\", layout=layout, filename=\"tikz_layout.svg\") In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\npp.plot(t, backend=\"manim\", layout_window_size=2, layout=\"fa2\", filename=\"manim_temporal_fa2.gif\")\n</pre> import pathpyG as pp  # Example temporal network data tedges = [     (\"a\", \"b\", 1),     (\"a\", \"b\", 2),     (\"b\", \"a\", 3),     (\"b\", \"c\", 3),     (\"d\", \"c\", 4),     (\"a\", \"b\", 4),     (\"c\", \"b\", 4),     (\"c\", \"d\", 5),     (\"b\", \"a\", 5),     (\"c\", \"b\", 6), ] t = pp.TemporalGraph.from_edge_list(tedges)  # Create temporal plot and display inline pp.plot(t, backend=\"manim\", layout_window_size=2, layout=\"fa2\", filename=\"manim_temporal_fa2.gif\") In\u00a0[3]: Copied! <pre>import pathpyG as pp\n\n# Example network data\ng = pp.Graph.from_edge_list([(\"a\", \"b\"), (\"a\", \"c\")])\n\n# Create network plot and display inline\npp.plot(g, node={\"opacity\": 0.2}, filename=\"d3js_node_opacity.html\")\n</pre> import pathpyG as pp  # Example network data g = pp.Graph.from_edge_list([(\"a\", \"b\"), (\"a\", \"c\")])  # Create network plot and display inline pp.plot(g, node={\"opacity\": 0.2}, filename=\"d3js_node_opacity.html\") Out[3]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f2e583ee050&gt;</pre> In\u00a0[2]: Copied! <pre>import pathpyG as pp\n\n# Simple network visualization\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g, backend=\"tikz\", filename=\"tikz_init_basic.svg\")\n</pre> import pathpyG as pp  # Simple network visualization edges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")] g = pp.Graph.from_edge_list(edges) pp.plot(g, backend=\"tikz\", filename=\"tikz_init_basic.svg\") Out[2]: <pre>&lt;pathpyG.visualisations._tikz.backend.TikzBackend at 0x7fc18b7a5120&gt;</pre> In\u00a0[4]: Copied! <pre>import pathpyG as pp\nimport torch\n\n# Graph with custom styling\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"D\"), (\"D\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\ng.data[\"node_size\"] = torch.tensor([15, 20, 25, 20])\n\npp.plot(\n    g,\n    backend=\"tikz\",\n    node_color={\"A\": \"red\", \"B\": \"#00FF00\"},\n    edge_opacity=0.7,\n    curvature=0.2,\n    width=\"8cm\",\n    height=\"6cm\",\n    filename=\"tikz_init_advanced.svg\",\n    margin=0.25\n)\n</pre> import pathpyG as pp import torch  # Graph with custom styling edges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"D\"), (\"D\", \"A\")] g = pp.Graph.from_edge_list(edges) g.data[\"node_size\"] = torch.tensor([15, 20, 25, 20])  pp.plot(     g,     backend=\"tikz\",     node_color={\"A\": \"red\", \"B\": \"#00FF00\"},     edge_opacity=0.7,     curvature=0.2,     width=\"8cm\",     height=\"6cm\",     filename=\"tikz_init_advanced.svg\",     margin=0.25 ) Out[4]: <pre>&lt;pathpyG.visualisations._tikz.backend.TikzBackend at 0x7fbfd7f51bd0&gt;</pre> In\u00a0[5]: Copied! <pre># The backend is typically used via pp.plot()\nimport pathpyG as pp\ng = pp.Graph.from_edge_list([(\"A\", \"B\"), (\"B\", \"C\")])\npp.plot(g, backend=\"tikz\", filename=\"tikz_backend_example.svg\")\n</pre> # The backend is typically used via pp.plot() import pathpyG as pp g = pp.Graph.from_edge_list([(\"A\", \"B\"), (\"B\", \"C\")]) pp.plot(g, backend=\"tikz\", filename=\"tikz_backend_example.svg\") Out[5]: <pre>&lt;pathpyG.visualisations._tikz.backend.TikzBackend at 0x7fbfd7ffe650&gt;</pre> In\u00a0[6]: Copied! <pre>import pathpyG as pp\n\n# Static network\ng = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')])\npp.plot(g, filename='network.png')\n</pre> import pathpyG as pp  # Static network g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c')]) pp.plot(g, filename='network.png') Out[6]: <pre>&lt;pathpyG.visualisations._matplotlib.backend.MatplotlibBackend at 0x7fbfd7f53250&gt;</pre> In\u00a0[8]: Copied! <pre>import pathpyG as pp\ntg = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('a', 'c', 3)])\npp.plot(tg, filename='temporal_network.html')\n</pre> import pathpyG as pp tg = pp.TemporalGraph.from_edge_list([('a', 'b', 1), ('b', 'c', 2), ('a', 'c', 3)]) pp.plot(tg, filename='temporal_network.html') Out[8]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7fbfd7fffa00&gt;</pre> In\u00a0[9]: Copied! <pre>import pathpyG as pp\ngraph = pp.Graph.from_edge_list([[\"a\", \"b\"], [\"b\", \"c\"], [\"a\", \"c\"]])\npp.plot(graph, kind=\"static\", filename=\"graph.png\")\n</pre> import pathpyG as pp graph = pp.Graph.from_edge_list([[\"a\", \"b\"], [\"b\", \"c\"], [\"a\", \"c\"]]) pp.plot(graph, kind=\"static\", filename=\"graph.png\") Out[9]: <pre>&lt;pathpyG.visualisations._matplotlib.backend.MatplotlibBackend at 0x7fbfd7e97550&gt;</pre> In\u00a0[11]: Copied! <pre>from pathpyG import Graph\nfrom pathpyG.visualisations import layout\n    \ng = Graph.from_edge_list([('a', 'b'), ('b', 'c')])\npositions = layout(g, layout='spring', k=0.5)\nprint(positions)\n</pre> from pathpyG import Graph from pathpyG.visualisations import layout      g = Graph.from_edge_list([('a', 'b'), ('b', 'c')]) positions = layout(g, layout='spring', k=0.5) print(positions) <pre>{'a': array([ 0.61899711, -1.        ]), 'b': array([-0.00132282,  0.00213747]), 'c': array([-0.61767429,  0.99786253])}\n</pre> In\u00a0[12]: Copied! <pre>import pathpyG as pp\n\n# Simple network visualization\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g, backend=\"matplotlib\", filename=\"network.png\")\n</pre> import pathpyG as pp  # Simple network visualization edges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")] g = pp.Graph.from_edge_list(edges) pp.plot(g, backend=\"matplotlib\", filename=\"network.png\") Out[12]: <pre>&lt;pathpyG.visualisations._matplotlib.backend.MatplotlibBackend at 0x7fbfd54dcc40&gt;</pre> In\u00a0[15]: Copied! <pre>import pathpyG as pp\n\n# Simple temporal network animation\ntedges = [(\"a\", \"b\", 1), (\"b\", \"c\", 2), (\"c\", \"a\", 3)]\ntg = pp.TemporalGraph.from_edge_list(tedges)\npp.plot(tg, backend=\"manim\", filename=\"temporal_network.gif\")\n</pre> import pathpyG as pp  # Simple temporal network animation tedges = [(\"a\", \"b\", 1), (\"b\", \"c\", 2), (\"c\", \"a\", 3)] tg = pp.TemporalGraph.from_edge_list(tedges) pp.plot(tg, backend=\"manim\", filename=\"temporal_network.gif\") <pre>                                                                                          \r</pre> Out[15]: <pre>&lt;pathpyG.visualisations._manim.backend.ManimBackend at 0x7fbfc4d47cd0&gt;</pre> In\u00a0[14]: Copied! <pre>import pathpyG as pp\n\n# Temporal network with evolving properties\ntedges = [\n    (\"a\", \"b\", 1), (\"b\", \"c\", 1),\n    (\"c\", \"d\", 2), (\"d\", \"a\", 2), \n    (\"a\", \"c\", 3), (\"b\", \"d\", 3)\n]\ntg = pp.TemporalGraph.from_edge_list(tedges)\n\npp.plot(\n    tg,\n    backend=\"manim\",\n    delta=2000,                    # 2 seconds per timestep\n    node_size={(\"a\", 1): 20, (\"b\", 2): 7},\n    node_color=[\"red\", \"blue\", \"green\", \"orange\"],\n    edge_opacity=0.7,\n    edge_color={(\"a\", \"b\", 1): \"purple\", (\"c\", \"d\", 2): \"orange\"},\n    filename=\"dynamic_network.mp4\"\n)\n</pre> import pathpyG as pp  # Temporal network with evolving properties tedges = [     (\"a\", \"b\", 1), (\"b\", \"c\", 1),     (\"c\", \"d\", 2), (\"d\", \"a\", 2),      (\"a\", \"c\", 3), (\"b\", \"d\", 3) ] tg = pp.TemporalGraph.from_edge_list(tedges)  pp.plot(     tg,     backend=\"manim\",     delta=2000,                    # 2 seconds per timestep     node_size={(\"a\", 1): 20, (\"b\", 2): 7},     node_color=[\"red\", \"blue\", \"green\", \"orange\"],     edge_opacity=0.7,     edge_color={(\"a\", \"b\", 1): \"purple\", (\"c\", \"d\", 2): \"orange\"},     filename=\"dynamic_network.mp4\" ) <pre>                                                                                             \r</pre> Out[14]: <pre>&lt;pathpyG.visualisations._manim.backend.ManimBackend at 0x7fbfc4e58850&gt;</pre> In\u00a0[16]: Copied! <pre>import pathpyG as pp\n\n# Simple network visualization\nedges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")]\ng = pp.Graph.from_edge_list(edges)\npp.plot(g, filename=\"simple_network.html\")  # Uses d3.js backend by default\n</pre> import pathpyG as pp  # Simple network visualization edges = [(\"A\", \"B\"), (\"B\", \"C\"), (\"C\", \"A\")] g = pp.Graph.from_edge_list(edges) pp.plot(g, filename=\"simple_network.html\")  # Uses d3.js backend by default Out[16]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7fbfd7d007f0&gt;</pre> In\u00a0[1]: Copied! <pre>import torch\nimport pathpyG as pp\n\n# Temporal network with evolving properties\ntedges = [\n    (\"a\", \"b\", 1), (\"b\", \"c\", 1),\n    (\"c\", \"d\", 2), (\"d\", \"a\", 2), \n    (\"a\", \"c\", 3), (\"b\", \"d\", 3)\n]\ntg = pp.TemporalGraph.from_edge_list(tedges)\ntg.data[\"edge_color\"] = torch.arange(tg.m)  # Assign a unique color index to each edge\n\npp.plot(\n    tg,\n    delta=750,  # 0.75 seconds per timestep\n    node_size={(\"a\", 1): 20, (\"b\", 2): 7},\n    node_color=[\"red\", \"blue\", \"green\", \"orange\"],\n    edge_opacity=0.7,\n    # filename=\"dynamic_network.html\"\n)\n</pre> import torch import pathpyG as pp  # Temporal network with evolving properties tedges = [     (\"a\", \"b\", 1), (\"b\", \"c\", 1),     (\"c\", \"d\", 2), (\"d\", \"a\", 2),      (\"a\", \"c\", 3), (\"b\", \"d\", 3) ] tg = pp.TemporalGraph.from_edge_list(tedges) tg.data[\"edge_color\"] = torch.arange(tg.m)  # Assign a unique color index to each edge  pp.plot(     tg,     delta=750,  # 0.75 seconds per timestep     node_size={(\"a\", 1): 20, (\"b\", 2): 7},     node_color=[\"red\", \"blue\", \"green\", \"orange\"],     edge_opacity=0.7,     # filename=\"dynamic_network.html\" ) Out[1]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f25676f24d0&gt;</pre> In\u00a0[2]: Copied! <pre>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\nnode_color = {\"a\": \"red\", (\"a\", 2): \"darkred\"}\nedge_color = {(\"a\", \"b\", 2): \"blue\"}\npp.plot(t, backend=\"tikz\", kind=\"unfolded\", node_size=12, node_color=node_color, edge_color=edge_color, filename=\"unfolded_graph.svg\")\n</pre> import pathpyG as pp  # Example temporal network data tedges = [     (\"a\", \"b\", 1),     (\"a\", \"b\", 2),     (\"b\", \"a\", 3),     (\"b\", \"c\", 3),     (\"d\", \"c\", 4),     (\"a\", \"b\", 4),     (\"c\", \"b\", 4),     (\"c\", \"d\", 5),     (\"b\", \"a\", 5),     (\"c\", \"b\", 6), ] t = pp.TemporalGraph.from_edge_list(tedges)  # Create temporal plot and display inline node_color = {\"a\": \"red\", (\"a\", 2): \"darkred\"} edge_color = {(\"a\", \"b\", 2): \"blue\"} pp.plot(t, backend=\"tikz\", kind=\"unfolded\", node_size=12, node_color=node_color, edge_color=edge_color, filename=\"unfolded_graph.svg\") Out[2]: <pre>&lt;pathpyG.visualisations._tikz.backend.TikzBackend at 0x7f351508ea10&gt;</pre> In\u00a0[1]: Copied! <pre>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\nnode_color = {\"a\": \"red\", (\"a\", 2): \"darkred\"}\nedge_color = {(\"a\", \"b\", 2): \"blue\"}\npp.plot(t, backend=\"tikz\", kind=\"unfolded\", node_size=12, node_color=node_color, edge_color=edge_color, orientation=\"right\", filename=\"unfolded_graph_tikz.svg\")\n</pre> import pathpyG as pp  # Example temporal network data tedges = [     (\"a\", \"b\", 1),     (\"a\", \"b\", 2),     (\"b\", \"a\", 3),     (\"a\", \"b\", 4),     (\"c\", \"b\", 4),     (\"c\", \"d\", 5),     (\"b\", \"a\", 5),     (\"c\", \"b\", 6), ] t = pp.TemporalGraph.from_edge_list(tedges)  # Create temporal plot and display inline node_color = {\"a\": \"red\", (\"a\", 2): \"darkred\"} edge_color = {(\"a\", \"b\", 2): \"blue\"} pp.plot(t, backend=\"tikz\", kind=\"unfolded\", node_size=12, node_color=node_color, edge_color=edge_color, orientation=\"right\", filename=\"unfolded_graph_tikz.svg\") Out[1]: <pre>&lt;pathpyG.visualisations._tikz.backend.TikzBackend at 0x7f9052bfa770&gt;</pre> In\u00a0[9]: Copied! <pre>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\nnode_opacity = {(node_id, time): 0.1 for node_id in t.nodes for time in range(t.data.time.max().item() + 2)}\nnode_opacity.update({(source_id, time): 1.0 for source_id, target_id, time in t.temporal_edges})\nnode_opacity.update({(target_id, time+1): 1.0 for source_id, target_id, time in t.temporal_edges})\npp.plot(t, backend=\"matplotlib\", kind=\"unfolded\", node_size=12, node_opacity=node_opacity, filename=\"unfolded_graph_matplotlib.png\")\n</pre> import pathpyG as pp  # Example temporal network data tedges = [     (\"a\", \"b\", 1),     (\"a\", \"b\", 2),     (\"b\", \"a\", 3),     (\"b\", \"c\", 3),     (\"d\", \"c\", 4),     (\"a\", \"b\", 4),     (\"c\", \"b\", 4), ] t = pp.TemporalGraph.from_edge_list(tedges)  # Create temporal plot and display inline node_opacity = {(node_id, time): 0.1 for node_id in t.nodes for time in range(t.data.time.max().item() + 2)} node_opacity.update({(source_id, time): 1.0 for source_id, target_id, time in t.temporal_edges}) node_opacity.update({(target_id, time+1): 1.0 for source_id, target_id, time in t.temporal_edges}) pp.plot(t, backend=\"matplotlib\", kind=\"unfolded\", node_size=12, node_opacity=node_opacity, filename=\"unfolded_graph_matplotlib.png\") Out[9]: <pre>&lt;pathpyG.visualisations._matplotlib.backend.MatplotlibBackend at 0x7f35150e76d0&gt;</pre> In\u00a0[13]: Copied! <pre>import pathpyG as pp\n\n# Example temporal network data\ntedges = [\n    (\"a\", \"d\", 1),\n    (\"b\", \"c\", 2),\n    (\"b\", \"c\", 3),\n    (\"b\", \"a\", 3),\n    (\"d\", \"b\", 4),\n\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\n\n# Create temporal plot and display inline\npp.plot(t, kind=\"unfolded\", show_labels=False, filename=\"unfolded_graph_d3js.html\")\n</pre> import pathpyG as pp  # Example temporal network data tedges = [     (\"a\", \"d\", 1),     (\"b\", \"c\", 2),     (\"b\", \"c\", 3),     (\"b\", \"a\", 3),     (\"d\", \"b\", 4),  ] t = pp.TemporalGraph.from_edge_list(tedges)  # Create temporal plot and display inline pp.plot(t, kind=\"unfolded\", show_labels=False, filename=\"unfolded_graph_d3js.html\") Out[13]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f33517d62f0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"reference/pathpyG/visualisations/plot/documentation_plots/#layouts","title":"Layouts\u00b6","text":""},{"location":"reference/pathpyG/visualisations/plot/documentation_plots/#time-unfolded-layout","title":"Time-Unfolded Layout\u00b6","text":""},{"location":"tutorial/basic_concepts/","title":"Basic Concepts","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nimport torch_geometric as pyG\nfrom torch_geometric.data import Data\nimport pandas as pd\n\nimport pathpyG as pp\n</pre> import torch import torch_geometric as pyG from torch_geometric.data import Data import pandas as pd  import pathpyG as pp <pre>/opt/conda/lib/python3.11/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n  return torch._C._show_config()\n</pre> In\u00a0[2]: Copied! <pre>d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]]))\ng = pp.Graph(d)\nprint(g)\n</pre> d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]])) g = pp.Graph(d) print(g) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>If we do not need additional node or edge attributes, we can use the class function <code>Graph.from_edge_index</code> to directly create a graph based on an edge index:</p> In\u00a0[3]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]))\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]])) print(g) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>We may want to inlude isolated nodes that do not have an edge. We can do so by passing a <code>num_nodes</code> parameter. The following graph thus contains a fourth node (which we could name as <code>d</code>) that is not connected to any of the other nodes.</p> In\u00a0[4]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes=4)\nprint(g)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes=4) print(g) <pre>Directed graph with 4 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>In both cases, the <code>Graph</code> instance has a property <code>g.data</code> that stores a <code>pyG</code> <code>Data</code> object that includes the edge index as well as any further node-, edge- or graph-level attributes.</p> In\u00a0[5]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 3], num_nodes=4, node_sequence=[4, 1])\n</pre> In\u00a0[6]: Copied! <pre>print(g.data.edge_index)\n</pre> print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1],\n           [2, 1, 2]], sparse_size=(4, 4), nnz=3, sort_order=row)\n</pre> <p>Note that the <code>edge_index</code> is actually of type <code>pyG.EdgeIndex</code>, which is a subclass of <code>torch.Tensor</code>. Any tensor passed as an edge index in the constructor of <code>Graph</code> will automatically be converted to an <code>EdgeIndex</code> instance, as this internally allows us to provide efficient edge traveral routines based on sparse matrix operations. To support this, the edge index will be automatically sorted by row when the <code>Graph</code> object is created. To avoid this additional sort operation, you can pass an already sorted <code>EdgeIndex</code> object in the <code>Data</code> object in the constructor or using the <code>from_edge_index</code> class function.</p> <p>We can use the generators <code>nodes</code> and <code>edges</code> to iterate through the nodes and edges of a graph as follows:</p> In\u00a0[5]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>0\n1\n2\n3\n(0, 2)\n(0, 1)\n(1, 2)\n</pre> <p>While the index-based representation of nodes allows for efficient tensor-based operations, it is often convenient to use string identifiers to refer to nodes. To simplify the handling of graphs with such node identifiers, <code>pathpyG</code> provides a class <code>IndexMap</code> that transparently maps string identifiers to integer indices. For our small example graph, we can create an <code>IndexMap</code> that associates node indices with string IDs. For our example, we can create a mapping as follows:</p> In\u00a0[6]: Copied! <pre>m = pp.IndexMap(['a', 'b', 'c', 'd'])\nprint(m)\n</pre> m = pp.IndexMap(['a', 'b', 'c', 'd']) print(m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n</pre> <p>We can use the functions <code>IndexMap.to_id</code> or <code>IndexMap.to_idx</code> to map a node to an index or an ID:</p> In\u00a0[10]: Copied! <pre>print(m.to_id(0))\n</pre> print(m.to_id(0)) <pre>a\n</pre> In\u00a0[11]: Copied! <pre>print(m.to_idx('b'))\n</pre> print(m.to_idx('b')) <pre>1\n</pre> <p><code>pathpyG</code> can apply this mapping transparently for the user. For this, we can add a mapping to a <code>Graph</code> object, either by passing it in the constructor or by setting the <code>mapping</code> attribute of an existing <code>Graph</code> instance.</p> In\u00a0[12]: Copied! <pre>g.mapping = m\n</pre> g.mapping = m <p>If we now iterate through the nodes and edges of the graph, we get:</p> In\u00a0[7]: Copied! <pre>for v in g.nodes:\n    print(v)\n\nfor e in g.edges:\n    print(e)\n</pre> for v in g.nodes:     print(v)  for e in g.edges:     print(e) <pre>0\n1\n2\n3\n(0, 2)\n(0, 1)\n(1, 2)\n</pre> <p>We can also pass an <code>IndexMap</code> object to the constructor of the <code>Graph</code> class. This transparently applies the mapping in all future operations on this graph instance.</p> In\u00a0[8]: Copied! <pre>g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes = 4, mapping=m)\n</pre> g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes = 4, mapping=m) <p>Above, we have created a graph based on an edge index tensor and we then additionally applied a mapping that we manually defined. We often have data in the form on an edge list, where edges are given as tuples of non-numeric node identifiers. The class function <code>Graph.from_edge_list</code> simplifies the construction of a <code>Graph</code> from such edge lists. It automatically creates an internal integer-based representation of the edge index along with the associated <code>IndexMap</code>, where integer node indices are based on the lexicographic order of node IDs.</p> In\u00a0[9]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')])\nprint(g)\nprint(g.data.edge_index)\nprint(g.mapping)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')]) print(g) print(g.data.edge_index) print(g.mapping) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 0, 1],\n           [1, 2, 2]], sparse_size=(3, 3), nnz=3, sort_order=row)\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n</pre> <p>We can also pass a custom index mapping, e.g. mapping node <code>c</code> to idex 1 and node <code>b</code> to index 2 (thus deviating from a lexicographic order):</p> In\u00a0[11]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('a','c'), ('b','c')], mapping = pp.IndexMap(['a', 'c', 'b']))\nprint(g.data.edge_index)\nprint(g.mapping)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('a','c'), ('b','c')], mapping = pp.IndexMap(['a', 'c', 'b'])) print(g.data.edge_index) print(g.mapping) <pre>EdgeIndex([[0, 0, 2],\n           [2, 1, 1]], sparse_size=(3, 3), nnz=3, sort_order=row)\na -&gt; 0\nc -&gt; 1\nb -&gt; 2\n\n</pre> In\u00a0[12]: Copied! <pre>g.get_successors(0)\n</pre> g.get_successors(0) Out[12]: <pre>tensor([2, 1])</pre> In\u00a0[23]: Copied! <pre>g.get_predecessors(0)\n</pre> g.get_predecessors(0) Out[23]: <pre>tensor([], dtype=torch.int64)</pre> <p>Note that, even if a mapping is defined, the <code>get_successors</code> and <code>get_predecessors</code> functions always return a tensor with node indices, rather than node IDs. This is useful to support fast tensor-based operations on the list of successors and predecessors. We can however manually map node indices using the <code>IndexMap</code> object stored in the <code>mapping</code> attribute.</p> <p>If we instead want to traverse graphs based on string node IDs, we can use the <code>successors</code> and <code>predecessors</code> generators of the <code>Graph</code> object, which -- if a mapping is defined - yield the string IDs of successor or predecessor nodes for a given node (also identified by its string identifier).</p> In\u00a0[24]: Copied! <pre>for v in g.successors('a'):\n    print(v)\n</pre> for v in g.successors('a'):     print(v) <pre>b\nc\n</pre> In\u00a0[25]: Copied! <pre>for v in g.predecessors('c'):\n    print(v)\n</pre> for v in g.predecessors('c'):     print(v) <pre>a\nb\n</pre> <p>To check (in constant time) whether an edge exists in the graph, we can call the <code>is_edge</code> function:</p> In\u00a0[26]: Copied! <pre>g.is_edge('a', 'b')\n</pre> g.is_edge('a', 'b') Out[26]: <pre>True</pre> <p>Alternatively, we can use the following function to check (in constant time) whether node <code>b</code> is a successor of <code>a</code></p> In\u00a0[27]: Copied! <pre>'b' in g.successors('a')\n</pre> 'b' in g.successors('a') Out[27]: <pre>True</pre> <p>By default, graph objects in <code>pathpyG</code> are directed, i.e. for the graph above, the edge <code>(b,a)</code> does not exist, which we can verify as follows:</p> In\u00a0[28]: Copied! <pre>print('a' in g.successors('b'))\nprint(g.is_edge('b', 'a'))\n</pre> print('a' in g.successors('b')) print(g.is_edge('b', 'a')) <pre>False\nFalse\n</pre> <p>To calculate (directed) in- and out-degrees of nodes, we can use the properties <code>in_degrees</code> and <code>out_degrees</code>, which return a dictionary that maps node IDs to their degrees:</p> In\u00a0[13]: Copied! <pre>for v in g.nodes:\n    print(f\"{v} -&gt; {g.in_degrees[v]}\")\n</pre> for v in g.nodes:     print(f\"{v} -&gt; {g.in_degrees[v]}\") <pre>a -&gt; 0\nc -&gt; 2\nb -&gt; 1\n</pre> <p>The <code>in_degree</code> and <code>out_degree</code> properties are shortcuts to a general <code>degree</code> function that can be used to calculate (weighted) in- and outdegrees.</p> In\u00a0[15]: Copied! <pre>g.degrees(mode='in')\n</pre> g.degrees(mode='in') Out[15]: <pre>{'a': 0, 'c': 2, 'b': 1}</pre> In\u00a0[16]: Copied! <pre>g.degrees(mode='out')\n</pre> g.degrees(mode='out') Out[16]: <pre>{'a': 2, 'c': 0, 'b': 1}</pre> <p>Degrees can be alternatively returned as torch.tensors.</p> In\u00a0[17]: Copied! <pre>g.degrees(mode='in', return_tensor=True)\n</pre> g.degrees(mode='in', return_tensor=True) Out[17]: <pre>tensor([0, 2, 1], dtype=torch.int32)</pre> <p>We can also use arbitrary numerical edge attributes that will be used for a weighted (in- or out) degree calculation.</p> In\u00a0[18]: Copied! <pre>g.data.edge_weight=torch.tensor([1.0, 2.0, 3.0])\n</pre> g.data.edge_weight=torch.tensor([1.0, 2.0, 3.0]) In\u00a0[19]: Copied! <pre>g.degrees(mode='in', edge_attr='edge_weight', return_tensor=True)\n</pre> g.degrees(mode='in', edge_attr='edge_weight', return_tensor=True) Out[19]: <pre>tensor([0., 5., 1.])</pre> In\u00a0[20]: Copied! <pre>g.degrees(mode='out', edge_attr='edge_weight', return_tensor=True)\n</pre> g.degrees(mode='out', edge_attr='edge_weight', return_tensor=True) Out[20]: <pre>tensor([3., 0., 3.])</pre> <p>Importantly, irrespective of how we have generated the graph object, the actual node and edge data are always stored as a <code>pyG</code> data object. This allows us to use the full power of <code>torch</code> and <code>pyG</code>, including the application of transforms, splits, or any easy migration between CPU and GPU-based computation.</p> In\u00a0[21]: Copied! <pre>g.data\n</pre> g.data Out[21]: <pre>Data(edge_index=[2, 3], num_nodes=3, node_sequence=[3, 1], edge_weight=[3])</pre> <p>In general, <code>pathpyG</code> handles device placement (i.e. if a tensor should be placed on CPU or GPU memory) similar to <code>pytorch</code>. By default, all tensors are created on the CPU, as we can see below:</p> In\u00a0[36]: Copied! <pre>g.data.is_cuda\n</pre> g.data.is_cuda Out[36]: <pre>False</pre> <p>If we instead want to create a graph on the GPU, we can specify the device during graph creation.</p> In\u00a0[16]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')], device='cuda')\ng.data.is_cuda\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')], device='cuda') g.data.is_cuda <pre>\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[16], line 1\n----&gt; 1 g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')], device='cuda')\n      2 g.data.is_cuda\n\nFile /workspaces/pathpyG/src/pathpyG/core/graph.py:179, in Graph.from_edge_list(edge_list, is_undirected, mapping, device)\n    174     mapping = IndexMap(node_ids)\n    176 num_nodes = mapping.num_ids()\n    178 edge_index = EdgeIndex(\n--&gt; 179     mapping.to_idxs(edge_list, device=device).T.contiguous(),\n    180     sparse_size=(num_nodes, num_nodes),\n    181     is_undirected=is_undirected,\n    182 )\n    183 return Graph(Data(edge_index=edge_index, num_nodes=num_nodes), mapping=mapping)\n\nFile /workspaces/pathpyG/src/pathpyG/core/index_map.py:361, in IndexMap.to_idxs(self, nodes, device)\n    359 shape = nodes.shape\n    360 if self.id_shape == (-1,):\n--&gt; 361     return torch.tensor([self.id_to_idx[node] for node in nodes.flatten()], device=device).reshape(shape)\n    362 else:\n    363     return torch.tensor([self.id_to_idx[tuple(node)] for node in nodes.reshape(self.id_shape)], device=device).reshape(\n    364         shape[: -len(self.id_shape) + 1]\n    365     )\n\nFile /opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:314, in _lazy_init()\n    312 if \"CUDA_MODULE_LOADING\" not in os.environ:\n    313     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n--&gt; 314 torch._C._cuda_init()\n    315 # Some of the queued calls may reentrantly call _lazy_init();\n    316 # we need to just return without initializing in that case.\n    317 # However, we must not let any *other* threads in!\n    318 _tls.is_initializing = True\n\nRuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found</pre> <p>We can move a graph that is stored on the GPU back to the CPU using the familiar <code>to</code> function:</p> In\u00a0[38]: Copied! <pre>g = g.to('cpu')\n</pre> g = g.to('cpu') In\u00a0[39]: Copied! <pre>g.data['node_class'] = torch.tensor([[0], [0], [1]])\ng.data['edge_weight'] = torch.tensor([[1], [2], [3]])\ng.data['feature'] = torch.tensor([3, 2])\n</pre> g.data['node_class'] = torch.tensor([[0], [0], [1]]) g.data['edge_weight'] = torch.tensor([[1], [2], [3]]) g.data['feature'] = torch.tensor([3, 2]) <p>Once we have added attributes to nodes, edges, or the graph, those attributes, along with their type and shape will be shown when you print a string representation of the graph object:</p> In\u00a0[40]: Copied! <pre>print(g)\n</pre> print(g) <pre>Directed graph with 3 nodes and 3 edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\"},\n    'Graph Attributes': {'feature': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {'node_class': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\"}}\n</pre> <p>To simplify access to attribute values, the <code>Graph</code> class provides getter and setter functions that allow to access attribute values based on node identifiers. To access the feature <code>node_feature</code> of node <code>a</code>, we can write:</p> In\u00a0[41]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[41]: <pre>tensor([0])</pre> <p>To access the weight of edge <code>(a, b)</code> we can write:</p> In\u00a0[42]: Copied! <pre>g['edge_weight', 'a', 'b']\n</pre> g['edge_weight', 'a', 'b'] Out[42]: <pre>tensor([1])</pre> <p>And finally, graph-based attributes can accessed as follows:</p> In\u00a0[43]: Copied! <pre>g['feature']\n</pre> g['feature'] Out[43]: <pre>tensor([3, 2])</pre> <p>We can also use the setter functions to change attributes:</p> In\u00a0[44]: Copied! <pre>g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda')\n</pre> g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda') <pre>\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[44], line 1\n----&gt; 1 g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda')\n\nFile /opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:314, in _lazy_init()\n    312 if \"CUDA_MODULE_LOADING\" not in os.environ:\n    313     os.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"\n--&gt; 314 torch._C._cuda_init()\n    315 # Some of the queued calls may reentrantly call _lazy_init();\n    316 # we need to just return without initializing in that case.\n    317 # However, we must not let any *other* threads in!\n    318 _tls.is_initializing = True\n\nRuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found</pre> In\u00a0[45]: Copied! <pre>g['node_class', 'a']\n</pre> g['node_class', 'a'] Out[45]: <pre>tensor([0])</pre> <p>To create sparse adjacency matrix representations of graphs, we can use the following function:</p> In\u00a0[46]: Copied! <pre>print(g.sparse_adj_matrix())\n</pre> print(g.sparse_adj_matrix()) <pre>&lt;COOrdinate sparse matrix of dtype 'float32'\n\twith 3 stored elements and shape (3, 3)&gt;\n  Coords\tValues\n  (0, 2)\t1.0\n  (0, 1)\t1.0\n  (2, 1)\t1.0\n</pre> <p>This returns a <code>scipy.sparse.coo_matrix</code> object, which can be turned into a dense <code>numpy</code> matrix as follows:</p> In\u00a0[47]: Copied! <pre>print(g.sparse_adj_matrix().todense())\n</pre> print(g.sparse_adj_matrix().todense()) <pre>[[0. 1. 1.]\n [0. 0. 0.]\n [0. 1. 0.]]\n</pre> <p>By passing the name of the attribute, we can use edge attributes in the creation of the adjacency matrix. To create a sparse, weighted adjacency matrix that uses the <code>edge_weight</code> attribute of our graph object we can simply write:</p> In\u00a0[48]: Copied! <pre>print(g.sparse_adj_matrix(edge_attr='edge_weight').todense())\n</pre> print(g.sparse_adj_matrix(edge_attr='edge_weight').todense()) <pre>[[0 2 1]\n [0 0 0]\n [0 3 0]]\n</pre> <p>By default, graphs in <code>pathpyG</code> are directed. To represent undirected edges, we must add edges in both directions. We can use the <code>to_undirected()</code> function to make a directed graph undirected, which adds all (missing) edges that point in the opposite direction. This will also automatically duplicate and assign the corresponding edge attributes to the newly formed (directed) edges, i.e. edges are assumed to have the same attributes in both directions.</p> In\u00a0[49]: Copied! <pre>g_u = g.to_undirected()\nprint(g_u)\n</pre> g_u = g.to_undirected() print(g_u) <pre>Undirected graph with 3 nodes and 6 (directed) edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 1])\"},\n    'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {'node_class': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3, 1])\"}}\n</pre> <p>By default, the <code>Graph</code> object can contain multiple identical edges, so the following is possible:</p> In\u00a0[17]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')])\nprint(g.data.edge_index)\n</pre> g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')]) print(g.data.edge_index) <pre>EdgeIndex([[0, 0, 1, 2],\n           [1, 1, 2, 0]], sparse_size=(3, 3), nnz=4, sort_order=row)\n</pre> <p>It is often convenient, to coalesce multi-edges into weighted single-edges, i.e. in the example above we may prefer a graph where each edge occurs once in the edge index, but the edge <code>a-&gt;b</code> has a weight attribute of two, while the two other edges have one.</p> <p>In <code>pathpyG</code> we can do this by turning a graph into a weighted graph, which will coalesce edges and add an edge weight attribute that counts multi-edges in the original istance.</p> In\u00a0[18]: Copied! <pre>g_w = g.to_weighted_graph()\nprint(g_w.data.edge_index)\nprint(g_w['edge_weight', 'a', 'b'])\nprint(g_w['edge_weight', 'b', 'c'])\nprint(g_w['edge_weight', 'c', 'a'])\n</pre> g_w = g.to_weighted_graph() print(g_w.data.edge_index) print(g_w['edge_weight', 'a', 'b']) print(g_w['edge_weight', 'b', 'c']) print(g_w['edge_weight', 'c', 'a']) <pre>EdgeIndex([[0, 1, 2],\n           [1, 2, 0]], sparse_size=(3, 3), nnz=3, sort_order=row)\ntensor(2.)\ntensor(1.)\ntensor(1.)\n</pre> <p>As we will see in a separate notebook focusing on the advanced (temporal) graph visualization features of <code>pathpyG</code>, it is easy to generate (interactive) HTML plots of graphs, that are embedded into jupyter notebooks. You can simply call the <code>pp.plot</code> function on the Graph object:</p> In\u00a0[19]: Copied! <pre>pp.plot(g, edge_color='gray', node_label=g.mapping.node_ids.tolist());\n</pre> pp.plot(g, edge_color='gray', node_label=g.mapping.node_ids.tolist()); In\u00a0[53]: Copied! <pre>g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('c','a')])\nprint(g)\n\ndf = pp.io.graph_to_df(g)\nprint(df)\n</pre> g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('c','a')]) print(g)  df = pp.io.graph_to_df(g) print(df) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n   v  w\n0  a  b\n1  b  c\n2  c  a\n</pre> In\u00a0[54]: Copied! <pre>g.data.edge_weight = torch.tensor([1.0, 2.0, 3.0])\nprint(g)\n\ndf = pp.io.graph_to_df(g)\nprint(df)\n</pre> g.data.edge_weight = torch.tensor([1.0, 2.0, 3.0]) print(g)  df = pp.io.graph_to_df(g) print(df) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n   v  w  edge_weight\n0  a  b          1.0\n1  b  c          2.0\n2  c  a          3.0\n</pre> In\u00a0[55]: Copied! <pre>node_attr = pd.DataFrame({'v': ['b', 'a', 'c'], 'node_size': [5.0, 2.0, 1.0]})\nprint(node_attr)\n</pre> node_attr = pd.DataFrame({'v': ['b', 'a', 'c'], 'node_size': [5.0, 2.0, 1.0]}) print(node_attr) <pre>   v  node_size\n0  b        5.0\n1  a        2.0\n2  c        1.0\n</pre> In\u00a0[56]: Copied! <pre>pp.io.add_node_attributes(node_attr, g)\nprint(g.data.node_size)\n</pre> pp.io.add_node_attributes(node_attr, g) print(g.data.node_size) <pre>tensor([2., 5., 1.], dtype=torch.float64)\n</pre> In\u00a0[57]: Copied! <pre>edge_attr = pd.DataFrame({'v': ['c', 'a', 'b'], 'w': ['a', 'b', 'c'], 'edge_weight': [42.0, 43.0, 45.0]})\nprint(edge_attr)\n</pre> edge_attr = pd.DataFrame({'v': ['c', 'a', 'b'], 'w': ['a', 'b', 'c'], 'edge_weight': [42.0, 43.0, 45.0]}) print(edge_attr) <pre>   v  w  edge_weight\n0  c  a         42.0\n1  a  b         43.0\n2  b  c         45.0\n</pre> In\u00a0[58]: Copied! <pre>pp.io.add_edge_attributes(edge_attr, g)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> pp.io.add_edge_attributes(edge_attr, g) print(g.data.edge_index) print(g.data.edge_weight) <pre>EdgeIndex([[0, 1, 2],\n           [1, 2, 0]], sparse_size=(3, 3), nnz=3, sort_order=row)\ntensor([45., 42., 43.], dtype=torch.float64)\n</pre> In\u00a0[59]: Copied! <pre>df = pp.io.graph_to_df(g, node_indices=True)\nprint(df)\n</pre> df = pp.io.graph_to_df(g, node_indices=True) print(df) <pre>   v  w  edge_weight\n0  0  1         45.0\n1  1  2         42.0\n2  2  0         43.0\n</pre> In\u00a0[60]: Copied! <pre>edge_attr = pd.DataFrame([['c', 'a', 'b'], ['a', 'b', 'c'], [42.0, 43.0, 45.0]])\nprint(edge_attr)\n</pre> edge_attr = pd.DataFrame([['c', 'a', 'b'], ['a', 'b', 'c'], [42.0, 43.0, 45.0]]) print(edge_attr) <pre>      0     1     2\n0     c     a     b\n1     a     b     c\n2  42.0  43.0  45.0\n</pre> In\u00a0[70]: Copied! <pre>pp.io.write_csv(g, path_or_buf='../data/test_graph.csv')\n</pre> pp.io.write_csv(g, path_or_buf='../data/test_graph.csv') In\u00a0[65]: Copied! <pre>import os \nprint(os.getcwd())\n</pre> import os  print(os.getcwd()) <pre>/workspaces/pathpyG/docs/tutorial\n</pre> In\u00a0[71]: Copied! <pre>g = pp.io.read_csv_graph(filename='../data/test_graph.csv')\nprint(g)\nprint(g.data)\nprint(g.mapping)\n</pre> g = pp.io.read_csv_graph(filename='../data/test_graph.csv') print(g) print(g.data) print(g.mapping) <pre>Directed graph with 3 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nData(edge_index=[2, 3], num_nodes=3, edge_weight=[3], node_sequence=[3, 1])\na -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n</pre> In\u00a0[72]: Copied! <pre>g.edge_attrs()\n</pre> g.edge_attrs() Out[72]: <pre>['edge_weight']</pre> In\u00a0[73]: Copied! <pre>g.data\n</pre> g.data Out[73]: <pre>Data(edge_index=[2, 3], num_nodes=3, edge_weight=[3], node_sequence=[3, 1])</pre> In\u00a0[74]: Copied! <pre>pp.algorithms.centrality.closeness_centrality(g)\n</pre> pp.algorithms.centrality.closeness_centrality(g) Out[74]: <pre>{np.str_('a'): 0.6666666666666666,\n np.str_('b'): 0.6666666666666666,\n np.str_('c'): 0.6666666666666666}</pre> In\u00a0[75]: Copied! <pre>pp.algorithms.centrality.eigenvector_centrality(g)\n</pre> pp.algorithms.centrality.eigenvector_centrality(g) Out[75]: <pre>{np.str_('a'): 0.5773502691896258,\n np.str_('b'): 0.5773502691896258,\n np.str_('c'): 0.5773502691896258}</pre> In\u00a0[76]: Copied! <pre>pp.algorithms.centrality.katz_centrality(g)\n</pre> pp.algorithms.centrality.katz_centrality(g) Out[76]: <pre>{np.str_('a'): 0.5773502691896258,\n np.str_('b'): 0.5773502691896258,\n np.str_('c'): 0.5773502691896258}</pre> In\u00a0[20]: Copied! <pre>import numpy as np\nimport seaborn as sns\n\nx = np.linspace(0, 1, 100)\ny = pp.statistics.degree_generating_function(g.to_undirected(), x)\nax = sns.lineplot(x=x, y=y)\nax.set_xlabel('$x$', fontsize=16)\nax.set_ylabel('$G_0(x)$', fontsize=16);\n</pre> import numpy as np import seaborn as sns  x = np.linspace(0, 1, 100) y = pp.statistics.degree_generating_function(g.to_undirected(), x) ax = sns.lineplot(x=x, y=y) ax.set_xlabel('$x$', fontsize=16) ax.set_ylabel('$G_0(x)$', fontsize=16); In\u00a0[21]: Copied! <pre>k_2 = pp.statistics.degree_raw_moment(g.to_undirected(), k=2)\nprint(k_2)\nk_1 = pp.statistics.degree_raw_moment(g.to_undirected(), k=1)\nprint(k_1)\nprint('Molloy-Reed Fraction &lt;k^2&gt;/&lt;k&gt;: ', k_2/k_1)\n</pre> k_2 = pp.statistics.degree_raw_moment(g.to_undirected(), k=2) print(k_2) k_1 = pp.statistics.degree_raw_moment(g.to_undirected(), k=1) print(k_1) print('Molloy-Reed Fraction /: ', k_2/k_1) <pre>4.0\n2.0\nMolloy-Reed Fraction &lt;k^2&gt;/&lt;k&gt;:  2.0\n</pre>"},{"location":"tutorial/basic_concepts/#basic-pathpyg-concepts","title":"Basic pathpyG Concepts\u00b6","text":""},{"location":"tutorial/basic_concepts/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/basic_concepts/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>This first step of our multi-stage introductory tutorial introduces key concepts of <code>pathpyG</code>. While <code>pathpyG</code> targets GPU-accelerated analysis and learning using higher-order graph models for time series data on graphs, it can also be used to represent, analyze and interactively visualize static graphs. For this, it provides a <code>Graph</code> class that is build around the <code>torch_geometric.data.Data</code> object, which has the advantage that we can directly apply <code>pyG</code> transforms and use the <code>Graph</code> object for deep graph learning.</p> <p>In this tutorial you will learn how we can use <code>pathpyG</code> to represent static graphs. We start with basic features to create directed and undirected graphs with node-, edge-, and graph-level attributes. We also show how we can read and write graph data and how we can implement graph algorithms that are based on a traversal of nodes and edges.</p> <p>We first import the modules <code>torch</code>, <code>torch_geometric</code> and <code>pathpyG</code>.</p>"},{"location":"tutorial/basic_concepts/#creating-graph-objects","title":"Creating Graph objects\u00b6","text":"<p>Let's start by generating a simple, directed graph with three nodes <code>a</code>, <code>b</code>, <code>c</code> and three edges <code>(a,b)</code>, <code>(b,c)</code> and <code>(a,b)</code>. The three nodes <code>a</code>, <code>b</code>, and <code>c</code> can be represented by integer indices $0, 1$ and $2$ respectively. Following the tensor-based representation in <code>pyG</code>, we use an <code>edge_index</code> tensor with shape <code>(2,m)</code> to represent the <code>m</code> edges of a graph. We can then add this to a <code>Data</code> object that can hold additional node and edge attributes. We finally pass the <code>Data</code> object to the constructor of the <code>Graph</code> class.</p> <p>Using the mapping of node names to indices specified above, the following code generates a directed <code>Graph</code> with three edges <code>(a,c)</code>, <code>(b,c)</code> and <code>(a,b)</code>.</p>"},{"location":"tutorial/basic_concepts/#traversing-graphs","title":"Traversing Graphs\u00b6","text":"<p>The <code>Graph</code> object provides <code>get_successors</code> and <code>get_predecessors</code> functions, which return the indices of nodes that are connected to a node with a given index. Based on cached CSR (compressed sparse row) and CSC (compressed sparse column) representations cached for the sorted <code>EdgeIndex</code>, access to the successors and predecessors of a node works in constant time, i.e. it does not require to enumerate the <code>edge_index</code> tensor.</p> <p>For node <code>a</code> with index $0$ in our directed network we obtain:</p>"},{"location":"tutorial/basic_concepts/#node-edge-or-graph-level-attributes","title":"Node-, Edge- or Graph-Level Attributes\u00b6","text":"<p>Real-world graphs often have node-, edge-, or graph-level attributes. In <code>pathpyG</code>, we can add attributes as tensors, either by directly assigning them to the <code>pyG</code> data object of an existing graph (or by adding them to the <code>Data</code> object passed to the constructor). Following the <code>pyG</code> semantics of attribute names, we use the prefixes <code>node_</code> and <code>edge_</code> to refer to node- and edge-level attributes. Attributes without those prefixes are assumed to refer to graph-level attributes.</p>"},{"location":"tutorial/basic_concepts/#reading-and-writing-graph-data","title":"Reading and writing graph data\u00b6","text":""},{"location":"tutorial/basic_concepts/#networkx-delegate-mechanism","title":"<code>networkx</code> Delegate Mechanism\u00b6","text":"<p>To calculate node centralities, we can use a <code>networkx</code> delegate mechanism implemented in the module <code>pathpyG.algorithms.centrality</code>. Simply speaking, you can call any function implented in the <code>networkx.centrality</code> module whose name ends with <code>_centrality</code>. The <code>pathpyG</code> graph object will be internally converted to a <code>networkx.DiGraph</code> object, the corresponding centrality function (with all of its parameters) will be called, and the result will be mapped back to nodes based on node IDs.</p> <p>In order to calculate the closeness centralities of all nodes for the graph above, we can call:</p>"},{"location":"tutorial/basic_concepts/#probability-generating-functions-for-degree-distributions","title":"Probability Generating functions for degree distributions\u00b6","text":""},{"location":"tutorial/dbgnn/","title":"Causality-Aware GNNs","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n!pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport scipy as sp\n\nimport torch\nfrom torch_geometric.transforms import RandomNodeSplit\n\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.manifold import TSNE\n\nimport pathpyG as pp\nfrom pathpyG.nn.dbgnn import DBGNN\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n</pre> import numpy as np import matplotlib.pyplot as plt import scipy as sp  import torch from torch_geometric.transforms import RandomNodeSplit  from sklearn.metrics import balanced_accuracy_score from sklearn.manifold import TSNE  import pathpyG as pp from pathpyG.nn.dbgnn import DBGNN  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') In\u00a0[2]: Copied! <pre>t = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False)\nt = t.to(device)\n</pre> t = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False) t = t.to(device) <p>This example has created in such a way that the nodes naturally form three clusters, which are highlighted in the interactive visualization below:</p> In\u00a0[3]: Copied! <pre>style = {}\nstyle['node_color'] = ['green']*10+['red']*10+['blue']*10\npp.plot(t, **style, edge_size=4, edge_color='gray');\n</pre> style = {} style['node_color'] = ['green']*10+['red']*10+['blue']*10 pp.plot(t, **style, edge_size=4, edge_color='gray'); In\u00a0[4]: Copied! <pre>pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray');\n</pre> pp.plot(t.to_static_graph(), **style, edge_size=1, edge_color='gray'); <p>In fact, the topology of this graph corresponds to that of a random graph, i.e. there are not patterns whatsoever in the topology of links. Nevertheless, the temporal graph contains a cluster pattern in the topology of causal or time-respecting paths. In particular, the temporal ordering of time-stamped edges is such that nodes with the same cluster label are more frequently connected by time-respecting paths than nodes with different cluster labels. Hence, nodes within the same clusters can more strongly influence each other in a causal way, i.e. via multiple interactions that follow the arrow of time.</p> <p>Traditional (temporal) graph neural networks will not be able to learn from this pattern, as it is due to the specific microscopic temporal ordering of edges. Using higher-order De Bruijn graph models implemented in pathpyG, we can learn from temporal graph data that contains such patterns. Let us explain this step by step.</p> <p>Referring to the previous tutorial on causal paths in temporal graphs, we first create a node-time directed acyclic graph that captures the causal structure of the temporal graph. In this small example, we will only consider two time-stamped edges $(u,v;t)$ and $(v,w;t')$ to contribute to a causal path iff $0 &lt; t'-t \\leq 1$, i.e. we use a delta for the maximum time difference of one time step.</p> In\u00a0[5]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2)\nprint(m)\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, max_order=2) print(m) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [01:04&lt;00:00, 926.86it/s] \n</pre> <pre>MultiOrderModel with max. order 2\n</pre> <p>We can get the first and second order networks from the Multi Order Network object. The first order network is the network of nodes and edges, while the second order network is the network of first order edges as second order nodes and second order edges. The second order network is a De Bruijn graph that captures the temporal-topological patterns in the data.</p> In\u00a0[6]: Copied! <pre>g = m.layers[1]\ng2 = m.layers[2]\n</pre> g = m.layers[1] g2 = m.layers[2] In\u00a0[7]: Copied! <pre>pp.plot(g, edge_size=2);\n</pre> pp.plot(g, edge_size=2); <p>Since it does not consider patterns in the causal topology of the temporal graph, this is not a meaningful model. We can instead use a second-order De Bruijn graph model, which we can easily fit to the paths:</p> In\u00a0[8]: Copied! <pre>layout_style = {}\nlayout_style['layout'] = 'Fruchterman-Reingold'\nlayout_style['seed'] = 1\nlayout_style['force'] = 0.5\nlayout_style['iterations'] = 300\nlayout = pp.layout(g2, **layout_style)\npp.plot(g2, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib',layout=layout);\n</pre> layout_style = {} layout_style['layout'] = 'Fruchterman-Reingold' layout_style['seed'] = 1 layout_style['force'] = 0.5 layout_style['iterations'] = 300 layout = pp.layout(g2, **layout_style) pp.plot(g2, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib',layout=layout); <p>In this graph, every node is a link and links correspond to causal paths of length two, i.e. temporally ordered sequences consisting of two edges that overlap in the center node. In this graph, we clearly see a cluster pattern that is due to the way in which temporal edges are ordered in time. In particular, we see three clusters, where the edges in three of the clusters correspond to causal paths of length two that connect nodes within each of the three clusters. The edges in the fourth cluster (in the center of the visualization) represent causal paths that connect nodes in different clusters.</p> In\u00a0[9]: Copied! <pre>t_shuffled = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False).to(device)\nt_shuffled.shuffle_time()\n</pre> t_shuffled = pp.io.read_csv_temporal_graph('../data/temporal_clusters.tedges', header=False).to(device) t_shuffled.shuffle_time() In\u00a0[10]: Copied! <pre>g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2]\nprint(g2_shuffled)\n</pre> g2_shuffled = pp.MultiOrderModel.from_temporal_graph(t_shuffled, max_order=2).layers[2] print(g2_shuffled) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 60000/60000 [00:53&lt;00:00, 1123.30it/s]\n</pre> <pre>Directed graph with 557 nodes and 1965 edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1965])\"},\n    'Graph Attributes': {'inverse_idx': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([60000])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {}}\n</pre> In\u00a0[11]: Copied! <pre>layout = pp.layout(g2_shuffled,**layout_style)\npp.plot(g2_shuffled, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib', layout=layout);\n</pre> layout = pp.layout(g2_shuffled,**layout_style) pp.plot(g2_shuffled, edge_size=0.1, edge_color='gray', node_color='blue', backend='matplotlib', layout=layout); <p>We now find that the cluster pattern in the second-order graph has vanished. In fact, there is no pattern whatsoever since the underlying (static) graph topology is random and the random shuffling of time stamps leads to random causal paths.</p> In\u00a0[12]: Copied! <pre>L = g2.laplacian(normalization='rw', edge_attr='edge_weight')\nL_shuffled= g2_shuffled.laplacian(normalization='rw',edge_attr='edge_weight')\n</pre> L = g2.laplacian(normalization='rw', edge_attr='edge_weight') L_shuffled= g2_shuffled.laplacian(normalization='rw',edge_attr='edge_weight') <p>We then calculate the eigenvalues and eigenvectors of the Laplacians, and compute the Fiedler vector, i.e. the eigenvector that corresponds to the second-smallest eigenvalue of the Laplacian.</p> In\u00a0[13]: Copied! <pre>w,v = sp.linalg.eig(L.todense(),left= False, right = True)\nw_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense())\n</pre> w,v = sp.linalg.eig(L.todense(),left= False, right = True) w_shuffled, v_shuffled = sp.linalg.eig(L_shuffled.todense()) In\u00a0[14]: Copied! <pre>fiedler = v[:,np.argsort(w)[1]]\nfiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]]\n</pre> fiedler = v[:,np.argsort(w)[1]] fiedler_shuffled = v_shuffled[:,np.argsort(w_shuffled)[1]] <p>Below, we show that the clusters in the causal topology of the temporal graph correspond to clusters in the distribution of entries in the Fiedler vector, while there is no such pattern for the Fiedler vector of the second-order graph constructed from the shuffled temporal graph:</p> In\u00a0[15]: Copied! <pre>c = []\na = []\nfor v in g2.nodes:\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c.append('green')\n        a.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c.append('red')\n        a.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c.append('blue')\n        a.append(1)\n    else:\n        c.append('black')\n        a.append(0.1)\n</pre> c = [] a = [] for v in g2.nodes:     if int(v[0])&lt;10 and int(v[1])&lt;10:         c.append('green')         a.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c.append('red')         a.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c.append('blue')         a.append(1)     else:         c.append('black')         a.append(0.1) In\u00a0[16]: Copied! <pre>c_shuffled = []\na_shuffled = []\nfor v in g2_shuffled.nodes: \n\n    if int(v[0])&lt;10 and int(v[1])&lt;10:\n        c_shuffled.append('green')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10: \n        c_shuffled.append('red')\n        a_shuffled.append(1)\n    elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:\n        c_shuffled.append('blue')\n        a_shuffled.append(1)\n    else:\n        c_shuffled.append('black')\n        a_shuffled.append(0.1)\n</pre> c_shuffled = [] a_shuffled = [] for v in g2_shuffled.nodes:       if int(v[0])&lt;10 and int(v[1])&lt;10:         c_shuffled.append('green')         a_shuffled.append(1)     elif int(v[0])&lt;20 and int(v[0])&gt;= 10 and int(v[1])&lt;20 and int(v[1])&gt;=10:          c_shuffled.append('red')         a_shuffled.append(1)     elif int(v[0])&lt;30 and int(v[0])&gt;= 20 and int(v[1])&lt;30 and int(v[1])&gt;=20:         c_shuffled.append('blue')         a_shuffled.append(1)     else:         c_shuffled.append('black')         a_shuffled.append(0.1) <p>In the plots below, we have colored those entries of the Fiedler vectors that correspond to edges connecting nodes within one of the three clusters shown above. The Fiedler vector shows a clear pattern, which translates to the cluster pattern in the causal topology that we have planted into our synthetic temporal graph.</p> In\u00a0[17]: Copied! <pre>plt.ylim(-.2, .25)\nplt.scatter(range(g2.n), np.real(fiedler),c=c, alpha=a);\n</pre> plt.ylim(-.2, .25) plt.scatter(range(g2.n), np.real(fiedler),c=c, alpha=a); <p>No such pattern exists in the Fiedler vector of the second-order graph corresponding to the shuffled <code>TemporalGraph</code>.</p> In\u00a0[18]: Copied! <pre>plt.ylim(-.1, .1)\nplt.scatter(range(g2_shuffled.n), np.real(fiedler_shuffled), c=c_shuffled, alpha=a_shuffled);\n</pre> plt.ylim(-.1, .1) plt.scatter(range(g2_shuffled.n), np.real(fiedler_shuffled), c=c_shuffled, alpha=a_shuffled); <p>We now set up a <code>pytorch_geometric.Data</code> object that contains all of the information needed to train the DBGNN model. For this, we can use a convenience function of the <code>MultiOrderModel</code> class in <code>pathpyG</code>. Combining a first- and a second-order model, this uses the edge indices and the weight tensors for a message passing scheme. it further constructs an <code>edge_index</code> of a bipartite graph that uses the last node in a second-order node to map messages back to first-order nodes.</p> In\u00a0[19]: Copied! <pre>data = m.to_dbgnn_data(max_order=2, mapping='last')\ndata.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids], device=device)\n</pre> data = m.to_dbgnn_data(max_order=2, mapping='last') data.y = torch.tensor([ int(i) // 10 for i in t.mapping.node_ids], device=device) In\u00a0[20]: Copied! <pre>data = RandomNodeSplit(num_val=0, num_test=0.3)(data)\n\nmodel = DBGNN(num_features=[g.n, g2.n], num_classes=len(data.y.unique()), hidden_dims=[16, 32, 8], p_dropout=0.4).to(\n    device\n)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)\nloss_function = torch.nn.CrossEntropyLoss()\n</pre> data = RandomNodeSplit(num_val=0, num_test=0.3)(data)  model = DBGNN(num_features=[g.n, g2.n], num_classes=len(data.y.unique()), hidden_dims=[16, 32, 8], p_dropout=0.4).to(     device )  optimizer = torch.optim.Adam(model.parameters(), lr=0.005) loss_function = torch.nn.CrossEntropyLoss() <p>The following function evaluates the prediction of our model based on the balanced accuracy score for categorical predictions.</p> In\u00a0[21]: Copied! <pre>def test(model, data):\n    model.eval()\n\n    _, pred = model(data).max(dim=1)\n\n    metrics_train = balanced_accuracy_score(\n        data.y[data.train_mask].cpu(),\n        pred[data.train_mask].cpu().numpy()\n        )\n\n    metrics_test = balanced_accuracy_score(\n        data.y[data.test_mask].cpu(),\n        pred[data.test_mask].cpu().numpy()\n        )\n\n    return metrics_train, metrics_test\n</pre> def test(model, data):     model.eval()      _, pred = model(data).max(dim=1)      metrics_train = balanced_accuracy_score(         data.y[data.train_mask].cpu(),         pred[data.train_mask].cpu().numpy()         )      metrics_test = balanced_accuracy_score(         data.y[data.test_mask].cpu(),         pred[data.test_mask].cpu().numpy()         )      return metrics_train, metrics_test In\u00a0[22]: Copied! <pre>losses = []\nfor epoch in range(100):\n        output = model(data)\n        loss = loss_function(output[data.train_mask], data.y[data.train_mask])\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        losses.append(loss)\n\n        if epoch % 10 == 0:\n                train_ba, test_ba = test(model, data)\n                print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}')\n</pre> losses = [] for epoch in range(100):         output = model(data)         loss = loss_function(output[data.train_mask], data.y[data.train_mask])         loss.backward()         optimizer.step()         optimizer.zero_grad()         losses.append(loss)          if epoch % 10 == 0:                 train_ba, test_ba = test(model, data)                 print(f'Epoch: {epoch}, Loss: {loss}, Train balanced accuracy: {train_ba}, Test balanced accuracy: {test_ba}') <pre>Epoch: 0, Loss: 1.5443899631500244, Train balanced accuracy: 0.3333333333333333, Test balanced accuracy: 0.3333333333333333\nEpoch: 10, Loss: 0.7875016331672668, Train balanced accuracy: 0.6666666666666666, Test balanced accuracy: 0.6666666666666666\nEpoch: 20, Loss: 0.061541132628917694, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 30, Loss: 0.0012057410785928369, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 40, Loss: 0.00011560289567569271, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 50, Loss: 4.159091258770786e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 60, Loss: 2.7213001885684207e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 70, Loss: 2.2796812118031085e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 80, Loss: 2.102010512317065e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\nEpoch: 90, Loss: 2.0162973669357598e-05, Train balanced accuracy: 1.0, Test balanced accuracy: 1.0\n</pre> In\u00a0[23]: Copied! <pre>model.eval()\nlatent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach()\nlatent = model.higher_order_layers[1].forward(latent, data.edge_index_higher_order).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())\n\ncolors = []\nfor v, w in g2.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g2.edges:\n    src = g2.mapping.to_idx(e[0])\n    tgt = g2.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.higher_order_layers[0].forward(data.x_h, data.edge_index_higher_order).detach() latent = model.higher_order_layers[1].forward(latent, data.edge_index_higher_order).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(latent.cpu())  colors = [] for v, w in g2.nodes:     if data.y[g.mapping.to_idx(v)] == 0 and data.y[g.mapping.to_idx(w)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1 and data.y[g.mapping.to_idx(w)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2 and data.y[g.mapping.to_idx(w)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g2.edges:     src = g2.mapping.to_idx(e[0])     tgt = g2.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show() <p>We can further generate latent space representations of the nodes generated by the last bipartite layer of our architecture:</p> In\u00a0[24]: Copied! <pre>model.eval()\nlatent = model.forward(data).detach()\nnode_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())\n\ncolors = []\nfor v in g.nodes:\n    if data.y[g.mapping.to_idx(v)] == 0:\n        colors.append('red')\n    elif data.y[g.mapping.to_idx(v)] == 1:\n        colors.append('green')\n    elif data.y[g.mapping.to_idx(v)] == 2:\n        colors.append('blue')\n    else:\n        colors.append('grey')\n\nplt.figure(figsize=(13,10))\nplt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)\n\nfor e in g.edges:\n    src = g.mapping.to_idx(e[0])\n    tgt = g.mapping.to_idx(e[1])\n    plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]], \n             color='lightsteelblue', \n             linestyle='-', \n             alpha=0.2,\n             lw=0.2)\nplt.axis('off')\nplt.show()\n</pre> model.eval() latent = model.forward(data).detach() node_embedding = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=10).fit_transform(latent.cpu())  colors = [] for v in g.nodes:     if data.y[g.mapping.to_idx(v)] == 0:         colors.append('red')     elif data.y[g.mapping.to_idx(v)] == 1:         colors.append('green')     elif data.y[g.mapping.to_idx(v)] == 2:         colors.append('blue')     else:         colors.append('grey')  plt.figure(figsize=(13,10)) plt.scatter(node_embedding[:,0], node_embedding[:,1], c=colors, alpha=0.5)  for e in g.edges:     src = g.mapping.to_idx(e[0])     tgt = g.mapping.to_idx(e[1])     plt.plot([node_embedding[src,0], node_embedding[tgt,0]], [node_embedding[src,1], node_embedding[tgt,1]],               color='lightsteelblue',               linestyle='-',               alpha=0.2,              lw=0.2) plt.axis('off') plt.show()"},{"location":"tutorial/dbgnn/#causality-aware-graph-neural-networks","title":"Causality-Aware Graph Neural Networks\u00b6","text":""},{"location":"tutorial/dbgnn/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/dbgnn/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In previous tutorials, we have introduced causal paths in temporal graphs, and how we can use them to generate higher-order De Bruijn graph models that capture temporal-topological patterns in time series data. In this tutorial, we will show how we can use De Bruijn Graph Neural Networks, a causality-aware deep learning architecture for temporal graph data. The details of this approach are introduced in this paper. The architecture is implemented in pathpyG and can be readily applied to temporal graph data.</p> <p>Below we illustrate this mthod in a supervised node classification task, i.e. given a temporal graph we will use the temporal-topological patterns in the graph to classify nodes.</p> <p>We start by importing a few modules:</p>"},{"location":"tutorial/dbgnn/#temporal-topological-clusters-in-temporal-graphs","title":"Temporal-Topological Clusters in Temporal Graphs\u00b6","text":"<p>Let us load a small synthetic toy example for a temporal graph with 60.000 time-stamped interactions between 30 nodes. We use the <code>TemporalGraph</code> class to load this example from a file containing edges with discrete time-stamps.</p>"},{"location":"tutorial/dbgnn/#modelling-causal-structures-with-higher-order-de-bruijn-graphs","title":"Modelling Causal Structures with Higher-Order De Bruijn Graphs\u00b6","text":"<p>But what is the origin for the cluster pattern? In the visualization above, you will notice that the time-stamped edges randomly interconnect nodes within and across clusters, actually there is no correlation whatsoever between the topology of links and the cluster membership of the nodes. Hence, the notion of clusters does not correspond to the common idea of cluster patterns in static graphs, which we can highlight further by plotting the static time-aggregated network:</p>"},{"location":"tutorial/dbgnn/#comparison-to-temporal-graph-with-shuffled-time-stamps","title":"Comparison to Temporal Graph with Shuffled Time Stamps\u00b6","text":"<p>You may wonder whether this pattern is really due to the temporal ordering of time-stamped edges. It is easy to check this. We can simply randomly shuffle the time stamps of all edges, which will break any correlations in the temporal ordering that lead to patterns in the causal topology.</p> <p>We repeat the path calculation for this shuffled temporal graph and construct the second-order De Bruijn Graph model again:</p>"},{"location":"tutorial/dbgnn/#spectral-clustering-with-second-order-graph-laplacian","title":"Spectral clustering with second-order graph Laplacian\u00b6","text":"<p>To take a different perspective on cluster patterns, we can actually use <code>pathpyG</code> to apply a spectral analysis to the higher-order graph. We can simply calculate a generalization of the Laplacian matrix to the second-order graph both for the actual temporal graph and its shuffled counterpart:</p>"},{"location":"tutorial/dbgnn/#node-classification-with-causality-aware-graph-neural-networks","title":"Node Classification with Causality-Aware Graph Neural Networks\u00b6","text":"<p>Let us now explore how we can develop a causality-aware deep graph learning architecture that utilizes this pattern in the causal topology. We will follow the architecture introduced in this work. The architecture actually performs message passing in higher-order models with multiple orders at once. In a final message passing step, a bipartite graph is used to obtain vector-space representations of actual nodes in the temporal graph.</p>"},{"location":"tutorial/dbgnn/#training-the-model","title":"Training the model\u00b6","text":"<p>We are now ready to train and evaluate our causality-aware graph neural network. We will frist create a random split of the nodes, set the optimizer and the hyperparameters of our model.</p>"},{"location":"tutorial/dbgnn/#causality-aware-latent-space-representation-of-nodes","title":"Causality-aware latent space representation of nodes\u00b6","text":"<p>We can inspect the model by plotting a latent space representation of the edges generated by the second-order layer of our architecture.</p>"},{"location":"tutorial/generative_models/","title":"Generative Models for Random Graphs","text":"In\u00a0[53]: Copied! <pre>import pathpyG as pp\nimport string \nimport numpy as np\n</pre> import pathpyG as pp import string  import numpy as np <p><code>pathpyG</code> provides implementations for several basic generative models for random graphs, such as different variants of the Erd\u00f6s-Renyi model for random graphs, the Molloy-Reed configuration model for random graphs with given degree sequence or distribution, or the Watts-Strogatz models for small-world graphs.</p> <p>These models are implemented in the module <code>pathpyG.algorithms.generative_models</code>.</p> <p>To generate a random Erd\u00f6s-Renyi graph using the so-called $G(n,p)$ model where $n$ is the number of nodes and $p$ is the probability for each node pair to be connected, we can call:</p> In\u00a0[7]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, p=0.2)\npp.plot(g);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, p=0.2) pp.plot(g); <pre>{'edges': [{'uid': '0-12', 'source': '0', 'target': '12', 'weight': 1}, {'uid': '1-14', 'source': '1', 'target': '14', 'weight': 1}, {'uid': '1-17', 'source': '1', 'target': '17', 'weight': 1}, {'uid': '1-12', 'source': '1', 'target': '12', 'weight': 1}, {'uid': '1-5', 'source': '1', 'target': '5', 'weight': 1}, {'uid': '1-11', 'source': '1', 'target': '11', 'weight': 1}, {'uid': '1-7', 'source': '1', 'target': '7', 'weight': 1}, {'uid': '2-6', 'source': '2', 'target': '6', 'weight': 1}, {'uid': '2-12', 'source': '2', 'target': '12', 'weight': 1}, {'uid': '2-10', 'source': '2', 'target': '10', 'weight': 1}, {'uid': '2-13', 'source': '2', 'target': '13', 'weight': 1}, {'uid': '3-8', 'source': '3', 'target': '8', 'weight': 1}, {'uid': '3-14', 'source': '3', 'target': '14', 'weight': 1}, {'uid': '4-17', 'source': '4', 'target': '17', 'weight': 1}, {'uid': '4-19', 'source': '4', 'target': '19', 'weight': 1}, {'uid': '4-11', 'source': '4', 'target': '11', 'weight': 1}, {'uid': '5-8', 'source': '5', 'target': '8', 'weight': 1}, {'uid': '5-19', 'source': '5', 'target': '19', 'weight': 1}, {'uid': '5-1', 'source': '5', 'target': '1', 'weight': 1}, {'uid': '5-14', 'source': '5', 'target': '14', 'weight': 1}, {'uid': '5-18', 'source': '5', 'target': '18', 'weight': 1}, {'uid': '5-17', 'source': '5', 'target': '17', 'weight': 1}, {'uid': '5-15', 'source': '5', 'target': '15', 'weight': 1}, {'uid': '6-11', 'source': '6', 'target': '11', 'weight': 1}, {'uid': '6-15', 'source': '6', 'target': '15', 'weight': 1}, {'uid': '6-13', 'source': '6', 'target': '13', 'weight': 1}, {'uid': '6-2', 'source': '6', 'target': '2', 'weight': 1}, {'uid': '6-12', 'source': '6', 'target': '12', 'weight': 1}, {'uid': '6-14', 'source': '6', 'target': '14', 'weight': 1}, {'uid': '7-19', 'source': '7', 'target': '19', 'weight': 1}, {'uid': '7-8', 'source': '7', 'target': '8', 'weight': 1}, {'uid': '7-1', 'source': '7', 'target': '1', 'weight': 1}, {'uid': '7-17', 'source': '7', 'target': '17', 'weight': 1}, {'uid': '7-12', 'source': '7', 'target': '12', 'weight': 1}, {'uid': '7-15', 'source': '7', 'target': '15', 'weight': 1}, {'uid': '8-5', 'source': '8', 'target': '5', 'weight': 1}, {'uid': '8-7', 'source': '8', 'target': '7', 'weight': 1}, {'uid': '8-9', 'source': '8', 'target': '9', 'weight': 1}, {'uid': '8-3', 'source': '8', 'target': '3', 'weight': 1}, {'uid': '9-8', 'source': '9', 'target': '8', 'weight': 1}, {'uid': '10-17', 'source': '10', 'target': '17', 'weight': 1}, {'uid': '10-18', 'source': '10', 'target': '18', 'weight': 1}, {'uid': '10-2', 'source': '10', 'target': '2', 'weight': 1}, {'uid': '10-11', 'source': '10', 'target': '11', 'weight': 1}, {'uid': '11-1', 'source': '11', 'target': '1', 'weight': 1}, {'uid': '11-13', 'source': '11', 'target': '13', 'weight': 1}, {'uid': '11-4', 'source': '11', 'target': '4', 'weight': 1}, {'uid': '11-10', 'source': '11', 'target': '10', 'weight': 1}, {'uid': '11-6', 'source': '11', 'target': '6', 'weight': 1}, {'uid': '12-16', 'source': '12', 'target': '16', 'weight': 1}, {'uid': '12-2', 'source': '12', 'target': '2', 'weight': 1}, {'uid': '12-1', 'source': '12', 'target': '1', 'weight': 1}, {'uid': '12-7', 'source': '12', 'target': '7', 'weight': 1}, {'uid': '12-6', 'source': '12', 'target': '6', 'weight': 1}, {'uid': '12-0', 'source': '12', 'target': '0', 'weight': 1}, {'uid': '12-13', 'source': '12', 'target': '13', 'weight': 1}, {'uid': '13-16', 'source': '13', 'target': '16', 'weight': 1}, {'uid': '13-6', 'source': '13', 'target': '6', 'weight': 1}, {'uid': '13-11', 'source': '13', 'target': '11', 'weight': 1}, {'uid': '13-12', 'source': '13', 'target': '12', 'weight': 1}, {'uid': '13-2', 'source': '13', 'target': '2', 'weight': 1}, {'uid': '14-3', 'source': '14', 'target': '3', 'weight': 1}, {'uid': '14-1', 'source': '14', 'target': '1', 'weight': 1}, {'uid': '14-6', 'source': '14', 'target': '6', 'weight': 1}, {'uid': '14-5', 'source': '14', 'target': '5', 'weight': 1}, {'uid': '15-6', 'source': '15', 'target': '6', 'weight': 1}, {'uid': '15-5', 'source': '15', 'target': '5', 'weight': 1}, {'uid': '15-16', 'source': '15', 'target': '16', 'weight': 1}, {'uid': '15-7', 'source': '15', 'target': '7', 'weight': 1}, {'uid': '16-12', 'source': '16', 'target': '12', 'weight': 1}, {'uid': '16-15', 'source': '16', 'target': '15', 'weight': 1}, {'uid': '16-13', 'source': '16', 'target': '13', 'weight': 1}, {'uid': '17-1', 'source': '17', 'target': '1', 'weight': 1}, {'uid': '17-7', 'source': '17', 'target': '7', 'weight': 1}, {'uid': '17-5', 'source': '17', 'target': '5', 'weight': 1}, {'uid': '17-10', 'source': '17', 'target': '10', 'weight': 1}, {'uid': '17-4', 'source': '17', 'target': '4', 'weight': 1}, {'uid': '18-10', 'source': '18', 'target': '10', 'weight': 1}, {'uid': '18-5', 'source': '18', 'target': '5', 'weight': 1}, {'uid': '19-5', 'source': '19', 'target': '5', 'weight': 1}, {'uid': '19-4', 'source': '19', 'target': '4', 'weight': 1}, {'uid': '19-7', 'source': '19', 'target': '7', 'weight': 1}], 'nodes': [{'uid': '0'}, {'uid': '1'}, {'uid': '2'}, {'uid': '3'}, {'uid': '4'}, {'uid': '5'}, {'uid': '6'}, {'uid': '7'}, {'uid': '8'}, {'uid': '9'}, {'uid': '10'}, {'uid': '11'}, {'uid': '12'}, {'uid': '13'}, {'uid': '14'}, {'uid': '15'}, {'uid': '16'}, {'uid': '17'}, {'uid': '18'}, {'uid': '19'}]}\n</pre> <p>By default, no self-loops are added. If we want self-loops to be generated with probability $p$ we can do this as follows (note that self-loops are currently not plotted):</p> In\u00a0[10]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, p=0.2, self_loops=True)\npp.plot(g);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, p=0.2, self_loops=True) pp.plot(g); <pre>{'edges': [{'uid': '0-8', 'source': '0', 'target': '8', 'weight': 1}, {'uid': '0-17', 'source': '0', 'target': '17', 'weight': 1}, {'uid': '0-4', 'source': '0', 'target': '4', 'weight': 1}, {'uid': '1-1', 'source': '1', 'target': '1', 'weight': 1}, {'uid': '1-17', 'source': '1', 'target': '17', 'weight': 1}, {'uid': '1-9', 'source': '1', 'target': '9', 'weight': 1}, {'uid': '1-14', 'source': '1', 'target': '14', 'weight': 1}, {'uid': '2-14', 'source': '2', 'target': '14', 'weight': 1}, {'uid': '2-3', 'source': '2', 'target': '3', 'weight': 1}, {'uid': '2-8', 'source': '2', 'target': '8', 'weight': 1}, {'uid': '2-7', 'source': '2', 'target': '7', 'weight': 1}, {'uid': '3-9', 'source': '3', 'target': '9', 'weight': 1}, {'uid': '3-18', 'source': '3', 'target': '18', 'weight': 1}, {'uid': '3-8', 'source': '3', 'target': '8', 'weight': 1}, {'uid': '3-11', 'source': '3', 'target': '11', 'weight': 1}, {'uid': '3-2', 'source': '3', 'target': '2', 'weight': 1}, {'uid': '3-19', 'source': '3', 'target': '19', 'weight': 1}, {'uid': '3-16', 'source': '3', 'target': '16', 'weight': 1}, {'uid': '4-0', 'source': '4', 'target': '0', 'weight': 1}, {'uid': '4-7', 'source': '4', 'target': '7', 'weight': 1}, {'uid': '5-17', 'source': '5', 'target': '17', 'weight': 1}, {'uid': '5-7', 'source': '5', 'target': '7', 'weight': 1}, {'uid': '5-18', 'source': '5', 'target': '18', 'weight': 1}, {'uid': '6-16', 'source': '6', 'target': '16', 'weight': 1}, {'uid': '7-5', 'source': '7', 'target': '5', 'weight': 1}, {'uid': '7-16', 'source': '7', 'target': '16', 'weight': 1}, {'uid': '7-4', 'source': '7', 'target': '4', 'weight': 1}, {'uid': '7-2', 'source': '7', 'target': '2', 'weight': 1}, {'uid': '8-2', 'source': '8', 'target': '2', 'weight': 1}, {'uid': '8-14', 'source': '8', 'target': '14', 'weight': 1}, {'uid': '8-19', 'source': '8', 'target': '19', 'weight': 1}, {'uid': '8-0', 'source': '8', 'target': '0', 'weight': 1}, {'uid': '8-3', 'source': '8', 'target': '3', 'weight': 1}, {'uid': '9-17', 'source': '9', 'target': '17', 'weight': 1}, {'uid': '9-3', 'source': '9', 'target': '3', 'weight': 1}, {'uid': '9-19', 'source': '9', 'target': '19', 'weight': 1}, {'uid': '9-1', 'source': '9', 'target': '1', 'weight': 1}, {'uid': '9-15', 'source': '9', 'target': '15', 'weight': 1}, {'uid': '10-13', 'source': '10', 'target': '13', 'weight': 1}, {'uid': '10-10', 'source': '10', 'target': '10', 'weight': 1}, {'uid': '11-13', 'source': '11', 'target': '13', 'weight': 1}, {'uid': '11-12', 'source': '11', 'target': '12', 'weight': 1}, {'uid': '11-3', 'source': '11', 'target': '3', 'weight': 1}, {'uid': '12-11', 'source': '12', 'target': '11', 'weight': 1}, {'uid': '12-15', 'source': '12', 'target': '15', 'weight': 1}, {'uid': '12-17', 'source': '12', 'target': '17', 'weight': 1}, {'uid': '13-11', 'source': '13', 'target': '11', 'weight': 1}, {'uid': '13-18', 'source': '13', 'target': '18', 'weight': 1}, {'uid': '13-16', 'source': '13', 'target': '16', 'weight': 1}, {'uid': '13-15', 'source': '13', 'target': '15', 'weight': 1}, {'uid': '13-19', 'source': '13', 'target': '19', 'weight': 1}, {'uid': '13-10', 'source': '13', 'target': '10', 'weight': 1}, {'uid': '14-1', 'source': '14', 'target': '1', 'weight': 1}, {'uid': '14-2', 'source': '14', 'target': '2', 'weight': 1}, {'uid': '14-8', 'source': '14', 'target': '8', 'weight': 1}, {'uid': '15-13', 'source': '15', 'target': '13', 'weight': 1}, {'uid': '15-9', 'source': '15', 'target': '9', 'weight': 1}, {'uid': '15-19', 'source': '15', 'target': '19', 'weight': 1}, {'uid': '15-12', 'source': '15', 'target': '12', 'weight': 1}, {'uid': '16-7', 'source': '16', 'target': '7', 'weight': 1}, {'uid': '16-6', 'source': '16', 'target': '6', 'weight': 1}, {'uid': '16-3', 'source': '16', 'target': '3', 'weight': 1}, {'uid': '16-16', 'source': '16', 'target': '16', 'weight': 1}, {'uid': '16-13', 'source': '16', 'target': '13', 'weight': 1}, {'uid': '17-12', 'source': '17', 'target': '12', 'weight': 1}, {'uid': '17-5', 'source': '17', 'target': '5', 'weight': 1}, {'uid': '17-9', 'source': '17', 'target': '9', 'weight': 1}, {'uid': '17-1', 'source': '17', 'target': '1', 'weight': 1}, {'uid': '17-0', 'source': '17', 'target': '0', 'weight': 1}, {'uid': '18-5', 'source': '18', 'target': '5', 'weight': 1}, {'uid': '18-13', 'source': '18', 'target': '13', 'weight': 1}, {'uid': '18-3', 'source': '18', 'target': '3', 'weight': 1}, {'uid': '19-13', 'source': '19', 'target': '13', 'weight': 1}, {'uid': '19-3', 'source': '19', 'target': '3', 'weight': 1}, {'uid': '19-15', 'source': '19', 'target': '15', 'weight': 1}, {'uid': '19-9', 'source': '19', 'target': '9', 'weight': 1}, {'uid': '19-8', 'source': '19', 'target': '8', 'weight': 1}], 'nodes': [{'uid': '0'}, {'uid': '1'}, {'uid': '2'}, {'uid': '3'}, {'uid': '4'}, {'uid': '5'}, {'uid': '6'}, {'uid': '7'}, {'uid': '8'}, {'uid': '9'}, {'uid': '10'}, {'uid': '11'}, {'uid': '12'}, {'uid': '13'}, {'uid': '14'}, {'uid': '15'}, {'uid': '16'}, {'uid': '17'}, {'uid': '18'}, {'uid': '19'}]}\n</pre> <p>This also works for directed networks and we can specify a given node ID mapping:</p> In\u00a0[18]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20, \n                                                    p=0.2, directed=True, mapping=pp.IndexMap([x for x in string.ascii_lowercase]))\npp.plot(g, node_label = g.nodes);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnp(n=20,                                                      p=0.2, directed=True, mapping=pp.IndexMap([x for x in string.ascii_lowercase])) pp.plot(g, node_label = g.nodes); <pre>{'edges': [{'uid': 'a-d', 'source': 'a', 'target': 'd', 'weight': 1}, {'uid': 'a-n', 'source': 'a', 'target': 'n', 'weight': 1}, {'uid': 'a-e', 'source': 'a', 'target': 'e', 'weight': 1}, {'uid': 'b-g', 'source': 'b', 'target': 'g', 'weight': 1}, {'uid': 'b-n', 'source': 'b', 'target': 'n', 'weight': 1}, {'uid': 'c-n', 'source': 'c', 'target': 'n', 'weight': 1}, {'uid': 'c-o', 'source': 'c', 'target': 'o', 'weight': 1}, {'uid': 'c-t', 'source': 'c', 'target': 't', 'weight': 1}, {'uid': 'c-j', 'source': 'c', 'target': 'j', 'weight': 1}, {'uid': 'c-l', 'source': 'c', 'target': 'l', 'weight': 1}, {'uid': 'c-q', 'source': 'c', 'target': 'q', 'weight': 1}, {'uid': 'c-s', 'source': 'c', 'target': 's', 'weight': 1}, {'uid': 'c-m', 'source': 'c', 'target': 'm', 'weight': 1}, {'uid': 'd-b', 'source': 'd', 'target': 'b', 'weight': 1}, {'uid': 'd-j', 'source': 'd', 'target': 'j', 'weight': 1}, {'uid': 'd-l', 'source': 'd', 'target': 'l', 'weight': 1}, {'uid': 'd-t', 'source': 'd', 'target': 't', 'weight': 1}, {'uid': 'e-h', 'source': 'e', 'target': 'h', 'weight': 1}, {'uid': 'e-s', 'source': 'e', 'target': 's', 'weight': 1}, {'uid': 'e-l', 'source': 'e', 'target': 'l', 'weight': 1}, {'uid': 'e-i', 'source': 'e', 'target': 'i', 'weight': 1}, {'uid': 'e-m', 'source': 'e', 'target': 'm', 'weight': 1}, {'uid': 'e-q', 'source': 'e', 'target': 'q', 'weight': 1}, {'uid': 'f-t', 'source': 'f', 'target': 't', 'weight': 1}, {'uid': 'f-o', 'source': 'f', 'target': 'o', 'weight': 1}, {'uid': 'g-l', 'source': 'g', 'target': 'l', 'weight': 1}, {'uid': 'g-m', 'source': 'g', 'target': 'm', 'weight': 1}, {'uid': 'g-c', 'source': 'g', 'target': 'c', 'weight': 1}, {'uid': 'g-a', 'source': 'g', 'target': 'a', 'weight': 1}, {'uid': 'h-e', 'source': 'h', 'target': 'e', 'weight': 1}, {'uid': 'h-n', 'source': 'h', 'target': 'n', 'weight': 1}, {'uid': 'h-m', 'source': 'h', 'target': 'm', 'weight': 1}, {'uid': 'i-f', 'source': 'i', 'target': 'f', 'weight': 1}, {'uid': 'i-k', 'source': 'i', 'target': 'k', 'weight': 1}, {'uid': 'i-j', 'source': 'i', 'target': 'j', 'weight': 1}, {'uid': 'j-s', 'source': 'j', 'target': 's', 'weight': 1}, {'uid': 'j-r', 'source': 'j', 'target': 'r', 'weight': 1}, {'uid': 'j-l', 'source': 'j', 'target': 'l', 'weight': 1}, {'uid': 'k-r', 'source': 'k', 'target': 'r', 'weight': 1}, {'uid': 'k-l', 'source': 'k', 'target': 'l', 'weight': 1}, {'uid': 'k-h', 'source': 'k', 'target': 'h', 'weight': 1}, {'uid': 'k-c', 'source': 'k', 'target': 'c', 'weight': 1}, {'uid': 'k-n', 'source': 'k', 'target': 'n', 'weight': 1}, {'uid': 'k-t', 'source': 'k', 'target': 't', 'weight': 1}, {'uid': 'k-e', 'source': 'k', 'target': 'e', 'weight': 1}, {'uid': 'l-d', 'source': 'l', 'target': 'd', 'weight': 1}, {'uid': 'l-b', 'source': 'l', 'target': 'b', 'weight': 1}, {'uid': 'l-o', 'source': 'l', 'target': 'o', 'weight': 1}, {'uid': 'l-c', 'source': 'l', 'target': 'c', 'weight': 1}, {'uid': 'm-e', 'source': 'm', 'target': 'e', 'weight': 1}, {'uid': 'm-s', 'source': 'm', 'target': 's', 'weight': 1}, {'uid': 'm-a', 'source': 'm', 'target': 'a', 'weight': 1}, {'uid': 'm-i', 'source': 'm', 'target': 'i', 'weight': 1}, {'uid': 'n-e', 'source': 'n', 'target': 'e', 'weight': 1}, {'uid': 'n-i', 'source': 'n', 'target': 'i', 'weight': 1}, {'uid': 'o-a', 'source': 'o', 'target': 'a', 'weight': 1}, {'uid': 'o-p', 'source': 'o', 'target': 'p', 'weight': 1}, {'uid': 'p-r', 'source': 'p', 'target': 'r', 'weight': 1}, {'uid': 'p-q', 'source': 'p', 'target': 'q', 'weight': 1}, {'uid': 'p-h', 'source': 'p', 'target': 'h', 'weight': 1}, {'uid': 'p-d', 'source': 'p', 'target': 'd', 'weight': 1}, {'uid': 'p-s', 'source': 'p', 'target': 's', 'weight': 1}, {'uid': 'p-a', 'source': 'p', 'target': 'a', 'weight': 1}, {'uid': 'q-b', 'source': 'q', 'target': 'b', 'weight': 1}, {'uid': 'q-m', 'source': 'q', 'target': 'm', 'weight': 1}, {'uid': 'q-j', 'source': 'q', 'target': 'j', 'weight': 1}, {'uid': 'q-h', 'source': 'q', 'target': 'h', 'weight': 1}, {'uid': 'q-e', 'source': 'q', 'target': 'e', 'weight': 1}, {'uid': 'q-l', 'source': 'q', 'target': 'l', 'weight': 1}, {'uid': 'r-e', 'source': 'r', 'target': 'e', 'weight': 1}, {'uid': 'r-l', 'source': 'r', 'target': 'l', 'weight': 1}, {'uid': 's-m', 'source': 's', 'target': 'm', 'weight': 1}, {'uid': 's-o', 'source': 's', 'target': 'o', 'weight': 1}, {'uid': 's-f', 'source': 's', 'target': 'f', 'weight': 1}, {'uid': 's-h', 'source': 's', 'target': 'h', 'weight': 1}, {'uid': 't-l', 'source': 't', 'target': 'l', 'weight': 1}, {'uid': 't-b', 'source': 't', 'target': 'b', 'weight': 1}, {'uid': 't-i', 'source': 't', 'target': 'i', 'weight': 1}, {'uid': 't-g', 'source': 't', 'target': 'g', 'weight': 1}], 'nodes': [{'uid': 'a', 'label': 'a'}, {'uid': 'b', 'label': 'b'}, {'uid': 'c', 'label': 'c'}, {'uid': 'd', 'label': 'd'}, {'uid': 'e', 'label': 'e'}, {'uid': 'f', 'label': 'f'}, {'uid': 'g', 'label': 'g'}, {'uid': 'h', 'label': 'h'}, {'uid': 'i', 'label': 'i'}, {'uid': 'j', 'label': 'j'}, {'uid': 'k', 'label': 'k'}, {'uid': 'l', 'label': 'l'}, {'uid': 'm', 'label': 'm'}, {'uid': 'n', 'label': 'n'}, {'uid': 'o', 'label': 'o'}, {'uid': 'p', 'label': 'p'}, {'uid': 'q', 'label': 'q'}, {'uid': 'r', 'label': 'r'}, {'uid': 's', 'label': 's'}, {'uid': 't', 'label': 't'}]}\n</pre> <p>For the random realizations generated by the $G(n,p)$ model with connection probability $p$, we have an expected number of $p \\cdot \\binom{n}{2}$ edges, i.e. the number of edges in each realization varies.</p> <p>We can use the alternative $G(n,m)$ formulation of the Erd\u00f6s-Renyi model, which generates a fixed number of $m$ edges chosen uniformly at random:</p> In\u00a0[20]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20, \n                                                    m=40, mapping=pp.IndexMap([x for x in string.ascii_lowercase]))\nprint(g)\npp.plot(g, node_label = g.nodes);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20,                                                      m=40, mapping=pp.IndexMap([x for x in string.ascii_lowercase])) print(g) pp.plot(g, node_label = g.nodes); <pre>Undirected graph with 20 nodes and 80 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n{'edges': [{'uid': 'a-f', 'source': 'a', 'target': 'f', 'weight': 1}, {'uid': 'a-h', 'source': 'a', 'target': 'h', 'weight': 1}, {'uid': 'a-k', 'source': 'a', 'target': 'k', 'weight': 1}, {'uid': 'b-q', 'source': 'b', 'target': 'q', 'weight': 1}, {'uid': 'b-j', 'source': 'b', 'target': 'j', 'weight': 1}, {'uid': 'b-r', 'source': 'b', 'target': 'r', 'weight': 1}, {'uid': 'c-q', 'source': 'c', 'target': 'q', 'weight': 1}, {'uid': 'd-s', 'source': 'd', 'target': 's', 'weight': 1}, {'uid': 'd-j', 'source': 'd', 'target': 'j', 'weight': 1}, {'uid': 'd-k', 'source': 'd', 'target': 'k', 'weight': 1}, {'uid': 'd-q', 'source': 'd', 'target': 'q', 'weight': 1}, {'uid': 'd-n', 'source': 'd', 'target': 'n', 'weight': 1}, {'uid': 'd-i', 'source': 'd', 'target': 'i', 'weight': 1}, {'uid': 'd-e', 'source': 'd', 'target': 'e', 'weight': 1}, {'uid': 'e-m', 'source': 'e', 'target': 'm', 'weight': 1}, {'uid': 'e-t', 'source': 'e', 'target': 't', 'weight': 1}, {'uid': 'e-d', 'source': 'e', 'target': 'd', 'weight': 1}, {'uid': 'e-l', 'source': 'e', 'target': 'l', 'weight': 1}, {'uid': 'f-s', 'source': 'f', 'target': 's', 'weight': 1}, {'uid': 'f-g', 'source': 'f', 'target': 'g', 'weight': 1}, {'uid': 'f-r', 'source': 'f', 'target': 'r', 'weight': 1}, {'uid': 'f-a', 'source': 'f', 'target': 'a', 'weight': 1}, {'uid': 'g-s', 'source': 'g', 'target': 's', 'weight': 1}, {'uid': 'g-j', 'source': 'g', 'target': 'j', 'weight': 1}, {'uid': 'g-r', 'source': 'g', 'target': 'r', 'weight': 1}, {'uid': 'g-n', 'source': 'g', 'target': 'n', 'weight': 1}, {'uid': 'g-f', 'source': 'g', 'target': 'f', 'weight': 1}, {'uid': 'h-n', 'source': 'h', 'target': 'n', 'weight': 1}, {'uid': 'h-a', 'source': 'h', 'target': 'a', 'weight': 1}, {'uid': 'h-r', 'source': 'h', 'target': 'r', 'weight': 1}, {'uid': 'i-p', 'source': 'i', 'target': 'p', 'weight': 1}, {'uid': 'i-k', 'source': 'i', 'target': 'k', 'weight': 1}, {'uid': 'i-n', 'source': 'i', 'target': 'n', 'weight': 1}, {'uid': 'i-d', 'source': 'i', 'target': 'd', 'weight': 1}, {'uid': 'i-l', 'source': 'i', 'target': 'l', 'weight': 1}, {'uid': 'j-g', 'source': 'j', 'target': 'g', 'weight': 1}, {'uid': 'j-d', 'source': 'j', 'target': 'd', 'weight': 1}, {'uid': 'j-b', 'source': 'j', 'target': 'b', 'weight': 1}, {'uid': 'j-o', 'source': 'j', 'target': 'o', 'weight': 1}, {'uid': 'k-t', 'source': 'k', 'target': 't', 'weight': 1}, {'uid': 'k-r', 'source': 'k', 'target': 'r', 'weight': 1}, {'uid': 'k-a', 'source': 'k', 'target': 'a', 'weight': 1}, {'uid': 'k-i', 'source': 'k', 'target': 'i', 'weight': 1}, {'uid': 'k-d', 'source': 'k', 'target': 'd', 'weight': 1}, {'uid': 'l-e', 'source': 'l', 'target': 'e', 'weight': 1}, {'uid': 'l-o', 'source': 'l', 'target': 'o', 'weight': 1}, {'uid': 'l-n', 'source': 'l', 'target': 'n', 'weight': 1}, {'uid': 'l-i', 'source': 'l', 'target': 'i', 'weight': 1}, {'uid': 'l-p', 'source': 'l', 'target': 'p', 'weight': 1}, {'uid': 'm-o', 'source': 'm', 'target': 'o', 'weight': 1}, {'uid': 'm-e', 'source': 'm', 'target': 'e', 'weight': 1}, {'uid': 'm-p', 'source': 'm', 'target': 'p', 'weight': 1}, {'uid': 'n-r', 'source': 'n', 'target': 'r', 'weight': 1}, {'uid': 'n-i', 'source': 'n', 'target': 'i', 'weight': 1}, {'uid': 'n-d', 'source': 'n', 'target': 'd', 'weight': 1}, {'uid': 'n-g', 'source': 'n', 'target': 'g', 'weight': 1}, {'uid': 'n-l', 'source': 'n', 'target': 'l', 'weight': 1}, {'uid': 'n-h', 'source': 'n', 'target': 'h', 'weight': 1}, {'uid': 'o-j', 'source': 'o', 'target': 'j', 'weight': 1}, {'uid': 'o-m', 'source': 'o', 'target': 'm', 'weight': 1}, {'uid': 'o-l', 'source': 'o', 'target': 'l', 'weight': 1}, {'uid': 'p-l', 'source': 'p', 'target': 'l', 'weight': 1}, {'uid': 'p-i', 'source': 'p', 'target': 'i', 'weight': 1}, {'uid': 'p-m', 'source': 'p', 'target': 'm', 'weight': 1}, {'uid': 'q-r', 'source': 'q', 'target': 'r', 'weight': 1}, {'uid': 'q-c', 'source': 'q', 'target': 'c', 'weight': 1}, {'uid': 'q-d', 'source': 'q', 'target': 'd', 'weight': 1}, {'uid': 'q-b', 'source': 'q', 'target': 'b', 'weight': 1}, {'uid': 'r-f', 'source': 'r', 'target': 'f', 'weight': 1}, {'uid': 'r-h', 'source': 'r', 'target': 'h', 'weight': 1}, {'uid': 'r-g', 'source': 'r', 'target': 'g', 'weight': 1}, {'uid': 'r-q', 'source': 'r', 'target': 'q', 'weight': 1}, {'uid': 'r-n', 'source': 'r', 'target': 'n', 'weight': 1}, {'uid': 'r-k', 'source': 'r', 'target': 'k', 'weight': 1}, {'uid': 'r-b', 'source': 'r', 'target': 'b', 'weight': 1}, {'uid': 's-d', 'source': 's', 'target': 'd', 'weight': 1}, {'uid': 's-g', 'source': 's', 'target': 'g', 'weight': 1}, {'uid': 's-f', 'source': 's', 'target': 'f', 'weight': 1}, {'uid': 't-k', 'source': 't', 'target': 'k', 'weight': 1}, {'uid': 't-e', 'source': 't', 'target': 'e', 'weight': 1}], 'nodes': [{'uid': 'a', 'label': 'a'}, {'uid': 'b', 'label': 'b'}, {'uid': 'c', 'label': 'c'}, {'uid': 'd', 'label': 'd'}, {'uid': 'e', 'label': 'e'}, {'uid': 'f', 'label': 'f'}, {'uid': 'g', 'label': 'g'}, {'uid': 'h', 'label': 'h'}, {'uid': 'i', 'label': 'i'}, {'uid': 'j', 'label': 'j'}, {'uid': 'k', 'label': 'k'}, {'uid': 'l', 'label': 'l'}, {'uid': 'm', 'label': 'm'}, {'uid': 'n', 'label': 'n'}, {'uid': 'o', 'label': 'o'}, {'uid': 'p', 'label': 'p'}, {'uid': 'q', 'label': 'q'}, {'uid': 'r', 'label': 'r'}, {'uid': 's', 'label': 's'}, {'uid': 't', 'label': 't'}]}\n</pre> <p>Naturally, the maximum number of edges that we can create depends on the size of the graph (and whether edges are directed and whether we allow for self-loops). The following fails:</p> In\u00a0[24]: Copied! <pre>g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20, \n                                                    m=195, mapping=pp.IndexMap([x for x in string.ascii_lowercase]))\nprint(g)\npp.plot(g, node_label = g.nodes);\n</pre> g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20,                                                      m=195, mapping=pp.IndexMap([x for x in string.ascii_lowercase])) print(g) pp.plot(g, node_label = g.nodes); <pre>\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\nCell In[24], line 1\n----&gt; 1 g = pp.algorithms.generative_models.erdos_renyi_gnm(n=20, \n      2                                                     m=195, mapping=pp.IndexMap([x for x in string.ascii_lowercase]))\n      3 print(g)\n      4 pp.plot(g, node_label = g.nodes)\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/generative_models.py:85, in erdos_renyi_gnm(n, m, mapping, self_loops, multi_edges, directed)\n     69 def erdos_renyi_gnm(n: int, m: int, mapping: IndexMap | None = None,\n     70                     self_loops: bool = False, multi_edges: bool = False,\n     71                     directed: bool = False) -&gt; Graph:\n     72     \"\"\"Generate a random graph with n nodes and m edges based on the G(n,m) model by Pal Er\u00f6ds and Alfred Renyi.\n     73 \n     74     Args:\n   (...)\n     83         Graph: graph object\n     84     \"\"\"\n---&gt; 85     assert m &lt;= max_edges(n, directed=directed, self_loops=self_loops, multi_edges=multi_edges)\n     87     edges = set()\n     88     edges_added: int = 0\n\nAssertionError: </pre> <p>To check how many edges a directed/undirected graph with/without self-loop can possibly have, you can use the <code>max_edges</code> function:</p> In\u00a0[25]: Copied! <pre>pp.algorithms.generative_models.max_edges(n=20, directed=False, self_loops=False)\n</pre> pp.algorithms.generative_models.max_edges(n=20, directed=False, self_loops=False) Out[25]: <pre>190</pre> <p>We often use random graph models to generate randomized versions of empirical networks. For this prupose, <code>pathpyG</code> provides <code>_randomize</code> variants for random graph models, which can be used to automatically fit the model parameters to an empirical graph, thus generating a randomized version that preserves the corresponding aggregate characteristics defined by the model.</p> <p>Let's try this for randomized versions of the Karate club network, which we can load from the netzschleuder database:</p> In\u00a0[11]: Copied! <pre>g_karate = pp.io.read_netzschleuder_graph('karate', '77')\nprint(g_karate)\n</pre> g_karate = pp.io.read_netzschleuder_graph('karate', '77') print(g_karate) <pre>Mapping node attributes based on node indices in column `index`\nUndirected graph with 34 nodes and 154 (directed) edges\n{   'Edge Attributes': {},\n    'Graph Attributes': {   'analyses_average_degree': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_assortativity': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_std_dev': \"&lt;class 'float'&gt;\",\n                            'analyses_diameter': \"&lt;class 'int'&gt;\",\n                            'analyses_edge_properties': \"&lt;class 'list'&gt;\",\n                            'analyses_edge_reciprocity': \"&lt;class 'float'&gt;\",\n                            'analyses_global_clustering': \"&lt;class 'float'&gt;\",\n                            'analyses_hashimoto_radius': \"&lt;class 'float'&gt;\",\n                            'analyses_is_bipartite': \"&lt;class 'bool'&gt;\",\n                            'analyses_is_directed': \"&lt;class 'bool'&gt;\",\n                            'analyses_knn_proj_1': \"&lt;class 'float'&gt;\",\n                            'analyses_knn_proj_2': \"&lt;class 'float'&gt;\",\n                            'analyses_largest_component_fraction': \"&lt;class 'float'&gt;\",\n                            'analyses_mixing_time': \"&lt;class 'float'&gt;\",\n                            'analyses_num_edges': \"&lt;class 'int'&gt;\",\n                            'analyses_num_vertices': \"&lt;class 'int'&gt;\",\n                            'analyses_transition_gap': \"&lt;class 'float'&gt;\",\n                            'analyses_vertex_properties': \"&lt;class 'list'&gt;\",\n                            'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {   'node__pos': \"&lt;class 'numpy.ndarray'&gt;\",\n                           'node_groups': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\",\n                           'node_name': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\"}}\n</pre> <p>Using <code>erdos_renyi_gnm_randomize</code>, we obtain a random graph with the same number of nodes and edges.</p> In\u00a0[29]: Copied! <pre>r_karate = pp.algorithms.generative_models.erdos_renyi_gnm_randomize(g_karate)\nprint(r_karate)\n</pre> r_karate = pp.algorithms.generative_models.erdos_renyi_gnm_randomize(g_karate) print(r_karate) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>Note that node, edge, and graph attributes are not preserved, but it is easy to add back those manually that you want to reassign.</p> In\u00a0[31]: Copied! <pre>r_karate.data.node_groups = g_karate.data.node_groups\nprint(r_karate)\n</pre> r_karate.data.node_groups = g_karate.data.node_groups print(r_karate) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {'node_groups': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\"}}\n</pre> <p>Using <code>erdos_renyi_gnp_randomize</code>, we obtain a random graph with the same number of nodes and where the expected number of edges matches the original graph, i.e. in each random realization the actual number of edges varies:</p> In\u00a0[33]: Copied! <pre>r_karate_1 = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate)\nr_karate_2 = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate)\nprint(r_karate_1)\nprint(r_karate_2)\n</pre> r_karate_1 = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate) r_karate_2 = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate) print(r_karate_1) print(r_karate_2) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nUndirected graph with 34 nodes and 196 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>Plotting the distribution of edges in the random realization confirms that we get a distribution that is centered around the edge count of our empirical graph.</p> In\u00a0[45]: Copied! <pre>from matplotlib import pyplot as plt\n\nedge_counts = []\nfor i in range(200):\n    r_karate = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate)\n    edge_counts.append(r_karate.m)\nax = plt.hist(edge_counts)\nplt.axvline(x=g_karate.m, color='red')\n</pre> from matplotlib import pyplot as plt  edge_counts = [] for i in range(200):     r_karate = pp.algorithms.generative_models.erdos_renyi_gnp_randomize(g_karate)     edge_counts.append(r_karate.m) ax = plt.hist(edge_counts) plt.axvline(x=g_karate.m, color='red') Out[45]: <pre>&lt;matplotlib.lines.Line2D at 0x7f638bcf9ea0&gt;</pre> <p>We can finally use the Molloy-Reed configuration model to generate random graphs with a given degree sequence:</p> In\u00a0[\u00a0]: Copied! <pre>g = pp.algorithms.generative_models.molloy_reed([2,2,3,2,3])\nprint(pp.statistics.degree_sequence(g))\nprint(g)\npp.plot(g)\n</pre> g = pp.algorithms.generative_models.molloy_reed([2,2,3,2,3]) print(pp.statistics.degree_sequence(g)) print(g) pp.plot(g) <pre>[2. 2. 3. 2. 3.]\nUndirected graph with 5 nodes and 12 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n{'edges': [{'uid': '0-2', 'source': '0', 'target': '2', 'weight': 1}, {'uid': '0-3', 'source': '0', 'target': '3', 'weight': 1}, {'uid': '1-2', 'source': '1', 'target': '2', 'weight': 1}, {'uid': '1-4', 'source': '1', 'target': '4', 'weight': 1}, {'uid': '2-0', 'source': '2', 'target': '0', 'weight': 1}, {'uid': '2-1', 'source': '2', 'target': '1', 'weight': 1}, {'uid': '2-4', 'source': '2', 'target': '4', 'weight': 1}, {'uid': '3-0', 'source': '3', 'target': '0', 'weight': 1}, {'uid': '3-4', 'source': '3', 'target': '4', 'weight': 1}, {'uid': '4-1', 'source': '4', 'target': '1', 'weight': 1}, {'uid': '4-2', 'source': '4', 'target': '2', 'weight': 1}, {'uid': '4-3', 'source': '4', 'target': '3', 'weight': 1}], 'nodes': [{'uid': '0'}, {'uid': '1'}, {'uid': '2'}, {'uid': '3'}, {'uid': '4'}]}\n</pre> Out[\u00a0]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f0be060c460&gt;</pre> <p>Not every sequence of integers is the degree sequence of a corresponding graph, the following thus fails:</p> In\u00a0[8]: Copied! <pre>g = pp.algorithms.generative_models.molloy_reed([2,2,6,2,3])\n</pre> g = pp.algorithms.generative_models.molloy_reed([2,2,6,2,3]) <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 g = pp.algorithms.generative_models.molloy_reed([2,2,6,2,3])\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/generative_models.py:437, in molloy_reed(degree_sequence, multiedge, relax, node_ids)\n    435 # assume that we are given a graphical degree sequence\n    436 if not is_graphic_erdos_gallai(degree_sequence):\n--&gt; 437     raise AttributeError('degree sequence is not graphic')\n    439 # create empty network with n nodes\n    440 n = len(degree_sequence)\n\nAttributeError: degree sequence is not graphic</pre> <p>We can test whether a sequence of integers is graphic, i.e. whether we can use it to generate a Molloy-Reed random graph:</p> In\u00a0[10]: Copied! <pre>pp.algorithms.generative_models.is_graphic_erdos_gallai([2,2,6,2,3])\n</pre> pp.algorithms.generative_models.is_graphic_erdos_gallai([2,2,6,2,3]) Out[10]: <pre>False</pre> <p>We can use the Molloy-Reed model to randomize empirical networks, generating a random graph with the same degree sequence but a randomized topology:</p> In\u00a0[16]: Copied! <pre>r_karate = pp.algorithms.generative_models.molloy_reed_randomize(g_karate)\nprint(r_karate)\nprint(pp.statistics.degree_sequence(g_karate))\nprint(pp.statistics.degree_sequence(r_karate))\n</pre> r_karate = pp.algorithms.generative_models.molloy_reed_randomize(g_karate) print(r_karate) print(pp.statistics.degree_sequence(g_karate)) print(pp.statistics.degree_sequence(r_karate)) <pre>Undirected graph with 34 nodes and 154 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n[16.  9. 10.  6.  3.  4.  4.  4.  5.  2.  3.  1.  2.  5.  2.  2.  2.  2.\n  2.  3.  2.  2.  1.  5.  3.  3.  2.  4.  3.  4.  4.  6. 12. 16.]\n[16.  9. 10.  6.  3.  4.  4.  4.  5.  2.  3.  1.  2.  5.  2.  2.  2.  2.\n  2.  3.  2.  2.  1.  5.  3.  3.  2.  4.  3.  4.  4.  6. 12. 16.]\n</pre> <p>Finally, the <code>generative_models</code> module also contains implementations of the Watts-Strogatz model as well as the stochastic block model. Different from the models above, those models cannot be used to randomize a graph though.</p> In\u00a0[18]: Copied! <pre>g = pp.algorithms.generative_models.watts_strogatz(n=100, s=2, p=0.1)\npp.plot(g);\n</pre> g = pp.algorithms.generative_models.watts_strogatz(n=100, s=2, p=0.1) pp.plot(g); <pre>{'edges': [{'uid': '0-2', 'source': '0', 'target': '2', 'weight': 1}, {'uid': '0-1', 'source': '0', 'target': '1', 'weight': 1}, {'uid': '0-99', 'source': '0', 'target': '99', 'weight': 1}, {'uid': '0-98', 'source': '0', 'target': '98', 'weight': 1}, {'uid': '1-0', 'source': '1', 'target': '0', 'weight': 1}, {'uid': '1-2', 'source': '1', 'target': '2', 'weight': 1}, {'uid': '1-3', 'source': '1', 'target': '3', 'weight': 1}, {'uid': '1-99', 'source': '1', 'target': '99', 'weight': 1}, {'uid': '2-0', 'source': '2', 'target': '0', 'weight': 1}, {'uid': '2-1', 'source': '2', 'target': '1', 'weight': 1}, {'uid': '2-3', 'source': '2', 'target': '3', 'weight': 1}, {'uid': '2-4', 'source': '2', 'target': '4', 'weight': 1}, {'uid': '3-5', 'source': '3', 'target': '5', 'weight': 1}, {'uid': '3-18', 'source': '3', 'target': '18', 'weight': 1}, {'uid': '3-4', 'source': '3', 'target': '4', 'weight': 1}, {'uid': '3-2', 'source': '3', 'target': '2', 'weight': 1}, {'uid': '3-1', 'source': '3', 'target': '1', 'weight': 1}, {'uid': '4-2', 'source': '4', 'target': '2', 'weight': 1}, {'uid': '4-3', 'source': '4', 'target': '3', 'weight': 1}, {'uid': '4-5', 'source': '4', 'target': '5', 'weight': 1}, {'uid': '4-6', 'source': '4', 'target': '6', 'weight': 1}, {'uid': '4-79', 'source': '4', 'target': '79', 'weight': 1}, {'uid': '5-3', 'source': '5', 'target': '3', 'weight': 1}, {'uid': '5-4', 'source': '5', 'target': '4', 'weight': 1}, {'uid': '5-6', 'source': '5', 'target': '6', 'weight': 1}, {'uid': '5-7', 'source': '5', 'target': '7', 'weight': 1}, {'uid': '6-7', 'source': '6', 'target': '7', 'weight': 1}, {'uid': '6-8', 'source': '6', 'target': '8', 'weight': 1}, {'uid': '6-5', 'source': '6', 'target': '5', 'weight': 1}, {'uid': '6-4', 'source': '6', 'target': '4', 'weight': 1}, {'uid': '7-5', 'source': '7', 'target': '5', 'weight': 1}, {'uid': '7-6', 'source': '7', 'target': '6', 'weight': 1}, {'uid': '7-9', 'source': '7', 'target': '9', 'weight': 1}, {'uid': '7-76', 'source': '7', 'target': '76', 'weight': 1}, {'uid': '8-6', 'source': '8', 'target': '6', 'weight': 1}, {'uid': '8-10', 'source': '8', 'target': '10', 'weight': 1}, {'uid': '8-96', 'source': '8', 'target': '96', 'weight': 1}, {'uid': '9-7', 'source': '9', 'target': '7', 'weight': 1}, {'uid': '9-10', 'source': '9', 'target': '10', 'weight': 1}, {'uid': '9-11', 'source': '9', 'target': '11', 'weight': 1}, {'uid': '10-9', 'source': '10', 'target': '9', 'weight': 1}, {'uid': '10-12', 'source': '10', 'target': '12', 'weight': 1}, {'uid': '10-11', 'source': '10', 'target': '11', 'weight': 1}, {'uid': '10-8', 'source': '10', 'target': '8', 'weight': 1}, {'uid': '11-9', 'source': '11', 'target': '9', 'weight': 1}, {'uid': '11-10', 'source': '11', 'target': '10', 'weight': 1}, {'uid': '11-12', 'source': '11', 'target': '12', 'weight': 1}, {'uid': '11-13', 'source': '11', 'target': '13', 'weight': 1}, {'uid': '12-10', 'source': '12', 'target': '10', 'weight': 1}, {'uid': '12-11', 'source': '12', 'target': '11', 'weight': 1}, {'uid': '12-13', 'source': '12', 'target': '13', 'weight': 1}, {'uid': '12-14', 'source': '12', 'target': '14', 'weight': 1}, {'uid': '13-12', 'source': '13', 'target': '12', 'weight': 1}, {'uid': '13-15', 'source': '13', 'target': '15', 'weight': 1}, {'uid': '13-14', 'source': '13', 'target': '14', 'weight': 1}, {'uid': '13-11', 'source': '13', 'target': '11', 'weight': 1}, {'uid': '14-13', 'source': '14', 'target': '13', 'weight': 1}, {'uid': '14-15', 'source': '14', 'target': '15', 'weight': 1}, {'uid': '14-16', 'source': '14', 'target': '16', 'weight': 1}, {'uid': '14-12', 'source': '14', 'target': '12', 'weight': 1}, {'uid': '15-13', 'source': '15', 'target': '13', 'weight': 1}, {'uid': '15-14', 'source': '15', 'target': '14', 'weight': 1}, {'uid': '15-16', 'source': '15', 'target': '16', 'weight': 1}, {'uid': '15-17', 'source': '15', 'target': '17', 'weight': 1}, {'uid': '16-18', 'source': '16', 'target': '18', 'weight': 1}, {'uid': '16-17', 'source': '16', 'target': '17', 'weight': 1}, {'uid': '16-15', 'source': '16', 'target': '15', 'weight': 1}, {'uid': '16-14', 'source': '16', 'target': '14', 'weight': 1}, {'uid': '17-15', 'source': '17', 'target': '15', 'weight': 1}, {'uid': '17-16', 'source': '17', 'target': '16', 'weight': 1}, {'uid': '17-18', 'source': '17', 'target': '18', 'weight': 1}, {'uid': '17-19', 'source': '17', 'target': '19', 'weight': 1}, {'uid': '18-3', 'source': '18', 'target': '3', 'weight': 1}, {'uid': '18-16', 'source': '18', 'target': '16', 'weight': 1}, {'uid': '18-17', 'source': '18', 'target': '17', 'weight': 1}, {'uid': '18-19', 'source': '18', 'target': '19', 'weight': 1}, {'uid': '19-53', 'source': '19', 'target': '53', 'weight': 1}, {'uid': '19-20', 'source': '19', 'target': '20', 'weight': 1}, {'uid': '19-17', 'source': '19', 'target': '17', 'weight': 1}, {'uid': '19-18', 'source': '19', 'target': '18', 'weight': 1}, {'uid': '20-19', 'source': '20', 'target': '19', 'weight': 1}, {'uid': '20-31', 'source': '20', 'target': '31', 'weight': 1}, {'uid': '20-70', 'source': '20', 'target': '70', 'weight': 1}, {'uid': '21-22', 'source': '21', 'target': '22', 'weight': 1}, {'uid': '21-23', 'source': '21', 'target': '23', 'weight': 1}, {'uid': '22-21', 'source': '22', 'target': '21', 'weight': 1}, {'uid': '22-23', 'source': '22', 'target': '23', 'weight': 1}, {'uid': '22-24', 'source': '22', 'target': '24', 'weight': 1}, {'uid': '22-77', 'source': '22', 'target': '77', 'weight': 1}, {'uid': '23-22', 'source': '23', 'target': '22', 'weight': 1}, {'uid': '23-25', 'source': '23', 'target': '25', 'weight': 1}, {'uid': '23-24', 'source': '23', 'target': '24', 'weight': 1}, {'uid': '23-21', 'source': '23', 'target': '21', 'weight': 1}, {'uid': '24-22', 'source': '24', 'target': '22', 'weight': 1}, {'uid': '24-23', 'source': '24', 'target': '23', 'weight': 1}, {'uid': '24-25', 'source': '24', 'target': '25', 'weight': 1}, {'uid': '24-26', 'source': '24', 'target': '26', 'weight': 1}, {'uid': '25-23', 'source': '25', 'target': '23', 'weight': 1}, {'uid': '25-24', 'source': '25', 'target': '24', 'weight': 1}, {'uid': '25-26', 'source': '25', 'target': '26', 'weight': 1}, {'uid': '25-27', 'source': '25', 'target': '27', 'weight': 1}, {'uid': '26-28', 'source': '26', 'target': '28', 'weight': 1}, {'uid': '26-24', 'source': '26', 'target': '24', 'weight': 1}, {'uid': '26-25', 'source': '26', 'target': '25', 'weight': 1}, {'uid': '26-27', 'source': '26', 'target': '27', 'weight': 1}, {'uid': '27-25', 'source': '27', 'target': '25', 'weight': 1}, {'uid': '27-26', 'source': '27', 'target': '26', 'weight': 1}, {'uid': '27-28', 'source': '27', 'target': '28', 'weight': 1}, {'uid': '27-29', 'source': '27', 'target': '29', 'weight': 1}, {'uid': '28-26', 'source': '28', 'target': '26', 'weight': 1}, {'uid': '28-27', 'source': '28', 'target': '27', 'weight': 1}, {'uid': '28-29', 'source': '28', 'target': '29', 'weight': 1}, {'uid': '28-45', 'source': '28', 'target': '45', 'weight': 1}, {'uid': '29-30', 'source': '29', 'target': '30', 'weight': 1}, {'uid': '29-31', 'source': '29', 'target': '31', 'weight': 1}, {'uid': '29-28', 'source': '29', 'target': '28', 'weight': 1}, {'uid': '29-27', 'source': '29', 'target': '27', 'weight': 1}, {'uid': '30-29', 'source': '30', 'target': '29', 'weight': 1}, {'uid': '30-31', 'source': '30', 'target': '31', 'weight': 1}, {'uid': '30-32', 'source': '30', 'target': '32', 'weight': 1}, {'uid': '31-20', 'source': '31', 'target': '20', 'weight': 1}, {'uid': '31-29', 'source': '31', 'target': '29', 'weight': 1}, {'uid': '31-30', 'source': '31', 'target': '30', 'weight': 1}, {'uid': '31-32', 'source': '31', 'target': '32', 'weight': 1}, {'uid': '31-33', 'source': '31', 'target': '33', 'weight': 1}, {'uid': '32-31', 'source': '32', 'target': '31', 'weight': 1}, {'uid': '32-34', 'source': '32', 'target': '34', 'weight': 1}, {'uid': '32-33', 'source': '32', 'target': '33', 'weight': 1}, {'uid': '32-30', 'source': '32', 'target': '30', 'weight': 1}, {'uid': '33-32', 'source': '33', 'target': '32', 'weight': 1}, {'uid': '33-34', 'source': '33', 'target': '34', 'weight': 1}, {'uid': '33-35', 'source': '33', 'target': '35', 'weight': 1}, {'uid': '33-31', 'source': '33', 'target': '31', 'weight': 1}, {'uid': '34-32', 'source': '34', 'target': '32', 'weight': 1}, {'uid': '34-33', 'source': '34', 'target': '33', 'weight': 1}, {'uid': '34-35', 'source': '34', 'target': '35', 'weight': 1}, {'uid': '34-71', 'source': '34', 'target': '71', 'weight': 1}, {'uid': '35-36', 'source': '35', 'target': '36', 'weight': 1}, {'uid': '35-37', 'source': '35', 'target': '37', 'weight': 1}, {'uid': '35-34', 'source': '35', 'target': '34', 'weight': 1}, {'uid': '35-33', 'source': '35', 'target': '33', 'weight': 1}, {'uid': '36-35', 'source': '36', 'target': '35', 'weight': 1}, {'uid': '36-37', 'source': '36', 'target': '37', 'weight': 1}, {'uid': '36-38', 'source': '36', 'target': '38', 'weight': 1}, {'uid': '37-35', 'source': '37', 'target': '35', 'weight': 1}, {'uid': '37-36', 'source': '37', 'target': '36', 'weight': 1}, {'uid': '37-38', 'source': '37', 'target': '38', 'weight': 1}, {'uid': '37-39', 'source': '37', 'target': '39', 'weight': 1}, {'uid': '38-39', 'source': '38', 'target': '39', 'weight': 1}, {'uid': '38-89', 'source': '38', 'target': '89', 'weight': 1}, {'uid': '38-36', 'source': '38', 'target': '36', 'weight': 1}, {'uid': '38-37', 'source': '38', 'target': '37', 'weight': 1}, {'uid': '39-38', 'source': '39', 'target': '38', 'weight': 1}, {'uid': '39-40', 'source': '39', 'target': '40', 'weight': 1}, {'uid': '39-41', 'source': '39', 'target': '41', 'weight': 1}, {'uid': '39-37', 'source': '39', 'target': '37', 'weight': 1}, {'uid': '40-39', 'source': '40', 'target': '39', 'weight': 1}, {'uid': '40-41', 'source': '40', 'target': '41', 'weight': 1}, {'uid': '40-42', 'source': '40', 'target': '42', 'weight': 1}, {'uid': '41-48', 'source': '41', 'target': '48', 'weight': 1}, {'uid': '41-43', 'source': '41', 'target': '43', 'weight': 1}, {'uid': '41-42', 'source': '41', 'target': '42', 'weight': 1}, {'uid': '41-40', 'source': '41', 'target': '40', 'weight': 1}, {'uid': '41-39', 'source': '41', 'target': '39', 'weight': 1}, {'uid': '42-40', 'source': '42', 'target': '40', 'weight': 1}, {'uid': '42-41', 'source': '42', 'target': '41', 'weight': 1}, {'uid': '42-44', 'source': '42', 'target': '44', 'weight': 1}, {'uid': '42-70', 'source': '42', 'target': '70', 'weight': 1}, {'uid': '43-41', 'source': '43', 'target': '41', 'weight': 1}, {'uid': '43-44', 'source': '43', 'target': '44', 'weight': 1}, {'uid': '43-45', 'source': '43', 'target': '45', 'weight': 1}, {'uid': '43-72', 'source': '43', 'target': '72', 'weight': 1}, {'uid': '44-46', 'source': '44', 'target': '46', 'weight': 1}, {'uid': '44-45', 'source': '44', 'target': '45', 'weight': 1}, {'uid': '44-42', 'source': '44', 'target': '42', 'weight': 1}, {'uid': '44-43', 'source': '44', 'target': '43', 'weight': 1}, {'uid': '45-28', 'source': '45', 'target': '28', 'weight': 1}, {'uid': '45-43', 'source': '45', 'target': '43', 'weight': 1}, {'uid': '45-44', 'source': '45', 'target': '44', 'weight': 1}, {'uid': '45-46', 'source': '45', 'target': '46', 'weight': 1}, {'uid': '45-47', 'source': '45', 'target': '47', 'weight': 1}, {'uid': '46-44', 'source': '46', 'target': '44', 'weight': 1}, {'uid': '46-45', 'source': '46', 'target': '45', 'weight': 1}, {'uid': '46-47', 'source': '46', 'target': '47', 'weight': 1}, {'uid': '46-48', 'source': '46', 'target': '48', 'weight': 1}, {'uid': '47-46', 'source': '47', 'target': '46', 'weight': 1}, {'uid': '47-49', 'source': '47', 'target': '49', 'weight': 1}, {'uid': '47-48', 'source': '47', 'target': '48', 'weight': 1}, {'uid': '47-45', 'source': '47', 'target': '45', 'weight': 1}, {'uid': '48-41', 'source': '48', 'target': '41', 'weight': 1}, {'uid': '48-46', 'source': '48', 'target': '46', 'weight': 1}, {'uid': '48-47', 'source': '48', 'target': '47', 'weight': 1}, {'uid': '48-49', 'source': '48', 'target': '49', 'weight': 1}, {'uid': '49-47', 'source': '49', 'target': '47', 'weight': 1}, {'uid': '49-48', 'source': '49', 'target': '48', 'weight': 1}, {'uid': '49-50', 'source': '49', 'target': '50', 'weight': 1}, {'uid': '49-51', 'source': '49', 'target': '51', 'weight': 1}, {'uid': '50-58', 'source': '50', 'target': '58', 'weight': 1}, {'uid': '50-52', 'source': '50', 'target': '52', 'weight': 1}, {'uid': '50-49', 'source': '50', 'target': '49', 'weight': 1}, {'uid': '50-51', 'source': '50', 'target': '51', 'weight': 1}, {'uid': '51-50', 'source': '51', 'target': '50', 'weight': 1}, {'uid': '51-52', 'source': '51', 'target': '52', 'weight': 1}, {'uid': '51-53', 'source': '51', 'target': '53', 'weight': 1}, {'uid': '51-49', 'source': '51', 'target': '49', 'weight': 1}, {'uid': '52-50', 'source': '52', 'target': '50', 'weight': 1}, {'uid': '52-51', 'source': '52', 'target': '51', 'weight': 1}, {'uid': '52-53', 'source': '52', 'target': '53', 'weight': 1}, {'uid': '52-54', 'source': '52', 'target': '54', 'weight': 1}, {'uid': '53-19', 'source': '53', 'target': '19', 'weight': 1}, {'uid': '53-51', 'source': '53', 'target': '51', 'weight': 1}, {'uid': '53-52', 'source': '53', 'target': '52', 'weight': 1}, {'uid': '53-54', 'source': '53', 'target': '54', 'weight': 1}, {'uid': '53-55', 'source': '53', 'target': '55', 'weight': 1}, {'uid': '54-52', 'source': '54', 'target': '52', 'weight': 1}, {'uid': '54-56', 'source': '54', 'target': '56', 'weight': 1}, {'uid': '54-55', 'source': '54', 'target': '55', 'weight': 1}, {'uid': '54-53', 'source': '54', 'target': '53', 'weight': 1}, {'uid': '55-53', 'source': '55', 'target': '53', 'weight': 1}, {'uid': '55-54', 'source': '55', 'target': '54', 'weight': 1}, {'uid': '55-56', 'source': '55', 'target': '56', 'weight': 1}, {'uid': '55-57', 'source': '55', 'target': '57', 'weight': 1}, {'uid': '56-54', 'source': '56', 'target': '54', 'weight': 1}, {'uid': '56-55', 'source': '56', 'target': '55', 'weight': 1}, {'uid': '56-57', 'source': '56', 'target': '57', 'weight': 1}, {'uid': '56-58', 'source': '56', 'target': '58', 'weight': 1}, {'uid': '57-55', 'source': '57', 'target': '55', 'weight': 1}, {'uid': '57-88', 'source': '57', 'target': '88', 'weight': 1}, {'uid': '57-56', 'source': '57', 'target': '56', 'weight': 1}, {'uid': '57-58', 'source': '57', 'target': '58', 'weight': 1}, {'uid': '58-50', 'source': '58', 'target': '50', 'weight': 1}, {'uid': '58-56', 'source': '58', 'target': '56', 'weight': 1}, {'uid': '58-57', 'source': '58', 'target': '57', 'weight': 1}, {'uid': '58-60', 'source': '58', 'target': '60', 'weight': 1}, {'uid': '59-60', 'source': '59', 'target': '60', 'weight': 1}, {'uid': '59-61', 'source': '59', 'target': '61', 'weight': 1}, {'uid': '60-62', 'source': '60', 'target': '62', 'weight': 1}, {'uid': '60-61', 'source': '60', 'target': '61', 'weight': 1}, {'uid': '60-59', 'source': '60', 'target': '59', 'weight': 1}, {'uid': '60-58', 'source': '60', 'target': '58', 'weight': 1}, {'uid': '61-59', 'source': '61', 'target': '59', 'weight': 1}, {'uid': '61-60', 'source': '61', 'target': '60', 'weight': 1}, {'uid': '61-62', 'source': '61', 'target': '62', 'weight': 1}, {'uid': '61-63', 'source': '61', 'target': '63', 'weight': 1}, {'uid': '61-73', 'source': '61', 'target': '73', 'weight': 1}, {'uid': '62-60', 'source': '62', 'target': '60', 'weight': 1}, {'uid': '62-61', 'source': '62', 'target': '61', 'weight': 1}, {'uid': '62-63', 'source': '62', 'target': '63', 'weight': 1}, {'uid': '62-64', 'source': '62', 'target': '64', 'weight': 1}, {'uid': '63-61', 'source': '63', 'target': '61', 'weight': 1}, {'uid': '63-65', 'source': '63', 'target': '65', 'weight': 1}, {'uid': '63-62', 'source': '63', 'target': '62', 'weight': 1}, {'uid': '63-64', 'source': '63', 'target': '64', 'weight': 1}, {'uid': '64-63', 'source': '64', 'target': '63', 'weight': 1}, {'uid': '64-65', 'source': '64', 'target': '65', 'weight': 1}, {'uid': '64-66', 'source': '64', 'target': '66', 'weight': 1}, {'uid': '64-62', 'source': '64', 'target': '62', 'weight': 1}, {'uid': '65-63', 'source': '65', 'target': '63', 'weight': 1}, {'uid': '65-64', 'source': '65', 'target': '64', 'weight': 1}, {'uid': '65-66', 'source': '65', 'target': '66', 'weight': 1}, {'uid': '65-67', 'source': '65', 'target': '67', 'weight': 1}, {'uid': '66-68', 'source': '66', 'target': '68', 'weight': 1}, {'uid': '66-67', 'source': '66', 'target': '67', 'weight': 1}, {'uid': '66-65', 'source': '66', 'target': '65', 'weight': 1}, {'uid': '66-64', 'source': '66', 'target': '64', 'weight': 1}, {'uid': '67-65', 'source': '67', 'target': '65', 'weight': 1}, {'uid': '67-66', 'source': '67', 'target': '66', 'weight': 1}, {'uid': '67-68', 'source': '67', 'target': '68', 'weight': 1}, {'uid': '67-69', 'source': '67', 'target': '69', 'weight': 1}, {'uid': '68-66', 'source': '68', 'target': '66', 'weight': 1}, {'uid': '68-67', 'source': '68', 'target': '67', 'weight': 1}, {'uid': '68-70', 'source': '68', 'target': '70', 'weight': 1}, {'uid': '68-97', 'source': '68', 'target': '97', 'weight': 1}, {'uid': '69-71', 'source': '69', 'target': '71', 'weight': 1}, {'uid': '69-70', 'source': '69', 'target': '70', 'weight': 1}, {'uid': '69-67', 'source': '69', 'target': '67', 'weight': 1}, {'uid': '70-20', 'source': '70', 'target': '20', 'weight': 1}, {'uid': '70-42', 'source': '70', 'target': '42', 'weight': 1}, {'uid': '70-68', 'source': '70', 'target': '68', 'weight': 1}, {'uid': '70-69', 'source': '70', 'target': '69', 'weight': 1}, {'uid': '70-71', 'source': '70', 'target': '71', 'weight': 1}, {'uid': '70-72', 'source': '70', 'target': '72', 'weight': 1}, {'uid': '71-73', 'source': '71', 'target': '73', 'weight': 1}, {'uid': '71-72', 'source': '71', 'target': '72', 'weight': 1}, {'uid': '71-70', 'source': '71', 'target': '70', 'weight': 1}, {'uid': '71-69', 'source': '71', 'target': '69', 'weight': 1}, {'uid': '71-34', 'source': '71', 'target': '34', 'weight': 1}, {'uid': '72-43', 'source': '72', 'target': '43', 'weight': 1}, {'uid': '72-70', 'source': '72', 'target': '70', 'weight': 1}, {'uid': '72-71', 'source': '72', 'target': '71', 'weight': 1}, {'uid': '72-73', 'source': '72', 'target': '73', 'weight': 1}, {'uid': '72-95', 'source': '72', 'target': '95', 'weight': 1}, {'uid': '73-61', 'source': '73', 'target': '61', 'weight': 1}, {'uid': '73-71', 'source': '73', 'target': '71', 'weight': 1}, {'uid': '73-72', 'source': '73', 'target': '72', 'weight': 1}, {'uid': '73-74', 'source': '73', 'target': '74', 'weight': 1}, {'uid': '74-76', 'source': '74', 'target': '76', 'weight': 1}, {'uid': '74-73', 'source': '74', 'target': '73', 'weight': 1}, {'uid': '74-75', 'source': '74', 'target': '75', 'weight': 1}, {'uid': '75-76', 'source': '75', 'target': '76', 'weight': 1}, {'uid': '75-74', 'source': '75', 'target': '74', 'weight': 1}, {'uid': '75-77', 'source': '75', 'target': '77', 'weight': 1}, {'uid': '76-7', 'source': '76', 'target': '7', 'weight': 1}, {'uid': '76-74', 'source': '76', 'target': '74', 'weight': 1}, {'uid': '76-75', 'source': '76', 'target': '75', 'weight': 1}, {'uid': '76-77', 'source': '76', 'target': '77', 'weight': 1}, {'uid': '76-78', 'source': '76', 'target': '78', 'weight': 1}, {'uid': '77-22', 'source': '77', 'target': '22', 'weight': 1}, {'uid': '77-75', 'source': '77', 'target': '75', 'weight': 1}, {'uid': '77-76', 'source': '77', 'target': '76', 'weight': 1}, {'uid': '77-78', 'source': '77', 'target': '78', 'weight': 1}, {'uid': '78-77', 'source': '78', 'target': '77', 'weight': 1}, {'uid': '78-80', 'source': '78', 'target': '80', 'weight': 1}, {'uid': '78-79', 'source': '78', 'target': '79', 'weight': 1}, {'uid': '78-76', 'source': '78', 'target': '76', 'weight': 1}, {'uid': '79-4', 'source': '79', 'target': '4', 'weight': 1}, {'uid': '79-78', 'source': '79', 'target': '78', 'weight': 1}, {'uid': '79-81', 'source': '79', 'target': '81', 'weight': 1}, {'uid': '80-78', 'source': '80', 'target': '78', 'weight': 1}, {'uid': '80-81', 'source': '80', 'target': '81', 'weight': 1}, {'uid': '80-82', 'source': '80', 'target': '82', 'weight': 1}, {'uid': '81-83', 'source': '81', 'target': '83', 'weight': 1}, {'uid': '81-82', 'source': '81', 'target': '82', 'weight': 1}, {'uid': '81-79', 'source': '81', 'target': '79', 'weight': 1}, {'uid': '81-80', 'source': '81', 'target': '80', 'weight': 1}, {'uid': '82-80', 'source': '82', 'target': '80', 'weight': 1}, {'uid': '82-81', 'source': '82', 'target': '81', 'weight': 1}, {'uid': '82-83', 'source': '82', 'target': '83', 'weight': 1}, {'uid': '82-84', 'source': '82', 'target': '84', 'weight': 1}, {'uid': '83-81', 'source': '83', 'target': '81', 'weight': 1}, {'uid': '83-82', 'source': '83', 'target': '82', 'weight': 1}, {'uid': '83-84', 'source': '83', 'target': '84', 'weight': 1}, {'uid': '83-85', 'source': '83', 'target': '85', 'weight': 1}, {'uid': '84-85', 'source': '84', 'target': '85', 'weight': 1}, {'uid': '84-86', 'source': '84', 'target': '86', 'weight': 1}, {'uid': '84-83', 'source': '84', 'target': '83', 'weight': 1}, {'uid': '84-82', 'source': '84', 'target': '82', 'weight': 1}, {'uid': '85-83', 'source': '85', 'target': '83', 'weight': 1}, {'uid': '85-84', 'source': '85', 'target': '84', 'weight': 1}, {'uid': '85-86', 'source': '85', 'target': '86', 'weight': 1}, {'uid': '85-87', 'source': '85', 'target': '87', 'weight': 1}, {'uid': '86-84', 'source': '86', 'target': '84', 'weight': 1}, {'uid': '86-85', 'source': '86', 'target': '85', 'weight': 1}, {'uid': '86-87', 'source': '86', 'target': '87', 'weight': 1}, {'uid': '86-88', 'source': '86', 'target': '88', 'weight': 1}, {'uid': '87-89', 'source': '87', 'target': '89', 'weight': 1}, {'uid': '87-88', 'source': '87', 'target': '88', 'weight': 1}, {'uid': '87-85', 'source': '87', 'target': '85', 'weight': 1}, {'uid': '87-86', 'source': '87', 'target': '86', 'weight': 1}, {'uid': '88-86', 'source': '88', 'target': '86', 'weight': 1}, {'uid': '88-87', 'source': '88', 'target': '87', 'weight': 1}, {'uid': '88-89', 'source': '88', 'target': '89', 'weight': 1}, {'uid': '88-90', 'source': '88', 'target': '90', 'weight': 1}, {'uid': '88-57', 'source': '88', 'target': '57', 'weight': 1}, {'uid': '89-38', 'source': '89', 'target': '38', 'weight': 1}, {'uid': '89-87', 'source': '89', 'target': '87', 'weight': 1}, {'uid': '89-88', 'source': '89', 'target': '88', 'weight': 1}, {'uid': '89-90', 'source': '89', 'target': '90', 'weight': 1}, {'uid': '89-91', 'source': '89', 'target': '91', 'weight': 1}, {'uid': '90-91', 'source': '90', 'target': '91', 'weight': 1}, {'uid': '90-92', 'source': '90', 'target': '92', 'weight': 1}, {'uid': '90-89', 'source': '90', 'target': '89', 'weight': 1}, {'uid': '90-88', 'source': '90', 'target': '88', 'weight': 1}, {'uid': '91-89', 'source': '91', 'target': '89', 'weight': 1}, {'uid': '91-90', 'source': '91', 'target': '90', 'weight': 1}, {'uid': '91-92', 'source': '91', 'target': '92', 'weight': 1}, {'uid': '91-93', 'source': '91', 'target': '93', 'weight': 1}, {'uid': '92-90', 'source': '92', 'target': '90', 'weight': 1}, {'uid': '92-91', 'source': '92', 'target': '91', 'weight': 1}, {'uid': '92-93', 'source': '92', 'target': '93', 'weight': 1}, {'uid': '92-94', 'source': '92', 'target': '94', 'weight': 1}, {'uid': '93-95', 'source': '93', 'target': '95', 'weight': 1}, {'uid': '93-92', 'source': '93', 'target': '92', 'weight': 1}, {'uid': '93-91', 'source': '93', 'target': '91', 'weight': 1}, {'uid': '93-94', 'source': '93', 'target': '94', 'weight': 1}, {'uid': '94-92', 'source': '94', 'target': '92', 'weight': 1}, {'uid': '94-93', 'source': '94', 'target': '93', 'weight': 1}, {'uid': '94-96', 'source': '94', 'target': '96', 'weight': 1}, {'uid': '95-72', 'source': '95', 'target': '72', 'weight': 1}, {'uid': '95-93', 'source': '95', 'target': '93', 'weight': 1}, {'uid': '95-97', 'source': '95', 'target': '97', 'weight': 1}, {'uid': '96-8', 'source': '96', 'target': '8', 'weight': 1}, {'uid': '96-94', 'source': '96', 'target': '94', 'weight': 1}, {'uid': '96-97', 'source': '96', 'target': '97', 'weight': 1}, {'uid': '96-98', 'source': '96', 'target': '98', 'weight': 1}, {'uid': '97-68', 'source': '97', 'target': '68', 'weight': 1}, {'uid': '97-99', 'source': '97', 'target': '99', 'weight': 1}, {'uid': '97-98', 'source': '97', 'target': '98', 'weight': 1}, {'uid': '97-96', 'source': '97', 'target': '96', 'weight': 1}, {'uid': '97-95', 'source': '97', 'target': '95', 'weight': 1}, {'uid': '98-0', 'source': '98', 'target': '0', 'weight': 1}, {'uid': '98-96', 'source': '98', 'target': '96', 'weight': 1}, {'uid': '98-97', 'source': '98', 'target': '97', 'weight': 1}, {'uid': '98-99', 'source': '98', 'target': '99', 'weight': 1}, {'uid': '99-0', 'source': '99', 'target': '0', 'weight': 1}, {'uid': '99-1', 'source': '99', 'target': '1', 'weight': 1}, {'uid': '99-97', 'source': '99', 'target': '97', 'weight': 1}, {'uid': '99-98', 'source': '99', 'target': '98', 'weight': 1}], 'nodes': [{'uid': '0'}, {'uid': '1'}, {'uid': '2'}, {'uid': '3'}, {'uid': '4'}, {'uid': '5'}, {'uid': '6'}, {'uid': '7'}, {'uid': '8'}, {'uid': '9'}, {'uid': '10'}, {'uid': '11'}, {'uid': '12'}, {'uid': '13'}, {'uid': '14'}, {'uid': '15'}, {'uid': '16'}, {'uid': '17'}, {'uid': '18'}, {'uid': '19'}, {'uid': '20'}, {'uid': '21'}, {'uid': '22'}, {'uid': '23'}, {'uid': '24'}, {'uid': '25'}, {'uid': '26'}, {'uid': '27'}, {'uid': '28'}, {'uid': '29'}, {'uid': '30'}, {'uid': '31'}, {'uid': '32'}, {'uid': '33'}, {'uid': '34'}, {'uid': '35'}, {'uid': '36'}, {'uid': '37'}, {'uid': '38'}, {'uid': '39'}, {'uid': '40'}, {'uid': '41'}, {'uid': '42'}, {'uid': '43'}, {'uid': '44'}, {'uid': '45'}, {'uid': '46'}, {'uid': '47'}, {'uid': '48'}, {'uid': '49'}, {'uid': '50'}, {'uid': '51'}, {'uid': '52'}, {'uid': '53'}, {'uid': '54'}, {'uid': '55'}, {'uid': '56'}, {'uid': '57'}, {'uid': '58'}, {'uid': '59'}, {'uid': '60'}, {'uid': '61'}, {'uid': '62'}, {'uid': '63'}, {'uid': '64'}, {'uid': '65'}, {'uid': '66'}, {'uid': '67'}, {'uid': '68'}, {'uid': '69'}, {'uid': '70'}, {'uid': '71'}, {'uid': '72'}, {'uid': '73'}, {'uid': '74'}, {'uid': '75'}, {'uid': '76'}, {'uid': '77'}, {'uid': '78'}, {'uid': '79'}, {'uid': '80'}, {'uid': '81'}, {'uid': '82'}, {'uid': '83'}, {'uid': '84'}, {'uid': '85'}, {'uid': '86'}, {'uid': '87'}, {'uid': '88'}, {'uid': '89'}, {'uid': '90'}, {'uid': '91'}, {'uid': '92'}, {'uid': '93'}, {'uid': '94'}, {'uid': '95'}, {'uid': '96'}, {'uid': '97'}, {'uid': '98'}, {'uid': '99'}]}\n</pre> <p>To generate an undirected random graph based on the stochastic block model, we must minimally specify two parameters:</p> <p>The stochastic block matrix $M$ contains edge probabilities for all pairs of nodes where the source and target belong to different blocks.</p> <p>The block assignment vector $z$ assigns nodes to blocks (based on their index). The length of this vector implicitly determined the number of nodes.</p> <p>In the example below, we generate a random graph with eight nodes, where the first four nodes <code>a</code> - <code>d</code> are assigned to block 0 and the last four nodes <code>e</code> - <code>h</code> are assigned to block 1. Edges between node pairs where both nodes are in block 0 are generated with probability $0.95$. If both nodes are in block 1 edges are generated with probability $0.85$. If the nodes are in different blocks, edges are generated with probability $0.1$.</p> In\u00a0[40]: Copied! <pre>M = np.matrix('0.95 0.15; 0.15 0.85')\nprint(M)\nz = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n\ng = pp.algorithms.generative_models.stochastic_block_model(M, z, pp.IndexMap(list('abcdefgh')))\npp.plot(g, node_label=g.nodes, node_color=z.tolist());\n</pre> M = np.matrix('0.95 0.15; 0.15 0.85') print(M) z = np.array([0, 0, 0, 0, 1, 1, 1, 1])  g = pp.algorithms.generative_models.stochastic_block_model(M, z, pp.IndexMap(list('abcdefgh'))) pp.plot(g, node_label=g.nodes, node_color=z.tolist()); <pre>[[0.95 0.15]\n [0.15 0.85]]\n{'edges': [{'uid': 'a-c', 'source': 'a', 'target': 'c', 'weight': 1}, {'uid': 'a-d', 'source': 'a', 'target': 'd', 'weight': 1}, {'uid': 'a-b', 'source': 'a', 'target': 'b', 'weight': 1}, {'uid': 'b-a', 'source': 'b', 'target': 'a', 'weight': 1}, {'uid': 'b-c', 'source': 'b', 'target': 'c', 'weight': 1}, {'uid': 'b-d', 'source': 'b', 'target': 'd', 'weight': 1}, {'uid': 'c-a', 'source': 'c', 'target': 'a', 'weight': 1}, {'uid': 'c-b', 'source': 'c', 'target': 'b', 'weight': 1}, {'uid': 'c-d', 'source': 'c', 'target': 'd', 'weight': 1}, {'uid': 'c-f', 'source': 'c', 'target': 'f', 'weight': 1}, {'uid': 'd-c', 'source': 'd', 'target': 'c', 'weight': 1}, {'uid': 'd-b', 'source': 'd', 'target': 'b', 'weight': 1}, {'uid': 'd-a', 'source': 'd', 'target': 'a', 'weight': 1}, {'uid': 'e-f', 'source': 'e', 'target': 'f', 'weight': 1}, {'uid': 'e-g', 'source': 'e', 'target': 'g', 'weight': 1}, {'uid': 'f-c', 'source': 'f', 'target': 'c', 'weight': 1}, {'uid': 'f-e', 'source': 'f', 'target': 'e', 'weight': 1}, {'uid': 'f-g', 'source': 'f', 'target': 'g', 'weight': 1}, {'uid': 'f-h', 'source': 'f', 'target': 'h', 'weight': 1}, {'uid': 'g-e', 'source': 'g', 'target': 'e', 'weight': 1}, {'uid': 'g-f', 'source': 'g', 'target': 'f', 'weight': 1}, {'uid': 'g-h', 'source': 'g', 'target': 'h', 'weight': 1}, {'uid': 'h-f', 'source': 'h', 'target': 'f', 'weight': 1}, {'uid': 'h-g', 'source': 'h', 'target': 'g', 'weight': 1}], 'nodes': [{'uid': 'a', 'label': 'a', 'color': '#00ff00'}, {'uid': 'b', 'label': 'b', 'color': '#00ff00'}, {'uid': 'c', 'label': 'c', 'color': '#00ff00'}, {'uid': 'd', 'label': 'd', 'color': '#00ff00'}, {'uid': 'e', 'label': 'e', 'color': '#ff0000'}, {'uid': 'f', 'label': 'f', 'color': '#ff0000'}, {'uid': 'g', 'label': 'g', 'color': '#ff0000'}, {'uid': 'h', 'label': 'h', 'color': '#ff0000'}]}\n</pre> <p>To generate a graph with three fully connected cliques, we can specify the parameters as follows:</p> In\u00a0[49]: Copied! <pre>M = np.matrix('1 0 0;0 1 0;0 0 1')\nprint(M)\nz = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\ng = pp.algorithms.generative_models.stochastic_block_model(M, z, pp.IndexMap(list('abcdefghi')))\nprint(g)\npp.plot(g, node_label=g.nodes, node_color=z.tolist());\n</pre> M = np.matrix('1 0 0;0 1 0;0 0 1') print(M) z = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2]) g = pp.algorithms.generative_models.stochastic_block_model(M, z, pp.IndexMap(list('abcdefghi'))) print(g) pp.plot(g, node_label=g.nodes, node_color=z.tolist()); <pre>[[1 0 0]\n [0 1 0]\n [0 0 1]]\nUndirected graph with 9 nodes and 18 (directed) edges\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n{'edges': [{'uid': 'a-c', 'source': 'a', 'target': 'c', 'weight': 1}, {'uid': 'a-b', 'source': 'a', 'target': 'b', 'weight': 1}, {'uid': 'b-a', 'source': 'b', 'target': 'a', 'weight': 1}, {'uid': 'b-c', 'source': 'b', 'target': 'c', 'weight': 1}, {'uid': 'c-a', 'source': 'c', 'target': 'a', 'weight': 1}, {'uid': 'c-b', 'source': 'c', 'target': 'b', 'weight': 1}, {'uid': 'd-e', 'source': 'd', 'target': 'e', 'weight': 1}, {'uid': 'd-f', 'source': 'd', 'target': 'f', 'weight': 1}, {'uid': 'e-f', 'source': 'e', 'target': 'f', 'weight': 1}, {'uid': 'e-d', 'source': 'e', 'target': 'd', 'weight': 1}, {'uid': 'f-d', 'source': 'f', 'target': 'd', 'weight': 1}, {'uid': 'f-e', 'source': 'f', 'target': 'e', 'weight': 1}, {'uid': 'g-h', 'source': 'g', 'target': 'h', 'weight': 1}, {'uid': 'g-i', 'source': 'g', 'target': 'i', 'weight': 1}, {'uid': 'h-g', 'source': 'h', 'target': 'g', 'weight': 1}, {'uid': 'h-i', 'source': 'h', 'target': 'i', 'weight': 1}, {'uid': 'i-g', 'source': 'i', 'target': 'g', 'weight': 1}, {'uid': 'i-h', 'source': 'i', 'target': 'h', 'weight': 1}], 'nodes': [{'uid': 'a', 'label': 'a', 'color': '#00ff00'}, {'uid': 'b', 'label': 'b', 'color': '#00ff00'}, {'uid': 'c', 'label': 'c', 'color': '#00ff00'}, {'uid': 'd', 'label': 'd', 'color': '#7f7f00'}, {'uid': 'e', 'label': 'e', 'color': '#7f7f00'}, {'uid': 'f', 'label': 'f', 'color': '#7f7f00'}, {'uid': 'g', 'label': 'g', 'color': '#ff0000'}, {'uid': 'h', 'label': 'h', 'color': '#ff0000'}, {'uid': 'i', 'label': 'i', 'color': '#ff0000'}]}\n</pre> In\u00a0[55]: Copied! <pre>from pathpyG.algorithms import connected_components\n</pre> from pathpyG.algorithms import connected_components In\u00a0[56]: Copied! <pre>connected_components(g)\n</pre> connected_components(g) Out[56]: <pre>(3, array([0, 0, 0, 1, 1, 1, 2, 2, 2], dtype=int32))</pre>"},{"location":"tutorial/generative_models/#generative-models-for-random-graphs","title":"Generative Models for Random Graphs\u00b6","text":""},{"location":"tutorial/generative_models/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/implementation_concepts/","title":"Implementation Concepts","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n# !pip install torch_geometric\n# !pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch # !pip install torch_geometric # !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[2]: Copied! <pre>import torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.utils import cumsum, degree, sort_edge_index\n\nimport pathpyG as pp\n</pre> import torch from torch_geometric.data import Data from torch_geometric.utils import cumsum, degree, sort_edge_index  import pathpyG as pp In\u00a0[3]: Copied! <pre>mapping = pp.IndexMap(list(\"abcdef\"))\ngraph = pp.Graph.from_edge_index(\n    edge_index=torch.tensor([[0, 1, 3, 4, 2, 2, 5], [2, 2, 5, 5, 3, 4, 0]]), mapping=mapping\n)\npp.plot(graph, node_label=graph.nodes)\n</pre> mapping = pp.IndexMap(list(\"abcdef\")) graph = pp.Graph.from_edge_index(     edge_index=torch.tensor([[0, 1, 3, 4, 2, 2, 5], [2, 2, 5, 5, 3, 4, 0]]), mapping=mapping ) pp.plot(graph, node_label=graph.nodes) Out[3]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd5d0e990f0&gt;</pre> <p>We can create the line graph for this graph using the <code>lift_order_edge_index</code> function as follows:</p> In\u00a0[4]: Copied! <pre>second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=graph.data.edge_index, num_nodes=graph.n)\nsecond_order_mapping = pp.IndexMap(graph.edges)\nsecond_order_data = Data(edge_index=second_order_edge_index, node_sequence=graph.data.edge_index.t())\nline_graph = pp.Graph(data=second_order_data, mapping=second_order_mapping)\npp.plot(line_graph, node_label=line_graph.nodes)\n</pre> second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=graph.data.edge_index, num_nodes=graph.n) second_order_mapping = pp.IndexMap(graph.edges) second_order_data = Data(edge_index=second_order_edge_index, node_sequence=graph.data.edge_index.t()) line_graph = pp.Graph(data=second_order_data, mapping=second_order_mapping) pp.plot(line_graph, node_label=line_graph.nodes) Out[4]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee1930&gt;</pre> <p>To create the higher-order <code>PathpyG.Graph</code>, we needed to specify a <code>node_sequence</code> in the <code>Data</code> object. The node sequence above was given by the original edges of the graph. This <code>node_sequence</code> keeps track of which original nodes correspond to which higher-order nodes in the higher-order graph. In a second order graph, each higher-order node corresponds to an edge in the original graph. In a graph of order k, each higher-order node corresponds to a path of length k in the original graph. With this, we can always trace back which higher-order node corresponds to which original nodes.</p> <p>As long as we have this mapping from higher-order nodes to original nodes, we can always do an additional line graph transformation to create even higher order graphs. Below, we create a third-order graph:</p> In\u00a0[5]: Copied! <pre>third_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=line_graph.data.edge_index, num_nodes=line_graph.n)\nthird_order_data = Data(edge_index=third_order_edge_index, node_sequence=torch.cat([line_graph.data.node_sequence[line_graph.data.edge_index[0]], line_graph.data.node_sequence[line_graph.data.edge_index[1]][:, -1:]], dim=1))\nthird_order_mapping = pp.IndexMap([tuple(seq) for seq in graph.mapping.to_ids(third_order_data.node_sequence).tolist()])\nthird_order_graph = pp.Graph(data=third_order_data, mapping=third_order_mapping)\npp.plot(third_order_graph, node_label=third_order_graph.nodes)\n</pre> third_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=line_graph.data.edge_index, num_nodes=line_graph.n) third_order_data = Data(edge_index=third_order_edge_index, node_sequence=torch.cat([line_graph.data.node_sequence[line_graph.data.edge_index[0]], line_graph.data.node_sequence[line_graph.data.edge_index[1]][:, -1:]], dim=1)) third_order_mapping = pp.IndexMap([tuple(seq) for seq in graph.mapping.to_ids(third_order_data.node_sequence).tolist()]) third_order_graph = pp.Graph(data=third_order_data, mapping=third_order_mapping) pp.plot(third_order_graph, node_label=third_order_graph.nodes) Out[5]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee3070&gt;</pre> <p>Note that above, we constructed the <code>node_sequence</code> for the third-order graph by concatenating the sequences of the two nodes that form each edge in the second-order graph. However, only the first node in the sequence of the higher-order source and the last node in the sequence of the higher-order target node are different. The middle nodes are the same for both higher-order nodes since they represent the overlapping part of the paths.</p> In\u00a0[6]: Copied! <pre>def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int ) -&gt; torch.Tensor:\n    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n    outdegree_per_dst = outdegree[edge_index[1]]\n    num_new_edges = outdegree_per_dst.sum()\n    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n    ptrs = cumsum(outdegree, dim=0)[:-1]\n    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n    idx_correction = torch.arange(num_new_edges, dtype=torch.long)\n    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n    ho_edge_dsts += idx_correction\n    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)\n</pre> def lift_order_edge_index(edge_index: torch.Tensor, num_nodes: int ) -&gt; torch.Tensor:     outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)     outdegree_per_dst = outdegree[edge_index[1]]     num_new_edges = outdegree_per_dst.sum()     ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)     ptrs = cumsum(outdegree, dim=0)[:-1]     ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)     idx_correction = torch.arange(num_new_edges, dtype=torch.long)     idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]     ho_edge_dsts += idx_correction     return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0) <p>However, what the function does exactly is obfuscated by the heavy use of tensor operations. Let us break down the function step-by-step to understand what is happening internally.</p> <p>Note</p> <p>         Due to the high complexity of the tensor operations, we will maintain to lines of explanations that try to explain the same concepts with different words. One explanation line will be added to the code snippets as comments and the other explanation line will be provided in the markdown cells between the code snippets.     </p> <p>Edge index must be sorted!</p> <p>     The <code>lift_order_edge_index</code> function assumes that the input <code>edge_index</code> is sorted by source nodes. This is not enforced by the function itself, because we ensure that the edge indices are sorted whenever we create a <code>PathpyG.Graph</code> object. This step is crucial for the correct functioning of the <code>lift_order_edge_index</code> function.     </p> <ol> <li>The function first computes the outdegree of each node in the graph using the <code>degree</code> function from <code>torch_geometric.utils</code>. This gives us a tensor containing the number of outgoing edges for each node.</li> </ol> In\u00a0[7]: Copied! <pre># Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge\noutdegree = degree(graph.data.edge_index[0], dtype=torch.long, num_nodes=graph.n)\nprint(\"Outdegree per node:\")\nfor node in graph.nodes:\n    print(f\"\\t{node}: {outdegree[graph.mapping.to_idx(node)].item()}\")\n</pre> # Compute the outdegree of each node used to get all the edge combinations leading to a higher-order edge outdegree = degree(graph.data.edge_index[0], dtype=torch.long, num_nodes=graph.n) print(\"Outdegree per node:\") for node in graph.nodes:     print(f\"\\t{node}: {outdegree[graph.mapping.to_idx(node)].item()}\") <pre>Outdegree per node:\n\ta: 1\n\tb: 1\n\tc: 2\n\td: 1\n\te: 1\n\tf: 1\n</pre> <ol> <li>Next, we map the outdegree values to the destination nodes of each edge in the edge index. This gives us a tensor where each entry corresponds to the outdegree of the target node of each edge.</li> </ol> <p>Note</p> <p>         This helps us because for the line graph transformation, we need to transform each edge into a node and then connect these nodes (previously edges) if a node in the original graph connects them. Therefore, we need to create a higher-order edge for each combination of incoming and outgoing edges for each node in the original graph. The outdegree of the target node tells us how many outgoing edges there are for each target node, which directly translates to how many higher-order edges we need to create for each incoming edge.     </p> In\u00a0[8]: Copied! <pre># For each center node, we need to combine each outgoing edge with each incoming edge\n# We achieve this by creating `outdegree` number of edges for each destination node \n# of the old edge index\noutdegree_per_dst = outdegree[graph.data.edge_index[1]]\nprint(\"\\nOutdegree per destination node of each edge:\")\nfor e, outdeg in zip(graph.edges, outdegree_per_dst.tolist()):\n    print(f\"\\t{e}: {outdeg}\")\n</pre> # For each center node, we need to combine each outgoing edge with each incoming edge # We achieve this by creating `outdegree` number of edges for each destination node  # of the old edge index outdegree_per_dst = outdegree[graph.data.edge_index[1]] print(\"\\nOutdegree per destination node of each edge:\") for e, outdeg in zip(graph.edges, outdegree_per_dst.tolist()):     print(f\"\\t{e}: {outdeg}\") <pre>\nOutdegree per destination node of each edge:\n\t('a', 'c'): 2\n\t('b', 'c'): 2\n\t('c', 'd'): 1\n\t('c', 'e'): 1\n\t('d', 'f'): 1\n\t('e', 'f'): 1\n\t('f', 'a'): 1\n</pre> <ol> <li>Next, we create the source nodes for the higher-order graph. For this, we create a new index that maps the original edges to its index as a higher-order node. This is done by creating a range from 0 to the number of edges in the original graph. We then repeat each index according to the outdegree of the corresponding target node. This way, we create a source node for each combination of incoming and outgoing edges for each target node, which will be the edges in the higher-order graph.</li> </ol> In\u00a0[9]: Copied! <pre># Use each edge from the edge index as node and assign the new indices in the order of the original edge index\n# Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n# Since we keep the ordering, we can just repeat each node using the `outdegree_per_dst` tensor\nho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\nprint(\"\\nHigher-order edge source indices:\\n\", ho_edge_srcs.tolist())\nprint(\"Higher-order edge sources:\\n\", graph.mapping.to_ids(graph.data.edge_index[:, ho_edge_srcs]).T)\n</pre> # Use each edge from the edge index as node and assign the new indices in the order of the original edge index # Each higher order node has one outgoing edge for each outgoing edge of the original destination node # Since we keep the ordering, we can just repeat each node using the `outdegree_per_dst` tensor ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst) print(\"\\nHigher-order edge source indices:\\n\", ho_edge_srcs.tolist()) print(\"Higher-order edge sources:\\n\", graph.mapping.to_ids(graph.data.edge_index[:, ho_edge_srcs]).T) <pre>\nHigher-order edge source indices:\n [0, 0, 1, 1, 2, 3, 4, 5, 6]\nHigher-order edge sources:\n [['a' 'c']\n ['a' 'c']\n ['b' 'c']\n ['b' 'c']\n ['c' 'd']\n ['c' 'e']\n ['d' 'f']\n ['e' 'f']\n ['f' 'a']]\n</pre> <ol> <li>Now, we need to create the target nodes for the higher-order edges. For this, we first need to know where the edges of each node start in the original edge index. We can compute this by calculating the cumulative sum of the outdegree values of all nodes. This gives us a tensor where each entry corresponds to the starting index of the edges for each node in the original edge index.</li> </ol> <p>Cumulative Sum</p> <p>         There is one <code>cumsum</code> implementation in PyTorch and one in PyTorch Geometric. The one in PyTorch Geometric starts with an initial zero value, while the one in PyTorch does not. This means that the <code>torch.cumsum</code> function will give us the end pointers of the edges for each node, while the <code>torch_geometric.utils.cumsum</code> function will give us the start pointers (including a last pointer that is equal to the total number of edges). Therefore, we use the <code>torch_geometric.utils.cumsum</code> function here and remove the last entry afterwards.     </p> In\u00a0[10]: Copied! <pre># For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges\n# (new higher-order nodes) that have the node as source node\nptrs = cumsum(outdegree, dim=0)[:-1]\nprint(\"Edge start pointers per node:\\n\", ptrs.tolist())\n</pre> # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges # (new higher-order nodes) that have the node as source node ptrs = cumsum(outdegree, dim=0)[:-1] print(\"Edge start pointers per node:\\n\", ptrs.tolist()) <pre>Edge start pointers per node:\n [0, 1, 2, 4, 5, 6]\n</pre> <ol> <li>With the starting pointers of the edges for each node, we can start with the creation of the target nodes for the higher-order edges. Remember that we assigned the node indices based on the order of edges in the original edge index and ordered the higher-order source nodes accordingly. Therefore, we are essentially going through each edge, and combine it with each outgoing edge of the edges target node to create the higher-order edges. Since the edges are ordered by source nodes, we are going through all nodes in the original graph in order by going through each outgoing edge of each node. This means that for each edge in the original graph, we can look up where the outgoing edges of its target node start in the original edge index using the <code>ptrs</code> tensor we created in the previous step. We then repeat these starting pointers according to the outdegree of the corresponding target node to create a target node for each combination of incoming and outgoing edges for each target node.</li> </ol> In\u00a0[11]: Copied! <pre># Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times\n# Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively\nho_edge_dsts = torch.repeat_interleave(ptrs[graph.data.edge_index[1]], outdegree_per_dst)\nprint(\"Higher-order edge destination indices (before correction):\\n\", ho_edge_dsts.tolist())\n</pre> # Use these pointers to get the start of the edges for each higher-order src and repeat it `outdegree` times # Since we keep the ordering, all new higher-order edges that have the same src are indexed consecutively ho_edge_dsts = torch.repeat_interleave(ptrs[graph.data.edge_index[1]], outdegree_per_dst) print(\"Higher-order edge destination indices (before correction):\\n\", ho_edge_dsts.tolist()) <pre>Higher-order edge destination indices (before correction):\n [2, 2, 2, 2, 4, 5, 6, 6, 0]\n</pre> <ol> <li>For now, we do not have the correct indices for the higher-order target nodes yet. Since we only repeated the starting pointers of the edges for each target node, we only have the correct offsets for each group of higher-order edges corresponding to each target node. However, within each group, we need to assign the correct indices to the higher-order target nodes. Luckily, we only need to count up from the starting pointer for each group corresponding to one incoming edge in the original graph due to the ordering of the edges. For this, we create a correction index that counts up from 0 to the total number of higher-order edges.</li> </ol> In\u00a0[12]: Copied! <pre># Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...)\n# for all `outdegree` number of edges consecutively to get the correct destination nodes\n# We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\nidx_correction = torch.arange(ho_edge_srcs.size(0), dtype=torch.long)\nprint(\"Index correction (before adjustment):\\n\", idx_correction.tolist())\n</pre> # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) # for all `outdegree` number of edges consecutively to get the correct destination nodes # We can achieve this by starting with a range from (0, 1, ..., num_new_edges) idx_correction = torch.arange(ho_edge_srcs.size(0), dtype=torch.long) print(\"Index correction (before adjustment):\\n\", idx_correction.tolist()) <pre>Index correction (before adjustment):\n [0, 1, 2, 3, 4, 5, 6, 7, 8]\n</pre> <ol> <li>We then subtract the cumulative sum of the outdegree values of the higher-order source nodes from this correction index. This effectively resets the counting for each group of higher-order edges corresponding to each target node.</li> </ol> In\u00a0[13]: Copied! <pre># Then, we subtract the cumulative sum of the outdegree for each destination node\nidx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\nprint(\"Index correction (after adjustment):\\n\", idx_correction.tolist())\n</pre> # Then, we subtract the cumulative sum of the outdegree for each destination node idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs] print(\"Index correction (after adjustment):\\n\", idx_correction.tolist()) <pre>Index correction (after adjustment):\n [0, 1, 0, 1, 0, 0, 0, 0, 0]\n</pre> <ol> <li>Finally, we add this correction index to the starting pointers of the edges for each target node to get the correct indices for the higher-order target nodes.</li> </ol> In\u00a0[14]: Copied! <pre># Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge        \nho_edge_dsts += idx_correction\nprint(\"Higher-order edge destination indices (after correction):\\n\", ho_edge_dsts.tolist())\nprint(\"Higher-order edge destinations:\\n\", graph.mapping.to_ids(graph.data.edge_index[:, ho_edge_dsts]).T)\n</pre> # Add this tensor to the destination nodes to get the correct destination nodes for each higher-order edge         ho_edge_dsts += idx_correction print(\"Higher-order edge destination indices (after correction):\\n\", ho_edge_dsts.tolist()) print(\"Higher-order edge destinations:\\n\", graph.mapping.to_ids(graph.data.edge_index[:, ho_edge_dsts]).T) <pre>Higher-order edge destination indices (after correction):\n [2, 3, 2, 3, 4, 5, 6, 6, 0]\nHigher-order edge destinations:\n [['c' 'd']\n ['c' 'e']\n ['c' 'd']\n ['c' 'e']\n ['d' 'f']\n ['e' 'f']\n ['f' 'a']\n ['f' 'a']\n ['a' 'c']]\n</pre> <p>This gives us the final higher-order edge index that we can return from the function.</p> In\u00a0[15]: Copied! <pre>tedges = [\n    (\"a\", \"b\", 1),\n    (\"a\", \"b\", 2),\n    (\"b\", \"a\", 3),\n    (\"b\", \"c\", 3),\n    (\"d\", \"c\", 4),\n    (\"a\", \"b\", 4),\n    (\"c\", \"b\", 4),\n    (\"c\", \"d\", 5),\n    (\"b\", \"a\", 5),\n    (\"c\", \"b\", 6),\n]\nt = pp.TemporalGraph.from_edge_list(tedges)\npp.plot(t, node_label=t.nodes)\n</pre> tedges = [     (\"a\", \"b\", 1),     (\"a\", \"b\", 2),     (\"b\", \"a\", 3),     (\"b\", \"c\", 3),     (\"d\", \"c\", 4),     (\"a\", \"b\", 4),     (\"c\", \"b\", 4),     (\"c\", \"d\", 5),     (\"b\", \"a\", 5),     (\"c\", \"b\", 6), ] t = pp.TemporalGraph.from_edge_list(tedges) pp.plot(t, node_label=t.nodes) Out[15]: <pre>&lt;pathpyG.visualisations.network_plots.TemporalNetworkPlot at 0x7fd5d0e98160&gt;</pre> <p>We can create a second-order graph from this temporal graph using the <code>lift_order_temporal</code> function. This second-order graph is typically referred to as an event graph. Each node in the graph is an event (edge) in the original temporal graph and two events are connected if they can follow each other in time respecting a maximum time difference <code>delta</code>. Here, we set <code>delta=2</code> which means that two events can be connected if the time difference between them is at most 2 time units.</p> In\u00a0[16]: Copied! <pre>event_edge_index = pp.algorithms.temporal.lift_order_temporal(t, delta=2)\nevent_mapping = pp.IndexMap(t.temporal_edges)\nevent_data = Data(edge_index=event_edge_index, node_sequence=graph.data.edge_index.t())\nevent_graph = pp.Graph(data=event_data, mapping=event_mapping)\npp.plot(event_graph, node_label=event_graph.nodes)\n</pre> event_edge_index = pp.algorithms.temporal.lift_order_temporal(t, delta=2) event_mapping = pp.IndexMap(t.temporal_edges) event_data = Data(edge_index=event_edge_index, node_sequence=graph.data.edge_index.t()) event_graph = pp.Graph(data=event_data, mapping=event_mapping) pp.plot(event_graph, node_label=event_graph.nodes) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 3495.74it/s]\n</pre> Out[16]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee3eb0&gt;</pre> <p>Starting with the event graph, we have a static higher-order representation of the temporal graph that we can use to create higher-order models. For each following lift-order transformations, we can use the same principles as described in the previous section on order-lifting and line graph transformations.</p> In\u00a0[17]: Copied! <pre>def filter_time_respecting_edges(event_edge_index: torch.Tensor, timestamps: torch.Tensor, delta: int) -&gt; torch.Tensor:\n    # Subtract timestamps of the two events to get the time difference\n    time_diff = timestamps[event_edge_index[1]] - timestamps[event_edge_index[0]]\n    # Create masks for filtering\n    # Remove non-time-respecting higher-order edges\n    non_negative_mask = time_diff &gt; 0\n    # Remove edges that are too far apart in time based on delta\n    delta_mask = time_diff &lt;= delta\n    # Combine masks to get the final time-respecting edges\n    time_respecting_mask = non_negative_mask &amp; delta_mask\n    # Filter the event_edge_index using the time_respecting_mask\n    return event_edge_index[:, time_respecting_mask]\n</pre> def filter_time_respecting_edges(event_edge_index: torch.Tensor, timestamps: torch.Tensor, delta: int) -&gt; torch.Tensor:     # Subtract timestamps of the two events to get the time difference     time_diff = timestamps[event_edge_index[1]] - timestamps[event_edge_index[0]]     # Create masks for filtering     # Remove non-time-respecting higher-order edges     non_negative_mask = time_diff &gt; 0     # Remove edges that are too far apart in time based on delta     delta_mask = time_diff &lt;= delta     # Combine masks to get the final time-respecting edges     time_respecting_mask = non_negative_mask &amp; delta_mask     # Filter the event_edge_index using the time_respecting_mask     return event_edge_index[:, time_respecting_mask] <p>We can combine the above filter function with the <code>lift_order_edge_index</code> function to create a lift-order function for temporal graphs as follows:</p> <p>Warning</p> <p>     If we use the standard <code>lift_order_edge_index</code> function, we need to ensure that the input edge index is sorted by source nodes because the <code>edge_index</code> of a <code>TemporalGraph</code> is sorted by time and not by source nodes.     </p> In\u00a0[18]: Copied! <pre># Sort by source node indices\nsorted_edge_index, time = sort_edge_index(t.data.edge_index.as_tensor(), t.data.time)\n# Lift the edge index to the second order\nsecond_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=sorted_edge_index, num_nodes=t.n)\n# Filter the edges based on the lifted edge index\nfiltered_edge_index = filter_time_respecting_edges(second_order_edge_index, timestamps=time, delta=2)\n# Create `pp.Graph` from the filtered edge index\nfiltered_event_mapping = pp.IndexMap([tuple([*t.mapping.to_ids(edge).tolist(), timestamp.item()]) for edge, timestamp in zip(sorted_edge_index.t(), time)])\nfiltered_event_data = Data(edge_index=filtered_edge_index, node_sequence=sorted_edge_index.t())\nfiltered_event_graph = pp.Graph(data=filtered_event_data, mapping=filtered_event_mapping)\npp.plot(filtered_event_graph, node_label=filtered_event_graph.nodes)\n</pre> # Sort by source node indices sorted_edge_index, time = sort_edge_index(t.data.edge_index.as_tensor(), t.data.time) # Lift the edge index to the second order second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(edge_index=sorted_edge_index, num_nodes=t.n) # Filter the edges based on the lifted edge index filtered_edge_index = filter_time_respecting_edges(second_order_edge_index, timestamps=time, delta=2) # Create `pp.Graph` from the filtered edge index filtered_event_mapping = pp.IndexMap([tuple([*t.mapping.to_ids(edge).tolist(), timestamp.item()]) for edge, timestamp in zip(sorted_edge_index.t(), time)]) filtered_event_data = Data(edge_index=filtered_edge_index, node_sequence=sorted_edge_index.t()) filtered_event_graph = pp.Graph(data=filtered_event_data, mapping=filtered_event_mapping) pp.plot(filtered_event_graph, node_label=filtered_event_graph.nodes) Out[18]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee0400&gt;</pre> <p>Note</p> <p>         The indexing of the above implementation is different from the one currently implemented in PathpyG. So while the illustrations look identical, the actual indices of the higher-order nodes will differ.     </p> <p>However, the above implementation has a large memory consumption for graphs with many edges because the full higher-order edge index is created before filtering. Therefore, we implement a more memory-efficient version in PathpyG that constructs the higher-order edges from the temporal graph sequentially for each timestamp. This implementation looks as follows:</p> In\u00a0[19]: Copied! <pre>def lift_order_temporal(g: pp.TemporalGraph, delta: int = 1):\n    indices = torch.arange(0, g.data.edge_index.size(1))\n\n    unique_t = torch.unique(g.data.time)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for t in unique_t:\n\n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = g.data.time == t\n        src_edge_idx = indices[src_time_mask]\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (g.data.time &gt; t) &amp; (g.data.time &lt;= t + delta)\n        dst_edge_idx = indices[dst_time_mask]\n\n        if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n            # compute second-order edges between src and dst idx\n            # create all possible combinations of src and dst edges\n            x = torch.cartesian_prod(src_edge_idx, dst_edge_idx)\n            # filter combinations for real higher-order edges\n            # for all edges where dst in src_edges (g.data.edge_index[1, x[:, 0]]) matches src in dst_edges (g.data.edge_index[0, x[:, 1]])\n            ho_edge_index = x[g.data.edge_index[1, x[:, 0]] == g.data.edge_index[0, x[:, 1]]]\n            second_order.append(ho_edge_index)\n\n    ho_index = torch.cat(second_order, dim=0).t().contiguous()\n    return ho_index\n</pre> def lift_order_temporal(g: pp.TemporalGraph, delta: int = 1):     indices = torch.arange(0, g.data.edge_index.size(1))      unique_t = torch.unique(g.data.time)     second_order = []      # lift order: find possible continuations for edges in each time stamp     for t in unique_t:          # find indices of all source edges that occur at unique timestamp t         src_time_mask = g.data.time == t         src_edge_idx = indices[src_time_mask]          # find indices of all edges that can possibly continue edges occurring at time t for the given delta         dst_time_mask = (g.data.time &gt; t) &amp; (g.data.time &lt;= t + delta)         dst_edge_idx = indices[dst_time_mask]          if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:             # compute second-order edges between src and dst idx             # create all possible combinations of src and dst edges             x = torch.cartesian_prod(src_edge_idx, dst_edge_idx)             # filter combinations for real higher-order edges             # for all edges where dst in src_edges (g.data.edge_index[1, x[:, 0]]) matches src in dst_edges (g.data.edge_index[0, x[:, 1]])             ho_edge_index = x[g.data.edge_index[1, x[:, 0]] == g.data.edge_index[0, x[:, 1]]]             second_order.append(ho_edge_index)      ho_index = torch.cat(second_order, dim=0).t().contiguous()     return ho_index <p>Note that above we do not use the same indexing trick that is used in the standard <code>lift_order_edge_index</code> function. Instead, we create all possible combinations of incoming and outgoing edges for all incoming edges at each timestamp. Therefore, we need a filtering step afterwards to ensure that only valid higher-order edges are created. However, we can skip the sorting step beforehand because we create all possible edge combinations using the cartesian product.</p> <p>It is also possible to combine both approaches, i.e., we create the higher-order edges for each timestamp separately using the indexing trick from the standard <code>lift_order_edge_index</code> function. While it saves the filtering step, it again requires sorting the edges beforehand which has been shown to be similar in performance to the above method. The code would look as follows:</p> In\u00a0[20]: Copied! <pre>def lift_order_temporal_combined(g: pp.TemporalGraph, delta: int = 1):\n    indices = torch.arange(0, g.data.edge_index.size(1))\n\n    unique_t = torch.unique(g.data.time)\n    second_order = []\n\n    # lift order: find possible continuations for edges in each time stamp\n    for i in range(unique_t.size(0)):\n        t = unique_t[i]\n\n        # find indices of all source edges that occur at unique timestamp t\n        src_time_mask = g.data.time == t\n        src_edge_idx = indices[src_time_mask]\n\n        # find indices of all edges that can possibly continue edges occurring at time t for the given delta\n        dst_time_mask = (g.data.time &gt; t) &amp; (g.data.time &lt;= t + delta)\n        dst_node_mask = torch.isin(g.data.edge_index[0], g.data.edge_index[1, src_edge_idx])\n        dst_edge_idx = indices[dst_time_mask &amp; dst_node_mask]\n\n        if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n            # get sorted dst edges for efficient processing\n            src_edges = g.data.edge_index[:, src_edge_idx]\n            dst_edges = g.data.edge_index[:, dst_edge_idx]\n            sorted_idx = torch.argsort(dst_edges[0])\n            dst_edge_idx = dst_edge_idx[sorted_idx]\n            dst_edges = dst_edges[:, sorted_idx]\n\n            # Use indexing trick to create higher-order edges\n            outdegree = degree(dst_edges[0], dtype=torch.long, num_nodes=g.n)\n            outdegree_per_dst = outdegree[src_edges[1]]\n            num_new_edges = outdegree_per_dst.sum()\n            ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n            ptrs = cumsum(outdegree, dim=0)[:-1]\n            ho_edge_dsts = torch.repeat_interleave(ptrs[src_edges[1]], outdegree_per_dst)\n            idx_correction = torch.arange(num_new_edges, dtype=torch.long)\n            idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n            ho_edge_dsts += idx_correction\n            second_order.append(torch.stack([src_edge_idx[ho_edge_srcs], dst_edge_idx[ho_edge_dsts]], dim=0))\n\n    ho_index = torch.cat(second_order, dim=1)\n    return ho_index\n</pre> def lift_order_temporal_combined(g: pp.TemporalGraph, delta: int = 1):     indices = torch.arange(0, g.data.edge_index.size(1))      unique_t = torch.unique(g.data.time)     second_order = []      # lift order: find possible continuations for edges in each time stamp     for i in range(unique_t.size(0)):         t = unique_t[i]          # find indices of all source edges that occur at unique timestamp t         src_time_mask = g.data.time == t         src_edge_idx = indices[src_time_mask]          # find indices of all edges that can possibly continue edges occurring at time t for the given delta         dst_time_mask = (g.data.time &gt; t) &amp; (g.data.time &lt;= t + delta)         dst_node_mask = torch.isin(g.data.edge_index[0], g.data.edge_index[1, src_edge_idx])         dst_edge_idx = indices[dst_time_mask &amp; dst_node_mask]          if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:             # get sorted dst edges for efficient processing             src_edges = g.data.edge_index[:, src_edge_idx]             dst_edges = g.data.edge_index[:, dst_edge_idx]             sorted_idx = torch.argsort(dst_edges[0])             dst_edge_idx = dst_edge_idx[sorted_idx]             dst_edges = dst_edges[:, sorted_idx]              # Use indexing trick to create higher-order edges             outdegree = degree(dst_edges[0], dtype=torch.long, num_nodes=g.n)             outdegree_per_dst = outdegree[src_edges[1]]             num_new_edges = outdegree_per_dst.sum()             ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)             ptrs = cumsum(outdegree, dim=0)[:-1]             ho_edge_dsts = torch.repeat_interleave(ptrs[src_edges[1]], outdegree_per_dst)             idx_correction = torch.arange(num_new_edges, dtype=torch.long)             idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]             ho_edge_dsts += idx_correction             second_order.append(torch.stack([src_edge_idx[ho_edge_srcs], dst_edge_idx[ho_edge_dsts]], dim=0))      ho_index = torch.cat(second_order, dim=1)     return ho_index <p>In contrast to the <code>lift_order_edge_index</code> implementation, the temporal version splits the edges into source and destination edges based on timestamps. For each timestamp, we select the edges that occur at that timestamp as source edges and all edges that occur at later timestamps (within the delta time window) as destination edges. Then, instead of repeating the higher-order source nodes for all edges, we only repeat them for the destination edges.</p> In\u00a0[21]: Copied! <pre>path_mapping = pp.IndexMap(list(\"abcde\"))\npaths = pp.PathData(mapping=path_mapping)\npaths.append_walk(list(\"ab\"))\npaths.append_walk(list(\"abd\"))\npaths.append_walk(list(\"abec\"))\npaths.append_walk(list(\"dbecb\"))\npp.plot(\n    pp.Graph.from_edge_index(paths.data.edge_index), node_label=paths.mapping.to_ids(paths.data.node_sequence).tolist()\n)\n</pre> path_mapping = pp.IndexMap(list(\"abcde\")) paths = pp.PathData(mapping=path_mapping) paths.append_walk(list(\"ab\")) paths.append_walk(list(\"abd\")) paths.append_walk(list(\"abec\")) paths.append_walk(list(\"dbecb\")) pp.plot(     pp.Graph.from_edge_index(paths.data.edge_index), node_label=paths.mapping.to_ids(paths.data.node_sequence).tolist() ) Out[21]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee34c0&gt;</pre> <p><code>pp.PathData</code> is the core class for working with paths in PathpyG. It allows us to gather a collection of paths that are all walks on the same underlying graph. All paths are stored using one <code>edge_index</code> internally. Thus, two nodes in a path that both correspond to the same node in the underlying graph will not share the same index in the path graph. Instead, each occurrence of a node in a path is represented by a separate node in the path graph. This allows us to represent paths that visit the same node multiple times without ambiguity. The information about the underlying graph is stored in the internal <code>PathData.data.node_sequence</code> tensor, similar to higher-order graphs. Let us look at the example above to illustrate this:</p> In\u00a0[22]: Copied! <pre>print(\"The paths represented using edge index look as follows:\")\nfor edge in paths.data.edge_index.t():\n    print(\n        f\"\\tInternal {edge.tolist()}: Underlying graph edge {paths.mapping.to_ids(paths.data.node_sequence[edge].view(-1)).tolist()}\"\n    )\n</pre> print(\"The paths represented using edge index look as follows:\") for edge in paths.data.edge_index.t():     print(         f\"\\tInternal {edge.tolist()}: Underlying graph edge {paths.mapping.to_ids(paths.data.node_sequence[edge].view(-1)).tolist()}\"     ) <pre>The paths represented using edge index look as follows:\n\tInternal [0, 1]: Underlying graph edge ['a', 'b']\n\tInternal [2, 3]: Underlying graph edge ['a', 'b']\n\tInternal [3, 4]: Underlying graph edge ['b', 'd']\n\tInternal [5, 6]: Underlying graph edge ['a', 'b']\n\tInternal [6, 7]: Underlying graph edge ['b', 'e']\n\tInternal [7, 8]: Underlying graph edge ['e', 'c']\n\tInternal [9, 10]: Underlying graph edge ['d', 'b']\n\tInternal [10, 11]: Underlying graph edge ['b', 'e']\n\tInternal [11, 12]: Underlying graph edge ['e', 'c']\n\tInternal [12, 13]: Underlying graph edge ['c', 'b']\n</pre> <p><code>PathData</code> additionally stores some metadata about the paths so that you can easily access information about which nodes belong to which path. This includes</p> <ul> <li><code>dag_weight</code>: A tensor that stores the weight of each path (i.e., the number of times the path was observed).</li> <li><code>dag_num_edges</code>: A tensor that stores the number of edges in each path.</li> <li><code>dag_num_nodes</code>: A tensor that stores the number of nodes in each path.</li> </ul> <p>Using this information, you can, e.g., access the second path in the collection as follows:</p> In\u00a0[23]: Copied! <pre>start = paths.data.dag_num_nodes[:1].sum().item()\nend = start + paths.data.dag_num_nodes[1].item()\npaths.mapping.to_ids(paths.data.node_sequence[start:end].view(-1)).tolist()\n</pre> start = paths.data.dag_num_nodes[:1].sum().item() end = start + paths.data.dag_num_nodes[1].item() paths.mapping.to_ids(paths.data.node_sequence[start:end].view(-1)).tolist() Out[23]: <pre>['a', 'b', 'd']</pre> <p>Lastly, since we are using an <code>edge_index</code> internally, the <code>lift_order_edge_index</code> function works out-of-the-box for paths. A second-order representation of the paths can be created as follows:</p> In\u00a0[24]: Copied! <pre>second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(\n    edge_index=paths.data.edge_index, num_nodes=paths.data.num_nodes\n)\nsecond_order_paths = pp.Graph.from_edge_index(edge_index=second_order_edge_index)\npp.plot(\n    second_order_paths,\n    node_label=paths.mapping.to_ids(paths.data.node_sequence[paths.data.edge_index.t()].squeeze()).tolist(),\n)\n</pre> second_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(     edge_index=paths.data.edge_index, num_nodes=paths.data.num_nodes ) second_order_paths = pp.Graph.from_edge_index(edge_index=second_order_edge_index) pp.plot(     second_order_paths,     node_label=paths.mapping.to_ids(paths.data.node_sequence[paths.data.edge_index.t()].squeeze()).tolist(), ) Out[24]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40ee8ff10&gt;</pre> <p>With the concepts above, we can now create multi-order models using the <code>MultiOrderModel</code> class. This class allows us to create higher-order models of arbitrary order from a given base temporal graph or paths. Let's look at an example of creating a multi-order model from a temporal graph:</p> In\u00a0[25]: Copied! <pre>m_t = pp.MultiOrderModel.from_temporal_graph(t, max_order=2)\npp.plot(m_t.layers[2], node_label=m_t.layers[2].nodes)\n</pre> m_t = pp.MultiOrderModel.from_temporal_graph(t, max_order=2) pp.plot(m_t.layers[2], node_label=m_t.layers[2].nodes) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 2312.82it/s]\n</pre> Out[25]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee32b0&gt;</pre> <p>We can see that the second-order graph created by the <code>MultiOrderModel</code> is different from the one created by the <code>lift_order_temporal</code> function directly. This is because the <code>MultiOrderModel</code> higher-order DeBruijn graph representation. This representation merges higher-order nodes that correspond to the same path in the original graph. This means that temporal edges that appear in the event graph as different nodes will be merged into one node in the DeBruijn graph if they correspond to the same path in the original graph. This results in a more compact representation of the higher-order graph.</p> <p>The same is true for paths. We can create a multi-order model from a collection of paths as follows:</p> In\u00a0[26]: Copied! <pre>m_p = pp.MultiOrderModel.from_path_data(paths, max_order=2)\npp.plot(m_p.layers[2], node_label=m_p.layers[2].nodes)\n</pre> m_p = pp.MultiOrderModel.from_path_data(paths, max_order=2) pp.plot(m_p.layers[2], node_label=m_p.layers[2].nodes) Out[26]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40eee2860&gt;</pre> <p>We can see that the higher-order node <code>a-&gt;b</code> which appeared thrice in the second-order graph created by the <code>lift_order_edge_index</code> function is now merged into one node in the DeBruijn graph representation.</p> In\u00a0[27]: Copied! <pre># We create the third-order representation of the paths\nthird_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(\n    edge_index=second_order_paths.data.edge_index, num_nodes=second_order_paths.n\n)\n</pre> # We create the third-order representation of the paths third_order_edge_index = pp.algorithms.lift_order.lift_order_edge_index(     edge_index=second_order_paths.data.edge_index, num_nodes=second_order_paths.n ) <ol> <li>Update Node Sequences: Next, we need to update the internal <code>node_sequence</code> tensor to reflect the new higher-order nodes. For this, we create a new <code>node_sequence</code> by concatenating the last node of the target node sequence to the source node sequence. This way, we create a new sequence that corresponds to the paths represented by the next order nodes.</li> </ol> In\u00a0[28]: Copied! <pre>second_order_node_sequence = paths.data.node_sequence[paths.data.edge_index.t()].squeeze()\nthird_order_node_sequence = torch.cat([\n    second_order_node_sequence[second_order_paths.data.edge_index[0]],\n    second_order_node_sequence[second_order_paths.data.edge_index[1]][:, -1:]\n], dim=1)\n</pre> second_order_node_sequence = paths.data.node_sequence[paths.data.edge_index.t()].squeeze() third_order_node_sequence = torch.cat([     second_order_node_sequence[second_order_paths.data.edge_index[0]],     second_order_node_sequence[second_order_paths.data.edge_index[1]][:, -1:] ], dim=1) <ol> <li>Merge Higher-Order Nodes: Finally, we need to merge the higher-order nodes that correspond to the same path in the original graph. For this, we create a unique mapping from the new <code>node_sequence</code> to unique indices. We can then use this mapping to update the higher-order edge index to reflect the merged nodes and then aggregate duplicate edges.</li> </ol> In\u00a0[29]: Copied! <pre>third_order_paths = pp.algorithms.lift_order.aggregate_edge_index(\n    edge_index=third_order_edge_index, node_sequence=third_order_node_sequence\n)\n</pre> third_order_paths = pp.algorithms.lift_order.aggregate_edge_index(     edge_index=third_order_edge_index, node_sequence=third_order_node_sequence ) <p>After performing these steps, we can again visualize the resulting higher-order graph:</p> In\u00a0[30]: Copied! <pre>third_order_paths.mapping = pp.IndexMap([tuple(mapping.to_ids(v).tolist()) for v in third_order_paths.data.node_sequence])\npp.plot(third_order_paths, node_label=third_order_paths.nodes)\n</pre> third_order_paths.mapping = pp.IndexMap([tuple(mapping.to_ids(v).tolist()) for v in third_order_paths.data.node_sequence]) pp.plot(third_order_paths, node_label=third_order_paths.nodes) Out[30]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7fd40ed71e70&gt;</pre> <p>These steps can be repeated for each order until we reach the desired maximum order for the <code>MultiOrderModel</code>.</p> In\u00a0[31]: Copied! <pre>def get_all_paths_DAG(g: pp.Graph) -&gt; dict:\n    \"\"\"Calculate all existing paths from any root node to any leaf node in a directed acyclic graph (DAG).\"\"\"\n    paths_of_length = {}\n    edge_index = g.data.edge_index.as_tensor()\n\n    # calculate degrees\n    out_degree = degree(edge_index[0], num_nodes=g.n, dtype=torch.long)\n    in_degree = degree(edge_index[1], num_nodes=g.n, dtype=torch.long)\n\n    # identify root nodes with in-degree zero\n    roots = torch.where(in_degree == 0)[0]\n    leafs = out_degree == 0\n\n    # create path tensor that contains all paths that are not yet at a leaf node\n    paths = roots.unsqueeze(1)\n    # remove all paths that are already at a leaf node\n    paths_of_length[1] = paths[leafs[roots]].cpu().tolist()\n    # continue all paths that are not at a leaf node\n    paths = paths[~leafs[roots]]\n    # remember nodes that haven't been traversed yet\n    nodes = roots[~leafs[roots]]\n\n    ptrs = cumsum(out_degree, dim=0)\n\n    # count all longest paths in DAG\n    step = 1\n    while nodes.size(0) &gt; 0 or step &gt; g.n:\n        idx_repeat = torch.repeat_interleave(out_degree[nodes])\n        next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])\n        idx_correction = (\n            torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]\n        )\n        next_idx += idx_correction\n        next_nodes = edge_index[1][next_idx]\n        paths = torch.cat([paths[idx_repeat], next_nodes.unsqueeze(1)], dim=1)\n        paths_of_length[step] = paths[leafs[next_nodes]].tolist()\n        paths = paths[~leafs[next_nodes]]\n        nodes = next_nodes[~leafs[next_nodes]]\n        step += 1\n\n    return paths_of_length\n</pre> def get_all_paths_DAG(g: pp.Graph) -&gt; dict:     \"\"\"Calculate all existing paths from any root node to any leaf node in a directed acyclic graph (DAG).\"\"\"     paths_of_length = {}     edge_index = g.data.edge_index.as_tensor()      # calculate degrees     out_degree = degree(edge_index[0], num_nodes=g.n, dtype=torch.long)     in_degree = degree(edge_index[1], num_nodes=g.n, dtype=torch.long)      # identify root nodes with in-degree zero     roots = torch.where(in_degree == 0)[0]     leafs = out_degree == 0      # create path tensor that contains all paths that are not yet at a leaf node     paths = roots.unsqueeze(1)     # remove all paths that are already at a leaf node     paths_of_length[1] = paths[leafs[roots]].cpu().tolist()     # continue all paths that are not at a leaf node     paths = paths[~leafs[roots]]     # remember nodes that haven't been traversed yet     nodes = roots[~leafs[roots]]      ptrs = cumsum(out_degree, dim=0)      # count all longest paths in DAG     step = 1     while nodes.size(0) &gt; 0 or step &gt; g.n:         idx_repeat = torch.repeat_interleave(out_degree[nodes])         next_idx = torch.repeat_interleave(ptrs[nodes], out_degree[nodes])         idx_correction = (             torch.arange(next_idx.size(0), device=edge_index.device) - cumsum(out_degree[nodes], dim=0)[idx_repeat]         )         next_idx += idx_correction         next_nodes = edge_index[1][next_idx]         paths = torch.cat([paths[idx_repeat], next_nodes.unsqueeze(1)], dim=1)         paths_of_length[step] = paths[leafs[next_nodes]].tolist()         paths = paths[~leafs[next_nodes]]         nodes = next_nodes[~leafs[next_nodes]]         step += 1      return paths_of_length <p>The function above starts at all root nodes (nodes with no incoming edges) and iteratively traverses all possible next nodes while keeping track of all current paths. Whenever a path reaches a leaf node (a node with no outgoing edges), it is added to the list of longest paths and removed from the current paths. This continues until all paths have reached a leaf node.</p> <p>Tip</p> <p>     Getting the next nodes for all current paths is done using a similar indexing trick as in the <code>lift_order_edge_index</code> function. This allows us to efficiently get all next nodes for all current paths in one go using tensor operations.     </p>"},{"location":"tutorial/implementation_concepts/#general-concepts-of-the-tensor-based-implementations","title":"General Concepts of the Tensor-based Implementations\u00b6","text":""},{"location":"tutorial/implementation_concepts/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/implementation_concepts/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>The inner workings of the core classes of PathpyG are based on tensor operations provided by PyTorch and PyTorch Geometric. Especially the creation of higher-order structures using the lift-order functions and the <code>MultiOderModel</code> heavily rely on tensor operations for efficiency reasons. While these implementations are highly optimized, they are very hard to read and understand for newcomers. This tutorial aims to explain the general concepts and ideas behind these implementations in a more accessible way. Additionally, we will provide step-by-step explanations of the core functions in the following sections.</p>"},{"location":"tutorial/implementation_concepts/#order-lifting-and-line-graph-transformations","title":"Order-lifting and Line Graph Transformations\u00b6","text":"<p>At the core of creating higher-order models is the <code>lift_order_edge_index</code> function that is essentially a line graph transformation. Given an edge index of a graph and the number of nodes in the graph, this function creates the edge index for the corresponding line graph. Let's look at an example:</p>"},{"location":"tutorial/implementation_concepts/#under-the-hood-of-lift_order_edge_index","title":"Under the Hood of <code>lift_order_edge_index</code>\u00b6","text":"<p>Let us now take a closer look at how the <code>lift_order_edge_index</code> function works under the hood. The whole function essentially only needs 10 lines of code and looks as follows:</p>"},{"location":"tutorial/implementation_concepts/#temporal-order-lifting","title":"Temporal Order Lifting\u00b6","text":"<p>One of the core functionalities of PathpyG is the ability to create temporal higher-order models. For this, an extension of the <code>lift_order_edge_index</code> function to temporal graphs is needed. We implement this in the <code>lift_order_temporal</code> function. This function works similarly to the <code>lift_order_edge_index</code> function, but with some additional steps to account for the temporal aspect of the graph. The main difference is that we need to ensure that the higher-order edges respect the temporal ordering of the original edges. Let us take a look at an example:</p>"},{"location":"tutorial/implementation_concepts/#internals-of-the-lift_order_temporal-function","title":"Internals of the <code>lift_order_temporal</code> Function\u00b6","text":"<p>The simplest way to implement the <code>lift_order_temporal</code> function would be to first create the full higher-order edge index using the <code>lift_order_edge_index</code> function and then filter out the edges that do not respect the temporal ordering. The filter function could look as follows:</p>"},{"location":"tutorial/implementation_concepts/#paths-in-pathpyg","title":"Paths in PathpyG\u00b6","text":"<p>One other core functionality of PathpyG is the ability to work with paths. Paths are sequences of nodes that represent a walk through the graph. We show an example below:</p>"},{"location":"tutorial/implementation_concepts/#multi-order-models","title":"Multi-Order Models\u00b6","text":""},{"location":"tutorial/implementation_concepts/#internals-of-the-multiordermodel-class","title":"Internals of the <code>MultiOrderModel</code> Class\u00b6","text":"<p>Let us now take a closer look at how the <code>MultiOrderModel</code> class works under the hood. We already saw that the <code>MultiOrderModel</code> merges higher-order nodes from the line/event graph transformations.</p> <p>This is done in 3 distinct steps which we will go through using the paths example above:</p> <ol> <li>Order Lifting: First, we create the higher-order edge index using the appropriate lift-order function (<code>lift_order_edge_index</code> or <code>lift_order_temporal</code>) depending on whether we are working with paths or temporal graphs in the first order and <code>lift_order_edge_index</code> for the second order and beyond regardless of the input type.</li> </ol> <p>Note</p> <p>         While we merge the higher-order nodes and aggregate the higher-order edges for each order, we need to use the original higher-order edge index to create the next order. This is because the transitivity of paths is only preserved in the original higher-order edge index.     </p>"},{"location":"tutorial/implementation_concepts/#other-tensor-based-implementations","title":"Other Tensor-based Implementations\u00b6","text":"<p>The concepts from above can also be useful to implement other functionalities using tensor operations.</p>"},{"location":"tutorial/implementation_concepts/#longest-path-extraction","title":"Longest Path Extraction\u00b6","text":"<p>One example is the extraction of all longest paths from a directed acyclic graph (DAG). This can be done by iterating through all nodes in the DAG in topological order at the same time. We provide an example implementation below:</p>"},{"location":"tutorial/manim_tutorial/","title":"Temporal Graph Visualisation using Manim","text":"In\u00a0[1]: Copied! <pre># %%capture\n# # !pip install torch\n# !pip install torch_geometric\n# !pip install git+https://github.com/pathpy/pathpyG.git\n</pre> # %%capture # # !pip install torch # !pip install torch_geometric # !pip install git+https://github.com/pathpy/pathpyG.git <p>Note that using the <code>Manim</code>-backend in <code>PathpyG</code> requires the installation of <code>Manim</code>. It will not be automatically installed with <code>PathpyG</code> due to its additional dependencies. We recommend using the installation instructions in the <code>Manim</code> documentation or our provided DevContainer.</p> In\u00a0[1]: Copied! <pre>import pathpyG as pp\n</pre> import pathpyG as pp <p>Next, we can create a temporal graph that we want to visualise:</p> In\u00a0[2]: Copied! <pre>t = pp.TemporalGraph.from_edge_list(\n    [\n        (\"a\", \"b\", 1),\n        (\"b\", \"c\", 5),\n        (\"c\", \"d\", 9),\n        (\"d\", \"a\", 9),\n        (\"a\", \"b\", 10),\n        (\"b\", \"c\", 10),\n        (\"a\", \"b\", 8),\n        (\"b\", \"c\", 13),\n        (\"c\", \"d\", 17),\n        (\"d\", \"a\", 19),\n        (\"a\", \"b\", 20),\n        (\"b\", \"c\", 18),\n    ]\n)\n</pre> t = pp.TemporalGraph.from_edge_list(     [         (\"a\", \"b\", 1),         (\"b\", \"c\", 5),         (\"c\", \"d\", 9),         (\"d\", \"a\", 9),         (\"a\", \"b\", 10),         (\"b\", \"c\", 10),         (\"a\", \"b\", 8),         (\"b\", \"c\", 13),         (\"c\", \"d\", 17),         (\"d\", \"a\", 19),         (\"a\", \"b\", 20),         (\"b\", \"c\", 18),     ] ) <p>The <code>plot</code> function using Manim as backend allows  to use a variety of customization options to visualize temporal graphs and outputs a video. Some examples are provided below, e.g. the <code>node_size</code> or the <code>edge_size</code>.</p> In\u00a0[3]: Copied! <pre>pp.plot(t, backend=\"manim\", node_size=20, edge_size=10, edge_color=\"red\", node_color=\"gray\")\n</pre> pp.plot(t, backend=\"manim\", node_size=20, edge_size=10, edge_color=\"red\", node_color=\"gray\") <pre>                                                                                          \r</pre>                  Your browser does not support the video tag.              Out[3]: <pre>&lt;pathpyG.visualisations._manim.backend.ManimBackend at 0x7f7404cdbfd0&gt;</pre> <p>The videos can be exported as <code>.mp4</code> or <code>.gif</code> if you provide a filename to the <code>plot</code> function.</p> In\u00a0[\u00a0]: Copied! <pre>pp.plot(\n    t,\n    backend=\"manim\",\n    node_size=20,\n    edge_size=4,\n    edge_color=\"red\",\n    node_color=\"gray\",\n    filename=\"tutorial_plot.gif\",\n)\n</pre> pp.plot(     t,     backend=\"manim\",     node_size=20,     edge_size=4,     edge_color=\"red\",     node_color=\"gray\",     filename=\"tutorial_plot.gif\", ) In\u00a0[\u00a0]: Copied! <pre>pp.plot(\n    t,\n    backend=\"manim\",\n    layout_window_size=[3, 1],\n    layout=\"fa2\",\n    node_size=12,\n    edge_color={(\"b\", \"c\", 10): \"green\"},\n    node_color={(\"a\", 3): \"yellow\", (\"a\", 0): \"green\", (\"b\", 3): \"black\"},\n)\n</pre> pp.plot(     t,     backend=\"manim\",     layout_window_size=[3, 1],     layout=\"fa2\",     node_size=12,     edge_color={(\"b\", \"c\", 10): \"green\"},     node_color={(\"a\", 3): \"yellow\", (\"a\", 0): \"green\", (\"b\", 3): \"black\"}, ) <pre>                                                                                           \r</pre>                  Your browser does not support the video tag.              Out[\u00a0]: <pre>&lt;pathpyG.visualisations._manim.backend.ManimBackend at 0x7f75d0d944c0&gt;</pre> In\u00a0[7]: Copied! <pre>g = pp.io.read_netzschleuder_graph('sp_baboons', 'observational', time_attr='time')\n</pre> g = pp.io.read_netzschleuder_graph('sp_baboons', 'observational', time_attr='time') <p>The timestamps are provided in seconds since epoch (converted from unix time). We first convert them to a more human-readable format (hours since the first interaction):</p> In\u00a0[8]: Copied! <pre>g.data.time -= g.data.time.min()\ng.data.time = g.data.time // (60 * 60 * 12) # convert to 12 hours intervals\n</pre> g.data.time -= g.data.time.min() g.data.time = g.data.time // (60 * 60 * 12) # convert to 12 hours intervals <p>The dataset contains different types of interactions between the baboons. We can use this information to color the edges based on the interaction type:</p> In\u00a0[9]: Copied! <pre>colors = []\nfor category in g.data[\"edge_category\"]:\n    match category:\n        case \"Affiliative\":\n            colors.append(\"red\")\n        case \"Agonistic\":\n            colors.append(\"green\")\n        case \"Other\":\n            colors.append(\"grey\")\n</pre> colors = [] for category in g.data[\"edge_category\"]:     match category:         case \"Affiliative\":             colors.append(\"red\")         case \"Agonistic\":             colors.append(\"green\")         case \"Other\":             colors.append(\"grey\") In\u00a0[11]: Copied! <pre>pp.plot(\n    g,\n    backend=\"manim\",\n    layout_window_size=12,  # three days\n    layout=\"kk\",\n    edge_color=colors,\n    edge_size=2.5,\n    delta=500,  # Each time step is 500 ms\n)\n</pre> pp.plot(     g,     backend=\"manim\",     layout_window_size=12,  # three days     layout=\"kk\",     edge_color=colors,     edge_size=2.5,     delta=500,  # Each time step is 500 ms ) <pre>                                                                                           \r</pre>                  Your browser does not support the video tag.              Out[11]: <pre>&lt;pathpyG.visualisations._manim.backend.ManimBackend at 0x7f73f9e5ae90&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/manim_tutorial/#temporal-network-visualizations-with-manim","title":"Temporal Network Visualizations with Manim\u00b6","text":""},{"location":"tutorial/manim_tutorial/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/manim_tutorial/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>While you already learned how to visualise graphs with <code>PathpyG</code> in the interactive graph visualisation tutorial, those visualisations mostly considered static graphs. In this tutorial, you will learn how to use the <code>Manim</code> backend in <code>PathpyG</code> to generate videos (<code>.mp4</code>) or animations (<code>.gif</code>) of temporal graphs.</p>"},{"location":"tutorial/manim_tutorial/#lets-get-started","title":"Let's Get Started\u00b6","text":"<p>We need to import <code>PathpyG</code> first:</p>"},{"location":"tutorial/manim_tutorial/#dynamic-customisations-and-layout","title":"Dynamic Customisations and Layout\u00b6","text":"<p>Since we use <code>manim</code> to animate temporal networks, we can also use dynamic customisations that change over time. For example, we can change the <code>node_size</code> or <code>edge_size</code> over time. To change those properties dynamically, we can provide a dictionary that maps node/source-target id and the time step to the desired property value.</p> <p>Additionally, we can use dynamic layouts that are based on sliding windows. For example, we can use a <code>ForceAtlas2</code> layout that is computed based on a sliding window of the last 3 time steps. This allows us to have a layout that changes over time but is still stable enough to be visually appealing.</p> <p>The following shows an example where all of the customisations described above are used:</p>"},{"location":"tutorial/manim_tutorial/#real-world-example","title":"Real-World Example\u00b6","text":"<p>As a final example, we show how to visualise a real-world temporal graph with <code>Manim</code>. We use Netschleuder Online Repository (see our next tutorial our next tutorial Graph Learning in Netzschleuder Data for more information) to obtain a temporal interaction graph between baboons and color the types of interactions in different colors.</p>"},{"location":"tutorial/netzschleuder/","title":"Graph Learning in Netzschleuder Data","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[29]: Copied! <pre>from matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.decomposition import TruncatedSVD\n\nimport torch\nfrom torch.nn import ReLU, Sigmoid\n\nimport torch_geometric\nfrom torch_geometric.nn import Sequential, GCNConv\n\nimport pathpyG as pp\n</pre> from matplotlib import pyplot as plt  from sklearn import metrics from sklearn.decomposition import TruncatedSVD  import torch from torch.nn import ReLU, Sigmoid  import torch_geometric from torch_geometric.nn import Sequential, GCNConv  import pathpyG as pp In\u00a0[30]: Copied! <pre>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n</pre> device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') In\u00a0[31]: Copied! <pre>g = pp.io.read_netzschleuder_graph(name='polbooks')\nprint(g)\n</pre> g = pp.io.read_netzschleuder_graph(name='polbooks') print(g) <pre>Undirected graph with 105 nodes and 441 edges\n{   'Edge Attributes': {},\n    'Graph Attributes': {   'analyses_average_degree': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_assortativity': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_std_dev': \"&lt;class 'float'&gt;\",\n                            'analyses_diameter': \"&lt;class 'int'&gt;\",\n                            'analyses_edge_properties': \"&lt;class 'list'&gt;\",\n                            'analyses_edge_reciprocity': \"&lt;class 'float'&gt;\",\n                            'analyses_global_clustering': \"&lt;class 'float'&gt;\",\n                            'analyses_hashimoto_radius': \"&lt;class 'float'&gt;\",\n                            'analyses_is_bipartite': \"&lt;class 'bool'&gt;\",\n                            'analyses_is_directed': \"&lt;class 'bool'&gt;\",\n                            'analyses_knn_proj_1': \"&lt;class 'float'&gt;\",\n                            'analyses_knn_proj_2': \"&lt;class 'float'&gt;\",\n                            'analyses_largest_component_fraction': \"&lt;class 'float'&gt;\",\n                            'analyses_mixing_time': \"&lt;class 'float'&gt;\",\n                            'analyses_num_edges': \"&lt;class 'int'&gt;\",\n                            'analyses_num_vertices': \"&lt;class 'int'&gt;\",\n                            'analyses_transition_gap': \"&lt;class 'float'&gt;\",\n                            'analyses_vertex_properties': \"&lt;class 'list'&gt;\",\n                            'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {'node__pos': \"&lt;class 'numpy.ndarray'&gt;\", 'node_label': \"&lt;class 'numpy.ndarray'&gt;\", 'node_value': \"&lt;class 'numpy.ndarray'&gt;\"}}\n</pre> <p>We can plot this temporal graph in an interactive way:</p> In\u00a0[33]: Copied! <pre>pp.plot(g, edge_color='lightgray', edge_size=5);\n</pre> pp.plot(g, edge_color='lightgray', edge_size=5); <p>To see how we can apply GNNs to attributed graphs, let us read the famous karate club network. The record <code>karate</code> actually contains two networks with labels <code>77</code> and <code>78</code>, which refer to two different versions of the data with different numbers of edges. If multiple graph data sets exist in the same record, we can specify the name of the network as second argument.</p> In\u00a0[34]: Copied! <pre>g = pp.io.read_netzschleuder_graph(name='karate', network='78').to(device)\nprint(g)\n</pre> g = pp.io.read_netzschleuder_graph(name='karate', network='78').to(device) print(g) <pre>Undirected graph with 34 nodes and 78 edges\n{   'Edge Attributes': {},\n    'Graph Attributes': {   'analyses_average_degree': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_assortativity': \"&lt;class 'float'&gt;\",\n                            'analyses_degree_std_dev': \"&lt;class 'float'&gt;\",\n                            'analyses_diameter': \"&lt;class 'int'&gt;\",\n                            'analyses_edge_properties': \"&lt;class 'list'&gt;\",\n                            'analyses_edge_reciprocity': \"&lt;class 'float'&gt;\",\n                            'analyses_global_clustering': \"&lt;class 'float'&gt;\",\n                            'analyses_hashimoto_radius': \"&lt;class 'float'&gt;\",\n                            'analyses_is_bipartite': \"&lt;class 'bool'&gt;\",\n                            'analyses_is_directed': \"&lt;class 'bool'&gt;\",\n                            'analyses_knn_proj_1': \"&lt;class 'float'&gt;\",\n                            'analyses_knn_proj_2': \"&lt;class 'float'&gt;\",\n                            'analyses_largest_component_fraction': \"&lt;class 'float'&gt;\",\n                            'analyses_mixing_time': \"&lt;class 'float'&gt;\",\n                            'analyses_num_edges': \"&lt;class 'int'&gt;\",\n                            'analyses_num_vertices': \"&lt;class 'int'&gt;\",\n                            'analyses_transition_gap': \"&lt;class 'float'&gt;\",\n                            'analyses_vertex_properties': \"&lt;class 'list'&gt;\",\n                            'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {   'node__pos': \"&lt;class 'numpy.ndarray'&gt;\",\n                           'node_groups': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\",\n                           'node_name': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([34])\"}}\n</pre> In\u00a0[35]: Copied! <pre>pp.plot(g, edge_color='gray');\n</pre> pp.plot(g, edge_color='gray'); <p>We see that the nodes actually have a <code>node_groups</code> property, which maps the nodes to two groups. Those groups are often used as <code>ground truth</code> for communities in this simple illustrative graph. We will instead use it as ground truth categorical node label for a node classification experiment based on a Graph Neural Network.</p> <p>Conveniently, numerical node attributes (either scalar or vector values) are automatically converted to torch tensors, so we can directly use them for a GNN.</p> In\u00a0[36]: Copied! <pre>print(g.data.node_groups)\n</pre> print(g.data.node_groups) <pre>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n</pre> <p>For convenience, let us shift the group labels to binary values 0 and 1:</p> In\u00a0[37]: Copied! <pre>g.data.node_groups -= 1\nprint(g.data.node_groups)\n</pre> g.data.node_groups -= 1 print(g.data.node_groups) <pre>tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n</pre> <p>We can plot categorical labels by passing node colors in the plot function.</p> In\u00a0[38]: Copied! <pre>pp.plot(g, node_color = [g['node_groups',v].item() for v in g.nodes])\n</pre> pp.plot(g, node_color = [g['node_groups',v].item() for v in g.nodes]) Out[38]: <pre>&lt;pathpyG.visualisations.network_plots.StaticNetworkPlot at 0x7f36e006f1d0&gt;</pre> <p>For convenience, let us shift the group labels to binary values 0 and 1:</p> In\u00a0[39]: Copied! <pre>color_map = {0: 'red', 1: 'blue'}\ncolors = [ color_map[g['node_groups',v].item()] for v in g.nodes ]\npp.plot(g, node_color = colors);\n</pre> color_map = {0: 'red', 1: 'blue'} colors = [ color_map[g['node_groups',v].item()] for v in g.nodes ] pp.plot(g, node_color = colors); <p>To simplify the application of deep learning models, we can retrieve a data object that contains the graph and its attributes:</p> In\u00a0[40]: Copied! <pre>print(g.data)\n</pre> print(g.data) <pre>Data(edge_index=[2, 156], num_nodes=34, node_sequence=[34, 1], node_name=[34], node_groups=[34], node__pos=[34], analyses_average_degree=4.588235294117647, analyses_degree_assortativity=-0.47561309768461424, analyses_degree_std_dev=3.820360677912828, analyses_diameter=5, analyses_edge_properties=[0], analyses_edge_reciprocity=1.0, analyses_global_clustering=0.2556818181818182, analyses_hashimoto_radius=5.292780644548693, analyses_is_bipartite=False, analyses_is_directed=False, analyses_knn_proj_1=3.6123615105719784, analyses_knn_proj_2=1.4566019942625823, analyses_largest_component_fraction=1.0, analyses_mixing_time=7.04834107126513, analyses_num_edges=78, analyses_num_vertices=34, analyses_transition_gap=0.8677276709836416, analyses_vertex_properties=[3])\n</pre> <p>Let's use a one-hot encoding of nodes as a simple additional node feature <code>x</code>, and let's use the node groups as target label <code>y</code>.</p> In\u00a0[41]: Copied! <pre>data = g.data\ng[\"node_feature\"] = torch.eye(g.n, device=device)\ndata['x'] = data['node_feature']\ndata['y'] = data['node_groups'].reshape(-1, 1).float()\n</pre> data = g.data g[\"node_feature\"] = torch.eye(g.n, device=device) data['x'] = data['node_feature'] data['y'] = data['node_groups'].reshape(-1, 1).float() <p>It is easy to define a Graph Convolutional Network that ues the one-hot-encodings of nodes and the topology to predict binary node labels:</p> In\u00a0[42]: Copied! <pre>model = Sequential('node_ohe, edge_index', [\n    (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),\n    ReLU(inplace=True),\n    (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),\n    Sigmoid(),\n])\nmodel.to(device)\n</pre> model = Sequential('node_ohe, edge_index', [     (GCNConv(in_channels=data.num_node_features, out_channels=8), 'node_ohe, edge_index -&gt; hidden'),     ReLU(inplace=True),     (GCNConv(in_channels=8, out_channels=1), 'hidden, edge_index -&gt; output'),     Sigmoid(), ]) model.to(device) Out[42]: <pre>Sequential(\n  (0) - GCNConv(34, 8): node_ohe, edge_index -&gt; hidden\n  (1) - ReLU(inplace=True): hidden -&gt; hidden\n  (2) - GCNConv(8, 1): hidden, edge_index -&gt; output\n  (3) - Sigmoid(): output -&gt; output\n)</pre> <p>We next apply a <code>RandomNodeSplit</code> transformation to split the nodes in a training and test set.</p> In\u00a0[25]: Copied! <pre>transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0)\ndata = transform(data)\n</pre> transform = torch_geometric.transforms.RandomNodeSplit(split='train_rest', num_val=0.5, num_test=0) data = transform(data) <p>We then train our model for 1000 epochs on the training set.</p> In\u00a0[26]: Copied! <pre>epochs = 1000\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n    \nlosses = []\n\nmodel.train()\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)\n    loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])\n    loss.backward()\n    optimizer.step()\n\n    losses.append(loss.cpu().detach().numpy())\n\nplt.plot(range(epochs), losses)\nplt.grid()\n</pre> epochs = 1000  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)      losses = []  model.train() for epoch in range(epochs):     optimizer.zero_grad()     out = model(data.x, data.edge_index)     loss = torch.nn.functional.binary_cross_entropy(out[data.train_mask], data.y[data.train_mask])     loss.backward()     optimizer.step()      losses.append(loss.cpu().detach().numpy())  plt.plot(range(epochs), losses) plt.grid() <p>We evaluate the model in the test set and calculate the adjusted mutual information for the ground truth.</p> In\u00a0[27]: Copied! <pre>model.eval()\npredicted_groups = model(data.x, data.edge_index).round().long()\nmetrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy())\n</pre> model.eval() predicted_groups = model(data.x, data.edge_index).round().long() metrics.adjusted_mutual_info_score(data.y[data.test_mask].squeeze().cpu().numpy(), predicted_groups[data.test_mask].squeeze().cpu().numpy()) Out[27]: <pre>1.0</pre> <p>We visualize node representations learned by the model. The test nodes are colored, while training nodes are greyed out.</p> In\u00a0[28]: Copied! <pre># get activations in first-layer\nembedding = model[0].forward(data.x, data.edge_index)\n\n# dimensionality reduction\nsvd = TruncatedSVD()\nlow_dim = svd.fit_transform(embedding.cpu().detach().numpy())\n\n# plot with colors corresponding to groups in validation set\ncolors = {}\nfor v in range(g.n):\n    if not data.val_mask[v]:\n        colors[v] = 'grey'\n    else:\n        if data.y[v].item() == 0.0:\n            colors[v] = 'blue'\n        else:\n            colors[v] = 'orange'\n\nplt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values());\n</pre> # get activations in first-layer embedding = model[0].forward(data.x, data.edge_index)  # dimensionality reduction svd = TruncatedSVD() low_dim = svd.fit_transform(embedding.cpu().detach().numpy())  # plot with colors corresponding to groups in validation set colors = {} for v in range(g.n):     if not data.val_mask[v]:         colors[v] = 'grey'     else:         if data.y[v].item() == 0.0:             colors[v] = 'blue'         else:             colors[v] = 'orange'  plt.scatter(low_dim[:,0], low_dim[:,1], c=colors.values()); <p>This simple code gives you thousands of networks with various meta information at your fingertips, to wich you can directly apply graph learning models provided in pyG, or deep graoh learning architectures defined by yourself.</p>"},{"location":"tutorial/netzschleuder/#learning-in-graphs-from-the-netzschleuder-repository","title":"Learning in Graphs from the Netzschleuder Repository\u00b6","text":""},{"location":"tutorial/netzschleuder/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/netzschleuder/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>Access to a large number of graphs with different topological characteristics and from different domains is crucial for the development and evaluation of graph learning methods. Tousands of graph data sets are available scattered throughout the web, possibly using different data formats and with missing information on their actual origin. Addressing this issue the Netschleuder Online Repository by Tiago Peixoto provides a single repository of graphs in a single format, including descriptions, citations, and node-/edge- or graph-level meta-data. To facilitate the development of graph learning techniques, pathpyG provides a feature that allows to directly read networks from the netzschleuder repository via an API.</p> <p>In this brief unit, we will learn how we can retrieve network records and graph data from the netzschleuder repository. We will further demonstrate how we can conveniently apply a Graph Neural Network to predict node-level categories contained in the meta-data.</p> <p>We first need to import a few modules.</p>"},{"location":"tutorial/netzschleuder/#reading-graphs-from-the-netzschleuder-repository","title":"Reading graphs from the netzschleuder repository\u00b6","text":"<p>In the <code>pathpy.io</code> module, there is a function that allows to read graph data from the API.</p> <p>We can read a given networks from the netzschleuder database using its record name. Just browse the Netschleuder Online Repository to find the record names. As an example, we use a graph capturing co-purchase relationships between political books.</p>"},{"location":"tutorial/netzschleuder/#applying-graph-neural-networks-to-netzschleuder-data","title":"Applying Graph Neural Networks to Netzschleuder Data\u00b6","text":""},{"location":"tutorial/paths_higher_order/","title":"Path Data and Higher-Order Models","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import torch\nimport pathpyG as pp\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n</pre> import torch import pathpyG as pp  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') <pre>/opt/conda/lib/python3.11/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n  return torch._C._show_config()\n</pre> <p>For the following examples, we consider a simple directed graph with five nodes <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>, <code>e</code> and four edges:</p> In\u00a0[2]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\npp.plot(g, node_label=g.nodes, edge_color='gray');\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c', 'e')]) pp.plot(g, node_label=g.nodes, edge_color='gray'); In\u00a0[3]: Copied! <pre>paths = pp.PathData(g.mapping)\n\npaths.append_walk(('a', 'c', 'd'), weight=4.0)\npaths.append_walk(('b', 'c', 'e'), weight=4.0)\nprint(paths)\n</pre> paths = pp.PathData(g.mapping)  paths.append_walk(('a', 'c', 'd'), weight=4.0) paths.append_walk(('b', 'c', 'e'), weight=4.0) print(paths) <pre>PathData with 2 paths with total weight 8.0\n</pre> <p>Let us inspect how those walks are internally stored in the <code>PathData</code> object. We find that the class internally stores a <code>pyG.Data</code> object, which contains the properties <code>edge_index</code>, <code>node_sequence</code>, <code>dag_weight</code>, <code>dag_num_edges</code> and <code>dag_num_nodes</code> that can be used to access all of the individual paths.</p> In\u00a0[4]: Copied! <pre>paths.data\n</pre> paths.data Out[4]: <pre>Data(edge_index=[2, 4], node_sequence=[6, 1], dag_weight=[2], dag_num_edges=[2], dag_num_nodes=[2], num_nodes=6)</pre> <p>The <code>edge_index</code> tensor represents an ordered sequence of edges traversed by the walk, where the indices of nodes map to the <code>node_sequence</code> tensor. This additional mapping is neccessary since walks can traverse the same edge multiple times. Moreover, it allows to internally concatenate multiple walks into a single <code>Data</code> object, which is needed for fast GPU-based operations on path data. We can access the first path as follows:</p> In\u00a0[5]: Copied! <pre>paths.data.edge_index[:, :paths.data.dag_num_edges[0]]\n</pre> paths.data.edge_index[:, :paths.data.dag_num_edges[0]] Out[5]: <pre>tensor([[0, 1],\n        [1, 2]])</pre> <p>The <code>node_sequence</code> tensor tells us that the node with index <code>1</code> in the <code>edge_index</code> maps to the node in the graph with index <code>2</code>, which is node <code>c</code>.</p> In\u00a0[6]: Copied! <pre>paths.data.node_sequence[:paths.data.dag_num_nodes[0]]\n</pre> paths.data.node_sequence[:paths.data.dag_num_nodes[0]] Out[6]: <pre>tensor([[0],\n        [2],\n        [3]])</pre> <p>We can index the second edge index accordingly and can see that the <code>node_sequence</code> tensor maps to the sequence <code>b -&gt; c -&gt; e</code>:</p> In\u00a0[7]: Copied! <pre>paths.data.node_sequence[paths.data.edge_index[:, paths.data.dag_num_edges[0]:]]\n</pre> paths.data.node_sequence[paths.data.edge_index[:, paths.data.dag_num_edges[0]:]] Out[7]: <pre>tensor([[[1],\n         [2]],\n\n        [[2],\n         [4]]])</pre> <p>We can actually see a collection of walks as a higher-order generalization of the usual way to define graphs as a collection of dyadic edges (which are simply walks of length one). From this point of view, a standard static (weighted) graph is simply a first-order model of node sequences, which only considers the frequency at which edges are traversed.</p> <p>To generate such a first-order model, we can use the class <code>MultiOderModel</code> and use the first-layer of the model, which is simply a weighted static graph where edge weights count the number of times each edge is traversed by a path. We will explain the class <code>MultiOrderModel</code>, which generalizes this concept to higher-order graph models for any order $k$ in a moment. For now, we can just use it to generate a first-order weighted graph as follows.</p> <p>The generated graph is again based on a <code>pyG.Data</code> object that contains an edge_index and edge weights. As we can see, for the example above the edge_index is just a concatenation of the edge indices of individual walks, where the node indices have been mapped to the correct nodes.</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths, max_order=1)\ng = m.layers[1]\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\npp.plot(g, node_label=paths.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_path_data(paths, max_order=1) g = m.layers[1] print(g.data.edge_index) print(g.data.edge_weight) pp.plot(g, node_label=paths.mapping.node_ids.tolist()); <pre>EdgeIndex([[0, 1, 2, 2],\n           [2, 2, 3, 4]], sparse_size=(5, 5), nnz=4, sort_order=row)\ntensor([4., 4., 4., 4.])\n</pre> <p>Why are data on paths and walks interesting in the first place. The answer is that they provide information on the causal topology of complex systems, i.e. which nodes can possibly causally influence each other via paths that follow the arrow of time. This information is lost if we were to split paths into an (unordered) collection of dyadyic interactions between pairs of nodes, i.e. if we were to only onsider links.</p> <p>To illustrate this, let us assume that the four walks above tell us which paths information (or whatever you may be interested in) can take in the simple graph above. That is, we observe something moving from <code>a</code> via <code>c</code> to <code>d</code> and from <code>b</code> via <code>c</code> to <code>e</code>, and each of those events occur four times. However, we never observed that something moving from <code>a</code> to <code>c</code> ended up in <code>d</code>. And neither did we observe that something moving from <code>b</code> to <code>c</code> ended up in <code>e</code>. This means that - assuming that we completely observed all walks or paths - there is no way that <code>a</code> can causally influence <code>e</code> or that <code>b</code> could causally influence <code>d</code> via the center node <code>c</code>. Note that this is not what we would assume if we consider possible paths in the topology of the underlying graph, where paths of length two exist between all four pairs of nodes (<code>a</code>, <code>d</code>), (<code>a</code>, <code>e</code>), (<code>b</code>, <code>d</code>), (<code>b</code>, <code>e</code>).</p> <p>Hence, we can use data capturing actually observed paths or walks ion a network in contrast to which paths or walks would theoretically be possible based on the topology.</p> <p>As a contrast, consider the following observations of walks in the same graph.</p> In\u00a0[9]: Copied! <pre>paths_2 = pp.PathData(g.mapping)\n\npaths_2.append_walk(('a', 'c', 'd'), weight=2)\npaths_2.append_walk(('a', 'c', 'e'), weight=2)\npaths_2.append_walk(('b', 'c', 'd'), weight=2)\npaths_2.append_walk(('b', 'c', 'e'), weight=2)\nprint(paths_2)\n</pre> paths_2 = pp.PathData(g.mapping)  paths_2.append_walk(('a', 'c', 'd'), weight=2) paths_2.append_walk(('a', 'c', 'e'), weight=2) paths_2.append_walk(('b', 'c', 'd'), weight=2) paths_2.append_walk(('b', 'c', 'e'), weight=2) print(paths_2) <pre>PathData with 4 paths with total weight 8.0\n</pre> <p>Here we have observed walks along all four possible paths of length two, each walk occurring only two times. Like in the example before, each edge was traversed exactly four times and thus the weighted edge index of a first-order graph model is identical to the one before:</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths_2, max_order=1)\ng = m.layers[1]\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_path_data(paths_2, max_order=1) g = m.layers[1] print(g.data.edge_index) print(g.data.edge_weight) pp.plot(g, node_label=g.mapping.node_ids.tolist()); <pre>EdgeIndex([[0, 1, 2, 2],\n           [2, 2, 3, 4]], sparse_size=(5, 5), nnz=4, sort_order=row)\ntensor([4., 4., 4., 4.])\n</pre> <p>This is a first-order graph representation, as it only captures the (weighted) edges in the underlying path data, i.e. we could say that we only count the frequency of paths (or walks) of length one. This naturally gives rise to an <code>edge_index</code> tensor with shape $(2,m)$, where $m$ is the number of unique edges in the graph that are traversed by the paths.</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths, max_order=2)\ng = m.layers[2]\npp.plot(g, node_label=g.nodes, edge_size=5);\n</pre> m = pp.MultiOrderModel.from_path_data(paths, max_order=2) g = m.layers[2] pp.plot(g, node_label=g.nodes, edge_size=5); <p>For $k=2$, we obtain a second-order De Bruijn graph where second-order nodes are first-order edges and second-order edges represent walks of length two in the original graph. Edge weights capture observation frequencies of those walks. In our example, we have two different walks of length two ($a$ -&gt; $c$ -&gt; $d$ and $b$ -&gt; $c$ -&gt; $e$), represented by two edges $(a-c, c-d)$ and $(b-c, c-e)$. Each of those walks appears four times so the weights of both edges are four.</p> In\u00a0[12]: Copied! <pre>print(g.mapping)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> print(g.mapping) print(g.data.edge_index) print(g.data.edge_weight) <pre>(np.str_('a'), np.str_('c')) -&gt; 0\n(np.str_('b'), np.str_('c')) -&gt; 1\n(np.str_('c'), np.str_('d')) -&gt; 2\n(np.str_('c'), np.str_('e')) -&gt; 3\n\nEdgeIndex([[0, 1],\n           [2, 3]], sparse_size=(4, 4), nnz=2, sort_order=row)\ntensor([4., 4.])\n</pre> <p>While this goes beyond the scope of this tutorial, thanks to the tensor-based representation of paths, the construction ofhigher-order De Bruijn graphs can be done based on efficient GPU operations, i.e. we can scale it up to large graphs.</p> <p>Let us have a closer look at our examples above. While the first-order edge indices of the two path objects <code>paths</code> and <code>paths_2</code> are the same, we find that the second-order edge indices are actually different. For <code>paths_2</code> we have four different paths of length two, each occurring twice. Hence, our second-order De Bruijn graph has four edges, each with weight two. These edges correspond to all possible paths of length two in the underlying graph.</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths_2, max_order=2)\ng = m.layers[2]\npp.plot(g, node_label=g.nodes);\n</pre> m = pp.MultiOrderModel.from_path_data(paths_2, max_order=2) g = m.layers[2] pp.plot(g, node_label=g.nodes); In\u00a0[14]: Copied! <pre>print(g.mapping)\nprint(g.data.edge_index)\nprint(g.data.edge_weight)\n</pre> print(g.mapping) print(g.data.edge_index) print(g.data.edge_weight) <pre>(np.str_('a'), np.str_('c')) -&gt; 0\n(np.str_('b'), np.str_('c')) -&gt; 1\n(np.str_('c'), np.str_('d')) -&gt; 2\n(np.str_('c'), np.str_('e')) -&gt; 3\n\nEdgeIndex([[0, 0, 1, 1],\n           [2, 3, 2, 3]], sparse_size=(4, 4), nnz=4, sort_order=row)\ntensor([2., 2., 2., 2.])\n</pre> <p>We thus find that the second-order De Bruijn graph representation of paths is sensitive to the differences in the causal topology, while a first-order graph is not. This is the basis to generalize network analysis and graph learning to causality-aware graph models for various kinds of time series data on graphs. In particular, as we shall see in more detail in a later tutorial, we can use paths to generate k-th order graphs that can be used to generalize Graph Neural Networks to higher-order De Bruijn Graphs.</p> <p>Note that all higher-order graphs are simply <code>Graph</code> objects, which means that we can iterate through the nodes of a higher-order graph just like for normal graphs. Node indices are automatically mapped, yielding tuples of first-order node identifiers.</p> In\u00a0[15]: Copied! <pre>for n in g.nodes:\n    print(n)\n</pre> for n in g.nodes:     print(n) <pre>('a', 'c')\n('b', 'c')\n('c', 'd')\n('c', 'e')\n</pre> <p>Edges are tuples with two elements, where each element is a k-th order node, i.e. a tuple of node IDs of length $k$. I.e. for a second-order model the edges are tuples of length two, each entry containing s tuple of length two.</p> In\u00a0[16]: Copied! <pre>for e in g.edges:\n    print(e)\n</pre> for e in g.edges:     print(e) <pre>(('a', 'c'), ('c', 'd'))\n(('a', 'c'), ('c', 'e'))\n(('b', 'c'), ('c', 'd'))\n(('b', 'c'), ('c', 'e'))\n</pre> <p>The weight attribute stores a tensor whose entries capture the frequencies of edges, i.e. the frequencies of paths of length $k$.</p> In\u00a0[17]: Copied! <pre>for e in g.edges:\n    print(e, g['edge_weight', e[0], e[1]].item())\n</pre> for e in g.edges:     print(e, g['edge_weight', e[0], e[1]].item()) <pre>(('a', 'c'), ('c', 'd')) 2.0\n(('a', 'c'), ('c', 'e')) 2.0\n(('b', 'c'), ('c', 'd')) 2.0\n(('b', 'c'), ('c', 'e')) 2.0\n</pre> <p>We can finally plot a higher-order De Bruijn graph in the same way as a first-order graph.</p> In\u00a0[18]: Copied! <pre>pp.plot(g, node_label=g.nodes, edge_color='gray');\n</pre> pp.plot(g, node_label=g.nodes, edge_color='gray'); <p>Let us compare this to a second-order graph model of the second path data set <code>paths_2</code> from above, which corresponds to a network where all possible paths of length two actually occur. Hence, different from the data in <code>paths</code>, all pairs of nodes in this graph can causally influence each other via paths of length two.</p> In\u00a0[\u00a0]: Copied! <pre>m1 = pp.MultiOrderModel.from_path_data(paths, max_order=2)\nprint(m1.estimate_order(paths, significance_threshold=0.01))\n</pre> m1 = pp.MultiOrderModel.from_path_data(paths, max_order=2) print(m1.estimate_order(paths, significance_threshold=0.01)) <pre>2\n</pre> <pre>/opt/conda/lib/python3.11/site-packages/torch_geometric/edge_index.py:863: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n  return torch.sparse_csr_tensor(\n</pre> <p>For <code>paths_2</code> where the observed paths are in line what we would expect based on the weighted edges in the first-order graph model, we correctly find that we do not need to consider a second-order model</p> In\u00a0[\u00a0]: Copied! <pre>m2 = pp.MultiOrderModel.from_path_data(paths_2, max_order=2)\nprint(m2.estimate_order(paths_2, significance_threshold=0.01))\n</pre> m2 = pp.MultiOrderModel.from_path_data(paths_2, max_order=2) print(m2.estimate_order(paths_2, significance_threshold=0.01)) <pre>1\n</pre> <p>Admittedly, the situation in the <code>paths</code> data is extreme insofar as two of the possible paths of lengths two have not been observed at all. We can also have more subtle deviations from the expectation based on the first-order graph model. Consider the following case, where two of the paths are observed more often than two other paths. Note that we have assigned the path frequencies such that again all edges are traversed with exactly the same frequencies, i.e. all edge weights are again equal in the first-order graph.</p> In\u00a0[\u00a0]: Copied! <pre>g = pp.Graph.from_edge_list([('a', 'c'),\n                             ('b', 'c'),\n                             ('c', 'd'),\n                             ('c', 'e')])\npaths_3 = pp.PathData(g.mapping)\n\npaths_3.append_walk(('a', 'c', 'd'), weight=6.0)\npaths_3.append_walk(('a', 'c', 'e'), weight=2.0)\n\npaths_3.append_walk(('b', 'c', 'e'), weight=6.0)\npaths_3.append_walk(('b', 'c', 'd'), weight=2.0)\n\nm3 = pp.MultiOrderModel.from_path_data(paths_3, max_order=2)\nprint(m3.layers[1].data.edge_weight)\nprint(m3.estimate_order(paths_3, significance_threshold=0.01))\n</pre> g = pp.Graph.from_edge_list([('a', 'c'),                              ('b', 'c'),                              ('c', 'd'),                              ('c', 'e')]) paths_3 = pp.PathData(g.mapping)  paths_3.append_walk(('a', 'c', 'd'), weight=6.0) paths_3.append_walk(('a', 'c', 'e'), weight=2.0)  paths_3.append_walk(('b', 'c', 'e'), weight=6.0) paths_3.append_walk(('b', 'c', 'd'), weight=2.0)  m3 = pp.MultiOrderModel.from_path_data(paths_3, max_order=2) print(m3.layers[1].data.edge_weight) print(m3.estimate_order(paths_3, significance_threshold=0.01)) <pre>tensor([8., 8., 8., 8.])\n1\n</pre> <p>In this example, due to the relatively small number of observations, the deviations from the expected baseline are still not strong enough to detect the optimal order of two (at least not for a significance threshold of $0.01$). We would need to raise the signififance threshold to $0.15$ to detect order two:</p> In\u00a0[22]: Copied! <pre>print(m3.estimate_order(paths_3, significance_threshold=0.15))\n</pre> print(m3.estimate_order(paths_3, significance_threshold=0.15)) <pre>2\n</pre> <p>Alternatively, we are able to detect a significant deviation from a first-order model for a significance threshold of $0.01$ if we make the deviations more extreme. If we observe two fo the paths seven times, while the other two are only observed once we find that order two is significant at a sigificance threshold of $0.01$.</p> In\u00a0[\u00a0]: Copied! <pre>paths_3 = pp.PathData(g.mapping)\n\npaths_3.append_walk(('a', 'c', 'd'), weight=7.0)\npaths_3.append_walk(('a', 'c', 'e'), weight=1.0)\n\npaths_3.append_walk(('b', 'c', 'e'), weight=7.0)\npaths_3.append_walk(('b', 'c', 'd'), weight=1.0)\n\nm3 = pp.MultiOrderModel.from_path_data(paths_3, max_order=2)\nprint(m3.layers[1].data.edge_weight)\nprint(m3.estimate_order(paths_3, significance_threshold=0.01))\n</pre> paths_3 = pp.PathData(g.mapping)  paths_3.append_walk(('a', 'c', 'd'), weight=7.0) paths_3.append_walk(('a', 'c', 'e'), weight=1.0)  paths_3.append_walk(('b', 'c', 'e'), weight=7.0) paths_3.append_walk(('b', 'c', 'd'), weight=1.0)  m3 = pp.MultiOrderModel.from_path_data(paths_3, max_order=2) print(m3.layers[1].data.edge_weight) print(m3.estimate_order(paths_3, significance_threshold=0.01)) <pre>tensor([8., 8., 8., 8.])\n2\n</pre> <p>The ability to detect the optimal higher-order for a given data set in a statistically principled way is a powerful feature of the modelling framework of higher-order De Bruijn Graphs. Admittedly, the likelihood-based model selection approach has its limitations especially for small data sets or partially observed graphs, where it can both over- or underfit. To address this, we have developed an alternative Bayesian model selection technique that is explained and evaluated in the following paper:</p> <p>L Petrovic, I Scholtes: Learning the Markov order of paths, In Proc. of the ACM Web Conference (WWW'22), April 2022</p> <p>Unfortunately, this method has not yet been implemented in <code>pathpyG</code> but we are planning to add it soon.</p> In\u00a0[11]: Copied! <pre>paths_tube = pp.io.read_csv_path_data(path_or_buf='../data/tube_paths_train.ngram', sep=',', weight=True)\nprint(paths_tube)\n</pre> paths_tube = pp.io.read_csv_path_data(path_or_buf='../data/tube_paths_train.ngram', sep=',', weight=True) print(paths_tube) <pre>PathData with 61748 paths with total weight 2147865.0\n</pre> <p>To plot a (first-order) graph representation of the London Tube metro network, we can use the following code:</p> In\u00a0[\u00a0]: Copied! <pre>m = pp.MultiOrderModel.from_path_data(paths_tube, max_order=1)\ng = m.layers[1]\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_path_data(paths_tube, max_order=1) g = m.layers[1] pp.plot(g, node_label=g.mapping.node_ids.tolist()); <p>In general, the maximum size of a higher-order model could grow exponentially with the number of nodes in the underlying graph. However, for most empirical data sets, higher-order models are actually sparse, which allows us to efficiently construct them using GPU-based operations. We demonstrate this in the London Tube data sets by constructing all higher-order De Bruijn graph models up to order 20, which takes approx. 25 seconds on a mobile GPU (RTX A2000) and yields reasonably sized higher-order models.</p> In\u00a0[\u00a0]: Copied! <pre>paths_tube.to(device)\nm = pp.MultiOrderModel.from_path_data(paths_tube, max_order=20)\nprint(m.layers[20])\n</pre> paths_tube.to(device) m = pp.MultiOrderModel.from_path_data(paths_tube, max_order=20) print(m.layers[20]) <pre>Directed graph with 5634 nodes and 4729 edges\n{   'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4729])\"},\n    'Graph Attributes': {'inverse_idx': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([18950])\", 'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {}}\n</pre> <p>As we shall see in the following two units, the <code>MultiOrderGraph</code> class is also the basis for the GPU-based analysis and modelling of causal structures in temporal graphs. In particular, the underlying generalization of first-order static graph models to higher-order De Bruijn graphs allows us to easily build causality-aware graph neural network architectures that consider both the topology and the temoral ordering of time-stamped edges in a temporal graph. We will</p>"},{"location":"tutorial/paths_higher_order/#path-data-and-higher-order-de-bruijn-graphs","title":"Path Data and Higher-Order De Bruijn Graphs\u00b6","text":""},{"location":"tutorial/paths_higher_order/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/paths_higher_order/#motivation-and-learning-objective","title":"Motivation and Learning Objective\u00b6","text":"<p>While <code>pathpyG</code> is useful to handle and visualize static graphs - as the name suggests - its main advantage is that it facilitates the analysis of time series data that can be used to calculate paths in a graph. As we shall see in the following tutorial, there are various situations in which naturally have access to data on paths, including data on (random) walks or trajectories, traces of dynamical processes giving rise to node sequences or directed acyclic graphs, or time-respecting paths in temporal graphs. ``pathpyG` can be used to model patterns in such data based on higher-order De Bruijn graph models.</p> <p>In this first unit, we will show how <code>pathpyG</code> supports to represent data on paths in graphs. Like graphs, such data are internally stored as tensors, which facilitates GPU-based operations to create higher-order De Bruijn graphs.</p> <p>We first import the modules <code>torch</code> and <code>pathpyG</code>. By setting the device used by <code>torch</code>, we can specify whether we want to run our code on the CPU or on the GPU.</p>"},{"location":"tutorial/paths_higher_order/#using-pathdata-to-store-walks-or-paths-in-a-graph","title":"Using <code>PathData</code> to store walks or paths in a graph\u00b6","text":"<p>Assume that we have time series data that captures observations of trajectories (i.e. walks or paths) in the graph above. For example, we could observe four walks of length two, four each of the following:</p> <ul> <li>4 x <code>a</code> -&gt; <code>c</code> -&gt; <code>d</code></li> <li>4 x <code>b</code> -&gt; <code>c</code> -&gt; <code>e</code></li> </ul> <p>Note that we define the length of a walk or path as the number of edges that are traversed, i.e. a sequence that consists of a single node, e.g. <code>a</code>, is considered a walk of length zero, while every edge in a graph is a walk of length one.</p> <p><code>pp.PathData</code> supports to store and model such sequential data. We first create an instance of the <code>PathData</code> class. To consistently map node IDs to indices across <code>Graph</code> and <code>PathData</code> objects, we can pass the <code>IndexMap</code> object from the <code>Graph</code> above in the constructor. We then use the <code>append_walk</code> function to add observations of our two walks, where the <code>weight</code> argument is used to indicate the number of times each path or walk has been observed.</p>"},{"location":"tutorial/paths_higher_order/#from-graphs-to-higher-order-de-bruijn-graph-models","title":"From Graphs to Higher-Order De Bruijn Graph Models\u00b6","text":"<p>As we have seen above, the use of a first-order graph model discards information in path data, which capture which nodes can possibly causally influence each other via paths. A key feature of <code>pathpyG</code> is it allows to generalize this first-order modelling perspective to $k$-th order De Bruijn graph models for paths, where the nodes in a $k$-th order De Bruijn graph model are sequences of $k$ nodes. Edges connect pairs of nodes that overlap in $k-1$ nodes and capture paths of length $k$.</p> <p>A De Bruijn graph of order $k=1$ is simply a normal (weighted) static graph consisting of nodes and edges. Pairs of nodes connected by edges overlap in $k-1=0$ nodes and capture paths of length $k=1$, i.e. simple dyadic edges in the underlying path data.</p> <p>For a De Bruijn graph with order $k=2$, in our example above, an edge connects a pair of nodes $(a,b)$ and $(b,c)$ that overlaps in the $k-1=1$ node $b$. Such an edge represents the path $a -&gt; b -&gt; c$ of length two. We can use the <code>MultiOderModel</code> class to generate a second-order De Bruijn graph representation of the path data above. We just have to set the <code>max_order</code> parameter to two and use the second layer of the resulting <code>MultiOrderModel</code> instance.</p>"},{"location":"tutorial/paths_higher_order/#detecting-the-optimal-order-of-higher-order-de-bruijn-graph-models","title":"Detecting the Optimal Order of Higher-Order De Bruijn Graph Models\u00b6","text":"<p>The fact that we can model the same set of paths with higher-order De Bruijn graph models with different orders $k$ raises an important question: What is the optimal order to model a given <code>PathData</code> instance. It is actually easy to answer this question in our example above.</p> <p>For the data contained in <code>paths</code>, we observe only two of the four possible paths, which is different from what we would expect based on a first-order graph model. To capture this pattern in the node sequenves, a first-order graph model is not sufficient and we need a second-order De Bruoijn graph model.</p> <p>For <code>paths_2</code> this is different: Here we observe all four paths of length two with the same frequency, which is exactly what we would expect based on the first-order weighted graph, where all edge weights are the same. Hence, for <code>paths_2</code> the second-order De Bruijn graph model contains no additional information compared to a first-order weighted graph, which means a first-order model is sufficient.</p> <p>While it is easy to see this in the toy example, for real data we need a principled method to automatically determine the optimal order of a higher-order De Bruijn graph model. Luckily, this can be achieved based on statistical model selection in a multi-order De Bruijn graph model. Here we cannot explain the details of this method, so we kindly refer you to the following paper:</p> <p>I Scholtes: When is a Network a Network?: Multi-Order Graphical Model Selection in Pathways and Temporal Networks, In Proc. of SIGKDD 2017, August 2017</p> <p>The method introduced in this paper is implemented in <code>pathpyG</code>. To determine the optimal order of a higher-order De Bruijn graph model for the node sequences contained in a given <code>PathData</code> instance, we can use the <code>MultiOderModel.estimate_order</code> method. Since the method is based on statistical hypothesis testing, we can also pass a significance threshold, which - in line with the interpretation of p-values - bounds the type I error rate of our test, i.e. the rate at which we wrongly reject the null hypothesis that the true optimal order of a data set is $k-1$ in favor of the alternative hypothesis that the order is $k$.</p> <p>Let us test this for our toy example. Using a significance threshold of $0.01$, we determine the optimal order for the data set <code>paths</code> that should actually warrant a second-order model:</p>"},{"location":"tutorial/paths_higher_order/#loading-empirical-path-data-from-n-gram-files","title":"Loading empirical path data from N-Gram Files\u00b6","text":"<p>For real data on walks in graphs it is not convenient to manually construct and add walks based on edge tensors. We can instead use the <code>from_ngram</code> function of class <code>PathData</code> to load such data from an n-gram file, i.e. a text file where each line corresponds to one observed walk consisting of comma-separated node IDs. If we set the argument <code>weight=True</code>, the last component of each line is considered to be the observation frequency of that particular walk.</p> <p>As an example, the file <code>data/tube_paths_train.ngram</code> contains observed passenger itineraries between nodes in a graph that representes the network of London Tube stations. Each of those itineraries is associated with an observation frequencies. The following is an excerpt from that file:</p> <pre><code>Southwark,Waterloo,212.0\nLiverpool Street,Bank / Monument,1271.0\nBarking,West Ham,283.0\nTufnell Park,Kentish Town,103.0\n...\n</code></pre> <p>Note that this will automatically create an internal mapping of node IDs to indices.</p>"},{"location":"tutorial/temporal_graphs/","title":"Temporal Graphs","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[3]: Copied! <pre>import torch\nfrom torch_geometric.data import Data\nimport pathpyG as pp\nimport pandas as pd\n</pre> import torch from torch_geometric.data import Data import pathpyG as pp import pandas as pd <p>We can create a temporal graph object from a list of time-stamped edges. Since <code>TemporalGraph</code> is a subclass of the <code>Graph</code> class, the internal structures are very similar:</p> In\u00a0[4]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nprint(t.mapping)\nprint(t.n)\nprint(t.m)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) print(t.mapping) print(t.n) print(t.m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n10\n</pre> <p>By default, all temporal graphs are directed. We can create an undirected version a temporal graph as follows:</p> In\u00a0[5]: Copied! <pre>x = t.to_undirected()\nprint(x.mapping)\nprint(x.n)\nprint(x.m)\n</pre> x = t.to_undirected() print(x.mapping) print(x.n) print(x.m) <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\nd -&gt; 3\n\n4\n20\n</pre> <p>We can also directly create a temporal graph from an instance of <code>pyG.TemporalData</code></p> In\u00a0[6]: Copied! <pre>td = Data(\n    edge_index = torch.Tensor([[0,1,2,0],[1,2,3,1]]).long(),\n    time = torch.Tensor([0,1,2,3])\n)\nprint(td)\nt2 = pp.TemporalGraph(td)\nprint(t2)\n</pre> td = Data(     edge_index = torch.Tensor([[0,1,2,0],[1,2,3,1]]).long(),     time = torch.Tensor([0,1,2,3]) ) print(td) t2 = pp.TemporalGraph(td) print(t2) <pre>Data(edge_index=[2, 4], time=[4])\nTemporal Graph with 4 nodes, 3 unique edges and 4 events in [0.0, 3.0]\n{'Edge Attributes': {}, 'Graph Attributes': {}, 'Node Attributes': {}}\n</pre> <pre>/opt/conda/lib/python3.11/site-packages/torch_geometric/data/storage.py:452: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index', 'time'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> <p>We can restrict a temporal graph to a time window, which returns a temporal graph that only contains time-stamped edges in the given time interval.</p> In\u00a0[7]: Copied! <pre>t1 = t.get_window(0,4)\nprint(t1)\nprint(t1.m)\nprint(t1.start_time)\nprint(t1.end_time)\n</pre> t1 = t.get_window(0,4) print(t1) print(t1.m) print(t1.start_time) print(t1.end_time) <pre>Temporal Graph with 4 nodes, 5 unique edges and 7 events in [1, 4]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n7\n1\n4\n</pre> <p>We can also extract a TemporalGraph object for a batch of temporal edges, which is defined by the start and end index of the edges defining the batch.</p> In\u00a0[8]: Copied! <pre>t1 = t.get_batch(1,6)\nprint(t1)\nprint(t1.m)\nprint(t1.start_time)\nprint(t1.end_time)\n</pre> t1 = t.get_batch(1,6) print(t1) print(t1.m) print(t1.start_time) print(t1.end_time) <pre>Temporal Graph with 4 nodes, 4 unique edges and 5 events in [2, 4]\n{'Edge Attributes': {}, 'Graph Attributes': {}, 'Node Attributes': {}}\n5\n2\n4\n</pre> <p>We can easily convert a temporal graph into a weighted time-aggregated static graph, where edge weights count the number of occurrences of an edge across all timestamps.</p> In\u00a0[9]: Copied! <pre>g = t.to_static_graph(weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(weighted=True) print(g) <pre>Directed graph with 4 nodes and 6 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>We can also aggregate a temporal graph within a certain time window:</p> In\u00a0[10]: Copied! <pre>g = t.to_static_graph(time_window=(1, 3), weighted=True)\nprint(g)\n</pre> g = t.to_static_graph(time_window=(1, 3), weighted=True) print(g) <pre>Directed graph with 2 nodes and 1 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> <p>Finally, we can use the class <code>RollingTimeWindow</code> to perform a rolling window analysis. The class returns an iterable object, where each iteration yields a time-aggregated weighted graph object as well as the corresponding time window.</p> In\u00a0[11]: Copied! <pre>r = pp.algorithms.RollingTimeWindow(t, window_size=3, step_size=1, return_window=True)\nfor g, w in r:\n    print('Time window ', w)\n    print(g)\n    print(g.data.edge_index)\n    print('---')\n</pre> r = pp.algorithms.RollingTimeWindow(t, window_size=3, step_size=1, return_window=True) for g, w in r:     print('Time window ', w)     print(g)     print(g.data.edge_index)     print('---') <pre>Time window  (1, 4)\nDirected graph with 3 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 1],\n           [1, 0, 2]], sparse_size=(3, 3), nnz=3, sort_order=row)\n---\nTime window  (2, 5)\nDirected graph with 4 nodes and 5 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 1, 2, 3],\n           [1, 0, 2, 1, 2]], sparse_size=(4, 4), nnz=5, sort_order=row)\n---\nTime window  (3, 6)\nDirected graph with 4 nodes and 6 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 1, 2, 2, 3],\n           [1, 0, 2, 1, 3, 2]], sparse_size=(4, 4), nnz=6, sort_order=row)\n---\nTime window  (4, 7)\nDirected graph with 4 nodes and 5 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[0, 1, 2, 2, 3],\n           [1, 0, 1, 3, 2]], sparse_size=(4, 4), nnz=5, sort_order=row)\n---\nTime window  (5, 8)\nDirected graph with 4 nodes and 3 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[1, 2, 2],\n           [0, 1, 3]], sparse_size=(4, 4), nnz=3, sort_order=row)\n---\nTime window  (6, 9)\nDirected graph with 3 nodes and 1 edges\n{'Edge Attributes': {'edge_weight': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1])\"}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\nEdgeIndex([[2],\n           [1]], sparse_size=(3, 3), nnz=1, sort_order=row)\n---\n</pre> <p>We can visualize temporal graphs using the plot function just like static graphs:</p> In\u00a0[26]: Copied! <pre>pp.plot(t, node_label=t.nodes, edge_color='lightgray');\n</pre> pp.plot(t, node_label=t.nodes, edge_color='lightgray'); <p>The source nodes, destination nodes and timestamps of time-stamped edges are stored as a <code>pyG TemporalData</code> object, which we can access in the following way.</p> In\u00a0[13]: Copied! <pre>t.data\n</pre> t.data Out[13]: <pre>Data(edge_index=[2, 10], time=[10], num_nodes=4)</pre> In\u00a0[14]: Copied! <pre>print(t.data.edge_index)\n</pre> print(t.data.edge_index) <pre>EdgeIndex([[0, 0, 1, 1, 3, 0, 2, 2, 1, 2],\n           [1, 1, 0, 2, 2, 1, 1, 3, 0, 1]], sparse_size=(4, 4), nnz=10)\n</pre> In\u00a0[15]: Copied! <pre>print(t.data.time)\n</pre> print(t.data.time) <pre>tensor([1, 2, 3, 3, 4, 4, 4, 5, 5, 6])\n</pre> <p>With the generator functions <code>edges</code> and <code>temporal_edges</code> we can iterate through the time-ordered (temporal) multi-edges of a temporal graph.</p> In\u00a0[16]: Copied! <pre>for v, w in t.edges:\n    print(v, w)\n</pre> for v, w in t.edges:     print(v, w) <pre>a b\na b\nb a\nb c\nd c\na b\nc b\nc d\nb a\nc b\n</pre> In\u00a0[17]: Copied! <pre>for v, w, time in t.temporal_edges:\n    print(v, w, time)\n</pre> for v, w, time in t.temporal_edges:     print(v, w, time) <pre>a b 1\na b 2\nb a 3\nb c 3\nd c 4\na b 4\nc b 4\nc d 5\nb a 5\nc b 6\n</pre> <p>We are often interested in time-respecting paths in a temporal graph. A time-respecting path consists of a sequence of nodes $v_0,...,v_l$ where consecutive nodes are connected by time-stamped edges that occur (i) in the right temporal ordering, and (ii) within a maximum time difference of $\\delta\\in \\N$.</p> <p>To calculate time-respecting paths in a temporal graph, we can construct a directed acyclic graph (DAG), where each time-stamped edge $(u,v;t)$ in the temporal graph is represented by a node and two nodes representing time-stamped edges $(u,v;t_1)$ and $(v,w;t_2)$ are connected by an edge iff $0 &lt; t_2-t_1 \\leq \\delta$. This implies that (i) each edge in the resulting DAG represents a time-respecting path of length two, and (ii) time-respecting paths of any lenghts are represented by paths in this DAG.</p> <p>We can construct such a DAG using the function <code>pp.algorithms.lift_order_temporal</code>, which returns an edge_index. We can pass this to the constructor of a <code>Graph</code> object, which we can use to visualize the resulting DAG.</p> In\u00a0[18]: Copied! <pre>e_i = pp.algorithms.lift_order_temporal(t, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\npp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]);\n</pre> e_i = pp.algorithms.lift_order_temporal(t, delta=1) dag = pp.Graph.from_edge_index(e_i) pp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 1993.65it/s]\n</pre> <p>For $\\delta=1$, this DAG with three connected components tells us that the underlying temporal graph has  the following time-respecting paths (of different lengths):</p> <p>Length one: a -&gt; b b -&gt; a b -&gt; c c -&gt; b c -&gt; d d -&gt; c</p> <p>Length two: a -&gt; b -&gt; a (twice, starting at time 2 and time 4) b -&gt; a -&gt; b a -&gt; b -&gt; c b -&gt; c -&gt; b c -&gt; b -&gt; a d -&gt; c -&gt; d</p> <p>Length three: a -&gt; b -&gt; a -&gt; b b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b b -&gt; c -&gt; b -&gt; a</p> <p>Length four: a -&gt; b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b -&gt; a</p> <p>We can can use the function <code>pp.algorithms.temporal.temporal_shortest_paths</code> to calculate shortest time-respecting path distances between any pair of nodes. This also returns a predecessor matrix, which can be used to reconstruct all shortest time-respecting paths (in analogy to the Dijkstra algorithm for static graphs):</p> In\u00a0[27]: Copied! <pre>dist, pred = pp.algorithms.temporal_shortest_paths(t, delta=1)\nprint(t.mapping)\nprint(dist)\nprint(pred)\n</pre> dist, pred = pp.algorithms.temporal_shortest_paths(t, delta=1) print(t.mapping) print(dist) print(pred) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00, 2171.34it/s]</pre> <pre>a -&gt; 0\nb -&gt; 1\nc -&gt; 2\n\n[[ 0.  1.  1.]\n [inf  0.  1.]\n [inf inf  0.]]\n[[ 0  0  0]\n [-1  1  1]\n [-1 -1  2]]\n</pre> <pre>\n</pre> <p>In the example above, the four <code>inf</code> values indicate that there is no time-respecting paths between the four node pairs (a, d), (b, d), (d,a) and (d, b). This is not something we would expect based on the (strongly connected) topology of the time-aggregated graph, which is shown below:</p> In\u00a0[20]: Copied! <pre>g = t.to_static_graph(weighted=True)\npp.plot(g, node_label=g.mapping.node_ids.tolist());\n</pre> g = t.to_static_graph(weighted=True) pp.plot(g, node_label=g.mapping.node_ids.tolist()); In\u00a0[21]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\ndf = pp.io.temporal_graph_to_df(t)\nprint(df)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) df = pp.io.temporal_graph_to_df(t) print(df) <pre>   v  w  t\n0  a  b  1\n1  a  b  2\n2  b  a  3\n3  b  c  3\n4  d  c  4\n5  a  b  4\n6  c  b  4\n7  c  d  5\n8  b  a  5\n9  c  b  6\n</pre> In\u00a0[22]: Copied! <pre>t = pp.io.df_to_temporal_graph(df)\nprint(t)\n</pre> t = pp.io.df_to_temporal_graph(df) print(t) <pre>Temporal Graph with 4 nodes, 6 unique edges and 10 events in [1, 6]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> In\u00a0[23]: Copied! <pre>df = pd.DataFrame([['a', 'b', 1], ['b', 'c', 2], ['a', 'c', 3]])\nprint(df)\nt = pp.io.df_to_temporal_graph(df)\nprint(t)\n</pre> df = pd.DataFrame([['a', 'b', 1], ['b', 'c', 2], ['a', 'c', 3]]) print(df) t = pp.io.df_to_temporal_graph(df) print(t) <pre>   0  1  2\n0  a  b  1\n1  b  c  2\n2  a  c  3\nTemporal Graph with 3 nodes, 3 unique edges and 3 events in [1, 3]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> In\u00a0[28]: Copied! <pre>pp.io.write_csv(t, path_or_buf='../data/test_temporal_graph.csv')\n</pre> pp.io.write_csv(t, path_or_buf='../data/test_temporal_graph.csv') In\u00a0[29]: Copied! <pre>t = pp.io.read_csv_temporal_graph('../data/test_temporal_graph.csv')\nprint(t)\n</pre> t = pp.io.read_csv_temporal_graph('../data/test_temporal_graph.csv') print(t) <pre>Temporal Graph with 3 nodes, 3 unique edges and 3 events in [1, 3]\n{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"}, 'Node Attributes': {}}\n</pre> In\u00a0[30]: Copied! <pre>t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False)\nprint(t_ants)\n</pre> t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False) print(t_ants) <pre>Temporal Graph with 89 nodes, 947 unique edges and 1911 events in [0, 1438]\n{   'Edge Attributes': {'edge_attr_1': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\", 'edge_attr_2': \"&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1911])\"},\n    'Graph Attributes': {'num_nodes': \"&lt;class 'int'&gt;\"},\n    'Node Attributes': {}}\n</pre> <p>To calculate the temporal closeness centrality, which is defined based on the length of shortest time-respecting paths of a node to all other nodes, we can write the following:</p> In\u00a0[\u00a0]: Copied! <pre>cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60)\nprint(cl)\nmx = max(cl.values())\nmn = min(cl.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=60) print(cl) mx = max(cl.values()) mn = min(cl.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3322.84it/s]\n</pre> <pre>{'GBGR': 3024.615873015872, 'GBGW': 2999.502564102565, 'GBG_': 2928.756043956045, 'GGGG': 2859.2000000000007, 'GGGR': 2811.4253968253956, 'GGRR': 4383.866666666668, 'GGRY': 3304.400000000001, 'GGWW': 3418.311111111112, 'GGWY': 5092.2666666666655, 'GGW_': 4230.076190476191, 'GGYW': 2556.571916971917, 'GG_W': 3788.4000000000015, 'GRBR': 2977.3714285714286, 'GRGY': 3039.911111111111, 'GRWG': 4162.714285714285, 'GRYY': 2736.625396825396, 'GR_Y': 3113.7333333333336, 'GR_Y2': 4416.133333333335, 'GR__': 3305.8666666666663, 'GWRG': 3379.2000000000003, 'GYGG': 3321.2977777777783, 'GYYY': 2301.3777777777777, 'GY__': 2260.066666666665, 'G_GW': 3525.866666666667, 'G_R_': 4034.800000000001, 'G_W_': 3010.4380952380957, 'G___': 3100.533333333335, 'G___big': 2068.308913308913, 'G___small': 2351.7999999999993, 'Q': 4177.311111111112, 'RWGY': 3708.5714285714307, 'RWWG': 3030.488888888889, 'WBGG': 3781.0666666666675, 'WBGW': 3166.742857142857, 'WBYG': 2668.5999999999995, 'WGBB': 3440.171428571429, 'WGGB': 3751.1047619047636, 'WGWB': 4185.7619047619055, 'WG_R': 4216.666666666668, 'WRBB': 4256.266666666667, 'WRRY': 3768.600000000001, 'WRR_': 2583.8825396825387, 'WRWR': 3951.200000000001, 'WR__': 3180.7111111111117, 'WWBG': 2788.5206349206346, 'WYGG': 3617.466666666668, 'W___': 3253.0666666666675, 'YGWW': 4867.866666666667, 'YGWY': 2735.542857142857, 'YWGW': 3273.5999999999995, 'YWWW': 2991.999999999999, 'YWW_': 3136.082539682539, 'YW__': 1220.9476986781337, 'YYGG': 4430.8, 'YYGGmid': 4461.6, 'YYGGright': 3284.565079365079, 'YYGW': 3462.844444444446, 'YYRB': 3366.0000000000005, 'YYRG': 2891.30862663906, 'YYWR': 3060.6888888888893, 'YYYY': 2510.339682539682, 'YYY_': 2561.692063492063, 'YY_R': 3472.926984126984, 'YY_W': 3874.9333333333357, 'YY__': 2901.5206349206346, 'Y_WY': 3572.800000000001, 'Y__W': 2301.933333333332, 'Y___': 3097.8444444444453, '_RYG': 1844.680341880342, '_R__': 4439.600000000002, '_WGG': 3781.0666666666684, '_WWW': 2961.6539682539687, '_WWY': 4007.771428571429, '_WYG': 3018.9199999999996, '_WYW': 4252.914285714287, '_W_Y': 3262.742857142857, '_W__': 4009.8666666666677, '_Y__': 2881.7179487179487, '__BB': 3040.9200000000005, '__W_': 3649.4158730158724, '____almost': 3127.809523809524, '____bm': 3655.6, '____bot': 2454.007326007325, '____brood': 3952.0380952380965, '____corner': 3856.638095238096, '____pale': 4692.7047619047635, '____right': 2577.243809523809, '____topleft': 3392.4, '____topright': 2641.047619047619}\n</pre> <p>The definition of time-respecting paths depends on our maximum time difference parameter $\\delta$, which implies that different values of this parameter also yield different centralities. This means that we can calculate temporal node centralities for different \"time scales\" of a temporal graph.</p> In\u00a0[\u00a0]: Copied! <pre>cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=20)\nprint(cl)\nmx = max(cl.values())\nmn = min(cl.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> cl = pp.algorithms.centrality.temporal_closeness_centrality(t_ants, delta=20) print(cl) mx = max(cl.values()) mn = min(cl.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in cl.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3573.09it/s]\n</pre> <pre>{'GBGR': 2207.0092796092795, 'GBGW': 1574.1780861656403, 'GBG_': 2245.6238095238077, 'GGGG': 2065.6316957552262, 'GGGR': 2052.219608851188, 'GGRR': 3774.042140822139, 'GGRY': 2541.641269841269, 'GGWW': 2203.5236655224166, 'GGWY': 4598.104761904761, 'GGW_': 3827.514285714286, 'GGYW': 1998.2796889101228, 'GG_W': 3159.310780722547, 'GRBR': 2252.3125606823146, 'GRGY': 1961.2073260073257, 'GRWG': 3434.115731505299, 'GRYY': 1769.6720992921016, 'GR_Y': 2458.6663362781, 'GR_Y2': 3750.974603174604, 'GR__': 2287.758730158729, 'GWRG': 2460.425432737198, 'GYGG': 2512.0908424908425, 'GYYY': 1082.0915750915751, 'GY__': 1348.5477329496612, 'G_GW': 2936.1425267542913, 'G_R_': 3429.2739926739923, 'G_W_': 2107.469050754098, 'G___': 2127.2349206349195, 'G___big': 440.0, 'G___small': 1357.2765347758534, 'Q': 3506.6336134453786, 'RWGY': 2859.332112332112, 'RWWG': 2268.550438842203, 'WBGG': 2896.1205924510273, 'WBGW': 2433.333613445378, 'WBYG': 1977.0355670473316, 'WGBB': 2559.064886091109, 'WGGB': 2960.0190476190473, 'WGWB': 3741.2707061969318, 'WG_R': 3544.1333333333337, 'WRBB': 3554.813675213675, 'WRRY': 3153.2702075702073, 'WRR_': 1459.0539682539682, 'WRWR': 3188.4784241901884, 'WR__': 2500.955555555555, 'WWBG': 2036.6218377769462, 'WYGG': 2725.1190476190477, 'W___': 2336.6073260073267, 'YGWW': 4164.021611721611, 'YGWY': 2041.505738705739, 'YWGW': 2504.1366234788234, 'YWWW': 2304.5686202686197, 'YWW_': 2371.849188204297, 'YW__': 176.0, 'YYGG': 3941.017740429505, 'YYGGmid': 3978.1587301587306, 'YYGGright': 2585.841391941392, 'YYGW': 2942.4609600925396, 'YYRB': 2324.445981469511, 'YYRG': 2314.7781799899453, 'YYWR': 2196.252000287295, 'YYYY': 1173.542857142857, 'YYY_': 1451.0821205745692, 'YY_R': 2608.8452541610436, 'YY_W': 3165.41684981685, 'YY__': 2165.776312576312, 'Y_WY': 3077.7333333333327, 'Y__W': 1355.0833598705335, 'Y___': 2157.622222222223, '_RYG': 885.6630036630038, '_R__': 3843.0485958485956, '_WGG': 3243.3761904761905, '_WWW': 1688.0676434676436, '_WWY': 3225.482539682539, '_WYG': 2279.3990591108236, '_WYW': 3684.37142857143, '_W_Y': 2395.1028197945843, '_W__': 3375.862184873949, '_Y__': 2151.667587957515, '__BB': 1831.7949074070343, '__W_': 2927.860263403607, '____almost': 2504.1190835308475, '____bm': 2888.322842445042, '____bot': 1918.2603174603173, '____brood': 3139.037484737485, '____corner': 3197.7706444286337, '____pale': 4135.756532356533, '____right': 1686.4830900989923, '____topleft': 2661.486524002313, '____topright': 1843.6328641362072}\n</pre> <p>We can also calculate the temporal betweenness centrality, which is based on the number of shortest time-respecting paths between pairs of nodes that pass through a given node. Again, this centrality score is sensitive to the time scale parameter $\\delta$.</p> In\u00a0[\u00a0]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=60)\nprint(bw)\nmx = max(bw.values())\nmn = min(bw.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=60) print(bw) mx = max(bw.values()) mn = min(bw.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3475.66it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 89/89 [00:03&lt;00:00, 27.00it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7fdf20a03640&gt;, {'GBGR': 20.192212842427075, 'WGBB': 194.79309833949083, 'WRBB': 365.05013895123216, 'G___': 57.80632230642795, '_WYW': 427.3675796732633, '____topright': 10.760025336141013, 'YYGGmid': 663.4450747248108, '__W_': 46.375038482274306, 'GG_W': 292.080282213412, '_W__': 428.33207844162627, 'WBGW': 71.89857589572318, 'GR__': 64.19763457586924, 'RWWG': 83.25286865190012, '____almost': 134.89554914241063, 'GGGG': 78.97281365765863, 'YYGW': 319.0275353843234, 'YWGW': 84.52883527311734, 'YYWR': 139.62781952597214, 'YYRG': 30.06998326775235, 'WRWR': 130.49639766193505, 'WYGG': 274.1787721126864, 'GGYW': 9.54474098670821, 'GYGG': 206.18561458924665, 'GGWY': 1080.0676471347801, 'G_W_': 30.258200815352502, '_W_Y': 88.46660448533098, '_R__': 724.7535183751095, 'WBGG': 184.56469995815524, 'Y___': 124.00746952439442, '____brood': 261.05135853722055, 'WRRY': 227.56794665132307, '_WWY': 258.17798469631225, 'Y_WY': 168.0214751986637, 'GGWW': 127.47912860736434, 'YYGG': 452.6097076570282, 'YY_W': 372.5488526120025, '____topleft': 72.04751294375436, 'GBG_': 156.55265249530558, 'G_GW': 322.43708957585955, 'YGWY': 17.697241798229907, 'GRBR': 71.17718734804407, 'GGGR': 106.77684001312716, 'GGW_': 756.8587346464093, '____bm': 155.14819522566728, 'WGWB': 353.62165711237867, 'WWBG': 210.3370212595935, 'GRYY': 63.34672574396869, '_WWW': 59.796937914791975, '____right': 6.536713311055403, '_WYG': 159.5168700848977, 'YY__': 48.63844749559088, 'GRGY': 45.365480292377676, 'G_R_': 90.00180925262697, 'Q': 554.8667166042984, 'YYGGright': 329.28472257372005, 'WR__': 38.99166576434191, '____corner': 502.8870906126399, 'WG_R': 269.7153804058385, 'GR_Y2': 337.26045226613337, 'GWRG': 218.44745266674752, 'G___small': 20.205088001429456, 'YGWW': 535.3204311320455, 'YY_R': 143.38496654670294, 'RWGY': 235.07340157680488, 'WGGB': 131.96062903943462, '_WGG': 318.5137155129991, '__BB': 79.02021455742683, 'WBYG': 26.79640022964187, 'GRWG': 385.8105700686363, 'W___': 115.05159194927882, 'GGRR': 487.43937337734934, 'Y__W': 1.0294117647058814, 'GY__': 35.364487473310994, 'GR_Y': 23.23800388929457, 'YWW_': 116.98999358694506, 'YYRB': 32.66941405832229, '_Y__': 25.129282093002608, 'GBGW': 49.133677074004986, 'YYY_': 86.25984566814704, 'GGRY': 269.8419665751779, 'YWWW': 39.83384050331751, '____pale': 591.7102550688354, '____bot': 7.010335960335962, 'GYYY': 9.375127968877965, '_RYG': 5.108461302211301, 'WRR_': 74.76533132490208, 'YYYY': 1.000000000000001, 'G___big': -1.7708057242771247e-14, 'YW__': 0.0})\n</pre> In\u00a0[\u00a0]: Copied! <pre>bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=20)\nprint(bw)\nmx = max(bw.values())\nmn = min(bw.values())\nnode_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() }\npp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4);\n</pre> bw = pp.algorithms.centrality.temporal_betweenness_centrality(t_ants, delta=20) print(bw) mx = max(bw.values()) mn = min(bw.values()) node_size = { v: 50*(x/(mx-mn)) for v, x in bw.items() } pp.plot(t_ants, node_size=node_size, edge_color='red', edge_size=4); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 883/883 [00:00&lt;00:00, 3813.91it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 89/89 [00:01&lt;00:00, 69.84it/s]\n</pre> <pre>defaultdict(&lt;function temporal_betweenness_centrality.&lt;locals&gt;.&lt;lambda&gt; at 0x7fdf20ed9b40&gt;, {'GBGR': 271.0549203258132, 'YY__': 260.787489965592, '_WYG': 394.1302318596431, '____right': 28.503246753246753, 'Q': 1457.263110413932, 'GGRR': 393.6459799032444, 'GGGR': 201.48208556149757, 'YYGGright': 534.66060053214, 'YY_R': 266.91765439796467, 'Y___': 172.67107899804276, '____corner': 551.646068862101, 'YGWW': 1201.1725191494913, 'WG_R': 512.4899073911774, '_WGG': 662.2060823813118, 'YWGW': 71.94722222222224, '____bm': 520.5037887625123, '__BB': 146.4024424420817, '_Y__': 116.65703669247497, 'WBYG': 337.50697274935305, 'YYWR': 346.0394146748694, '_W_Y': 126.7397860593513, 'WBGG': 100.16123039327377, 'Y_WY': 709.6990969778257, '_W__': 888.9702395101842, 'GGWW': 252.45108178976466, 'RWGY': 400.3435250525273, 'WR__': 324.7003673342413, 'G_R_': 74.0687563696638, '____bot': 18.876190476190477, '____pale': 1160.042127920021, '____almost': 586.5742800306991, '____topright': 6.242857142857144, 'YYGG': 900.9820998851815, '_WYW': 910.3151884148607, 'GGW_': 1229.7209102391769, 'G_GW': 411.33446741036244, 'YYGGmid': 941.7798494844893, 'GG_W': 893.2237821543014, 'WWBG': 82.09047619047621, 'GRWG': 765.7519205139172, 'WGGB': 562.7259479161665, 'WRWR': 79.9309806206866, '____topleft': 31.47539682539684, 'GGRY': 1009.5761263646133, 'GGWY': 2510.3962123782903, 'RWWG': 238.21048955595802, 'GBG_': 219.31044140486634, 'WGWB': 651.4299970278146, '_R__': 1516.87808629868, 'GGYW': 96.16713560885782, 'WGBB': 458.9464625746425, 'GRBR': 229.0634357985618, '____brood': 241.461111111111, 'G___small': 2.0000000000000027, 'GR_Y2': 782.0649724285778, 'W___': 307.82509532385853, 'YYGW': 851.6365545426578, 'GY__': 74.0, 'GBGW': 47.5015406162465, 'YYY_': 148.44444444444446, '__W_': 184.20506454409792, 'YYRB': 213.21211161607084, 'WYGG': 427.62927891499254, 'WRBB': 343.03298248682995, 'WRRY': 409.20603349701526, 'YWWW': 8.403968253968255, 'WBGW': 28.814786967418545, 'GR_Y': 24.047859363598853, 'YWW_': 32.92341269841275, '_WWY': 660.9893002248847, 'YGWY': 172.38878675703566, 'GWRG': 172.5340550134477, 'GYGG': 596.7332954372962, 'GRYY': 221.22555230251604, '_RYG': 16.17857142857143, 'YY_W': 444.00904725283243, 'GRGY': 140.32892318821007, 'G___': 111.45865644159763, 'GR__': 91.98653846153846, 'GGGG': 148.8203370642651, 'G_W_': 13.97619047619047, '_WWW': 49.37142857142858, 'YYRG': 13.01755106156194, 'WRR_': 67.70574974670724, 'Y__W': 0.9999999999999983, 'YYYY': 2.0, 'GYYY': 0.0, 'G___big': 1.5154544286133387e-14, 'YW__': -1.4210854715202004e-14})\n</pre>"},{"location":"tutorial/temporal_graphs/#temporal-graph-analysis","title":"Temporal Graph Analysis\u00b6","text":""},{"location":"tutorial/temporal_graphs/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/temporal_graphs/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In this tutorial we will introduce the representation of temporal graph data using the <code>TemporalGraph</code> class and how such data can be used to calculate shortest time respecting paths between nodes as well temporal node cemtralities.</p>"},{"location":"tutorial/temporal_graphs/#extracting-time-respecting-paths-in-temporal-networks","title":"Extracting Time-Respecting Paths in Temporal Networks\u00b6","text":""},{"location":"tutorial/temporal_graphs/#reading-and-writing-temporal-graph-data","title":"Reading and writing temporal graph data\u00b6","text":""},{"location":"tutorial/temporal_graphs/#temporal-centralities-in-empirical-temporal-networks","title":"Temporal Centralities in Empirical Temporal Networks\u00b6","text":"<p><code>pathpyG</code>'s ability to calculate (shortest) time-respecting paths enables us to calulate different notions of temporal centralities for nodes in empirial temporal networks. We can read an empirical temporal graph based on CSV data, where each line contains the source, target, and timestamp of an edge as comma-separated value:</p>"},{"location":"tutorial/trp_higher_order/","title":"Higher-Order Models for Time-Respecting Paths","text":"In\u00a0[1]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[\u00a0]: Copied! <pre>import pathpyG as pp\n</pre> import pathpyG as pp In\u00a0[2]: Copied! <pre>tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),\n              ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)]\nt = pp.TemporalGraph.from_edge_list(tedges)\nprint(t)\n</pre> tedges = [('a', 'b', 1),('a', 'b', 2), ('b', 'a', 3), ('b', 'c', 3), ('d', 'c', 4), ('a', 'b', 4), ('c', 'b', 4),               ('c', 'd', 5), ('b', 'a', 5), ('c', 'b', 6)] t = pp.TemporalGraph.from_edge_list(tedges) print(t) <pre>Temporal Graph with 4 nodes, 6 unique edges and 10 events in [1.0, 6.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> <p>To better understand this temporal graph, we can again create a directed acyclic graph that represents the topology of time-respecting paths:</p> In\u00a0[3]: Copied! <pre>e_i = pp.algorithms.lift_order_temporal(t, delta=1)\ndag = pp.Graph.from_edge_index(e_i)\npp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]);\n</pre> e_i = pp.algorithms.lift_order_temporal(t, delta=1) dag = pp.Graph.from_edge_index(e_i) pp.plot(dag, node_label = [f'{v}-{w}-{time}' for v, w, time in t.temporal_edges]); <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00&lt;00:00, 930.41it/s]\n</pre> <p>For $\\delta=1$, we again have the following time-respecting paths:</p> <p>Length one: a -&gt; b b -&gt; a b -&gt; c c -&gt; b c -&gt; d d -&gt; c Length two: a -&gt; b -&gt; a (twice) b -&gt; a -&gt; b a -&gt; b -&gt; c b -&gt; c -&gt; b c -&gt; b -&gt; a d -&gt; c -&gt; d Length three: a -&gt; b -&gt; a -&gt; b b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b b -&gt; c -&gt; b -&gt; a Length four: a -&gt; b -&gt; a -&gt; b -&gt; a a -&gt; b -&gt; c -&gt; b -&gt; a</p> <p>As you can see, these time-respecting paths are actually very similar to the paths data that we have previously represented using the <code>PathData</code> object. In fact, we could - in theory - first extract all time-respecting paths of all lengths, add them to a <code>PathData</code> object and then use the <code>MultiOderModel</code> class to generate higher-order De Bruijn graph models of all orders. In the example above, since we have paths of length one to four, we could create higher-order models with orders from one to four.</p> <p>However, this approach would not be efficient for large temporal graphs, as it is computationally expensive to calculate all possible time-respecting paths as well as subpaths of length $k$, especially for larger values of $\\delta$. To avoid this bottleneck, <code>pathpyG</code> uses a smarter, GPU-based algorithm to calculate time-respecting paths of length $k$ that are needed for a given order $k$.</p> <p>For the example above, we can generate all higher-order models up to order four as follows:</p> In\u00a0[4]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=4)\n\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=4)  print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 6 nodes and 4 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Remember that in a $k$-th order model nodes capture paths of length $k-1$, while edges capture paths of length $k$.</p> <p>This implies that the first-order model has four nodes and six edges, which simply corresponds to the time-aggregated weighted graph for our example temporal network.</p> In\u00a0[5]: Copied! <pre>print(m.layers[1])\npp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes]);\n</pre> print(m.layers[1]) pp.plot(m.layers[1], node_label=[v for v in m.layers[1].nodes]); <pre>Undirected graph with 4 nodes and 6 (directed) edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 1])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>For the second-order model, we have six nodes, which map to the six different edges (each edge trivially being a time-respecting path of length one) of the temporal graph. The six edges in the second-order model represent the six different time-respecting paths of length two (see above). Since the time-respecting path $a \\rightarrow b \\rightarrow a$  occurs twice at different times, we have one edge with weight two.</p> In\u00a0[6]: Copied! <pre>print(m.layers[2])\nprint(m.layers[2].data.edge_weight)\npp.plot(m.layers[2], node_label=m.layers[2].mapping.node_ids.tolist());\n</pre> print(m.layers[2]) print(m.layers[2].data.edge_weight) pp.plot(m.layers[2], node_label=m.layers[2].mapping.node_ids.tolist()); <pre>Directed graph with 6 nodes and 6 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6])\n\nGraph attributes\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([10])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\ntensor([2., 1., 1., 1., 1., 1.])\n</pre> <p>For the third-oder mode, we have four edges representing the four diffeerent time-respecting paths of length three in the temporal graph above:</p> In\u00a0[7]: Copied! <pre>print(m.layers[3])\npp.plot(m.layers[3], node_label=m.layers[3].mapping.node_ids.tolist());\n</pre> print(m.layers[3]) pp.plot(m.layers[3], node_label=m.layers[3].mapping.node_ids.tolist()); <pre>Directed graph with 6 nodes and 4 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nGraph attributes\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7])\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>And finally, for the model with order $k=4$ we only have two edges, representing the two time-respecting paths $a \\rightarrow b \\rightarrow a \\rightarrow b \\rightarrow a$ and $a \\rightarrow b \\rightarrow c \\rightarrow b \\rightarrow a$:</p> In\u00a0[8]: Copied! <pre>print(m.layers[4])\npp.plot(m.layers[4], node_label=m.layers[4].mapping.node_ids.tolist());\n</pre> print(m.layers[4]) pp.plot(m.layers[4], node_label=m.layers[4].mapping.node_ids.tolist()); <pre>Directed graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>Intuitively, since in our example there are no time-respecting paths longer than four, if we were to generate a multi-order model with De Bruijn graphs with orders larger than four, those graphs cannot contain any edges. We see this in the following example. The first-order graph is simply the time-aggregated weighted graph, i.e. the number of nodes is equal to the number of nodes in the temporal graph and the number of edges is equal to the number of different time-stamped edges. In each graph of order $k&gt;1$, the number of nodes corresponds to the number of edges in the graph with order $k-1$, since each of those nodes corresponds to a time-respecting path of length $k-1$, which are represented by edges in a $k-1$-th order gaph. This implies that the graph with order five has two nodes, which are the two time-respecting paths of length four. Those nodes are not connected since there is no time-respecting path with length five.</p> In\u00a0[9]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=5)\n\nprint(m.layers[4])\nprint(m.layers[5])\npp.plot(m.layers[5], node_label=m.layers[5].mapping.node_ids.tolist());\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t, delta=1, max_order=5)  print(m.layers[4]) print(m.layers[5]) pp.plot(m.layers[5], node_label=m.layers[5].mapping.node_ids.tolist()); <pre>Directed graph with 4 nodes and 2 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4, 4])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nUndirected graph with 2 nodes and 0 (directed) edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2, 5])\n\tinverse_idx\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([0])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> In\u00a0[10]: Copied! <pre>t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False)\nprint(t_ants)\n</pre> t_ants = pp.io.read_csv_temporal_graph('../data/ants_1_1.tedges', header=False) print(t_ants) <pre>Temporal Graph with 89 nodes, 1298 unique edges and 3822 events in [0.0, 1438.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3822])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3822])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3822])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[11]: Copied! <pre>t_email = pp.io.read_csv_temporal_graph('../data/manufacturing_email.tedges', header=False)\nprint(t_email)\n</pre> t_email = pp.io.read_csv_temporal_graph('../data/manufacturing_email.tedges', header=False) print(t_email) <pre>Temporal Graph with 167 nodes, 6501 unique edges and 165854 events in [1262454016.0, 1285884544.0]\n\nGraph attributes\n\tsrc\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([165854])\n\tdst\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([165854])\n\tt\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([165854])\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'src', 'dst', 't'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n  warnings.warn(\n</pre> In\u00a0[12]: Copied! <pre>t_sp = pp.io.read_csv_temporal_graph('../data/sociopatterns_highschool_2013.tedges', header=False)\nprint(t_sp)\n</pre> t_sp = pp.io.read_csv_temporal_graph('../data/sociopatterns_highschool_2013.tedges', header=False) print(t_sp) <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 t_sp = pp.io.read_csv_temporal_graph('../data/sociopatterns_highschool_2013.tedges', header=False)\n      2 print(t_sp)\n\nFile /workspaces/pathpyG/src/pathpyG/io/pandas.py:399, in read_csv_temporal_graph(filename, sep, header, is_undirected, timestamp_format, time_rescale, **kwargs)\n    397     df = pd.read_csv(filename, header=0, sep=sep)\n    398 else:\n--&gt; 399     df = pd.read_csv(filename, header=None, sep=sep)\n    400 return df_to_temporal_graph(df, is_undirected=is_undirected, timestamp_fromat=timestamp_format, time_rescale=time_rescale, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211, in deprecate_kwarg.&lt;locals&gt;._deprecate_kwarg.&lt;locals&gt;.wrapper(*args, **kwargs)\n    209     else:\n    210         kwargs[new_arg_name] = new_arg_value\n--&gt; 211 return func(*args, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper(*args, **kwargs)\n    325 if len(args) &gt; num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--&gt; 331 return func(*args, **kwargs)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\n    935 kwds_defaults = _refine_defaults_read(\n    936     dialect,\n    937     delimiter,\n   (...)\n    946     defaults={\"delimiter\": \",\"},\n    947 )\n    948 kwds.update(kwds_defaults)\n--&gt; 950 return _read(filepath_or_buffer, kwds)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605, in _read(filepath_or_buffer, kwds)\n    602 _validate_names(kwds.get(\"names\", None))\n    604 # Create the parser.\n--&gt; 605 parser = TextFileReader(filepath_or_buffer, **kwds)\n    607 if chunksize or iterator:\n    608     return parser\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442, in TextFileReader.__init__(self, f, engine, **kwds)\n   1439     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1441 self.handles: IOHandles | None = None\n-&gt; 1442 self._engine = self._make_engine(f, self.engine)\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735, in TextFileReader._make_engine(self, f, engine)\n   1733     if \"b\" not in mode:\n   1734         mode += \"b\"\n-&gt; 1735 self.handles = get_handle(\n   1736     f,\n   1737     mode,\n   1738     encoding=self.options.get(\"encoding\", None),\n   1739     compression=self.options.get(\"compression\", None),\n   1740     memory_map=self.options.get(\"memory_map\", False),\n   1741     is_text=is_text,\n   1742     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1743     storage_options=self.options.get(\"storage_options\", None),\n   1744 )\n   1745 assert self.handles is not None\n   1746 f = self.handles.handle\n\nFile /opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    851 elif isinstance(handle, str):\n    852     # Check whether the filename is to be opened in binary mode.\n    853     # Binary mode does not support 'encoding' and 'newline'.\n    854     if ioargs.encoding and \"b\" not in ioargs.mode:\n    855         # Encoding\n--&gt; 856         handle = open(\n    857             handle,\n    858             ioargs.mode,\n    859             encoding=ioargs.encoding,\n    860             errors=errors,\n    861             newline=\"\",\n    862         )\n    863     else:\n    864         # Binary mode\n    865         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '../data/sociopatterns_highschool_2013.tedges'</pre> <p>To generate a <code>MultiOderModel</code> consisting of multiple layers of higher-order De Bruijn graph models, we can use the <code>MultiOderModel.from_temporal_graph</code> method. We can further specify the maximum order of the highest-order layer, as well as the maximum time difference $\\delta$ for time-respecting paths.</p> <p>For the ants, we consider time-respecting paths with a maximum time difference of 30 seconds up to length four:</p> In\u00a0[6]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_ants, delta=30, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 89 nodes and 947 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([89, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 947 nodes and 1780 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([947, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 1780 nodes and 2410 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1780, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 2410 nodes and 3292 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2410, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3292])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>For the E-Mail communication network, we use time-respecting paths up to length four with a maximum time difference of one hour.</p> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_email, delta=3600, max_order=4)\nprint(m.layers[1])\nprint(m.layers[2])\nprint(m.layers[3])\nprint(m.layers[4])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_email, delta=3600, max_order=4) print(m.layers[1]) print(m.layers[2]) print(m.layers[3]) print(m.layers[4]) <pre>Directed graph with 167 nodes and 5784 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([167, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 5784 nodes and 25596 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5784, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([25596])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 25596 nodes and 47326 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([25596, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([47326])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 47326 nodes and 67801 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([47326, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([67801])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>And finally, for the largest data set from the Sociopatterns collaboration, we use a maximum time difference of 15 minutes. As you can see below, we can efficiently generate a 5-th order model despite using a temporal graph with more than 188,000 time-stamped edges and considering all time-respecting paths up to length five with a large maximum time difference. Thanks to the use of GPU-accelerated operations, creating such a model takes less than 12 seconds on an (old) RTX 2090 GPU.</p> In\u00a0[7]: Copied! <pre>m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=900, max_order=5)\nprint(m.layers[1])\nprint(m.layers[5])\n</pre> m = pp.MultiOrderModel.from_temporal_graph(t_sp, delta=900, max_order=5) print(m.layers[1]) print(m.layers[5]) <pre>Directed graph with 327 nodes and 5818 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([327, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5818])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\nDirected graph with 16307 nodes and 8712 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([16307, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([8712])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n</pre> <p>How can we use such higher-order graph models for graph learning tasks? We will demonstrate this in the next unit of our tutorial.</p>"},{"location":"tutorial/trp_higher_order/#higher-order-models-for-time-respecting-paths-in-temporal-graphs","title":"Higher-Order Models for Time-Respecting Paths in Temporal Graphs\u00b6","text":""},{"location":"tutorial/trp_higher_order/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/trp_higher_order/#motivation-and-learning-objectives","title":"Motivation and Learning Objectives\u00b6","text":"<p>In the previous tutorial, we have seen how we can use higher-order models to model paths in complex networks. In this example, paths were directly given in terms of sequences of nodes traversed by some process (like a random walk). We have further seen that higher-order De Bruijn graph models can be used to capture patterns that influence the causal topology of a complex network, i.e. which nodes can possibly influence each other via paths. The same is true for time-respecting paths in a temporal graph. Due to the fact that time-stamped edges need to occur in the correct temporal ordering (and within a given time interval based on the maximum time difference $\\delta$), the causal topology given by time-respecting paths can be very different from what we would expect from the (static) topology of links.</p> <p>In the following, we will show how we can easiy and efficiently construct higher-order models for time-respecting paths in a temporal graph. To illustrate this, we use the same toy example as before:</p>"},{"location":"tutorial/trp_higher_order/#constructing-higher-order-de-bruijn-graph-models-for-empirical-temporal-networks","title":"Constructing Higher-Order De Bruijn Graph Models for Empirical Temporal Networks\u00b6","text":"<p>Let us now use <code>pathpyG</code> to construcct higher-order De Bruijn graph models for time-respecting paths in empirical temporal network. For this, we first read a number of temporal graphs using <code>TemporalGraph.from_csv</code>. In the following, we use the following three publicly available data sets:</p> <ul> <li>Antenna interactions between ants in a colony (Blonder and Dornhaus, 2011)</li> <li>E-Mail exchanges in a manufacturing company (Nurek and Michalski, 2020)</li> <li>Face-to-face interactions in a highschool (Mastrandrea, Fournet, Barrat, 2015)</li> </ul>"},{"location":"tutorial/visualisation/","title":"Interactive Graph Visualisation","text":"In\u00a0[\u00a0]: Copied! <pre>%%capture\n# !pip install torch\n!pip install torch_geometric\n!pip install git+https://github.com/pathpy/pathpyG.git\n</pre> %%capture # !pip install torch !pip install torch_geometric !pip install git+https://github.com/pathpy/pathpyG.git In\u00a0[1]: Copied! <pre>import pathpyG as pp\nimport torch\n</pre> import pathpyG as pp import torch <p>With these preparations complete, we are ready to construct our first graph. This is achieved through the <code>Graph.from_edge_list</code> constructor provided by <code>pathpyG</code>, a method that allows us to transform a list of edges into a basic graphical representation.</p> In\u00a0[2]: Copied! <pre>g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']])\npp.plot(g, edge_color='gray')\n</pre> g = pp.Graph.from_edge_list([['a', 'b'], ['c','b']]) pp.plot(g, edge_color='gray') Out[2]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d972cc9d0&gt;</pre> <p>After successfully creating a simple graph using <code>pathpyG</code>, our next step is to examine its structure. This is a crucial part of the process as it gives us an initial understanding of the complexity and scale of our graph. By printing out the number of nodes and edges, we gain insight into the size and connectivity of the graph.</p> <p>Although it may seem unnecessary for this simple graph, it's good practice to gather information about the number of nodes and edges before attempting to visualize it. This preemptive step is crucial, especially when dealing with larger graphs. Visualizing extensive networks can be a time-consuming or even unfeasible task, depending on the sheer volume of elements that need to be represented. Therefore, understanding the graph's scale upfront helps in efficiently planning the visualization process and avoiding potential complications that could arise with larger datasets.</p> In\u00a0[3]: Copied! <pre>f'Our graph has {g.n} nodes and {g.m} edges.'\n</pre> f'Our graph has {g.n} nodes and {g.m} edges.' Out[3]: <pre>'Our graph has 3 nodes and 2 edges.'</pre> In\u00a0[4]: Copied! <pre>pp.plot(g)\n</pre> pp.plot(g) Out[4]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d972ccf40&gt;</pre> In\u00a0[5]: Copied! <pre>pp.plot(g, backend=\"matplotlib\");\n</pre> pp.plot(g, backend=\"matplotlib\"); In\u00a0[6]: Copied! <pre>pp.plot(g, backend=\"matplotlib\", layout=\"fr\")\n</pre> pp.plot(g, backend=\"matplotlib\", layout=\"fr\") Out[6]: <pre>&lt;pathpyG.visualisations._matplotlib.backend.MatplotlibBackend at 0x7f0d9aaa4190&gt;</pre> <p>Additionally, <code>pathpyG</code> offers the flexibility to incorporate custom layout algorithms. If you have developed your own method or have specific requirements for node positioning, you can directly provide the node coordinates to the visualization. This capability ensures that <code>pathpyG</code> can cater to a wide range of visualization needs, from simple and automatic layouts to highly customized and complex arrangements, making it a versatile tool in the field of data visualization.</p> In\u00a0[7]: Copied! <pre>layout = {\"a\": [0.25, 0.75], \"b\": [1, 1], \"c\": [0, 0]}\npp.plot(g, backend=\"matplotlib\", layout=layout)\n</pre> layout = {\"a\": [0.25, 0.75], \"b\": [1, 1], \"c\": [0, 0]} pp.plot(g, backend=\"matplotlib\", layout=layout) Out[7]: <pre>&lt;pathpyG.visualisations._matplotlib.backend.MatplotlibBackend at 0x7f0d972cf820&gt;</pre> In\u00a0[8]: Copied! <pre>style = {}\nstyle[\"node_color\"] = (255, 1, 255)  # RGB tuple\nstyle[\"edge_color\"] = \"green\"  # Color name as str\npp.plot(g, **style)\n</pre> style = {} style[\"node_color\"] = (255, 1, 255)  # RGB tuple style[\"edge_color\"] = \"green\"  # Color name as str pp.plot(g, **style) Out[8]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d96ff8d00&gt;</pre> <p>In <code>pathpyG</code>, there are various methods for assigning styles to objects, each offering a different level of customization and control. A straightforward approach, as previously shown, involves using a single value, such as a color string (e.g., <code>'green'</code>) or an RGB tuple (e.g., <code>(255,1,255)</code>). Applying this single value uniformly alters the appearance of all elements within a specific category, providing a quick and easy way to set a general style. However, for more detailed styling, one can utilize a <code>list</code> of values. In this approach, each value in the <code>list</code> is associated with an element according to its index position. This method is particularly familiar and efficient when working with tensors, where the association of values to elements is often index-based.</p> <p>Additionally, a more tailored approach can be employed through the use of dictionaries. In this case, each element id is paired with a corresponding value in the <code>dict</code>. Elements not included in the dictionary are assigned default values, ensuring that every element is styled, albeit some with custom and others with default styles. The types of values that can be used in these styling methods are diverse, including strings, integers, floats, and tuples, each type depending on the specific styling parameter being adjusted. This flexibility in value types and assignment methods allows for a high degree of customization, enabling the creation of visually distinct and information-rich visualizations.</p> In\u00a0[9]: Copied! <pre>style = {}\nstyle['node_color'] = ['red', 'green','blue'] # list based approach\nstyle['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach\nstyle['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value\nstyle['edge_color'] = ['orange','#00FF00']    # hex based color\npp.plot(g,**style)\n</pre> style = {} style['node_color'] = ['red', 'green','blue'] # list based approach style['node_size'] = {\"a\":40,\"b\":10, \"c\":25}  # dict based approach style['node_opacity'] = {\"b\":.5,\"c\":.3}       # missing dict value style['edge_color'] = ['orange','#00FF00']    # hex based color pp.plot(g,**style) Out[9]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d971dfb50&gt;</pre> In\u00a0[12]: Copied! <pre>style = {}\nstyle['edge_color'] = [1, 9]      # int values\n\nstyle['node_color'] = pp.algorithms.centrality.degree_centrality(g)\nstyle['cmap'] = \"plasma\"       # new color map from matplotlib for nodes\npp.plot(g,**style)\n</pre> style = {} style['edge_color'] = [1, 9]      # int values  style['node_color'] = pp.algorithms.centrality.degree_centrality(g) style['cmap'] = \"plasma\"       # new color map from matplotlib for nodes pp.plot(g,**style) Out[12]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d9702bd90&gt;</pre> In\u00a0[13]: Copied! <pre>pp.plot(g,filename='test_plot.html')\n</pre> pp.plot(g,filename='test_plot.html') Out[13]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d9702bac0&gt;</pre> In\u00a0[14]: Copied! <pre>n = pp.io.read_netzschleuder_graph('karate', '77')\n</pre> n = pp.io.read_netzschleuder_graph('karate', '77') In\u00a0[15]: Copied! <pre>pp.plot(n)\n</pre> pp.plot(n) Out[15]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d94690700&gt;</pre> In\u00a0[16]: Copied! <pre>node_color = [n['node_groups',v].item() for v in n.nodes]\npp.plot(n, edge_color='gray',node_color=node_color)\n</pre> node_color = [n['node_groups',v].item() for v in n.nodes] pp.plot(n, edge_color='gray',node_color=node_color) Out[16]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d96ffba00&gt;</pre> In\u00a0[17]: Copied! <pre>t = pp.TemporalGraph.from_edge_list(\n        [\n            (\"a\", \"b\", 1),\n            (\"b\", \"c\", 5),\n            (\"c\", \"d\", 9),\n            (\"d\", \"a\", 9),\n            (\"a\", \"b\", 10),\n            (\"b\", \"c\", 10),\n        ]\n    )\n</pre> t = pp.TemporalGraph.from_edge_list(         [             (\"a\", \"b\", 1),             (\"b\", \"c\", 5),             (\"c\", \"d\", 9),             (\"d\", \"a\", 9),             (\"a\", \"b\", 10),             (\"b\", \"c\", 10),         ]     ) In\u00a0[18]: Copied! <pre>pp.plot(t)\n</pre> pp.plot(t) Out[18]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d97195000&gt;</pre> <p>Besides the standard formatting options available in <code>pathpyG</code>, temporal plots come with specific options tailored to their unique nature. These specialized settings allow for precise control over the time dimension of the visualization. The <code>delta</code> option lets you adjust the progression speed through the time steps of your visualization. Here, a value of 1000 translates to a one-second interval, providing a way to calibrate the pace at which the temporal data unfolds.</p> In\u00a0[\u00a0]: Copied! <pre>color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"}\npp.plot(t, node_color=color, delta=2500)\n</pre> color = {\"a\": \"blue\", \"b\": \"red\", \"c\": \"green\", \"d\": \"yellow\"} pp.plot(t, node_color=color, delta=2500) Out[\u00a0]: <pre>&lt;pathpyG.visualisations._d3js.backend.D3jsBackend at 0x7f0d971dded0&gt;</pre>"},{"location":"tutorial/visualisation/#interactive-graph-visualization","title":"Interactive Graph Visualization\u00b6","text":""},{"location":"tutorial/visualisation/#prerequisites","title":"Prerequisites\u00b6","text":"<p>First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed.</p> <p>In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install <code>pathpyG</code> especially if you want to install it with GPU-support, we refer to our documentation. Note that <code>%%capture</code> discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment <code>%%capture</code> out.</p>"},{"location":"tutorial/visualisation/#motivation","title":"Motivation\u00b6","text":"<p>This tutorial is specifically designed to guide you through the process of visualizing your data using <code>pathpyG</code>, an advanced data visualization tool. Data visualization is a crucial aspect of data analysis and interpretation, allowing for the transformation of complex datasets into visually appealing and easy-to-understand formats. pathpyG excels in this area by providing a range of functionalities that cater to both beginners and advanced users. Throughout this tutorial, you will be introduced to the basic and advanced features of pathpyG, empowering you to effectively visualize your data. This will not only enhance your understanding of your data but also enable you to communicate your findings more effectively to others.</p> <p>Visualization is a core concept of <code>pathpyG</code> because it bridges the gap between raw data and meaningful visual representations. We, as humans, are wired to process visual information much more rapidly compared to text or audio. This innate ability enables us to quickly identify patterns, outliers, and trends in visual data. Data visualization leverages this capability by graphically representing data, thereby facilitating the swift interpretation of large and complex datasets. Interactive visualizations further this advantage by allowing users to directly engage with the data, exploring and analyzing it in an intuitive and insightful manner. Whether it's understanding the intricate details of microscopic structures or grasping the dynamics of global phenomena, visualizations are instrumental in helping researchers and analysts gain deeper insights and effectively communicate their findings.</p>"},{"location":"tutorial/visualisation/#learning-objectives","title":"Learning objectives\u00b6","text":"<p>In this tutorial, you will learn to master the art of creating simple yet powerful interactive visualizations using <code>pathpyG</code>. You will learn the nuances of customizing the style of your visualizations, enabling you to tailor them to your specific needs and preferences. This customization extends to the aesthetics, layout, and interactive elements, ensuring that your visualizations are not only informative but also engaging. Additionally, the tutorial covers the essential skills needed to save your visualizations in various formats, making it easier to share your work across different platforms and audiences. Lastly, a significant part of the tutorial is dedicated to creating temporal visualizations. These types of visualizations are particularly useful in understanding and presenting data that changes over time, offering dynamic insights into trends and patterns that static visualizations cannot capture. By the end of this tutorial, you will have a comprehensive understanding of how to effectively use pathpyG to create and customize a wide range of visualizations.</p>"},{"location":"tutorial/visualisation/#lets-get-started","title":"Let's Get Started\u00b6","text":"<p>To embark on our journey of visualizing data with <code>pathpyG</code>, the initial step involves initializing and loading the required modules, a crucial process that sets the foundation for our data visualization work. This preparation ensures that all necessary tools and functionalities from <code>pathpyG</code> are at our disposal.</p> <p>In anticipation of enhancing our graphs with additional attributes, we also include the <code>torch</code> package in our setup. <code>torch</code> is renowned for its robust capabilities in data processing and machine learning, and its inclusion allows us to enrich our graphs with more complex and informative attributes.</p>"},{"location":"tutorial/visualisation/#the-plot-function","title":"The <code>plot</code> Function\u00b6","text":"<p>The <code>plot</code> function in <code>pathpyG</code> stands out as the simplest and most direct method for creating visualizations. Designed to encapsulate all the plotting capabilities of <code>pathpyG</code> in a single command, it streamlines the process of generating quick and efficient plots. This functionality is particularly beneficial for users who seek immediate visual feedback from their data without delving into more complex coding. The only prerequisite for using this function is the <code>Graph</code> object, which serves as the foundation for the visualization. Moreover, when working within an interactive environment, such as a <code>Jupyter notebook</code>, the <code>plot</code> function is particularly powerful. In such settings, invoking the <code>plot</code> command will automatically generate and display an interactive visualization. This feature is particularly beneficial as it allows for immediate visual feedback, making it an ideal tool for exploratory data analysis where quick and efficient visualization is key.</p>"},{"location":"tutorial/visualisation/#kwargs-in-the-plot-function","title":"<code>kwargs</code> in the <code>plot</code> function\u00b6","text":"<p>In <code>pathpyG</code>, the customization of your plot is managed through keyword arguments (kwargs), where each customization is specified as a keyword followed by its corresponding value. This approach is what gives the <code>plot</code> function its remarkable flexibility, allowing it to adapt to a wide variety of plotting requirements. Whether you're aiming for a simple graph or a complex, multi-faceted visualization, the keyword arguments provide the tools to tailor your plot precisely to your needs.</p> <p>However, this wealth of options can be somewhat overwhelming for beginners, given the extensive range of available choices. But worry not, as we will guide you through the most essential and basic options, ensuring you have a solid foundation to start from. By mastering these fundamental aspects, you'll be well on your way to effectively utilizing <code>pathpyG</code>'s plot function, gradually building up to more advanced features as you gain confidence and expertise.</p>"},{"location":"tutorial/visualisation/#plotting-backends","title":"Plotting Backends\u00b6","text":"<p>In the diverse world of data visualization, there is no one-size-fits-all technique, as different scenarios demand different approaches. Recognizing this, <code>pathpyG</code> offers a variety of plotting backends, each tailored for specific use cases, ensuring that users have the right tools for their unique requirements.</p> <ul> <li><p>For instance, <code>pathpyG</code> facilitates interactive visualizations, as previously demonstrated, which are immensely useful for dynamic exploration of data. This feature is particularly beneficial in educational settings, exploratory data analysis, and communication, where interaction with the data can lead to deeper understanding and insights.</p> </li> <li><p>On the other hand, <code>pathpyG</code> also integrates with matplotlib, a widely recognized package for creating static plots. This is especially efficient for visualizing large graphs where interactivity might be less critical.</p> </li> <li><p>Additionally, <code>pathpyG</code> caters to the academic and publication community by offering tikz plots, which are highly valued in formal publications for their precision and quality. (Note that for generating tikz plots, currently, the installation of <code>latexmk</code> is necessary to produce the corresponding <code>.tex</code> and <code>.pdf</code> files.)</p> </li> </ul> <p>Let's generate a static png image using the <code>matplotlib</code> backend:</p>"},{"location":"tutorial/visualisation/#quick-introduction-to-layouts","title":"Quick Introduction to Layouts\u00b6","text":"<p>An important aspect to consider is the layout of your plot. The previous plot we generated is static, meaning the positions of the nodes are fixed and do not change. This fixed arrangement presents a unique challenge, as finding the optimal placement for nodes and edges to convey information effectively is not a straightforward task. To assist with this, <code>pathpyG</code> supports simple layout functions designed to create visually appealing and coherent graphs. By default, nodes are assigned random locations for computational efficiency. However, this arrangement can be significantly improved with the use of the <code>layout</code> keyword in the <code>plot</code> function, allowing for more structured and meaningful representations of your graph.</p> <p>For example, <code>pathpyG</code> includes support for sophisticated layout algorithms, such as the Fruchterman-Reingold algorithm for force-directed layouts. This can be activated using the <code>\"fr\"</code> option, which applies a physics-based approach to arrange nodes and edges in a way that visually represents their relational dynamics. Such force-directed layouts are particularly useful for highlighting the underlying structure and relationships within the data.</p>"},{"location":"tutorial/visualisation/#styling-your-plots","title":"Styling Your Plots\u00b6","text":"<p>To enhance the effectiveness and appeal of our visualizations in <code>pathpyG</code>, styling of our plots becomes a key aspect. The ability to style your plots is not just about aesthetic appeal; it is about effectively conveying more information through visual means. Depending on the type of plot you are working with, there are multiple styling options available to tailor your visualization to your specific needs. The fundamental principle here is that the styles applied to your plot should not be dependent on the data of your model. In other words, you should be able to present the same data in different styles, depending on the context or the information you wish to highlight. To facilitate this, styles are organized in dictionaries, which are then incorporated into the <code>plot</code> function.</p> <p>For network plots, where the focus is on the topology of the data, there are several basic styling options you can adjust, including the <code>size</code>, <code>color</code>, and <code>opacity</code> of each node and edge object. These options provide a foundational level of customization, allowing you to make your graph more readable and visually appealing. However, the styling possibilities extend further, varying according to the specific kind of plot you are creating. To distinguish between the styling of edges and nodes, a prefix corresponding to each element type is added to the keyword, such as <code>node_size</code>. This distinction ensures that your styling choices are accurately applied to the intended elements of the graph, further enhancing the clarity and effectiveness of your visualization.</p>"},{"location":"tutorial/visualisation/#colormaps","title":"Colormaps\u00b6","text":"<p>In many instances, particularly when visualizing numerical data, the use of color gradients to represent values can greatly enhance the clarity and effectiveness of a plot. <code>pathpyG</code> addresses this need through its native support for <code>colormaps</code>. When the colors of node or edge elements are defined using <code>int</code> or <code>float</code> values, <code>pathpyG</code> automatically assigns colors based on these colormaps, effectively interpolating the correct color value for each element. By default, <code>pathpyG</code> offers a simple colormap that transitions from red to green, sufficient for many basic visualization needs. However, for more customized or advanced styling, users have the option to utilize any colormap from the extensive color palettes provided by <code>matplotlib</code>. Thit library offer a wide range of color schemes, enabling you to select the perfect palette to convey the nuances of your data.</p>"},{"location":"tutorial/visualisation/#saving-plots","title":"Saving Plots\u00b6","text":"<p>In <code>pathpyG</code>, sharing your plots or incorporating them into various mediums is facilitated by the ability to save them as files. This functionality is conveniently accessed by simply adding the <code>filename</code> keyword within the plot function. When you specify a filename, <code>pathpyG</code> assigns the appropriate backend to use based on the file extension provided. For instance, if you save your file with an <code>.html</code> extension, <code>pathpyG</code> generates a standalone interactive visualization, perfect for web applications or interactive presentations. On the other hand, if you choose to save your plot as a <code>.png</code> file, a static image is created using the <code>matplotlib</code> backend, ideal for including in documents, reports, or presentations where interactivity is not required. Additionally, for those seeking to incorporate plots into academic papers or publications, saving the file with a <code>.tex</code> extension activates the <code>tikz</code> backend. This feature is particularly beneficial for creating high-quality, publication-ready figures.</p>"},{"location":"tutorial/visualisation/#larger-network-visualizations","title":"Larger Network Visualizations\u00b6","text":"<p>Having covered the basics, we are now well-prepared to venture into the realm of larger network visualizations using <code>pathpyG</code>.</p>"},{"location":"tutorial/visualisation/#temporal-network-visualizations","title":"Temporal Network Visualizations\u00b6","text":"<p>In the realm of network analysis, <code>pathpyG</code> particularly excels in handling and visualizing temporal graphs, a domain where both nodes and edges can change their properties over time. This dynamic aspect of temporal graphs adds a layer of complexity and richness to data analysis, capturing the evolution of relationships and properties within the network. <code>pathpyG</code> supports this advanced functionality, allowing users to apply the same versatile <code>plot</code> function used for static graphs to <code>TemporalGraph</code> data structures. This integration means that all the customization options, styling features, and layout choices previously explored for static network visualizations are also applicable to temporal graphs. The ability to utilize these tools in the context of temporal data opens up a world of possibilities for in-depth analysis and insightful visualization of networks where time plays a crucial role. Whether you're tracking changes in social networks, analyzing traffic patterns, or studying dynamic biological systems, <code>pathpyG</code>'s capabilities in temporal network visualization provide a powerful tool to uncover and illustrate the temporal dynamics inherent in these complex systems.</p>"},{"location":"tutorial/archive/_higher_order_scalability/","title":"higher order scalability","text":"In\u00a0[\u00a0]: Copied! <pre>import time\nimport torch\n\nimport pathpy as pp2\nimport pathpyG as pp\nfrom matplotlib import pyplot as plt\n</pre> import time import torch  import pathpy as pp2 import pathpyG as pp from matplotlib import pyplot as plt <pre>Running on cuda\n</pre> In\u00a0[2]: Copied! <pre>p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\n</pre> p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') In\u00a0[3]: Copied! <pre>m = pp.MultiOrderModel.from_DAGs(p, max_order=2)\ng2 = m.layers[2]\nprint(g2.n)\nprint(g2.m)\nprint(g2['edge_weight'].sum().item())\n</pre> m = pp.MultiOrderModel.from_DAGs(p, max_order=2) g2 = m.layers[2] print(g2.n) print(g2.m) print(g2['edge_weight'].sum().item()) <pre>646\n1139\n634916.0\n</pre> In\u00a0[4]: Copied! <pre>for e in g2.edges:\n    print(e, g2['edge_weight', e[0], e[1]])\n</pre> for e in g2.edges:     print(e, g2['edge_weight', e[0], e[1]]) <pre>(('Acton Town', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(2399., device='cuda:0')\n(('Acton Town', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(155., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(398., device='cuda:0')\n(('Acton Town', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(96., device='cuda:0')\n(('Acton Town', 'South Ealing'), ('South Ealing', 'Northfields')) tensor(1149., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(481., device='cuda:0')\n(('Acton Town', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(113., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(8., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(117., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(9., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(173., device='cuda:0')\n(('Aldgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(24., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Aldgate', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(112., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(5., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2121., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1453., device='cuda:0')\n(('Aldgate East', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(135., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(6., device='cuda:0')\n(('Aldgate East', 'Tower Hill'), ('Tower Hill', 'Bank / Monument')) tensor(2147., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(234., device='cuda:0')\n(('Aldgate East', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(5062., device='cuda:0')\n(('Alperton', 'Park Royal'), ('Park Royal', 'North Ealing')) tensor(232., device='cuda:0')\n(('Alperton', 'Sudbury Town'), ('Sudbury Town', 'Sudbury Hill')) tensor(117., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(1., device='cuda:0')\n(('Amersham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(180., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(46., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(665., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1404., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(3., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(33., device='cuda:0')\n(('Angel', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(56., device='cuda:0')\n(('Angel', 'Old Street'), ('Old Street', 'Moorgate')) tensor(2150., device='cuda:0')\n(('Archway', 'Highgate'), ('Highgate', 'East Finchley')) tensor(818., device='cuda:0')\n(('Archway', 'Tufnell Park'), ('Tufnell Park', 'Kentish Town')) tensor(1248., device='cuda:0')\n(('Arnos Grove', 'Bounds Green'), ('Bounds Green', 'Wood Green')) tensor(503., device='cuda:0')\n(('Arnos Grove', 'Southgate'), ('Southgate', 'Oakwood')) tensor(207., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(71., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(20., device='cuda:0')\n(('Arsenal', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(78., device='cuda:0')\n(('Arsenal', 'Holloway Road'), ('Holloway Road', 'Caledonian Road')) tensor(87., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(2561., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(104., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(669., device='cuda:0')\n(('Baker Street', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(2627., device='cuda:0')\n(('Baker Street', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Paddington')) tensor(5427., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(1379., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(157., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(639., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(290., device='cuda:0')\n(('Baker Street', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(463., device='cuda:0')\n(('Baker Street', 'Great Portland Street'), ('Great Portland Street', 'Euston Square')) tensor(4311., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(126., device='cuda:0')\n(('Baker Street', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(1391., device='cuda:0')\n(('Baker Street', \"Regent's Park\"), (\"Regent's Park\", 'Oxford Circus')) tensor(662., device='cuda:0')\n(('Baker Street', \"St. John's Wood\"), (\"St. John's Wood\", 'Swiss Cottage')) tensor(159., device='cuda:0')\n(('Balham', 'Clapham South'), ('Clapham South', 'Clapham Common')) tensor(1132., device='cuda:0')\n(('Balham', 'Tooting Bec'), ('Tooting Bec', 'Tooting Broadway')) tensor(637., device='cuda:0')\n(('Bank / Monument', 'Cannon Street'), ('Cannon Street', 'Mansion House')) tensor(274., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(110., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(2194., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(2353., device='cuda:0')\n(('Bank / Monument', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(522., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(264., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Borough')) tensor(805., device='cuda:0')\n(('Bank / Monument', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(3545., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(279., device='cuda:0')\n(('Bank / Monument', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(301., device='cuda:0')\n(('Bank / Monument', \"St. Paul's\"), (\"St. Paul's\", 'Chancery Lane')) tensor(3344., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate')) tensor(116., device='cuda:0')\n(('Bank / Monument', 'Tower Hill'), ('Tower Hill', 'Aldgate East')) tensor(2188., device='cuda:0')\n(('Barbican', 'Farringdon'), ('Farringdon', \"King's Cross St. Pancras\")) tensor(2027., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1800., device='cuda:0')\n(('Barbican', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(2., device='cuda:0')\n(('Barking', 'East Ham'), ('East Ham', 'Upton Park')) tensor(9., device='cuda:0')\n(('Barking', 'Upminster'), ('Upminster', 'Upminster Bridge')) tensor(561., device='cuda:0')\n(('Barking', 'Upney'), ('Upney', 'Becontree')) tensor(684., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(20., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Canning Town')) tensor(288., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Plaistow')) tensor(7., device='cuda:0')\n(('Barking', 'West Ham'), ('West Ham', 'Stratford')) tensor(2122., device='cuda:0')\n(('Barkingside', 'Fairlop'), ('Fairlop', 'Hainault')) tensor(201., device='cuda:0')\n(('Barkingside', 'Newbury Park'), ('Newbury Park', 'Gants Hill')) tensor(448., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1088., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(94., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(6., device='cuda:0')\n(('Barons Court', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(150., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(340., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(182., device='cuda:0')\n(('Barons Court', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(316., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(634., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(114., device='cuda:0')\n(('Bayswater', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(23., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(101., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(113., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(414., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(40., device='cuda:0')\n(('Bayswater', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(82., device='cuda:0')\n(('Becontree', 'Dagenham Heathway'), ('Dagenham Heathway', 'Dagenham East')) tensor(169., device='cuda:0')\n(('Becontree', 'Upney'), ('Upney', 'Barking')) tensor(623., device='cuda:0')\n(('Belsize Park', 'Chalk Farm'), ('Chalk Farm', 'Camden Town')) tensor(1156., device='cuda:0')\n(('Belsize Park', 'Hampstead'), ('Hampstead', 'Golders Green')) tensor(771., device='cuda:0')\n(('Bermondsey', 'Canada Water'), ('Canada Water', 'Canary Wharf')) tensor(1026., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(320., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Borough')) tensor(110., device='cuda:0')\n(('Bermondsey', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(1094., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(11., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(7., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(2252., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(1505., device='cuda:0')\n(('Bethnal Green', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(119., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(253., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(144., device='cuda:0')\n(('Bethnal Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(3210., device='cuda:0')\n(('Blackfriars', 'Mansion House'), ('Mansion House', 'Cannon Street')) tensor(255., device='cuda:0')\n(('Blackfriars', 'Temple'), ('Temple', 'Embankment')) tensor(384., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(224., device='cuda:0')\n(('Blackhorse Road', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(152., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2570., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(1699., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(92., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(999., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(174., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(282., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(225., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Victoria')) tensor(858., device='cuda:0')\n(('Bond Street', 'Green Park'), ('Green Park', 'Westminster')) tensor(1524., device='cuda:0')\n(('Bond Street', 'Marble Arch'), ('Marble Arch', 'Lancaster Gate')) tensor(835., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(226., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(1., device='cuda:0')\n(('Bond Street', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(519., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(93., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(3138., device='cuda:0')\n(('Bond Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(283., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(679., device='cuda:0')\n(('Borough', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(86., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(845., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(103., device='cuda:0')\n(('Borough', 'London Bridge'), ('London Bridge', 'Southwark')) tensor(38., device='cuda:0')\n(('Boston Manor', 'Northfields'), ('Northfields', 'South Ealing')) tensor(1179., device='cuda:0')\n(('Boston Manor', 'Osterley'), ('Osterley', 'Hounslow East')) tensor(819., device='cuda:0')\n(('Bounds Green', 'Arnos Grove'), ('Arnos Grove', 'Southgate')) tensor(350., device='cuda:0')\n(('Bounds Green', 'Wood Green'), ('Wood Green', 'Turnpike Lane')) tensor(630., device='cuda:0')\n(('Bow Road', 'BromleyByBow'), ('BromleyByBow', 'West Ham')) tensor(13., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(225., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(5., device='cuda:0')\n(('Bow Road', 'Mile End'), ('Mile End', 'Stratford')) tensor(10., device='cuda:0')\n(('Brent Cross', 'Golders Green'), ('Golders Green', 'Hampstead')) tensor(680., device='cuda:0')\n(('Brent Cross', 'Hendon Central'), ('Hendon Central', 'Colindale')) tensor(382., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(9., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Oval')) tensor(167., device='cuda:0')\n(('Brixton', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(147., device='cuda:0')\n(('BromleyByBow', 'Bow Road'), ('Bow Road', 'Mile End')) tensor(87., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Barking')) tensor(16., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(3., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Plaistow')) tensor(4., device='cuda:0')\n(('BromleyByBow', 'West Ham'), ('West Ham', 'Stratford')) tensor(9., device='cuda:0')\n(('Buckhurst Hill', 'Loughton'), ('Loughton', 'Debden')) tensor(468., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(6., device='cuda:0')\n(('Buckhurst Hill', 'Woodford'), ('Woodford', 'South Woodford')) tensor(934., device='cuda:0')\n(('Burnt Oak', 'Colindale'), ('Colindale', 'Hendon Central')) tensor(218., device='cuda:0')\n(('Caledonian Road', 'Holloway Road'), ('Holloway Road', 'Arsenal')) tensor(93., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(36., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(139., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(155., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(34., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(14., device='cuda:0')\n(('Caledonian Road', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(39., device='cuda:0')\n(('Camden Town', 'Chalk Farm'), ('Chalk Farm', 'Belsize Park')) tensor(1083., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(1459., device='cuda:0')\n(('Camden Town', 'Euston'), ('Euston', 'Warren Street')) tensor(1639., device='cuda:0')\n(('Camden Town', 'Kentish Town'), ('Kentish Town', 'Tufnell Park')) tensor(1335., device='cuda:0')\n(('Canada Water', 'Bermondsey'), ('Bermondsey', 'London Bridge')) tensor(1333., device='cuda:0')\n(('Canada Water', 'Canary Wharf'), ('Canary Wharf', 'North Greenwich')) tensor(765., device='cuda:0')\n(('Canary Wharf', 'Canada Water'), ('Canada Water', 'Bermondsey')) tensor(1104., device='cuda:0')\n(('Canary Wharf', 'North Greenwich'), ('North Greenwich', 'Canning Town')) tensor(600., device='cuda:0')\n(('Canning Town', 'North Greenwich'), ('North Greenwich', 'Canary Wharf')) tensor(598., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Barking')) tensor(304., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(5., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Plaistow')) tensor(79., device='cuda:0')\n(('Canning Town', 'West Ham'), ('West Ham', 'Stratford')) tensor(222., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(198., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(78., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(42., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(59., device='cuda:0')\n(('Cannon Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(96., device='cuda:0')\n(('Cannon Street', 'Mansion House'), ('Mansion House', 'Blackfriars')) tensor(268., device='cuda:0')\n(('Canons Park', 'Queensbury'), ('Queensbury', 'Kingsbury')) tensor(218., device='cuda:0')\n(('Chalfont &amp; Latimer', 'Chorleywood'), ('Chorleywood', 'Rickmansworth')) tensor(395., device='cuda:0')\n(('Chalk Farm', 'Belsize Park'), ('Belsize Park', 'Hampstead')) tensor(910., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1248., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(43., device='cuda:0')\n(('Chalk Farm', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(9., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(220., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Russell Square')) tensor(115., device='cuda:0')\n(('Chancery Lane', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(3066., device='cuda:0')\n(('Chancery Lane', \"St. Paul's\"), (\"St. Paul's\", 'Bank / Monument')) tensor(3482., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Temple')) tensor(61., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Waterloo')) tensor(231., device='cuda:0')\n(('Charing Cross', 'Embankment'), ('Embankment', 'Westminster')) tensor(5., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(59., device='cuda:0')\n(('Charing Cross', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(159., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(122., device='cuda:0')\n(('Charing Cross', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(304., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(1., device='cuda:0')\n(('Chesham', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chorleywood')) tensor(85., device='cuda:0')\n(('Chigwell', 'Grange Hill'), ('Grange Hill', 'Hainault')) tensor(204., device='cuda:0')\n(('Chigwell', 'Roding Valley'), ('Roding Valley', 'Woodford')) tensor(320., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(90., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(6., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('Chiswick Park', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(1., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Amersham')) tensor(146., device='cuda:0')\n(('Chorleywood', 'Chalfont &amp; Latimer'), ('Chalfont &amp; Latimer', 'Chesham')) tensor(62., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'HarrowOnTheHill')) tensor(496., device='cuda:0')\n(('Chorleywood', 'Rickmansworth'), ('Rickmansworth', 'Moor Park')) tensor(10., device='cuda:0')\n(('Clapham Common', 'Clapham North'), ('Clapham North', 'Stockwell')) tensor(1504., device='cuda:0')\n(('Clapham Common', 'Clapham South'), ('Clapham South', 'Balham')) tensor(969., device='cuda:0')\n(('Clapham North', 'Clapham Common'), ('Clapham Common', 'Clapham South')) tensor(1148., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(8., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Oval')) tensor(964., device='cuda:0')\n(('Clapham North', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(686., device='cuda:0')\n(('Clapham South', 'Balham'), ('Balham', 'Tooting Bec')) tensor(782., device='cuda:0')\n(('Clapham South', 'Clapham Common'), ('Clapham Common', 'Clapham North')) tensor(1297., device='cuda:0')\n(('Cockfosters', 'Oakwood'), ('Oakwood', 'Southgate')) tensor(120., device='cuda:0')\n(('Colindale', 'Burnt Oak'), ('Burnt Oak', 'Edgware')) tensor(139., device='cuda:0')\n(('Colindale', 'Hendon Central'), ('Hendon Central', 'Brent Cross')) tensor(370., device='cuda:0')\n(('Colliers Wood', 'South Wimbledon'), ('South Wimbledon', 'Morden')) tensor(152., device='cuda:0')\n(('Colliers Wood', 'Tooting Broadway'), ('Tooting Broadway', 'Tooting Bec')) tensor(477., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(239., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Russell Square')) tensor(90., device='cuda:0')\n(('Covent Garden', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(52., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(129., device='cuda:0')\n(('Covent Garden', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(103., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(238., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(6., device='cuda:0')\n(('Croxley', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Dagenham East', 'Dagenham Heathway'), ('Dagenham Heathway', 'Becontree')) tensor(161., device='cuda:0')\n(('Dagenham East', 'Elm Park'), ('Elm Park', 'Hornchurch')) tensor(5., device='cuda:0')\n(('Dagenham Heathway', 'Becontree'), ('Becontree', 'Upney')) tensor(418., device='cuda:0')\n(('Dagenham Heathway', 'Dagenham East'), ('Dagenham East', 'Elm Park')) tensor(5., device='cuda:0')\n(('Debden', 'Loughton'), ('Loughton', 'Buckhurst Hill')) tensor(577., device='cuda:0')\n(('Debden', 'Theydon Bois'), ('Theydon Bois', 'Epping')) tensor(217., device='cuda:0')\n(('Dollis Hill', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(118., device='cuda:0')\n(('Dollis Hill', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(2., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(2315., device='cuda:0')\n(('Ealing Broadway', 'Ealing Common'), ('Ealing Common', 'North Ealing')) tensor(113., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Bayswater')) tensor(117., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(132., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(3451., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(94., device='cuda:0')\n(('Ealing Broadway', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(60., device='cuda:0')\n(('Ealing Broadway', 'West Acton'), ('West Acton', 'North Acton')) tensor(875., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(105., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(508., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(1068., device='cuda:0')\n(('Ealing Common', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(699., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(2570., device='cuda:0')\n(('Ealing Common', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(49., device='cuda:0')\n(('Ealing Common', 'North Ealing'), ('North Ealing', 'Park Royal')) tensor(232., device='cuda:0')\n((\"Earl's Court\", 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(1065., device='cuda:0')\n((\"Earl's Court\", 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(3117., device='cuda:0')\n((\"Earl's Court\", 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(504., device='cuda:0')\n((\"Earl's Court\", 'West Brompton'), ('West Brompton', 'Fulham Broadway')) tensor(1757., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(70., device='cuda:0')\n(('East Acton', 'North Acton'), ('North Acton', 'West Acton')) tensor(168., device='cuda:0')\n(('East Acton', 'White City'), ('White City', \"Shepherd's Bush (Cen)\")) tensor(103., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(69., device='cuda:0')\n(('East Finchley', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(427., device='cuda:0')\n(('East Finchley', 'Highgate'), ('Highgate', 'Archway')) tensor(844., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upminster')) tensor(8., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'Upney')) tensor(7., device='cuda:0')\n(('East Ham', 'Barking'), ('Barking', 'West Ham')) tensor(426., device='cuda:0')\n(('East Ham', 'Upton Park'), ('Upton Park', 'Plaistow')) tensor(1., device='cuda:0')\n(('East Putney', 'Putney Bridge'), ('Putney Bridge', 'Parsons Green')) tensor(969., device='cuda:0')\n(('East Putney', 'Southfields'), ('Southfields', 'Wimbledon Park')) tensor(375., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(66., device='cuda:0')\n(('Eastcote', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(918., device='cuda:0')\n(('Eastcote', 'Ruislip Manor'), ('Ruislip Manor', 'Ruislip')) tensor(619., device='cuda:0')\n(('Edgware', 'Burnt Oak'), ('Burnt Oak', 'Colindale')) tensor(118., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(122., device='cuda:0')\n(('Edgware Road (Bak)', 'Marylebone'), ('Marylebone', 'HarrowOnTheHill')) tensor(326., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(153., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(135., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(50., device='cuda:0')\n(('Edgware Road (Bak)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(44., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(2860., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(253., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(2439., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(13., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(425., device='cuda:0')\n(('Edgware Road (Cir)', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(57., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Bayswater')) tensor(475., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(3182., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(590., device='cuda:0')\n(('Edgware Road (Cir)', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(924., device='cuda:0')\n(('Elephant &amp; Castle', 'Borough'), ('Borough', 'London Bridge')) tensor(867., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Oval')) tensor(627., device='cuda:0')\n(('Elephant &amp; Castle', 'Kennington'), ('Kennington', 'Waterloo')) tensor(217., device='cuda:0')\n(('Elephant &amp; Castle', 'Lambeth North'), ('Lambeth North', 'Waterloo')) tensor(211., device='cuda:0')\n(('Elm Park', 'Dagenham East'), ('Dagenham East', 'Dagenham Heathway')) tensor(5., device='cuda:0')\n(('Elm Park', 'Hornchurch'), ('Hornchurch', 'Upminster Bridge')) tensor(238., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Leicester Square')) tensor(114., device='cuda:0')\n(('Embankment', 'Charing Cross'), ('Charing Cross', 'Piccadilly Circus')) tensor(175., device='cuda:0')\n(('Embankment', 'Temple'), ('Temple', 'Blackfriars')) tensor(412., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(105., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(23., device='cuda:0')\n(('Embankment', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(276., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', 'Green Park')) tensor(549., device='cuda:0')\n(('Embankment', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(132., device='cuda:0')\n(('Epping', 'Theydon Bois'), ('Theydon Bois', 'Debden')) tensor(306., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(1176., device='cuda:0')\n(('Euston', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(1482., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(703., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(131., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(326., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(683., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(576., device='cuda:0')\n(('Euston', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(100., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(88., device='cuda:0')\n(('Euston', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(2579., device='cuda:0')\n(('Euston Square', 'Great Portland Street'), ('Great Portland Street', 'Baker Street')) tensor(4039., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(1503., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(154., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(315., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(1522., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(739., device='cuda:0')\n(('Euston Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(87., device='cuda:0')\n(('Fairlop', 'Barkingside'), ('Barkingside', 'Newbury Park')) tensor(301., device='cuda:0')\n(('Fairlop', 'Hainault'), ('Hainault', 'Grange Hill')) tensor(3., device='cuda:0')\n(('Farringdon', 'Barbican'), ('Barbican', 'Moorgate')) tensor(2110., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(3., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(45., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(626., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(1384., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(32., device='cuda:0')\n(('Farringdon', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(45., device='cuda:0')\n(('Finchley Central', 'East Finchley'), ('East Finchley', 'Highgate')) tensor(687., device='cuda:0')\n(('Finchley Central', 'West Finchley'), ('West Finchley', 'Woodside Park')) tensor(345., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1763., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(214., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(1034., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(145., device='cuda:0')\n(('Finchley Road', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(8., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(245., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(172., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(95., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(235., device='cuda:0')\n(('Finchley Road', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(603., device='cuda:0')\n(('Finchley Road', 'Swiss Cottage'), ('Swiss Cottage', \"St. John's Wood\")) tensor(25., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(338., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(96., device='cuda:0')\n(('Finchley Road', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(85., device='cuda:0')\n(('Finchley Road', 'West Hampstead'), ('West Hampstead', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(110., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(167., device='cuda:0')\n(('Finchley Road', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(98., device='cuda:0')\n(('Finsbury Park', 'Arsenal'), ('Arsenal', 'Holloway Road')) tensor(65., device='cuda:0')\n(('Finsbury Park', 'Highbury &amp; Islington'), ('Highbury &amp; Islington', \"King's Cross St. Pancras\")) tensor(1377., device='cuda:0')\n(('Finsbury Park', 'Manor House'), ('Manor House', 'Turnpike Lane')) tensor(960., device='cuda:0')\n(('Finsbury Park', 'Seven Sisters'), ('Seven Sisters', 'Tottenham Hale')) tensor(708., device='cuda:0')\n(('Fulham Broadway', 'Parsons Green'), ('Parsons Green', 'Putney Bridge')) tensor(1095., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', \"Earl's Court\")) tensor(1813., device='cuda:0')\n(('Fulham Broadway', 'West Brompton'), ('West Brompton', 'Kensington (Olympia)')) tensor(4., device='cuda:0')\n(('Gants Hill', 'Newbury Park'), ('Newbury Park', 'Barkingside')) tensor(471., device='cuda:0')\n(('Gants Hill', 'Redbridge'), ('Redbridge', 'Wanstead')) tensor(1094., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(1135., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(98., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(1410., device='cuda:0')\n(('Gloucester Road', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(192., device='cuda:0')\n(('Gloucester Road', 'High Street Kensington'), ('High Street Kensington', 'Notting Hill Gate')) tensor(158., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(1378., device='cuda:0')\n(('Gloucester Road', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(2449., device='cuda:0')\n(('Golders Green', 'Brent Cross'), ('Brent Cross', 'Hendon Central')) tensor(542., device='cuda:0')\n(('Golders Green', 'Hampstead'), ('Hampstead', 'Belsize Park')) tensor(846., device='cuda:0')\n(('Goldhawk Road', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Wood Lane')) tensor(201., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(73., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(59., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(38., device='cuda:0')\n(('Goodge Street', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(41., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Euston')) tensor(79., device='cuda:0')\n(('Goodge Street', 'Warren Street'), ('Warren Street', 'Oxford Circus')) tensor(42., device='cuda:0')\n(('Grange Hill', 'Chigwell'), ('Chigwell', 'Roding Valley')) tensor(256., device='cuda:0')\n(('Grange Hill', 'Hainault'), ('Hainault', 'Fairlop')) tensor(3., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(93., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(2262., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(946., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(582., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(14., device='cuda:0')\n(('Great Portland Street', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(115., device='cuda:0')\n(('Great Portland Street', 'Euston Square'), ('Euston Square', \"King's Cross St. Pancras\")) tensor(4322., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2417., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(156., device='cuda:0')\n(('Green Park', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(245., device='cuda:0')\n(('Green Park', 'Hyde Park Corner'), ('Hyde Park Corner', 'Knightsbridge')) tensor(1812., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(41., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(250., device='cuda:0')\n(('Green Park', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(1507., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(131., device='cuda:0')\n(('Green Park', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(101., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Pimlico')) tensor(1017., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1741., device='cuda:0')\n(('Green Park', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(140., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Embankment')) tensor(595., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(136., device='cuda:0')\n(('Green Park', 'Westminster'), ('Westminster', 'Waterloo')) tensor(3391., device='cuda:0')\n(('Greenford', 'Northolt'), ('Northolt', 'South Ruislip')) tensor(194., device='cuda:0')\n(('Greenford', 'Perivale'), ('Perivale', 'Hanger Lane')) tensor(544., device='cuda:0')\n(('Gunnersbury', 'Kew Gardens'), ('Kew Gardens', 'Richmond')) tensor(293., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(557., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(217., device='cuda:0')\n(('Gunnersbury', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(6., device='cuda:0')\n(('Hainault', 'Fairlop'), ('Fairlop', 'Barkingside')) tensor(189., device='cuda:0')\n(('Hainault', 'Grange Hill'), ('Grange Hill', 'Chigwell')) tensor(187., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(437., device='cuda:0')\n(('Hammersmith (Dis)', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(191., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', \"Earl's Court\")) tensor(1123., device='cuda:0')\n(('Hammersmith (Dis)', 'Barons Court'), ('Barons Court', 'West Kensington')) tensor(25., device='cuda:0')\n(('Hammersmith (Dis)', 'Ravenscourt Park'), ('Ravenscourt Park', 'Stamford Brook')) tensor(54., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(15., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(177., device='cuda:0')\n(('Hammersmith (Dis)', 'Turnham Green'), ('Turnham Green', 'Stamford Brook')) tensor(58., device='cuda:0')\n(('Hammersmith (H&amp;C)', 'Goldhawk Road'), ('Goldhawk Road', \"Shepherd's Bush Market\")) tensor(108., device='cuda:0')\n(('Hampstead', 'Belsize Park'), ('Belsize Park', 'Chalk Farm')) tensor(982., device='cuda:0')\n(('Hampstead', 'Golders Green'), ('Golders Green', 'Brent Cross')) tensor(610., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'East Acton')) tensor(80., device='cuda:0')\n(('Hanger Lane', 'North Acton'), ('North Acton', 'West Acton')) tensor(688., device='cuda:0')\n(('Hanger Lane', 'Perivale'), ('Perivale', 'Greenford')) tensor(454., device='cuda:0')\n(('Harlesden', 'Stonebridge Park'), ('Stonebridge Park', 'Wembley Central')) tensor(333., device='cuda:0')\n(('Harlesden', 'Willesden Junction'), ('Willesden Junction', 'Kensal Green')) tensor(545., device='cuda:0')\n(('Harrow &amp; Wealdstone', 'Kenton'), ('Kenton', 'South Kenton')) tensor(118., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(1461., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(29., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(33., device='cuda:0')\n(('HarrowOnTheHill', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(36., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Baker Street')) tensor(1479., device='cuda:0')\n(('HarrowOnTheHill', 'Marylebone'), ('Marylebone', 'Edgware Road (Bak)')) tensor(383., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(222., device='cuda:0')\n(('HarrowOnTheHill', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'North Harrow'), ('North Harrow', 'Pinner')) tensor(259., device='cuda:0')\n(('HarrowOnTheHill', 'Northwick Park'), ('Northwick Park', 'Preston Road')) tensor(21., device='cuda:0')\n(('HarrowOnTheHill', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(389., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(59., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(22., device='cuda:0')\n(('HarrowOnTheHill', 'West Harrow'), ('West Harrow', 'Rayners Lane')) tensor(1303., device='cuda:0')\n(('Hatton Cross', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Heathrow Terminal 5')) tensor(75., device='cuda:0')\n(('Hatton Cross', 'Hounslow West'), ('Hounslow West', 'Hounslow Central')) tensor(571., device='cuda:0')\n(('Heathrow Terminal 4', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(123., device='cuda:0')\n(('Heathrow Terminal 5', 'Heathrow Terminals 123'), ('Heathrow Terminals 123', 'Hatton Cross')) tensor(92., device='cuda:0')\n(('Heathrow Terminals 123', 'Hatton Cross'), ('Hatton Cross', 'Hounslow West')) tensor(332., device='cuda:0')\n(('Hendon Central', 'Brent Cross'), ('Brent Cross', 'Golders Green')) tensor(568., device='cuda:0')\n(('Hendon Central', 'Colindale'), ('Colindale', 'Burnt Oak')) tensor(251., device='cuda:0')\n(('High Barnet', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'Woodside Park')) tensor(159., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(97., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Kensington (Olympia)')) tensor(15., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(379., device='cuda:0')\n(('High Street Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(34., device='cuda:0')\n(('High Street Kensington', 'Gloucester Road'), ('Gloucester Road', 'South Kensington')) tensor(452., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(518., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(110., device='cuda:0')\n(('High Street Kensington', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(172., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(80., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(768., device='cuda:0')\n(('Highbury &amp; Islington', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(392., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(32., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(13., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(617., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(725., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(33., device='cuda:0')\n(('Highbury &amp; Islington', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Russell Square')) tensor(144., device='cuda:0')\n(('Highgate', 'Archway'), ('Archway', 'Tufnell Park')) tensor(1030., device='cuda:0')\n(('Highgate', 'East Finchley'), ('East Finchley', 'Finchley Central')) tensor(639., device='cuda:0')\n(('Hillingdon', 'Ickenham'), ('Ickenham', 'Ruislip')) tensor(424., device='cuda:0')\n(('Holborn', 'Chancery Lane'), ('Chancery Lane', \"St. Paul's\")) tensor(3506., device='cuda:0')\n(('Holborn', 'Covent Garden'), ('Covent Garden', 'Leicester Square')) tensor(203., device='cuda:0')\n(('Holborn', 'Russell Square'), ('Russell Square', \"King's Cross St. Pancras\")) tensor(302., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(2909., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(63., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(215., device='cuda:0')\n(('Holborn', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(404., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(96., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(127., device='cuda:0')\n(('Holland Park', 'Notting Hill Gate'), ('Notting Hill Gate', 'Queensway')) tensor(328., device='cuda:0')\n(('Holland Park', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'White City')) tensor(277., device='cuda:0')\n(('Holloway Road', 'Arsenal'), ('Arsenal', 'Finsbury Park')) tensor(69., device='cuda:0')\n(('Holloway Road', 'Caledonian Road'), ('Caledonian Road', \"King's Cross St. Pancras\")) tensor(243., device='cuda:0')\n(('Hornchurch', 'Elm Park'), ('Elm Park', 'Dagenham East')) tensor(4., device='cuda:0')\n(('Hornchurch', 'Upminster Bridge'), ('Upminster Bridge', 'Upminster')) tensor(437., device='cuda:0')\n(('Hounslow Central', 'Hounslow East'), ('Hounslow East', 'Osterley')) tensor(828., device='cuda:0')\n(('Hounslow Central', 'Hounslow West'), ('Hounslow West', 'Hatton Cross')) tensor(433., device='cuda:0')\n(('Hounslow East', 'Hounslow Central'), ('Hounslow Central', 'Hounslow West')) tensor(554., device='cuda:0')\n(('Hounslow East', 'Osterley'), ('Osterley', 'Boston Manor')) tensor(959., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminal 4')) tensor(69., device='cuda:0')\n(('Hounslow West', 'Hatton Cross'), ('Hatton Cross', 'Heathrow Terminals 123')) tensor(277., device='cuda:0')\n(('Hounslow West', 'Hounslow Central'), ('Hounslow Central', 'Hounslow East')) tensor(667., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Bond Street')) tensor(234., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(492., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(73., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Victoria')) tensor(20., device='cuda:0')\n(('Hyde Park Corner', 'Green Park'), ('Green Park', 'Westminster')) tensor(1029., device='cuda:0')\n(('Hyde Park Corner', 'Knightsbridge'), ('Knightsbridge', 'South Kensington')) tensor(1581., device='cuda:0')\n(('Ickenham', 'Hillingdon'), ('Hillingdon', 'Uxbridge')) tensor(257., device='cuda:0')\n(('Ickenham', 'Ruislip'), ('Ruislip', 'Ruislip Manor')) tensor(541., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(774., device='cuda:0')\n(('Kennington', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Oval'), ('Oval', 'Stockwell')) tensor(1245., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(113., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(10., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(715., device='cuda:0')\n(('Kennington', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(378., device='cuda:0')\n(('Kensal Green', \"Queen's Park\"), (\"Queen's Park\", 'Kilburn Park')) tensor(754., device='cuda:0')\n(('Kensal Green', 'Willesden Junction'), ('Willesden Junction', 'Harlesden')) tensor(470., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(47., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Euston')) tensor(1547., device='cuda:0')\n(('Kentish Town', 'Camden Town'), ('Camden Town', 'Mornington Crescent')) tensor(11., device='cuda:0')\n(('Kentish Town', 'Tufnell Park'), ('Tufnell Park', 'Archway')) tensor(1191., device='cuda:0')\n(('Kenton', 'South Kenton'), ('South Kenton', 'North Wembley')) tensor(150., device='cuda:0')\n(('Kew Gardens', 'Gunnersbury'), ('Gunnersbury', 'Turnham Green')) tensor(510., device='cuda:0')\n(('Kilburn', 'West Hampstead'), ('West Hampstead', 'Finchley Road')) tensor(140., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Dollis Hill')) tensor(1., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(145., device='cuda:0')\n(('Kilburn', 'Willesden Green'), ('Willesden Green', 'Neasden')) tensor(8., device='cuda:0')\n(('Kilburn Park', 'Maida Vale'), ('Maida Vale', 'Warwick Avenue')) tensor(1048., device='cuda:0')\n(('Kilburn Park', \"Queen's Park\"), (\"Queen's Park\", 'Kensal Green')) tensor(622., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Angel'), ('Angel', 'Old Street')) tensor(2221., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Caledonian Road'), ('Caledonian Road', 'Holloway Road')) tensor(246., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Camden Town')) tensor(1406., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Mornington Crescent')) tensor(85., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston'), ('Euston', 'Warren Street')) tensor(881., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Euston Square'), ('Euston Square', 'Great Portland Street')) tensor(4062., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Farringdon'), ('Farringdon', 'Barbican')) tensor(2195., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Highbury &amp; Islington'), ('Highbury &amp; Islington', 'Finsbury Park')) tensor(1352., device='cuda:0')\n((\"King's Cross St. Pancras\", 'Russell Square'), ('Russell Square', 'Holborn')) tensor(299., device='cuda:0')\n(('Kingsbury', 'Queensbury'), ('Queensbury', 'Canons Park')) tensor(189., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(334., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(66., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(16., device='cuda:0')\n(('Kingsbury', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(1., device='cuda:0')\n(('Knightsbridge', 'Hyde Park Corner'), ('Hyde Park Corner', 'Green Park')) tensor(1733., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(1409., device='cuda:0')\n(('Knightsbridge', 'South Kensington'), ('South Kensington', 'Sloane Square')) tensor(14., device='cuda:0')\n(('Ladbroke Grove', 'Latimer Road'), ('Latimer Road', 'Wood Lane')) tensor(299., device='cuda:0')\n(('Ladbroke Grove', 'Westbourne Park'), ('Westbourne Park', 'Royal Oak')) tensor(607., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Borough')) tensor(83., device='cuda:0')\n(('Lambeth North', 'Elephant &amp; Castle'), ('Elephant &amp; Castle', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(19., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(8., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(45., device='cuda:0')\n(('Lambeth North', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(287., device='cuda:0')\n(('Lancaster Gate', 'Marble Arch'), ('Marble Arch', 'Bond Street')) tensor(839., device='cuda:0')\n(('Lancaster Gate', 'Queensway'), ('Queensway', 'Notting Hill Gate')) tensor(616., device='cuda:0')\n(('Latimer Road', 'Ladbroke Grove'), ('Ladbroke Grove', 'Westbourne Park')) tensor(446., device='cuda:0')\n(('Latimer Road', 'Wood Lane'), ('Wood Lane', \"Shepherd's Bush Market\")) tensor(240., device='cuda:0')\n(('Leicester Square', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(103., device='cuda:0')\n(('Leicester Square', 'Covent Garden'), ('Covent Garden', 'Holborn')) tensor(222., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Green Park')) tensor(101., device='cuda:0')\n(('Leicester Square', 'Piccadilly Circus'), ('Piccadilly Circus', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Bond Street')) tensor(277., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(39., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(212., device='cuda:0')\n(('Leicester Square', 'Tottenham Court Road'), ('Tottenham Court Road', 'Oxford Circus')) tensor(29., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(1851., device='cuda:0')\n(('Leyton', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(1449., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Mile End')) tensor(1671., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'West Ham')) tensor(95., device='cuda:0')\n(('Leyton', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2639., device='cuda:0')\n(('Leytonstone', 'Leyton'), ('Leyton', 'Stratford')) tensor(3987., device='cuda:0')\n(('Leytonstone', 'Snaresbrook'), ('Snaresbrook', 'South Woodford')) tensor(1706., device='cuda:0')\n(('Leytonstone', 'Wanstead'), ('Wanstead', 'Redbridge')) tensor(1245., device='cuda:0')\n(('Liverpool Street', 'Aldgate'), ('Aldgate', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(3609., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(2842., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(2155., device='cuda:0')\n(('Liverpool Street', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(14., device='cuda:0')\n(('Liverpool Street', 'Bethnal Green'), ('Bethnal Green', 'Mile End')) tensor(3900., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(1688., device='cuda:0')\n(('Liverpool Street', 'Moorgate'), ('Moorgate', 'Old Street')) tensor(1701., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(200., device='cuda:0')\n(('Liverpool Street', 'Tottenham Hale'), ('Tottenham Hale', 'Seven Sisters')) tensor(546., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(73., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2915., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(495., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(107., device='cuda:0')\n(('London Bridge', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1264., device='cuda:0')\n(('London Bridge', 'Bermondsey'), ('Bermondsey', 'Canada Water')) tensor(1250., device='cuda:0')\n(('London Bridge', 'Borough'), ('Borough', 'Elephant &amp; Castle')) tensor(795., device='cuda:0')\n(('London Bridge', 'Southwark'), ('Southwark', 'Waterloo')) tensor(4797., device='cuda:0')\n(('Loughton', 'Buckhurst Hill'), ('Buckhurst Hill', 'Woodford')) tensor(773., device='cuda:0')\n(('Loughton', 'Debden'), ('Debden', 'Theydon Bois')) tensor(301., device='cuda:0')\n(('Maida Vale', 'Kilburn Park'), ('Kilburn Park', \"Queen's Park\")) tensor(736., device='cuda:0')\n(('Maida Vale', 'Warwick Avenue'), ('Warwick Avenue', 'Paddington')) tensor(1186., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(21., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(806., device='cuda:0')\n(('Manor House', 'Finsbury Park'), ('Finsbury Park', 'Seven Sisters')) tensor(328., device='cuda:0')\n(('Manor House', 'Turnpike Lane'), ('Turnpike Lane', 'Wood Green')) tensor(794., device='cuda:0')\n(('Mansion House', 'Blackfriars'), ('Blackfriars', 'Temple')) tensor(286., device='cuda:0')\n(('Mansion House', 'Cannon Street'), ('Cannon Street', 'Bank / Monument')) tensor(265., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(104., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(145., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Oxford Circus')) tensor(161., device='cuda:0')\n(('Marble Arch', 'Bond Street'), ('Bond Street', 'Tottenham Court Road')) tensor(658., device='cuda:0')\n(('Marble Arch', 'Lancaster Gate'), ('Lancaster Gate', 'Queensway')) tensor(725., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(1060., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(1., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(4., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(601., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(104., device='cuda:0')\n(('Marylebone', 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(15., device='cuda:0')\n(('Marylebone', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Paddington')) tensor(393., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(5., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(262., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(185., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(115., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(265., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(69., device='cuda:0')\n(('Marylebone', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(699., device='cuda:0')\n(('Mile End', 'Bethnal Green'), ('Bethnal Green', 'Liverpool Street')) tensor(3726., device='cuda:0')\n(('Mile End', 'Bow Road'), ('Bow Road', 'BromleyByBow')) tensor(112., device='cuda:0')\n(('Mile End', 'Stepney Green'), ('Stepney Green', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Leyton')) tensor(1541., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'West Ham')) tensor(1383., device='cuda:0')\n(('Mile End', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(7., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(94., device='cuda:0')\n(('Mill Hill East', 'Finchley Central'), ('Finchley Central', 'West Finchley')) tensor(3., device='cuda:0')\n(('Moor Park', 'Croxley'), ('Croxley', 'Watford')) tensor(124., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(255., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(284., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(9., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(13., device='cuda:0')\n(('Moor Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(20., device='cuda:0')\n(('Moor Park', 'Northwood'), ('Northwood', 'Northwood Hills')) tensor(113., device='cuda:0')\n(('Moor Park', 'Rickmansworth'), ('Rickmansworth', 'Chorleywood')) tensor(9., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(55., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(455., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(15., device='cuda:0')\n(('Moorgate', 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(54., device='cuda:0')\n(('Moorgate', 'Barbican'), ('Barbican', 'Farringdon')) tensor(1978., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(187., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(1525., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(1624., device='cuda:0')\n(('Moorgate', 'Liverpool Street'), ('Liverpool Street', 'Tottenham Hale')) tensor(26., device='cuda:0')\n(('Moorgate', 'Old Street'), ('Old Street', 'Angel')) tensor(2014., device='cuda:0')\n(('Morden', 'South Wimbledon'), ('South Wimbledon', 'Colliers Wood')) tensor(199., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Chalk Farm')) tensor(9., device='cuda:0')\n(('Mornington Crescent', 'Camden Town'), ('Camden Town', 'Kentish Town')) tensor(10., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(82., device='cuda:0')\n(('Mornington Crescent', 'Euston'), ('Euston', 'Warren Street')) tensor(88., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(114., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(14., device='cuda:0')\n(('Neasden', 'Wembley Park'), ('Wembley Park', 'Preston Road')) tensor(5., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Finchley Road')) tensor(108., device='cuda:0')\n(('Neasden', 'Willesden Green'), ('Willesden Green', 'Kilburn')) tensor(8., device='cuda:0')\n(('Newbury Park', 'Barkingside'), ('Barkingside', 'Fairlop')) tensor(335., device='cuda:0')\n(('Newbury Park', 'Gants Hill'), ('Gants Hill', 'Redbridge')) tensor(742., device='cuda:0')\n(('North Acton', 'East Acton'), ('East Acton', 'White City')) tensor(131., device='cuda:0')\n(('North Acton', 'Hanger Lane'), ('Hanger Lane', 'Perivale')) tensor(534., device='cuda:0')\n(('North Acton', 'West Acton'), ('West Acton', 'Ealing Broadway')) tensor(1035., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Acton Town')) tensor(189., device='cuda:0')\n(('North Ealing', 'Ealing Common'), ('Ealing Common', 'Ealing Broadway')) tensor(152., device='cuda:0')\n(('North Ealing', 'Park Royal'), ('Park Royal', 'Alperton')) tensor(180., device='cuda:0')\n(('North Greenwich', 'Canary Wharf'), ('Canary Wharf', 'Canada Water')) tensor(806., device='cuda:0')\n(('North Greenwich', 'Canning Town'), ('Canning Town', 'West Ham')) tensor(513., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(190., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(196., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(3., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(7., device='cuda:0')\n(('North Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(10., device='cuda:0')\n(('North Harrow', 'Pinner'), ('Pinner', 'Northwood Hills')) tensor(104., device='cuda:0')\n(('North Wembley', 'South Kenton'), ('South Kenton', 'Kenton')) tensor(163., device='cuda:0')\n(('North Wembley', 'Wembley Central'), ('Wembley Central', 'Stonebridge Park')) tensor(272., device='cuda:0')\n(('Northfields', 'Boston Manor'), ('Boston Manor', 'Osterley')) tensor(924., device='cuda:0')\n(('Northfields', 'South Ealing'), ('South Ealing', 'Acton Town')) tensor(1308., device='cuda:0')\n(('Northolt', 'Greenford'), ('Greenford', 'Perivale')) tensor(382., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'Ruislip Gardens')) tensor(51., device='cuda:0')\n(('Northolt', 'South Ruislip'), ('South Ruislip', 'West Ruislip')) tensor(73., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(92., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(110., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(7., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(2., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwick Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(13., device='cuda:0')\n(('Northwick Park', 'Preston Road'), ('Preston Road', 'Wembley Park')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(5., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'HarrowOnTheHill')) tensor(257., device='cuda:0')\n(('Northwood', 'Moor Park'), ('Moor Park', 'Rickmansworth')) tensor(5., device='cuda:0')\n(('Northwood', 'Northwood Hills'), ('Northwood Hills', 'Pinner')) tensor(5., device='cuda:0')\n(('Northwood Hills', 'Northwood'), ('Northwood', 'Moor Park')) tensor(124., device='cuda:0')\n(('Northwood Hills', 'Pinner'), ('Pinner', 'North Harrow')) tensor(107., device='cuda:0')\n(('Notting Hill Gate', 'Bayswater'), ('Bayswater', 'Paddington')) tensor(656., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', \"Earl's Court\")) tensor(581., device='cuda:0')\n(('Notting Hill Gate', 'High Street Kensington'), ('High Street Kensington', 'Gloucester Road')) tensor(194., device='cuda:0')\n(('Notting Hill Gate', 'Holland Park'), ('Holland Park', \"Shepherd's Bush (Cen)\")) tensor(462., device='cuda:0')\n(('Notting Hill Gate', 'Queensway'), ('Queensway', 'Lancaster Gate')) tensor(611., device='cuda:0')\n(('Oakwood', 'Southgate'), ('Southgate', 'Arnos Grove')) tensor(229., device='cuda:0')\n(('Old Street', 'Angel'), ('Angel', \"King's Cross St. Pancras\")) tensor(2078., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Bank / Monument')) tensor(296., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Barbican')) tensor(3., device='cuda:0')\n(('Old Street', 'Moorgate'), ('Moorgate', 'Liverpool Street')) tensor(1828., device='cuda:0')\n(('Osterley', 'Boston Manor'), ('Boston Manor', 'Northfields')) tensor(1091., device='cuda:0')\n(('Osterley', 'Hounslow East'), ('Hounslow East', 'Hounslow Central')) tensor(679., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(691., device='cuda:0')\n(('Oval', 'Kennington'), ('Kennington', 'Waterloo')) tensor(837., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(155., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(859., device='cuda:0')\n(('Oval', 'Stockwell'), ('Stockwell', 'Vauxhall')) tensor(169., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(672., device='cuda:0')\n(('Oxford Circus', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(178., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(519., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(999., device='cuda:0')\n(('Oxford Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(361., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Charing Cross')) tensor(304., device='cuda:0')\n(('Oxford Circus', 'Piccadilly Circus'), ('Piccadilly Circus', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', \"Regent's Park\"), (\"Regent's Park\", 'Baker Street')) tensor(674., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Goodge Street')) tensor(47., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Holborn')) tensor(376., device='cuda:0')\n(('Oxford Circus', 'Tottenham Court Road'), ('Tottenham Court Road', 'Leicester Square')) tensor(29., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Euston')) tensor(2437., device='cuda:0')\n(('Oxford Circus', 'Warren Street'), ('Warren Street', 'Goodge Street')) tensor(48., device='cuda:0')\n(('Paddington', 'Bayswater'), ('Bayswater', 'Notting Hill Gate')) tensor(811., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(2429., device='cuda:0')\n(('Paddington', 'Ealing Broadway'), ('Ealing Broadway', 'West Acton')) tensor(891., device='cuda:0')\n(('Paddington', 'Edgware Road (Bak)'), ('Edgware Road (Bak)', 'Marylebone')) tensor(353., device='cuda:0')\n(('Paddington', 'Edgware Road (Cir)'), ('Edgware Road (Cir)', 'Baker Street')) tensor(5928., device='cuda:0')\n(('Paddington', 'Royal Oak'), ('Royal Oak', 'Westbourne Park')) tensor(686., device='cuda:0')\n(('Paddington', 'Warwick Avenue'), ('Warwick Avenue', 'Maida Vale')) tensor(976., device='cuda:0')\n(('Park Royal', 'Alperton'), ('Alperton', 'Sudbury Town')) tensor(128., device='cuda:0')\n(('Park Royal', 'North Ealing'), ('North Ealing', 'Ealing Common')) tensor(305., device='cuda:0')\n(('Parsons Green', 'Fulham Broadway'), ('Fulham Broadway', 'West Brompton')) tensor(1506., device='cuda:0')\n(('Parsons Green', 'Putney Bridge'), ('Putney Bridge', 'East Putney')) tensor(828., device='cuda:0')\n(('Perivale', 'Greenford'), ('Greenford', 'Northolt')) tensor(321., device='cuda:0')\n(('Perivale', 'Hanger Lane'), ('Hanger Lane', 'North Acton')) tensor(621., device='cuda:0')\n(('Piccadilly Circus', 'Charing Cross'), ('Charing Cross', 'Embankment')) tensor(180., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Bond Street')) tensor(220., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(74., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Victoria')) tensor(109., device='cuda:0')\n(('Piccadilly Circus', 'Green Park'), ('Green Park', 'Westminster')) tensor(106., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(138., device='cuda:0')\n(('Piccadilly Circus', 'Leicester Square'), ('Leicester Square', 'Tottenham Court Road')) tensor(82., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(218., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(215., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(80., device='cuda:0')\n(('Piccadilly Circus', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(174., device='cuda:0')\n(('Pimlico', 'Vauxhall'), ('Vauxhall', 'Stockwell')) tensor(940., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Green Park')) tensor(1025., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', 'Sloane Square')) tensor(258., device='cuda:0')\n(('Pimlico', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(89., device='cuda:0')\n(('Pinner', 'North Harrow'), ('North Harrow', 'HarrowOnTheHill')) tensor(261., device='cuda:0')\n(('Pinner', 'Northwood Hills'), ('Northwood Hills', 'Northwood')) tensor(5., device='cuda:0')\n(('Plaistow', 'Upton Park'), ('Upton Park', 'East Ham')) tensor(1., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Barking')) tensor(9., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(4., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Canning Town')) tensor(97., device='cuda:0')\n(('Plaistow', 'West Ham'), ('West Ham', 'Stratford')) tensor(770., device='cuda:0')\n(('Preston Road', 'Northwick Park'), ('Northwick Park', 'HarrowOnTheHill')) tensor(23., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Finchley Road')) tensor(84., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'HarrowOnTheHill')) tensor(22., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Kingsbury')) tensor(2., device='cuda:0')\n(('Preston Road', 'Wembley Park'), ('Wembley Park', 'Neasden')) tensor(5., device='cuda:0')\n(('Putney Bridge', 'East Putney'), ('East Putney', 'Southfields')) tensor(577., device='cuda:0')\n(('Putney Bridge', 'Parsons Green'), ('Parsons Green', 'Fulham Broadway')) tensor(1250., device='cuda:0')\n((\"Queen's Park\", 'Kensal Green'), ('Kensal Green', 'Willesden Junction')) tensor(551., device='cuda:0')\n((\"Queen's Park\", 'Kilburn Park'), ('Kilburn Park', 'Maida Vale')) tensor(903., device='cuda:0')\n(('Queensbury', 'Canons Park'), ('Canons Park', 'Stanmore')) tensor(99., device='cuda:0')\n(('Queensbury', 'Kingsbury'), ('Kingsbury', 'Wembley Park')) tensor(312., device='cuda:0')\n(('Queensway', 'Lancaster Gate'), ('Lancaster Gate', 'Marble Arch')) tensor(723., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Bayswater')) tensor(18., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'High Street Kensington')) tensor(165., device='cuda:0')\n(('Queensway', 'Notting Hill Gate'), ('Notting Hill Gate', 'Holland Park')) tensor(333., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Acton Town')) tensor(76., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(173., device='cuda:0')\n(('Ravenscourt Park', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Ravenscourt Park', 'Stamford Brook'), ('Stamford Brook', 'Turnham Green')) tensor(4., device='cuda:0')\n(('Rayners Lane', 'Eastcote'), ('Eastcote', 'Ruislip Manor')) tensor(743., device='cuda:0')\n(('Rayners Lane', 'South Harrow'), ('South Harrow', 'Sudbury Hill')) tensor(253., device='cuda:0')\n(('Rayners Lane', 'West Harrow'), ('West Harrow', 'HarrowOnTheHill')) tensor(1408., device='cuda:0')\n(('Redbridge', 'Gants Hill'), ('Gants Hill', 'Newbury Park')) tensor(701., device='cuda:0')\n(('Redbridge', 'Wanstead'), ('Wanstead', 'Leytonstone')) tensor(1302., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(426., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(150., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(6., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(106., device='cuda:0')\n((\"Regent's Park\", 'Baker Street'), ('Baker Street', \"St. John's Wood\")) tensor(12., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(40., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(211., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(26., device='cuda:0')\n((\"Regent's Park\", 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(347., device='cuda:0')\n(('Richmond', 'Kew Gardens'), ('Kew Gardens', 'Gunnersbury')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'Chorleywood'), ('Chorleywood', 'Chalfont &amp; Latimer')) tensor(312., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(276., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(305., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(5., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(9., device='cuda:0')\n(('Rickmansworth', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(11., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Croxley')) tensor(7., device='cuda:0')\n(('Rickmansworth', 'Moor Park'), ('Moor Park', 'Northwood')) tensor(3., device='cuda:0')\n(('Roding Valley', 'Chigwell'), ('Chigwell', 'Grange Hill')) tensor(261., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(8., device='cuda:0')\n(('Roding Valley', 'Woodford'), ('Woodford', 'South Woodford')) tensor(372., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Bayswater')) tensor(47., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(92., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(54., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(684., device='cuda:0')\n(('Royal Oak', 'Paddington'), ('Paddington', 'Warwick Avenue')) tensor(8., device='cuda:0')\n(('Royal Oak', 'Westbourne Park'), ('Westbourne Park', 'Ladbroke Grove')) tensor(569., device='cuda:0')\n(('Ruislip', 'Ickenham'), ('Ickenham', 'Hillingdon')) tensor(398., device='cuda:0')\n(('Ruislip', 'Ruislip Manor'), ('Ruislip Manor', 'Eastcote')) tensor(712., device='cuda:0')\n(('Ruislip Gardens', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(78., device='cuda:0')\n(('Ruislip Manor', 'Eastcote'), ('Eastcote', 'Rayners Lane')) tensor(825., device='cuda:0')\n(('Ruislip Manor', 'Ruislip'), ('Ruislip', 'Ickenham')) tensor(496., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(119., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(90., device='cuda:0')\n(('Russell Square', 'Holborn'), ('Holborn', 'Tottenham Court Road')) tensor(327., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Angel')) tensor(59., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Caledonian Road')) tensor(40., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston')) tensor(91., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Euston Square')) tensor(86., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Farringdon')) tensor(53., device='cuda:0')\n(('Russell Square', \"King's Cross St. Pancras\"), (\"King's Cross St. Pancras\", 'Highbury &amp; Islington')) tensor(151., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Arsenal')) tensor(66., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Highbury &amp; Islington')) tensor(387., device='cuda:0')\n(('Seven Sisters', 'Finsbury Park'), ('Finsbury Park', 'Manor House')) tensor(335., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Blackhorse Road')) tensor(153., device='cuda:0')\n(('Seven Sisters', 'Tottenham Hale'), ('Tottenham Hale', 'Liverpool Street')) tensor(561., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'Holland Park'), ('Holland Park', 'Notting Hill Gate')) tensor(468., device='cuda:0')\n((\"Shepherd's Bush (Cen)\", 'White City'), ('White City', 'East Acton')) tensor(93., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Goldhawk Road'), ('Goldhawk Road', 'Hammersmith (H&amp;C)')) tensor(77., device='cuda:0')\n((\"Shepherd's Bush Market\", 'Wood Lane'), ('Wood Lane', 'Latimer Road')) tensor(279., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Gloucester Road')) tensor(2467., device='cuda:0')\n(('Sloane Square', 'South Kensington'), ('South Kensington', 'Knightsbridge')) tensor(15., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Green Park')) tensor(1713., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', 'Pimlico')) tensor(260., device='cuda:0')\n(('Sloane Square', 'Victoria'), ('Victoria', \"St. James's Park\")) tensor(1042., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(2080., device='cuda:0')\n(('Snaresbrook', 'Leytonstone'), ('Leytonstone', 'Wanstead')) tensor(7., device='cuda:0')\n(('Snaresbrook', 'South Woodford'), ('South Woodford', 'Woodford')) tensor(1415., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Chiswick Park')) tensor(8., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(1168., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Hammersmith (Dis)')) tensor(212., device='cuda:0')\n(('South Ealing', 'Acton Town'), ('Acton Town', 'Turnham Green')) tensor(25., device='cuda:0')\n(('South Ealing', 'Northfields'), ('Northfields', 'Boston Manor')) tensor(1019., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(62., device='cuda:0')\n(('South Harrow', 'Rayners Lane'), ('Rayners Lane', 'West Harrow')) tensor(316., device='cuda:0')\n(('South Harrow', 'Sudbury Hill'), ('Sudbury Hill', 'Sudbury Town')) tensor(183., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', \"Earl's Court\")) tensor(3171., device='cuda:0')\n(('South Kensington', 'Gloucester Road'), ('Gloucester Road', 'High Street Kensington')) tensor(414., device='cuda:0')\n(('South Kensington', 'Knightsbridge'), ('Knightsbridge', 'Hyde Park Corner')) tensor(1538., device='cuda:0')\n(('South Kensington', 'Sloane Square'), ('Sloane Square', 'Victoria')) tensor(2746., device='cuda:0')\n(('South Kenton', 'Kenton'), ('Kenton', 'Harrow &amp; Wealdstone')) tensor(119., device='cuda:0')\n(('South Kenton', 'North Wembley'), ('North Wembley', 'Wembley Central')) tensor(207., device='cuda:0')\n(('South Ruislip', 'Northolt'), ('Northolt', 'Greenford')) tensor(252., device='cuda:0')\n(('South Wimbledon', 'Colliers Wood'), ('Colliers Wood', 'Tooting Broadway')) tensor(328., device='cuda:0')\n(('South Woodford', 'Snaresbrook'), ('Snaresbrook', 'Leytonstone')) tensor(1888., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Buckhurst Hill')) tensor(830., device='cuda:0')\n(('South Woodford', 'Woodford'), ('Woodford', 'Roding Valley')) tensor(309., device='cuda:0')\n(('Southfields', 'East Putney'), ('East Putney', 'Putney Bridge')) tensor(677., device='cuda:0')\n(('Southfields', 'Wimbledon Park'), ('Wimbledon Park', 'Wimbledon')) tensor(255., device='cuda:0')\n(('Southgate', 'Arnos Grove'), ('Arnos Grove', 'Bounds Green')) tensor(390., device='cuda:0')\n(('Southgate', 'Oakwood'), ('Oakwood', 'Cockfosters')) tensor(101., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bank / Monument')) tensor(3604., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Bermondsey')) tensor(1002., device='cuda:0')\n(('Southwark', 'London Bridge'), ('London Bridge', 'Borough')) tensor(52., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')) tensor(279., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(640., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(45., device='cuda:0')\n(('Southwark', 'Waterloo'), ('Waterloo', 'Westminster')) tensor(3875., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Green Park')) tensor(132., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Pimlico')) tensor(84., device='cuda:0')\n((\"St. James's Park\", 'Victoria'), ('Victoria', 'Sloane Square')) tensor(1027., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Embankment')) tensor(128., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Green Park')) tensor(135., device='cuda:0')\n((\"St. James's Park\", 'Westminster'), ('Westminster', 'Waterloo')) tensor(1190., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Bond Street')) tensor(168., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Edgware Road (Cir)')) tensor(54., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Great Portland Street')) tensor(119., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', 'Marylebone')) tensor(16., device='cuda:0')\n((\"St. John's Wood\", 'Baker Street'), ('Baker Street', \"Regent's Park\")) tensor(11., device='cuda:0')\n((\"St. John's Wood\", 'Swiss Cottage'), ('Swiss Cottage', 'Finchley Road')) tensor(27., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(49., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(2220., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(86., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(13., device='cuda:0')\n((\"St. Paul's\", 'Bank / Monument'), ('Bank / Monument', 'Tower Hill')) tensor(1106., device='cuda:0')\n((\"St. Paul's\", 'Chancery Lane'), ('Chancery Lane', 'Holborn')) tensor(3317., device='cuda:0')\n(('Stamford Brook', 'Ravenscourt Park'), ('Ravenscourt Park', 'Hammersmith (Dis)')) tensor(63., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Acton Town')) tensor(89., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Chiswick Park')) tensor(1., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Gunnersbury')) tensor(6., device='cuda:0')\n(('Stamford Brook', 'Turnham Green'), ('Turnham Green', 'Hammersmith (Dis)')) tensor(67., device='cuda:0')\n(('Stanmore', 'Canons Park'), ('Canons Park', 'Queensbury')) tensor(110., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(132., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Bow Road')) tensor(5., device='cuda:0')\n(('Stepney Green', 'Mile End'), ('Mile End', 'Stratford')) tensor(24., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(214., device='cuda:0')\n(('Stepney Green', 'Whitechapel'), ('Whitechapel', 'Stratford')) tensor(25., device='cuda:0')\n(('Stockwell', 'Clapham North'), ('Clapham North', 'Clapham Common')) tensor(1366., device='cuda:0')\n(('Stockwell', 'Oval'), ('Oval', 'Kennington')) tensor(1370., device='cuda:0')\n(('Stockwell', 'Vauxhall'), ('Vauxhall', 'Pimlico')) tensor(928., device='cuda:0')\n(('Stonebridge Park', 'Harlesden'), ('Harlesden', 'Willesden Junction')) tensor(443., device='cuda:0')\n(('Stonebridge Park', 'Wembley Central'), ('Wembley Central', 'North Wembley')) tensor(257., device='cuda:0')\n(('Stratford', 'Leyton'), ('Leyton', 'Leytonstone')) tensor(3711., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bethnal Green')) tensor(3185., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Bow Road')) tensor(8., device='cuda:0')\n(('Stratford', 'Mile End'), ('Mile End', 'Stepney Green')) tensor(27., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Barking')) tensor(2374., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'BromleyByBow')) tensor(7., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Canning Town')) tensor(170., device='cuda:0')\n(('Stratford', 'West Ham'), ('West Ham', 'Plaistow')) tensor(707., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Aldgate East')) tensor(5039., device='cuda:0')\n(('Stratford', 'Whitechapel'), ('Whitechapel', 'Stepney Green')) tensor(26., device='cuda:0')\n(('Sudbury Hill', 'South Harrow'), ('South Harrow', 'Rayners Lane')) tensor(290., device='cuda:0')\n(('Sudbury Hill', 'Sudbury Town'), ('Sudbury Town', 'Alperton')) tensor(143., device='cuda:0')\n(('Sudbury Town', 'Alperton'), ('Alperton', 'Park Royal')) tensor(166., device='cuda:0')\n(('Sudbury Town', 'Sudbury Hill'), ('Sudbury Hill', 'South Harrow')) tensor(190., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(180., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(25., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(14., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(4., device='cuda:0')\n(('Swiss Cottage', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(8., device='cuda:0')\n(('Swiss Cottage', \"St. John's Wood\"), (\"St. John's Wood\", 'Baker Street')) tensor(175., device='cuda:0')\n(('Temple', 'Blackfriars'), ('Blackfriars', 'Mansion House')) tensor(291., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(57., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Waterloo')) tensor(44., device='cuda:0')\n(('Temple', 'Embankment'), ('Embankment', 'Westminster')) tensor(487., device='cuda:0')\n(('Theydon Bois', 'Debden'), ('Debden', 'Loughton')) tensor(447., device='cuda:0')\n(('Tooting Bec', 'Balham'), ('Balham', 'Clapham South')) tensor(939., device='cuda:0')\n(('Tooting Bec', 'Tooting Broadway'), ('Tooting Broadway', 'Colliers Wood')) tensor(404., device='cuda:0')\n(('Tooting Broadway', 'Colliers Wood'), ('Colliers Wood', 'South Wimbledon')) tensor(264., device='cuda:0')\n(('Tooting Broadway', 'Tooting Bec'), ('Tooting Bec', 'Balham')) tensor(763., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Baker Street')) tensor(2377., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Green Park')) tensor(244., device='cuda:0')\n(('Tottenham Court Road', 'Bond Street'), ('Bond Street', 'Marble Arch')) tensor(630., device='cuda:0')\n(('Tottenham Court Road', 'Goodge Street'), ('Goodge Street', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Chancery Lane')) tensor(3254., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Covent Garden')) tensor(104., device='cuda:0')\n(('Tottenham Court Road', 'Holborn'), ('Holborn', 'Russell Square')) tensor(322., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Charing Cross')) tensor(154., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Covent Garden')) tensor(101., device='cuda:0')\n(('Tottenham Court Road', 'Leicester Square'), ('Leicester Square', 'Piccadilly Circus')) tensor(86., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(245., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(80., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(40., device='cuda:0')\n(('Tottenham Court Road', 'Oxford Circus'), ('Oxford Circus', 'Warren Street')) tensor(54., device='cuda:0')\n(('Tottenham Hale', 'Blackhorse Road'), ('Blackhorse Road', 'Walthamstow Central')) tensor(197., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate')) tensor(24., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Aldgate East')) tensor(138., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bank / Monument')) tensor(566., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Bethnal Green')) tensor(133., device='cuda:0')\n(('Tottenham Hale', 'Liverpool Street'), ('Liverpool Street', 'Moorgate')) tensor(26., device='cuda:0')\n(('Tottenham Hale', 'Seven Sisters'), ('Seven Sisters', 'Finsbury Park')) tensor(690., device='cuda:0')\n(('Totteridge &amp; Whetstone', 'Woodside Park'), ('Woodside Park', 'West Finchley')) tensor(259., device='cuda:0')\n(('Tower Hill', 'Aldgate'), ('Aldgate', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(16., device='cuda:0')\n(('Tower Hill', 'Aldgate East'), ('Aldgate East', 'Whitechapel')) tensor(2085., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Cannon Street')) tensor(96., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Liverpool Street')) tensor(17., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'London Bridge')) tensor(1239., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', 'Moorgate')) tensor(59., device='cuda:0')\n(('Tower Hill', 'Bank / Monument'), ('Bank / Monument', \"St. Paul's\")) tensor(1078., device='cuda:0')\n(('Tufnell Park', 'Archway'), ('Archway', 'Highgate')) tensor(965., device='cuda:0')\n(('Tufnell Park', 'Kentish Town'), ('Kentish Town', 'Camden Town')) tensor(1387., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'Ealing Common')) tensor(769., device='cuda:0')\n(('Turnham Green', 'Acton Town'), ('Acton Town', 'South Ealing')) tensor(21., device='cuda:0')\n(('Turnham Green', 'Gunnersbury'), ('Gunnersbury', 'Kew Gardens')) tensor(470., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Barons Court')) tensor(367., device='cuda:0')\n(('Turnham Green', 'Hammersmith (Dis)'), ('Hammersmith (Dis)', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnham Green', 'Stamford Brook'), ('Stamford Brook', 'Ravenscourt Park')) tensor(5., device='cuda:0')\n(('Turnpike Lane', 'Manor House'), ('Manor House', 'Finsbury Park')) tensor(1014., device='cuda:0')\n(('Turnpike Lane', 'Wood Green'), ('Wood Green', 'Bounds Green')) tensor(618., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'Upney')) tensor(5., device='cuda:0')\n(('Upminster', 'Barking'), ('Barking', 'West Ham')) tensor(735., device='cuda:0')\n(('Upminster', 'Upminster Bridge'), ('Upminster Bridge', 'Hornchurch')) tensor(468., device='cuda:0')\n(('Upminster Bridge', 'Hornchurch'), ('Hornchurch', 'Elm Park')) tensor(269., device='cuda:0')\n(('Upminster Bridge', 'Upminster'), ('Upminster', 'Barking')) tensor(571., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'East Ham')) tensor(8., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'Upminster')) tensor(4., device='cuda:0')\n(('Upney', 'Barking'), ('Barking', 'West Ham')) tensor(779., device='cuda:0')\n(('Upney', 'Becontree'), ('Becontree', 'Dagenham Heathway')) tensor(478., device='cuda:0')\n(('Upton Park', 'East Ham'), ('East Ham', 'Barking')) tensor(8., device='cuda:0')\n(('Upton Park', 'Plaistow'), ('Plaistow', 'West Ham')) tensor(464., device='cuda:0')\n(('Uxbridge', 'Hillingdon'), ('Hillingdon', 'Ickenham')) tensor(256., device='cuda:0')\n(('Vauxhall', 'Pimlico'), ('Pimlico', 'Victoria')) tensor(1094., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Brixton')) tensor(152., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Clapham North')) tensor(680., device='cuda:0')\n(('Vauxhall', 'Stockwell'), ('Stockwell', 'Oval')) tensor(173., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Bond Street')) tensor(835., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(23., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(974., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(116., device='cuda:0')\n(('Victoria', 'Green Park'), ('Green Park', 'Westminster')) tensor(1201., device='cuda:0')\n(('Victoria', 'Pimlico'), ('Pimlico', 'Vauxhall')) tensor(1093., device='cuda:0')\n(('Victoria', 'Sloane Square'), ('Sloane Square', 'South Kensington')) tensor(2745., device='cuda:0')\n(('Victoria', \"St. James's Park\"), (\"St. James's Park\", 'Westminster')) tensor(1214., device='cuda:0')\n(('Walthamstow Central', 'Blackhorse Road'), ('Blackhorse Road', 'Tottenham Hale')) tensor(221., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Leyton')) tensor(1544., device='cuda:0')\n(('Wanstead', 'Leytonstone'), ('Leytonstone', 'Snaresbrook')) tensor(15., device='cuda:0')\n(('Wanstead', 'Redbridge'), ('Redbridge', 'Gants Hill')) tensor(1049., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Camden Town')) tensor(1550., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', \"King's Cross St. Pancras\")) tensor(881., device='cuda:0')\n(('Warren Street', 'Euston'), ('Euston', 'Mornington Crescent')) tensor(73., device='cuda:0')\n(('Warren Street', 'Goodge Street'), ('Goodge Street', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Bond Street')) tensor(553., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Green Park')) tensor(1574., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Piccadilly Circus')) tensor(182., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', \"Regent's Park\")) tensor(369., device='cuda:0')\n(('Warren Street', 'Oxford Circus'), ('Oxford Circus', 'Tottenham Court Road')) tensor(55., device='cuda:0')\n(('Warwick Avenue', 'Maida Vale'), ('Maida Vale', 'Kilburn Park')) tensor(836., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Bayswater')) tensor(103., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Ealing Broadway')) tensor(58., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Bak)')) tensor(43., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Edgware Road (Cir)')) tensor(1143., device='cuda:0')\n(('Warwick Avenue', 'Paddington'), ('Paddington', 'Royal Oak')) tensor(8., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(229., device='cuda:0')\n(('Waterloo', 'Embankment'), ('Embankment', 'Temple')) tensor(53., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Elephant &amp; Castle')) tensor(231., device='cuda:0')\n(('Waterloo', 'Kennington'), ('Kennington', 'Oval')) tensor(779., device='cuda:0')\n(('Waterloo', 'Lambeth North'), ('Lambeth North', 'Elephant &amp; Castle')) tensor(226., device='cuda:0')\n(('Waterloo', 'Southwark'), ('Southwark', 'London Bridge')) tensor(4777., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', 'Green Park')) tensor(3439., device='cuda:0')\n(('Waterloo', 'Westminster'), ('Westminster', \"St. James's Park\")) tensor(1183., device='cuda:0')\n(('Watford', 'Croxley'), ('Croxley', 'Moor Park')) tensor(122., device='cuda:0')\n(('Wembley Central', 'North Wembley'), ('North Wembley', 'South Kenton')) tensor(199., device='cuda:0')\n(('Wembley Central', 'Stonebridge Park'), ('Stonebridge Park', 'Harlesden')) tensor(356., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(657., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(13., device='cuda:0')\n(('Wembley Park', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(68., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(12., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(14., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(4., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(7., device='cuda:0')\n(('Wembley Park', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'West Harrow')) tensor(36., device='cuda:0')\n(('Wembley Park', 'Kingsbury'), ('Kingsbury', 'Queensbury')) tensor(311., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Dollis Hill')) tensor(14., device='cuda:0')\n(('Wembley Park', 'Neasden'), ('Neasden', 'Willesden Green')) tensor(12., device='cuda:0')\n(('Wembley Park', 'Preston Road'), ('Preston Road', 'Northwick Park')) tensor(4., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Ealing Common')) tensor(61., device='cuda:0')\n(('West Acton', 'Ealing Broadway'), ('Ealing Broadway', 'Paddington')) tensor(1040., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'East Acton')) tensor(149., device='cuda:0')\n(('West Acton', 'North Acton'), ('North Acton', 'Hanger Lane')) tensor(600., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Barons Court')) tensor(144., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(1519., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(344., device='cuda:0')\n(('West Brompton', \"Earl's Court\"), (\"Earl's Court\", 'West Kensington')) tensor(7., device='cuda:0')\n(('West Brompton', 'Fulham Broadway'), ('Fulham Broadway', 'Parsons Green')) tensor(1357., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'East Finchley')) tensor(468., device='cuda:0')\n(('West Finchley', 'Finchley Central'), ('Finchley Central', 'Mill Hill East')) tensor(2., device='cuda:0')\n(('West Finchley', 'Woodside Park'), ('Woodside Park', 'Totteridge &amp; Whetstone')) tensor(221., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'East Ham')) tensor(588., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upminster')) tensor(788., device='cuda:0')\n(('West Ham', 'Barking'), ('Barking', 'Upney')) tensor(857., device='cuda:0')\n(('West Ham', 'BromleyByBow'), ('BromleyByBow', 'Bow Road')) tensor(16., device='cuda:0')\n(('West Ham', 'Canning Town'), ('Canning Town', 'North Greenwich')) tensor(490., device='cuda:0')\n(('West Ham', 'Plaistow'), ('Plaistow', 'Upton Park')) tensor(482., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Leyton')) tensor(122., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Mile End')) tensor(1283., device='cuda:0')\n(('West Ham', 'Stratford'), ('Stratford', 'Whitechapel')) tensor(2023., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(267., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(19., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(4., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(13., device='cuda:0')\n(('West Hampstead', 'Finchley Road'), ('Finchley Road', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Hampstead', 'Kilburn'), ('Kilburn', 'Willesden Green')) tensor(3., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Finchley Road')) tensor(660., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Marylebone')) tensor(779., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Moor Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'North Harrow')) tensor(6., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Northwick Park')) tensor(15., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Rickmansworth')) tensor(13., device='cuda:0')\n(('West Harrow', 'HarrowOnTheHill'), ('HarrowOnTheHill', 'Wembley Park')) tensor(31., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'Eastcote')) tensor(853., device='cuda:0')\n(('West Harrow', 'Rayners Lane'), ('Rayners Lane', 'South Harrow')) tensor(270., device='cuda:0')\n(('West Kensington', 'Barons Court'), ('Barons Court', 'Hammersmith (Dis)')) tensor(21., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'Gloucester Road')) tensor(205., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'High Street Kensington')) tensor(40., device='cuda:0')\n(('West Kensington', \"Earl's Court\"), (\"Earl's Court\", 'West Brompton')) tensor(5., device='cuda:0')\n(('West Ruislip', 'South Ruislip'), ('South Ruislip', 'Northolt')) tensor(64., device='cuda:0')\n(('Westbourne Park', 'Ladbroke Grove'), ('Ladbroke Grove', 'Latimer Road')) tensor(405., device='cuda:0')\n(('Westbourne Park', 'Royal Oak'), ('Royal Oak', 'Paddington')) tensor(780., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Charing Cross')) tensor(5., device='cuda:0')\n(('Westminster', 'Embankment'), ('Embankment', 'Temple')) tensor(525., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Bond Street')) tensor(1478., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Hyde Park Corner')) tensor(1051., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Oxford Circus')) tensor(353., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Piccadilly Circus')) tensor(101., device='cuda:0')\n(('Westminster', 'Green Park'), ('Green Park', 'Victoria')) tensor(1205., device='cuda:0')\n(('Westminster', \"St. James's Park\"), (\"St. James's Park\", 'Victoria')) tensor(1204., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Kennington')) tensor(372., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Lambeth North')) tensor(319., device='cuda:0')\n(('Westminster', 'Waterloo'), ('Waterloo', 'Southwark')) tensor(3784., device='cuda:0')\n(('White City', 'East Acton'), ('East Acton', 'North Acton')) tensor(127., device='cuda:0')\n(('White City', \"Shepherd's Bush (Cen)\"), (\"Shepherd's Bush (Cen)\", 'Holland Park')) tensor(279., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Liverpool Street')) tensor(3522., device='cuda:0')\n(('Whitechapel', 'Aldgate East'), ('Aldgate East', 'Tower Hill')) tensor(2077., device='cuda:0')\n(('Whitechapel', 'Stepney Green'), ('Stepney Green', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Leyton')) tensor(2499., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'Mile End')) tensor(7., device='cuda:0')\n(('Whitechapel', 'Stratford'), ('Stratford', 'West Ham')) tensor(2098., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Baker Street')) tensor(512., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'HarrowOnTheHill')) tensor(27., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Swiss Cottage')) tensor(8., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Green', 'Finchley Road'), ('Finchley Road', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Kilburn'), ('Kilburn', 'West Hampstead')) tensor(3., device='cuda:0')\n(('Willesden Green', 'Neasden'), ('Neasden', 'Wembley Park')) tensor(12., device='cuda:0')\n(('Willesden Junction', 'Harlesden'), ('Harlesden', 'Stonebridge Park')) tensor(405., device='cuda:0')\n(('Willesden Junction', 'Kensal Green'), ('Kensal Green', \"Queen's Park\")) tensor(678., device='cuda:0')\n(('Wimbledon', 'Wimbledon Park'), ('Wimbledon Park', 'Southfields')) tensor(299., device='cuda:0')\n(('Wimbledon Park', 'Southfields'), ('Southfields', 'East Putney')) tensor(456., device='cuda:0')\n(('Wood Green', 'Bounds Green'), ('Bounds Green', 'Arnos Grove')) tensor(479., device='cuda:0')\n(('Wood Green', 'Turnpike Lane'), ('Turnpike Lane', 'Manor House')) tensor(831., device='cuda:0')\n(('Wood Lane', 'Latimer Road'), ('Latimer Road', 'Ladbroke Grove')) tensor(346., device='cuda:0')\n(('Wood Lane', \"Shepherd's Bush Market\"), (\"Shepherd's Bush Market\", 'Goldhawk Road')) tensor(133., device='cuda:0')\n(('Woodford', 'Buckhurst Hill'), ('Buckhurst Hill', 'Loughton')) tensor(683., device='cuda:0')\n(('Woodford', 'Roding Valley'), ('Roding Valley', 'Chigwell')) tensor(294., device='cuda:0')\n(('Woodford', 'South Woodford'), ('South Woodford', 'Snaresbrook')) tensor(1601., device='cuda:0')\n(('Woodside Park', 'Totteridge &amp; Whetstone'), ('Totteridge &amp; Whetstone', 'High Barnet')) tensor(132., device='cuda:0')\n(('Woodside Park', 'West Finchley'), ('West Finchley', 'Finchley Central')) tensor(384., device='cuda:0')\n</pre> In\u00a0[5]: Copied! <pre>g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')]\n</pre> g2['edge_weight', ('Southwark', 'Waterloo'), ('Waterloo', 'Embankment')] Out[5]: <pre>tensor(279., device='cuda:0')</pre> In\u00a0[6]: Copied! <pre>paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2)\ng2 = pp2.HigherOrderNetwork(paths, k=2)\nprint(g2)\n</pre> paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=2) g2 = pp2.HigherOrderNetwork(paths, k=2) print(g2) <pre>2024-03-27 11:21:58 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:58 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:58 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n</pre> In\u00a0[7]: Copied! <pre>ks = range(1,10)\ntimes = []\nfor k in ks:\n    start = time.time() \n    paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)\n    g2 = pp2.HigherOrderNetwork(paths, k=k)\n    print(g2)\n    elapsed_pp = time.time()-start\n    times.append(elapsed_pp)\nplt.plot(ks, times)\n</pre> ks = range(1,10) times = [] for k in ks:     start = time.time()      paths = pp2.Paths.read_file(\"../data/tube_paths_train.ngram\", max_subpath_length=k)     g2 = pp2.HigherOrderNetwork(paths, k=k)     print(g2)     elapsed_pp = time.time()-start     times.append(elapsed_pp) plt.plot(ks, times) <pre>2024-03-27 11:21:59 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:21:59 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:21:59 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished.\nHigher-order network of order k = 1\n\nNodes:\t\t\t\t268\nLinks:\t\t\t\t646\nTotal weight (subpaths/longest paths):\t14404381.0/99956.0\n\n2024-03-27 11:22:00 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:00 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:00 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished.\nHigher-order network of order k = 2\n\nNodes:\t\t\t\t646\nLinks:\t\t\t\t1139\nTotal weight (subpaths/longest paths):\t12182604.0/173868.0\n\n2024-03-27 11:22:01 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:01 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:01 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished.\nHigher-order network of order k = 3\n\nNodes:\t\t\t\t1889\nLinks:\t\t\t\t1869\nTotal weight (subpaths/longest paths):\t10078001.0/230562.0\n\n2024-03-27 11:22:02 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:02 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:02 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:03 [Severity.INFO]\tfinished.\nHigher-order network of order k = 4\n\nNodes:\t\t\t\t5770\nLinks:\t\t\t\t2730\nTotal weight (subpaths/longest paths):\t8198110.0/236412.0\n\n2024-03-27 11:22:04 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:04 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:04 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:05 [Severity.INFO]\tfinished.\nHigher-order network of order k = 5\n\nNodes:\t\t\t\t19424\nLinks:\t\t\t\t3683\nTotal weight (subpaths/longest paths):\t6547275.0/243768.0\n\n2024-03-27 11:22:06 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:06 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:06 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:08 [Severity.INFO]\tfinished.\nHigher-order network of order k = 6\n\nNodes:\t\t\t\t66882\nLinks:\t\t\t\t4748\nTotal weight (subpaths/longest paths):\t5174028.0/209948.0\n\n2024-03-27 11:22:09 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:09 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:09 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:11 [Severity.INFO]\tfinished.\nHigher-order network of order k = 7\n\nNodes:\t\t\t\t242779\nLinks:\t\t\t\t5745\nTotal weight (subpaths/longest paths):\t4044268.0/176409.0\n\n2024-03-27 11:22:14 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:15 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:15 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:17 [Severity.INFO]\tfinished.\nHigher-order network of order k = 8\n\nNodes:\t\t\t\t888479\nLinks:\t\t\t\t6463\nTotal weight (subpaths/longest paths):\t3116104.0/151222.0\n\n2024-03-27 11:22:29 [Severity.INFO]\tReading ngram data ... \n2024-03-27 11:22:29 [Severity.INFO]\tfinished. Read 61748 paths with maximum length 35\n2024-03-27 11:22:29 [Severity.INFO]\tCalculating sub path statistics ... \n2024-03-27 11:22:31 [Severity.INFO]\tfinished.\nHigher-order network of order k = 9\n\nNodes:\t\t\t\t3348421\nLinks:\t\t\t\t7053\nTotal weight (subpaths/longest paths):\t2349934.0/140450.0\n\n</pre> Out[7]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f081d30d9c0&gt;]</pre> In\u00a0[\u00a0]: Copied! <pre>ks = range(1,10)\ntimes_new_gpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram').to('cuda')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_gpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_gpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram').to('cuda') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_gpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[18]: Copied! <pre>ks = range(1,10)\ntimes_new_cpu = []\np = pp.DAGData.from_ngram('../data/tube_paths_train.ngram')\nfor k in ks:\n    start = time.time()\n    m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)\n    print(m.layers[k])\n    print('---')\n    elapsed_new = time.time()-start\n    times_new_cpu.append(elapsed_new)\n</pre> ks = range(1,10) times_new_cpu = [] p = pp.DAGData.from_ngram('../data/tube_paths_train.ngram') for k in ks:     start = time.time()     m = pp.MultiOrderModel.from_DAGs(p, max_order=k, cached=False)     print(m.layers[k])     print('---')     elapsed_new = time.time()-start     times_new_cpu.append(elapsed_new) <pre>Directed graph with 268 nodes and 646 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([268, 1])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 646 nodes and 1139 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([646, 2])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1139 nodes and 1869 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1139, 3])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 1869 nodes and 2730 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([1869, 4])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 2730 nodes and 3683 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2730, 5])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 3683 nodes and 4748 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([3683, 6])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 4748 nodes and 5745 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([4748, 7])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 5745 nodes and 6463 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([5745, 8])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\nDirected graph with 6463 nodes and 7053 edges\n\nNode attributes\n\tnode_sequence\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([6463, 9])\n\nEdge attributes\n\tedge_weight\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([7053])\n\nGraph attributes\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\n---\n</pre> In\u00a0[19]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.grid()\nplt.ylabel('time [s]')\nplt.legend()\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.grid() plt.ylabel('time [s]') plt.legend() Out[19]: <pre>&lt;matplotlib.legend.Legend at 0x7f082668d9f0&gt;</pre> In\u00a0[20]: Copied! <pre>plt.plot(ks, times, label='pathpy2')\nplt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)')\nplt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)')\nplt.xlabel('order')\nplt.ylabel('time [s]')\nplt.legend()\nplt.grid()\nplt.yscale('log')\n</pre> plt.plot(ks, times, label='pathpy2') plt.plot(ks, times_new_gpu, label='pathpyG prototype (GPU)') plt.plot(ks, times_new_cpu, label='pathpyG prototype (CPU)') plt.xlabel('order') plt.ylabel('time [s]') plt.legend() plt.grid() plt.yscale('log') In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorial/archive/_higher_order_scalability/#pathpy-20","title":"Pathpy 2.0\u00b6","text":""},{"location":"tutorial/archive/_higher_order_scalability/#pathpyg-gpu","title":"pathpyG (GPU)\u00b6","text":""},{"location":"tutorial/archive/_higher_order_scalability/#pathpyg-cpu","title":"pathpyG (CPU)\u00b6","text":""},{"location":"tutorial/archive/_scalability_analysis/","title":"scalability analysis","text":"In\u00a0[1]: Copied! <pre>import pathpyG as pp\nimport torch\nimport copy\nimport time\nimport numpy as np\nfrom collections import defaultdict\nimport json\n\nimport pprint \nprinter = pprint.PrettyPrinter(indent=4)\npp.config['device'] = 'cpu'\nimport seaborn as sns\n</pre> import pathpyG as pp import torch import copy import time import numpy as np from collections import defaultdict import json  import pprint  printer = pprint.PrettyPrinter(indent=4) pp.config['device'] = 'cpu' import seaborn as sns In\u00a0[2]: Copied! <pre>def test_mo_scalability(g, exp):\n    res = copy.deepcopy(exp)\n    pp.config['device'] = exp['device']\n    g.data.to(exp['device'])\n    res['temp_net_nodes'] = g.n\n    res['temp_net_edges'] = g.m\n    res['temp_net_events'] = g.data.edge_index.size(1)\n\n    start_time = time.time()\n    eg = pp.algorithms.lift_order_temporal(g, delta=exp['delta'])\n    eg.to(exp['device'])\n    res['lift_event_graph_time'] = time.time() - start_time\n    res['event_graph_edges'] = eg.size(1)\n\n    start_time = time.time()\n    m = pp.MultiOrderModel.from_temporal_graph(g, delta=exp['delta'], max_order=exp['max_order'])\n    res['mo_time'] = time.time() - start_time\n    res['max_order_nodes'] = m.layers[exp['max_order']].n\n    res['max_order_edges'] = m.layers[exp['max_order']].m\n    return res\n</pre> def test_mo_scalability(g, exp):     res = copy.deepcopy(exp)     pp.config['device'] = exp['device']     g.data.to(exp['device'])     res['temp_net_nodes'] = g.n     res['temp_net_edges'] = g.m     res['temp_net_events'] = g.data.edge_index.size(1)      start_time = time.time()     eg = pp.algorithms.lift_order_temporal(g, delta=exp['delta'])     eg.to(exp['device'])     res['lift_event_graph_time'] = time.time() - start_time     res['event_graph_edges'] = eg.size(1)      start_time = time.time()     m = pp.MultiOrderModel.from_temporal_graph(g, delta=exp['delta'], max_order=exp['max_order'])     res['mo_time'] = time.time() - start_time     res['max_order_nodes'] = m.layers[exp['max_order']].n     res['max_order_edges'] = m.layers[exp['max_order']].m     return res  In\u00a0[3]: Copied! <pre>results = defaultdict(lambda: defaultdict())\nexp = {}\n\ng = pp.io.read_netzschleuder_graph('copenhagen', 'sms', time_attr='timestamp')\nprint(g)\nfor d in ['cuda', 'cpu']:\n    exp['device'] = d\n    for delta in np.linspace(30, 3600, 5):\n        exp['delta'] = delta\n        for k in range(2, 6):\n            exp['max_order'] = k\n            try:\n                res = test_mo_scalability(g, exp)\n                printer.pprint(res)\n                results[delta][k] = res\n            except Exception as e:\n                print(e)\n\nwith open('results_copenhagen.json', 'w') as f:\n    json.dump(results, f)\n</pre> results = defaultdict(lambda: defaultdict()) exp = {}  g = pp.io.read_netzschleuder_graph('copenhagen', 'sms', time_attr='timestamp') print(g) for d in ['cuda', 'cpu']:     exp['device'] = d     for delta in np.linspace(30, 3600, 5):         exp['delta'] = delta         for k in range(2, 6):             exp['max_order'] = k             try:                 res = test_mo_scalability(g, exp)                 printer.pprint(res)                 results[delta][k] = res             except Exception as e:                 print(e)  with open('results_copenhagen.json', 'w') as f:     json.dump(results, f) <pre>Mapping node attributes based on node indices in column `index`\nTemporal Graph with 568 nodes, 1303 unique edges and 24333 events in [18.0, 2418982.0]\n\nNode attributes\n\tnode_female\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([568])\n\tnode_id\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([568])\n\tnode__pos\t\t&lt;class 'numpy.ndarray'&gt;\n\nEdge attributes\n\ttime\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([24333])\n\tedge_index\t\t&lt;class 'torch_geometric.edge_index.EdgeIndex'&gt;\n\nGraph attributes\n\tanalyses_edge_properties\t\t&lt;class 'list'&gt;\n\tanalyses_num_edges\t\t&lt;class 'int'&gt;\n\tanalyses_degree_assortativity\t\t&lt;class 'float'&gt;\n\tanalyses_mixing_time\t\t&lt;class 'float'&gt;\n\tanalyses_diameter\t\t&lt;class 'int'&gt;\n\tanalyses_largest_component_fraction\t\t&lt;class 'float'&gt;\n\tanalyses_is_directed\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_2\t\t&lt;class 'float'&gt;\n\tanalyses_num_vertices\t\t&lt;class 'int'&gt;\n\tanalyses_vertex_properties\t\t&lt;class 'list'&gt;\n\tanalyses_edge_reciprocity\t\t&lt;class 'float'&gt;\n\tanalyses_is_bipartite\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_1\t\t&lt;class 'float'&gt;\n\tanalyses_transition_gap\t\t&lt;class 'float'&gt;\n\tanalyses_average_degree\t\t&lt;class 'float'&gt;\n\tanalyses_hashimoto_radius\t\t&lt;class 'float'&gt;\n\tnum_nodes\t\t&lt;class 'int'&gt;\n\tanalyses_degree_std_dev\t\t&lt;class 'float'&gt;\n\tanalyses_global_clustering\t\t&lt;class 'float'&gt;\n\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2167.73it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2088.86it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.122706413269043,\n    'max_order': 2,\n    'max_order_edges': 557,\n    'max_order_nodes': 1303,\n    'mo_time': 12.025795459747314,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2038.99it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2069.14it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.795116186141968,\n    'max_order': 3,\n    'max_order_edges': 229,\n    'max_order_nodes': 557,\n    'mo_time': 11.878443956375122,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2042.28it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2011.84it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.777009963989258,\n    'max_order': 4,\n    'max_order_edges': 110,\n    'max_order_nodes': 229,\n    'mo_time': 12.220279693603516,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2074.25it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2061.54it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cuda',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 11.595112562179565,\n    'max_order': 5,\n    'max_order_edges': 61,\n    'max_order_nodes': 110,\n    'mo_time': 12.093271017074585,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1082.67it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1130.39it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 22.232107639312744,\n    'max_order': 2,\n    'max_order_edges': 1236,\n    'max_order_nodes': 1303,\n    'mo_time': 21.630196571350098,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1095.26it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1120.23it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 21.974792957305908,\n    'max_order': 3,\n    'max_order_edges': 1122,\n    'max_order_nodes': 1236,\n    'mo_time': 22.22197437286377,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1107.00it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1109.25it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 21.74143648147583,\n    'max_order': 4,\n    'max_order_edges': 1008,\n    'max_order_nodes': 1122,\n    'mo_time': 22.65464735031128,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1091.36it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1142.30it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cuda',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 22.076518774032593,\n    'max_order': 5,\n    'max_order_edges': 878,\n    'max_order_nodes': 1008,\n    'mo_time': 22.64402413368225,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1059.94it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:26&lt;00:00, 896.10it/s] \n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 22.712382793426514,\n    'max_order': 2,\n    'max_order_edges': 1344,\n    'max_order_nodes': 1303,\n    'mo_time': 27.22113013267517,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:28&lt;00:00, 844.85it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:27&lt;00:00, 889.93it/s] \n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 28.49084734916687,\n    'max_order': 3,\n    'max_order_edges': 1306,\n    'max_order_nodes': 1344,\n    'mo_time': 27.783222198486328,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:23&lt;00:00, 1003.20it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:24&lt;00:00, 966.13it/s] \n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 24.00903582572937,\n    'max_order': 4,\n    'max_order_edges': 1279,\n    'max_order_nodes': 1306,\n    'mo_time': 26.02214217185974,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:23&lt;00:00, 1032.85it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1111.71it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cuda',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 23.30103063583374,\n    'max_order': 5,\n    'max_order_edges': 1232,\n    'max_order_nodes': 1279,\n    'mo_time': 32.56914210319519,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1102.31it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:18&lt;00:00, 1283.34it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 21.834106922149658,\n    'max_order': 2,\n    'max_order_edges': 1408,\n    'max_order_nodes': 1303,\n    'mo_time': 19.122129917144775,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:17&lt;00:00, 1371.76it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:23&lt;00:00, 1042.82it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 17.55621361732483,\n    'max_order': 3,\n    'max_order_edges': 1420,\n    'max_order_nodes': 1408,\n    'mo_time': 23.811742305755615,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1078.05it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:22&lt;00:00, 1062.19it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 22.32985234260559,\n    'max_order': 4,\n    'max_order_edges': 1448,\n    'max_order_nodes': 1420,\n    'mo_time': 23.88112759590149,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:25&lt;00:00, 950.98it/s] \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:24&lt;00:00, 976.45it/s] \n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cuda',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 25.302610397338867,\n    'max_order': 5,\n    'max_order_edges': 1452,\n    'max_order_nodes': 1448,\n    'mo_time': 58.79792809486389,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:21&lt;00:00, 1140.34it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1482.82it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 21.1067316532135,\n    'max_order': 2,\n    'max_order_edges': 1453,\n    'max_order_nodes': 1303,\n    'mo_time': 16.5167076587677,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:15&lt;00:00, 1506.81it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:18&lt;00:00, 1323.43it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 15.98039698600769,\n    'max_order': 3,\n    'max_order_edges': 1506,\n    'max_order_nodes': 1453,\n    'mo_time': 18.9002103805542,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1448.36it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1452.72it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 16.622321605682373,\n    'max_order': 4,\n    'max_order_edges': 1594,\n    'max_order_nodes': 1506,\n    'mo_time': 17.679415464401245,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:16&lt;00:00, 1473.71it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:15&lt;00:00, 1547.80it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cuda',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 16.335521936416626,\n    'max_order': 5,\n    'max_order_edges': 1674,\n    'max_order_nodes': 1594,\n    'mo_time': 126.71205115318298,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2870.65it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2878.70it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.384625434875488,\n    'max_order': 2,\n    'max_order_edges': 557,\n    'max_order_nodes': 1303,\n    'mo_time': 8.44395112991333,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2934.42it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2889.33it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.201921463012695,\n    'max_order': 3,\n    'max_order_edges': 229,\n    'max_order_nodes': 557,\n    'mo_time': 8.436858654022217,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2906.52it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2908.75it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.282766819000244,\n    'max_order': 4,\n    'max_order_edges': 110,\n    'max_order_nodes': 229,\n    'mo_time': 8.383979320526123,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2896.13it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:08&lt;00:00, 2940.09it/s]\n</pre> <pre>{   'delta': 30.0,\n    'device': 'cpu',\n    'event_graph_edges': 4394,\n    'lift_event_graph_time': 8.31244707107544,\n    'max_order': 5,\n    'max_order_edges': 61,\n    'max_order_nodes': 110,\n    'mo_time': 8.297135353088379,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:09&lt;00:00, 2424.21it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2379.18it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 9.95227837562561,\n    'max_order': 2,\n    'max_order_edges': 1236,\n    'max_order_nodes': 1303,\n    'mo_time': 10.21712613105774,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2373.41it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2403.32it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 10.163817644119263,\n    'max_order': 3,\n    'max_order_edges': 1122,\n    'max_order_nodes': 1236,\n    'mo_time': 10.227073669433594,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:09&lt;00:00, 2415.48it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2388.56it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 9.988727569580078,\n    'max_order': 4,\n    'max_order_edges': 1008,\n    'max_order_nodes': 1122,\n    'mo_time': 10.93671178817749,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:09&lt;00:00, 2404.24it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2394.89it/s]\n</pre> <pre>{   'delta': 922.5,\n    'device': 'cpu',\n    'event_graph_edges': 54935,\n    'lift_event_graph_time': 10.032788515090942,\n    'max_order': 5,\n    'max_order_edges': 878,\n    'max_order_nodes': 1008,\n    'mo_time': 16.719266414642334,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2240.81it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2338.14it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.765197515487671,\n    'max_order': 2,\n    'max_order_edges': 1344,\n    'max_order_nodes': 1303,\n    'mo_time': 10.433187007904053,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2329.00it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2352.14it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.362721920013428,\n    'max_order': 3,\n    'max_order_edges': 1306,\n    'max_order_nodes': 1344,\n    'mo_time': 10.513421058654785,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2353.53it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2286.25it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.253392696380615,\n    'max_order': 4,\n    'max_order_edges': 1279,\n    'max_order_nodes': 1306,\n    'mo_time': 12.241335153579712,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2351.43it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2389.42it/s]\n</pre> <pre>{   'delta': 1815.0,\n    'device': 'cpu',\n    'event_graph_edges': 77345,\n    'lift_event_graph_time': 10.25893259048462,\n    'max_order': 5,\n    'max_order_edges': 1232,\n    'max_order_nodes': 1279,\n    'mo_time': 24.42807126045227,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2166.44it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2259.16it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 11.133711338043213,\n    'max_order': 2,\n    'max_order_edges': 1408,\n    'max_order_nodes': 1303,\n    'mo_time': 10.760009765625,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2304.09it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2265.84it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 10.470611095428467,\n    'max_order': 3,\n    'max_order_edges': 1420,\n    'max_order_nodes': 1408,\n    'mo_time': 10.977295637130737,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2313.20it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2345.28it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 10.43064832687378,\n    'max_order': 4,\n    'max_order_edges': 1448,\n    'max_order_nodes': 1420,\n    'mo_time': 12.300642490386963,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2258.72it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2333.72it/s]\n</pre> <pre>{   'delta': 2707.5,\n    'device': 'cpu',\n    'event_graph_edges': 92566,\n    'lift_event_graph_time': 10.682463884353638,\n    'max_order': 5,\n    'max_order_edges': 1452,\n    'max_order_nodes': 1448,\n    'mo_time': 36.225979804992676,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:12&lt;00:00, 1882.08it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:11&lt;00:00, 2125.78it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 12.819502115249634,\n    'max_order': 2,\n    'max_order_edges': 1453,\n    'max_order_nodes': 1303,\n    'mo_time': 11.431120872497559,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2244.69it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2262.04it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 10.74588942527771,\n    'max_order': 3,\n    'max_order_edges': 1506,\n    'max_order_nodes': 1453,\n    'mo_time': 10.993196725845337,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2252.99it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2266.47it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 10.709041357040405,\n    'max_order': 4,\n    'max_order_edges': 1594,\n    'max_order_nodes': 1506,\n    'mo_time': 13.24429202079773,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2223.72it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 24039/24039 [00:10&lt;00:00, 2248.93it/s]\n</pre> <pre>{   'delta': 3600.0,\n    'device': 'cpu',\n    'event_graph_edges': 105280,\n    'lift_event_graph_time': 10.85075306892395,\n    'max_order': 5,\n    'max_order_edges': 1674,\n    'max_order_nodes': 1594,\n    'mo_time': 63.68161463737488,\n    'temp_net_edges': 24333,\n    'temp_net_events': 24333,\n    'temp_net_nodes': 568}\n</pre> In\u00a0[4]: Copied! <pre>results_rm = defaultdict(lambda: defaultdict())\nexp = {}\n\ng = pp.io.read_netzschleuder_graph('reality_mining', time_attr='time')\nprint(g)\nfor d in ['cuda', 'cpu']:\n    exp['device'] = d\n    for delta in np.linspace(300, 3600, 5):\n        exp['delta'] = delta\n        for k in range(2, 6):\n            exp['max_order'] = k\n            try:\n                res = test_mo_scalability(g, exp)\n                printer.pprint(res)\n                results_rm[delta][k] = res\n            except Exception as e:\n                print(e)\n\n            with open('results_rm_realitymining.json', 'w') as f:\n                json.dump(results_rm, f)\n</pre> results_rm = defaultdict(lambda: defaultdict()) exp = {}  g = pp.io.read_netzschleuder_graph('reality_mining', time_attr='time') print(g) for d in ['cuda', 'cpu']:     exp['device'] = d     for delta in np.linspace(300, 3600, 5):         exp['delta'] = delta         for k in range(2, 6):             exp['max_order'] = k             try:                 res = test_mo_scalability(g, exp)                 printer.pprint(res)                 results_rm[delta][k] = res             except Exception as e:                 print(e)              with open('results_rm_realitymining.json', 'w') as f:                 json.dump(results_rm, f) <pre>Mapping node attributes based on node indices in column `index`\nTemporal Graph with 96 nodes, 5078 unique edges and 2172808 events in [1095183104.0, 1115253760.0]\n\nNode attributes\n\tnode__pos\t\t&lt;class 'numpy.ndarray'&gt;\n\nEdge attributes\n\ttime\t\t&lt;class 'torch.Tensor'&gt; -&gt; torch.Size([2172808])\n\tedge_index\t\t&lt;class 'torch_geometric.edge_index.EdgeIndex'&gt;\n\nGraph attributes\n\tanalyses_edge_properties\t\t&lt;class 'list'&gt;\n\tanalyses_num_edges\t\t&lt;class 'int'&gt;\n\tanalyses_degree_assortativity\t\t&lt;class 'float'&gt;\n\tanalyses_mixing_time\t\t&lt;class 'float'&gt;\n\tanalyses_diameter\t\t&lt;class 'int'&gt;\n\tanalyses_largest_component_fraction\t\t&lt;class 'float'&gt;\n\tanalyses_is_directed\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_2\t\t&lt;class 'float'&gt;\n\tanalyses_num_vertices\t\t&lt;class 'int'&gt;\n\tanalyses_vertex_properties\t\t&lt;class 'list'&gt;\n\tanalyses_edge_reciprocity\t\t&lt;class 'float'&gt;\n\tanalyses_is_bipartite\t\t&lt;class 'bool'&gt;\n\tanalyses_knn_proj_1\t\t&lt;class 'float'&gt;\n\tanalyses_transition_gap\t\t&lt;class 'float'&gt;\n\tanalyses_average_degree\t\t&lt;class 'float'&gt;\n\tanalyses_hashimoto_radius\t\t&lt;class 'float'&gt;\n\tanalyses_degree_std_dev\t\t&lt;class 'float'&gt;\n\tanalyses_global_clustering\t\t&lt;class 'float'&gt;\n\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:05&lt;00:00, 267.26it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:04&lt;00:00, 268.49it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:04&lt;00:00, 268.28it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [02:03&lt;00:00, 270.22it/s]\n</pre> <pre>torch.cat(): expected a non-empty list of Tensors\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:37&lt;00:00, 153.98it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:35&lt;00:00, 155.29it/s]\n</pre> <pre>{   'delta': 1125.0,\n    'device': 'cuda',\n    'event_graph_edges': 55088257,\n    'lift_event_graph_time': 217.30356216430664,\n    'max_order': 2,\n    'max_order_edges': 68938,\n    'max_order_nodes': 5078,\n    'mo_time': 243.20855259895325,\n    'temp_net_edges': 2172808,\n    'temp_net_events': 2172808,\n    'temp_net_nodes': 96}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:36&lt;00:00, 154.75it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [03:34&lt;00:00, 155.62it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 13.03 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 16.23 GiB is allocated by PyTorch, and 576.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:02&lt;00:00, 138.14it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:04&lt;00:00, 137.04it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 13.03 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 16.23 GiB is allocated by PyTorch, and 576.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:01&lt;00:00, 138.29it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:04&lt;00:00, 136.87it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 13.03 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 16.23 GiB is allocated by PyTorch, and 576.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:10&lt;00:00, 133.29it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:10&lt;00:00, 133.48it/s]\n</pre> <pre>{   'delta': 1950.0,\n    'device': 'cuda',\n    'event_graph_edges': 96946987,\n    'lift_event_graph_time': 251.03341007232666,\n    'max_order': 2,\n    'max_order_edges': 74773,\n    'max_order_nodes': 5078,\n    'mo_time': 281.3313329219818,\n    'temp_net_edges': 2172808,\n    'temp_net_events': 2172808,\n    'temp_net_nodes': 96}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:10&lt;00:00, 133.66it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [04:11&lt;00:00, 133.02it/s]\n</pre> <pre>CUDA out of memory. Tried to allocate 41.73 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.80 GiB is allocated by PyTorch, and 11.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [40:51&lt;00:00, 13.65it/s]  \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [49:33&lt;00:00, 11.25it/s]  \n</pre> <pre>CUDA out of memory. Tried to allocate 41.73 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.80 GiB is allocated by PyTorch, and 11.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [40:54&lt;00:00, 13.63it/s]  \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [49:35&lt;00:00, 11.24it/s]  \n</pre> <pre>CUDA out of memory. Tried to allocate 41.73 GiB. GPU 0 has a total capacty of 4.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.80 GiB is allocated by PyTorch, and 11.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [51:22&lt;00:00, 10.85it/s]  \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [53:05&lt;00:00, 10.50it/s]  \n</pre> <pre>{   'delta': 2775.0,\n    'device': 'cuda',\n    'event_graph_edges': 124683153,\n    'lift_event_graph_time': 3082.5759828090668,\n    'max_order': 2,\n    'max_order_edges': 77875,\n    'max_order_nodes': 5078,\n    'mo_time': 3224.959701538086,\n    'temp_net_edges': 2172808,\n    'temp_net_events': 2172808,\n    'temp_net_nodes': 96}\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33452/33452 [50:31&lt;00:00, 11.03it/s]  \n 44%|\u2588\u2588\u2588\u2588\u258e     | 14586/33452 [22:45&lt;29:25, 10.68it/s]  \n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[4], line 13\n     11 exp['max_order'] = k\n     12 try:\n---&gt; 13     res = test_mo_scalability(g, exp)\n     14     printer.pprint(res)\n     15     results_rm[delta][k] = res\n\nCell In[2], line 16, in test_mo_scalability(g, exp)\n     13 res['event_graph_edges'] = eg.size(1)\n     15 start_time = time.time()\n---&gt; 16 m = pp.MultiOrderModel.from_temporal_graph(g, delta=exp['delta'], max_order=exp['max_order'])\n     17 res['mo_time'] = time.time() - start_time\n     18 res['max_order_nodes'] = m.layers[exp['max_order']].N\n\nFile /workspaces/pathpyG/src/pathpyG/core/multi_order_model.py:108, in MultiOrderModel.from_temporal_graph(g, delta, max_order, weight, cached)\n    106 if max_order &gt; 1:\n    107     node_sequence = torch.cat([node_sequence[edge_index[0]], node_sequence[edge_index[1]][:, -1:]], dim=1)\n--&gt; 108     edge_index = lift_order_temporal(g, delta)\n    109     edge_weight = aggregate_node_attributes(edge_index, edge_weight, \"src\")\n    111     # Aggregate\n\nFile /workspaces/pathpyG/src/pathpyG/algorithms/temporal.py:39, in lift_order_temporal(g, delta)\n     36 dst_node_mask = torch.isin(edge_index[0], edge_index[1, src_edge_idx])\n     37 dst_edge_idx = indices[dst_time_mask &amp; dst_node_mask]\n---&gt; 39 if dst_edge_idx.size(0) &gt; 0 and src_edge_idx.size(0) &gt; 0:\n     40 \n     41     # compute second-order edges between src and dst idx for all edges where dst in src_edges matches src in dst_edges\n     42     x = torch.cartesian_prod(src_edge_idx, dst_edge_idx).t()\n     43     # print(x.size(1))\n\nKeyboardInterrupt: </pre> In\u00a0[\u00a0]: Copied! <pre>order = [] \neg_time = []\nmo_time = []\ndelta = 3600.\n\nfor k in results[delta]:\n    order.append(k)\n    eg_time.append(results[delta][k]['lift_event_graph_time'])\n    mo_time.append(results[delta][k]['mo_time']-results[delta][k]['lift_event_graph_time'])\nsns.lineplot(x=order, y=eg_time, label='event graph')\nsns.lineplot(x=order, y=mo_time, label='order lifting')\n</pre> order = []  eg_time = [] mo_time = [] delta = 3600.  for k in results[delta]:     order.append(k)     eg_time.append(results[delta][k]['lift_event_graph_time'])     mo_time.append(results[delta][k]['mo_time']-results[delta][k]['lift_event_graph_time']) sns.lineplot(x=order, y=eg_time, label='event graph') sns.lineplot(x=order, y=mo_time, label='order lifting') Out[\u00a0]: <pre>&lt;Axes: &gt;</pre>"}]}