{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "from tqdm import trange\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric import EdgeIndex\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.experimental import disable_dynamic_shapes\n",
    "from torch_geometric.nn.aggr import Aggregation\n",
    "from torch_geometric.transforms import LineGraph\n",
    "from torch_geometric.utils import scatter, cumsum, coalesce, degree\n",
    "from torch_geometric.utils import to_torch_sparse_tensor, to_torch_csc_tensor, to_torch_csr_tensor, to_torch_coo_tensor\n",
    "\n",
    "\n",
    "import pathpyG as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor) -> torch.Tensor:\n",
    "    N = edge_index.max().item() + 1\n",
    "    if isinstance(edge_index, torch.Tensor):\n",
    "        edge_index = EdgeIndex(edge_index, sparse_size=(N, N))\n",
    "    edge_index = edge_index.sort_by(\"row\")[0]\n",
    "    # Compute A^2 to get all paths of length 2 with source and target nodes\n",
    "    # A_2 is a tensor of shape (2, num_p) where num_p is the number of paths that have unique source and target nodes\n",
    "    # A_2_counts is a tensor of shape (num_p,) that contains the number of paths that have the corresponding source and target node\n",
    "    A_2, A_2_counts = edge_index @ edge_index\n",
    "    # as many times as A_2_counts specifies\n",
    "    # For that we first use the torch.cumsum function to get index pointers where the next source/target node starts\n",
    "    # (Note that the cumsum from PyG appends a 0 at the beginning, so we need explicitly the torch.cumsum function)\n",
    "    ptrs = torch.cumsum(A_2_counts, dim=0)\n",
    "    # Then we use the bucketize function to get the repeated index pointers\n",
    "    # We use the `ptrs` to specify the boundaries for each bucket\n",
    "    # With a range of ints from 0 to the sum of all A_2_counts, we can then repeat each index as many times as specified in A_2_counts\n",
    "    idx_range = torch.arange(A_2_counts.sum(), device=edge_index.device)\n",
    "    expand_idx = torch.bucketize(idx_range, ptrs, right=True)\n",
    "    # We use this index to expand the source and target nodes\n",
    "    path_srcs = A_2[0][expand_idx]\n",
    "    path_dsts = A_2[1][expand_idx]\n",
    "\n",
    "    # Now only the center nodes are missing!\n",
    "    # The center nodes are all the nodes that have at least one incoming and one outgoing edge\n",
    "    # Thus we can compute the indegree and outdegree of each node \n",
    "    indegree = degree(edge_index[1], dtype=torch.long, num_nodes=N)\n",
    "    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=N)\n",
    "    # If the product of indegree and outdegree is not 0, the node is a center node\n",
    "    in_out = indegree * outdegree\n",
    "    center_nodes = in_out.nonzero().squeeze()\n",
    "    # Next, we filter out all none center nodes from the the destination nodes of all edges\n",
    "    # Note that the destinations keep the original order of the edge index\n",
    "    # We also have each destination node repeated as many times as it has incoming edges\n",
    "    filtered_dsts = edge_index[1][torch.isin(edge_index[1], center_nodes)]\n",
    "\n",
    "    # Since in the end we need a higher order edge for each combination of source and destination nodes for each center node,\n",
    "    # we also need to repeat each center node as many times as it has outgoing edges.\n",
    "    # Note that our edge index is sorted by the source nodes and we are repeating the center nodes for each existing outgoing edge\n",
    "    # so we can insert the repeated center nodes right before/after the existing destination nodes\n",
    "    # For this we repeat the bucketize function from above but use the outdegree as the boundaries\n",
    "    ptrs_center = torch.cumsum(outdegree[filtered_dsts], dim=0)\n",
    "    expand_idx_center = torch.bucketize(idx_range, ptrs_center, right=True)\n",
    "    path_centers = filtered_dsts[expand_idx_center]\n",
    "\n",
    "    # Finally, we can stack the source, center and destination nodes to get the higher order edge index\n",
    "    ho_srcs = torch.stack([path_srcs, path_centers], dim=1)\n",
    "    ho_dsts = torch.stack([path_centers, path_dsts], dim=1)\n",
    "    ho_edge_index = torch.stack([ho_srcs, ho_dsts], dim=0)\n",
    "    return ho_edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeBruijn Transformations using GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatAggregation(Aggregation):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    # Not sure how this aggregation works, only that it does\n",
    "    # Inspired by the LSTMAggregation implementation in PyG:\n",
    "    # https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/aggr/lstm.html\n",
    "    @disable_dynamic_shapes(required_args=['dim_size', 'max_num_elements'])\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        index: Optional[Tensor] = None,\n",
    "        ptr: Optional[Tensor] = None,\n",
    "        dim_size: Optional[int] = None,\n",
    "        dim: int = -2,\n",
    "        max_num_elements: Optional[int] = None,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        # Concetenate all messages with padding value -1\n",
    "        x, _ = self.to_dense_batch(x, index, ptr, dim_size, dim, max_num_elements=max_num_elements, fill_value=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeBruijnTransform(MessagePassing):\n",
    "    # freq_aggr is a string specifying how we should count each path in the network\n",
    "    # This can either be `propagation` where every path is counted once\n",
    "    # or `diffusion` where every path is counted depending on the number of outgoing edges\n",
    "    # of the source node.\n",
    "    def __init__(self, freq_aggr: str = \"propagation\"):\n",
    "        super().__init__(aggr=ConcatAggregation(), flow=\"target_to_source\")\n",
    "        self.freq_aggr = freq_aggr\n",
    "\n",
    "    def forward(self, node_idx, edge_index, edge_attr=None):\n",
    "        # Sort edge_index because otherwise propagate will not work in combination with the ConcatAggregation\n",
    "        edge_index = coalesce(edge_index, sort_by_row=True)\n",
    "        # Set the dimension along which the node feature tensor is expected\n",
    "        # This is the default value, but we need to set it explicitly here\n",
    "        # because we change it later\n",
    "        self.node_dim = -2\n",
    "        # Update the node idx by passing the messages and aggregating them\n",
    "        # In the message function, we concatenate the node idx of the source node\n",
    "        # with the node idx of the target node\n",
    "        # In the aggregation function, we concatenate all messages from the neighbors\n",
    "        # The resulting feature for every node is a tensor of shape (max_degree, 2)\n",
    "        # where max_degree is the maximum degree of the graph\n",
    "        # If a node has less neighbors than max_degree, the remaining entries are filled with -1\n",
    "        node_idx_set_higher_order = self.propagate(edge_index, node_idx=node_idx)\n",
    "        # Since our node features changed from shape (N, 1) to (N, max_degree, 2)\n",
    "        # we need to set the node_dim to -3\n",
    "        self.node_dim = -3\n",
    "        # We use the function that is used to update node features to create the higher order edges\n",
    "        edge_index_higher_order, edge_attr_higher_order = self.edge_updater(\n",
    "            edge_index, \n",
    "            node_idx=node_idx_set_higher_order,\n",
    "            edge_attr=edge_attr\n",
    "            )\n",
    "\n",
    "        if edge_attr_higher_order is not None:\n",
    "            return edge_index_higher_order, edge_attr_higher_order\n",
    "        return edge_index_higher_order\n",
    "\n",
    "    def message(self, node_idx_i, node_idx_j):\n",
    "        # Concatenate the node idx of the source node with the node idx of the target node\n",
    "        # The shape changes from (N, k) to (N, k+1) where k is the order of the nodes before\n",
    "        return torch.cat([node_idx_i, node_idx_j[:, -1:]], dim=-1)\n",
    "    \n",
    "    def edge_update(self, node_idx_i, node_idx_j, edge_attr=None) -> tuple[Tensor, Optional[Tensor]]:\n",
    "        # We take the higher order node idx sets that have been created for each node adjacent\n",
    "        # to the edge (node_idx_i, node_idx_j) and repeat each node idx across different dimensions\n",
    "        # so that we can compare them with each other\n",
    "        #\n",
    "        # Example:\n",
    "        #\n",
    "        #   node_idx_i = [[0, 3], [1, 3], [2, 3]]\n",
    "        #   node_idx_j = [[3, 4], [2, 4], [-1, -1]]\n",
    "        #\n",
    "        #   strided_node_idx_i = [[\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3], \n",
    "        #                           [2, 3]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3],\n",
    "        #                           [2, 3]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3],\n",
    "        #                           [2, 3]\n",
    "        #                         ]]\n",
    "        #   strided_node_idx_j = [[\n",
    "        #                           [3, 4],\n",
    "        #                           [3, 4],\n",
    "        #                           [3, 4]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [2, 4],\n",
    "        #                           [2, 4],\n",
    "        #                           [2, 4]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [-1, -1],\n",
    "        #                           [-1, -1],\n",
    "        #                           [-1, -1]\n",
    "        #                         ]]\n",
    "        strided_node_idx_i = node_idx_i.unsqueeze(1).expand(-1, node_idx_j.size(1), -1, -1)\n",
    "        strided_node_idx_j = node_idx_j.unsqueeze(2).expand(-1, -1, node_idx_i.size(1), -1)\n",
    "        # Only create an higher order edge if the target node idx of the first edge is equal to\n",
    "        # the source node idx of the second edge\n",
    "        edge_mask = (strided_node_idx_i[:, :, :, 1:] == strided_node_idx_j[:, :, :, :-1]).all(dim=-1)\n",
    "        # Also, we need to remove the -1 padding values\n",
    "        padd_mask = (\n",
    "            (strided_node_idx_i[:, :, :] != -1).all(dim=-1) &\n",
    "            (strided_node_idx_j[:, :, :] != -1).all(dim=-1)\n",
    "        )\n",
    "        # For the above, the following mask is:\n",
    "        #\n",
    "        #   mask = [[True, True, True],\n",
    "        #           [False, False, False],\n",
    "        #           [False, False, False]]\n",
    "        mask = (edge_mask & padd_mask)\n",
    "        # Concetenate the remaining higher order edges to create a new edge index\n",
    "        higher_order_edges = torch.cat([strided_node_idx_i[mask].unsqueeze(0), strided_node_idx_j[mask].unsqueeze(0)], dim=0)\n",
    "        \n",
    "        if edge_attr is not None:\n",
    "            # If edge attributes are given, we need to fit the shape to apply the same mask\n",
    "            strided_edge_attr = edge_attr.unsqueeze(1).unsqueeze(1).expand(-1, node_idx_j.size(1), node_idx_i.size(1))\n",
    "            # Apply the mask and use some way to combine the edge attributes of source and target node\n",
    "            # For now, we just take the edge attribute of the source node\n",
    "            if self.freq_aggr == \"propagation\":\n",
    "                higher_order_edge_attr = strided_edge_attr[mask]\n",
    "            elif self.freq_aggr == \"diffusion\":\n",
    "                higher_order_edge_attr = strided_edge_attr[mask] / mask.sum(dim=(1,2), keepdim=True).expand(-1, node_idx_j.size(1), node_idx_i.size(1))[mask]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown frequency aggregation method {self.freq_aggr}\")\n",
    "            return higher_order_edges, higher_order_edge_attr\n",
    "        return higher_order_edges, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [6, 5],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 5, 6, 5, 7]])\n",
    "node_idx = torch.arange(edge_index.max() + 1).reshape(-1, 1)\n",
    "edge_index_2_fast = DeBruijnTransform()(node_idx, edge_index)\n",
    "print(edge_index_2_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA_gather)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m edge_index_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDAGData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlift_order_dag\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(edge_index_2)\n",
      "File \u001b[0;32m/workspaces/pathpyG/src/pathpyG/core/DAGData.py:184\u001b[0m, in \u001b[0;36mDAGData.lift_order_dag\u001b[0;34m(edge_index)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m srcs:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dsts:\n\u001b[0;32m--> 184\u001b[0m             src\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mcat((\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, v)))\n\u001b[1;32m    185\u001b[0m             dst\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mcat((v, torch\u001b[38;5;241m.\u001b[39mgather(d, \u001b[38;5;241m0\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor([d\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])))))\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(src) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA_gather)"
     ]
    }
   ],
   "source": [
    "edge_index_2 = pp.DAGData.lift_order_dag(edge_index.unsqueeze(-1))\n",
    "print(edge_index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [6, 5],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_new = lift_order_edge_index(EdgeIndex(edge_index))\n",
    "print(edge_index_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print((edge_index_2_fast == edge_index_new).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Edge Weights\n",
    "\n",
    "Depending on how you count each walk, you will get different statistics. We can choose the aggregation via `freq_aggr` to be either \"propagation\", i.e. each walk counts with its weight, or \"diffusion\" i.e. each walk is counted with the probability of a random walker starting at the first node to end up in the last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [6, 5],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 5, 6, 5, 7]])\n",
    "node_idx = torch.arange(edge_index.max() + 1).reshape(-1, 1)\n",
    "edge_attr = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.float32)\n",
    "edge_index_2_fast, edge_attr_2 = DeBruijnTransform(freq_aggr=\"diffusion\")(node_idx, edge_index, edge_attr)\n",
    "print(edge_index_2_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3333, 0.3333, 0.3333, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(edge_attr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd order\n",
    "Currently, the transformation works only with a standard edge index. The good thing is, you can still pass in the higher_order node_idx and then the output is directly a third order edge index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the edge index since the DeBruijnTransform only works for the normal edge index\n",
    "edges_2 = edge_index_2_fast.reshape(-1, 2)\n",
    "uniques, inverse_idx = edges_2.unique(dim=0, return_inverse=True)\n",
    "transformed_edge_index_2_fast = inverse_idx.reshape(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 3],\n",
      "         [0, 1, 6],\n",
      "         [0, 3, 4],\n",
      "         [1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5],\n",
      "         [3, 4, 5],\n",
      "         [6, 5, 7],\n",
      "         [4, 5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_3_fast = DeBruijnTransform()(uniques, transformed_edge_index_2_fast)\n",
    "print(edge_index_3_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 3],\n",
      "         [0, 1, 6],\n",
      "         [0, 3, 4],\n",
      "         [1, 3, 4],\n",
      "         [3, 4, 5],\n",
      "         [1, 6, 5]],\n",
      "\n",
      "        [[1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5],\n",
      "         [3, 4, 5],\n",
      "         [4, 5, 7],\n",
      "         [6, 5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_3 = pp.DAGData.lift_order_dag(edge_index_2)\n",
    "print(edge_index_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponentionally Large DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 18.74it/s]\n"
     ]
    }
   ],
   "source": [
    "layers = 5\n",
    "branches = 15\n",
    "\n",
    "edges = []\n",
    "prev_layer_nodes = [0]\n",
    "j = 1\n",
    "for _ in trange(layers):\n",
    "    layer_nodes = []\n",
    "    for node in prev_layer_nodes:\n",
    "        for _ in range(branches):\n",
    "            layer_nodes.append(j)\n",
    "            edges.append((f\"{node}\", f\"{j}\"))\n",
    "            j+=1\n",
    "    prev_layer_nodes = layer_nodes\n",
    "\n",
    "dag = pp.Graph.from_edge_list(edges)\n",
    "dag_edge_index = dag.data.edge_index.unsqueeze(-1)\n",
    "\n",
    "node_idx = torch.arange(dag_edge_index.max().item() + 1).unsqueeze(-1)\n",
    "node_idx_gpu = node_idx.cuda()\n",
    "dag_edge_index_gpu = dag.data.edge_index.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 9s ± 3.52 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pp.DAGData.lift_order_dag(dag_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing based implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717 ms ± 14.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit DeBruijnTransform()(node_idx, dag.data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing based implementation (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.1 ms ± 2.89 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit DeBruijnTransform()(node_idx_gpu, dag_edge_index_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 ms ± 2.68 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(dag.data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.9 ms ± 12.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(dag_edge_index_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gpu = dag.data.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinegraph(data_gpu)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/magics/execution.py:1189\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1187\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[1;32m   1191\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/timeit.py:206\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    204\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[0;32m--> 206\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/magics/execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/transforms/line_graph.py:53\u001b[0m, in \u001b[0;36mLineGraph.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m count \u001b[38;5;241m=\u001b[39m scatter(torch\u001b[38;5;241m.\u001b[39mones_like(row), row, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     50\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mnum_nodes, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m ptr \u001b[38;5;241m=\u001b[39m cumsum(count)\n\u001b[0;32m---> 53\u001b[0m cols \u001b[38;5;241m=\u001b[39m [i[ptr[col[j]]:ptr[col[j] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(col\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))]\n\u001b[1;32m     54\u001b[0m rows \u001b[38;5;241m=\u001b[39m [row\u001b[38;5;241m.\u001b[39mnew_full((c\u001b[38;5;241m.\u001b[39mnumel(), ), j) \u001b[38;5;28;01mfor\u001b[39;00m j, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cols)]\n\u001b[1;32m     56\u001b[0m row, col \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(rows, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mcat(cols, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/transforms/line_graph.py:53\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m count \u001b[38;5;241m=\u001b[39m scatter(torch\u001b[38;5;241m.\u001b[39mones_like(row), row, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     50\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mnum_nodes, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m ptr \u001b[38;5;241m=\u001b[39m cumsum(count)\n\u001b[0;32m---> 53\u001b[0m cols \u001b[38;5;241m=\u001b[39m [i[ptr[col[j]]:ptr[col[j] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(col\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))]\n\u001b[1;32m     54\u001b[0m rows \u001b[38;5;241m=\u001b[39m [row\u001b[38;5;241m.\u001b[39mnew_full((c\u001b[38;5;241m.\u001b[39mnumel(), ), j) \u001b[38;5;28;01mfor\u001b[39;00m j, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cols)]\n\u001b[1;32m     56\u001b[0m row, col \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(rows, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mcat(cols, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%timeit linegraph(data_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.82 s ± 167 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "linegraph = LineGraph()\n",
    "%timeit linegraph(dag.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((dag_edge_index_order_2.sort(dim=1)[0] == dag_edge_index_order_2_fast.sort(dim=1)[0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/pathpyG/src/pathpyG/core/WalkDataNested.py:56: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  self.paths = nested_tensor(paths, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "n_walks = 10000\n",
    "walk_length = 1000\n",
    "\n",
    "walks = [list(range(walk_length)) for _ in range(n_walks)]\n",
    "orig_walk = pp.WalkData()\n",
    "for walk in walks:\n",
    "    orig_walk.add_walk_seq(walk)\n",
    "\n",
    "path_list = list(orig_walk.paths.values())\n",
    "path_freq_tensor = torch.tensor(list(orig_walk.path_freq.values()))\n",
    "mapping = pp.IndexMap()\n",
    "nested_walk = pp.WalkDataNested(path_list, path_freq=path_freq_tensor, mapping=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Walk Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.5 s ± 7.25 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit orig_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor Implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466 ms ± 20.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cpu\"\n",
    "%timeit nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 ms ± 24.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cuda\"\n",
    "cuda_path_list = [path.cuda() for path in path_list]\n",
    "cuda_path_freq = path_freq_tensor.cuda()\n",
    "cuda_nested_walk = pp.WalkDataNested(cuda_path_list, path_freq=cuda_path_freq, mapping=mapping)\n",
    "%timeit cuda_nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing Implementation (CPU + GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a list of Data objects where each Data object contains the edge index of a path (could also be a DAG in theory)\n",
    "data_list = [Data(edge_index=path.long(), num_nodes=walk_length) for path in path_list]\n",
    "# We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs\n",
    "# If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards\n",
    "# Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once\n",
    "walk_graph = next(iter(DataLoader(data_list, batch_size=n_walks)))\n",
    "edge_index = walk_graph.edge_index\n",
    "node_idx = torch.arange(edge_index.max() + 1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following measures the time to do the De Bruijn graph transformation for the edge index that contains all paths as disjunct subgraphs. Since the aggregations afterwards are omitted, the runtimes are not exactly comparable to the above. See the next section (With Weights and the Aggregation) for a full `edge_index_k_weighted` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 ms ± 76.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit DeBruijnTransform()(node_idx, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.2 ms ± 5.52 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "cuda_edge_index = edge_index.cuda()\n",
    "cuda_node_idx = node_idx.cuda()\n",
    "%timeit DeBruijnTransform()(cuda_node_idx, cuda_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24 s ± 26.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 ms ± 135 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(cuda_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Weights and the Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_index_k_weighted(path_list, path_freq, aggregation=\"propagation\", device=\"cuda\"):\n",
    "    data_list = [\n",
    "        Data(\n",
    "            edge_index=path.long(), \n",
    "            num_nodes=walk_length,\n",
    "            edge_attr=torch.ones(path.size(1), dtype=torch.float32) * path_freq[i],\n",
    "            node_idx=torch.arange(walk_length).unsqueeze(-1)\n",
    "        ) for i, path in enumerate(path_list)\n",
    "        ]\n",
    "    walk_graph = next(iter(DataLoader(data_list, batch_size=n_walks, follow_batch=[\"node_idx\"]))).to(device)\n",
    "    edge_index = walk_graph.edge_index\n",
    "    edge_attr = walk_graph.edge_attr\n",
    "    node_idx = torch.arange(edge_index.max() + 1, device=device).unsqueeze(-1)\n",
    "    edge_index_2, edge_attr_2 = DeBruijnTransform(aggregation)(node_idx, edge_index, edge_attr)\n",
    "    orig_edge_index_2 = walk_graph.node_idx.squeeze()[edge_index_2]\n",
    "    unique_edge_index_2, inverse_idx = orig_edge_index_2.unique(dim=1, return_inverse=True)\n",
    "    edge_attr_2 = torch.zeros(unique_edge_index_2.size(1), device=device).index_add(0, inverse_idx, edge_attr_2)\n",
    "    return unique_edge_index_2, edge_attr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774 ms ± 48.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit edge_index_k_weighted(path_list, path_freq_tensor, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = EdgeIndex(torch.tensor([\n",
    "                                        [0, 0, 1, 0, 0, 2, 2, 3, 3, 4, 4],\n",
    "                                        [1, 2, 2, 4, 6, 3, 4, 4, 5, 5, 6]\n",
    "]), sparse_size=(7, 7))\n",
    "edge_index = edge_index.sort_by(\"row\")[0]\n",
    "N = 7\n",
    "A = edge_index.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [0, 2],\n",
       "         [0, 2],\n",
       "         [0, 4],\n",
       "         [0, 4],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [2, 3],\n",
       "         [2, 3],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [3, 4],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[1, 2],\n",
       "         [2, 3],\n",
       "         [2, 4],\n",
       "         [4, 5],\n",
       "         [4, 6],\n",
       "         [2, 3],\n",
       "         [2, 4],\n",
       "         [3, 4],\n",
       "         [3, 5],\n",
       "         [4, 5],\n",
       "         [4, 6],\n",
       "         [4, 5],\n",
       "         [4, 6]]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(edge_index=edge_index)\n",
    "line_graph = LineGraph(force_directed=True)(data)\n",
    "edge_index.T[line_graph.edge_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lift_order_edge_index(edge_index) == edge_index.T[line_graph.edge_index]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeIndex([[0, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4],\n",
       "           [1, 2, 4, 6, 2, 3, 4, 4, 5, 5, 6]], sparse_size=(7, 7), nnz=11,\n",
       "          sort_order=row)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [0, 2, 3],\n",
       "        [0, 2, 4],\n",
       "        [0, 4, 5],\n",
       "        [0, 4, 6],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 4],\n",
       "        [2, 3, 4],\n",
       "        [2, 3, 5],\n",
       "        [2, 4, 5],\n",
       "        [2, 4, 6],\n",
       "        [3, 4, 5],\n",
       "        [3, 4, 6]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fast dense implementation\n",
    "(A * A.unsqueeze(2)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Indexing and PyG are equal\n",
      "Number of nodes: 100 vs 99\n",
      "tensor([[ 0,  2,  5,  5,  9, 11, 12, 14, 14, 16, 16, 19, 22, 23, 25, 27, 27, 30,\n",
      "         30, 34, 34, 35, 35, 38, 39, 42, 43, 43, 46, 52, 57, 66, 67, 67, 68, 70,\n",
      "         72, 73, 75, 77, 79, 80, 83, 86, 87, 88, 90, 93, 94, 98],\n",
      "        [41, 85, 40, 58, 25, 12, 43, 27, 57,  5,  9, 48, 82, 34, 13, 34, 58, 26,\n",
      "         44, 50, 60, 62, 83, 28, 27, 46, 45, 51, 11, 59,  3, 15, 39, 73, 81, 33,\n",
      "         89,  2, 57,  7, 27,  6, 80, 77, 68, 58, 22, 90, 96, 47]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1,  4,  1],\n",
      "        [ 1,  5,  1],\n",
      "        [ 1,  6,  1],\n",
      "        [ 1,  7,  1],\n",
      "        [ 1,  8,  1],\n",
      "        [ 1,  9,  1],\n",
      "        [ 1, 19,  1],\n",
      "        [ 1, 20,  1]], device='cuda:0')\n",
      "######################\n",
      "tensor([[[ 9, 25],\n",
      "         [11, 12],\n",
      "         [12, 43],\n",
      "         [12, 43],\n",
      "         [14, 27],\n",
      "         [14, 27],\n",
      "         [14, 57],\n",
      "         [16,  5],\n",
      "         [16,  5],\n",
      "         [16,  9],\n",
      "         [23, 34],\n",
      "         [23, 34],\n",
      "         [27, 34],\n",
      "         [27, 34],\n",
      "         [35, 83],\n",
      "         [39, 27],\n",
      "         [39, 27],\n",
      "         [42, 46],\n",
      "         [46, 11],\n",
      "         [67, 39],\n",
      "         [67, 73],\n",
      "         [73,  2],\n",
      "         [75, 57],\n",
      "         [79, 27],\n",
      "         [79, 27],\n",
      "         [83, 80],\n",
      "         [86, 77],\n",
      "         [87, 68],\n",
      "         [90, 22],\n",
      "         [93, 90]],\n",
      "\n",
      "        [[25, 13],\n",
      "         [12, 43],\n",
      "         [43, 45],\n",
      "         [43, 51],\n",
      "         [27, 34],\n",
      "         [27, 58],\n",
      "         [57,  3],\n",
      "         [ 5, 40],\n",
      "         [ 5, 58],\n",
      "         [ 9, 25],\n",
      "         [34, 50],\n",
      "         [34, 60],\n",
      "         [34, 50],\n",
      "         [34, 60],\n",
      "         [83, 80],\n",
      "         [27, 34],\n",
      "         [27, 58],\n",
      "         [46, 11],\n",
      "         [11, 12],\n",
      "         [39, 27],\n",
      "         [73,  2],\n",
      "         [ 2, 85],\n",
      "         [57,  3],\n",
      "         [27, 34],\n",
      "         [27, 58],\n",
      "         [80,  6],\n",
      "         [77,  7],\n",
      "         [68, 81],\n",
      "         [22, 82],\n",
      "         [90, 22]]], device='cuda:0')\n",
      "######################\n",
      "tensor([[[ 9, 25],\n",
      "         [11, 12],\n",
      "         [12, 43],\n",
      "         [12, 43],\n",
      "         [14, 27],\n",
      "         [14, 27],\n",
      "         [14, 57],\n",
      "         [16,  5],\n",
      "         [16,  5],\n",
      "         [16,  9],\n",
      "         [23, 34],\n",
      "         [23, 34],\n",
      "         [27, 34],\n",
      "         [27, 34],\n",
      "         [35, 83],\n",
      "         [39, 27],\n",
      "         [39, 27],\n",
      "         [42, 46],\n",
      "         [46, 11],\n",
      "         [67, 39],\n",
      "         [67, 73],\n",
      "         [73,  2],\n",
      "         [75, 57],\n",
      "         [79, 27],\n",
      "         [79, 27],\n",
      "         [83, 80],\n",
      "         [86, 77],\n",
      "         [87, 68],\n",
      "         [90, 22],\n",
      "         [93, 90]],\n",
      "\n",
      "        [[25, 13],\n",
      "         [12, 43],\n",
      "         [43, 45],\n",
      "         [43, 51],\n",
      "         [27,  3],\n",
      "         [27, 34],\n",
      "         [57, 58],\n",
      "         [ 5, 25],\n",
      "         [ 5, 40],\n",
      "         [ 9, 58],\n",
      "         [34, 50],\n",
      "         [34, 60],\n",
      "         [34, 50],\n",
      "         [34, 60],\n",
      "         [83, 80],\n",
      "         [27, 34],\n",
      "         [27, 58],\n",
      "         [46, 11],\n",
      "         [11, 12],\n",
      "         [39,  2],\n",
      "         [73, 27],\n",
      "         [ 2, 85],\n",
      "         [57,  3],\n",
      "         [27, 34],\n",
      "         [27, 58],\n",
      "         [80,  6],\n",
      "         [77,  7],\n",
      "         [68, 81],\n",
      "         [22, 82],\n",
      "         [90, 22]]], device='cuda:0')\n",
      "######################\n",
      "(EdgeIndex([[ 9, 11, 12, 12, 14, 14, 14, 16, 16, 16, 23, 23, 27, 27, 35, 39, 39,\n",
      "            42, 46, 67, 67, 73, 75, 79, 79, 83, 86, 87, 90, 93],\n",
      "           [13, 43, 45, 51,  3, 34, 58, 25, 40, 58, 50, 60, 50, 60, 80, 34, 58,\n",
      "            11, 12,  2, 27, 85,  3, 34, 58,  6,  7, 81, 82, 22]],\n",
      "          device='cuda:0', sparse_size=(100, 100), nnz=30, sort_order=row), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from torch_geometric.testing import get_random_edge_index\n",
    "\n",
    "for i in range(1, 31):\n",
    "    edge_index = get_random_edge_index(100*i, 100*i, 50*i).to(\"cuda\")\n",
    "    edge_index = coalesce(edge_index)\n",
    "    num_nodes = 100*i\n",
    "\n",
    "    PyG_times, MP_times, Indexing_times = [], [], []\n",
    "    t = time()\n",
    "    PyG_line_graph_data = LineGraph(force_directed=True)(Data(edge_index=edge_index, num_nodes=num_nodes))\n",
    "    PyG_line_graph = edge_index.T[PyG_line_graph_data.edge_index]\n",
    "    PyG_times.append(time() - t)\n",
    "\n",
    "    t = time()\n",
    "    MP_line_graph = DeBruijnTransform()(torch.arange(edge_index.max() + 1).unsqueeze(-1).to(\"cuda\"), edge_index)\n",
    "    MP_times.append(time() - t)\n",
    "\n",
    "    t = time()\n",
    "    Indexing_line_graph = lift_order_edge_index(edge_index)\n",
    "    Indexing_times.append(time() - t)\n",
    "\n",
    "    # check if the line graphs are equal\n",
    "    if not (PyG_line_graph == MP_line_graph).all():\n",
    "        print(f\"Iteration {i}: Message Passing and PyG are equal\")\n",
    "        print((PyG_line_graph != MP_line_graph).nonzero())\n",
    "        break\n",
    "    if not (PyG_line_graph == Indexing_line_graph).all():\n",
    "        print(f\"Iteration {i}: Indexing and PyG are equal\")\n",
    "        print(f\"Number of nodes: {num_nodes} vs {edge_index.max().item() + 1}\")\n",
    "        print(edge_index)\n",
    "        print((PyG_line_graph != Indexing_line_graph).nonzero())\n",
    "        print(\"######################\")\n",
    "        print(PyG_line_graph)\n",
    "        print(\"######################\")\n",
    "        print(Indexing_line_graph)\n",
    "        print(\"######################\")\n",
    "        edge_index_obj = EdgeIndex(edge_index, sparse_size=(num_nodes, num_nodes)).sort_by(\"row\")[0]\n",
    "        print(edge_index_obj @ edge_index_obj)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 2, 3, 3, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 2, 4, 7, 5, 6, 5, 7]])\n",
    "\n",
    "edge_index = EdgeIndex(edge_index, sparse_size=(8, 8)).sort_by(\"row\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 3],\n",
       "         [0, 3],\n",
       "         [0, 3],\n",
       "         [1, 2],\n",
       "         [1, 3],\n",
       "         [1, 3],\n",
       "         [1, 3],\n",
       "         [1, 6],\n",
       "         [2, 4],\n",
       "         [3, 2],\n",
       "         [3, 4],\n",
       "         [4, 5],\n",
       "         [6, 5]],\n",
       "\n",
       "        [[1, 2],\n",
       "         [1, 2],\n",
       "         [1, 3],\n",
       "         [3, 6],\n",
       "         [3, 4],\n",
       "         [3, 7],\n",
       "         [2, 4],\n",
       "         [3, 4],\n",
       "         [3, 2],\n",
       "         [3, 7],\n",
       "         [6, 5],\n",
       "         [4, 5],\n",
       "         [2, 4],\n",
       "         [4, 5],\n",
       "         [5, 7],\n",
       "         [5, 7]]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_edge = lift_order_edge_index(edge_index)\n",
    "index_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 3],\n",
       "         [0, 3],\n",
       "         [0, 3],\n",
       "         [1, 2],\n",
       "         [1, 3],\n",
       "         [1, 3],\n",
       "         [1, 3],\n",
       "         [1, 6],\n",
       "         [2, 4],\n",
       "         [3, 2],\n",
       "         [3, 4],\n",
       "         [4, 5],\n",
       "         [6, 5]],\n",
       "\n",
       "        [[1, 2],\n",
       "         [1, 3],\n",
       "         [1, 6],\n",
       "         [3, 2],\n",
       "         [3, 4],\n",
       "         [3, 7],\n",
       "         [2, 4],\n",
       "         [3, 2],\n",
       "         [3, 4],\n",
       "         [3, 7],\n",
       "         [6, 5],\n",
       "         [4, 5],\n",
       "         [2, 4],\n",
       "         [4, 5],\n",
       "         [5, 7],\n",
       "         [5, 7]]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_edge = edge_index.T[LineGraph()(Data(edge_index=edge_index, num_nodes=8)).edge_index]\n",
    "line_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True]],\n",
       "\n",
       "        [[ True,  True],\n",
       "         [ True, False],\n",
       "         [ True, False],\n",
       "         [ True, False],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True, False],\n",
       "         [ True, False],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True],\n",
       "         [ True,  True]]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_edge == line_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeIndex([[0, 0, 1, 1, 1, 2, 3, 3, 3, 4, 5, 6],\n",
       "           [1, 3, 2, 3, 6, 4, 2, 4, 7, 5, 7, 5]], sparse_size=(8, 8), nnz=12,\n",
       "          sort_order=row)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = to_torch_csc_tensor(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 3, 3, 4, 6],\n",
       "                       [2, 3, 4, 6, 7, 2, 4, 5, 7, 5, 4, 5, 7, 7]]),\n",
       "       values=tensor([2., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "       size=(8, 8), nnz=14, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(crow_indices=tensor([ 0,  5,  9, 10, 12, 13, 13, 14, 14]),\n",
       "       col_indices=tensor([2, 3, 6, 4, 7, 4, 2, 7, 5, 5, 4, 5, 7, 7]),\n",
       "       values=tensor([2., 1., 1., 1., 1., 2., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "       size=(8, 8), nnz=14, layout=torch.sparse_csr)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_2 = A @ A\n",
    "A_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 6, 4, 7, 4, 2, 7, 5, 5, 4, 5, 7, 7])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_2.col_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
