{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from tqdm import trange\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.experimental import disable_dynamic_shapes\n",
    "from torch_geometric.nn.aggr import Aggregation\n",
    "from torch_geometric.utils import coalesce\n",
    "\n",
    "import pathpyG as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeBruijn Transformations using GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatAggregation(Aggregation):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    # Not sure how this aggregation works, only that it does\n",
    "    # Inspired by the LSTMAggregation implementation in PyG:\n",
    "    # https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/aggr/lstm.html\n",
    "    @disable_dynamic_shapes(required_args=['dim_size', 'max_num_elements'])\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        index: Optional[Tensor] = None,\n",
    "        ptr: Optional[Tensor] = None,\n",
    "        dim_size: Optional[int] = None,\n",
    "        dim: int = -2,\n",
    "        max_num_elements: Optional[int] = None,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        # Concetenate all messages with padding value -1\n",
    "        x, _ = self.to_dense_batch(x, index, ptr, dim_size, dim, max_num_elements=max_num_elements, fill_value=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeBruijnTransform(MessagePassing):\n",
    "    # freq_aggr is a string specifying how we should count each path in the network\n",
    "    # This can either be `propagation` where every path is counted once\n",
    "    # or `diffusion` where every path is counted depending on the number of outgoing edges\n",
    "    # of the source node.\n",
    "    def __init__(self, freq_aggr: str = \"propagation\"):\n",
    "        super().__init__(aggr=ConcatAggregation(), flow=\"target_to_source\")\n",
    "        self.freq_aggr = freq_aggr\n",
    "\n",
    "    def forward(self, node_idx, edge_index, edge_attr=None):\n",
    "        # Sort edge_index because otherwise propagate will not work in combination with the ConcatAggregation\n",
    "        edge_index = coalesce(edge_index, sort_by_row=True)\n",
    "        # Set the dimension along which the node feature tensor is expected\n",
    "        # This is the default value, but we need to set it explicitly here\n",
    "        # because we change it later\n",
    "        self.node_dim = -2\n",
    "        # Update the node idx by passing the messages and aggregating them\n",
    "        # In the message function, we concatenate the node idx of the source node\n",
    "        # with the node idx of the target node\n",
    "        # In the aggregation function, we concatenate all messages from the neighbors\n",
    "        # The resulting feature for every node is a tensor of shape (max_degree, 2)\n",
    "        # where max_degree is the maximum degree of the graph\n",
    "        # If a node has less neighbors than max_degree, the remaining entries are filled with -1\n",
    "        node_idx_set_higher_order = self.propagate(edge_index, node_idx=node_idx)\n",
    "        # Since our node features changed from shape (N, 1) to (N, max_degree, 2)\n",
    "        # we need to set the node_dim to -3\n",
    "        self.node_dim = -3\n",
    "        # We use the function that is used to update node features to create the higher order edges\n",
    "        edge_index_higher_order, edge_attr_higher_order = self.edge_updater(\n",
    "            edge_index, \n",
    "            node_idx=node_idx_set_higher_order,\n",
    "            edge_attr=edge_attr\n",
    "            )\n",
    "\n",
    "        if edge_attr_higher_order is not None:\n",
    "            return edge_index_higher_order, edge_attr_higher_order\n",
    "        return edge_index_higher_order\n",
    "\n",
    "    def message(self, node_idx_i, node_idx_j):\n",
    "        # Concatenate the node idx of the source node with the node idx of the target node\n",
    "        # The shape changes from (N, k) to (N, k+1) where k is the order of the nodes before\n",
    "        return torch.cat([node_idx_i, node_idx_j[:, -1:]], dim=-1)\n",
    "    \n",
    "    def edge_update(self, node_idx_i, node_idx_j, edge_attr=None) -> tuple[Tensor, Optional[Tensor]]:\n",
    "        # We take the higher order node idx sets that have been created for each node adjacent\n",
    "        # to the edge (node_idx_i, node_idx_j) and repeat each node idx across different dimensions\n",
    "        # so that we can compare them with each other\n",
    "        #\n",
    "        # Example:\n",
    "        #\n",
    "        #   node_idx_i = [[0, 3], [1, 3], [2, 3]]\n",
    "        #   node_idx_j = [[3, 4], [2, 4], [-1, -1]]\n",
    "        #\n",
    "        #   strided_node_idx_i = [[\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3], \n",
    "        #                           [2, 3]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3],\n",
    "        #                           [2, 3]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3],\n",
    "        #                           [2, 3]\n",
    "        #                         ]]\n",
    "        #   strided_node_idx_j = [[\n",
    "        #                           [3, 4],\n",
    "        #                           [3, 4],\n",
    "        #                           [3, 4]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [2, 4],\n",
    "        #                           [2, 4],\n",
    "        #                           [2, 4]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [-1, -1],\n",
    "        #                           [-1, -1],\n",
    "        #                           [-1, -1]\n",
    "        #                         ]]\n",
    "        strided_node_idx_i = node_idx_i.unsqueeze(1).expand(-1, node_idx_j.size(1), -1, -1)\n",
    "        strided_node_idx_j = node_idx_j.unsqueeze(2).expand(-1, -1, node_idx_i.size(1), -1)\n",
    "        # Only create an higher order edge if the target node idx of the first edge is equal to\n",
    "        # the source node idx of the second edge\n",
    "        edge_mask = (strided_node_idx_i[:, :, :, 1:] == strided_node_idx_j[:, :, :, :-1]).all(dim=-1)\n",
    "        # Also, we need to remove the -1 padding values\n",
    "        padd_mask = (\n",
    "            (strided_node_idx_i[:, :, :] != -1).all(dim=-1) &\n",
    "            (strided_node_idx_j[:, :, :] != -1).all(dim=-1)\n",
    "        )\n",
    "        # For the above, the following mask is:\n",
    "        #\n",
    "        #   mask = [[True, True, True],\n",
    "        #           [False, False, False],\n",
    "        #           [False, False, False]]\n",
    "        mask = (edge_mask & padd_mask)\n",
    "        # Concetenate the remaining higher order edges to create a new edge index\n",
    "        higher_order_edges = torch.cat([strided_node_idx_i[mask].unsqueeze(0), strided_node_idx_j[mask].unsqueeze(0)], dim=0)\n",
    "        \n",
    "        if edge_attr is not None:\n",
    "            # If edge attributes are given, we need to fit the shape to apply the same mask\n",
    "            strided_edge_attr = edge_attr.unsqueeze(1).unsqueeze(1).expand(-1, node_idx_j.size(1), node_idx_i.size(1))\n",
    "            # Apply the mask and use some way to combine the edge attributes of source and target node\n",
    "            # For now, we just take the edge attribute of the source node\n",
    "            if self.freq_aggr == \"propagation\":\n",
    "                higher_order_edge_attr = strided_edge_attr[mask]\n",
    "            elif self.freq_aggr == \"diffusion\":\n",
    "                higher_order_edge_attr = strided_edge_attr[mask] / mask.sum(dim=(1,2), keepdim=True).expand(-1, node_idx_j.size(1), node_idx_i.size(1))[mask]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown frequency aggregation method {self.freq_aggr}\")\n",
    "            return higher_order_edges, higher_order_edge_attr\n",
    "        return higher_order_edges, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [6, 5],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 5, 6, 5, 7]])\n",
    "node_idx = torch.arange(edge_index.max() + 1).reshape(-1, 1)\n",
    "edge_index_2_fast = DeBruijnTransform()(node_idx, edge_index)\n",
    "print(edge_index_2_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5],\n",
      "         [1, 6]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7],\n",
      "         [6, 5]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_2 = pp.DAGData.lift_order_dag(edge_index.unsqueeze(-1))\n",
    "print(edge_index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print((edge_index_2.sort(dim=1)[0] == edge_index_2_fast.sort(dim=1)[0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Edge Weights\n",
    "\n",
    "Depending on how you count each walk, you will get different statistics. We can choose the aggregation via `freq_aggr` to be either \"propagation\", i.e. each walk counts with its weight, or \"diffusion\" i.e. each walk is counted with the probability of a random walker starting at the first node to end up in the last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [6, 5],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 5, 6, 5, 7]])\n",
    "node_idx = torch.arange(edge_index.max() + 1).reshape(-1, 1)\n",
    "edge_attr = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.float32)\n",
    "edge_index_2_fast, edge_attr_2 = DeBruijnTransform(freq_aggr=\"diffusion\")(node_idx, edge_index, edge_attr)\n",
    "print(edge_index_2_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3333, 0.3333, 0.3333, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(edge_attr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd order\n",
    "Currently, the transformation works only with a standard edge index. The good thing is, you can still pass in the higher_order node_idx and then the output is directly a third order edge index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the edge index since the DeBruijnTransform only works for the normal edge index\n",
    "edges_2 = edge_index_2_fast.reshape(-1, 2)\n",
    "uniques, inverse_idx = edges_2.unique(dim=0, return_inverse=True)\n",
    "transformed_edge_index_2_fast = inverse_idx.reshape(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 3],\n",
      "         [0, 1, 6],\n",
      "         [0, 3, 4],\n",
      "         [1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5],\n",
      "         [3, 4, 5],\n",
      "         [6, 5, 7],\n",
      "         [4, 5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_3_fast = DeBruijnTransform()(uniques, transformed_edge_index_2_fast)\n",
    "print(edge_index_3_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 3],\n",
      "         [0, 1, 6],\n",
      "         [0, 3, 4],\n",
      "         [1, 3, 4],\n",
      "         [3, 4, 5],\n",
      "         [1, 6, 5]],\n",
      "\n",
      "        [[1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5],\n",
      "         [3, 4, 5],\n",
      "         [4, 5, 7],\n",
      "         [6, 5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_3 = pp.DAGData.lift_order_dag(edge_index_2)\n",
    "print(edge_index_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponentionally Large DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 18.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "layers = 5\n",
    "branches = 15\n",
    "\n",
    "edges = []\n",
    "prev_layer_nodes = [0]\n",
    "j = 1\n",
    "for _ in trange(layers):\n",
    "    layer_nodes = []\n",
    "    for node in prev_layer_nodes:\n",
    "        for _ in range(branches):\n",
    "            layer_nodes.append(j)\n",
    "            edges.append((f\"{node}\", f\"{j}\"))\n",
    "            j+=1\n",
    "    prev_layer_nodes = layer_nodes\n",
    "\n",
    "dag = pp.Graph.from_edge_list(edges)\n",
    "dag_edge_index = dag.data.edge_index.unsqueeze(-1)\n",
    "\n",
    "node_idx = torch.arange(dag_edge_index.max().item() + 1).unsqueeze(-1)\n",
    "node_idx_gpu = node_idx.cuda()\n",
    "dag_edge_index_gpu = dag.data.edge_index.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 9s ± 3.52 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pp.DAGData.lift_order_dag(dag_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing based implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694 ms ± 15.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit DeBruijnTransform()(node_idx, dag.data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing based implementation (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.6 ms ± 2.42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit DeBruijnTransform()(node_idx_gpu, dag_edge_index_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((dag_edge_index_order_2.sort(dim=1)[0] == dag_edge_index_order_2_fast.sort(dim=1)[0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/pathpyG/src/pathpyG/core/WalkDataNested.py:56: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  self.paths = nested_tensor(paths, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "n_walks = 10000\n",
    "walk_length = 1000\n",
    "\n",
    "walks = [list(range(walk_length)) for _ in range(n_walks)]\n",
    "orig_walk = pp.WalkData()\n",
    "for walk in walks:\n",
    "    orig_walk.add_walk_seq(walk)\n",
    "\n",
    "path_list = list(orig_walk.paths.values())\n",
    "path_freq_tensor = torch.tensor(list(orig_walk.path_freq.values()))\n",
    "mapping = pp.IndexMap()\n",
    "nested_walk = pp.WalkDataNested(path_list, path_freq=path_freq_tensor, mapping=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Walk Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.5 s ± 7.25 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit orig_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor Implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466 ms ± 20.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cpu\"\n",
    "%timeit nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 ms ± 27.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cuda\"\n",
    "cuda_path_list = [path.cuda() for path in path_list]\n",
    "cuda_path_freq = path_freq_tensor.cuda()\n",
    "cuda_nested_walk = pp.WalkDataNested(cuda_path_list, path_freq=cuda_path_freq, mapping=mapping)\n",
    "%timeit cuda_nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing Implementation (CPU + GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a list of Data objects where each Data object contains the edge index of a path (could also be a DAG in theory)\n",
    "data_list = [Data(edge_index=path.long(), num_nodes=walk_length) for path in path_list]\n",
    "# We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs\n",
    "# If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards\n",
    "# Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once\n",
    "walk_graph = next(iter(DataLoader(data_list, batch_size=n_walks)))\n",
    "edge_index = walk_graph.edge_index\n",
    "node_idx = torch.arange(edge_index.max() + 1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following measures the time to do the De Bruijn graph transformation for the edge index that contains all paths as disjunct subgraphs. Since the aggregations afterwards are omitted, the runtimes are not exactly comparable to the above. See the next section (With Weights and the Aggregation) for a full `edge_index_k_weighted` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 s ± 64.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit DeBruijnTransform()(node_idx, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.8 ms ± 5.33 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "cuda_edge_index = edge_index.cuda()\n",
    "cuda_node_idx = node_idx.cuda()\n",
    "%timeit DeBruijnTransform()(cuda_node_idx, cuda_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Weights and the Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_index_k_weighted(path_list, path_freq, aggregation=\"propagation\", device=\"cuda\"):\n",
    "    data_list = [\n",
    "        Data(\n",
    "            edge_index=path.long(), \n",
    "            num_nodes=walk_length,\n",
    "            edge_attr=torch.ones(path.size(1), dtype=torch.float32) * path_freq[i],\n",
    "            node_idx=torch.arange(walk_length).unsqueeze(-1)\n",
    "        ) for i, path in enumerate(path_list)\n",
    "        ]\n",
    "    walk_graph = next(iter(DataLoader(data_list, batch_size=n_walks, follow_batch=[\"node_idx\"]))).to(device)\n",
    "    edge_index = walk_graph.edge_index\n",
    "    edge_attr = walk_graph.edge_attr\n",
    "    node_idx = torch.arange(edge_index.max() + 1, device=device).unsqueeze(-1)\n",
    "    edge_index_2, edge_attr_2 = DeBruijnTransform(aggregation)(node_idx, edge_index, edge_attr)\n",
    "    orig_edge_index_2 = walk_graph.node_idx.squeeze()[edge_index_2]\n",
    "    unique_edge_index_2, inverse_idx = orig_edge_index_2.unique(dim=1, return_inverse=True)\n",
    "    edge_attr_2 = torch.zeros(unique_edge_index_2.size(1), device=device).index_add(0, inverse_idx, edge_attr_2)\n",
    "    return unique_edge_index_2, edge_attr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774 ms ± 48.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit edge_index_k_weighted(path_list, path_freq_tensor, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Translations using torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 3],\n",
      "        [0, 3, 2]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0,1,2], [1,2,3]])\n",
    "# The indices should be mapped as follows: {0: 1, 1: 0, 2: 3, 3: 2}\n",
    "mapping = torch.tensor([1, 0, 3, 2])\n",
    "edge_index_mapped = mapping[edge_index]\n",
    "print(edge_index_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['a->b', 'b->c', 'c->d'],\n",
       "       ['b->c', 'c->d', 'd->e']], dtype='<U4')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "string_mapping = np.array([\"a->b\", \"b->c\", \"c->d\", \"d->e\"])\n",
    "edge_index_string_mapped = string_mapping[edge_index]\n",
    "edge_index_string_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
