{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "from tqdm import trange\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch_geometric import EdgeIndex\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.experimental import disable_dynamic_shapes\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.nn.aggr import Aggregation\n",
    "from torch_geometric.transforms import LineGraph\n",
    "from torch_geometric.utils import scatter, cumsum, coalesce, degree\n",
    "from torch_geometric.utils import to_torch_sparse_tensor, to_torch_csc_tensor, to_torch_csr_tensor, to_torch_coo_tensor\n",
    "\n",
    "\n",
    "import pathpyG as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor, num_nodes: int = None) -> torch.Tensor:\n",
    "    num_edges = edge_index.size(1)\n",
    "    if num_nodes is None:\n",
    "        num_nodes = int(edge_index.max().item() + 1)\n",
    "    if isinstance(edge_index, torch.Tensor):\n",
    "        edge_index = EdgeIndex(edge_index, sparse_size=(num_nodes, num_nodes))\n",
    "    if not edge_index.is_sorted_by_row:\n",
    "        print(\"Sorting edge index\")\n",
    "        edge_index = edge_index.sort_by(\"row\")[0]\n",
    "    \n",
    "    i = torch.arange(num_edges, dtype=torch.long, device=edge_index.device)\n",
    "    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n",
    "    # For each center node, we need to combine each outgoing edge with each incoming edge\n",
    "    # We achieve this by creating `outdegree` edges for each destination node of the old edge index\n",
    "    outdegree_per_dst = outdegree[edge_index[1]]\n",
    "    # We use each edge from the edge index as new nodes and assign the new indices in the order of the original edge index\n",
    "    # Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n",
    "    # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor and the bucketize function\n",
    "    # First we create a tensor of shape (num_edges,) that contains the index at which the next node index starts for each node\n",
    "    # (Note here we use Torch's cumsum function because it does not add a 0 at the beginning of the tensor)\n",
    "    expanded_ptrs = torch.cumsum(outdegree_per_dst, dim=0)\n",
    "    # Using this tensor with the starting indices, we can create a new tensor of shape (num_ho_edges,) that contains the index of the new higher order source nodes\n",
    "    ho_edge_srcs = torch.bucketize(torch.arange(expanded_ptrs[-1], dtype=torch.long, device=edge_index.device), expanded_ptrs, right=True)\n",
    "\n",
    "    # Get the corresponding destination nodes for each higher order edge:\n",
    "    # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges (new higher order nodes) that have the node as source node\n",
    "    # (Note here we use PyG's cumsum function because it adds a 0 at the beginning of the tensor)\n",
    "    ptrs = cumsum(outdegree, dim=0)[:-1]\n",
    "    # Use these pointers to get the start of the edges for each higher order source node and repeat it `outdegree` times\n",
    "    # Since we keep the ordering, all new higher order edges that have the same source node are indexed consecutively\n",
    "    ho_edge_dsts = ptrs[edge_index[1]][ho_edge_srcs]\n",
    "    # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) for all `outdegree` edges to get the correct destination nodes\n",
    "    # We can achieve this by constructing a matrix of shape (num_nodes, num_edges) that contain the numbers 0, 1, 2, ... for each row\n",
    "    # Next, we get a mask that is True for all elements of the matrix that are smaller than the outdegree of the corresponding node\n",
    "    # Finally, we use this mask to get the correct numbers we need to add for each destination node in the edge index\n",
    "    ho_edge_dsts += i.unsqueeze(0).expand(num_edges, -1)[(i.unsqueeze(0).expand(num_nodes, -1) < outdegree.unsqueeze(1))[edge_index[1]]]\n",
    "\n",
    "    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeBruijn Transformations using GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatAggregation(Aggregation):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    # Not sure how this aggregation works, only that it does\n",
    "    # Inspired by the LSTMAggregation implementation in PyG:\n",
    "    # https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/aggr/lstm.html\n",
    "    @disable_dynamic_shapes(required_args=['dim_size', 'max_num_elements'])\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        index: Optional[Tensor] = None,\n",
    "        ptr: Optional[Tensor] = None,\n",
    "        dim_size: Optional[int] = None,\n",
    "        dim: int = -2,\n",
    "        max_num_elements: Optional[int] = None,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        # Concetenate all messages with padding value -1\n",
    "        x, _ = self.to_dense_batch(x, index, ptr, dim_size, dim, max_num_elements=max_num_elements, fill_value=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeBruijnTransform(MessagePassing):\n",
    "    # freq_aggr is a string specifying how we should count each path in the network\n",
    "    # This can either be `propagation` where every path is counted once\n",
    "    # or `diffusion` where every path is counted depending on the number of outgoing edges\n",
    "    # of the source node.\n",
    "    def __init__(self, freq_aggr: str = \"propagation\"):\n",
    "        super().__init__(aggr=ConcatAggregation(), flow=\"target_to_source\")\n",
    "        self.freq_aggr = freq_aggr\n",
    "\n",
    "    def forward(self, node_idx, edge_index, edge_attr=None):\n",
    "        # Sort edge_index because otherwise propagate will not work in combination with the ConcatAggregation\n",
    "        edge_index = coalesce(edge_index, sort_by_row=True)\n",
    "        # Set the dimension along which the node feature tensor is expected\n",
    "        # This is the default value, but we need to set it explicitly here\n",
    "        # because we change it later\n",
    "        self.node_dim = -2\n",
    "        # Update the node idx by passing the messages and aggregating them\n",
    "        # In the message function, we concatenate the node idx of the source node\n",
    "        # with the node idx of the target node\n",
    "        # In the aggregation function, we concatenate all messages from the neighbors\n",
    "        # The resulting feature for every node is a tensor of shape (max_degree, 2)\n",
    "        # where max_degree is the maximum degree of the graph\n",
    "        # If a node has less neighbors than max_degree, the remaining entries are filled with -1\n",
    "        node_idx_set_higher_order = self.propagate(edge_index, node_idx=node_idx)\n",
    "        # Since our node features changed from shape (N, 1) to (N, max_degree, 2)\n",
    "        # we need to set the node_dim to -3\n",
    "        self.node_dim = -3\n",
    "        # We use the function that is used to update node features to create the higher order edges\n",
    "        edge_index_higher_order, edge_attr_higher_order = self.edge_updater(\n",
    "            edge_index, \n",
    "            node_idx=node_idx_set_higher_order,\n",
    "            edge_attr=edge_attr\n",
    "            )\n",
    "\n",
    "        if edge_attr_higher_order is not None:\n",
    "            return edge_index_higher_order, edge_attr_higher_order\n",
    "        return edge_index_higher_order\n",
    "\n",
    "    def message(self, node_idx_i, node_idx_j):\n",
    "        # Concatenate the node idx of the source node with the node idx of the target node\n",
    "        # The shape changes from (N, k) to (N, k+1) where k is the order of the nodes before\n",
    "        return torch.cat([node_idx_i, node_idx_j[:, -1:]], dim=-1)\n",
    "    \n",
    "    def edge_update(self, node_idx_i, node_idx_j, edge_attr=None) -> tuple[Tensor, Optional[Tensor]]:\n",
    "        # We take the higher order node idx sets that have been created for each node adjacent\n",
    "        # to the edge (node_idx_i, node_idx_j) and repeat each node idx across different dimensions\n",
    "        # so that we can compare them with each other\n",
    "        #\n",
    "        # Example:\n",
    "        #\n",
    "        #   node_idx_i = [[0, 3], [1, 3], [2, 3]]\n",
    "        #   node_idx_j = [[3, 4], [2, 4], [-1, -1]]\n",
    "        #\n",
    "        #   strided_node_idx_i = [[\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3], \n",
    "        #                           [2, 3]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3],\n",
    "        #                           [2, 3]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3],\n",
    "        #                           [2, 3]\n",
    "        #                         ]]\n",
    "        #   strided_node_idx_j = [[\n",
    "        #                           [3, 4],\n",
    "        #                           [3, 4],\n",
    "        #                           [3, 4]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [2, 4],\n",
    "        #                           [2, 4],\n",
    "        #                           [2, 4]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [-1, -1],\n",
    "        #                           [-1, -1],\n",
    "        #                           [-1, -1]\n",
    "        #                         ]]\n",
    "        strided_node_idx_i = node_idx_i.unsqueeze(1).expand(-1, node_idx_j.size(1), -1, -1)\n",
    "        strided_node_idx_j = node_idx_j.unsqueeze(2).expand(-1, -1, node_idx_i.size(1), -1)\n",
    "        # Only create an higher order edge if the target node idx of the first edge is equal to\n",
    "        # the source node idx of the second edge\n",
    "        edge_mask = (strided_node_idx_i[:, :, :, 1:] == strided_node_idx_j[:, :, :, :-1]).all(dim=-1)\n",
    "        # Also, we need to remove the -1 padding values\n",
    "        padd_mask = (\n",
    "            (strided_node_idx_i[:, :, :] != -1).all(dim=-1) &\n",
    "            (strided_node_idx_j[:, :, :] != -1).all(dim=-1)\n",
    "        )\n",
    "        # For the above, the following mask is:\n",
    "        #\n",
    "        #   mask = [[True, True, True],\n",
    "        #           [False, False, False],\n",
    "        #           [False, False, False]]\n",
    "        mask = (edge_mask & padd_mask)\n",
    "        # Concetenate the remaining higher order edges to create a new edge index\n",
    "        higher_order_edges = torch.cat([strided_node_idx_i[mask].unsqueeze(0), strided_node_idx_j[mask].unsqueeze(0)], dim=0)\n",
    "        \n",
    "        if edge_attr is not None:\n",
    "            # If edge attributes are given, we need to fit the shape to apply the same mask\n",
    "            strided_edge_attr = edge_attr.unsqueeze(1).unsqueeze(1).expand(-1, node_idx_j.size(1), node_idx_i.size(1))\n",
    "            # Apply the mask and use some way to combine the edge attributes of source and target node\n",
    "            # For now, we just take the edge attribute of the source node\n",
    "            if self.freq_aggr == \"propagation\":\n",
    "                higher_order_edge_attr = strided_edge_attr[mask]\n",
    "            elif self.freq_aggr == \"diffusion\":\n",
    "                higher_order_edge_attr = strided_edge_attr[mask] / mask.sum(dim=(1,2), keepdim=True).expand(-1, node_idx_j.size(1), node_idx_i.size(1))[mask]\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown frequency aggregation method {self.freq_aggr}\")\n",
    "            return higher_order_edges, higher_order_edge_attr\n",
    "        return higher_order_edges, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General evaluation of correctness and runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Nodes: 1000, Edges: 1000\n",
      "\tGNN baseline: 0.009559392929077148s\n",
      "\tPyG: 0.011368513107299805s\n",
      "\tMP: 0.0021982192993164062s\n",
      "\tCUDA GNN baseline: 0.24655723571777344s\n",
      "\tCUDA PyG: 0.17524504661560059s\n",
      "\tCUDA MP: 0.022670745849609375s\n",
      "Iteration 0: Nodes: 1000, Edges: 11000\n",
      "\tGNN baseline: 0.002803802490234375s\n",
      "\tPyG: 0.09699869155883789s\n",
      "\tMP: 0.025521039962768555s\n",
      "\tCUDA GNN baseline: 0.001293182373046875s\n",
      "\tCUDA PyG: 1.4798369407653809s\n",
      "\tCUDA MP: 0.0063130855560302734s\n",
      "Iteration 0: Nodes: 1000, Edges: 21000\n",
      "\tGNN baseline: 0.0033135414123535156s\n",
      "\tPyG: 0.18238019943237305s\n",
      "\tMP: 0.08893465995788574s\n",
      "\tCUDA GNN baseline: 0.001046895980834961s\n",
      "\tCUDA PyG: 2.9825801849365234s\n",
      "\tCUDA MP: 0.018616437911987305s\n",
      "Iteration 0: Nodes: 1000, Edges: 31000\n",
      "\tGNN baseline: 0.001140594482421875s\n",
      "\tPyG: 0.256192684173584s\n",
      "\tMP: 0.2131354808807373s\n",
      "\tCUDA GNN baseline: 0.001361846923828125s\n",
      "\tCUDA PyG: 4.372312784194946s\n",
      "\tCUDA MP: 0.03851914405822754s\n",
      "Iteration 0: Nodes: 1000, Edges: 41000\n",
      "\tGNN baseline: 0.0019257068634033203s\n",
      "\tPyG: 0.34531736373901367s\n",
      "\tMP: 0.4323594570159912s\n",
      "\tCUDA GNN baseline: 0.0007429122924804688s\n",
      "\tCUDA PyG: 6.548636198043823s\n",
      "\tCUDA MP: 0.26354479789733887s\n",
      "Iteration 1: Nodes: 21000, Edges: 21000\n",
      "\tGNN baseline: 0.0023336410522460938s\n",
      "\tPyG: 0.16171979904174805s\n",
      "\tMP: 0.006488323211669922s\n",
      "\tCUDA GNN baseline: 0.0015926361083984375s\n",
      "\tCUDA PyG: 2.9223718643188477s\n",
      "\tCUDA MP: 0.019771099090576172s\n",
      "Iteration 1: Nodes: 21000, Edges: 231000\n",
      "\tGNN baseline: 0.01358652114868164s\n",
      "\tPyG: 2.368117570877075s\n",
      "\tMP: 0.5148305892944336s\n",
      "\tCUDA GNN baseline: 0.0011348724365234375s\n",
      "\tCUDA PyG: 40.534847259521484s\n",
      "\tCUDA MP: 0.10106515884399414s\n",
      "Iteration 1: Nodes: 21000, Edges: 441000\n",
      "\tGNN baseline: 0.023207664489746094s\n",
      "\tPyG: 4.614865064620972s\n",
      "\tMP: 2.1620090007781982s\n",
      "\tCUDA GNN baseline: 0.001644134521484375s\n",
      "\tCUDA PyG: 74.25145387649536s\n",
      "\tCUDA MP: 0.5114841461181641s\n",
      "Iteration 1: Nodes: 21000, Edges: 651000\n",
      "\tGNN baseline: 0.03272128105163574s\n",
      "\tPyG: 6.80631947517395s\n",
      "\tMP: 6.021017789840698s\n",
      "\tCUDA GNN baseline: 0.0009026527404785156s\n",
      "\tCUDA PyG: 111.37693238258362s\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 8.00 GiB of which 1.59 GiB is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.25 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mCUDA PyG: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcuda_PyG_times[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m t \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 62\u001b[0m cuda_MP_line_graph \u001b[38;5;241m=\u001b[39m \u001b[43mDeBruijnTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_edges\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_edge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m cuda_MP_times\u001b[38;5;241m.\u001b[39mappend(time() \u001b[38;5;241m-\u001b[39m t)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mCUDA MP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcuda_MP_times[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mDeBruijnTransform.forward\u001b[0;34m(self, node_idx, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# We use the function that is used to update node features to create the higher order edges\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m edge_index_higher_order, edge_attr_higher_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_updater\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_idx_set_higher_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_attr_higher_order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m edge_index_higher_order, edge_attr_higher_order\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:676\u001b[0m, in \u001b[0;36mMessagePassing.edge_updater\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edge_user_args, edge_index,\n\u001b[1;32m    672\u001b[0m                           mutable_size, kwargs)\n\u001b[1;32m    674\u001b[0m edge_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mcollect_param_data(\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_update\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[0;32m--> 676\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43medge_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edge_update_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    679\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (edge_index, size, kwargs), out)\n",
      "Cell \u001b[0;32mIn[3], line 112\u001b[0m, in \u001b[0;36mDeBruijnTransform.edge_update\u001b[0;34m(self, node_idx_i, node_idx_j, edge_attr)\u001b[0m\n\u001b[1;32m    109\u001b[0m strided_node_idx_j \u001b[38;5;241m=\u001b[39m node_idx_j\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, node_idx_i\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Only create an higher order edge if the target node idx of the first edge is equal to\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# the source node idx of the second edge\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m edge_mask \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mstrided_node_idx_i\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstrided_node_idx_j\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Also, we need to remove the -1 padding values\u001b[39;00m\n\u001b[1;32m    114\u001b[0m padd_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     (strided_node_idx_i[:, :, :] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mall(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m    116\u001b[0m     (strided_node_idx_j[:, :, :] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mall(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    117\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacty of 8.00 GiB of which 1.59 GiB is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 4.25 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from torch_geometric.testing import get_random_edge_index\n",
    "\n",
    "gnn_conv = SAGEConv(128, 16)\n",
    "cuda_gnn_conv = SAGEConv(128, 16).to(\"cuda\")\n",
    "line_graph_transform = LineGraph(force_directed=True)\n",
    "\n",
    "GNN_baseline_times, cuda_GNN_baseline_times = [], []\n",
    "PyG_times, MP_times, indexing_times = [], [], []\n",
    "cuda_PyG_times, cuda_MP_times, cuda_indexing_times = [], [], []\n",
    "for i in range(1, 201, 20):\n",
    "    num_nodes = 1000*i\n",
    "    x = torch.randn(num_nodes, 128)\n",
    "    cuda_x = x.to(\"cuda\")\n",
    "    for j in range(1, 50, 10):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        num_edges = num_nodes*j\n",
    "        print(f\"Iteration {int(i/20)}: Nodes: {num_nodes}, Edges: {num_edges}\")\n",
    "        edge_index = get_random_edge_index(num_nodes, num_nodes, num_edges)\n",
    "        edge_index = EdgeIndex(edge_index, sparse_size=(num_nodes, num_nodes))\n",
    "        edge_index = coalesce(edge_index, num_nodes=num_nodes)\n",
    "\n",
    "        # GNN baseline\n",
    "        \n",
    "        t = time()\n",
    "        gnn_conv(x, edge_index)\n",
    "        GNN_baseline_times.append(time() - t)\n",
    "        print(f\"\\tGNN baseline: {GNN_baseline_times[-1]}s\")\n",
    "\n",
    "        t = time()\n",
    "        PyG_line_graph_data = line_graph_transform(Data(edge_index=edge_index, num_nodes=num_nodes))\n",
    "        PyG_times.append(time() - t)\n",
    "        PyG_line_graph = PyG_line_graph_data.edge_index\n",
    "        print(f\"\\tPyG: {PyG_times[-1]}s\")\n",
    "\n",
    "        t = time()\n",
    "        MP_line_graph = DeBruijnTransform()(torch.arange(num_edges).unsqueeze(-1), edge_index)\n",
    "        MP_times.append(time() - t)\n",
    "        print(f\"\\tMP: {MP_times[-1]}s\")\n",
    "\n",
    "        # t = time()\n",
    "        # indexing_line_graph = lift_order_edge_index(edge_index, num_nodes)\n",
    "        # indexing_times.append(time() - t)\n",
    "        # print(f\"\\tIndexing: {indexing_times[-1]}s\")\n",
    "\n",
    "        cuda_edge_index = edge_index.to(\"cuda\")\n",
    "\n",
    "        t = time()\n",
    "        cuda_gnn_conv(cuda_x, cuda_edge_index)\n",
    "        cuda_GNN_baseline_times.append(time() - t)\n",
    "        print(f\"\\tCUDA GNN baseline: {cuda_GNN_baseline_times[-1]}s\")\n",
    "\n",
    "        t = time()\n",
    "        cuda_PyG_line_graph_data = line_graph_transform(Data(edge_index=cuda_edge_index, num_nodes=num_nodes))\n",
    "        cuda_PyG_times.append(time() - t)\n",
    "        cuda_PyG_line_graph = cuda_PyG_line_graph_data.edge_index\n",
    "        print(f\"\\tCUDA PyG: {cuda_PyG_times[-1]}s\")\n",
    "\n",
    "        t = time()\n",
    "        cuda_MP_line_graph = DeBruijnTransform()(torch.arange(num_edges).unsqueeze(-1).to(\"cuda\"), cuda_edge_index)\n",
    "        cuda_MP_times.append(time() - t)\n",
    "        print(f\"\\tCUDA MP: {cuda_MP_times[-1]}s\")\n",
    "\n",
    "        # t = time()\n",
    "        # cuda_indexing_line_graph = lift_order_edge_index(cuda_edge_index, num_nodes)\n",
    "        # cuda_indexing_times.append(time() - t)\n",
    "        # print(f\"\\tCUDA Indexing: {cuda_indexing_times[-1]}s\")\n",
    "\n",
    "        # check if the line graphs are equal\n",
    "        # if not (edge_index.T[PyG_line_graph] == MP_line_graph).all():\n",
    "        #     print(f\"Iteration {i}: Message Passing and PyG are equal\")\n",
    "        #     print((edge_index.T[PyG_line_graph] != MP_line_graph).nonzero())\n",
    "        #     break\n",
    "        # if not (PyG_line_graph == indexing_line_graph).all():\n",
    "        #     print(f\"Iteration {i}: Indexing and PyG are not equal\")\n",
    "        #     print(PyG_line_graph)\n",
    "        #     print(indexing_line_graph)\n",
    "        #     print((PyG_line_graph != indexing_line_graph).nonzero())\n",
    "        #     print(edge_index)\n",
    "        #     break\n",
    "        # if not (cuda_PyG_line_graph == cuda_indexing_line_graph).all():\n",
    "        #     print(f\"Iteration {i}: CUDA Indexing and CUDA PyG are not equal\")\n",
    "        #     break\n",
    "\n",
    "print(f\"Avg PyG time: {np.mean(PyG_times)}s +/- {np.std(PyG_times)}s\")\n",
    "print(f\"Avg MP time: {sum(MP_times) / len(MP_times)}\")\n",
    "print(f\"Avg Indexing time: {np.mean(indexing_times)}s +/- {np.std(indexing_times)}s\")\n",
    "# print(f\"Avg CUDA PyG time: {np.mean(cuda_PyG_times)}s +/- {np.std(cuda_PyG_times)}s\")\n",
    "print(f\"Avg CUDA MP time: {sum(cuda_MP_times) / len(cuda_MP_times)}\")\n",
    "# print(f\"Avg CUDA Indexing time: {np.mean(cuda_indexing_times)}s +/- {np.std(cuda_indexing_times)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [6, 5],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 5, 6, 5, 7]])\n",
    "node_idx = torch.arange(edge_index.max() + 1).reshape(-1, 1)\n",
    "edge_index_2_fast = DeBruijnTransform()(node_idx, edge_index)\n",
    "print(edge_index_2_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA_gather)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m edge_index_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDAGData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlift_order_dag\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(edge_index_2)\n",
      "File \u001b[0;32m/workspaces/pathpyG/src/pathpyG/core/DAGData.py:184\u001b[0m, in \u001b[0;36mDAGData.lift_order_dag\u001b[0;34m(edge_index)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m srcs:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dsts:\n\u001b[0;32m--> 184\u001b[0m             src\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mcat((\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, v)))\n\u001b[1;32m    185\u001b[0m             dst\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mcat((v, torch\u001b[38;5;241m.\u001b[39mgather(d, \u001b[38;5;241m0\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor([d\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])))))\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(src) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA_gather)"
     ]
    }
   ],
   "source": [
    "edge_index_2 = pp.DAGData.lift_order_dag(edge_index.unsqueeze(-1))\n",
    "print(edge_index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [6, 5],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_new = lift_order_edge_index(EdgeIndex(edge_index))\n",
    "print(edge_index_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print((edge_index_2_fast == edge_index_new).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Edge Weights\n",
    "\n",
    "Depending on how you count each walk, you will get different statistics. We can choose the aggregation via `freq_aggr` to be either \"propagation\", i.e. each walk counts with its weight, or \"diffusion\" i.e. each walk is counted with the probability of a random walker starting at the first node to end up in the last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [6, 5],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 5, 6, 5, 7]])\n",
    "node_idx = torch.arange(edge_index.max() + 1).reshape(-1, 1)\n",
    "edge_attr = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.float32)\n",
    "edge_index_2_fast, edge_attr_2 = DeBruijnTransform(freq_aggr=\"diffusion\")(node_idx, edge_index, edge_attr)\n",
    "print(edge_index_2_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3333, 0.3333, 0.3333, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(edge_attr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd order\n",
    "Currently, the transformation works only with a standard edge index. The good thing is, you can still pass in the higher_order node_idx and then the output is directly a third order edge index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the edge index since the DeBruijnTransform only works for the normal edge index\n",
    "edges_2 = edge_index_2_fast.reshape(-1, 2)\n",
    "uniques, inverse_idx = edges_2.unique(dim=0, return_inverse=True)\n",
    "transformed_edge_index_2_fast = inverse_idx.reshape(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 3],\n",
      "         [0, 1, 6],\n",
      "         [0, 3, 4],\n",
      "         [1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5],\n",
      "         [3, 4, 5],\n",
      "         [6, 5, 7],\n",
      "         [4, 5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_3_fast = DeBruijnTransform()(uniques, transformed_edge_index_2_fast)\n",
    "print(edge_index_3_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 3],\n",
      "         [0, 1, 6],\n",
      "         [0, 3, 4],\n",
      "         [1, 3, 4],\n",
      "         [3, 4, 5],\n",
      "         [1, 6, 5]],\n",
      "\n",
      "        [[1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5],\n",
      "         [3, 4, 5],\n",
      "         [4, 5, 7],\n",
      "         [6, 5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_3 = pp.DAGData.lift_order_dag(edge_index_2)\n",
    "print(edge_index_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponentionally Large DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 18.74it/s]\n"
     ]
    }
   ],
   "source": [
    "layers = 5\n",
    "branches = 15\n",
    "\n",
    "edges = []\n",
    "prev_layer_nodes = [0]\n",
    "j = 1\n",
    "for _ in trange(layers):\n",
    "    layer_nodes = []\n",
    "    for node in prev_layer_nodes:\n",
    "        for _ in range(branches):\n",
    "            layer_nodes.append(j)\n",
    "            edges.append((f\"{node}\", f\"{j}\"))\n",
    "            j+=1\n",
    "    prev_layer_nodes = layer_nodes\n",
    "\n",
    "dag = pp.Graph.from_edge_list(edges)\n",
    "dag_edge_index = dag.data.edge_index.unsqueeze(-1)\n",
    "\n",
    "node_idx = torch.arange(dag_edge_index.max().item() + 1).unsqueeze(-1)\n",
    "node_idx_gpu = node_idx.cuda()\n",
    "dag_edge_index_gpu = dag.data.edge_index.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 9s ± 3.52 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pp.DAGData.lift_order_dag(dag_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing based implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717 ms ± 14.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit DeBruijnTransform()(node_idx, dag.data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing based implementation (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.1 ms ± 2.89 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit DeBruijnTransform()(node_idx_gpu, dag_edge_index_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 ms ± 2.68 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(dag.data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.9 ms ± 12.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(dag_edge_index_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gpu = dag.data.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinegraph(data_gpu)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/magics/execution.py:1189\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1187\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m all_runs \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n\u001b[1;32m   1191\u001b[0m worst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(all_runs) \u001b[38;5;241m/\u001b[39m number\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/timeit.py:206\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    204\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[0;32m--> 206\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/magics/execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/transforms/line_graph.py:53\u001b[0m, in \u001b[0;36mLineGraph.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m count \u001b[38;5;241m=\u001b[39m scatter(torch\u001b[38;5;241m.\u001b[39mones_like(row), row, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     50\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mnum_nodes, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m ptr \u001b[38;5;241m=\u001b[39m cumsum(count)\n\u001b[0;32m---> 53\u001b[0m cols \u001b[38;5;241m=\u001b[39m [i[ptr[col[j]]:ptr[col[j] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(col\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))]\n\u001b[1;32m     54\u001b[0m rows \u001b[38;5;241m=\u001b[39m [row\u001b[38;5;241m.\u001b[39mnew_full((c\u001b[38;5;241m.\u001b[39mnumel(), ), j) \u001b[38;5;28;01mfor\u001b[39;00m j, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cols)]\n\u001b[1;32m     56\u001b[0m row, col \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(rows, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mcat(cols, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/transforms/line_graph.py:53\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m count \u001b[38;5;241m=\u001b[39m scatter(torch\u001b[38;5;241m.\u001b[39mones_like(row), row, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     50\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mnum_nodes, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m ptr \u001b[38;5;241m=\u001b[39m cumsum(count)\n\u001b[0;32m---> 53\u001b[0m cols \u001b[38;5;241m=\u001b[39m [i[ptr[col[j]]:ptr[col[j] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(col\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))]\n\u001b[1;32m     54\u001b[0m rows \u001b[38;5;241m=\u001b[39m [row\u001b[38;5;241m.\u001b[39mnew_full((c\u001b[38;5;241m.\u001b[39mnumel(), ), j) \u001b[38;5;28;01mfor\u001b[39;00m j, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cols)]\n\u001b[1;32m     56\u001b[0m row, col \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(rows, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mcat(cols, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%timeit linegraph(data_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.82 s ± 167 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "linegraph = LineGraph()\n",
    "%timeit linegraph(dag.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((dag_edge_index_order_2.sort(dim=1)[0] == dag_edge_index_order_2_fast.sort(dim=1)[0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/pathpyG/src/pathpyG/core/WalkDataNested.py:56: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  self.paths = nested_tensor(paths, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "n_walks = 10000\n",
    "walk_length = 1000\n",
    "\n",
    "walks = [list(range(walk_length)) for _ in range(n_walks)]\n",
    "orig_walk = pp.WalkData()\n",
    "for walk in walks:\n",
    "    orig_walk.add_walk_seq(walk)\n",
    "\n",
    "path_list = list(orig_walk.paths.values())\n",
    "path_freq_tensor = torch.tensor(list(orig_walk.path_freq.values()))\n",
    "mapping = pp.IndexMap()\n",
    "nested_walk = pp.WalkDataNested(path_list, path_freq=path_freq_tensor, mapping=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Walk Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.5 s ± 7.25 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit orig_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor Implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466 ms ± 20.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cpu\"\n",
    "%timeit nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 ms ± 24.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cuda\"\n",
    "cuda_path_list = [path.cuda() for path in path_list]\n",
    "cuda_path_freq = path_freq_tensor.cuda()\n",
    "cuda_nested_walk = pp.WalkDataNested(cuda_path_list, path_freq=cuda_path_freq, mapping=mapping)\n",
    "%timeit cuda_nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing Implementation (CPU + GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a list of Data objects where each Data object contains the edge index of a path (could also be a DAG in theory)\n",
    "data_list = [Data(edge_index=path.long(), num_nodes=walk_length) for path in path_list]\n",
    "# We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs\n",
    "# If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards\n",
    "# Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once\n",
    "walk_graph = next(iter(DataLoader(data_list, batch_size=n_walks)))\n",
    "edge_index = walk_graph.edge_index\n",
    "node_idx = torch.arange(edge_index.max() + 1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following measures the time to do the De Bruijn graph transformation for the edge index that contains all paths as disjunct subgraphs. Since the aggregations afterwards are omitted, the runtimes are not exactly comparable to the above. See the next section (With Weights and the Aggregation) for a full `edge_index_k_weighted` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 ms ± 76.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit DeBruijnTransform()(node_idx, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.2 ms ± 5.52 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "cuda_edge_index = edge_index.cuda()\n",
    "cuda_node_idx = node_idx.cuda()\n",
    "%timeit DeBruijnTransform()(cuda_node_idx, cuda_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24 s ± 26.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 ms ± 135 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(cuda_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Weights and the Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_index_k_weighted(path_list, path_freq, aggregation=\"propagation\", device=\"cuda\"):\n",
    "    data_list = [\n",
    "        Data(\n",
    "            edge_index=path.long(), \n",
    "            num_nodes=walk_length,\n",
    "            edge_attr=torch.ones(path.size(1), dtype=torch.float32) * path_freq[i],\n",
    "            node_idx=torch.arange(walk_length).unsqueeze(-1)\n",
    "        ) for i, path in enumerate(path_list)\n",
    "        ]\n",
    "    walk_graph = next(iter(DataLoader(data_list, batch_size=n_walks, follow_batch=[\"node_idx\"]))).to(device)\n",
    "    edge_index = walk_graph.edge_index\n",
    "    edge_attr = walk_graph.edge_attr\n",
    "    node_idx = torch.arange(edge_index.max() + 1, device=device).unsqueeze(-1)\n",
    "    edge_index_2, edge_attr_2 = DeBruijnTransform(aggregation)(node_idx, edge_index, edge_attr)\n",
    "    orig_edge_index_2 = walk_graph.node_idx.squeeze()[edge_index_2]\n",
    "    unique_edge_index_2, inverse_idx = orig_edge_index_2.unique(dim=1, return_inverse=True)\n",
    "    edge_attr_2 = torch.zeros(unique_edge_index_2.size(1), device=device).index_add(0, inverse_idx, edge_attr_2)\n",
    "    return unique_edge_index_2, edge_attr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774 ms ± 48.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit edge_index_k_weighted(path_list, path_freq_tensor, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = EdgeIndex(torch.tensor([\n",
    "                                        [0, 0, 1, 0, 0, 2, 2, 3, 3, 4, 4],\n",
    "                                        [1, 2, 2, 4, 6, 3, 4, 4, 5, 5, 6]\n",
    "]), sparse_size=(7, 7))\n",
    "edge_index = edge_index.sort_by(\"row\")[0]\n",
    "N = 7\n",
    "A = edge_index.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [0, 2],\n",
       "         [0, 2],\n",
       "         [0, 4],\n",
       "         [0, 4],\n",
       "         [1, 2],\n",
       "         [1, 2],\n",
       "         [2, 3],\n",
       "         [2, 3],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [3, 4],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[1, 2],\n",
       "         [2, 3],\n",
       "         [2, 4],\n",
       "         [4, 5],\n",
       "         [4, 6],\n",
       "         [2, 3],\n",
       "         [2, 4],\n",
       "         [3, 4],\n",
       "         [3, 5],\n",
       "         [4, 5],\n",
       "         [4, 6],\n",
       "         [4, 5],\n",
       "         [4, 6]]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(edge_index=edge_index)\n",
    "line_graph = LineGraph(force_directed=True)(data)\n",
    "edge_index.T[line_graph.edge_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [0, 2, 3],\n",
       "        [0, 2, 4],\n",
       "        [0, 4, 5],\n",
       "        [0, 4, 6],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 4],\n",
       "        [2, 3, 4],\n",
       "        [2, 3, 5],\n",
       "        [2, 4, 5],\n",
       "        [2, 4, 6],\n",
       "        [3, 4, 5],\n",
       "        [3, 4, 6]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fast dense implementation\n",
    "(A * A.unsqueeze(2)).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 2, 3, 3, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 2, 4, 7, 5, 6, 5, 7]])\n",
    "num_nodes = int(edge_index.max().item() + 1)\n",
    "num_edges = edge_index.size(1)\n",
    "edge_index = EdgeIndex(edge_index, sparse_size=(8, 8)).sort_by(\"row\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  1,  1,  1,  2,  3,  3,  3,  4,  5,  6,  7,  9, 11],\n",
       "        [ 2,  3,  4,  6,  7,  8,  5,  6,  7,  8, 11,  9,  5,  9, 10, 10]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_order_edge_index(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  1,  1,  1,  2,  3,  3,  3,  4,  5,  6,  7,  9, 11],\n",
       "        [ 2,  3,  4,  6,  7,  8,  5,  6,  7,  8, 11,  9,  5,  9, 10, 10]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LineGraph()(Data(edge_index=edge_index, num_nodes=num_nodes)).edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
