{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from tqdm import trange\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.experimental import disable_dynamic_shapes\n",
    "from torch_geometric.nn.aggr import Aggregation\n",
    "from torch_geometric.utils import coalesce\n",
    "\n",
    "import pathpyG as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeBruijn Transformations using GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatAggregation(Aggregation):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @disable_dynamic_shapes(required_args=['dim_size', 'max_num_elements'])\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        index: Optional[Tensor] = None,\n",
    "        ptr: Optional[Tensor] = None,\n",
    "        dim_size: Optional[int] = None,\n",
    "        dim: int = -2,\n",
    "        max_num_elements: Optional[int] = None,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        # Concetenate all messages with padding value -1\n",
    "        x, _ = self.to_dense_batch(x, index, ptr, dim_size, dim, max_num_elements=max_num_elements, fill_value=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeBruijnTransform(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super().__init__(aggr=ConcatAggregation(), flow=\"target_to_source\")\n",
    "\n",
    "    def forward(self, node_idx, edge_index):\n",
    "        # Sort edge_index because otherwise propagate will not work in combination with the ConcatAggregation\n",
    "        edge_index = coalesce(edge_index, sort_by_row=True)\n",
    "        # Set the dimension along which the node feature tensor is expected\n",
    "        # This is the default value, but we need to set it explicitly here\n",
    "        # because we change it later\n",
    "        self.node_dim = -2\n",
    "        # Update the node idx by passing the messages and aggregating them\n",
    "        # In the message function, we concatenate the node idx of the source node\n",
    "        # with the node idx of the target node\n",
    "        # In the aggregation function, we concatenate all messages from the neighbors\n",
    "        # The resulting feature for every node is a tensor of shape (max_degree, 2)\n",
    "        # where max_degree is the maximum degree of the graph\n",
    "        # If a node has less neighbors than max_degree, the remaining entries are filled with -1\n",
    "        node_idx_set_higher_order = self.propagate(edge_index, node_idx=node_idx)\n",
    "        # Since our node features changed from shape (N, 1) to (N, max_degree, 2)\n",
    "        # we need to set the node_dim to -3\n",
    "        self.node_dim = -3\n",
    "        # We use the function that is used to update node features to create the higher order edges\n",
    "        edge_index_higher_order = self.edge_updater(edge_index, node_idx=node_idx_set_higher_order)\n",
    "        # Select unique higher order nodes from the set of higher order neighbors\n",
    "        node_idx_higher_order = node_idx_set_higher_order.view(-1, node_idx_set_higher_order.size(-1)).unique(dim=0)[1:]\n",
    "\n",
    "        return node_idx_higher_order, edge_index_higher_order\n",
    "\n",
    "    def message(self, node_idx_i, node_idx_j):\n",
    "        # Concatenate the node idx of the source node with the node idx of the target node\n",
    "        # The shape changes from (N, 1) to (N, 2)\n",
    "        return torch.cat([node_idx_i, node_idx_j[:, -1:]], dim=-1)\n",
    "    \n",
    "    def edge_update(self, node_idx_i, node_idx_j) -> Tensor:\n",
    "        # We take the higher order node idx sets that have been created for each node adjacent\n",
    "        # to the edge (node_idx_i, node_idx_j) and repeat each node idx across different dimensions\n",
    "        # so that we can compare them with each other\n",
    "        #\n",
    "        # Example:\n",
    "        #\n",
    "        #   node_idx_i = [[0, 3], [1, 3], [2, 3]]\n",
    "        #   node_idx_j = [[3, 4], [2, 4], [-1, -1]]\n",
    "        #\n",
    "        #   strided_node_idx_i = [[\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3], \n",
    "        #                           [2, 3]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3],\n",
    "        #                           [2, 3]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [0, 3],\n",
    "        #                           [1, 3],\n",
    "        #                           [2, 3]\n",
    "        #                         ]]\n",
    "        #   strided_node_idx_j = [[\n",
    "        #                           [3, 4],\n",
    "        #                           [3, 4],\n",
    "        #                           [3, 4]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [2, 4],\n",
    "        #                           [2, 4],\n",
    "        #                           [2, 4]\n",
    "        #                         ],\n",
    "        #                         [\n",
    "        #                           [-1, -1],\n",
    "        #                           [-1, -1],\n",
    "        #                           [-1, -1]\n",
    "        #                         ]]\n",
    "        strided_node_idx_i = node_idx_i.unsqueeze(1).expand(-1, node_idx_j.size(1), -1, -1)\n",
    "        strided_node_idx_j = node_idx_j.unsqueeze(2).expand(-1, -1, node_idx_i.size(1), -1)\n",
    "        # Only create an higher order edge if the target node idx of the first edge is equal to\n",
    "        # the source node idx of the second edge\n",
    "        edge_mask = (strided_node_idx_i[:, :, :, 1:] == strided_node_idx_j[:, :, :, :-1]).all(dim=-1)\n",
    "        # Also, we need to remove the -1 padding values\n",
    "        padd_mask = (\n",
    "            (strided_node_idx_i[:, :, :] != -1).all(dim=-1) &\n",
    "            (strided_node_idx_j[:, :, :] != -1).all(dim=-1)\n",
    "        )\n",
    "        # For the above, the following mask is:\n",
    "        #\n",
    "        #   mask = [[True, True, True],\n",
    "        #           [False, False, False],\n",
    "        #           [False, False, False]]\n",
    "        mask = (edge_mask & padd_mask)\n",
    "        # Concetenate the remaining higher order edges to create a new edge index\n",
    "        higher_order_edges = torch.cat([strided_node_idx_i[mask].unsqueeze(0), strided_node_idx_j[mask].unsqueeze(0)], dim=0)\n",
    "        return higher_order_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [6, 5],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 5, 6, 5, 7]])\n",
    "# edge_index = torch.tensor([[0, 1, 2, 3, 4, 5, 6],\n",
    "                        #    [1, 2, 3, 4, 5, 6, 7]])\n",
    "node_idx = torch.arange(edge_index.max() + 1).reshape(-1, 1)\n",
    "node_idx_2, edge_index_2_fast = DeBruijnTransform()(node_idx, edge_index)\n",
    "print(edge_index_2_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5],\n",
      "         [1, 6]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7],\n",
      "         [6, 5]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_2 = pp.DAGData.lift_order_dag(edge_index.unsqueeze(-1))\n",
    "print(edge_index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print((edge_index_2.sort(dim=1)[0] == edge_index_2_fast.sort(dim=1)[0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd order\n",
    "Currently, the transformation works only with a standard edge index. The good thing is, you can still pass in the higher_order node_idx and then the output is directly a third order edge index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the edge index since the DeBruijnTransform only works for the normal edge index\n",
    "edges_2 = edge_index_2_fast.reshape(-1, 2)\n",
    "uniques, inverse_idx = edges_2.unique(dim=0, return_inverse=True)\n",
    "transformed_edge_index_2_fast = inverse_idx.reshape(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 3],\n",
      "         [0, 1, 6],\n",
      "         [0, 3, 4],\n",
      "         [1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5],\n",
      "         [3, 4, 5],\n",
      "         [6, 5, 7],\n",
      "         [4, 5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "node_idx_3, edge_index_3_fast = DeBruijnTransform()(node_idx_2, transformed_edge_index_2_fast)\n",
    "print(edge_index_3_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 3],\n",
      "         [0, 1, 6],\n",
      "         [0, 3, 4],\n",
      "         [1, 3, 4],\n",
      "         [3, 4, 5],\n",
      "         [1, 6, 5]],\n",
      "\n",
      "        [[1, 3, 4],\n",
      "         [1, 6, 5],\n",
      "         [3, 4, 5],\n",
      "         [3, 4, 5],\n",
      "         [4, 5, 7],\n",
      "         [6, 5, 7]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_3 = pp.DAGData.lift_order_dag(edge_index_2)\n",
    "print(edge_index_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponentionally Large DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 16.04it/s]\n"
     ]
    }
   ],
   "source": [
    "layers = 5\n",
    "branches = 15\n",
    "\n",
    "edges = []\n",
    "prev_layer_nodes = [0]\n",
    "j = 1\n",
    "for _ in trange(layers):\n",
    "    layer_nodes = []\n",
    "    for node in prev_layer_nodes:\n",
    "        for _ in range(branches):\n",
    "            layer_nodes.append(j)\n",
    "            edges.append((f\"{node}\", f\"{j}\"))\n",
    "            j+=1\n",
    "    prev_layer_nodes = layer_nodes\n",
    "\n",
    "dag = pp.Graph.from_edge_list(edges)\n",
    "dag_edge_index = dag.data.edge_index.unsqueeze(-1)\n",
    "\n",
    "node_idx = torch.arange(dag_edge_index.max().item() + 1).unsqueeze(-1)\n",
    "node_idx_gpu = node_idx.cuda()\n",
    "dag_edge_index_gpu = dag.data.edge_index.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 11s ± 877 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dag_edge_index_order_2 = pp.DAGData.lift_order_dag(dag_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing based implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642 ms ± 21.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit node_idx_2, dag_edge_index_order_2_fast = DeBruijnTransform()(node_idx, dag.data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing based implementation (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 ms ± 1.58 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit node_idx_2, dag_edge_index_order_2_fast = DeBruijnTransform()(node_idx_gpu, dag_edge_index_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((dag_edge_index_order_2.sort(dim=1)[0] == dag_edge_index_order_2_fast.sort(dim=1)[0]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/pathpyG/src/pathpyG/core/WalkDataNested.py:56: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  self.paths = nested_tensor(paths, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "n_walks = 1000\n",
    "walk_length = 100\n",
    "\n",
    "walks = [list(range(walk_length)) for _ in range(n_walks)]\n",
    "orig_walk = pp.WalkData()\n",
    "for walk in walks:\n",
    "    orig_walk.add_walk_seq(walk)\n",
    "\n",
    "path_list = list(orig_walk.paths.values())\n",
    "path_freq_tensor = torch.tensor(list(orig_walk.path_freq.values()))\n",
    "mapping = pp.IndexMap()\n",
    "nested_walk = pp.WalkDataNested(path_list, path_freq=path_freq_tensor, mapping=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Walk Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 ms ± 3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit orig_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor Implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.03 ms ± 449 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cpu\"\n",
    "%timeit nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.2 ms ± 4.72 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cuda\"\n",
    "cuda_path_list = [path.cuda() for path in path_list]\n",
    "cuda_path_freq = path_freq_tensor.cuda()\n",
    "cuda_nested_walk = pp.WalkDataNested(cuda_path_list, path_freq=cuda_path_freq, mapping=mapping)\n",
    "%timeit cuda_nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing Implementation (CPU + GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [Data(edge_index=path.long(), num_nodes=walk_length-1) for path in path_list]\n",
    "walk_graph = next(iter(DataLoader(data_list, batch_size=n_walks)))\n",
    "edge_index = walk_graph.edge_index\n",
    "node_idx = torch.arange(edge_index.max() + 1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 ms ± 2.55 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit node_idx_2, edge_index_2_fast = DeBruijnTransform()(node_idx, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.64 ms ± 154 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "cuda_edge_index = edge_index.cuda()\n",
    "cuda_node_idx = node_idx.cuda()\n",
    "%timeit node_idx_2, edge_index_2_fast = DeBruijnTransform()(cuda_node_idx, cuda_edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
