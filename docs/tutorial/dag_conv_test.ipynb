{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from time import time\n",
    "\n",
    "from tqdm import trange\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch_geometric import EdgeIndex\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.transforms import LineGraph\n",
    "from torch_geometric.utils import cumsum, coalesce, degree\n",
    "\n",
    "import pathpyG as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_order_edge_index(edge_index: EdgeIndex | torch.Tensor, num_nodes: int = None) -> torch.Tensor:\n",
    "    # Since this is a complicated function, we will use the following example to explain the steps:\n",
    "    # Example:\n",
    "    #   edge_index = [[0, 0, 1, 1, 1, 3, 4, 5, 6],\n",
    "    #                 [1, 3, 2, 3, 6, 4, 5, 7, 5]]\n",
    "\n",
    "    edges = edge_index.size(1)\n",
    "    if num_nodes is None:\n",
    "        num_nodes = int(edge_index.max().item() + 1)\n",
    "    if isinstance(edge_index, torch.Tensor):\n",
    "        edge_index = EdgeIndex(edge_index, sparse_size=(num_nodes, num_nodes))\n",
    "    if not edge_index.is_sorted_by_row:\n",
    "        edge_index = edge_index.sort_by(\"row\")[0]\n",
    "    \n",
    "    # Compute the outdegree of each node which we will use to get all the edge combinations that lead to a higher order edge\n",
    "    # Example:\n",
    "    #   outdegree = [2, 3, 0, 1, 1, 1, 1, 0]\n",
    "    outdegree = degree(edge_index[0], dtype=torch.long, num_nodes=num_nodes)\n",
    "\n",
    "    # For each center node, we need to combine each outgoing edge with each incoming edge\n",
    "    # We achieve this by creating `outdegree` number of edges for each destination node of the old edge index\n",
    "    # Example:\n",
    "    #   outdegree_per_dst = [3, 1, 0, 1, 1, 1, 1, 0, 1]\n",
    "    #   num_new_edges = 9\n",
    "    outdegree_per_dst = outdegree[edge_index[1]]\n",
    "    num_new_edges = outdegree_per_dst.sum()\n",
    "\n",
    "    # We use each edge from the edge index as new node and assign the new indices in the order of the original edge index\n",
    "    # Each higher order node has one outgoing edge for each outgoing edge of the original destination node\n",
    "    # Since we keep the ordering, we can just repeat each node using the outdegree_per_dst tensor\n",
    "    # Example:\n",
    "    #   ho_edge_srcs = [0, 0, 0, 1, 3, 4, 5, 6, 8]\n",
    "    ho_edge_srcs = torch.repeat_interleave(outdegree_per_dst)\n",
    "\n",
    "    # For each node, we calculate pointers of shape (num_nodes,) that indicate the start of the original edges (new higher order nodes) that have the node as source node\n",
    "    # (Note we use PyG's cumsum function because it adds a 0 at the beginning of the tensor and we want the `left` boundaries of the intervals, so we also remove the last element of the result with [:-1])\n",
    "    # Example:\n",
    "    #   ptrs = [0, 2, 5, 5, 6, 7, 8, 9]\n",
    "    ptrs = cumsum(outdegree, dim=0)[:-1]\n",
    "\n",
    "    # Use these pointers to get the start of the edges for each higher order source node and repeat it `outdegree` times\n",
    "    # Since we keep the ordering, all new higher order edges that have the same source node are indexed consecutively\n",
    "    # Example:\n",
    "    #   ho_edge_dsts = [2, 2, 2, 5, 5, 8, 6, 7, 7]\n",
    "    ho_edge_dsts = torch.repeat_interleave(ptrs[edge_index[1]], outdegree_per_dst)\n",
    "\n",
    "    # Since the above only repeats the start of the edges, we need to add (0, 1, 2, 3, ...) for all `outdegree` number of edges consecutively to get the correct destination nodes\n",
    "    # We can achieve this by starting with a range from (0, 1, ..., num_new_edges)\n",
    "    # Example: \n",
    "    #   idx_correction    = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    idx_correction = torch.arange(num_new_edges, dtype=torch.long, device=edge_index.device)\n",
    "    # Then, we subtract the cumulative sum of the outdegree for each destination node to get a tensor.\n",
    "    # Example:\n",
    "    #   idx_correction    = [0, 1, 2, 0, 0, 0, 0, 0, 0]\n",
    "    idx_correction -= cumsum(outdegree_per_dst, dim=0)[ho_edge_srcs]\n",
    "    # Finally, we add this tensor to the destination nodes to get the correct destination nodes for each higher order edge\n",
    "    # Example:\n",
    "    #   ho_edge_dsts = [2, 3, 4, 5, 5, 8, 6, 7, 7]\n",
    "    ho_edge_dsts += idx_correction\n",
    "# tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n",
    "#         [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n",
    "    return torch.stack([ho_edge_srcs, ho_edge_dsts], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General evaluation of correctness and runtime\n",
    "\n",
    "The PyG version on the GPU is omitted since it takes even longer than the CPU version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 50000, Edges: 500000\n",
      "\tGNN baseline: 0.030921459197998047s\n",
      "\tPyG: 5.057637929916382s\n",
      "\tIndexing: 0.0286409854888916s\n",
      "\tCUDA GNN baseline: 0.21027898788452148s\n",
      "\tCUDA Indexing: 0.021584033966064453s\n",
      "Nodes: 50000, Edges: 1000000\n",
      "\tGNN baseline: 0.05266857147216797s\n",
      "\tPyG: 10.635715246200562s\n",
      "\tIndexing: 0.11666655540466309s\n",
      "\tCUDA GNN baseline: 0.0031747817993164062s\n",
      "\tCUDA Indexing: 0.34000468254089355s\n",
      "Avg PyG time: 7.846676588058472s +/- 2.78903865814209s\n",
      "Avg Indexing time: 0.07265377044677734s +/- 0.04401278495788574s\n",
      "Avg CUDA Indexing time: 0.180794358253479s +/- 0.15921032428741455s\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.testing import get_random_edge_index\n",
    "\n",
    "gnn_conv = SAGEConv(128, 16)\n",
    "cuda_gnn_conv = SAGEConv(128, 16).to(\"cuda\")\n",
    "line_graph_transform = LineGraph(force_directed=True)\n",
    "\n",
    "GNN_baseline_times, cuda_GNN_baseline_times = [], []\n",
    "PyG_times, MP_times, indexing_times = [], [], []\n",
    "cuda_PyG_times, cuda_MP_times, cuda_indexing_times = [], [], []\n",
    "for i in range(50, 51, 50):\n",
    "    num_nodes = 1000*i\n",
    "    x = torch.randn(num_nodes, 128)\n",
    "    cuda_x = x.to(\"cuda\")\n",
    "    for j in range(10, 21, 10):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        num_edges = num_nodes*j\n",
    "        print(f\"Nodes: {num_nodes}, Edges: {num_edges}\")\n",
    "        edge_index = get_random_edge_index(num_nodes, num_nodes, num_edges)\n",
    "        edge_index = EdgeIndex(edge_index, sparse_size=(num_nodes, num_nodes))\n",
    "        edge_index = coalesce(edge_index, num_nodes=num_nodes)\n",
    "\n",
    "        # GNN baseline\n",
    "        \n",
    "        t = time()\n",
    "        gnn_conv(x, edge_index)\n",
    "        GNN_baseline_times.append(time() - t)\n",
    "        print(f\"\\tGNN baseline: {GNN_baseline_times[-1]}s\")\n",
    "\n",
    "        t = time()\n",
    "        PyG_line_graph_data = line_graph_transform(Data(edge_index=edge_index, num_nodes=num_nodes))\n",
    "        PyG_times.append(time() - t)\n",
    "        PyG_line_graph = PyG_line_graph_data.edge_index\n",
    "        print(f\"\\tPyG: {PyG_times[-1]}s\")\n",
    "\n",
    "        t = time()\n",
    "        indexing_line_graph = lift_order_edge_index(edge_index, num_nodes)\n",
    "        indexing_times.append(time() - t)\n",
    "        print(f\"\\tIndexing: {indexing_times[-1]}s\")\n",
    "\n",
    "        cuda_edge_index = edge_index.to(\"cuda\")\n",
    "\n",
    "        t = time()\n",
    "        cuda_gnn_conv(cuda_x, cuda_edge_index)\n",
    "        cuda_GNN_baseline_times.append(time() - t)\n",
    "        print(f\"\\tCUDA GNN baseline: {cuda_GNN_baseline_times[-1]}s\")\n",
    "\n",
    "        # t = time()\n",
    "        # cuda_PyG_line_graph_data = line_graph_transform(Data(edge_index=cuda_edge_index, num_nodes=num_nodes))\n",
    "        # cuda_PyG_times.append(time() - t)\n",
    "        # cuda_PyG_line_graph = cuda_PyG_line_graph_data.edge_index\n",
    "        # print(f\"\\tCUDA PyG: {cuda_PyG_times[-1]}s\")\n",
    "\n",
    "        t = time()\n",
    "        cuda_indexing_line_graph = lift_order_edge_index(cuda_edge_index, num_nodes)\n",
    "        cuda_indexing_times.append(time() - t)\n",
    "        print(f\"\\tCUDA Indexing: {cuda_indexing_times[-1]}s\")\n",
    "\n",
    "        if not (PyG_line_graph == indexing_line_graph).all():\n",
    "            print(f\"Iteration {i}: Indexing and PyG are not equal\")\n",
    "            print(PyG_line_graph)\n",
    "            print(indexing_line_graph)\n",
    "            print((PyG_line_graph != indexing_line_graph).nonzero())\n",
    "            print(edge_index)\n",
    "            break\n",
    "\n",
    "print(f\"Avg PyG time: {np.mean(PyG_times)}s +/- {np.std(PyG_times)}s\")\n",
    "print(f\"Avg Indexing time: {np.mean(indexing_times)}s +/- {np.std(indexing_times)}s\")\n",
    "# print(f\"Avg CUDA PyG time: {np.mean(cuda_PyG_times)}s +/- {np.std(cuda_PyG_times)}s\")\n",
    "print(f\"Avg CUDA Indexing time: {np.mean(cuda_indexing_times)}s +/- {np.std(cuda_indexing_times)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 5, 6, 5, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [0, 1],\n",
      "         [0, 1],\n",
      "         [0, 3],\n",
      "         [1, 3],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [6, 5],\n",
      "         [1, 6]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [1, 3],\n",
      "         [1, 6],\n",
      "         [3, 4],\n",
      "         [3, 4],\n",
      "         [4, 5],\n",
      "         [5, 7],\n",
      "         [5, 7],\n",
      "         [6, 5]]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_2 = pp.DAGData.lift_order_dag(edge_index.unsqueeze(-1))\n",
    "print(edge_index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n",
      "        [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_new = lift_order_edge_index(EdgeIndex(edge_index))\n",
    "print(edge_index_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 1, 3, 4, 5, 6, 8],\n",
      "        [2, 3, 4, 5, 5, 8, 6, 7, 7]])\n"
     ]
    }
   ],
   "source": [
    "edge_index_pyg = LineGraph()(Data(edge_index=edge_index, num_nodes=8)).edge_index\n",
    "print(edge_index_pyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print((edge_index_pyg == edge_index_new).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Edge Weights (TODO)\n",
    "\n",
    "Depending on how you count each walk, you will get different statistics. We can choose the aggregation via `freq_aggr` to be either \"propagation\", i.e. each walk counts with its weight, or \"diffusion\" i.e. each walk is counted with the probability of a random walker starting at the first node to end up in the last. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 0, 1, 1, 3, 4, 1, 6, 5],\n",
    "                           [1, 3, 2, 3, 4, 5, 6, 5, 7]])\n",
    "edge_attr = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponentionally Large DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 20.25it/s]\n"
     ]
    }
   ],
   "source": [
    "layers = 5\n",
    "branches = 15\n",
    "\n",
    "edges = []\n",
    "prev_layer_nodes = [0]\n",
    "j = 1\n",
    "for _ in trange(layers):\n",
    "    layer_nodes = []\n",
    "    for node in prev_layer_nodes:\n",
    "        for _ in range(branches):\n",
    "            layer_nodes.append(j)\n",
    "            edges.append((f\"{node}\", f\"{j}\"))\n",
    "            j+=1\n",
    "    prev_layer_nodes = layer_nodes\n",
    "\n",
    "dag = pp.Graph.from_edge_list(edges)\n",
    "dag_edge_index = dag.data.edge_index.unsqueeze(-1)\n",
    "\n",
    "dag_edge_index_gpu = dag.data.edge_index.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 14s ± 1.2 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pp.DAGData.lift_order_dag(dag_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Indexing based implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6 ms ± 155 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(dag.data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Indexing based implementation (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 ms ± 43.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(dag_edge_index_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyG implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.04 s ± 634 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit line_graph_transform(dag.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG implementation (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 55s ± 43 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit line_graph_transform(dag.data.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/pathpyG/src/pathpyG/core/WalkDataNested.py:56: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  self.paths = nested_tensor(paths, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "n_walks = 10000\n",
    "walk_length = 1000\n",
    "\n",
    "walks = [list(range(walk_length)) for _ in range(n_walks)]\n",
    "orig_walk = pp.WalkData()\n",
    "for walk in walks:\n",
    "    orig_walk.add_walk_seq(walk)\n",
    "\n",
    "path_list = list(orig_walk.paths.values())\n",
    "path_freq_tensor = torch.tensor(list(orig_walk.path_freq.values()))\n",
    "mapping = pp.IndexMap()\n",
    "nested_walk = pp.WalkDataNested(path_list, path_freq=path_freq_tensor, mapping=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Walk Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.3 s ± 9.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit orig_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor Implementation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459 ms ± 17.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cpu\"\n",
    "%timeit nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Tensor (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394 ms ± 51.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pp.config['torch'][\"device\"] = \"cuda\"\n",
    "cuda_path_list = [path.cuda() for path in path_list]\n",
    "cuda_path_freq = path_freq_tensor.cuda()\n",
    "cuda_nested_walk = pp.WalkDataNested(cuda_path_list, path_freq=cuda_path_freq, mapping=mapping)\n",
    "%timeit cuda_nested_walk.edge_index_k_weighted(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing Implementation (CPU + GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a list of Data objects where each Data object contains the edge index of a path (could also be a DAG in theory)\n",
    "data_list = [Data(edge_index=path.long(), num_nodes=walk_length) for path in path_list]\n",
    "# We use a dataloader from PyG to combine all the edge indices into a single graph with multiple disjoint subgraphs\n",
    "# If two paths share a node, the node is duplicated in the resulting graph and the new higher order edges need to be aggregated afterwards\n",
    "# Note that due to the `batch_size` parameter, we can also do computations on a set of paths that are too large to fit into memory at once\n",
    "walk_graph = next(iter(DataLoader(data_list, batch_size=n_walks)))\n",
    "edge_index = walk_graph.edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following measures the time to do the LineGraph graph transformation for the edge index that contains all paths as disjunct subgraphs. Since the aggregations afterwards are omitted, the runtimes are not exactly comparable to the above. See the next section (With Weights and the Aggregation) for a full `edge_index_k_weighted` transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 ms ± 42.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.8 ms ± 1.38 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "cuda_edge_index = edge_index.cuda()\n",
    "%timeit lift_order_edge_index(cuda_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG Implementation (CPU + GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 19s ± 2.58 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit line_graph_transform(walk_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit line_graph_transform(walk_graph.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Weights and the Aggregation (TODO: Change to indexing based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def edge_index_k_weighted(path_list, path_freq, aggregation=\"propagation\", device=\"cuda\"):\n",
    "#     data_list = [\n",
    "#         Data(\n",
    "#             edge_index=path.long(), \n",
    "#             num_nodes=walk_length,\n",
    "#             edge_attr=torch.ones(path.size(1), dtype=torch.float32) * path_freq[i],\n",
    "#             node_idx=torch.arange(walk_length).unsqueeze(-1)\n",
    "#         ) for i, path in enumerate(path_list)\n",
    "#         ]\n",
    "#     walk_graph = next(iter(DataLoader(data_list, batch_size=n_walks, follow_batch=[\"node_idx\"]))).to(device)\n",
    "#     edge_index = walk_graph.edge_index\n",
    "#     edge_attr = walk_graph.edge_attr\n",
    "#     node_idx = torch.arange(edge_index.max() + 1, device=device).unsqueeze(-1)\n",
    "#     edge_index_2, edge_attr_2 = DeBruijnTransform(aggregation)(node_idx, edge_index, edge_attr)\n",
    "#     orig_edge_index_2 = walk_graph.node_idx.squeeze()[edge_index_2]\n",
    "#     unique_edge_index_2, inverse_idx = orig_edge_index_2.unique(dim=1, return_inverse=True)\n",
    "#     edge_attr_2 = torch.zeros(unique_edge_index_2.size(1), device=device).index_add(0, inverse_idx, edge_attr_2)\n",
    "#     return unique_edge_index_2, edge_attr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit edge_index_k_weighted(path_list, path_freq_tensor, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Graph Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw file found, skipping download\n",
      "Dataset directory is  /opt/conda/lib/python3.10/site-packages/tgb/datasets/tgbl_wiki\n",
      "loading processed file\n"
     ]
    }
   ],
   "source": [
    "# !pip install py-tgb\n",
    "\n",
    "from torch_geometric.edge_index import EdgeIndex, SortOrder\n",
    "from tgb.linkproppred.dataset_pyg import PyGLinkPropPredDataset\n",
    "\n",
    "from pathpyG import TemporalGraph\n",
    "from pathpyG.algorithms import temporal_graph_to_event_dag\n",
    "\n",
    "dataset = PyGLinkPropPredDataset(name=\"tgbl-wiki\", root=\"datasets\")\n",
    "data = dataset.get_TemporalData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = EdgeIndex(data.edge_index, sparse_size=(data.num_nodes, data.num_nodes))\n",
    "edge_index._sort_order = SortOrder.ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 ms ± 36.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(edge_index, num_nodes=data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal graph to event DAG: 5.8s\n"
     ]
    }
   ],
   "source": [
    "temporal_graph = TemporalGraph(data)\n",
    "t = time()\n",
    "temporal_graph_to_event_dag(temporal_graph, delta=100)\n",
    "print(f\"Temporal graph to event DAG: {time() - t:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw file found, skipping download\n",
      "Dataset directory is  /opt/conda/lib/python3.10/site-packages/tgb/datasets/tgbl_review\n",
      "loading processed file\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "large_dataset = PyGLinkPropPredDataset(name=\"tgbl-review\", root=\"datasets\")\n",
    "large_data = large_dataset.get_TemporalData()\n",
    "print(large_data.is_coalesced())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_edge_index = EdgeIndex(large_data.edge_index, sparse_size=(large_data.num_nodes, large_data.num_nodes))\n",
    "large_edge_index._sort_order = SortOrder.ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.43 s ± 37.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit lift_order_edge_index(large_edge_index, num_nodes=large_data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "large_temporal_graph = TemporalGraph(large_data)\n",
    "t = time()\n",
    "temporal_graph_to_event_dag(large_temporal_graph)\n",
    "print(f\"Temporal graph to event DAG: {time() - t:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
