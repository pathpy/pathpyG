{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pathpyG Concepts\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "First, we need to set up our Python environment that has PyTorch, PyTorch Geometric and PathpyG installed. Depending on where you are executing this notebook, this might already be (partially) done. E.g. Google Colab has PyTorch installed by default so we only need to install the remaining dependencies. The DevContainer that is part of our GitHub Repository on the other hand already has all of the necessary dependencies installed. \n",
    "\n",
    "In the following, we install the packages for usage in Google Colab using Jupyter magic commands. For other environments comment in or out the commands as necessary. For more details on how to install `pathpyG` especially if you want to install it with GPU-support, we refer to our [documentation](https://www.pathpy.net/dev/getting_started/). Note that `%%capture` discards the full output of the cell to not clutter this tutorial with unnecessary installation details. If you want to print the output, you can comment `%%capture` out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip install torch\n",
    "!pip install torch_geometric\n",
    "!pip install git+https://github.com/pathpy/pathpyG.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation and Learning Objectives\n",
    "\n",
    "This first step of our multi-stage introductory tutorial introduces key concepts of `pathpyG`. While `pathpyG` targets GPU-accelerated analysis and learning using higher-order graph models for time series data on graphs, it can also be used to represent, analyze and interactively visualize static graphs. For this, it provides a `Graph` class that is build around the `torch_geometric.data.Data` object, which has the advantage that we can directly apply `pyG` transforms and use the `Graph` object for deep graph learning.\n",
    "\n",
    "In this tutorial you will learn how we can use `pathpyG` to represent static graphs. We start with basic features to create directed and undirected graphs with node-, edge-, and graph-level attributes. We also show how we can read and write graph data and how we can implement graph algorithms that are based on a traversal of nodes and edges.\n",
    "\n",
    "We first import the modules `torch`, `torch_geometric` and `pathpyG`. By setting the device used by `torch`, we specify whether we want to run our code on the CPU or on the GPU. For a CPU-based execution, set the `torch.device` configuration to `cpu`. Set the device to `cuda` if you want to run it on the GPU instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as pyG\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "\n",
    "import pathpyG as pp\n",
    "pp.config['torch']['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Graph objects\n",
    " \n",
    "Let's start by generating a simple, directed graph with three nodes `a`, `b`, `c` and three edges `(a,b)`, `(b,c)` and `(a,b)`. The three nodes `a`, `b`, and `c` can be represented by integer indices $0, 1$ and $2$ respectively. Following the tensor-based representation in `pyG`, we use an `edge_index` tensor with shape `(2,m)` to represent the `m` edges of a graph.\n",
    "We can then add this to a `Data` object that can hold additional node and edge attributes. We finally pass the `Data` object to the constructor of the `Graph` class.\n",
    "\n",
    "Using the mapping of node names to indices specified above, the following code generates a directed `Graph` with three edges `(a,c)`, `(b,c)` and `(a,b)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 3 nodes and 3 edges\n",
      "{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"<class 'int'>\"}, 'Node Attributes': {}}\n"
     ]
    }
   ],
   "source": [
    "d = Data(edge_index = torch.tensor([[0,1,0], [2,2,1]]))\n",
    "g = pp.Graph(d)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not need additional node or edge attributes, we can use the class function `Graph.from_edge_index` to directly create a graph based on an edge index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 3 nodes and 3 edges\n",
      "{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"<class 'int'>\"}, 'Node Attributes': {}}\n"
     ]
    }
   ],
   "source": [
    "g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]))\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to inlude isolated nodes that do not have an edge. We can do so by passing a `num_nodes` parameter. The following graph thus contains a fourth node (which we could name as `d`) that is not connected to any of the other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 4 nodes and 3 edges\n",
      "{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"<class 'int'>\"}, 'Node Attributes': {}}\n"
     ]
    }
   ],
   "source": [
    "g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes=4)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases, the `Graph` instance has a property `g.data` that stores a `pyG` `Data` object that includes the edge index as well as any further node-, edge- or graph-level attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 3], num_nodes=4, node_sequence=[4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(g.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `edge_index` is actually of type `pyG.EdgeIndex`, which is a subclass of `torch.Tensor`. Any tensor passed as an edge index in the constructor of `Graph` will automatically be converted to an `EdgeIndex` instance, as this internally allows us to provide efficient edge traveral routines based on sparse matrix operations. To support this, the edge index will be automatically sorted by row when the `Graph` object is created. To avoid this additional sort operation, you can pass an already sorted `EdgeIndex` object in the `Data` object in the constructor or using the `from_edge_index` class function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeIndex([[0, 0, 1],\n",
      "           [2, 1, 2]], sparse_size=(4, 4), nnz=3, sort_order=row)\n"
     ]
    }
   ],
   "source": [
    "print(g.data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the generators `nodes` and `edges` to iterate through the nodes and edges of a graph as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "(0, 2)\n",
      "(0, 1)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "for v in g.nodes:\n",
    "    print(v)\n",
    "\n",
    "for e in g.edges:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the index-based representation of nodes allows for efficient tensor-based operations, it is often more convenient to use string identifiers to refer to nodes. To simplify the handling of graphs with such string node identifiers, `pathpyG` provides a class `IndexMap` that transparently maps string identifiers to integer indices. For our small example graph, we can create an `IndexMap` that associates node indices with string IDs. For our example, we can create a mapping as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a -> 0\n",
      "b -> 1\n",
      "c -> 2\n",
      "d -> 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = pp.IndexMap(['a', 'b', 'c', 'd'])\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the functions `IndexMap.to_id` or `IndexMap.to_idx` to map a node to an index or an ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.to_id(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.to_idx('b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pathpyG` actually makes this mapping transparent for the user. For this, we can add our mapping to the `Graph` object, either by passing it in the constructor or by setting the `mapping` attribute of an existing `Graph` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.mapping = m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now iterate through the nodes and edges of the graph, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "('a', 'c')\n",
      "('a', 'b')\n",
      "('b', 'c')\n"
     ]
    }
   ],
   "source": [
    "for v in g.nodes:\n",
    "    print(v)\n",
    "\n",
    "for e in g.edges:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can achieve the same result if we pass the `IndexMap` object in the constructor of a graph. This transparently applies the mapping in all future function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 4 nodes and 3 edges\n",
      "{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"<class 'int'>\"}, 'Node Attributes': {}}\n"
     ]
    }
   ],
   "source": [
    "g = pp.Graph.from_edge_index(torch.tensor([[0,1,0], [2,2,1]]), num_nodes = 4, mapping=m)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have created a graph based on an edge index tensor and we then additionally applied a mapping that we manually defined. We often have data in the form on an edge list, where edges are given as tuples of non-numeric node identifiers. The class function `Graph.from_edge_list` simplifies the construction of a `Graph` from such edge lists. This will automatically generate an internal integer-based representation of the edge index, as well as the associated `IndexMap`, where the integer node indices are based on the lexicographic order of node IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 3 nodes and 3 edges\n",
      "{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"<class 'int'>\"}, 'Node Attributes': {}}\n",
      "EdgeIndex([[0, 0, 1],\n",
      "           [1, 2, 2]], sparse_size=(3, 3), nnz=3, sort_order=row)\n",
      "a -> 0\n",
      "b -> 1\n",
      "c -> 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')])\n",
    "print(g)\n",
    "print(g.data.edge_index)\n",
    "print(g.mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could alternatively pass a custom index mapping, e.g. mapping node `c` to idex 1 and node `b` to index 2 (thus deviating from a lexicographic order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeIndex([[0, 0, 2],\n",
      "           [2, 1, 1]], sparse_size=(3, 3), nnz=3, sort_order=row)\n",
      "a -> 0\n",
      "c -> 1\n",
      "b -> 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = pp.Graph.from_edge_list([('a','b'), ('a','c'), ('b','c')], mapping = pp.IndexMap(['a', 'c', 'b']))\n",
    "print(g.data.edge_index)\n",
    "print(g.mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traversing Graphs\n",
    "\n",
    "\n",
    "The `Graph` object provides `get_successors` and `get_predecessors` functions, which return the indices of nodes that are connected to a node with a given index. Based on cached CSR (compressed sparse row) and CSC (compressed sparse column) representations cached for the sorted `EdgeIndex`, access to the successors and predecessors of a node works in constant time, i.e. it does not require to enumerate the `edge_index` tensor.\n",
    "\n",
    "\n",
    "For node `a` with index $0$ in our directed network we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_successors(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], dtype=torch.int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_predecessors(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, even if a mapping is defined, the `get_successors` and `get_predecessors` functions always return a tensor with node indices, rather than node IDs. This is useful to support fast tensor-based operations on the list of successors and predecessors. We could always manually map the node indices using the `IndexMap` object defined in the `mapping` attribute.\n",
    "\n",
    "If we want to traverse graphs based on string node IDs, we can use the `successors` and `predecessors` generators of the `Graph` object, which -- if an ID-Index mapping is defined - yield the string labels of successor or predecessor nodes for a given node (also identified by its string label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "for v in g.successors('a'):\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "for v in g.predecessors('c'):\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check (again in constant time) whether an edge exists in the graph, we can call the `is_edge` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.is_edge('a', 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the following function to check (in constant time) whether node `b` is a successor of `a`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'b' in g.successors('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, graph objects in `pathpyG` are directed, i.e. for the graph above, the edge `(b,a)` does not exist, which we can verify as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print('a' in g.successors('b'))\n",
    "print(g.is_edge('b', 'a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate (directed) in- and out-degrees of nodes, we can use the properties `in_degrees` and `out_degrees`, which return a dictionary that maps node IDs to their degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'c': 2, 'b': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.in_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.in_degrees['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.in_degrees['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.in_degrees['c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, irrespective of how we have generated the graph object, the actual node and edge data are always stored as a `pyG` data object. This allows us to use the full power of `torch` and `pyG`, including the application of transforms, splits, or any easy migration between CPU and GPU-based computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 3], num_nodes=3, node_sequence=[3, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, `pathpyG` will use the device specified in the `torch.device` configuration (see above) whenver it internally creates a torch tensor. Since above, we have specified the `cpu` device, the data object of the graph generated above will reside in main memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.data.is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we instead set the device to `cuda`, the `Data` object will internally be created in main memory instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.config['torch']['device'] = 'cuda'\n",
    "\n",
    "g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('a','c')])\n",
    "g.data.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.config['torch']['device'] = 'cpu'\n",
    "g.data = g.data.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node-, Edge- or Graph-Level Attributes\n",
    "\n",
    "Real-world graphs often have node-, edge-, or graph-level attributes. In `pathpyG`, we can add attributes as tensors, either by directly assigning them to the `pyG` data object of an existing graph (or by adding them to the `Data` object passed to the constructor). Following the `pyG` semantics of attribute names, we use the prefixes `node_` and `edge_` to refer to node- and edge-level attributes. Attributes without those prefixes are assumed to refer to graph-level attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.data['node_class'] = torch.tensor([[0], [0], [1]], device=pp.config['torch']['device'])\n",
    "g.data['edge_weight'] = torch.tensor([[1], [2], [3]], device=pp.config['torch']['device'])\n",
    "g.data['feature'] = torch.tensor([3, 2], device=pp.config['torch']['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have added attributes to nodes, edges, or the graph, those attributes, along with their type and shape will be shown when you print a string representation of the graph object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 3 nodes and 3 edges\n",
      "{   'Edge Attributes': {'edge_weight': \"<class 'torch.Tensor'> -> torch.Size([3, 1])\"},\n",
      "    'Graph Attributes': {'feature': \"<class 'torch.Tensor'> -> torch.Size([2])\", 'num_nodes': \"<class 'int'>\"},\n",
      "    'Node Attributes': {'node_class': \"<class 'torch.Tensor'> -> torch.Size([3, 1])\"}}\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify access to attribute values, the `Graph` class provides getter and setter functions that allow to access attribute values based on node identifiers. To access the feature `node_feature` of node `a`, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['node_class', 'a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the weight of edge `(a, b)` we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['edge_weight', 'a', 'b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, graph-based attributes can accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['feature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the setter functions to change attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "g['node_class'] = torch.tensor([[7], [2], [3]], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g['node_class', 'a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create sparse adjacency matrix representations of graphs, we can use the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (1, 2)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(g.sparse_adj_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a `scipy.sparse.coo_matrix` object, which can be turned into a dense `numpy` matrix as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(g.sparse_adj_matrix().todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By passing the name of the attribute, we can use edge attributes in the creation of the adjacency matrix. To create a sparse, weighted adjacency matrix that uses the `edge_weight` attribute of our graph object we can simply write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [0 0 3]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(g.sparse_adj_matrix(edge_attr='edge_weight').todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, graphs in `pathpyG` are directed. To represent undirected edges, we must add edges in both directions. We can use the `to_undirected()` function to make a directed graph undirected, which adds all (missing) edges that point in the opposite direction. This will also automatically duplicate and assign the corresponding edge attributes to the newly formed (directed) edges, i.e. edges are assumed to have the same attributes in both directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undirected graph with 3 nodes and 6 (directed) edges\n",
      "{   'Edge Attributes': {'edge_weight': \"<class 'torch.Tensor'> -> torch.Size([6, 1])\"},\n",
      "    'Graph Attributes': {'feature': \"<class 'torch.Tensor'> -> torch.Size([2])\", 'num_nodes': \"<class 'int'>\"},\n",
      "    'Node Attributes': {'node_class': \"<class 'torch.Tensor'> -> torch.Size([3, 1])\"}}\n"
     ]
    }
   ],
   "source": [
    "g_u = g.to_undirected()\n",
    "print(g_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the `Graph` object can contain multiple identical edges, so the following is possible: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeIndex([[0, 0, 1, 2],\n",
      "           [1, 1, 2, 0]], sparse_size=(3, 3), nnz=4, sort_order=row)\n"
     ]
    }
   ],
   "source": [
    "g = pp.Graph.from_edge_list([('a', 'b'), ('b', 'c'), ('c', 'a'), ('a', 'b')])\n",
    "print(g.data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often convenient, to coalesce multi-edges into weighted single-edges, i.e. in the example above we may prefer a graph where each edge occurs once in the edge index, but the edge `a->b` has a weight attribute of two, while the two other edges have one.\n",
    "\n",
    "In `pathpyG` we can do this by turning a graph into a weighted graph, which will coalesce edges and add an edge weight attribute that counts multi-edges in the original istance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeIndex([[0, 1, 2],\n",
      "           [1, 2, 0]], sparse_size=(3, 3), nnz=3, sort_order=row)\n",
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "g_w = g.to_weighted_graph()\n",
    "print(g_w.data.edge_index)\n",
    "print(g_w['edge_weight', 'a', 'b'])\n",
    "print(g_w['edge_weight', 'b', 'c'])\n",
    "print(g_w['edge_weight', 'c', 'a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see in a separate notebook focusing on the advanced (temporal) graph visualization features of `pathpyG`, it is easy to generate (interactive) HTML plots of graphs, that are embedded into jupyter notebooks. You can simply call the `pp.plot` function on the Graph object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "svg circle.node {\n",
       "  fill: #3b5998;\n",
       "  stroke: #1b3978;\n",
       "  stroke-width: 2.5px;\n",
       "  r: 15px;\n",
       "  opacity: 1;\n",
       "}\n",
       "\n",
       ".link {\n",
       "  stroke: #969595;\n",
       "  stroke-opacity: .75;\n",
       "  stroke-width: 2.5px;\n",
       "}\n",
       "\n",
       ".arrow {\n",
       "  fill: #969595;\n",
       "}\n",
       "\n",
       "\n",
       ".label-text {\n",
       "    fill: #969595;\n",
       "    font-size: 16px;\n",
       "    font-family: sans-serif;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<div id = \"x4f7a283db6ba42338a87215d0b9e8a8d\"> </div>\n",
       "<script charset=\"utf-8\" src=\"https://d3js.org/d3.v5.min.js\"></script>\n",
       "<script charset=\"utf-8\">\n",
       "// Load via requireJS if available (jupyter notebook environment)\n",
       "try {\n",
       "    // Problem: require.config will raise an exception when called for the second time \n",
       "    require.config({\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v5.min.js\".replace(\".js\", \"\")\n",
       "        }\n",
       "    });\n",
       "    console.log(\"OKAY: requireJS was detected.\");\n",
       "}\n",
       "catch(err){\n",
       "    // a reference error indicates that requireJS does not exist. \n",
       "    // other errors may occur due to multiple calls to config\n",
       "    if (err instanceof ReferenceError){\n",
       "        console.log(\"WARNING: NO requireJS was detected!\");\n",
       "\n",
       "        // Helper function that waits for d3js to be loaded\n",
       "        require = function require(symbols, callback) {\n",
       "            var ms = 10;\n",
       "            window.setTimeout(function(t) {\n",
       "                if (window[symbols[0]])\n",
       "                    callback(window[symbols[0]]);\n",
       "                else \n",
       "                    window.setTimeout(arguments.callee, ms);\n",
       "            }, ms);\n",
       "        }\n",
       "    }\n",
       "};\n",
       "require(['d3'], function(d3){ //START\n",
       "const data = {\"edges\": [{\"uid\": \"a-b\", \"source\": \"a\", \"target\": \"b\", \"color\": \"gray\", \"weight\": 1}, {\"uid\": \"b-c\", \"source\": \"b\", \"target\": \"c\", \"color\": \"gray\", \"weight\": 1}, {\"uid\": \"c-a\", \"source\": \"c\", \"target\": \"a\", \"color\": \"gray\", \"weight\": 1}], \"nodes\": [{\"uid\": \"a\", \"label\": \"a\"}, {\"uid\": \"b\", \"label\": \"b\"}, {\"uid\": \"c\", \"label\": \"c\"}]}\n",
       "const config = {\"edge_color\": \"gray\", \"node_label\": [\"a\", \"b\", \"c\"], \"directed\": true, \"curved\": true, \"selector\": \"#x4f7a283db6ba42338a87215d0b9e8a8d\"}\n",
       "console.log(\"Static Network Template\");\n",
       "/* Resources\n",
       "   https://bl.ocks.org/mapio/53fed7d84cd1812d6a6639ed7aa83868\n",
       "   https://codepen.io/smlo/pen/JdMOej\n",
       "*/\n",
       "\n",
       "// variables from the config file\n",
       "const selector = config.selector;\n",
       "const width = config.width || 800;\n",
       "const height = config.height || 600;\n",
       "const charge_distance = config.charge_distance || 400;\n",
       "const charge_force = config.charge_force || -3000;\n",
       "const curved = config.curved || false;\n",
       "const directed = config.directed || false;\n",
       "// const weight = false;\n",
       "\n",
       "/* Create a svg element to display the network */\n",
       "var svg = d3.select(selector)\n",
       "    .append('svg')\n",
       "    .attr('width', width)\n",
       "    .attr('height', height)\n",
       "\n",
       "// add container to store the elements\n",
       "var container = svg.append(\"g\");\n",
       "\n",
       "/*Add zoom function to the container */\n",
       "svg.call(\n",
       "    d3.zoom()\n",
       "        .scaleExtent([.1, 4])\n",
       "        .on(\"zoom\", function() { container.attr(\"transform\", d3.event.transform); })\n",
       ");\n",
       "\n",
       "\n",
       "/*Load nodes and links from the data */\n",
       "var nodes = data.nodes\n",
       "var links = data.edges\n",
       "\n",
       "/*Create arrow head with same color as the edge */\n",
       "function marker (color) {\n",
       "       var reference;\n",
       "       svg.append(\"svg:defs\").selectAll(\"marker\")\n",
       "          .data([reference])\n",
       "          .enter().append(\"svg:marker\")\n",
       "          .attr(\"id\", \"arrow\"+color)\n",
       "          .attr(\"viewBox\", \"0 -5 10 10\")\n",
       "          .attr(\"refX\", 10)\n",
       "          .attr(\"refY\", -0)\n",
       "          .attr(\"markerWidth\", 6)\n",
       "          .attr(\"markerHeight\", 6)\n",
       "          .attr(\"orient\", \"auto\")\n",
       "          .append(\"svg:path\")\n",
       "          .attr('class','.arrow')\n",
       "          .attr(\"d\", \"M0,-5L10,0L0,5\")\n",
       "          .style('opacity',1)\n",
       "          .style(\"fill\", color);\n",
       "       return \"url(#\" + \"arrow\"+color + \")\";\n",
       "     };\n",
       "\n",
       "/*Link creation template */\n",
       "var link = container.append(\"g\").attr(\"class\", \"links\")\n",
       "    .selectAll(\".link\")\n",
       "    .data(links)\n",
       "    .enter()\n",
       "    .append(\"path\")\n",
       "    .attr(\"class\", \"link\")\n",
       "    .style(\"stroke\", function(d) { return d.color; })\n",
       "    .style(\"stroke-opacity\", function(d) { return d.opacity; })\n",
       "    .style(\"stroke-width\", function(d){  return d.size })\n",
       "    .style(\"fill\",\"none\")\n",
       "    .attr(\"marker-end\", function (d) {if(directed){return marker(d.color)}else{return null}; });\n",
       "\n",
       "    //.attr(\"marker-end\", function (d) { return marker(d.color); });\n",
       "    //.attr(\"marker-end\", \"url(#arrow)\");\n",
       "\n",
       "/*Node creation template */\n",
       "var node = container.append(\"g\").attr(\"class\", \"nodes\")\n",
       "    .selectAll(\"circle.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"circle\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"x\", function(d) { return d.x; })\n",
       "    .attr(\"y\", function(d) { return d.y; })\n",
       "    .style(\"r\", function(d){  return d.size+\"px\"; })\n",
       "    .style(\"fill\", function(d) { return d.color; })\n",
       "    .style(\"opacity\", function(d) { return d.opacity; });\n",
       "\n",
       "/*Label creation template */\n",
       "var text = container.append(\"g\").attr(\"class\",\"labels\")\n",
       "    .selectAll(\"g\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "\n",
       "text.append(\"text\")\n",
       "    .attr(\"class\", \"label-text\")\n",
       "    .attr(\"x\", function(d) {\n",
       "        var r = (d.size === undefined) ? 15 : d.size;\n",
       "        return 5 + r; })\n",
       "    .attr(\"dy\", \".31em\")\n",
       "    .text(function(d) { return d.label; });\n",
       "\n",
       "/*Scale weight for d3js */\n",
       "var weightScale = d3.scaleLinear()\n",
       "    .domain(d3.extent(links, function (d) { return d.weight }))\n",
       "    .range([.1, 1]);\n",
       "\n",
       "/*Simulation of the forces*/\n",
       "var simulation = d3.forceSimulation(nodes)\n",
       "    .force(\"links\", d3.forceLink(links)\n",
       "           .id(function(d) {return d.uid; })\n",
       "           .distance(50)\n",
       "           .strength(function(d){return weightScale(d.weight);})\n",
       "          )\n",
       "    .force(\"charge\", d3.forceManyBody()\n",
       "           .strength(charge_force)\n",
       "           .distanceMax(charge_distance)\n",
       "          )\n",
       "    .force(\"center\", d3.forceCenter(width / 2, height / 2))\n",
       "    .on(\"tick\", ticked);\n",
       "\n",
       "/*Update of the node and edge objects*/\n",
       "function ticked() {\n",
       "    node.call(updateNode);\n",
       "    link.call(updateLink);\n",
       "    text.call(updateText);\n",
       "};\n",
       "\n",
       "/*Update link positions */\n",
       "function updateLink(link) {\n",
       "    // link\n",
       "    //     .attr(\"x1\", function(d) { return d.source.x; })\n",
       "    //     .attr(\"y1\", function(d) { return d.source.y; })\n",
       "    //     .attr(\"x2\", function(d) { return d.target.x; })\n",
       "    //     .attr(\"y2\", function(d) { return d.target.y; });\n",
       "\n",
       "\n",
       "    link.attr(\"d\", function(d) {\n",
       "        var dx = d.target.x - d.source.x,\n",
       "            dy = d.target.y - d.source.y,\n",
       "            dr = Math.sqrt(dx * dx + dy * dy);\n",
       "        if(!curved)dr=0;\n",
       "        return \"M\" +\n",
       "            d.source.x + \",\" +\n",
       "            d.source.y + \"A\" +\n",
       "            dr + \",\" + dr + \" 0 0,1 \" +\n",
       "            d.target.x + \",\" +\n",
       "            d.target.y;\n",
       "    });\n",
       "\n",
       "    // recalculate and back off the distance\n",
       "    link.attr(\"d\", function (d, i) {\n",
       "        var pl = this.getTotalLength();\n",
       "        var r = (d.target.size === undefined) ? 15 : d.target.size;\n",
       "        var m = this.getPointAtLength(pl - r);\n",
       "        var dx = d.target.x - d.source.x,\n",
       "            dy = d.target.y - d.source.y,\n",
       "            dr = Math.sqrt(dx * dx + dy * dy);\n",
       "        if(!curved)dr=0;\n",
       "        var result = \"M\" + d.source.x + \",\" + d.source.y + \"A\" + dr + \",\" + dr + \" 0 0,1 \" + m.x + \",\" + m.y;\n",
       "        return result;\n",
       "    });\n",
       "};\n",
       "\n",
       "\n",
       "/*Update node positions */\n",
       "function updateNode(node) {\n",
       "    node.attr(\"transform\", function(d) {\n",
       "        return \"translate(\" + d.x + \",\" + d.y + \")\";\n",
       "    });\n",
       "    // node\n",
       "    //     .attr(\"cx\", function(d) { return d.x; })\n",
       "    //     .attr(\"cy\", function(d) { return d.y; });\n",
       "};\n",
       "\n",
       "/*Update text positions */\n",
       "function updateText(text) {\n",
       "    text.attr(\"transform\", function(d) {\n",
       "        return \"translate(\" + d.x + \",\" + d.y + \")\";\n",
       "    });\n",
       "};\n",
       "\n",
       "/*Add drag functionality to the node objects*/\n",
       "node.call(\n",
       "    d3.drag()\n",
       "        .on(\"start\", dragstarted)\n",
       "        .on(\"drag\", dragged)\n",
       "        .on(\"end\", dragended)\n",
       ");\n",
       "\n",
       "function dragstarted(d) {\n",
       "    d3.event.sourceEvent.stopPropagation();\n",
       "    if (!d3.event.active) simulation.alphaTarget(0.3).restart();\n",
       "    d.fx = d.x;\n",
       "    d.fy = d.y;\n",
       "};\n",
       "\n",
       "function dragged(d) {\n",
       "    d.fx = d3.event.x;\n",
       "    d.fy = d3.event.y;\n",
       "};\n",
       "\n",
       "function dragended(d) {\n",
       "    if (!d3.event.active) simulation.alphaTarget(0);\n",
       "    d.fx = null;\n",
       "    d.fy = null;\n",
       "};\n",
       "\n",
       "}); //END\n",
       "\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pp.plot(g, edge_color='gray', node_label=g.mapping.node_ids.tolist());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 3 nodes and 3 edges\n",
      "{'Edge Attributes': {}, 'Graph Attributes': {'num_nodes': \"<class 'int'>\"}, 'Node Attributes': {}}\n",
      "   v  w\n",
      "0  a  b\n",
      "1  b  c\n",
      "2  c  a\n"
     ]
    }
   ],
   "source": [
    "g = pp.Graph.from_edge_list([('a','b'), ('b','c'), ('c','a')])\n",
    "print(g)\n",
    "\n",
    "df = pp.io.graph_to_df(g)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 3 nodes and 3 edges\n",
      "{'Edge Attributes': {'edge_weight': \"<class 'list'>\"}, 'Graph Attributes': {'num_nodes': \"<class 'int'>\"}, 'Node Attributes': {}}\n",
      "   v  w  edge_weight\n",
      "0  a  b          1.0\n",
      "1  b  c          2.0\n",
      "2  c  a          3.0\n"
     ]
    }
   ],
   "source": [
    "g.data.edge_weight = [1.0, 2.0, 3.0]\n",
    "print(g)\n",
    "\n",
    "df = pp.io.graph_to_df(g)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   v  node_size\n",
      "0  b        5.0\n",
      "1  a        2.0\n",
      "2  c        1.0\n"
     ]
    }
   ],
   "source": [
    "node_attr = pd.DataFrame({'v': ['b', 'a', 'c'], 'node_size': [5.0, 2.0, 1.0]})\n",
    "print(node_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping node attributes based on node names in column `v`\n",
      "tensor([2., 5., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pp.io.add_node_attributes(node_attr, g)\n",
    "print(g.data.node_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   v  w  edge_weight\n",
      "0  c  a         42.0\n",
      "1  a  b         43.0\n",
      "2  b  c         45.0\n"
     ]
    }
   ],
   "source": [
    "edge_attr = pd.DataFrame({'v': ['c', 'a', 'b'], 'w': ['a', 'b', 'c'], 'edge_weight': [42.0, 43.0, 45.0]})\n",
    "print(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeIndex([[0, 1, 2],\n",
      "           [1, 2, 0]], sparse_size=(3, 3), nnz=3, sort_order=row)\n",
      "tensor([45., 42., 43.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pp.io.add_edge_attributes(edge_attr, g)\n",
    "print(g.data.edge_index)\n",
    "print(g.data.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   v  w  edge_weight\n",
      "0  0  1         45.0\n",
      "1  1  2         42.0\n",
      "2  2  0         43.0\n"
     ]
    }
   ],
   "source": [
    "df = pp.io.graph_to_df(g, node_indices=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2\n",
      "0     c     a     b\n",
      "1     a     b     c\n",
      "2  42.0  43.0  45.0\n"
     ]
    }
   ],
   "source": [
    "edge_attr = pd.DataFrame([['c', 'a', 'b'], ['a', 'b', 'c'], [42.0, 43.0, 45.0]])\n",
    "print(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.io.write_csv(g, '../data/test_graph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directed graph with 3 nodes and 3 edges\n",
      "{'Edge Attributes': {'edge_weight': \"<class 'torch.Tensor'> -> torch.Size([3])\"}, 'Graph Attributes': {'num_nodes': \"<class 'int'>\"}, 'Node Attributes': {}}\n",
      "Data(edge_index=[2, 3], num_nodes=3, node_sequence=[3, 1], edge_weight=[3])\n",
      "a -> 0\n",
      "b -> 1\n",
      "c -> 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = pp.io.read_csv_graph('../data/test_graph.csv')\n",
    "print(g)\n",
    "print(g.data)\n",
    "print(g.mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edge_weight']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.edge_attrs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 3], num_nodes=3, node_sequence=[3, 1], edge_weight=[3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `networkx` Delegate Mechanism\n",
    "\n",
    "To calculate node centralities, we can use a `networkx` delegate mechanism implemented in the module `pathpyG.algorithms.centrality`. Simply speaking, you can call any function implented in the `networkx.centrality` module whose name ends with `_centrality`. The `pathpyG` graph object will be internally converted to a `networkx.DiGraph` object, the corresponding centrality function (with all of its parameters) will be called, and the result will be mapped back to nodes based on node IDs.\n",
    "\n",
    "In order to calculate the closeness centralities of all nodes for the graph above, we can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.6666666666666666, 'b': 0.6666666666666666, 'c': 0.6666666666666666}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.centrality.closeness_centrality(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.5773502691896258, 'b': 0.5773502691896258, 'c': 0.5773502691896258}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.centrality.eigenvector_centrality(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.5773502691896258, 'b': 0.5773502691896258, 'c': 0.5773502691896258}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.algorithms.centrality.katz_centrality(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Generating functions for degree distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "y = pp.statistics.degree_generating_function(g.to_undirected(), x)\n",
    "ax = sns.lineplot(x=x, y=y)\n",
    "ax.set_xlabel('$x$', fontsize=16)\n",
    "ax.set_ylabel('$G_0(x)$', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "2.0\n",
      "Molloy-Reed Fraction <k^2>/<k>:  2.0\n"
     ]
    }
   ],
   "source": [
    "k_2 = pp.statistics.degree_raw_moment(g.to_undirected(), k=2)\n",
    "print(k_2)\n",
    "k_1 = pp.statistics.degree_raw_moment(g.to_undirected(), k=1)\n",
    "print(k_1)\n",
    "print('Molloy-Reed Fraction <k^2>/<k>: ', k_2/k_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
